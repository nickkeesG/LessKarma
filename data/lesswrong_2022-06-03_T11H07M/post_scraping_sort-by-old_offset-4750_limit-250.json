{"results": [{"createdAt": null, "postedAt": "2011-10-02T07:40:13.176Z", "modifiedAt": null, "url": null, "title": "[Funny] Even Clippy can be blamed on the use of non-Bayesian methods", "slug": "funny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.185Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8Cdn7z7eM7CWs87Xm/funny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian", "pageUrlRelative": "/posts/8Cdn7z7eM7CWs87Xm/funny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian", "linkUrl": "https://www.lesswrong.com/posts/8Cdn7z7eM7CWs87Xm/funny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian", "postedAtFormatted": "Sunday, October 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BFunny%5D%20Even%20Clippy%20can%20be%20blamed%20on%20the%20use%20of%20non-Bayesian%20methods&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BFunny%5D%20Even%20Clippy%20can%20be%20blamed%20on%20the%20use%20of%20non-Bayesian%20methods%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Cdn7z7eM7CWs87Xm%2Ffunny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BFunny%5D%20Even%20Clippy%20can%20be%20blamed%20on%20the%20use%20of%20non-Bayesian%20methods%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Cdn7z7eM7CWs87Xm%2Ffunny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8Cdn7z7eM7CWs87Xm%2Ffunny-even-clippy-can-be-blamed-on-the-use-of-non-bayesian", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<p>From <a href=\"http://people.cs.ubc.ca/~murphyk/Bayes/econ.22mar01.html\">this 2001 article</a>:</p>\n<blockquote>\n<p>\n<p>Eric Horvitz... feels bad about [Microsoft Office's Clippy]... many people regard the paperclip as annoyingly over-enthusiastic, since it appears without warning and gets in the way.</p>\n<p>To be fair, that is not Dr Horvitz's fault. Originally, he programmed the paperclip to use Bayesian decision-making techniques both to determine when to pop up, and to decide what advice to offer...</p>\n<p>The paperclip's problem is that the algorithm... that determined when it should appear was deemed too cautious. To make the feature more prominent, a cruder non-Bayesian algorithm was substituted in the final product, so the paperclip would pop up more often.</p>\n<p>Ever since, Dr Horvitz has wondered whether he should have fought harder to keep the original algorithm.</p>\n</p>\n</blockquote>\n<p><em>I</em>, at least, found this amusing.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"HFou6RHqFagkyrKkW": 1, "LhX3F2SvGDarZCuh6": 1, "hNFdS3rRiYgqqD8aM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8Cdn7z7eM7CWs87Xm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 54, "baseScore": 41, "extendedScore": null, "score": 7.779110330802976e-07, "legacy": true, "legacyId": "10253", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-02T09:05:25.900Z", "modifiedAt": null, "url": null, "title": "Open thread, October 2011", "slug": "open-thread-october-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:40.813Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MarkusRamikin", "createdAt": "2011-06-08T11:45:41.506Z", "isAdmin": false, "displayName": "MarkusRamikin"}, "userId": "eiLDv2Z6N8zDn87mK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Czxzzkq3Z5PYDhnKa/open-thread-october-2011", "pageUrlRelative": "/posts/Czxzzkq3Z5PYDhnKa/open-thread-october-2011", "linkUrl": "https://www.lesswrong.com/posts/Czxzzkq3Z5PYDhnKa/open-thread-october-2011", "postedAtFormatted": "Sunday, October 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20October%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20October%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCzxzzkq3Z5PYDhnKa%2Fopen-thread-october-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20October%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCzxzzkq3Z5PYDhnKa%2Fopen-thread-october-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCzxzzkq3Z5PYDhnKa%2Fopen-thread-october-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p>This thread is for discussing anything that doesn't seem to deserve its own post.</p>\n<p>If the resulting discussion becomes impractical to continue here, it means the topic is a promising candidate for its own thread.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Czxzzkq3Z5PYDhnKa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.779397377444039e-07, "legacy": true, "legacyId": "10254", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 314, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-02T09:05:58.698Z", "modifiedAt": null, "url": null, "title": "Physics Video Lectures", "slug": "physics-video-lectures", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:38.587Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k4vcr4Z5jhdW4L2Fr/physics-video-lectures", "pageUrlRelative": "/posts/k4vcr4Z5jhdW4L2Fr/physics-video-lectures", "linkUrl": "https://www.lesswrong.com/posts/k4vcr4Z5jhdW4L2Fr/physics-video-lectures", "postedAtFormatted": "Sunday, October 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Physics%20Video%20Lectures&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhysics%20Video%20Lectures%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4vcr4Z5jhdW4L2Fr%2Fphysics-video-lectures%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Physics%20Video%20Lectures%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4vcr4Z5jhdW4L2Fr%2Fphysics-video-lectures", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4vcr4Z5jhdW4L2Fr%2Fphysics-video-lectures", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 47, "htmlBody": "<p>The Perimeter Institute has videos of classes of all of their areas of research:</p>\n<p>http://www.perimeterinstitute.ca/en/Outreach/What_We_Research/Quantum_Gravity/</p>\n<p>http://www.perimeterinstitute.ca/en/Outreach/What_We_Research/Superstring_Theory_/</p>\n<p>http://www.perimeterinstitute.ca/en/Outreach/What_We_Research/Quantum_Foundations_/</p>\n<p>http://www.perimeterinstitute.ca/en/Outreach/What_We_Research/Cosmology_%26_Gravitation/</p>\n<p>http://www.perimeterinstitute.ca/en/Outreach/What_We_Research/Particle_Physics_/</p>\n<p>http://www.perimeterinstitute.ca/en/Outreach/What_We_Research/Quantum_Information/</p>\n<p>Scroll to the bottom for the lectures.</p>\n<p>&nbsp;</p>\n<p>A lecture from 2005&nbsp; by Roger Penrose on the pre-Big Bang and Weyl Curvature.</p>\n<p><a href=\"http://www.newton.ac.uk/webseminars/pg+ws/2005/gmr/gmrw04/1107/penrose/index.html\">INI Web Seminars: Penrose, 2005-11-07</a></p>\n<p>This one is quite good. \"Time is nothing to a photon.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k4vcr4Z5jhdW4L2Fr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 5, "extendedScore": null, "score": 7.779399218790175e-07, "legacy": true, "legacyId": "10255", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-02T23:01:02.843Z", "modifiedAt": null, "url": null, "title": "Meetup : Stockholm meetup", "slug": "meetup-stockholm-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:00.712Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NihilCredo", "createdAt": "2009-04-22T23:40:56.227Z", "isAdmin": false, "displayName": "NihilCredo"}, "userId": "W6f2cwKiKSroig5kb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2Fr73xx2JWryaSWD4/meetup-stockholm-meetup", "pageUrlRelative": "/posts/2Fr73xx2JWryaSWD4/meetup-stockholm-meetup", "linkUrl": "https://www.lesswrong.com/posts/2Fr73xx2JWryaSWD4/meetup-stockholm-meetup", "postedAtFormatted": "Sunday, October 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Stockholm%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Stockholm%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Fr73xx2JWryaSWD4%2Fmeetup-stockholm-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Stockholm%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Fr73xx2JWryaSWD4%2Fmeetup-stockholm-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Fr73xx2JWryaSWD4%2Fmeetup-stockholm-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/3u'>Stockholm meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 October 2011 02:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 Tabac (Stora Nygatan 46, Gamla Stan, Stockholm, Sweden)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Where there are nerds there are Swedes, and LessWrong is no exception. Let's meet up!</p>\n\n<p>The first event, as normal, will be more about introducing ourselves, sharing interests, and generally having a good time. We will then decide what would interest us further (rationalist book club? Regular discussion of LW material? Scientific/math/CS/language subjects? Social/political activism? etc.)</p>\n\n<p><strong>If you are interested but cannot attend this meetup for whatever reason, leave a comment! We want to know you're out there!</strong> (Also, the date is flexible)</p>\n\n<p>Disclaimer: I don't live in Stockholm so I don't have much experience with its venues in the daytime. I tried to pick something in a central location and without terrible reviews, but locals should feel free to recommend alternatives. In particular, if you know a library that has a caf\u00e9 or meeting room, I believe that would be ideal; biblioteket.se is rather unhelpful to that end.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/3u'>Stockholm meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2Fr73xx2JWryaSWD4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.782213239183623e-07, "legacy": true, "legacyId": "10256", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Stockholm_meetup\">Discussion article for the meetup : <a href=\"/meetups/3u\">Stockholm meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 October 2011 02:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 Tabac (Stora Nygatan 46, Gamla Stan, Stockholm, Sweden)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Where there are nerds there are Swedes, and LessWrong is no exception. Let's meet up!</p>\n\n<p>The first event, as normal, will be more about introducing ourselves, sharing interests, and generally having a good time. We will then decide what would interest us further (rationalist book club? Regular discussion of LW material? Scientific/math/CS/language subjects? Social/political activism? etc.)</p>\n\n<p><strong>If you are interested but cannot attend this meetup for whatever reason, leave a comment! We want to know you're out there!</strong> (Also, the date is flexible)</p>\n\n<p>Disclaimer: I don't live in Stockholm so I don't have much experience with its venues in the daytime. I tried to pick something in a central location and without terrible reviews, but locals should feel free to recommend alternatives. In particular, if you know a library that has a caf\u00e9 or meeting room, I believe that would be ideal; biblioteket.se is rather unhelpful to that end.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Stockholm_meetup1\">Discussion article for the meetup : <a href=\"/meetups/3u\">Stockholm meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Stockholm meetup", "anchor": "Discussion_article_for_the_meetup___Stockholm_meetup", "level": 1}, {"title": "Discussion article for the meetup : Stockholm meetup", "anchor": "Discussion_article_for_the_meetup___Stockholm_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "22 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-03T03:10:21.073Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Self-Anchoring", "slug": "seq-rerun-self-anchoring", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HF6qxQdkpBQicC2jc/seq-rerun-self-anchoring", "pageUrlRelative": "/posts/HF6qxQdkpBQicC2jc/seq-rerun-self-anchoring", "linkUrl": "https://www.lesswrong.com/posts/HF6qxQdkpBQicC2jc/seq-rerun-self-anchoring", "postedAtFormatted": "Monday, October 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Self-Anchoring&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Self-Anchoring%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHF6qxQdkpBQicC2jc%2Fseq-rerun-self-anchoring%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Self-Anchoring%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHF6qxQdkpBQicC2jc%2Fseq-rerun-self-anchoring", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHF6qxQdkpBQicC2jc%2Fseq-rerun-self-anchoring", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 166, "htmlBody": "<p>Today's post, <a href=\"/lw/kf/selfanchoring/\">Self-Anchoring</a> was originally published on 22 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Related to contamination and the illusion of transparancy, we \"anchor\" on our own experience and underadjust when trying to understand others.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/7wo/seq_rerun_illusion_of_transparency_why_no_one/\">Illusion of Transparency: Why No One Understands You</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HF6qxQdkpBQicC2jc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 7.783053693676796e-07, "legacy": true, "legacyId": "10257", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sWtvoBsknYvS6QPTb", "LJc7WqrRvp4q7Xd64", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-03T06:41:13.512Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes October 2011", "slug": "rationality-quotes-october-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:57.511Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LsK7FBHLrWJkbdwo7/rationality-quotes-october-2011", "pageUrlRelative": "/posts/LsK7FBHLrWJkbdwo7/rationality-quotes-october-2011", "linkUrl": "https://www.lesswrong.com/posts/LsK7FBHLrWJkbdwo7/rationality-quotes-october-2011", "postedAtFormatted": "Monday, October 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20October%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20October%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLsK7FBHLrWJkbdwo7%2Frationality-quotes-october-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20October%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLsK7FBHLrWJkbdwo7%2Frationality-quotes-october-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLsK7FBHLrWJkbdwo7%2Frationality-quotes-october-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Here's the new thread for posting quotes, with the usual rules:</p>\n<ul style=\"padding: 0px;\">\n<li>Please post all quotes separately, so that they can be voted up/down separately.&nbsp;&nbsp;(If they are strongly related, reply to your own comments.&nbsp;&nbsp;If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LsK7FBHLrWJkbdwo7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.783763073371518e-07, "legacy": true, "legacyId": "10246", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 541, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-03T08:15:48.972Z", "modifiedAt": null, "url": null, "title": "January 2011 Oxford Intelligence Conference videos online", "slug": "january-2011-oxford-intelligence-conference-videos-online", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AGYSqce4TMTT8ckMz/january-2011-oxford-intelligence-conference-videos-online", "pageUrlRelative": "/posts/AGYSqce4TMTT8ckMz/january-2011-oxford-intelligence-conference-videos-online", "linkUrl": "https://www.lesswrong.com/posts/AGYSqce4TMTT8ckMz/january-2011-oxford-intelligence-conference-videos-online", "postedAtFormatted": "Monday, October 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20January%202011%20Oxford%20Intelligence%20Conference%20videos%20online&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJanuary%202011%20Oxford%20Intelligence%20Conference%20videos%20online%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGYSqce4TMTT8ckMz%2Fjanuary-2011-oxford-intelligence-conference-videos-online%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=January%202011%20Oxford%20Intelligence%20Conference%20videos%20online%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGYSqce4TMTT8ckMz%2Fjanuary-2011-oxford-intelligence-conference-videos-online", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAGYSqce4TMTT8ckMz%2Fjanuary-2011-oxford-intelligence-conference-videos-online", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 22, "htmlBody": "<p><a href=\"http://www.fhi.ox.ac.uk/multimedia_all/wic_videos2\">Here</a>. Including, for example, Nick Bostrom's talk \"Superintelligence: The Control Problem\" and Jurgen Schmidhuber's talk \"Universal AI &amp; Formal Theory of Fun.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AGYSqce4TMTT8ckMz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 7.784083697692057e-07, "legacy": true, "legacyId": "10259", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-03T16:06:40.329Z", "modifiedAt": null, "url": null, "title": "Bayesian analysis under threat in British courts", "slug": "bayesian-analysis-under-threat-in-british-courts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.285Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "whpearson", "createdAt": "2009-02-28T00:34:00.976Z", "isAdmin": false, "displayName": "whpearson"}, "userId": "bq8qsRbPNvFihHxgi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iYpcyA2JRNRQNwn3q/bayesian-analysis-under-threat-in-british-courts", "pageUrlRelative": "/posts/iYpcyA2JRNRQNwn3q/bayesian-analysis-under-threat-in-british-courts", "linkUrl": "https://www.lesswrong.com/posts/iYpcyA2JRNRQNwn3q/bayesian-analysis-under-threat-in-british-courts", "postedAtFormatted": "Monday, October 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20analysis%20under%20threat%20in%20British%20courts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20analysis%20under%20threat%20in%20British%20courts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYpcyA2JRNRQNwn3q%2Fbayesian-analysis-under-threat-in-british-courts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20analysis%20under%20threat%20in%20British%20courts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYpcyA2JRNRQNwn3q%2Fbayesian-analysis-under-threat-in-british-courts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiYpcyA2JRNRQNwn3q%2Fbayesian-analysis-under-threat-in-british-courts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<p>This is an interesting article talking about the <a href=\"http://www.guardian.co.uk/law/2011/oct/02/formula-justice-bayes-theorem-miscarriage\">use of bayes in british courts</a> and efforts to improve how statistics are used in court cases. Probably worth keeping an eye on. It might expose more people to bayes if it becomes common and thus portrayed in TV dramas.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iYpcyA2JRNRQNwn3q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 7.785671859764109e-07, "legacy": true, "legacyId": "10262", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-03T20:24:14.748Z", "modifiedAt": null, "url": null, "title": "Knox and Sollecito freed", "slug": "knox-and-sollecito-freed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:57.899Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "komponisto", "createdAt": "2009-03-01T21:10:23.585Z", "isAdmin": false, "displayName": "komponisto"}, "userId": "h48TMtPzfimsEobTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sA7MtWkdyJHFrDyce/knox-and-sollecito-freed", "pageUrlRelative": "/posts/sA7MtWkdyJHFrDyce/knox-and-sollecito-freed", "linkUrl": "https://www.lesswrong.com/posts/sA7MtWkdyJHFrDyce/knox-and-sollecito-freed", "postedAtFormatted": "Monday, October 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Knox%20and%20Sollecito%20freed&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKnox%20and%20Sollecito%20freed%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsA7MtWkdyJHFrDyce%2Fknox-and-sollecito-freed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Knox%20and%20Sollecito%20freed%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsA7MtWkdyJHFrDyce%2Fknox-and-sollecito-freed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsA7MtWkdyJHFrDyce%2Fknox-and-sollecito-freed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p><strong>See:</strong> <strong><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/\">You Be the Jury</a>, <a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/\">The Amanda Knox Test</a></strong></p>\n<p>While we hear about <a href=\"/r/discussion/lw/7x2/bayesian_analysis_under_threat_in_british_courts/\">Bayes' Theorem being under threat in some courts</a>, it is nice to savor <a href=\"http://www.cbsnews.com/stories/2011/10/03/501364/main20114867.shtml\">the occasional moment of rationality prevailing in the justice system, and of mistakes being corrected.</a></p>\n<p>Congratulations to the Italian court system for successfully <a href=\"/lw/i9/the_importance_of_saying_oops/\">saying \"Oops!\"&nbsp;</a></p>\n<p>Things go wrong in this world quite a bit, as we know. Sometimes it's appropriate to just say \"hooray!\" when they go right.</p>\n<p>Discuss, or celebrate.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3RnEKrsNgNEDxuNnw": 1, "wGGAjTfXZBatQkft5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sA7MtWkdyJHFrDyce", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 39, "extendedScore": null, "score": 7.786540879176403e-07, "legacy": true, "legacyId": "10263", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["mkAcXPEJ7RZCJs8ry", "G9dptrW9CJi7wNg3b", "iYpcyA2JRNRQNwn3q", "wCqfCLs8z5Qw4GbKS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T02:45:31.391Z", "modifiedAt": "2020-03-06T04:12:36.127Z", "url": null, "title": "Rationality Lessons Learned from Irrational Adventures in Romance", "slug": "rationality-lessons-learned-from-irrational-adventures-in", "viewCount": null, "lastCommentedAt": "2018-08-20T16:27:29.645Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x8Fp9NMgDWbuMpizA/rationality-lessons-learned-from-irrational-adventures-in", "pageUrlRelative": "/posts/x8Fp9NMgDWbuMpizA/rationality-lessons-learned-from-irrational-adventures-in", "linkUrl": "https://www.lesswrong.com/posts/x8Fp9NMgDWbuMpizA/rationality-lessons-learned-from-irrational-adventures-in", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Lessons%20Learned%20from%20Irrational%20Adventures%20in%20Romance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Lessons%20Learned%20from%20Irrational%20Adventures%20in%20Romance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx8Fp9NMgDWbuMpizA%2Frationality-lessons-learned-from-irrational-adventures-in%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Lessons%20Learned%20from%20Irrational%20Adventures%20in%20Romance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx8Fp9NMgDWbuMpizA%2Frationality-lessons-learned-from-irrational-adventures-in", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx8Fp9NMgDWbuMpizA%2Frationality-lessons-learned-from-irrational-adventures-in", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1764, "htmlBody": "<p><img style=\"float: right; padding: 10px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/UnhappyCouple.jpg\" alt=\"\" /><small>Gooey personal details alert! See also: Alicorn's <a href=\"/lw/79x/polyhacking\">Polyhacking</a>.</small></p>\n<p>Years ago, my first girlfriend (let's call her 'Alice') ran into her ex-boyfriend at a coffee shop. They traded anecdotes, felt connected, a spark of intimacy...</p>\n<p>And then she left the coffee shop, quickly.</p>\n<p>Later she explained: \"<em>You</em> have my heart now, Luke.\"</p>\n<p>I felt proud, but even Luke<sub>2005</sub>&nbsp;also felt a twinge of \"the universe is suboptimal,\" because Alice hadn't been able to engage that connection any further. The cultural scripts defining our relationship said that only <em>one</em> man owned her heart. But surely that wasn't optimal for producing utilons?</p>\n<p>This is an account of some lessons in rationality that I learned during my journeys in romance.<sup>*</sup> I haven't been very rational in my relationships until recently, but in retrospect I learned a fair bit about rationality from the failures resulting from my&nbsp;<em>irrationality</em> in past relationships.</p>\n<p>Early lessons included realizations like the one above &mdash; that I wasn't happy with the standard cultural scripts. I hadn't really noticed the cultural scripts up until that point. I was a victim of <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a> and a <a href=\"/lw/4e/cached_selves/\">cached self</a>.</p>\n<p><em>Rationality Lesson</em>: Until you explicitly notice the cached rules for what you're doing, you won't start thinking of them as something to be optimized. Ask yourself: Which parts of romance do you currently think of as subjects of optimization? What else should you be optimizing?</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Gather data</h4>\n<p>At the time, I didn't know how to optimize. I decided I needed data. How did relationships work? How did women work? How did attraction work? The value of information was high, so I decided to become a <a href=\"http://www.amazon.com/Social-Psychology-7th-Elliot-Aronson/dp/0138144788/\">social psychology</a> nerd. I began to spend less time with Alice so I could spend more time studying.</p>\n<p>This wasn't easy. She and I had connected in some pretty intimate ways, including a simultaneous <a href=\"/lw/7dy/a_rationalists_tale/\">deconversion</a> from fundamentalist Christianity. But in the end my studies paid off. Moreover, my studies in personality and relationship styles helped me to realize that I (and therefore she) would have been miserable if I had decided to pursue marriage with her (or anyone at the time). Now <em>that</em>&nbsp;is valuable information to have!</p>\n<p><em>Rationality Lesson</em>: Respond to <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">the value of information</a>. Once you notice you might be running in the wrong direction, don't keep going that way just because you've got momentum. Stop a moment, and invest some energy in the thoughts or information you've now realized is valuable because it might change your policies, i.e., figuring out <em>which</em> direction to go.</p>\n<p>&nbsp;</p>\n<h4>Sanity-check yourself</h4>\n<p>Before long, Alice was always pushing me to spend more time with her, and I was always pushing to spend more time studying psychology.&nbsp;By then I knew I couldn't give her what she wanted: marriage.</p>\n<p>So I broke up with Alice over a long conversation that included an hour-long primer on evolutionary psychology in which I explained how natural selection had built me to be attracted to certain features that she lacked. I thought she would appreciate this because she had previously expressed admiration for detailed honesty. Now I realize that there's hardly a <em>more</em>&nbsp;damaging way to break up with someone. She asked that I kindly never speak to her again, and I can't blame her.</p>\n<p>This gives you some idea of just how incompetent I was, at the time. I had <em>some</em>&nbsp;idea of how incompetent I was, but not enough of one to avoid badly wounding somebody I loved.</p>\n<p><em>Rationality Lesson</em>: Know your fields of incompetence. If you suspect you may be incompetent, sanity-check yourself by asking others for advice, or by Googling. (E.g. \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+break+up+with+your+girlfriend+nicely\">how to break up with your girlfriend nicely</a>\", or \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+not+die+on+a+motorcycle\">how to not die on a motorcycle</a>\" or whatever.)</p>\n<p>&nbsp;</p>\n<h4>Study</h4>\n<p>During the next couple years, I spent <em>no</em>&nbsp;time in (what would have been) sub-par relationships, and instead invested that time optimizing for better relationships in the future. Which meant I was celibate.</p>\n<p>Neither <em><a href=\"http://www.amazon.com/Intimate-Relationships-Thomas-N-Bradbury/dp/0393979571/\">Intimate Relationships</a>&nbsp;</em>nor <em><a href=\"http://www.amazon.com/Handbook-Relationship-Initiation-Susan-Sprecher/dp/0805861599/\">Handbook of Relationship Initiation</a></em>&nbsp;existed at the time, but I still learned quite a bit from books like <em><a href=\"http://www.amazon.com/Red-Queen-Evolution-Human-Nature/dp/0060556579/\">The Red Queen</a></em>&nbsp;and <em><a href=\"http://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/\">The Moral Animal</a></em>. I experienced a long series of 'Aha!' moments, like:</p>\n<ul>\n<li>\"Aha! Body language and fashion matter because they communicate large packets of information about me at light speed, and are harder to fake than words.\"</li>\n<li>\"Aha! Women <em>want</em>&nbsp;men to be better at making them laugh and feel good and get aroused and not be creeped out. They <em>want</em>&nbsp;men to be as purposefully skilled at flirting and social awareness as <em>they</em> are. Many a young woman is&nbsp;<em>tired</em>&nbsp;of running into men whom they <em>could</em> be attracted to except for the fact that he doesn't know how to have a fun conversation, doesn't know how to create arousal in her, and doesn't know how to lead her smoothly from flirting to great sex.\"</li>\n<li>\"Aha! When women say \"Be yourself,\" they mean \"Don't be fake; be uniquely you.\" But they <em>don't</em>&nbsp;mean \"Just keep acting and talking the awkward way you do now because you haven't learned the skills required to be the best man you can be.\"</li>\n</ul>\n<p>Within a few months, I had more dating-relevant <em>head</em> knowledge than any guy I knew.</p>\n<p><em>Lesson</em>: Use <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">scholarship</a>. Especially if you can do it <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">efficiently</a>, scholarship is a quick and cheap way to gain a certain class of experience points.</p>\n<p>&nbsp;</p>\n<h4>Just try it / just test yourself</h4>\n<p>Scholarship was warm and comfy, so I stayed in scholar mode for too long. I hit diminishing returns in what books could teach me. Every book on dating skills told me to go talk to women, but I thought I needed a completed decision tree first: <em>What if she does this? What if she says that? I won't know what to do if I don't have a plan! I should read 10 more books, so I know how to handle every contingency</em>.</p>\n<p>The dating books <em>told</em>&nbsp;me I would think that, but I told myself I was unusually analytical, and could actually benefit from completing the decision tree in advance of actually talking to women.</p>\n<p>The dating books told me I would think <em>that</em>, too, and that it was just a rationalization. Really, I was just nervous about the blows my ego would receive from newbie mistakes.</p>\n<p><em>Rationality Lesson</em>: Be especially suspicious of <a href=\"http://wiki.lesswrong.com/wiki/Rationalization\">rationalizations</a> for not obeying the empiricist rules \"try it and see what happens\" or \"test yourself to see what happens\" or \"get some concrete experience on the ground\". Think of the cost of time happening as a result of rationalizing. Consider the opportunities you are missing if you don't just realize you're wrong right <em>now</em>&nbsp;and change course. How many months or years will your life be less awesome as a result? How many opportunities will you miss while you're still (kinda) young?</p>\n<p>&nbsp;</p>\n<h4>Use science, and maybe drugs</h4>\n<p>The dating books told me to swallow my fear and talk to women. I couldn't swallow my fear, so I tried swallowing <a href=\"http://www.ejbrandy.com/\">brandy</a> instead. That worked.</p>\n<p>So I went out and talked to women, mostly at coffee shops or on the street. I learned all kinds of interesting details I hadn't learned in the books about what makes an interaction fun for most women:</p>\n<ul>\n<li>Keep up the emotional momentum. Don't stay in the same stage of the conversation (rapport, storytelling, self-disclosure, etc.) for very long.</li>\n<li>Almost every gesture or line is improved by adding a big smile.</li>\n<li>\"Hi. I've gotta run, but I think you're cute so we should grab a coffee sometime\" totally <em>works</em> &mdash; as long as the other person is already attracted because my body language, fashion, and other signals have been optimized.</li>\n</ul>\n<p>After a while, I could talk to women even without the brandy. And a little after that, I had my first one-night stand, which was great because it was exactly what she and I wanted.</p>\n<p>But as time passed I was surprised by how much I <em>didn't</em>&nbsp;enjoy casual flings. I didn't feel engaged when I didn't know and didn't have much in common with the girl in my bed. I had gone in thinking all I wanted was sex, but it turned out that I wanted <em>connection</em> to another person. (And sex.)</p>\n<p><em>Rationality Lesson</em>: Use empiricism and <a href=\"/lw/3wh/science_do_it_yourself/\">do-it-yourself science</a>. <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just try things</a>. <a href=\"/lw/5a5/no_seriously_just_try_it/\">No, seriously</a>.</p>\n<p>&nbsp;</p>\n<h4>Self-modify to succeed</h4>\n<p>By this time my misgivings about the idea of \"owning\" another's sexuality had led me to adopt a polyamorous mindset for myself. (I saw many other people apparently happy with monogamy, but it wasn't for <em>me</em>.) But if I was going to be polyamorous, I needed to deprogram my sexual jealousy, which sounded daunting. Sexual jealousy was hard-wired into me by evolution, right?</p>\n<p>It turned out to be easier than I had predicted. <a href=\"http://books.google.com/books?id=SNCy0iqZMskC&amp;lpg=PT87&amp;vq=unlearning%20jealousy&amp;pg=PT87#v=onepage&amp;q&amp;f=false\">Tactics</a> that helped me destroy my capacity for sexual jealousy include:</p>\n<ul>\n<li>Whenever I noticed sexual jealousy in myself, I brought to mind my moral objections to the idea of owning another's sexuality.</li>\n<li>I thought in terms of sexual abundance, not sexual scarcity. When I realized there were thousands of other nearby women I could date, I didn't need to be so needy for any particular girl.</li>\n<li>Mentally, I continually associated 'jealousy' with 'immaturity' and 'neediness' and other concepts that have negative affect for me.</li>\n</ul>\n<p>This lack of sexual jealousy came in handy when I later dated a polyamorous girl who was already dating two of my friends.</p>\n<p><em>Rationality Lesson</em>: Have <a href=\"/lw/2c/a_sense_that_more_is_possible/\">a sense that more is possible</a>. Know that you haven't yet reached the limits of self-modification. Try things. Let your map of what is possible be constrained by evidence, not by popular opinion.</p>\n<p>&nbsp;</p>\n<h4>Finale</h4>\n<p>There might have been a learning curve, but by golly, at the end of all that DIY science and rationality training and scholarship I'm much more romantically capable, I'm free to take up relationships when I want, I know fashion well enough to teach it at <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality camps</a>, and I can build rapport with almost anyone. My hair looks good and I'm happy.</p>\n<p>If you're a nerd-at-heart like me, I highly recommend becoming a nerd <em>about romance</em>, so long as you read the right nerd books and you know the nerd rule about being empirical. <a href=\"/lw/7i/rationality_is_systematized_winning/\">Rationality is for winning</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h3><br /></h3>\n<p><small><sup><a name=\"notes\"></a>*</sup>&nbsp;My thanks to everyone who commented on <a href=\"/lw/6pf/new_post_version_1_please_read_this_only_if_your/\">earlier</a> <a href=\"/r/discussion/lw/6v5/new_post_version_2_please_read_this_only_if_your/\">drafts</a> of this post. Here are the biggest changes I made:</small></p>\n<ul>\n<li><small>Some&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4kia\">said</a>&nbsp;that while it's okay to be analytic about relationships, it would help the tone of the post if it was clear I was interacting with people&nbsp;<em>as people</em>, too. So I added more of that.</small></li>\n<li><small>Some&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4kiv\">thought</a>&nbsp;I implied that everyone could or should be polyamorous, which is not something I intended or believe. I've made that clearer now.</small></li>\n<li><small>Robert Lumley provided some detailed&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4kgc\">comments</a>&nbsp;that I updated in response to.</small></li>\n<li><small>I also made use of some&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4l9u\">suggestions</a>&nbsp;made by HughRistik.</small></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x8Fp9NMgDWbuMpizA", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 91, "baseScore": 73, "extendedScore": null, "score": 0.000143, "legacy": true, "legacyId": "9102", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 74, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><img style=\"float: right; padding: 10px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/UnhappyCouple.jpg\" alt=\"\"><small>Gooey personal details alert! See also: Alicorn's <a href=\"/lw/79x/polyhacking\">Polyhacking</a>.</small></p>\n<p>Years ago, my first girlfriend (let's call her 'Alice') ran into her ex-boyfriend at a coffee shop. They traded anecdotes, felt connected, a spark of intimacy...</p>\n<p>And then she left the coffee shop, quickly.</p>\n<p>Later she explained: \"<em>You</em> have my heart now, Luke.\"</p>\n<p>I felt proud, but even Luke<sub>2005</sub>&nbsp;also felt a twinge of \"the universe is suboptimal,\" because Alice hadn't been able to engage that connection any further. The cultural scripts defining our relationship said that only <em>one</em> man owned her heart. But surely that wasn't optimal for producing utilons?</p>\n<p>This is an account of some lessons in rationality that I learned during my journeys in romance.<sup>*</sup> I haven't been very rational in my relationships until recently, but in retrospect I learned a fair bit about rationality from the failures resulting from my&nbsp;<em>irrationality</em> in past relationships.</p>\n<p>Early lessons included realizations like the one above \u2014 that I wasn't happy with the standard cultural scripts. I hadn't really noticed the cultural scripts up until that point. I was a victim of <a href=\"/lw/k5/cached_thoughts/\">cached thoughts</a> and a <a href=\"/lw/4e/cached_selves/\">cached self</a>.</p>\n<p><em>Rationality Lesson</em>: Until you explicitly notice the cached rules for what you're doing, you won't start thinking of them as something to be optimized. Ask yourself: Which parts of romance do you currently think of as subjects of optimization? What else should you be optimizing?</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Gather_data\">Gather data</h4>\n<p>At the time, I didn't know how to optimize. I decided I needed data. How did relationships work? How did women work? How did attraction work? The value of information was high, so I decided to become a <a href=\"http://www.amazon.com/Social-Psychology-7th-Elliot-Aronson/dp/0138144788/\">social psychology</a> nerd. I began to spend less time with Alice so I could spend more time studying.</p>\n<p>This wasn't easy. She and I had connected in some pretty intimate ways, including a simultaneous <a href=\"/lw/7dy/a_rationalists_tale/\">deconversion</a> from fundamentalist Christianity. But in the end my studies paid off. Moreover, my studies in personality and relationship styles helped me to realize that I (and therefore she) would have been miserable if I had decided to pursue marriage with her (or anyone at the time). Now <em>that</em>&nbsp;is valuable information to have!</p>\n<p><em>Rationality Lesson</em>: Respond to <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">the value of information</a>. Once you notice you might be running in the wrong direction, don't keep going that way just because you've got momentum. Stop a moment, and invest some energy in the thoughts or information you've now realized is valuable because it might change your policies, i.e., figuring out <em>which</em> direction to go.</p>\n<p>&nbsp;</p>\n<h4 id=\"Sanity_check_yourself\">Sanity-check yourself</h4>\n<p>Before long, Alice was always pushing me to spend more time with her, and I was always pushing to spend more time studying psychology.&nbsp;By then I knew I couldn't give her what she wanted: marriage.</p>\n<p>So I broke up with Alice over a long conversation that included an hour-long primer on evolutionary psychology in which I explained how natural selection had built me to be attracted to certain features that she lacked. I thought she would appreciate this because she had previously expressed admiration for detailed honesty. Now I realize that there's hardly a <em>more</em>&nbsp;damaging way to break up with someone. She asked that I kindly never speak to her again, and I can't blame her.</p>\n<p>This gives you some idea of just how incompetent I was, at the time. I had <em>some</em>&nbsp;idea of how incompetent I was, but not enough of one to avoid badly wounding somebody I loved.</p>\n<p><em>Rationality Lesson</em>: Know your fields of incompetence. If you suspect you may be incompetent, sanity-check yourself by asking others for advice, or by Googling. (E.g. \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+break+up+with+your+girlfriend+nicely\">how to break up with your girlfriend nicely</a>\", or \"<a href=\"http://www.google.com/search?sourceid=chrome&amp;ie=UTF-8&amp;q=how+to+not+die+on+a+motorcycle\">how to not die on a motorcycle</a>\" or whatever.)</p>\n<p>&nbsp;</p>\n<h4 id=\"Study\">Study</h4>\n<p>During the next couple years, I spent <em>no</em>&nbsp;time in (what would have been) sub-par relationships, and instead invested that time optimizing for better relationships in the future. Which meant I was celibate.</p>\n<p>Neither <em><a href=\"http://www.amazon.com/Intimate-Relationships-Thomas-N-Bradbury/dp/0393979571/\">Intimate Relationships</a>&nbsp;</em>nor <em><a href=\"http://www.amazon.com/Handbook-Relationship-Initiation-Susan-Sprecher/dp/0805861599/\">Handbook of Relationship Initiation</a></em>&nbsp;existed at the time, but I still learned quite a bit from books like <em><a href=\"http://www.amazon.com/Red-Queen-Evolution-Human-Nature/dp/0060556579/\">The Red Queen</a></em>&nbsp;and <em><a href=\"http://www.amazon.com/Moral-Animal-Science-Evolutionary-Psychology/dp/0679763996/\">The Moral Animal</a></em>. I experienced a long series of 'Aha!' moments, like:</p>\n<ul>\n<li>\"Aha! Body language and fashion matter because they communicate large packets of information about me at light speed, and are harder to fake than words.\"</li>\n<li>\"Aha! Women <em>want</em>&nbsp;men to be better at making them laugh and feel good and get aroused and not be creeped out. They <em>want</em>&nbsp;men to be as purposefully skilled at flirting and social awareness as <em>they</em> are. Many a young woman is&nbsp;<em>tired</em>&nbsp;of running into men whom they <em>could</em> be attracted to except for the fact that he doesn't know how to have a fun conversation, doesn't know how to create arousal in her, and doesn't know how to lead her smoothly from flirting to great sex.\"</li>\n<li>\"Aha! When women say \"Be yourself,\" they mean \"Don't be fake; be uniquely you.\" But they <em>don't</em>&nbsp;mean \"Just keep acting and talking the awkward way you do now because you haven't learned the skills required to be the best man you can be.\"</li>\n</ul>\n<p>Within a few months, I had more dating-relevant <em>head</em> knowledge than any guy I knew.</p>\n<p><em>Lesson</em>: Use <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\">scholarship</a>. Especially if you can do it <a href=\"/lw/5me/scholarship_how_to_do_it_efficiently/\">efficiently</a>, scholarship is a quick and cheap way to gain a certain class of experience points.</p>\n<p>&nbsp;</p>\n<h4 id=\"Just_try_it___just_test_yourself\">Just try it / just test yourself</h4>\n<p>Scholarship was warm and comfy, so I stayed in scholar mode for too long. I hit diminishing returns in what books could teach me. Every book on dating skills told me to go talk to women, but I thought I needed a completed decision tree first: <em>What if she does this? What if she says that? I won't know what to do if I don't have a plan! I should read 10 more books, so I know how to handle every contingency</em>.</p>\n<p>The dating books <em>told</em>&nbsp;me I would think that, but I told myself I was unusually analytical, and could actually benefit from completing the decision tree in advance of actually talking to women.</p>\n<p>The dating books told me I would think <em>that</em>, too, and that it was just a rationalization. Really, I was just nervous about the blows my ego would receive from newbie mistakes.</p>\n<p><em>Rationality Lesson</em>: Be especially suspicious of <a href=\"http://wiki.lesswrong.com/wiki/Rationalization\">rationalizations</a> for not obeying the empiricist rules \"try it and see what happens\" or \"test yourself to see what happens\" or \"get some concrete experience on the ground\". Think of the cost of time happening as a result of rationalizing. Consider the opportunities you are missing if you don't just realize you're wrong right <em>now</em>&nbsp;and change course. How many months or years will your life be less awesome as a result? How many opportunities will you miss while you're still (kinda) young?</p>\n<p>&nbsp;</p>\n<h4 id=\"Use_science__and_maybe_drugs\">Use science, and maybe drugs</h4>\n<p>The dating books told me to swallow my fear and talk to women. I couldn't swallow my fear, so I tried swallowing <a href=\"http://www.ejbrandy.com/\">brandy</a> instead. That worked.</p>\n<p>So I went out and talked to women, mostly at coffee shops or on the street. I learned all kinds of interesting details I hadn't learned in the books about what makes an interaction fun for most women:</p>\n<ul>\n<li>Keep up the emotional momentum. Don't stay in the same stage of the conversation (rapport, storytelling, self-disclosure, etc.) for very long.</li>\n<li>Almost every gesture or line is improved by adding a big smile.</li>\n<li>\"Hi. I've gotta run, but I think you're cute so we should grab a coffee sometime\" totally <em>works</em> \u2014 as long as the other person is already attracted because my body language, fashion, and other signals have been optimized.</li>\n</ul>\n<p>After a while, I could talk to women even without the brandy. And a little after that, I had my first one-night stand, which was great because it was exactly what she and I wanted.</p>\n<p>But as time passed I was surprised by how much I <em>didn't</em>&nbsp;enjoy casual flings. I didn't feel engaged when I didn't know and didn't have much in common with the girl in my bed. I had gone in thinking all I wanted was sex, but it turned out that I wanted <em>connection</em> to another person. (And sex.)</p>\n<p><em>Rationality Lesson</em>: Use empiricism and <a href=\"/lw/3wh/science_do_it_yourself/\">do-it-yourself science</a>. <a href=\"/lw/53e/just_try_it_quantity_trumps_quality/\">Just try things</a>. <a href=\"/lw/5a5/no_seriously_just_try_it/\">No, seriously</a>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Self_modify_to_succeed\">Self-modify to succeed</h4>\n<p>By this time my misgivings about the idea of \"owning\" another's sexuality had led me to adopt a polyamorous mindset for myself. (I saw many other people apparently happy with monogamy, but it wasn't for <em>me</em>.) But if I was going to be polyamorous, I needed to deprogram my sexual jealousy, which sounded daunting. Sexual jealousy was hard-wired into me by evolution, right?</p>\n<p>It turned out to be easier than I had predicted. <a href=\"http://books.google.com/books?id=SNCy0iqZMskC&amp;lpg=PT87&amp;vq=unlearning%20jealousy&amp;pg=PT87#v=onepage&amp;q&amp;f=false\">Tactics</a> that helped me destroy my capacity for sexual jealousy include:</p>\n<ul>\n<li>Whenever I noticed sexual jealousy in myself, I brought to mind my moral objections to the idea of owning another's sexuality.</li>\n<li>I thought in terms of sexual abundance, not sexual scarcity. When I realized there were thousands of other nearby women I could date, I didn't need to be so needy for any particular girl.</li>\n<li>Mentally, I continually associated 'jealousy' with 'immaturity' and 'neediness' and other concepts that have negative affect for me.</li>\n</ul>\n<p>This lack of sexual jealousy came in handy when I later dated a polyamorous girl who was already dating two of my friends.</p>\n<p><em>Rationality Lesson</em>: Have <a href=\"/lw/2c/a_sense_that_more_is_possible/\">a sense that more is possible</a>. Know that you haven't yet reached the limits of self-modification. Try things. Let your map of what is possible be constrained by evidence, not by popular opinion.</p>\n<p>&nbsp;</p>\n<h4 id=\"Finale\">Finale</h4>\n<p>There might have been a learning curve, but by golly, at the end of all that DIY science and rationality training and scholarship I'm much more romantically capable, I'm free to take up relationships when I want, I know fashion well enough to teach it at <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality camps</a>, and I can build rapport with almost anyone. My hair looks good and I'm happy.</p>\n<p>If you're a nerd-at-heart like me, I highly recommend becoming a nerd <em>about romance</em>, so long as you read the right nerd books and you know the nerd rule about being empirical. <a href=\"/lw/7i/rationality_is_systematized_winning/\">Rationality is for winning</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h3><br></h3>\n<p><small><sup><a name=\"notes\"></a>*</sup>&nbsp;My thanks to everyone who commented on <a href=\"/lw/6pf/new_post_version_1_please_read_this_only_if_your/\">earlier</a> <a href=\"/r/discussion/lw/6v5/new_post_version_2_please_read_this_only_if_your/\">drafts</a> of this post. Here are the biggest changes I made:</small></p>\n<ul>\n<li><small>Some&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4kia\">said</a>&nbsp;that while it's okay to be analytic about relationships, it would help the tone of the post if it was clear I was interacting with people&nbsp;<em>as people</em>, too. So I added more of that.</small></li>\n<li><small>Some&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4kiv\">thought</a>&nbsp;I implied that everyone could or should be polyamorous, which is not something I intended or believe. I've made that clearer now.</small></li>\n<li><small>Robert Lumley provided some detailed&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4kgc\">comments</a>&nbsp;that I updated in response to.</small></li>\n<li><small>I also made use of some&nbsp;<a href=\"/lw/6v5/new_post_version_2_please_read_this_only_if_your/4l9u\">suggestions</a>&nbsp;made by HughRistik.</small></li>\n</ul>", "sections": [{"title": "Gather data", "anchor": "Gather_data", "level": 1}, {"title": "Sanity-check yourself", "anchor": "Sanity_check_yourself", "level": 1}, {"title": "Study", "anchor": "Study", "level": 1}, {"title": "Just try it / just test yourself", "anchor": "Just_try_it___just_test_yourself", "level": 1}, {"title": "Use science, and maybe drugs", "anchor": "Use_science__and_maybe_drugs", "level": 1}, {"title": "Self-modify to succeed", "anchor": "Self_modify_to_succeed", "level": 1}, {"title": "Finale", "anchor": "Finale", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "616 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 616, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kLR5H4pbaBjzZxLv6", "2MD3NMLBPCqPfnfre", "BHYBdijDcAKQ6e45Z", "9WX59u7g2sdKqnjDm", "64FdKLwmea8MCLWkE", "37sHjeisS9uJufi4u", "K82evF2iRAiRWwvyn", "hY86FhYysQ7dBg3d8", "Zmfo388RA9oky3KYe", "Nu3wa6npK4Ry66vFp", "4ARtkT3EYox3THYjF", "CMSaT7sv96C4jWN2J", "aYfjK9oHuTcYqwBvp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-10-04T02:45:31.391Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T04:22:10.903Z", "modifiedAt": null, "url": null, "title": "Meetup : UMD Meetup", "slug": "meetup-umd-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.580Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7sBT6qin8g3AmczYj/meetup-umd-meetup", "pageUrlRelative": "/posts/7sBT6qin8g3AmczYj/meetup-umd-meetup", "linkUrl": "https://www.lesswrong.com/posts/7sBT6qin8g3AmczYj/meetup-umd-meetup", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20UMD%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20UMD%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7sBT6qin8g3AmczYj%2Fmeetup-umd-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20UMD%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7sBT6qin8g3AmczYj%2Fmeetup-umd-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7sBT6qin8g3AmczYj%2Fmeetup-umd-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 37, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/3v'>UMD Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 October 2011 04:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">University of Maryland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're meeting in Terrapin Room B of the Student Involvement Suite in STAMP.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/3v'>UMD Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7sBT6qin8g3AmczYj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "10266", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___UMD_Meetup\">Discussion article for the meetup : <a href=\"/meetups/3v\">UMD Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 October 2011 04:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">University of Maryland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're meeting in Terrapin Room B of the Student Involvement Suite in STAMP.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___UMD_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/3v\">UMD Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : UMD Meetup", "anchor": "Discussion_article_for_the_meetup___UMD_Meetup", "level": 1}, {"title": "Discussion article for the meetup : UMD Meetup", "anchor": "Discussion_article_for_the_meetup___UMD_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T09:46:55.391Z", "modifiedAt": null, "url": null, "title": "Cryonics on Castle [Spoilers]", "slug": "cryonics-on-castle-spoilers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:37.697Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wedrifid", "createdAt": "2009-07-04T22:18:20.822Z", "isAdmin": false, "displayName": "wedrifid"}, "userId": "FqKohKFRCZnbfbbcS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rFKsmJEwfhsgAHg7P/cryonics-on-castle-spoilers", "pageUrlRelative": "/posts/rFKsmJEwfhsgAHg7P/cryonics-on-castle-spoilers", "linkUrl": "https://www.lesswrong.com/posts/rFKsmJEwfhsgAHg7P/cryonics-on-castle-spoilers", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%20on%20Castle%20%5BSpoilers%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%20on%20Castle%20%5BSpoilers%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrFKsmJEwfhsgAHg7P%2Fcryonics-on-castle-spoilers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%20on%20Castle%20%5BSpoilers%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrFKsmJEwfhsgAHg7P%2Fcryonics-on-castle-spoilers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrFKsmJEwfhsgAHg7P%2Fcryonics-on-castle-spoilers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 585, "htmlBody": "<p>Check out the latest episode of Castle (<a href=\"http://www.sidereel.com/Castle/season-4/episode-3\">Headcase</a>) to see Cryonics covered in mainstream fiction in a not entirely terrible manner. The details are not exactly accurate but probably not more&nbsp;inaccurate&nbsp;than similar fictionalised coverage of most other industries. In fact there is one obvious implementation difference that the company in Castle uses which is how things clearly ought to be:</p>\n<h4><span style=\"font-size: 15px; font-weight: bold;\"><strong><em>Amulets of Immortality</em></strong></span></h4>\n<p>It is not uncommon for cryonics&nbsp;enthusiasts&nbsp;to make 'immortality' jokes about their ALCOR necklaces but the equivalent on the show make the obvious practical next step. The patients have heart rate monitors with GPS signalers that signal the cryonics company as soon as the patient flatlines. This is just obviously the way things should be and it is&nbsp;regrettable&nbsp;that the market is not yet broad enough for 'obvious' to have been translated into common practice.</p>\n<h4>Other things to watch out for:</h4>\n<p>\n<ul>\n<li>Predictable attempts by the cops to take the already preserved body so they can collect more evidence.</li>\n<li>A somewhat insightful question of whether the cryonics company should hand over the corpsicle without taking things to court because that way they would not risk legal precedent being set based on a case where there are unusual factors which may make them lose. It may be better to lose one patient so that they can force the fight to happen on a stronger case.</li>\n<li>Acknowledgement that only the head is required, which allows a compromise of handing over the body minus the head.</li>\n<li>Smug superiority of cops trying to take the cryonics patient against the will of the patient himself, his family and the custodians. This is different than cops just trying to claim territory and do their job and to the hell with everyone else, it is cops trying to convey that it is morally virtuous to take the corpse and the wife would understand that it was in her and her corpsicle husband's best interest to autopsy his head if she wasn't so stupid. (Which seems like a realistic attitude.)</li>\n<li>Costar and lead detective Beckett actually attempts to murder a cryonics patient (to whatever extent that murder applies to corpsicle&nbsp;desiccation). For my part this gave me the chance to explore somewhat more tangibly my ethical intuitions over what types of responses would be appropriate. My conclusion was that if someone had shot Beckett in order to protect the corpsicle I would have been indifferent. Not glad that she was killed but not proud of the person killing her either. I suspect (but cannot test) that most of the pain and frustration of losing a character that I cared about would be averted as well. Curious.</li>\n<li>Brain destroying disease vs cryonicist standoff!</li>\n<li>Beckett redeems herself on the 'not being an ass to&nbsp;cryonicists' front by being completely non-judgemental of the woman for committing \"involuntary euthenasia\" of her tumor-infested husband. (Almost to the point of being inconsistent with her earlier behavior but I'm not complaining.)</li>\n<li>A clever \"Romeo and Juliet\" conclusion to wrap up the case without Beckett being forced to put the wife in jail for an act that has some fairly reasonable consequentialist upsides. Played out to be about as close to a happy ending as you could get.</li>\n</ul>\n<div><br /></div>\n<div>Overall a positive portrayal of cryonics or at least one I am happy with. It doesn't convey cryonics as normal but even so it is a step less weird than I would usually expect. I'd call it good publicity.</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZnHkaTkxukegSrZqE": 1, "GBpwq8cWvaeRoE9X5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rFKsmJEwfhsgAHg7P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 35, "extendedScore": null, "score": 7.789248458321657e-07, "legacy": true, "legacyId": "10275", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Check out the latest episode of Castle (<a href=\"http://www.sidereel.com/Castle/season-4/episode-3\">Headcase</a>) to see Cryonics covered in mainstream fiction in a not entirely terrible manner. The details are not exactly accurate but probably not more&nbsp;inaccurate&nbsp;than similar fictionalised coverage of most other industries. In fact there is one obvious implementation difference that the company in Castle uses which is how things clearly ought to be:</p>\n<h4 id=\"Amulets_of_Immortality\"><span style=\"font-size: 15px; font-weight: bold;\"><strong><em>Amulets of Immortality</em></strong></span></h4>\n<p>It is not uncommon for cryonics&nbsp;enthusiasts&nbsp;to make 'immortality' jokes about their ALCOR necklaces but the equivalent on the show make the obvious practical next step. The patients have heart rate monitors with GPS signalers that signal the cryonics company as soon as the patient flatlines. This is just obviously the way things should be and it is&nbsp;regrettable&nbsp;that the market is not yet broad enough for 'obvious' to have been translated into common practice.</p>\n<h4 id=\"Other_things_to_watch_out_for_\">Other things to watch out for:</h4>\n<p>\n</p><ul>\n<li>Predictable attempts by the cops to take the already preserved body so they can collect more evidence.</li>\n<li>A somewhat insightful question of whether the cryonics company should hand over the corpsicle without taking things to court because that way they would not risk legal precedent being set based on a case where there are unusual factors which may make them lose. It may be better to lose one patient so that they can force the fight to happen on a stronger case.</li>\n<li>Acknowledgement that only the head is required, which allows a compromise of handing over the body minus the head.</li>\n<li>Smug superiority of cops trying to take the cryonics patient against the will of the patient himself, his family and the custodians. This is different than cops just trying to claim territory and do their job and to the hell with everyone else, it is cops trying to convey that it is morally virtuous to take the corpse and the wife would understand that it was in her and her corpsicle husband's best interest to autopsy his head if she wasn't so stupid. (Which seems like a realistic attitude.)</li>\n<li>Costar and lead detective Beckett actually attempts to murder a cryonics patient (to whatever extent that murder applies to corpsicle&nbsp;desiccation). For my part this gave me the chance to explore somewhat more tangibly my ethical intuitions over what types of responses would be appropriate. My conclusion was that if someone had shot Beckett in order to protect the corpsicle I would have been indifferent. Not glad that she was killed but not proud of the person killing her either. I suspect (but cannot test) that most of the pain and frustration of losing a character that I cared about would be averted as well. Curious.</li>\n<li>Brain destroying disease vs cryonicist standoff!</li>\n<li>Beckett redeems herself on the 'not being an ass to&nbsp;cryonicists' front by being completely non-judgemental of the woman for committing \"involuntary euthenasia\" of her tumor-infested husband. (Almost to the point of being inconsistent with her earlier behavior but I'm not complaining.)</li>\n<li>A clever \"Romeo and Juliet\" conclusion to wrap up the case without Beckett being forced to put the wife in jail for an act that has some fairly reasonable consequentialist upsides. Played out to be about as close to a happy ending as you could get.</li>\n</ul>\n<div><br></div>\n<div>Overall a positive portrayal of cryonics or at least one I am happy with. It doesn't convey cryonics as normal but even so it is a step less weird than I would usually expect. I'd call it good publicity.</div>\n<p></p>", "sections": [{"title": "Amulets of Immortality", "anchor": "Amulets_of_Immortality", "level": 1}, {"title": "Other things to watch out for:", "anchor": "Other_things_to_watch_out_for_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "23 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T10:21:25.771Z", "modifiedAt": null, "url": null, "title": "Religion, happiness, and Bayes", "slug": "religion-happiness-and-bayes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.873Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fortyeridania", "createdAt": "2010-07-21T15:35:12.558Z", "isAdmin": false, "displayName": "fortyeridania"}, "userId": "roBPqtzsvG6dC3YFT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eW8ygDydov5YeHyxb/religion-happiness-and-bayes", "pageUrlRelative": "/posts/eW8ygDydov5YeHyxb/religion-happiness-and-bayes", "linkUrl": "https://www.lesswrong.com/posts/eW8ygDydov5YeHyxb/religion-happiness-and-bayes", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Religion%2C%20happiness%2C%20and%20Bayes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReligion%2C%20happiness%2C%20and%20Bayes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeW8ygDydov5YeHyxb%2Freligion-happiness-and-bayes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Religion%2C%20happiness%2C%20and%20Bayes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeW8ygDydov5YeHyxb%2Freligion-happiness-and-bayes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeW8ygDydov5YeHyxb%2Freligion-happiness-and-bayes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 320, "htmlBody": "<p>Religion <a href=\"http://www.voxeu.org/index.php?q=node/7052\">apparently</a> makes people happier. Is that evidence for the truth of religion, or against it?</p>\r\n<p>(Of course, it matters <em>which</em> religion we're talking about, but let's just stick with theism generally.)</p>\r\n<p>My initial inclination was to interpret this as evidence against theism, in the sense that it weakens the evidence <em>for</em> theism. Here's why:</p>\r\n<ol>\r\n<li>As all Bayesians know, a piece of information F is evidence for an hypothesis H to the degree that F depends on H. If F can happen just as easily without H as with it, then F is not evidence for H. The more likely we are to find F in a world without H, the weaker F is as evidence for H.</li>\r\n<li>Here, F is \"Theism makes people happier.\" H is \"Theism is true.\"</li>\r\n<li>The fact of widespread theism is evidence for H. The strength of this evidence depends on how likely such belief would be if H were false.</li>\r\n<li>As people are more likely to do something if it makes them happy, people are more likely to be theists given F.</li>\r\n<li>Thus F opens up a way for people to be theists even if H is false.</li>\r\n<li>It therefore weakens the evidence of widespread theism for the truth of H.</li>\r\n<li>Therefore, F should decrease one's confidence in H, i.e., it is evidence against H.</li>\r\n</ol>\r\n<p>We could also put this in mathematical terms, where F represents an <em>increase</em> in the prior probability of our encountering the evidence. Since that prior is a denominator in Bayes' equation, a bigger one means a smaller posterior probability--in other words, weaker evidence.</p>\r\n<p>OK, so that was my first thought.</p>\r\n<p>But then I had second thoughts: Perhaps the evidence points the other way? If we reframe the finding as \"Atheism causes unhappiness,\" or posit that contrarians (such as atheists) are dispositionally unhappy, does that change the sign of the evidence?</p>\r\n<p>Obviously, I am confused. What's going on here?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eW8ygDydov5YeHyxb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 7.789366609292748e-07, "legacy": true, "legacyId": "10264", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T10:59:51.107Z", "modifiedAt": null, "url": null, "title": "Another \"Oops\" moment [link]", "slug": "another-oops-moment-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.520Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fortyeridania", "createdAt": "2010-07-21T15:35:12.558Z", "isAdmin": false, "displayName": "fortyeridania"}, "userId": "roBPqtzsvG6dC3YFT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qzLws7xqjHHMEnSfy/another-oops-moment-link", "pageUrlRelative": "/posts/qzLws7xqjHHMEnSfy/another-oops-moment-link", "linkUrl": "https://www.lesswrong.com/posts/qzLws7xqjHHMEnSfy/another-oops-moment-link", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Another%20%22Oops%22%20moment%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnother%20%22Oops%22%20moment%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqzLws7xqjHHMEnSfy%2Fanother-oops-moment-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Another%20%22Oops%22%20moment%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqzLws7xqjHHMEnSfy%2Fanother-oops-moment-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqzLws7xqjHHMEnSfy%2Fanother-oops-moment-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 81, "htmlBody": "<p><a href=\"http://www.thebigquestions.com/2011/10/04/big-news/\">http://www.thebigquestions.com/2011/10/04/big-news/</a></p>\r\n<p>Steven Landsburg notes that mathematician Edward Nelson has retracted his claim that the axioms of Peano Arithmetic are inconsistent.</p>\r\n<p>The bit Landsburg cites indicates that the retraction was cordial and drama-free, the way a retraction should be--even a retraction of a claim as momentous as this one.</p>\r\n<p>Now, is this kind of event more common in math than in other fields? Is it more common now than before? (Landsburg seems to attribute it in part to the existence of the Internet.) Your thoughts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qzLws7xqjHHMEnSfy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 17, "extendedScore": null, "score": 7.789496338905753e-07, "legacy": true, "legacyId": "10278", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T13:28:25.222Z", "modifiedAt": null, "url": null, "title": "Ig Nobel for the anti-akrasia guy", "slug": "ig-nobel-for-the-anti-akrasia-guy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.960Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Craig_Heldreth", "createdAt": "2010-06-14T23:30:28.110Z", "isAdmin": false, "displayName": "Craig_Heldreth"}, "userId": "hhKowsjZBQSyBE6c5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/87XDsitE8yB8wCc8H/ig-nobel-for-the-anti-akrasia-guy", "pageUrlRelative": "/posts/87XDsitE8yB8wCc8H/ig-nobel-for-the-anti-akrasia-guy", "linkUrl": "https://www.lesswrong.com/posts/87XDsitE8yB8wCc8H/ig-nobel-for-the-anti-akrasia-guy", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ig%20Nobel%20for%20the%20anti-akrasia%20guy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIg%20Nobel%20for%20the%20anti-akrasia%20guy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F87XDsitE8yB8wCc8H%2Fig-nobel-for-the-anti-akrasia-guy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ig%20Nobel%20for%20the%20anti-akrasia%20guy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F87XDsitE8yB8wCc8H%2Fig-nobel-for-the-anti-akrasia-guy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F87XDsitE8yB8wCc8H%2Fig-nobel-for-the-anti-akrasia-guy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 39, "htmlBody": "<p>The Improbable Research folks have awarded an Ig Nobel prize to John Perry (<a href=\"/lw/1fe/antiakrasia_technique_structured_procrastination/\">previously on Less Wrong</a>) for his work on how to procrastinate and still get things done.</p>\n<p><a href=\"http://www.improbable.com/\"><br /></a></p>\n<p><a href=\"http://www.improbable.com/2011/10/04/a-philosopher-who-procrastinated-and-prospered/\">On their website.<br /></a></p>\n<p>&nbsp;</p>\n<p><a href=\"http://chronicle.com/article/How-to-ProcrastinateStill/93959\">Also.</a></p>\n<p>&nbsp;</p>\n<p>(edited to fix the link)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "87XDsitE8yB8wCc8H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 7.789998004325303e-07, "legacy": true, "legacyId": "10279", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["n5Yfhygz42QNK2vFe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T14:11:43.312Z", "modifiedAt": null, "url": null, "title": "Lecturing congressmen on cognitive biases", "slug": "lecturing-congressmen-on-cognitive-biases", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.370Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Apprentice", "createdAt": "2009-05-20T13:06:35.976Z", "isAdmin": false, "displayName": "Apprentice"}, "userId": "X5f7X9PkRFwGyxWsb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q3Yi5GrXxbpQQY2PR/lecturing-congressmen-on-cognitive-biases", "pageUrlRelative": "/posts/q3Yi5GrXxbpQQY2PR/lecturing-congressmen-on-cognitive-biases", "linkUrl": "https://www.lesswrong.com/posts/q3Yi5GrXxbpQQY2PR/lecturing-congressmen-on-cognitive-biases", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Lecturing%20congressmen%20on%20cognitive%20biases&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALecturing%20congressmen%20on%20cognitive%20biases%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3Yi5GrXxbpQQY2PR%2Flecturing-congressmen-on-cognitive-biases%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Lecturing%20congressmen%20on%20cognitive%20biases%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3Yi5GrXxbpQQY2PR%2Flecturing-congressmen-on-cognitive-biases", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3Yi5GrXxbpQQY2PR%2Flecturing-congressmen-on-cognitive-biases", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>A new session of Iceland's parliament convened on Saturday, opening with a religious service as is traditional. For the last couple of years, a local humanist group has offered alternatives to the religious ceremony. On Saturday they had a psychologist give a lecture on cognitive biases, principally on confirmation bias and the availability heuristic. This was attended by 13 out of 63 members of parliament. (<a href=\"http://sidmennt.is/2011/10/01/einstaklega-god-hugvekja-huldu-thorisdottur-i-athofn-fyrir-althingismenn/\">Source in Icelandic</a>).</p>\n<p>I'm more pro-religion than most people who read Less Wrong and I am generally not excited about atheist activism. This, however, struck me as a good idea.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q3Yi5GrXxbpQQY2PR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 7.790144229396169e-07, "legacy": true, "legacyId": "10280", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T16:49:59.198Z", "modifiedAt": null, "url": null, "title": "Apply your knowledge: pick half a number", "slug": "apply-your-knowledge-pick-half-a-number", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:57.308Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H7eGg5Tvufh8bS66Y/apply-your-knowledge-pick-half-a-number", "pageUrlRelative": "/posts/H7eGg5Tvufh8bS66Y/apply-your-knowledge-pick-half-a-number", "linkUrl": "https://www.lesswrong.com/posts/H7eGg5Tvufh8bS66Y/apply-your-knowledge-pick-half-a-number", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Apply%20your%20knowledge%3A%20pick%20half%20a%20number&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApply%20your%20knowledge%3A%20pick%20half%20a%20number%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH7eGg5Tvufh8bS66Y%2Fapply-your-knowledge-pick-half-a-number%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Apply%20your%20knowledge%3A%20pick%20half%20a%20number%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH7eGg5Tvufh8bS66Y%2Fapply-your-knowledge-pick-half-a-number", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH7eGg5Tvufh8bS66Y%2Fapply-your-knowledge-pick-half-a-number", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 56, "htmlBody": "<p>NPR's Planet Money is running an&nbsp;experiment&nbsp;which could be an interesting way to test your other-people-modeling skills.</p>\n<p><span style=\"color: #666666; font-family: georgia, sans-serif; font-size: 16px; line-height: 23px; background-color: #e5e5e5;\">This is a guessing game. To play, pick a number between 0 and 100. The goal is to pick the number that's closest to half the average of all guesses.</span></p>\n<p><a href=\"http://www.npr.org/blogs/money/2011/10/03/133654225/please-help-us-pick-a-number?sc=fb&amp;cc=fp\">http://www.npr.org/blogs/money/2011/10/03/133654225/please-help-us-pick-a-number?sc=fb&amp;cc=fp</a></p>\n<p>The other people guessing are self-selected, I would assume primarily NPR listeners.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H7eGg5Tvufh8bS66Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "10281", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T17:30:53.926Z", "modifiedAt": null, "url": null, "title": "Peter Thiel warns of upcoming (and current) stagnation", "slug": "peter-thiel-warns-of-upcoming-and-current-stagnation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.373Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GKqBQDMsAFdgHfd49/peter-thiel-warns-of-upcoming-and-current-stagnation", "pageUrlRelative": "/posts/GKqBQDMsAFdgHfd49/peter-thiel-warns-of-upcoming-and-current-stagnation", "linkUrl": "https://www.lesswrong.com/posts/GKqBQDMsAFdgHfd49/peter-thiel-warns-of-upcoming-and-current-stagnation", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Peter%20Thiel%20warns%20of%20upcoming%20(and%20current)%20stagnation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APeter%20Thiel%20warns%20of%20upcoming%20(and%20current)%20stagnation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGKqBQDMsAFdgHfd49%2Fpeter-thiel-warns-of-upcoming-and-current-stagnation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Peter%20Thiel%20warns%20of%20upcoming%20(and%20current)%20stagnation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGKqBQDMsAFdgHfd49%2Fpeter-thiel-warns-of-upcoming-and-current-stagnation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGKqBQDMsAFdgHfd49%2Fpeter-thiel-warns-of-upcoming-and-current-stagnation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 524, "htmlBody": "<p><span style=\"font-size: x-small;\">\r\n<p>SIAI benefactor and VC Peter Thiel has an <a href=\"http://www.nationalreview.com/articles/print/278758\">excellent article</a> at National Review about the stagnating progress of science and technology, which he attributes to poorly-grounded political opposition, widespread scientific illiteracy, and overspecialized, insular scientific fields.&nbsp; He warns that this stagnation will undermine the growth that past policies have relied on.</p>\r\n<p>Noteworthy excerpts (bold added by me):</p>\r\n<p>In relation to concerns expressed here about <a href=\"/lw/4ba/some_heuristics_for_evaluating_the_soundness_of/\">evaluating scientific field soundness:</a></p>\r\n<blockquote>\r\n<p><strong>When any given field takes half a lifetime of study to master, who can</strong> compare and contrast and <strong>properly weight the rate of progress</strong> in nanotechnology and cryptography and superstring theory and 610 other disciplines? Indeed, <strong>how do we even know whether the so-called scientists are not just lawmakers and politicians in disguise</strong>, as some conservatives suspect in fields as disparate as climate change, evolutionary biology, and embryonic-stem-cell research, and <strong>as I have come to suspect in almost all fields? </strong>[!!! -- SB]</p>\r\n</blockquote>\r\n<strong></strong>\r\n<p>Grave indictors:</p>\r\n<blockquote>\r\n<p><strong>Looking forward, we see far fewer blockbuster drugs in the pipeline</strong> &mdash; perhaps because of the intransigence of the FDA, perhaps because of the fecklessness of today&rsquo;s biological scientists, and perhaps because of the incredible complexity of human biology. In the next three years, <strong>the large pharmaceutical companies</strong> will lose approximately one-third of their current revenue stream as patents expire, so, in a perverse yet understandable response, they <strong>have begun the wholesale liquidation of the research departments that have borne so little fruit in the last decade and a half.</strong> [...]</p>\r\n</blockquote>\r\n<blockquote>\r\n<p><strong>The single most important economic development in recent times has been the broad stagnation of real wages and incomes since 1973</strong>, the year when oil prices quadrupled. To a first approximation, <strong>the progress in computers and the failure in energy appear to have roughly canceled each other ou</strong>t. Like Alice in the Red Queen&rsquo;s race, we (and our computers) have been forced to run faster and faster to stay in the same place.</p>\r\n</blockquote>\r\n<blockquote>\r\n<p>Taken at face value, the economic numbers suggest that the notion of breathtaking and across-the-board progress is far from the mark. If one believes the economic data, then one must reject the optimism of the scientific establishment. Indeed,<strong> if one shares the widely held view that the U.S. government may have understated the true rate of inflation </strong>&mdash; perhaps by ignoring the runaway inflation in government itself, notably in education and health care (where much higher spending has yielded no improvement in the former and only modest improvement in the latter) &mdash; <strong>then one may be inclined to take gold prices seriously and conclude that real incomes have fared even worse than the official data indicate. </strong>[...]</p>\r\n</blockquote>\r\n<blockquote>\r\n<p>College graduates did better, and high-school graduates did worse. But both became worse off in the years after 2000, especially when one includes the rapidly escalating costs of college.[...]</p>\r\n</blockquote>\r\n<blockquote>\r\n<p>The current crisis of housing and financial leverage contains many hidden links to broader questions concerning long-term progress in science and technology. On one hand, the lack of easy progress makes leverage more dangerous, because when something goes wrong, macroeconomic growth cannot offer a salve; time will not cure liquidity or solvency problems in a world where little grows or improves with time.</p>\r\n</blockquote>\r\n<p>HT: <a href=\"http://marginalrevolution.com/marginalrevolution/2011/10/assorted-links-241.html\">MarginalRevolution</a></p>\r\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sPpZRaxpNNJjw55eu": 1, "aHjTRDkGypPqbXWpN": 1, "bkgy24HML6nLSLqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GKqBQDMsAFdgHfd49", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 36, "extendedScore": null, "score": 7.7e-05, "legacy": true, "legacyId": "10282", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 121, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fyZBtNB3Ki3fM4a6Y"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-04T18:21:44.472Z", "modifiedAt": null, "url": null, "title": "The National Institute of Theology", "slug": "the-national-institute-of-theology", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.578Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wkWLjzy75gFabRohg/the-national-institute-of-theology", "pageUrlRelative": "/posts/wkWLjzy75gFabRohg/the-national-institute-of-theology", "linkUrl": "https://www.lesswrong.com/posts/wkWLjzy75gFabRohg/the-national-institute-of-theology", "postedAtFormatted": "Tuesday, October 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20National%20Institute%20of%20Theology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20National%20Institute%20of%20Theology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwkWLjzy75gFabRohg%2Fthe-national-institute-of-theology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20National%20Institute%20of%20Theology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwkWLjzy75gFabRohg%2Fthe-national-institute-of-theology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwkWLjzy75gFabRohg%2Fthe-national-institute-of-theology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<p>Lots of charlatans spend lots of money advertising diets and health products that don't work.&nbsp; We have a National Institutes of Health that, among other things, funds studies that make more-objective pronouncements on diet and health.</p>\n<p>Argue pro or con:&nbsp; It would be a good investment (payback would exceed opportunity cost) for the US government to create a National Institute of Theology, that would fund research into theological questions.&nbsp; For instance:</p>\n<ul>\n<li>How effective is prayer?</li>\n<li>Which religions are the most effective (at healing the sick, making their adherents rich, or other metrics)?</li>\n<li>What is the probability that someone will become happier, more productive, less violent, or commit acts of terrorism as a result of joining different religions (or not joining any)?</li>\n</ul>\n<p>Everyone, religious and atheist, should be motivated to want the answers to these questions to become widely known.</p>\n<p>(Yes, I know this would be politically impractical.&nbsp; Pointing that out is not interesting.&nbsp; What is interesting, is whether such a NIT would be beneficial, supposing it could be made.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wkWLjzy75gFabRohg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": -2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "10283", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T00:08:33.404Z", "modifiedAt": null, "url": null, "title": "Prize for the best introduction to the LessWrong source ($250)", "slug": "prize-for-the-best-introduction-to-the-lesswrong-source", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:06.506Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JDMtDBmaycM3SmDBk/prize-for-the-best-introduction-to-the-lesswrong-source", "pageUrlRelative": "/posts/JDMtDBmaycM3SmDBk/prize-for-the-best-introduction-to-the-lesswrong-source", "linkUrl": "https://www.lesswrong.com/posts/JDMtDBmaycM3SmDBk/prize-for-the-best-introduction-to-the-lesswrong-source", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Prize%20for%20the%20best%20introduction%20to%20the%20LessWrong%20source%20(%24250)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrize%20for%20the%20best%20introduction%20to%20the%20LessWrong%20source%20(%24250)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJDMtDBmaycM3SmDBk%2Fprize-for-the-best-introduction-to-the-lesswrong-source%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Prize%20for%20the%20best%20introduction%20to%20the%20LessWrong%20source%20(%24250)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJDMtDBmaycM3SmDBk%2Fprize-for-the-best-introduction-to-the-lesswrong-source", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJDMtDBmaycM3SmDBk%2Fprize-for-the-best-introduction-to-the-lesswrong-source", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 927, "htmlBody": "<p>Now that it's <a href=\"/lw/7fv/hacking_on_lesswrong_just_got_easier/\">easy to host lesswrong and hack on the code</a>, you may have gotten excited about adding a feature (facebook likes for articles! or expanded user pages!). So, you take a look at the code and &hellip; &nbsp;oh, it's kind of complicated ... You don&rsquo;t know how the site works and don&rsquo;t know how to learn. LessWrong lacks a good introduction to its source code.&nbsp;</p>\n<p>The <a href=\"http://groups.google.com/group/lw-public-goods-team\">LW Public Goods Team</a>&nbsp;and <a href=\"/lesswrong.com/user/Dr_Manhattan\">Dr_Manhattan</a>&nbsp;would like the process of getting to know the code to be easier. Therefore, we&rsquo;re sponsoring a prize for the best introduction to the code. The prize fund is currently $250 (<a href=\"http://jsalvatier.chipin.com/lesswrong-source-code-introduction\">ChipIn page</a>; contributions welcome!).&nbsp;Submissions are due by October 25th. The prize will be judged by <a href=\"/user/jsalvatier\">jsalvatier</a>, <a href=\"/lesswrong.com/user/Dr_Manhattan\">Dr_Manhattan</a>, and <a href=\"/user/morendil\">Morendil</a>.&nbsp;</p>\n<p>The submissions will be judged according to how effective the judges expect them to be at lowering the barriers to working productively on lesswrong.</p>\n<p><a id=\"more\"></a>One strategy we expect to use for making this judgment is to think of specific change we might want to make and then see how much the tutorial would help us understand the relevant issues.&nbsp;For example, we might think about trying to allow comments to be declared karma-neutral for the purposes of implementing polls or rank ordering of suggestions. We might ask ourselves:</p>\n<ul>\n<li>Does this tutorial help me form an accurate mental model of what happens as a result of clicking the upvote button, in terms of how LW is implemented?&nbsp;</li>\n<li>Does it help me think effectively about bringing about the desired effects?&nbsp;</li>\n<li>Does it help me anticipate potentially detrimental unintended effects?&nbsp;</li>\n<li>Does it help me map that (dynamic) execution model to specific bits of the (static) source code?&nbsp;</li>\n<li>Does the tutorial cover enough of the major relevant aspects of LW besides the example (picked at random) of votes and karma?</li>\n</ul>\n<p>We might think about linking wiki pages to users pages so that users can give more background about themselves. We might ask ourselves:</p>\n<ul>\n<li>Does the tutorial give me a clear idea of where user information is stored and accessed?</li>\n<li>Does it help me understand how wikipages are rendered on the main site?</li>\n<li>Does it help me learn how the individual parts of existing user pages are rendered?</li>\n<li>Does it help me know where to go answer this questions that it doesn&rsquo;t answer directly?&nbsp;</li>\n</ul>\n<p>The winner of the prize will be asked to incorporate the work of other submissions (with help of course). The prize money will be split up according to how much each submission contributed to the final product. The Introduction's final location will be the&nbsp;<a href=\"https://github.com/tricycle/lesswrong/wiki\">LessWrong Github wiki</a>.</p>\n<p>At the bottom of this article is some general information about the code graciously provided by Wes from <a href=\"http://trikeapps.com/\">TrikeApps</a> and Morendil. If you have questions/comments/concerns about the prize please speak up!</p>\n<p style=\"padding-left: 30px;\">1. How different is LW from its parent Reddit code?&nbsp;</p>\n<p style=\"padding-left: 60px;\">Reddit has obviously changed a bit since it forked the code almost 3 years ago, but the changes to the version we forked are mostly around the appearance of the site and addition of Less Wrong specific features such as the concept of an Article, addition of Meetups, etc. So in general it isn't hugely different from Reddit. You can get more specific information by looking at the&nbsp;<a href=\"https://github.com/tricycle/lesswrong/commits/master?page=41\">commit history</a>.</p>\n<p style=\"padding-left: 30px;\">2. What knowledge is useful for hacking on LW assuming generic programming experience?</p>\n<p style=\"padding-left: 60px;\">Along with programming experience you should have a knowledge of web applications and web technologies in general (HTML, CSS, JS, HTTP). To a lesser degree some database knowledge (SQL). More specific things to know are Python (or another comparable scripting language such as Perl or Ruby, maybe PHP if the experience was with a modern object oriented PHP web framework) and Pylons (although Less Wrong/Reddit doesn't use Pylons model layer). Whilst the code uses PostgreSQL as the database it is not used as a typical relational database so familiarity with the concept of a key-value store(so called \"NoSQL\") is useful.</p>\n<p style=\"padding-left: 60px;\">One key question is \"how are the objects perceived at user level (articles, comments, karma, etc) represented at the implementation level\". For instance, karma is tricky because there isn't a \"total karma\" field in the DB, it's computed by summing comment and article karma scores each time you query it.</p>\n<p style=\"padding-left: 30px;\">3. What frameworks, tools is LW/Reddit based on?</p>\n<p style=\"padding-left: 60px;\">Noteworthy things the code uses are:</p>\n<ul style=\"padding-left: 60px;\">\n<li><a href=\"http://www.python.org/\">Python</a></li>\n<li><a href=\"http://wiki.pylonshq.com/display/pylonsdocs/QuickWiki+Tutorial\">Pylons</a></li>\n<li><a href=\"http://www.sqlalchemy.org/\">SQLAlchmey</a></li>\n<li><a href=\"http://www.postgresql.org/\">PostgreSQL</a></li>\n<li>Prototype (although jQuery is now also present)</li>\n<li><a href=\"http://memcached.org/\">Memcached</a></li>\n<li><a href=\"http://www.makotemplates.org/\">Mako Templates</a></li>\n<li>Ajax</li>\n<li>TinyMCE</li>\n</ul>\n<p style=\"padding-left: 30px;\">4. Is LW organized the same way as lots of other websites or some particular framework or is it idiosyncratic?</p>\n<p style=\"padding-left: 60px;\">The code follows a loose MVC (<a href=\"http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller\">Model View Controller</a>) paradigm and the code is organised to reflect that. MVC is certainly something to be familiar with. The r2/r2/ path (poorly named by the Reddit people representing their \"release 2\", to original Reddit was written in Lisp) contains the meat of the app. You will note 'models' and 'controllers' directories for those things and a 'templates' directory for the views plus other support code in 'lib'. This structure is typical of other MVC web apps such as Ruby on Rails.</p>\n<p style=\"padding-left: 30px;\">5. How long would it take to be able to start hacking on LW effectively?</p>\n<p style=\"padding-left: 60px;\">With Python and web experience you could be effective in a 1 - 3 days. Without web experience you're likely to feel quite lost for a bit as there's a bunch of conventions and technologies to learn. It would be more like 3 - 7 days. Keep in mind programmers are notorious for underestimating though.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JDMtDBmaycM3SmDBk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 24, "extendedScore": null, "score": 7.792160180201923e-07, "legacy": true, "legacyId": "10261", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SRdvYJrDNvWkpcm8F"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T00:09:10.104Z", "modifiedAt": null, "url": null, "title": "Private Manned Moonbase in the 1990s, Yet Another Planning Fallacy", "slug": "private-manned-moonbase-in-the-1990s-yet-another-planning", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:49.463Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DavidPlumpton", "createdAt": "2011-07-08T09:36:12.175Z", "isAdmin": false, "displayName": "DavidPlumpton"}, "userId": "JyR3HoGsDEckYxEGE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EDS2tGdYcEnJgrwid/private-manned-moonbase-in-the-1990s-yet-another-planning", "pageUrlRelative": "/posts/EDS2tGdYcEnJgrwid/private-manned-moonbase-in-the-1990s-yet-another-planning", "linkUrl": "https://www.lesswrong.com/posts/EDS2tGdYcEnJgrwid/private-manned-moonbase-in-the-1990s-yet-another-planning", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Private%20Manned%20Moonbase%20in%20the%201990s%2C%20Yet%20Another%20Planning%20Fallacy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrivate%20Manned%20Moonbase%20in%20the%201990s%2C%20Yet%20Another%20Planning%20Fallacy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEDS2tGdYcEnJgrwid%2Fprivate-manned-moonbase-in-the-1990s-yet-another-planning%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Private%20Manned%20Moonbase%20in%20the%201990s%2C%20Yet%20Another%20Planning%20Fallacy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEDS2tGdYcEnJgrwid%2Fprivate-manned-moonbase-in-the-1990s-yet-another-planning", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEDS2tGdYcEnJgrwid%2Fprivate-manned-moonbase-in-the-1990s-yet-another-planning", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 249, "htmlBody": "<p>Back in the 1990s I came across a <a title=\"Artemis Project\" href=\"http://asi.org/\">site describing a plan for returning to the moon via privately funded enterprise</a>. They presented a <a href=\"http://asi.org/adb/01/03/overview.html\">Reference Mission</a>, a timeline (raise some money now, design the hardware, build the hardware, hire a launch vehicle, get to the moon, sell the movie rights) which had them starting to build hardware in a few years and touching down on the moon only a few years later. I even met one of the enthusiasts.</p>\n<p>What I found interesting at the time was a presentation of the \"<a title=\"Frequently Raised Objections\" href=\"http://asi.org/adb/j/02/\">Frequently Raised Objections</a>\" and their counter arguments. Their viewpoint was \"we've got this completely solved--we're going!\" The primary issue seemed to be raising the money, and this was covered by a business plan at least to some degree of detail. Of particular relevance was <a href=\"http://asi.org/adb/j/02/all-on-paper.html\">\"It's all on paper, nothing is real\"</a>. Wow, take that Mr Frequently Raised Objection.</p>\n<p>Most of their points looked fairly reasonable in isolation, but of course the idea has failed completely. No launch, no hardware, and very little money. High confidence in the business plan despite little supporting evidence seems to have been the major problem.</p>\n<p>I can't help thinking of these guys every now and then, with their nifty ideas like ascending from the moon with the astronaut sitting on a rocket motor in his spacesuit with no spacecraft needed. I guess the detail made the Planning Fallacy seem less likely at the time.</p>\n<p>The parallels with some other ventures are striking.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb105": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EDS2tGdYcEnJgrwid", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 12, "extendedScore": null, "score": 7.792162246668289e-07, "legacy": true, "legacyId": "10286", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T00:36:43.766Z", "modifiedAt": null, "url": null, "title": "Not By Empathy Alone", "slug": "not-by-empathy-alone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:38.683Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vAsQNjW3gbiskP9Wf/not-by-empathy-alone", "pageUrlRelative": "/posts/vAsQNjW3gbiskP9Wf/not-by-empathy-alone", "linkUrl": "https://www.lesswrong.com/posts/vAsQNjW3gbiskP9Wf/not-by-empathy-alone", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Not%20By%20Empathy%20Alone&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANot%20By%20Empathy%20Alone%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvAsQNjW3gbiskP9Wf%2Fnot-by-empathy-alone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Not%20By%20Empathy%20Alone%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvAsQNjW3gbiskP9Wf%2Fnot-by-empathy-alone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvAsQNjW3gbiskP9Wf%2Fnot-by-empathy-alone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3665, "htmlBody": "<p><a name=\"TOC\"> </a></p>\n<ul>\n<a name=\"TOC\"> </a>\n<li><a name=\"TOC\"></a><a href=\"#introduction\"><span class=\"toc-section-number\">1</span> Introduction</a></li>\n<li><a href=\"#is-empathy-necessary-for-moral-judgment\"><span class=\"toc-section-number\">2</span> Is Empathy Necessary for Moral Judgment?</a></li>\n<li><a href=\"#is-empathy-necessary-for-moral-development\"><span class=\"toc-section-number\">3</span> Is Empathy Necessary for Moral Development?</a></li>\n<li><a href=\"#is-empathy-necessary-for-moral-conduct\"><span class=\"toc-section-number\">4</span> Is Empathy Necessary for Moral Conduct?</a></li>\n<li><a href=\"#should-we-cultivate-an-empathy-based-morality\"><span class=\"toc-section-number\">5</span> Should we Cultivate An Empathy Based Morality?</a></li>\n</ul>\n<p>The following are extracts from the paper <a href=\"http://subcortex.com/IsEmpathyNecessaryForMoralityPrinz.pdf\">&ldquo;Is Empathy Necessary For Morality?&rdquo;</a> (<a href=\"http://philpapers.org/rec/PRIIEN\">philpapers</a>) by <a href=\"http://subcortex.com\">Jesse Prinz</a> (<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Jesse_Prinz\">WP</a>) of CUNY; recently linked in a David Brooks <em>New York Times</em> column, <a href=\"https://www.nytimes.com/2011/09/30/opinion/brooks-the-limits-of-empathy.html\">&ldquo;The Limits of Empathy&rdquo;</a>:</p>\n<h1 id=\"introduction\"><a href=\"#TOC\"><span class=\"header-section-number\">1</span> Introduction</a></h1>\n<blockquote>\n<p>Not only is there little evidence for the claim that empathy is necessary, there is also reason to think empathy can interfere with the ends of morality. A capacity for empathy might make us better people, but placing empathy at the center of our moral lives may be ill\u2010advised. That is not to say that morality shouldn&rsquo;t centrally involve emotions. I think emotions are essential for moral judgment and moral motivation (Prinz, 2007)<sup><a id=\"fnref1\" class=\"footnoteRef\" href=\"#fn1\">1</a></sup>. It&rsquo;s just that empathetic emotions are not ideally suited for these jobs.</p>\n</blockquote>\n<h1 id=\"is-empathy-necessary-for-moral-judgment\"><a id=\"more\"></a></h1>\n<h1><a href=\"#TOC\"><span class=\"header-section-number\">2</span> Is Empathy Necessary for Moral Judgment?</a></h1>\n<blockquote>\n<p>&hellip;For example, one might judge that charity is good, or that wife beating is bad. According to the view under consideration these judgments depend on empathetic responses: we empathize with the positive feelings experienced by the recipients of charity and with the negative feelings of those who fall prey to domestic violence. It is these empathetic responses that allow one to see these actions as good and bad respectively.</p>\n<p>&hellip;[but] consider cases where deontological considerations overrule utilitarian principles. For example, one might judge that it is bad to kill an innocent person even if his vital organs could be used to save five others who desperately need transplants. Here, arguably, we feel cumulatively more empathy for the five people in need than for the one healthy person, but our moral judgment does not track that empathetic response. Second, consider the moral judgments one might issue from behind a Rawlsian veil of ignorance; you might decide it&rsquo;s good to distribute resources to the needy because you might be needy. Here there is no empathy for the needy, but rather concern for the self. Third, while on the topic of the self, consider cases in which you yourself are the victim of a moral transgression. You judge that you&rsquo;ve been wronged, but you don&rsquo;t thereby empathize with yourself, whatever that would mean. Fourth, consider cases in which there is no salient victim. One can judge that it would be wrong to evade taxes or steal from a department store, for instance, without dwelling first on the suffering of those who would be harmed. Fifth, there are victimless transgressions, such as necrophilia, consensual sibling incest, destruction of (unpopulated) places in the environment, or desecration of a grave of someone who has no surviving relative. Empathy makes no sense in these cases. As a descriptive claim it seems wrong to suppose that empathy is a precondition for moral judgment.</p>\n<p>&hellip;It might be objected that empathy is needed to construe an action as greedy, but I find that implausible. I can recognize an action as greedy without putting myself in someone else&rsquo;s shoes. It&rsquo;s cognitively cumbersome to think I route through the simulation of another person every time I classify some behavior as greedy (or thieving, or murderous, or incestuous, or nepotistic, or indecent, and so on, for everything I am apt to condemn as morally bad). Morally significant actions can be recognized without empathy, even if those actions are ones that involve harm. We need not reflect on the harm to see that the action is bad. Perhaps you are delighted that I ate the last cookie. I recognize that, empathetically, and I still feel guilty; I still think I should have offered the cookie to you.</p>\n<p>If this is right, then empathy is not a necessary precursor to moral judgment. I emphasize this point, because it is sometimes presumed that sentimentalist theories of moral judgment must be empathy\u2010based theories. The tradition that includes David Hume and Adam Smith has placed empathy in a central place. It is even sometimes suggested that empathy is the fundamental affective response involved in moral judgment. That is a mistake. The emotions just mentioned have been demonstrated to play a major part in morality. One can advance a sentimentalist theory based on such emotions as anger and guilt, while giving only marginal import to empathy. Empathy may help us come to the conclusion that a particular action is wrong on a particular occasion, but it hardly seems necessary for that purpose.</p>\n</blockquote>\n<h1 id=\"is-empathy-necessary-for-moral-development\"><a href=\"#TOC\"><span class=\"header-section-number\">3</span> Is Empathy Necessary for Moral Development?</a></h1>\n<blockquote>\n<p>&hellip;The emergence of empathy has been extensively investigated, and some developmentalists speculate that empathy plays an essential role in developing a sense of morality (Hoffman, 2000)<sup><a id=\"fnref2\" class=\"footnoteRef\" href=\"#fn2\">2</a></sup>. Conceptually, the idea has much appeal.</p>\n<p>&hellip;It&rsquo;s somewhat difficult to find evidence for developmental hypotheses of this kind. Most studies of normally developing children measure relationships between empathy and morally relevant behaviors such as aggression and helping behaviors (Eisenberg et al., 2006)<sup><a id=\"fnref3\" class=\"footnoteRef\" href=\"#fn3\">3</a></sup>. But what&rsquo;s really at issue here is whether empathy gives rise to the capacity to make moral judgments. Studies do show that children engage in empathetic reasoning when making moral judgments (Eisenberg\u2010Berg, 1979)<sup><a id=\"fnref4\" class=\"footnoteRef\" href=\"#fn4\">4</a></sup>, but they do not show that empathy is essential to moral judgment.</p>\n<p>&hellip;To assess the necessity thesis, researchers must consider pathological populations. They must identify people who lack empathy and see whether they lack moral competence as a result. Blair (1995)<sup><a id=\"fnref5\" class=\"footnoteRef\" href=\"#fn5\">5</a></sup> takes on precisely this challenge. His study investigates morality in psychopaths. Lack of empathy is a diagnostic criterion for psychopathy (Hare, 1991), and Blair shows that psychopaths also suffer from a profound deficit in moral competence. In particular, they do not draw a distinction between moral rules (e.g., don&rsquo;t hit people) and conventional rules (e.g., rules about what clothing to wear in school). Blair concludes that psychopaths&rsquo; failure to draw this distinction indicates that they do not comprehend the essence of moral rules. When they say that something is &ldquo;morally wrong,&rdquo; they don&rsquo;t really understand what these words mean. Blair speculates that this failure is a direct result of the empathy deficit.</p>\n<p>&hellip;One of the diagnostic criteria for psychopathy is &ldquo;criminal versatility,&rdquo; which suggests that psychopathy does not stem from a specific deficit in violence inhibition, as Blair&rsquo;s model suggests. Third, there is evidence that normally developing children draw the moral/conventional distinction well before they associate empathy with morality. Smetana and Braeges (1990)<sup><a id=\"fnref6\" class=\"footnoteRef\" href=\"#fn6\">6</a></sup> show sensitivity to the distinction before the third birthday, and Eisenberg\u2010Berg (1979) shows that empathy does not enter actively into moral reasoning until high school. Fourth, there are other explanations of why psychopaths have deficits in both empathy and moral competence: these two deficits may arise from a third cause. In particular, psychopaths suffer from a more general deficit in moral emotions. &ldquo;Shallow Affect&rdquo; is one of the diagnostic criteria on psychopathy&hellip;.Psychopaths are also poor at recognizing emotions, especially fear and sadness&mdash; and recognition deficits are known to be correlated with deficits in emotional experience (Blair et al., 2002)<sup><a id=\"fnref7\" class=\"footnoteRef\" href=\"#fn7\">7</a></sup>. These affective abnormalities could explain both the low levels of empathy in psychopaths and the lack of moral competence. Empathy requires a disposition to experience emotions appropriate for another person, and a person with shallow affect and poor emotional recognition will have a diminished capacity for empathy as a result. The emotion deficit will also make an individual comparatively insensitive to common methods of moral education: they will be relatively indifferent to punishment, because they have low levels of fear, and they will be unmoved by love withdrawal, because they have low levels of sadness. They will also have a diminished capacity for emotions like guilt, which seem to have sadness as a component (Prinz, 2004)<sup><a id=\"fnref8\" class=\"footnoteRef\" href=\"#fn8\">8</a></sup>, and moral anger. So psychopaths will lack emotions that facilitate moral education as well as the emotions that constitute moral judgments on the model that I outlined in the previous section. Therefore, the deficit in moral competence can be explained without appeal to the empathy deficit.</p>\n</blockquote>\n<h1 id=\"is-empathy-necessary-for-moral-conduct\"><a href=\"#TOC\"><span class=\"header-section-number\">4</span> Is Empathy Necessary for Moral Conduct?</a></h1>\n<blockquote>\n<p>&hellip;Still it might be conjectured that empathy is necessary in another way: it might be necessary for moral motivation. Let&rsquo;s suppose someone arrives at the judgment that it would be good to give charity. It might be possible to make such a judgment without feeling motivated to act on it. Perhaps empathy with the recipients of charity is what converts moral judgment into moral conduct. Or suppose someone comes to think it&rsquo;s bad to abuse his spouse. Without empathy for her, he might continue to be abusive.</p>\n<p>&hellip;[but] Anger promotes aggression, disgust promotes withdrawal, guilt promotes reparation, and shame promotes self\u2010concealment. More generally, these emotions are negatively valenced, and negative emotions are things we work to avoid (Prinz, 2004). If we anticipate that an action will make us feel guilty, we will be thereby inclined to avoid that action. The guilt\u2010prone would\u2010be wife beater might learn to overcome his abusive rages. It follows from this that moral judgments, which contain emotions, are intrinsically motivating states. A person who judges that stealing is wrong, for example, will be motivated to resist the urge to steal, even when it would be easy and lucrative. Such a person will also be motivated to prevent others from stealing; for example, those who think stealing is wrong might report a shoplifter to store clerk even though this intervention carries some risk and no direct reward. And this is just half the story. I have been focusing on disapprobation. There may also be a suite of positive emotions associated with moral approbation. Good behavior by others elicits admiration and gratitude, as remarked above. And the person who engages in good behavior feels pride or gratification. Anticipating these good feelings can lead to good actions. On this view, moral judgments have plenty of motivational impact in the absence of empathy.</p>\n<p>&hellip;That empathy leads to action is actually quite weak. &hellip;In an extensive meta\u2010analysis, Underwood and Moore (1982)<sup><a id=\"fnref9\" class=\"footnoteRef\" href=\"#fn9\">9</a></sup> show that there is a positive correlation between emotion <em>attribution</em> and prosocial behavior in children, but no correlation between <em>empathy</em> and prosocial behavior. Indeed, a number of the studies show negative correlations between empathy and altruism. Critics have worried that the studies contained in this meta\u2010 analysis are flawed because they measure empathy by self report (though measures include non\u2010verbal self report, such as asking children to point out a facial expression corresponding to how they feel). In lieu of self report, Eisenberg et al. (1989)<sup><a id=\"fnref10\" class=\"footnoteRef\" href=\"#fn10\">10</a></sup> used observers&rsquo; reports and found that prosocial behavior is positively correlated with &ldquo;concerned attention&rdquo; in children. A child who wrinkles her brow when watching someone in need, is more likely to help. But no correlation was found for &ldquo;shared emotion.&rdquo;&hellip;There are modest correlations in adults between prosocial behavior and shared sadness (Eisenberg et al., 1989). Adults who looked sad while watching a film about a woman whose children had been in a car wreck were slightly more likely to offer to help that woman with yard work when, later in the experiment, they read a letter from her requesting help. But this study does not establish that empathy, in general, relates to altruism, because it is restricted to sadness. And curiously, there is no correlation between expressions of sadness while reading the letter, and the decision to help, which is made just afterwards&hellip;.A meta\u2010analysis shows that empathy only weakly correlated with prosocial behavior (Neuberg, et al., 1997)<sup><a id=\"fnref11\" class=\"footnoteRef\" href=\"#fn11\">11</a></sup>. More strikingly, the correlation appears only when there is little cost. If someone has to do something as easy as crossing a street to help someone in need, they are not especially likely to, and those who are empathetic show no greater tendency to help in such circumstances than those who are not.</p>\n<p>&hellip;The meager effects of empathy are greatly overshadowed by other emotions. Consider, for example, positive affect. Above, I suggested the feelings of approbation are positive and positive emotions may help to explain why people do good things. Empirical support for this hypothesis comes from the large literature on positive emotions and helping (Carlson et al., 1988)<sup><a id=\"fnref12\" class=\"footnoteRef\" href=\"#fn12\">12</a></sup>. For example, Isen and Levin (1982)<sup><a id=\"fnref13\" class=\"footnoteRef\" href=\"#fn13\">13</a></sup> induced positive affect by planting a dime in a neighborhood phone booth. They then watched to see whether the person who found the dime would help a passerby who dropped some papers. Among those who found the dime, 87.5% helped. Among those in the control condition, where there was no dime planted in the phone, only 4% helped. Other studies have not always shown such a large effect size, but they do tend to confirm that a small dose of happiness seems to promote considerable altruism. This is often true even when the altruism is costly. For example, Weyant (1978)<sup><a id=\"fnref14\" class=\"footnoteRef\" href=\"#fn14\">14</a></sup> found that people who are made to feel good by being given an easy test to solve are almost twice as likely, when compared to neutral controls, to volunteer for a charity that requires going door to door collecting donation. Happiness seems to make us work for people in need. This conclusion is embarrassing for those who think empathy is crucial for altruism because vicarious distress presumably has a negative correlation with positive happiness.</p>\n<p>&hellip;[And on the flip side] Lerner et al. (1998)<sup><a id=\"fnref15\" class=\"footnoteRef\" href=\"#fn15\">15</a></sup> showed subjects emotion\u2010inducing film clips and then probed their attitudes towards punishment on unrelated vignettes. Subjects who watched anger inducing films recommended harsher punishments than those in the control condition. Studies using economic games have shown that, when angry, people are even willing to pay significant costs to punish those who fail to cooperate (Fehr and G&auml;chter, 2002)<sup><a id=\"fnref16\" class=\"footnoteRef\" href=\"#fn16\">16</a></sup>. This contrasts strikingly with empathy, which does not motivate moral behavior when there are significant costs. Guilt is also a great motivator. In a study by Carlsmith and Gross (1969)<sup><a id=\"fnref17\" class=\"footnoteRef\" href=\"#fn17\">17</a></sup> subjects were asked to make some fundraising phone calls for a charity organization after they administered shocks to an innocent person. These subjects made more than three times as many fundraising calls as the subjects in a control condition where no shocks were administered.</p>\n</blockquote>\n<h1 id=\"should-we-cultivate-an-empathy-based-morality\"><a href=\"#TOC\"><span class=\"header-section-number\">5</span> Should we Cultivate An Empathy Based Morality?</a></h1>\n<blockquote>\n<p>&hellip;empathy may lead to preferential treatment. Batson et al. (1995)<sup><a id=\"fnref18\" class=\"footnoteRef\" href=\"#fn18\">18</a></sup> presented subjects with a vignette about a woman, Sheri, awaiting medical treatment, and then asked them if they wanted to move Sheri to the top of the waitlist, above others who were more needy. In the control condition, the majority declined to more her up the list, but in a condition where they were encouraged to empathize with Sheri, they overwhelmingly elected to move her up at the expense of those in greater need.</p>\n<p>&hellip;Third, empathy may be subject to unfortunate biases including cuteness effects. Batson et al. (2005)<sup><a id=\"fnref19\" class=\"footnoteRef\" href=\"#fn19\">19</a></sup> found that college students were more likely to feel empathetic concern for children, dogs, and puppies than their own peers. Batson&rsquo;s notion of empathetic concern is not equivalent to empathy, as I am defining it, because it does not require feeling what the object of empathy should feel, but I think cuteness effects would also arise for empathy. For example, I&rsquo;d wager that we would feel more vicarious sadness for a dying mouse than a rat, and more vicarious fear for a frog crossing the highway than a lizard. It has also been found that empathetic accuracy&mdash;which includes the ability to identify someone else&rsquo;s emotions, and, thus, perhaps, to mirror them&mdash;increases when the target is viewed as attractive (Ickes et al., 1990)<sup><a id=\"fnref20\" class=\"footnoteRef\" href=\"#fn20\">20</a></sup>.</p>\n<p>Fourth, empathy can be easily manipulated. Tsoudis (2002) found that in mock trials, a jury&rsquo;s recommendation for sentencing could be influenced by whether or not victims and defendants expressed emotions. When sadness was expressed, empathy went up, ingratiating the jury to the one who expressed the sadness. Sad victims evoked harsher sentences, and sad defendants got lighter sentences.</p>\n<p>&hellip;Sixth, empathy is prone to in\u2010group biases. We have more empathy for those we see as like us, and that empathy is also more efficacious. Brown et al. (2006)<sup><a id=\"fnref21\" class=\"footnoteRef\" href=\"#fn21\">21</a></sup> found that when viewing pictures of faces, people show more empathetic responses, as measured by physiology and self report, for members of the same ethnic group. St&uuml;rmer et al. (2005)<sup><a id=\"fnref22\" class=\"footnoteRef\" href=\"#fn22\">22</a></sup> found that empathy leads to helping only in cases when the person in need is a member of the in\u2010group. In one of their studies, participants learn about someone who may have contracted hepatitis and their willingness to offer support, such as talking on the phone, depended on both empathy and whether the person had the same sexual orientation as the participant. This strong in\u2010group bias doesn&rsquo;t show up in every study, but even if only occasional, it is something that defenders of empathy should worry about.</p>\n<p>Seventh, empathy is subject to proximity effects. There was an outpouring of support for the Katrina hurricane victims in the United States in 2005, and passionate expressions of empathy for the victims is still frequently expressed in public discourse here. The death toll was 1,836. A year later, an earthquake in Java killed 5,782 people and there was little news coverage in comparison. I would venture to guess that few Americans remember the incident.</p>\n<p>Eighth, empathy is subject to salience effects. Natural disasters and wars are salient, news worthy events. The happen during temporary circumscribed periods in localized areas, and can be characterized in narrative terms (preconditions, the catastrophe, the aftermath). Other causes of mass death are less salient, because they are too constant and diffuse to be news items. This is the case with hunger and disease. To put some depressing numbers on the problem consider the following: malaria is estimated to kill between 1.5 and 4 million people a year; tuberculosis kills 2 million; and AIDS kills 2.8 million. Hunger is the biggest killer of all: 9 million die each year for lack of food. That means that every single day, there are 24 Katrinas. 10.5 times the number of people who died in Katrina die each day from preventable diseases, and 13.5 times as many people die from malnutrition. These deaths are not salient, so they induce little empathy.</p>\n<p>In sum, empathy has serious shortcomings.</p>\n</blockquote>\n<p><a name=\"footnotes\"> </a></p>\n<hr />\n<p><a name=\"footnotes\"> </a></p>\n<p>&nbsp;</p>\n<ol><a name=\"footnotes\"> </a>\n<li id=\"fn1\"><a name=\"footnotes\"> </a>\n<p><a name=\"footnotes\">Prinz, J. J. (2007). <em>The Emotional Construction of Morals</em>. Oxford: Oxford University Press. </a><a class=\"footnoteBackLink\" href=\"#fnref1\">\u21a9</a></p>\n</li>\n<li id=\"fn2\">\n<p>Hoffman, M. (2000). <em>Empathy and moral development: The implications for caring and justice</em>. Cambridge, UK: Cambridge University Press. <a class=\"footnoteBackLink\" href=\"#fnref2\">\u21a9</a></p>\n</li>\n<li id=\"fn3\">\n<p>Eisenberg, N., Spinrad, T.L., and Sadovsky, A. (2006). Empathy\u2010related responding in children. In M. Killen and J. G. Smetana (Eds); Handbook of Moral Development (pp.&nbsp;517\u2010549). Mahwah, NJ, US: Lawrence Erlbaum Associates <a class=\"footnoteBackLink\" href=\"#fnref3\">\u21a9</a></p>\n</li>\n<li id=\"fn4\">\n<p>Eisenberg\u2010Berg, N. (1979). The development of children&rsquo;s prosocial moral judgment. Developmental Psychology, 15, 128\u2010137 <a class=\"footnoteBackLink\" href=\"#fnref4\">\u21a9</a></p>\n</li>\n<li id=\"fn5\">\n<p>Blair, R. J. R. (1995). A cognitive developmental approach to morality: Investigating the psychopath. Cognition, 57, 1\u201029 <a class=\"footnoteBackLink\" href=\"#fnref5\">\u21a9</a></p>\n</li>\n<li id=\"fn6\">\n<p>Smetana, J. and Braeges, J. (1990). The development of toddlers&rsquo; moral and conventional judgments. Merrill&shy;Palmer Quarterly, 36, 329\u2010346 <a class=\"footnoteBackLink\" href=\"#fnref6\">\u21a9</a></p>\n</li>\n<li id=\"fn7\">\n<p>Blair, R. J. R., Mitchell, D. G. V., Richell, R. A., Kelly, S., Leonard, A., Newman, C., and Scott, S. K. (2002). Turning a deaf ear to fear: Impaired recognition of vocal affect in psychopathic individuals. Journal of Abnormal Psychology, 111, 682&ndash; 686 <a class=\"footnoteBackLink\" href=\"#fnref7\">\u21a9</a></p>\n</li>\n<li id=\"fn8\">\n<p>Prinz, J. J. (2004). Gut Reactions: A Perceptual Theory of Emotion. New York: Oxford University Press <a class=\"footnoteBackLink\" href=\"#fnref8\">\u21a9</a></p>\n</li>\n<li id=\"fn9\">\n<p>Underwood, B., and Moore, B. (1982). Perspective\u2010taking and altruism. Psychological Bulletin, 91, 143\u2010173 <a class=\"footnoteBackLink\" href=\"#fnref9\">\u21a9</a></p>\n</li>\n<li id=\"fn10\">\n<p>Eisenberg, N., Fabes, R. A., Miller, P. A., Fultz, J., Shell, R., Mathy, R. M., and Reno, R. R. Relation of sympathy and personal distress to prosocial behavior: a multimethod study. Journal of personality and social psychology, 57, 55\u201066 <a class=\"footnoteBackLink\" href=\"#fnref10\">\u21a9</a></p>\n</li>\n<li id=\"fn11\">\n<p>Neuberg, S. L., Cialdini, R. B., Brown, S. L., Luce, C., Sagarin, B. J., and Lewis, B. P. (1997). Does empathy lead to anything more than superficial helping? Comment on Batson et al (1997). Journal of Personality and Social Psychology, 73, 510\u2010516 <a class=\"footnoteBackLink\" href=\"#fnref11\">\u21a9</a></p>\n</li>\n<li id=\"fn12\">\n<p>Carlson, M., Charlin, V., and Miller, N. (1988). Positive mood and helping behavior: A test of six hypotheses. Journal of Personality and Social Psychology, 55, 211&ndash;229 <a class=\"footnoteBackLink\" href=\"#fnref12\">\u21a9</a></p>\n</li>\n<li id=\"fn13\">\n<p>Isen, A. M. and Levin, P. F. (1972). The effect of feeling good on helping: Cookies and kindness. Journal of Personality and Social Psychology, 21, 384\u2010388 <a class=\"footnoteBackLink\" href=\"#fnref13\">\u21a9</a></p>\n</li>\n<li id=\"fn14\">\n<p>Weyant, J. M. (1978). Effects of mood states, costs, and benefits on helping. Journal of Personality and Social Psychology, 36, 1169&ndash;1176 <a class=\"footnoteBackLink\" href=\"#fnref14\">\u21a9</a></p>\n</li>\n<li id=\"fn15\">\n<p>Lerner, J., and Tiedens, L. (2006). Portrait of The Angry Decision Maker: How Appraisal Tendencies Shape Anger&rsquo;s Influence on Cognition. Journal of Behavioral Decision Making, 19, 115\u2010137 <a class=\"footnoteBackLink\" href=\"#fnref15\">\u21a9</a></p>\n</li>\n<li id=\"fn16\">\n<p>Fehr, E., and G&auml;chter, S. (2002). Altruistic punishment in humans. Nature, 415, 137\u2010140 <a class=\"footnoteBackLink\" href=\"#fnref16\">\u21a9</a></p>\n</li>\n<li id=\"fn17\">\n<p>Carlsmith, J. M., and Gross, A. E. (1969). Some Effects of Guilt on Compliance. Journal of Personality and Social Psychology, 11, 232\u20109 <a class=\"footnoteBackLink\" href=\"#fnref17\">\u21a9</a></p>\n</li>\n<li id=\"fn18\">\n<p>Batson, C. D., Klein, T. R., Highberger, L., and Shaw, L. L. (1995). Immorality from empathy\u2010induced altruism: When compassion and justice conflict. Journal of Personality and Social Psychology, 68, 1042\u20101054 <a class=\"footnoteBackLink\" href=\"#fnref18\">\u21a9</a></p>\n</li>\n<li id=\"fn19\">\n<p>Batson, C., Lishner, D., Cook, J., and Sawyer, S. (2005). Similarity and Nurturance: Two Possible Sources of Empathy for Strangers. Basic and Applied Social Psychology, 27, 15\u201025 <a class=\"footnoteBackLink\" href=\"#fnref19\">\u21a9</a></p>\n</li>\n<li id=\"fn20\">\n<p>Ickkes, W., Stinson, L., Bissonnette, V., and Garcia, S. (1990). Naturalistic social cognition: Empathic accuracy in mixed\u2010sex dyads. Journal of Personality and Social Psychology, 59, 730\u2010742 <a class=\"footnoteBackLink\" href=\"#fnref20\">\u21a9</a></p>\n</li>\n<li id=\"fn21\">\n<p>Brown, L., Bradley, M., and Lang, P. (2006). Affective reactions to pictures of ingroup and outgroup members. Biological Psychology, 71, 303\u2010311 <a class=\"footnoteBackLink\" href=\"#fnref21\">\u21a9</a></p>\n</li>\n<li id=\"fn22\">\n<p>St&uuml;rmer, S., Snyder, M., and Omoto, A. (2005). Prosocial Emotions and Helping: The Moderating Role of Group Membership. Journal of Personality and Social Psychology, 88, 532\u2010546 <a class=\"footnoteBackLink\" href=\"#fnref22\">\u21a9</a></p>\n</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vAsQNjW3gbiskP9Wf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 29, "extendedScore": null, "score": 7.792252062453302e-07, "legacy": true, "legacyId": "10287", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a name=\"TOC\"> </a></p>\n<ul>\n<a name=\"TOC\"> </a>\n<li><a name=\"TOC\"></a><a href=\"#introduction\"><span class=\"toc-section-number\">1</span> Introduction</a></li>\n<li><a href=\"#is-empathy-necessary-for-moral-judgment\"><span class=\"toc-section-number\">2</span> Is Empathy Necessary for Moral Judgment?</a></li>\n<li><a href=\"#is-empathy-necessary-for-moral-development\"><span class=\"toc-section-number\">3</span> Is Empathy Necessary for Moral Development?</a></li>\n<li><a href=\"#is-empathy-necessary-for-moral-conduct\"><span class=\"toc-section-number\">4</span> Is Empathy Necessary for Moral Conduct?</a></li>\n<li><a href=\"#should-we-cultivate-an-empathy-based-morality\"><span class=\"toc-section-number\">5</span> Should we Cultivate An Empathy Based Morality?</a></li>\n</ul>\n<p>The following are extracts from the paper <a href=\"http://subcortex.com/IsEmpathyNecessaryForMoralityPrinz.pdf\">\u201cIs Empathy Necessary For Morality?\u201d</a> (<a href=\"http://philpapers.org/rec/PRIIEN\">philpapers</a>) by <a href=\"http://subcortex.com\">Jesse Prinz</a> (<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Jesse_Prinz\">WP</a>) of CUNY; recently linked in a David Brooks <em>New York Times</em> column, <a href=\"https://www.nytimes.com/2011/09/30/opinion/brooks-the-limits-of-empathy.html\">\u201cThe Limits of Empathy\u201d</a>:</p>\n<h1 id=\"1_Introduction\"><a href=\"#TOC\"><span class=\"header-section-number\">1</span> Introduction</a></h1>\n<blockquote>\n<p>Not only is there little evidence for the claim that empathy is necessary, there is also reason to think empathy can interfere with the ends of morality. A capacity for empathy might make us better people, but placing empathy at the center of our moral lives may be ill\u2010advised. That is not to say that morality shouldn\u2019t centrally involve emotions. I think emotions are essential for moral judgment and moral motivation (Prinz, 2007)<sup><a id=\"fnref1\" class=\"footnoteRef\" href=\"#fn1\">1</a></sup>. It\u2019s just that empathetic emotions are not ideally suited for these jobs.</p>\n</blockquote>\n<h1 id=\"is-empathy-necessary-for-moral-judgment\"><a id=\"more\"></a></h1>\n<h1 id=\"2_Is_Empathy_Necessary_for_Moral_Judgment_\"><a href=\"#TOC\"><span class=\"header-section-number\">2</span> Is Empathy Necessary for Moral Judgment?</a></h1>\n<blockquote>\n<p>\u2026For example, one might judge that charity is good, or that wife beating is bad. According to the view under consideration these judgments depend on empathetic responses: we empathize with the positive feelings experienced by the recipients of charity and with the negative feelings of those who fall prey to domestic violence. It is these empathetic responses that allow one to see these actions as good and bad respectively.</p>\n<p>\u2026[but] consider cases where deontological considerations overrule utilitarian principles. For example, one might judge that it is bad to kill an innocent person even if his vital organs could be used to save five others who desperately need transplants. Here, arguably, we feel cumulatively more empathy for the five people in need than for the one healthy person, but our moral judgment does not track that empathetic response. Second, consider the moral judgments one might issue from behind a Rawlsian veil of ignorance; you might decide it\u2019s good to distribute resources to the needy because you might be needy. Here there is no empathy for the needy, but rather concern for the self. Third, while on the topic of the self, consider cases in which you yourself are the victim of a moral transgression. You judge that you\u2019ve been wronged, but you don\u2019t thereby empathize with yourself, whatever that would mean. Fourth, consider cases in which there is no salient victim. One can judge that it would be wrong to evade taxes or steal from a department store, for instance, without dwelling first on the suffering of those who would be harmed. Fifth, there are victimless transgressions, such as necrophilia, consensual sibling incest, destruction of (unpopulated) places in the environment, or desecration of a grave of someone who has no surviving relative. Empathy makes no sense in these cases. As a descriptive claim it seems wrong to suppose that empathy is a precondition for moral judgment.</p>\n<p>\u2026It might be objected that empathy is needed to construe an action as greedy, but I find that implausible. I can recognize an action as greedy without putting myself in someone else\u2019s shoes. It\u2019s cognitively cumbersome to think I route through the simulation of another person every time I classify some behavior as greedy (or thieving, or murderous, or incestuous, or nepotistic, or indecent, and so on, for everything I am apt to condemn as morally bad). Morally significant actions can be recognized without empathy, even if those actions are ones that involve harm. We need not reflect on the harm to see that the action is bad. Perhaps you are delighted that I ate the last cookie. I recognize that, empathetically, and I still feel guilty; I still think I should have offered the cookie to you.</p>\n<p>If this is right, then empathy is not a necessary precursor to moral judgment. I emphasize this point, because it is sometimes presumed that sentimentalist theories of moral judgment must be empathy\u2010based theories. The tradition that includes David Hume and Adam Smith has placed empathy in a central place. It is even sometimes suggested that empathy is the fundamental affective response involved in moral judgment. That is a mistake. The emotions just mentioned have been demonstrated to play a major part in morality. One can advance a sentimentalist theory based on such emotions as anger and guilt, while giving only marginal import to empathy. Empathy may help us come to the conclusion that a particular action is wrong on a particular occasion, but it hardly seems necessary for that purpose.</p>\n</blockquote>\n<h1 id=\"3_Is_Empathy_Necessary_for_Moral_Development_\"><a href=\"#TOC\"><span class=\"header-section-number\">3</span> Is Empathy Necessary for Moral Development?</a></h1>\n<blockquote>\n<p>\u2026The emergence of empathy has been extensively investigated, and some developmentalists speculate that empathy plays an essential role in developing a sense of morality (Hoffman, 2000)<sup><a id=\"fnref2\" class=\"footnoteRef\" href=\"#fn2\">2</a></sup>. Conceptually, the idea has much appeal.</p>\n<p>\u2026It\u2019s somewhat difficult to find evidence for developmental hypotheses of this kind. Most studies of normally developing children measure relationships between empathy and morally relevant behaviors such as aggression and helping behaviors (Eisenberg et al., 2006)<sup><a id=\"fnref3\" class=\"footnoteRef\" href=\"#fn3\">3</a></sup>. But what\u2019s really at issue here is whether empathy gives rise to the capacity to make moral judgments. Studies do show that children engage in empathetic reasoning when making moral judgments (Eisenberg\u2010Berg, 1979)<sup><a id=\"fnref4\" class=\"footnoteRef\" href=\"#fn4\">4</a></sup>, but they do not show that empathy is essential to moral judgment.</p>\n<p>\u2026To assess the necessity thesis, researchers must consider pathological populations. They must identify people who lack empathy and see whether they lack moral competence as a result. Blair (1995)<sup><a id=\"fnref5\" class=\"footnoteRef\" href=\"#fn5\">5</a></sup> takes on precisely this challenge. His study investigates morality in psychopaths. Lack of empathy is a diagnostic criterion for psychopathy (Hare, 1991), and Blair shows that psychopaths also suffer from a profound deficit in moral competence. In particular, they do not draw a distinction between moral rules (e.g., don\u2019t hit people) and conventional rules (e.g., rules about what clothing to wear in school). Blair concludes that psychopaths\u2019 failure to draw this distinction indicates that they do not comprehend the essence of moral rules. When they say that something is \u201cmorally wrong,\u201d they don\u2019t really understand what these words mean. Blair speculates that this failure is a direct result of the empathy deficit.</p>\n<p>\u2026One of the diagnostic criteria for psychopathy is \u201ccriminal versatility,\u201d which suggests that psychopathy does not stem from a specific deficit in violence inhibition, as Blair\u2019s model suggests. Third, there is evidence that normally developing children draw the moral/conventional distinction well before they associate empathy with morality. Smetana and Braeges (1990)<sup><a id=\"fnref6\" class=\"footnoteRef\" href=\"#fn6\">6</a></sup> show sensitivity to the distinction before the third birthday, and Eisenberg\u2010Berg (1979) shows that empathy does not enter actively into moral reasoning until high school. Fourth, there are other explanations of why psychopaths have deficits in both empathy and moral competence: these two deficits may arise from a third cause. In particular, psychopaths suffer from a more general deficit in moral emotions. \u201cShallow Affect\u201d is one of the diagnostic criteria on psychopathy\u2026.Psychopaths are also poor at recognizing emotions, especially fear and sadness\u2014 and recognition deficits are known to be correlated with deficits in emotional experience (Blair et al., 2002)<sup><a id=\"fnref7\" class=\"footnoteRef\" href=\"#fn7\">7</a></sup>. These affective abnormalities could explain both the low levels of empathy in psychopaths and the lack of moral competence. Empathy requires a disposition to experience emotions appropriate for another person, and a person with shallow affect and poor emotional recognition will have a diminished capacity for empathy as a result. The emotion deficit will also make an individual comparatively insensitive to common methods of moral education: they will be relatively indifferent to punishment, because they have low levels of fear, and they will be unmoved by love withdrawal, because they have low levels of sadness. They will also have a diminished capacity for emotions like guilt, which seem to have sadness as a component (Prinz, 2004)<sup><a id=\"fnref8\" class=\"footnoteRef\" href=\"#fn8\">8</a></sup>, and moral anger. So psychopaths will lack emotions that facilitate moral education as well as the emotions that constitute moral judgments on the model that I outlined in the previous section. Therefore, the deficit in moral competence can be explained without appeal to the empathy deficit.</p>\n</blockquote>\n<h1 id=\"4_Is_Empathy_Necessary_for_Moral_Conduct_\"><a href=\"#TOC\"><span class=\"header-section-number\">4</span> Is Empathy Necessary for Moral Conduct?</a></h1>\n<blockquote>\n<p>\u2026Still it might be conjectured that empathy is necessary in another way: it might be necessary for moral motivation. Let\u2019s suppose someone arrives at the judgment that it would be good to give charity. It might be possible to make such a judgment without feeling motivated to act on it. Perhaps empathy with the recipients of charity is what converts moral judgment into moral conduct. Or suppose someone comes to think it\u2019s bad to abuse his spouse. Without empathy for her, he might continue to be abusive.</p>\n<p>\u2026[but] Anger promotes aggression, disgust promotes withdrawal, guilt promotes reparation, and shame promotes self\u2010concealment. More generally, these emotions are negatively valenced, and negative emotions are things we work to avoid (Prinz, 2004). If we anticipate that an action will make us feel guilty, we will be thereby inclined to avoid that action. The guilt\u2010prone would\u2010be wife beater might learn to overcome his abusive rages. It follows from this that moral judgments, which contain emotions, are intrinsically motivating states. A person who judges that stealing is wrong, for example, will be motivated to resist the urge to steal, even when it would be easy and lucrative. Such a person will also be motivated to prevent others from stealing; for example, those who think stealing is wrong might report a shoplifter to store clerk even though this intervention carries some risk and no direct reward. And this is just half the story. I have been focusing on disapprobation. There may also be a suite of positive emotions associated with moral approbation. Good behavior by others elicits admiration and gratitude, as remarked above. And the person who engages in good behavior feels pride or gratification. Anticipating these good feelings can lead to good actions. On this view, moral judgments have plenty of motivational impact in the absence of empathy.</p>\n<p>\u2026That empathy leads to action is actually quite weak. \u2026In an extensive meta\u2010analysis, Underwood and Moore (1982)<sup><a id=\"fnref9\" class=\"footnoteRef\" href=\"#fn9\">9</a></sup> show that there is a positive correlation between emotion <em>attribution</em> and prosocial behavior in children, but no correlation between <em>empathy</em> and prosocial behavior. Indeed, a number of the studies show negative correlations between empathy and altruism. Critics have worried that the studies contained in this meta\u2010 analysis are flawed because they measure empathy by self report (though measures include non\u2010verbal self report, such as asking children to point out a facial expression corresponding to how they feel). In lieu of self report, Eisenberg et al. (1989)<sup><a id=\"fnref10\" class=\"footnoteRef\" href=\"#fn10\">10</a></sup> used observers\u2019 reports and found that prosocial behavior is positively correlated with \u201cconcerned attention\u201d in children. A child who wrinkles her brow when watching someone in need, is more likely to help. But no correlation was found for \u201cshared emotion.\u201d\u2026There are modest correlations in adults between prosocial behavior and shared sadness (Eisenberg et al., 1989). Adults who looked sad while watching a film about a woman whose children had been in a car wreck were slightly more likely to offer to help that woman with yard work when, later in the experiment, they read a letter from her requesting help. But this study does not establish that empathy, in general, relates to altruism, because it is restricted to sadness. And curiously, there is no correlation between expressions of sadness while reading the letter, and the decision to help, which is made just afterwards\u2026.A meta\u2010analysis shows that empathy only weakly correlated with prosocial behavior (Neuberg, et al., 1997)<sup><a id=\"fnref11\" class=\"footnoteRef\" href=\"#fn11\">11</a></sup>. More strikingly, the correlation appears only when there is little cost. If someone has to do something as easy as crossing a street to help someone in need, they are not especially likely to, and those who are empathetic show no greater tendency to help in such circumstances than those who are not.</p>\n<p>\u2026The meager effects of empathy are greatly overshadowed by other emotions. Consider, for example, positive affect. Above, I suggested the feelings of approbation are positive and positive emotions may help to explain why people do good things. Empirical support for this hypothesis comes from the large literature on positive emotions and helping (Carlson et al., 1988)<sup><a id=\"fnref12\" class=\"footnoteRef\" href=\"#fn12\">12</a></sup>. For example, Isen and Levin (1982)<sup><a id=\"fnref13\" class=\"footnoteRef\" href=\"#fn13\">13</a></sup> induced positive affect by planting a dime in a neighborhood phone booth. They then watched to see whether the person who found the dime would help a passerby who dropped some papers. Among those who found the dime, 87.5% helped. Among those in the control condition, where there was no dime planted in the phone, only 4% helped. Other studies have not always shown such a large effect size, but they do tend to confirm that a small dose of happiness seems to promote considerable altruism. This is often true even when the altruism is costly. For example, Weyant (1978)<sup><a id=\"fnref14\" class=\"footnoteRef\" href=\"#fn14\">14</a></sup> found that people who are made to feel good by being given an easy test to solve are almost twice as likely, when compared to neutral controls, to volunteer for a charity that requires going door to door collecting donation. Happiness seems to make us work for people in need. This conclusion is embarrassing for those who think empathy is crucial for altruism because vicarious distress presumably has a negative correlation with positive happiness.</p>\n<p>\u2026[And on the flip side] Lerner et al. (1998)<sup><a id=\"fnref15\" class=\"footnoteRef\" href=\"#fn15\">15</a></sup> showed subjects emotion\u2010inducing film clips and then probed their attitudes towards punishment on unrelated vignettes. Subjects who watched anger inducing films recommended harsher punishments than those in the control condition. Studies using economic games have shown that, when angry, people are even willing to pay significant costs to punish those who fail to cooperate (Fehr and G\u00e4chter, 2002)<sup><a id=\"fnref16\" class=\"footnoteRef\" href=\"#fn16\">16</a></sup>. This contrasts strikingly with empathy, which does not motivate moral behavior when there are significant costs. Guilt is also a great motivator. In a study by Carlsmith and Gross (1969)<sup><a id=\"fnref17\" class=\"footnoteRef\" href=\"#fn17\">17</a></sup> subjects were asked to make some fundraising phone calls for a charity organization after they administered shocks to an innocent person. These subjects made more than three times as many fundraising calls as the subjects in a control condition where no shocks were administered.</p>\n</blockquote>\n<h1 id=\"5_Should_we_Cultivate_An_Empathy_Based_Morality_\"><a href=\"#TOC\"><span class=\"header-section-number\">5</span> Should we Cultivate An Empathy Based Morality?</a></h1>\n<blockquote>\n<p>\u2026empathy may lead to preferential treatment. Batson et al. (1995)<sup><a id=\"fnref18\" class=\"footnoteRef\" href=\"#fn18\">18</a></sup> presented subjects with a vignette about a woman, Sheri, awaiting medical treatment, and then asked them if they wanted to move Sheri to the top of the waitlist, above others who were more needy. In the control condition, the majority declined to more her up the list, but in a condition where they were encouraged to empathize with Sheri, they overwhelmingly elected to move her up at the expense of those in greater need.</p>\n<p>\u2026Third, empathy may be subject to unfortunate biases including cuteness effects. Batson et al. (2005)<sup><a id=\"fnref19\" class=\"footnoteRef\" href=\"#fn19\">19</a></sup> found that college students were more likely to feel empathetic concern for children, dogs, and puppies than their own peers. Batson\u2019s notion of empathetic concern is not equivalent to empathy, as I am defining it, because it does not require feeling what the object of empathy should feel, but I think cuteness effects would also arise for empathy. For example, I\u2019d wager that we would feel more vicarious sadness for a dying mouse than a rat, and more vicarious fear for a frog crossing the highway than a lizard. It has also been found that empathetic accuracy\u2014which includes the ability to identify someone else\u2019s emotions, and, thus, perhaps, to mirror them\u2014increases when the target is viewed as attractive (Ickes et al., 1990)<sup><a id=\"fnref20\" class=\"footnoteRef\" href=\"#fn20\">20</a></sup>.</p>\n<p>Fourth, empathy can be easily manipulated. Tsoudis (2002) found that in mock trials, a jury\u2019s recommendation for sentencing could be influenced by whether or not victims and defendants expressed emotions. When sadness was expressed, empathy went up, ingratiating the jury to the one who expressed the sadness. Sad victims evoked harsher sentences, and sad defendants got lighter sentences.</p>\n<p>\u2026Sixth, empathy is prone to in\u2010group biases. We have more empathy for those we see as like us, and that empathy is also more efficacious. Brown et al. (2006)<sup><a id=\"fnref21\" class=\"footnoteRef\" href=\"#fn21\">21</a></sup> found that when viewing pictures of faces, people show more empathetic responses, as measured by physiology and self report, for members of the same ethnic group. St\u00fcrmer et al. (2005)<sup><a id=\"fnref22\" class=\"footnoteRef\" href=\"#fn22\">22</a></sup> found that empathy leads to helping only in cases when the person in need is a member of the in\u2010group. In one of their studies, participants learn about someone who may have contracted hepatitis and their willingness to offer support, such as talking on the phone, depended on both empathy and whether the person had the same sexual orientation as the participant. This strong in\u2010group bias doesn\u2019t show up in every study, but even if only occasional, it is something that defenders of empathy should worry about.</p>\n<p>Seventh, empathy is subject to proximity effects. There was an outpouring of support for the Katrina hurricane victims in the United States in 2005, and passionate expressions of empathy for the victims is still frequently expressed in public discourse here. The death toll was 1,836. A year later, an earthquake in Java killed 5,782 people and there was little news coverage in comparison. I would venture to guess that few Americans remember the incident.</p>\n<p>Eighth, empathy is subject to salience effects. Natural disasters and wars are salient, news worthy events. The happen during temporary circumscribed periods in localized areas, and can be characterized in narrative terms (preconditions, the catastrophe, the aftermath). Other causes of mass death are less salient, because they are too constant and diffuse to be news items. This is the case with hunger and disease. To put some depressing numbers on the problem consider the following: malaria is estimated to kill between 1.5 and 4 million people a year; tuberculosis kills 2 million; and AIDS kills 2.8 million. Hunger is the biggest killer of all: 9 million die each year for lack of food. That means that every single day, there are 24 Katrinas. 10.5 times the number of people who died in Katrina die each day from preventable diseases, and 13.5 times as many people die from malnutrition. These deaths are not salient, so they induce little empathy.</p>\n<p>In sum, empathy has serious shortcomings.</p>\n</blockquote>\n<p><a name=\"footnotes\"> </a></p>\n<hr>\n<p><a name=\"footnotes\"> </a></p>\n<p>&nbsp;</p>\n<ol><a name=\"footnotes\"> </a>\n<li id=\"fn1\"><a name=\"footnotes\"> </a>\n<p><a name=\"footnotes\">Prinz, J. J. (2007). <em>The Emotional Construction of Morals</em>. Oxford: Oxford University Press. </a><a class=\"footnoteBackLink\" href=\"#fnref1\">\u21a9</a></p>\n</li>\n<li id=\"fn2\">\n<p>Hoffman, M. (2000). <em>Empathy and moral development: The implications for caring and justice</em>. Cambridge, UK: Cambridge University Press. <a class=\"footnoteBackLink\" href=\"#fnref2\">\u21a9</a></p>\n</li>\n<li id=\"fn3\">\n<p>Eisenberg, N., Spinrad, T.L., and Sadovsky, A. (2006). Empathy\u2010related responding in children. In M. Killen and J. G. Smetana (Eds); Handbook of Moral Development (pp.&nbsp;517\u2010549). Mahwah, NJ, US: Lawrence Erlbaum Associates <a class=\"footnoteBackLink\" href=\"#fnref3\">\u21a9</a></p>\n</li>\n<li id=\"fn4\">\n<p>Eisenberg\u2010Berg, N. (1979). The development of children\u2019s prosocial moral judgment. Developmental Psychology, 15, 128\u2010137 <a class=\"footnoteBackLink\" href=\"#fnref4\">\u21a9</a></p>\n</li>\n<li id=\"fn5\">\n<p>Blair, R. J. R. (1995). A cognitive developmental approach to morality: Investigating the psychopath. Cognition, 57, 1\u201029 <a class=\"footnoteBackLink\" href=\"#fnref5\">\u21a9</a></p>\n</li>\n<li id=\"fn6\">\n<p>Smetana, J. and Braeges, J. (1990). The development of toddlers\u2019 moral and conventional judgments. Merrill\u00adPalmer Quarterly, 36, 329\u2010346 <a class=\"footnoteBackLink\" href=\"#fnref6\">\u21a9</a></p>\n</li>\n<li id=\"fn7\">\n<p>Blair, R. J. R., Mitchell, D. G. V., Richell, R. A., Kelly, S., Leonard, A., Newman, C., and Scott, S. K. (2002). Turning a deaf ear to fear: Impaired recognition of vocal affect in psychopathic individuals. Journal of Abnormal Psychology, 111, 682\u2013 686 <a class=\"footnoteBackLink\" href=\"#fnref7\">\u21a9</a></p>\n</li>\n<li id=\"fn8\">\n<p>Prinz, J. J. (2004). Gut Reactions: A Perceptual Theory of Emotion. New York: Oxford University Press <a class=\"footnoteBackLink\" href=\"#fnref8\">\u21a9</a></p>\n</li>\n<li id=\"fn9\">\n<p>Underwood, B., and Moore, B. (1982). Perspective\u2010taking and altruism. Psychological Bulletin, 91, 143\u2010173 <a class=\"footnoteBackLink\" href=\"#fnref9\">\u21a9</a></p>\n</li>\n<li id=\"fn10\">\n<p>Eisenberg, N., Fabes, R. A., Miller, P. A., Fultz, J., Shell, R., Mathy, R. M., and Reno, R. R. Relation of sympathy and personal distress to prosocial behavior: a multimethod study. Journal of personality and social psychology, 57, 55\u201066 <a class=\"footnoteBackLink\" href=\"#fnref10\">\u21a9</a></p>\n</li>\n<li id=\"fn11\">\n<p>Neuberg, S. L., Cialdini, R. B., Brown, S. L., Luce, C., Sagarin, B. J., and Lewis, B. P. (1997). Does empathy lead to anything more than superficial helping? Comment on Batson et al (1997). Journal of Personality and Social Psychology, 73, 510\u2010516 <a class=\"footnoteBackLink\" href=\"#fnref11\">\u21a9</a></p>\n</li>\n<li id=\"fn12\">\n<p>Carlson, M., Charlin, V., and Miller, N. (1988). Positive mood and helping behavior: A test of six hypotheses. Journal of Personality and Social Psychology, 55, 211\u2013229 <a class=\"footnoteBackLink\" href=\"#fnref12\">\u21a9</a></p>\n</li>\n<li id=\"fn13\">\n<p>Isen, A. M. and Levin, P. F. (1972). The effect of feeling good on helping: Cookies and kindness. Journal of Personality and Social Psychology, 21, 384\u2010388 <a class=\"footnoteBackLink\" href=\"#fnref13\">\u21a9</a></p>\n</li>\n<li id=\"fn14\">\n<p>Weyant, J. M. (1978). Effects of mood states, costs, and benefits on helping. Journal of Personality and Social Psychology, 36, 1169\u20131176 <a class=\"footnoteBackLink\" href=\"#fnref14\">\u21a9</a></p>\n</li>\n<li id=\"fn15\">\n<p>Lerner, J., and Tiedens, L. (2006). Portrait of The Angry Decision Maker: How Appraisal Tendencies Shape Anger\u2019s Influence on Cognition. Journal of Behavioral Decision Making, 19, 115\u2010137 <a class=\"footnoteBackLink\" href=\"#fnref15\">\u21a9</a></p>\n</li>\n<li id=\"fn16\">\n<p>Fehr, E., and G\u00e4chter, S. (2002). Altruistic punishment in humans. Nature, 415, 137\u2010140 <a class=\"footnoteBackLink\" href=\"#fnref16\">\u21a9</a></p>\n</li>\n<li id=\"fn17\">\n<p>Carlsmith, J. M., and Gross, A. E. (1969). Some Effects of Guilt on Compliance. Journal of Personality and Social Psychology, 11, 232\u20109 <a class=\"footnoteBackLink\" href=\"#fnref17\">\u21a9</a></p>\n</li>\n<li id=\"fn18\">\n<p>Batson, C. D., Klein, T. R., Highberger, L., and Shaw, L. L. (1995). Immorality from empathy\u2010induced altruism: When compassion and justice conflict. Journal of Personality and Social Psychology, 68, 1042\u20101054 <a class=\"footnoteBackLink\" href=\"#fnref18\">\u21a9</a></p>\n</li>\n<li id=\"fn19\">\n<p>Batson, C., Lishner, D., Cook, J., and Sawyer, S. (2005). Similarity and Nurturance: Two Possible Sources of Empathy for Strangers. Basic and Applied Social Psychology, 27, 15\u201025 <a class=\"footnoteBackLink\" href=\"#fnref19\">\u21a9</a></p>\n</li>\n<li id=\"fn20\">\n<p>Ickkes, W., Stinson, L., Bissonnette, V., and Garcia, S. (1990). Naturalistic social cognition: Empathic accuracy in mixed\u2010sex dyads. Journal of Personality and Social Psychology, 59, 730\u2010742 <a class=\"footnoteBackLink\" href=\"#fnref20\">\u21a9</a></p>\n</li>\n<li id=\"fn21\">\n<p>Brown, L., Bradley, M., and Lang, P. (2006). Affective reactions to pictures of ingroup and outgroup members. Biological Psychology, 71, 303\u2010311 <a class=\"footnoteBackLink\" href=\"#fnref21\">\u21a9</a></p>\n</li>\n<li id=\"fn22\">\n<p>St\u00fcrmer, S., Snyder, M., and Omoto, A. (2005). Prosocial Emotions and Helping: The Moderating Role of Group Membership. Journal of Personality and Social Psychology, 88, 532\u2010546 <a class=\"footnoteBackLink\" href=\"#fnref22\">\u21a9</a></p>\n</li>\n</ol>", "sections": [{"title": "1 Introduction", "anchor": "1_Introduction", "level": 1}, {"title": "2 Is Empathy Necessary for Moral Judgment?", "anchor": "2_Is_Empathy_Necessary_for_Moral_Judgment_", "level": 1}, {"title": "3 Is Empathy Necessary for Moral Development?", "anchor": "3_Is_Empathy_Necessary_for_Moral_Development_", "level": 1}, {"title": "4 Is Empathy Necessary for Moral Conduct?", "anchor": "4_Is_Empathy_Necessary_for_Moral_Conduct_", "level": 1}, {"title": "5 Should we Cultivate An Empathy Based Morality?", "anchor": "5_Should_we_Cultivate_An_Empathy_Based_Morality_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "109 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 109, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T01:18:10.054Z", "modifiedAt": null, "url": null, "title": "Re-evaluate old beliefs", "slug": "re-evaluate-old-beliefs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.552Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bZjYMFZuymymCkDDG/re-evaluate-old-beliefs", "pageUrlRelative": "/posts/bZjYMFZuymymCkDDG/re-evaluate-old-beliefs", "linkUrl": "https://www.lesswrong.com/posts/bZjYMFZuymymCkDDG/re-evaluate-old-beliefs", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Re-evaluate%20old%20beliefs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARe-evaluate%20old%20beliefs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbZjYMFZuymymCkDDG%2Fre-evaluate-old-beliefs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Re-evaluate%20old%20beliefs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbZjYMFZuymymCkDDG%2Fre-evaluate-old-beliefs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbZjYMFZuymymCkDDG%2Fre-evaluate-old-beliefs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 633, "htmlBody": "<p>I've noticed that, although people can become more rational, they don't win noticeably more.&nbsp; We usually re-calibrate our self-confidence, become more stubborn, and make bigger errors.</p>\n<p>Is it possible that the benefit from increasing your prediction accuracy is no greater than the loss incurred from taking riskier bets due to greater self-confidence?</p>\n<h2><a id=\"more\"></a>Model 1:&nbsp; Static (or, constant re-evaluation of all beliefs)<br /></h2>\n<p>For any yes/no question <em>q</em>, person <em>i</em> has probability <em>p<sub>i</sub></em> of being right.&nbsp; Suppose person <em>i</em> always knows the true value of <em>p<sub>i</sub></em>.</p>\n<p>Suppose, without loss of generality, that we consider only questions where person <em>i</em> decides the answer is \"yes\".&nbsp; (The situation is symmetric for cases where they answer \"no\", so we will get the same results considering only the \"yes\" questions.)</p>\n<p>Suppose that, for every question <em>q</em>, there is some current odds offered by the world, described by society's accepted value <em>y</em> for P(q).&nbsp; Society sets odds to have an expected profit near zero.&nbsp; So the bet will cost the player <em>C</em> if <em>q</em> is false, and will give a payout <em>D</em> if <em>q</em> is true, such that y(D) = (1-y)C.&nbsp; Set D = 1-y, C = y.</p>\n<p>Person <em>i </em>then takes the bet for each question<em> q </em>for which <em>i </em>thinks <em>q</em> is true, and Dp<sub>i</sub> &gt; C(1-p<sub>i</sub>), or (1-y)p<sub>i</sub> &gt; y(1-p<sub>i</sub>), 1/y - y/y &gt; 1/p - p/p, y &lt; p.&nbsp; As they are right with probability <em>p<sub>i</sub>,</em> they win p<sub>i</sub> of these bets.</p>\n<p>Suppose <em>y</em> is distributed uniformly from zero to one<em>.</em>&nbsp; <em>This is the most-suspicious assumption.</em></p>\n<p><em></em>Person <em>i'</em>s profit F(p<sub>i</sub>) is their payouts minus their losses.&nbsp; So F(p<sub>i</sub>) is the integral, from <em>y</em> = 0 to p<sub>i</sub>, of [(1-y)p<sub>i</sub> - y(1-p<sub>i</sub>) = p<sub>i</sub> - y].&nbsp; This integral equals p<sub>i</sub><sup>2</sup> / 2.</p>\n<p>Good!&nbsp; Your winnings should be proportional to the square of your accuracy!</p>\n<p>But that doesn't seem to match what I observe.</p>\n<h2>Model 2: No re-evaluation of old beliefs<br /></h2>\n<p>Now suppose that a person improves their accuracy p<sub>i</sub> over time, and assumes that p<sub>i</sub> is the accuracy for all their beliefs, but doesn't constantly re-evaluate all old beliefs.&nbsp; In this model, time t will be equal to p<sub>i</sub> (representing linear increase in accuracy, which may or may not be realistic, but is simple), ranging from p = p<sub>0</sub> to p<sub>i</sub>, over time t=p<sub>0</sub> to t=p<sub>i</sub>.</p>\n<p>At time t, person <em>i</em> will take all bets with <em>y</em> &lt; <em>t </em>for all their beliefs, although some of these beliefs were formed earlier, when person <em>i</em> had less accuracy.&nbsp; Their profit F(i, t) is now the integral, from x = p<sub>0</sub> to t (x representing the time a belief was formed and its probability of being correct), of the integral, from y = 0 to t, of [(1-y)x - y(1-x) = x - y].&nbsp; The inner integral evaluates to xt - tt/2, the outer integral evaluates to p<sub>i</sub>p<sub>0</sub>(p<sub>i</sub>-p<sub>0</sub>)/2, and we will divide the whole mess by (p<sub>i</sub>-p<sub>0</sub>) to normalize for the number of chances person <em>i</em> had to place bets.</p>\n<p>Now, the expected profit is p<sub>i</sub>p<sub>0</sub>/2.&nbsp; This is only linear in person <em>i</em>'s current accuracy.&nbsp; Perhaps more interesting, if we set p<sub>0</sub> = 0, expected profit is always zero.&nbsp; The new bets taken based on new, more accurate beliefs are exactly balanced out by the losses from bets taken at increasingly worse odds on old, inaccurate beliefs.</p>\n<p>p<sub>0</sub> ~ 0 is not as unreasonable as it sounds.&nbsp; This is because we are not presented in life with a random sample of all possible questions.&nbsp; We are presented with questions that have been filtered by other peoples' uncertainty about these questions.&nbsp; Questions on which an answer is commonly accepted get that answer worked into the fabric of society (so that the decision is usually made for you), and then get ignored.&nbsp; I expect for that reason that the average person has p<sub>i</sub> ~ .5, and some people have p<sub>i</sub> &lt;&lt; .5.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bZjYMFZuymymCkDDG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 7.792395367236223e-07, "legacy": true, "legacyId": "10284", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I've noticed that, although people can become more rational, they don't win noticeably more.&nbsp; We usually re-calibrate our self-confidence, become more stubborn, and make bigger errors.</p>\n<p>Is it possible that the benefit from increasing your prediction accuracy is no greater than the loss incurred from taking riskier bets due to greater self-confidence?</p>\n<h2 id=\"Model_1___Static__or__constant_re_evaluation_of_all_beliefs_\"><a id=\"more\"></a>Model 1:&nbsp; Static (or, constant re-evaluation of all beliefs)<br></h2>\n<p>For any yes/no question <em>q</em>, person <em>i</em> has probability <em>p<sub>i</sub></em> of being right.&nbsp; Suppose person <em>i</em> always knows the true value of <em>p<sub>i</sub></em>.</p>\n<p>Suppose, without loss of generality, that we consider only questions where person <em>i</em> decides the answer is \"yes\".&nbsp; (The situation is symmetric for cases where they answer \"no\", so we will get the same results considering only the \"yes\" questions.)</p>\n<p>Suppose that, for every question <em>q</em>, there is some current odds offered by the world, described by society's accepted value <em>y</em> for P(q).&nbsp; Society sets odds to have an expected profit near zero.&nbsp; So the bet will cost the player <em>C</em> if <em>q</em> is false, and will give a payout <em>D</em> if <em>q</em> is true, such that y(D) = (1-y)C.&nbsp; Set D = 1-y, C = y.</p>\n<p>Person <em>i </em>then takes the bet for each question<em> q </em>for which <em>i </em>thinks <em>q</em> is true, and Dp<sub>i</sub> &gt; C(1-p<sub>i</sub>), or (1-y)p<sub>i</sub> &gt; y(1-p<sub>i</sub>), 1/y - y/y &gt; 1/p - p/p, y &lt; p.&nbsp; As they are right with probability <em>p<sub>i</sub>,</em> they win p<sub>i</sub> of these bets.</p>\n<p>Suppose <em>y</em> is distributed uniformly from zero to one<em>.</em>&nbsp; <em>This is the most-suspicious assumption.</em></p>\n<p><em></em>Person <em>i'</em>s profit F(p<sub>i</sub>) is their payouts minus their losses.&nbsp; So F(p<sub>i</sub>) is the integral, from <em>y</em> = 0 to p<sub>i</sub>, of [(1-y)p<sub>i</sub> - y(1-p<sub>i</sub>) = p<sub>i</sub> - y].&nbsp; This integral equals p<sub>i</sub><sup>2</sup> / 2.</p>\n<p>Good!&nbsp; Your winnings should be proportional to the square of your accuracy!</p>\n<p>But that doesn't seem to match what I observe.</p>\n<h2 id=\"Model_2__No_re_evaluation_of_old_beliefs\">Model 2: No re-evaluation of old beliefs<br></h2>\n<p>Now suppose that a person improves their accuracy p<sub>i</sub> over time, and assumes that p<sub>i</sub> is the accuracy for all their beliefs, but doesn't constantly re-evaluate all old beliefs.&nbsp; In this model, time t will be equal to p<sub>i</sub> (representing linear increase in accuracy, which may or may not be realistic, but is simple), ranging from p = p<sub>0</sub> to p<sub>i</sub>, over time t=p<sub>0</sub> to t=p<sub>i</sub>.</p>\n<p>At time t, person <em>i</em> will take all bets with <em>y</em> &lt; <em>t </em>for all their beliefs, although some of these beliefs were formed earlier, when person <em>i</em> had less accuracy.&nbsp; Their profit F(i, t) is now the integral, from x = p<sub>0</sub> to t (x representing the time a belief was formed and its probability of being correct), of the integral, from y = 0 to t, of [(1-y)x - y(1-x) = x - y].&nbsp; The inner integral evaluates to xt - tt/2, the outer integral evaluates to p<sub>i</sub>p<sub>0</sub>(p<sub>i</sub>-p<sub>0</sub>)/2, and we will divide the whole mess by (p<sub>i</sub>-p<sub>0</sub>) to normalize for the number of chances person <em>i</em> had to place bets.</p>\n<p>Now, the expected profit is p<sub>i</sub>p<sub>0</sub>/2.&nbsp; This is only linear in person <em>i</em>'s current accuracy.&nbsp; Perhaps more interesting, if we set p<sub>0</sub> = 0, expected profit is always zero.&nbsp; The new bets taken based on new, more accurate beliefs are exactly balanced out by the losses from bets taken at increasingly worse odds on old, inaccurate beliefs.</p>\n<p>p<sub>0</sub> ~ 0 is not as unreasonable as it sounds.&nbsp; This is because we are not presented in life with a random sample of all possible questions.&nbsp; We are presented with questions that have been filtered by other peoples' uncertainty about these questions.&nbsp; Questions on which an answer is commonly accepted get that answer worked into the fabric of society (so that the decision is usually made for you), and then get ignored.&nbsp; I expect for that reason that the average person has p<sub>i</sub> ~ .5, and some people have p<sub>i</sub> &lt;&lt; .5.</p>", "sections": [{"title": "Model 1:\u00a0 Static (or, constant re-evaluation of all beliefs)", "anchor": "Model_1___Static__or__constant_re_evaluation_of_all_beliefs_", "level": 1}, {"title": "Model 2: No re-evaluation of old beliefs", "anchor": "Model_2__No_re_evaluation_of_old_beliefs", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T01:37:06.937Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge, MA Sunday meetup", "slug": "meetup-cambridge-ma-sunday-meetup-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.141Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KFbKbn6SbzatE5R6g/meetup-cambridge-ma-sunday-meetup-0", "pageUrlRelative": "/posts/KFbKbn6SbzatE5R6g/meetup-cambridge-ma-sunday-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/KFbKbn6SbzatE5R6g/meetup-cambridge-ma-sunday-meetup-0", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%2C%20MA%20Sunday%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%2C%20MA%20Sunday%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKFbKbn6SbzatE5R6g%2Fmeetup-cambridge-ma-sunday-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%2C%20MA%20Sunday%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKFbKbn6SbzatE5R6g%2Fmeetup-cambridge-ma-sunday-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKFbKbn6SbzatE5R6g%2Fmeetup-cambridge-ma-sunday-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 74, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/3w'>Cambridge, MA Sunday meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 October 2011 09:37:25PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">MIT Stata Center 32 Vassar Street, Cambridge, MA; room 261</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the MIT Stata center. We will have someone posted at the entrance to let people in for the first 30 minutes; if you arrive after that, or are having trouble finding us, call 607-339-5552.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/3w'>Cambridge, MA Sunday meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KFbKbn6SbzatE5R6g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.792459387191232e-07, "legacy": true, "legacyId": "10289", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA_Sunday_meetup\">Discussion article for the meetup : <a href=\"/meetups/3w\">Cambridge, MA Sunday meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 October 2011 09:37:25PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">MIT Stata Center 32 Vassar Street, Cambridge, MA; room 261</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will be meeting in the MIT Stata center. We will have someone posted at the entrance to let people in for the first 30 minutes; if you arrive after that, or are having trouble finding us, call 607-339-5552.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA_Sunday_meetup1\">Discussion article for the meetup : <a href=\"/meetups/3w\">Cambridge, MA Sunday meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge, MA Sunday meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA_Sunday_meetup", "level": 1}, {"title": "Discussion article for the meetup : Cambridge, MA Sunday meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA_Sunday_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T01:55:11.751Z", "modifiedAt": null, "url": null, "title": "Another Mechanism for the Placebo Effect?", "slug": "another-mechanism-for-the-placebo-effect", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:03.151Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5F4fksQwJDE5EKKxK/another-mechanism-for-the-placebo-effect", "pageUrlRelative": "/posts/5F4fksQwJDE5EKKxK/another-mechanism-for-the-placebo-effect", "linkUrl": "https://www.lesswrong.com/posts/5F4fksQwJDE5EKKxK/another-mechanism-for-the-placebo-effect", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Another%20Mechanism%20for%20the%20Placebo%20Effect%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnother%20Mechanism%20for%20the%20Placebo%20Effect%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5F4fksQwJDE5EKKxK%2Fanother-mechanism-for-the-placebo-effect%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Another%20Mechanism%20for%20the%20Placebo%20Effect%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5F4fksQwJDE5EKKxK%2Fanother-mechanism-for-the-placebo-effect", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5F4fksQwJDE5EKKxK%2Fanother-mechanism-for-the-placebo-effect", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 268, "htmlBody": "<p>The placebo effect (benefit in groups receiving fake pills) and nocebo effect (detriment in those same groups) have frequently been the bane of medical research. They are usually explained in terms of psychology: because people receiving placebos believe they have been treated, they get psychosomatic effects that cure symptoms and create side effects. This explanation is supported by the fact that the placebo effect is strongest when the effect being studied is subjective - eg, tests of painkillers and antidepressants. This explanation is neat, tidy, and in my opinion, altogether unsatisfying.</p>\n<p>I have an alternative theory. Most people in medical studies take more than one medication; in addition to the drug being studied, they take unrelated drugs and supplements, usually including a multivitamin and often including other things they were prescribed. However, many people take their pills inconsistently; they miss or mistime some fraction of their doses. This is especially true of depressed people. Prescribing a placebo, however, fixes this; when they take their placebo pill in the morning, they are reminded to take everything else they should be taking. In addition to making pill-taking more salient, being prescribed a placebo may also cause some people to fix the organization and affordances they have for taking pills.</p>\n<p>I suspect that many of the benefits attributed from placebos may in fact be due to increased compliance with unrelated prescriptions and correction of vitamin and mineral deficiencies. Arranging a study to test this should be fairly straightforward; simply measure the rate at which unrelated prescriptions are refilled in two groups, one of which receives sugar pills and one of which does not.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5F4fksQwJDE5EKKxK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 8, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "10290", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T02:34:16.124Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Expecting Short Inferential Distances", "slug": "seq-rerun-expecting-short-inferential-distances", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:49.379Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iwxEw6Cy6uXLPCXEB/seq-rerun-expecting-short-inferential-distances", "pageUrlRelative": "/posts/iwxEw6Cy6uXLPCXEB/seq-rerun-expecting-short-inferential-distances", "linkUrl": "https://www.lesswrong.com/posts/iwxEw6Cy6uXLPCXEB/seq-rerun-expecting-short-inferential-distances", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Expecting%20Short%20Inferential%20Distances&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Expecting%20Short%20Inferential%20Distances%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiwxEw6Cy6uXLPCXEB%2Fseq-rerun-expecting-short-inferential-distances%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Expecting%20Short%20Inferential%20Distances%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiwxEw6Cy6uXLPCXEB%2Fseq-rerun-expecting-short-inferential-distances", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiwxEw6Cy6uXLPCXEB%2Fseq-rerun-expecting-short-inferential-distances", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 195, "htmlBody": "<p>Today's post, <a href=\"/lw/kg/expecting_short_inferential_distances/\">Expecting Short Inferential Distances</a> was originally published on 22 October 2007. A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Humans evolved in an environment where we almost never needed to explain long inferential chains of reasoning. This fact may account for the difficulty many people have when trying to explain complicated subjects. We only explain the last step of the argument, and not every step that must be taken from our listener's premises.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them. The previous post was <a href=\"/r/discussion/lw/7wx/seq_rerun_selfanchoring/\">Self-Anchoring</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort. You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iwxEw6Cy6uXLPCXEB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 7.792652496828653e-07, "legacy": true, "legacyId": "10291", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HLqWn5LASfhhArZ7w", "HF6qxQdkpBQicC2jc", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T02:52:48.759Z", "modifiedAt": null, "url": null, "title": "Why are you downvoting?", "slug": "why-are-you-downvoting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:48.897Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gBJwAjydby5rte79K", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Qyw9kbPXDN2q3eoNP/why-are-you-downvoting", "pageUrlRelative": "/posts/Qyw9kbPXDN2q3eoNP/why-are-you-downvoting", "linkUrl": "https://www.lesswrong.com/posts/Qyw9kbPXDN2q3eoNP/why-are-you-downvoting", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20are%20you%20downvoting%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20are%20you%20downvoting%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQyw9kbPXDN2q3eoNP%2Fwhy-are-you-downvoting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20are%20you%20downvoting%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQyw9kbPXDN2q3eoNP%2Fwhy-are-you-downvoting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQyw9kbPXDN2q3eoNP%2Fwhy-are-you-downvoting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>Look <a href=\"/lw/7x4/religion_happiness_and_bayes/4ygp\">here</a> for example.</p>\n<p>Let's not discourage discussion by downvoting people that \"are wrong\". It is hard enough to correct your mistaken beliefs, if a community is pushing you away for having them this makes it even worse.</p>\n<p>The thumbs down button should be for posts that are bad, if someone says something you don't agree with it you should argue instead. It's unhealthy to just push away people that have different views, rather than challenging yourself to explain why they are wrong.</p>\n<p>Here is an exercise that will help improve LessWrong: watch for reasons why you downvote comments you do the next couple of days.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Qyw9kbPXDN2q3eoNP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -5, "extendedScore": null, "score": -2e-06, "legacy": true, "legacyId": "10292", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T03:15:21.502Z", "modifiedAt": null, "url": null, "title": "[LINK] A Review and Summary of John Harris's Case for Chemical Enhancement", "slug": "link-a-review-and-summary-of-john-harris-s-case-for-chemical", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.148Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "r_claypool", "createdAt": "2011-02-13T13:43:23.915Z", "isAdmin": false, "displayName": "r_claypool"}, "userId": "afmiWkqiSCpzHD4Xd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WmmW7WcaJyaikoyCh/link-a-review-and-summary-of-john-harris-s-case-for-chemical", "pageUrlRelative": "/posts/WmmW7WcaJyaikoyCh/link-a-review-and-summary-of-john-harris-s-case-for-chemical", "linkUrl": "https://www.lesswrong.com/posts/WmmW7WcaJyaikoyCh/link-a-review-and-summary-of-john-harris-s-case-for-chemical", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20A%20Review%20and%20Summary%20of%20John%20Harris's%20Case%20for%20Chemical%20Enhancement&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20A%20Review%20and%20Summary%20of%20John%20Harris's%20Case%20for%20Chemical%20Enhancement%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWmmW7WcaJyaikoyCh%2Flink-a-review-and-summary-of-john-harris-s-case-for-chemical%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20A%20Review%20and%20Summary%20of%20John%20Harris's%20Case%20for%20Chemical%20Enhancement%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWmmW7WcaJyaikoyCh%2Flink-a-review-and-summary-of-john-harris-s-case-for-chemical", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWmmW7WcaJyaikoyCh%2Flink-a-review-and-summary-of-john-harris-s-case-for-chemical", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 7, "htmlBody": "<p><a title=\"John Harris on Chemical Enhancement \" href=\"http://philosophicaldisquisitions.blogspot.com/2011/10/john-harris-on-chemical-enhancement.html\">http://philosophicaldisquisitions.blogspot.com/2011/10/john-harris-on-chemical-enhancement.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WmmW7WcaJyaikoyCh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.792791336175635e-07, "legacy": true, "legacyId": "10293", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T07:51:22.952Z", "modifiedAt": null, "url": null, "title": "[LINK] Robin Hanson on Carl Shulman's recent paper on Whole Brain Emulation", "slug": "link-robin-hanson-on-carl-shulman-s-recent-paper-on-whole", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.047Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nS2gCL5xcTi8vu42e/link-robin-hanson-on-carl-shulman-s-recent-paper-on-whole", "pageUrlRelative": "/posts/nS2gCL5xcTi8vu42e/link-robin-hanson-on-carl-shulman-s-recent-paper-on-whole", "linkUrl": "https://www.lesswrong.com/posts/nS2gCL5xcTi8vu42e/link-robin-hanson-on-carl-shulman-s-recent-paper-on-whole", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Robin%20Hanson%20on%20Carl%20Shulman's%20recent%20paper%20on%20Whole%20Brain%20Emulation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Robin%20Hanson%20on%20Carl%20Shulman's%20recent%20paper%20on%20Whole%20Brain%20Emulation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnS2gCL5xcTi8vu42e%2Flink-robin-hanson-on-carl-shulman-s-recent-paper-on-whole%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Robin%20Hanson%20on%20Carl%20Shulman's%20recent%20paper%20on%20Whole%20Brain%20Emulation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnS2gCL5xcTi8vu42e%2Flink-robin-hanson-on-carl-shulman-s-recent-paper-on-whole", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnS2gCL5xcTi8vu42e%2Flink-robin-hanson-on-carl-shulman-s-recent-paper-on-whole", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 235, "htmlBody": "<p><a href=\"http://www.overcomingbias.com/2011/10/shulman-on-superorgs.html\">Shulman on Superorgs</a></p>\n<p>Best to read the link first and my comments later.</p>\n<p>I have very little to comment on the topic itself, but I do find it odd that Robin takes such a confrontational stance, beginning from the first sentence \"It has come to my attention that&nbsp;<a href=\"/lw/5jb/link_whole_brain_emulation_and_the_evolution_of/\">some</a>&nbsp;think that by now I should have commented on Carl Shulman&rsquo;s em paper\" and culminating with a harsh analysis not only of Carl's conclusions, but about what (Robin believes) made him want to reach those conclusions, as well as SIAI's mission statement in general. There is negative framing, \"obsession with making a god to rule us all (well)\", that I wouldn't expect from someone trying to honestly represent the other side. It's not that I don't share some of those concerns, but to psychoanalyse (who you seem to have identified as) your opponent in an obvious effort to discredit, is at the very least unfair.&nbsp; I was generally aware that there was some kind of tension between the former dynamic duo of Hanson - Yudkowsky, but it seems to have become full-blown hostility.</p>\n<p>Robin does seem to find the courage to say he's glad others are looking into emulations, but the overall vibe I get is of someone protective of a research field they believe they uniquely 'get', someone who feels others should just get in line or get out of the ring, and it's a vibe not uncommon in academia.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nS2gCL5xcTi8vu42e", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 21, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "10299", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bjQroWRe33yQM75Ha"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T08:43:56.508Z", "modifiedAt": null, "url": null, "title": "Pascal's wager re-examined", "slug": "pascal-s-wager-re-examined", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:09.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qvxFu7gtHiLfc5Egp/pascal-s-wager-re-examined", "pageUrlRelative": "/posts/qvxFu7gtHiLfc5Egp/pascal-s-wager-re-examined", "linkUrl": "https://www.lesswrong.com/posts/qvxFu7gtHiLfc5Egp/pascal-s-wager-re-examined", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pascal's%20wager%20re-examined&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APascal's%20wager%20re-examined%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqvxFu7gtHiLfc5Egp%2Fpascal-s-wager-re-examined%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pascal's%20wager%20re-examined%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqvxFu7gtHiLfc5Egp%2Fpascal-s-wager-re-examined", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqvxFu7gtHiLfc5Egp%2Fpascal-s-wager-re-examined", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 837, "htmlBody": "<p>Let P(chr) = the probability that the statements attributed to Jesus of Nazareth and Paul of Tarsus regarding salvation and the afterlife are factually mostly correct; and let U(C) be the utility of action C, where <em>C</em> is in {Christianity, Islam, Judaism, atheism}.</p>\n<p>Two of the key criticisms of Pascal's wager are that</p>\n<ul>\n<li>limit <sub>U(Christianity)&rarr;&infin;, P(chr)&rarr;0 </sub><em>P(chr)</em>U(Christianity) is undefined, and</li>\n<li>invoking infinite utilities isn't fair.</li>\n</ul>\n<p>If, however, P(chr) is not infinitessimal, and U(Christianity) is merely very large, these counter-arguments fail.</p>\n<p><a id=\"more\"></a>Many poor arguments have been made that P(chr) &gt; .1.&nbsp; But as far as I know, no one has ever made the best argument in favor of Christianity:</p>\n<ul>\n<li>Let P(sim) be the probability that we are living in a simulation.</li>\n<li>Let P(ent|sim) be the probability that this simulation was created for entertainment purposes, as opposed to purposes including scientific, economic, or governmental reasons.</li>\n<li>Let P(ego|ent, sim) be the probability that the person or organization running our simulation wants to be personally glorified within their simulation, and therefore created an avatar of themselves, or represented themselves in myth, or in some other way put some being into the sim whose status in the sim they identify with.</li>\n<li>Let P(chr0|ego, ent, sim, Earth) be the probability, given the observed history of Earth, that, of the various candidate religions or leaders or possible avatars, this egoist God is using Christianity.&nbsp; (The same argument applies for Islam.&nbsp; Judaism has a different payoff matrix.&nbsp; I'm deliberately ignoring polytheistic religions.)</li>\n<li>Let P(follow-thru | chr0, ego, ent, sim, Earth) be the probability that our simulator God, on Earth, who is representing itself via Christianity, will follow through on promises of implementing Heaven and Hell - if not for an infinite time period, then for a long enough time periods that your utility is at least 99% afterlife.&nbsp; Heaven and Hell could provide utility/disutility much greater than a human lifespan even if they run only until the end of game.&nbsp; I imagine that pure torment could provide more than a lifetime's worth of disutility in a few days or weeks.</li>\n<li>Then P(chr) &gt; P(sim)P(ent|sim)P(ego|ent,sim)P(chr0|ego,ent,sim,Earth)P(follow-thru|chr0, ego, ent, sim, Earth).</li>\n</ul>\n<p>If you accept the <a href=\"http://www.simulation-argument.com/\">simulation argument</a>, then P(sim) &gt; .99.</p>\n<p>If you look at the fraction of computing power used for entertainment, I don't know what it is, but the <a href=\"http://top500.org/list/2011/06/100\">top 100 supercomputer list</a> for June 2011 lists a total of 4,531,940 cores in the top 100 supercomputers in the world; versus (rough guess) a billion personal computers and video game consoles, and a similar number of ordinary computers used at work.&nbsp; It would be reasonable to set p(ent|sim) = .5.</p>\n<p>If you set P(ego|ent, sim) according to the fraction of entertainment simulations in which the person playing the game has an avatar in the game, then P(ego|ent, sim) is large.&nbsp; I originally set this at p &gt; .99, but am now setting it to p = .5 in response to <a href=\"/r/discussion/lw/7x7/pascals_wager_reexamined/4ydh\">Jack's comment</a> below.</p>\n<p>We notice there are no obviously immortal world leaders on Earth (but see <a href=\"/r/discussion/lw/7x7/pascals_wager_reexamined/4yea\">vi21maobk9vp's comment</a> below).&nbsp; If we therefore limit the possible avatars that our simulator God is using on Earth to the major monotheistic religions of Christianity, Islam, and Judaism, and consider them all equiprobable; plus a 25% chance that this God is jumping from one avatar to another, or chose to reveal Himself via Jesus but then Paul screwed everything up, or some other minority position; then p(chr0|ego, ent, sim, Earth) = .25.</p>\n<p>P(follow-thru) is difficult to estimate; I will set it somewhat arbitrarily as .1.&nbsp; Given our observations of game-players here on Earth, it is not independent of p(ego), as players of self-glorifying games are likely to be young adolescent males, and so are people who enjoy burning insects with magnifying glasses.</p>\n<p>We now have p(chr) &gt; .99 x .5 x .5 x .25 x .1 = .0061875.&nbsp; As stipulated, your afterlife accounts for at least 99% of your utility if <em>follow-thru </em>(and hence <em>chr</em>) is true.&nbsp; If we suppose that the length of time for which God rewards us in Heaven or torments us in Hell has an exponential distribution, and we are considering only the part of that distribution where &gt;= 99% of your utility is in the afterlife, then almost certainly p(chr) * U(Christianity | chr) &gt; (1-p(chr)) * U(atheism | not(chr)). It now appears we should accept Pascal's wager.</p>\n<p>(The expected utilities for Christianity and Islam are similar, and this argument gives no reason for favoring one over the other.&nbsp; That is of only minor interest to me unless I accept the wager.&nbsp; The important point is that they both will have expected utilities similar to, and possibly exceeding, that of atheism.)</p>\n<p>You can argue with any of the individual numbers above.&nbsp; But you would have to make pretty big changes to make p(chr)(U(Christianity|chr)) negligible in your utility calculation.</p>\n<p>(IMHO, voting this article up should indicate it passed the threshold, \"That's an interesting observation that contributes to the discussion\", not, \"Omigod you're right, I am going out to get baptized RIGHT NOW!\".)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qvxFu7gtHiLfc5Egp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": -10, "extendedScore": null, "score": -2.6e-05, "legacy": true, "legacyId": "10267", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 120, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T11:08:45.712Z", "modifiedAt": null, "url": null, "title": "Repairing Yudkowsky's anti-zombie argument", "slug": "repairing-yudkowsky-s-anti-zombie-argument", "viewCount": null, "lastCommentedAt": "2019-10-18T20:36:26.023Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "4mYMvt6SSZtZRbMMX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6TBhBjiYivtLCKGoy/repairing-yudkowsky-s-anti-zombie-argument", "pageUrlRelative": "/posts/6TBhBjiYivtLCKGoy/repairing-yudkowsky-s-anti-zombie-argument", "linkUrl": "https://www.lesswrong.com/posts/6TBhBjiYivtLCKGoy/repairing-yudkowsky-s-anti-zombie-argument", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Repairing%20Yudkowsky's%20anti-zombie%20argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARepairing%20Yudkowsky's%20anti-zombie%20argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6TBhBjiYivtLCKGoy%2Frepairing-yudkowsky-s-anti-zombie-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Repairing%20Yudkowsky's%20anti-zombie%20argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6TBhBjiYivtLCKGoy%2Frepairing-yudkowsky-s-anti-zombie-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6TBhBjiYivtLCKGoy%2Frepairing-yudkowsky-s-anti-zombie-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3189, "htmlBody": "<p>Eliezer Yudkowsky argues with David Chalmers <a href=\"/lw/p7/zombies_zombies\">here</a> on the subject of &ldquo;philosophical zombies&rdquo;. I submit that, although Yudkowsky&rsquo;s position on this question is correct, his argument fails to establish what he claims it to.<br /><br />To summarise Yudkowsky and Chalmers&rsquo;s argument:<br /><br />1. Both Yudkowsky and Chalmers agree that humans possess &ldquo;qualia&rdquo;.<br />2. Chalmers argues that a superintelligent being which somewhow knew the positions of all particles in a large region of the Universe would need to be told as an additional fact that any humans (or other minds possessing qualia) in this region of space possess qualia &ndash; it could not deduce this from mere perfect physical knowledge of their constituent particles. Therefore, qualia are in some sense extra-physical.<br />3. Yudkowsky argues that such a being would notice that humans discuss at length the fact that they possess qualia, and their internal narratives also represent this fact. It is extraordinarily improbable that beings would behave in this manner if they did not actually possess qualia. Therefore an omniscient being would conclude that it is extremely likely that humans possess qualia. Therefore, qualia are not extra-physical.<br /><br />My objection to Yudkowsky&rsquo;s argument is that it is not enough merely to demonstrate that the omniscient being would find it extremely likely that humans possess qualia. Probability is a state of partial information; therefore unless the being is certain that humans possess qualia, it is not in fact omniscient regarding this region of the Universe despite the fact that it is postulated to possess perfect physical knowledge about it.</p>\n<p>I expect that some Lesswrongians may object to this on account of the fact that 1 and 0 are not probabilities. However, the thought experiment postulates an omniscient being that possesses perfect knowledge about the physical state of a region of the Universe, therefore in the thought experiment absolute certainty is defined to be possible. If this is objectionable*, then the entire argument is badly posed including Yudkowsky&rsquo;s contribution.</p>\n<p>Additionally (although superfluously), it seems that the thought experiment should generalise to any possible configuration of particles in a region of the Universe, since we are trying to prove that qualia are not extra-physical under any circumstances, and a proof of this should not rely on contingent features of the qualia-experiencing beings under consideration. Therefore let us suppose that due to a miracle of quantum tunnelling, the only qualia-experiencing being in the region of space in question is a newborn human infant (I presume wide agreement upon the fact that such an infant does in fact possess qualia.) Is it still the case that the omniscient being can deduce, from the infant&rsquo;s mental behaviours, the extreme likelihood of its possessing qualia? After all, it doesn&rsquo;t write philosophy papers and may not even have an internal narrative.</p>\n<p>My own solution to the zombie problem is that it is a restatement of the Mary&rsquo;s room problem. In the zombie thought experiment we are dealing with a mind that has perfect knowledge of a physical human brain (or any brain that produces qualia). Since the Universe&rsquo;s computational accuracy appears to be infinite, in order for the mind to be omniscient about a human brain it must be running the human brain&rsquo;s quark-level computations within its own mind; any approximate computation would yield imperfect predictions. In the act of running this computation, the brain&rsquo;s qualia are generated, if (as we have assumed) the brain in question experiences qualia. Therefore the omniscient mind is fully aware of all of the qualia that are experienced within the volume of the Universe about which it has perfect knowledge.</p>\n<p>It is legitimate for us to believe with extremely high probability that the computations occurring in a brain are causally related to the qualia that it produces, for the reasons that Yudkowsky has given; therefore, it is fair for us to state (as I did in the preceding paragraph) with extremely high probability that when it runs a brain&rsquo;s computations the omniscient mind will experience the same qualia that the brain&rsquo;s original owner does. The distinction is that <em>we</em> can be <em>extremely confident</em> (by Yudkowsky&rsquo;s reasoning) that the omniscient mind will <em>itself</em> be <em>certain</em> (by my reasoning) about the existence of qualia within the volume of the Universe about which it has perfect knowledge &ndash; whereas if one is trying to prove that qualia are not extra-physical, it insufficient to argue (as Yudkowsky did) that the omniscient mind will <em>itself</em> only be <em>extremely confident</em> about the existence of qualia within the volume of the Universe about which it has perfect knowledge.</p>\n<p>There is an objection to the above argument that I would expect readers to suggest. The objection is that I have misinterpreted Yudkowsky&rsquo;s argument, and in fact my summary of Yudkowsky and Chalmers&rsquo;s argument should read as follows:</p>\n<p>3. Yudkowsky argues that such a being would notice that humans discuss at length the fact that they possess qualia, and their internal narratives also represent this fact. It would use its perfect knowledge of their mental processes to investigate the chain of reasoning that leads humans to refer to themselves as being &ldquo;aware&rdquo; and possessing &ldquo;qualia&rdquo;. It would thereby discover the cause of their discussing these things, which is extremely likely to provide it with a reduction of the qualia concept. Therefore the omniscient mind will with extremely high probability obtain for itself perfect certainty that the qualia-experiencing beings within the region of the Universe about which it has perfect knowledge do in fact experience qualia.<br /><br />If this argument was valid, it would have exactly the same outcome as my own conclusion (and a different outcome to Yudkowsky&rsquo;s argument as I summarised it earlier): we can be extremely confident that the omniscient mind will itself be certain about the existence of qualia within the volume of the Universe about which it has perfect knowledge (rather than: the omniscient mind will be extremely confident about the existence of qualia within the volume of the Universe about which it has perfect knowledge).<br /><br />I don&rsquo;t interpret Yudkowsky&rsquo;s argument in this way, but since it is a closely related meaning I cannot be very sure that he does not intend the above. In any case, I believe that this argument begs the question.<br /><br />The revised argument assumes that the qualia concept is almost certainly reducible. However, doubt regarding this appears to be the entire motivation for Yudkowsky and Chalmers&rsquo;s debate. If Yudkowsky were to regard it is a given that qualia are reducible, then why not replace his 6,600 word post with the following: the thesis of reductionism is proven beyond reasonable doubt to be true. Therefore qualia, like other phenomena that we observe, must be reducible to the level of quarks. Therefore if a mind possesses perfect knowledge about a region of the Universe at the level of quarks, it necessarily understands qualia and recognises their existence because qualia are merely higher-order phenomena composed of quarks. QED.<br /><br />Since Yudkowsky did not do that, I presume that he does not believe that the reducibility of qualia can be taken for granted. Regardless of what he believes, I would nonetheless criticise the revised argument on the basis that qualia should not be assumed to be reducible.<br /><br />An observation about qualia: they do not appear to be susceptible to definition. All of the definitions of qualia that I have encountered have been either nonsensical, or liable to be interpreted (&agrave; la Dennett) as mere computational properties of the brain.&nbsp; And definition, done properly, is in fact the same act as philosophical reduction.<br /><br />For example, qualia might be defined as &ldquo;subjective qualities of experience&rdquo;. Subjective in this context means the same thing as incommunicable. A definition of something as essentially incommunicable is tantamout to defining it as indefinable, which is nonsense. &ldquo;The inner listener&rdquo; and similar attempted definitions are interpreted by Dennett in the sense of the brain&rsquo;s having a parallel computational structure &ndash; not the intended referent at all. And the &ldquo;mysterious redness of red&rdquo; could either be interpreted as a reference to the nature of redness as a derived or computational property of objects rather than a fundamental property, or as gibberish (since there are no inherently mysterious phenomena).<br /><br />Nonetheless, since (I believe with extremely high probability) we all possess qualia, we are able to figure out the intended referent of words like &ldquo;qualia&rdquo; and &ldquo;consciousness&rdquo; (at least before the word consciousness was philosophically co-opted by Dennett). We are aware of the existence of one indefinable concept, and we can shore up our mutual recognition of terms that refer to it by discussing the apparent relationship between the properties of this concept and the state of our physical brains, which seem perfectly reducible to quarks and susceptible to definition.<br /><br />In <a href=\"/lw/tv/excluding_the_supernatural\">this post</a>, Yudkowsky writes: <br /><br /><em>Suppose that a 747 had a fundamental physical existence apart from the quarks making up the 747.<br /><br />What experimental observations would you expect to make, if you found yourself in such a universe?<br /><br />If you can't come up with a good answer to that, it's not observation that's ruling out \"non-reductionist\" beliefs, but a priori logical incoherence. If you can't say what predictions the \"non-reductionist\" model makes, how can you say that experimental evidence rules it out?<br /><br />My thesis is that non-reductionism is a confusion; and once you realize that an idea is a confusion, it becomes a tad difficult to envision what the universe would look like if the confusion were true.</em><br /><br />May I offer, as a suggestion of what an authentic irreducible concept looks like, qualia?<br /><br />There are two reasons why it is rational to hold a completely reductionist view of the Universe. Firstly, reductionism is a historically successful means of explaining things and solving problems, and always defeats non-reductionism. Secondly, non-reductionism is a priori logically incoherent in the sense that Yudkowsky describes.</p>\n<p>However, what if the qualia concept is actually a counter-example to both of these? Of course it&rsquo;s far too early to conclude that reductionist means have failed to explain qualia &ndash; we need to learn more about the brain first. But is it not also reasonable to suggest that our experience of qualia is exactly what we would expect the universe to look like, if irreducible phenomena were to exist? We almost all agree that qualia exist, and in fact my belief in the existence of qualia is the last belief of which I can imagine anyone dissuading me, yet we have thus far (despite much philosophical inquiry and a fair amount of neuroscience) been incapable of reducing the concept to the slightest extent. By comparison concepts such as <a href=\"/lw/sm/the_meaning_of_right\">shouldness</a> and <a href=\"/lw/rb/possibility_and_couldness\">couldness</a>, which are complex computational properties of the brain, have already been reduced a level or two within our map of reality.<br /><br />To summarise, I argue that neither version of Yudkowsky&rsquo;s anti-zombie argument, as I interpret it, is sound. The first version is unsound because it fails to demonstrate that an omniscient mind possesses the same level of confidence in its judgements about qualia as it does about the physical Universe, and the second version is unsound because it presumes that qualia are reducible, which is unwarranted. I also propose my own anti-zombie argument, which I believe demonstrates that qualia are not in fact extra-physical (although they may yet be irreducible).<br /><br />*I see the premise of an agent with perfect knowledge as a helpful simplification in the thought experiment. But I believe that it could be exchanged for a fallible superintelligence without the conclusions changing. The contrast between perfect certainty and infinitesimal uncertainty would be replaced by minor uncertainty and infinitesimally increased uncertainty. The problem still exists with Yudkowsky&rsquo;s argument that if qualia are not extra-physical, then uncertainty about qualia should be no greater than total uncertainty regarding the physical configuration of reality.</p>\n<p>&nbsp;</p>\n<p><strong>EDIT:</strong></p>\n<p>It seems to me that I should have paid more attention to (i.e. re-read) Eliezer&rsquo;s post &ldquo;the generalised anti-zombie principle&rdquo; before writing this article. Because in it he states:</p>\n<blockquote>\n<p>&ldquo;Consciousness, whatever it may be - a substance, a process, a name for a confusion - is not epiphenomenal; your mind can catch the inner listener in the act of listening, and say so out loud. The fact that I have typed this paragraph would at least seem to refute the idea that consciousness has no experimentally detectable consequences.&rdquo;</p>\n<p>...</p>\n<p><br />Could we define the word \"consciousness\" to mean \"whatever actually makes humans talk about 'consciousness'\"? This would have the powerful advantage of guaranteeing that there is at least one real fact named by the word \"consciousness\". Even if our belief in consciousness is a confusion, \"consciousness\" would name the cognitive architecture that generated the confusion.</p>\n</blockquote>\n<p><br />So Vladimir Nesov appears to be correct in that I was wrong to assume that Yudkowsky was necessarily referring to the same kind of \"qualia\" or \"consciousness\" that Chalmers was.</p>\n<p>Rather than further delving into guesses about Yudkowsky&rsquo;s intentions, I&rsquo;ll just attempt to clarify my conclusions in general:</p>\n<p>1. I notice that most humans regard themselves as possessing &ldquo;qualia&rdquo;. Formerly this concept might have been known as &ldquo;consciousness&rdquo;, but at this point that term is ambiguous. No-one seems able to define qualia, despite their insistence that it is a real concept. Qualia are considered to be related to brain processes in some way.</p>\n<p>2. Writers such as Dennett believe that they can (or have already) described approximately the physical process by which the brain computes an internal narrative containing statements such as &ldquo;I am aware that I am aware&rdquo;, and similar references that many would understand as referring to qualia. Specifically, according to wikipedia: &ldquo;Dennett's view of consciousness is that it is the apparently serial account for the brain's underlying parallelism.&rdquo;</p>\n<p>3. As I believe I have demonstrated, if we assume that qualia exist then we are bound to believe with extremely high probability that a being that has perfect knowledge of a physical brain is fully aware of the qualia that are being produced in this brain. It has no more uncertainty about qualia than it has about the physical brain states. I also believe that Yudkowsky&rsquo;s argument did not prove this, for reasons already stated.</p>\n<p>4. &ldquo;3&rdquo; does not allow us to conclude that &ldquo;qualia&rdquo; are the cause of our making statements such as &ldquo;I am aware that I am aware&rdquo;. These statements can be explained according to Dennett&rsquo;s eliminative materialist view, in which qualia are held not to exist on the basis that the concept is resolutely indefinable and therefore unreal. However although &ldquo;qualia&rdquo; are apparently indefinable, since a given human&rsquo;s degree of belief in the existence of qualia is typically extremely high, many humans are unwilling to apply normal standards to the concept. One possibility, which I favour, is to expect that we will ultimately discover that the brain produces statements about consciousness for a reason along the lines of what Dennett describes, but that this physically instantiated computation serves a double role* both as a reducible causal explanation for why we talk about &ldquo;qualia&rdquo; and in producing the irreducible phenomenon of qualia by means of a psycho-physical bridging law. This would mean that qualia supervene upon brain states, but the causality operates only in one direction. In this scenario qualia are an irreducible phenomenon, and since our means of investigating the world necessarily involve the tool of reduction we cannot expect to understand qualia or any putative &ldquo;psycho-physical bridging law&rdquo;. Although this appears to be similar to irrational scientific confusions of the past, there is reason (as I have argued) to view qualia as a legitimate exception.</p>\n<p>5. Alternatively, it may turn out to be the case that when we learn more about the brain, we will discover a reduction of qualia that satisfies everyone who claims to experience qualia. In this case &ldquo;qualia&rdquo; would indeed be the cause of our referring to ourselves as possessing qualia, and qualia would also be seen to be real. However, as I have discussed the concept of qualia possesses unusual features that make this seem somewhat unlikely.</p>\n<p>*Think of it as being the algorithm, and &ldquo;how the algorithm feels from inside&rdquo;. In this case, since we <em>are</em> the algorithm, both are real!</p>\n<p>So on reflection, it appears that I have quite a large disagreement with Yudkowsky:</p>\n<p>It seems to me that Yudkowsky&rsquo;s argument <a href=\"/lw/p7/zombies_zombies\">here</a> does not prove what it is supposed to prove &ndash; that complete physical knowledge entails complete knowledge of qualia &ndash; and this is necessary in order for qualia not to be some entirely airy-fairy mystical concept that neither of us agrees with. The only way in which it could be interpreted to prove that, is if we simply assume that the concept of irreducible qualia is disallowed and he only means to refer to \"reducible qualia\" or \"qualia-eliminative reducible consciousness\" &ndash; this is both unwarranted, and sheds a rather confusing light on why Yudkowsky took 6,600 words to make his point.</p>\n<p>If Yudkowsky is an eliminativist about &ldquo;qualia&rdquo;, i.e. he is actually attempting to prove that complete physical knowledge entails complete knowledge of reducible, qualia-eliminative <em>consciousness</em> (per Dennett), he is both in conflict with a majority of people&rsquo;s extremely strong beliefs and he could have countered Chalmers with a very brief argument stating simply that talk about consciousness necessarily has a cause, and this cause must be a computation in the brain reducible to quarks.</p>\n<p>If Yudkowsky is a reductionist regarding &ldquo;qualia&rdquo;, i.e. he is actually attempting to prove that complete physical knowledge entails complete knowledge of reducible qualia only, the question remains why qualia still appear to be entirely elusive to definition and again he could have countered Chalmers with a very brief argument stating simply that talk about qualia necessarily has a cause, and this cause must be a computation in the brain reducible to quarks.</p>\n<p>If on the other hand Yudkowsky is ambivalent about these options, I don&rsquo;t believe that it is sensible for him to refer under a single banner &ldquo;consciousness&rdquo; to the concepts &ldquo;irreducible qualia&rdquo; and &ldquo;reductive explanation of qualia&rdquo; and &ldquo;reductive qualia-eliminative explanation of consciousness&rdquo; because statements that are true of one are not true of the others. So he should stick to arguing about the consequences of one at a time.</p>\n<p>For example, despite the fact that I agree that complete physical knowledge entails complete knowledge of <em>irreducible qualia</em>, I don&rsquo;t see how this proves that <em>irreducible qualia</em> are the cause of our making statements such as &ldquo;I am aware that I am aware&rdquo;. So if Yudkowsky argues that complete physical knowledge entails complete knowledge of <em>consciousness</em> as though this proved that <em>consciousness</em> is the cause of our making statements such as &ldquo;I am aware that I am aware&rdquo; then he must only mean consciousness in the sense of reducible qualia or qualia-eliminative consciousness. And I have already discussed the problem with assuming these concepts at the expense of irreducible qualia, and asked the question why it takes 6,600 words to refute Chalmers under those assumptions.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6TBhBjiYivtLCKGoy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 7, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "10302", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 79, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fdEWWr8St59bXLbQr", "u6JzcFtPGiznFgDxP", "fG3g3764tSubr6xvs", "3buXtNiSK8gcRLMSG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T16:41:24.534Z", "modifiedAt": null, "url": null, "title": "Freewill vs. Determinism", "slug": "freewill-vs-determinism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:38.284Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "fmossJdRymLR3KvDx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HSRpoHvaFszh5se4j/freewill-vs-determinism", "pageUrlRelative": "/posts/HSRpoHvaFszh5se4j/freewill-vs-determinism", "linkUrl": "https://www.lesswrong.com/posts/HSRpoHvaFszh5se4j/freewill-vs-determinism", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Freewill%20vs.%20Determinism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFreewill%20vs.%20Determinism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHSRpoHvaFszh5se4j%2Ffreewill-vs-determinism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Freewill%20vs.%20Determinism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHSRpoHvaFszh5se4j%2Ffreewill-vs-determinism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHSRpoHvaFszh5se4j%2Ffreewill-vs-determinism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1165, "htmlBody": "<p>This topic has been covered ad nauseum on nearly every page on the internet. But it still generates so much good conversation that I will stir he pot again.&nbsp;</p>\n<p><span style=\"line-height: 26px;\">\n<p class=\"MsoNormal\" style=\"line-height: normal;\">Imagine you are walking down the street and come upon a woman lying on the ground crying. Suddenly you realize she has obviously been assaulted. You rush to her side, feeling an intense desire to help. The thing we would refer to as our &ldquo;self&rdquo; stands at the intersection of the lines of input and stimuli with decision and action. By all accounts you will tend to feel that you are the root cause of your own thoughts and actions. Personal choice has led you to either act or not to act. You seem to be acting on your own free will. However, as I hope to highlight this perspective cannot be held in light of what science tells us about the workings of the human brain.</p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\">At a conscious level we are aware of only a small portion of the information that our brains are processing at each moment. While we are continually aware of acute changes in our moods, thoughts, perceptions, behavior, etc. we are left completely unaware of the brain states that produce these changes. Yet nearly all of us maintain that we are the creators of our own patterns of thought and action. The physiologist Benjamin Libet has demonstrated that neural activity in the motor regions can be detected 350 milliseconds before the subject is aware that they have decided to move. (Libet, Gleason, Wright and Pearl, 1983). More recently fMRI data has been shown to convey that &ldquo;conscious&rdquo; decisions can be seen in neural activity 10 seconds before the subject is aware of them. (Soon, Brass, Heinze and Hayes, 2008) These findings make it difficult to maintain that one is the conscious author of their own actions.</p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\">No perspective which takes into account causality leaves room for freewill. Our internal dialog of thoughts, desires and moods simply pop into minds producing either action or stasis. The reasons for this are left unexplained from a purely subjective point of view.<span>&nbsp; </span>Our belief in free will seems to spring out of our moment to moment ignorance of the causal chain which produces our thoughts and actions. The term &ldquo;free will&rdquo; merely describes the feeling of being the author of our own thoughts as they arise in consciousness. Take for instance a train of thoughts like, &ldquo;I&rsquo;m hungry. I think there is some cake in the fridge. Well cake isn&rsquo;t very healthy, maybe cottage cheese would be better,&rdquo; this example highlights the apparent choices one can make, and they seem freely made. <span>&nbsp;</span>But looking deeper reveals that these thoughts simply arise free of our authorship and yet direct our actions nevertheless.</p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\">The alternative position to traditional free will is often known as Determinism, and is almost considered a bad word by most people. The philosopher Daniel Dennett has highlighted the confusion most people carry with regards to determinism. &ldquo;They equate determinism with fatalism.&rdquo; This confusion produces questions such as, &ldquo;if determinism is true why should I do anything? Why not just wait and see what happens?&rdquo; This line of questioning reveals that most people imagine that if our choices depend on prior causes that they do not matter. The fact that I am writing this paper is the result of a choice to do so, if I had not decided to write it, it would not get written. But my choice to do so was unquestionably the result of many causal factors, such as the desire to achieve a decent grade, social pressures and a desire to achieve a goal. Choice is as important as those who fancy free will state that it is. Some people imagine that if we acknowledge that we are not the author of our own thoughts and actions that, moral and political freedoms then become unimportant. But merely acknowledging the causal influences and the fact that we do not know what we will intend until the intention arises, does not lessen the value of personal freedom of individuals to do what they intend or not to do otherwise, regardless of the source of those intentions.</p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\">This issue is not purely philosophical and academic, meant to be a silly logical exercise. This belief in free will is the foundation of the religious notion of &ldquo;sin&rdquo; as well as the underlying commitment to retributive justice. Free will has been deemed by The Supreme Court a &ldquo;universal and persistent&rdquo; base for law in our country, also stating &ldquo;a deterministic view of human conduct that is inconsistent with the underlying precepts of our criminal justice system&rdquo; (United States v. Grayson, 1978). It seems that any advancements in science which threaten the commonly held notions about free will draw into question the ethics of punishing people for their bad behavior. It seems that the primary worry is that an honest discussion of the root causes of our behavior will erode moral responsibility. But does the acknowledgement of underlying causes for our behavior mean that we cannot be expected to take responsibility for our actions? Of course we wouldn't.</p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\">We can view human beings as forces of genetic and environmental influences and still not be prevented from talking about moral responsibility, it does however, cause problems for our practices of retributive punishment. Obviously there are people who possess the intent to harm and cannot be helped away from his intention. We need to protect society from them. It is clear from the scientific findings that the people who are the worst criminals we can imagine have some grouping of bad genetics, bad influences, bad ideas and bad circumstances. The role these have played in the bad choices they have made should seem obvious. The question then becomes, which of these ingredients can we hold them responsible for? The justice system (if is to be just) must reflect the understanding that any of us could easily have been dealt a very different hand in life, and given that different hand we could be in their place. It borders on immorality to not consider the level of blind chance which is involved in morality.</p>\n<p class=\"MsoNormal\" style=\"line-height: normal;\">Imagine a heinous murder in which the killer did it &ldquo;just for the fun of it&rdquo;. Yet upon psychiatric and medical examination he is found to have a tumor the size of a golf ball in the medial prefrontal cortex of his brain (this area is responsible for emotional control and behavioral impulse). It would be fairly easy to surmise that he was not in any real sense responsible for his actions in carrying out the murder. He was not in his right mind. We would not prescribe the same punishment for him as we would a perfectly healthy individual. Why not? Would it be moral to deny this man surgery as a &rdquo;punishment&rdquo; for his crime? And furthermore where do we draw the line in ascribing personal responsibility apart from the causal forces which author our thoughts and actions?&nbsp;</p>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HSRpoHvaFszh5se4j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -8, "extendedScore": null, "score": 7.795515817879114e-07, "legacy": true, "legacyId": "10303", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T18:02:40.682Z", "modifiedAt": null, "url": null, "title": "Meetup : Ottawa Meetup - Learning Linear Algebra", "slug": "meetup-ottawa-meetup-learning-linear-algebra", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PBubLywizysaxnxTA/meetup-ottawa-meetup-learning-linear-algebra", "pageUrlRelative": "/posts/PBubLywizysaxnxTA/meetup-ottawa-meetup-learning-linear-algebra", "linkUrl": "https://www.lesswrong.com/posts/PBubLywizysaxnxTA/meetup-ottawa-meetup-learning-linear-algebra", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Ottawa%20Meetup%20-%20Learning%20Linear%20Algebra&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Ottawa%20Meetup%20-%20Learning%20Linear%20Algebra%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPBubLywizysaxnxTA%2Fmeetup-ottawa-meetup-learning-linear-algebra%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Ottawa%20Meetup%20-%20Learning%20Linear%20Algebra%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPBubLywizysaxnxTA%2Fmeetup-ottawa-meetup-learning-linear-algebra", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPBubLywizysaxnxTA%2Fmeetup-ottawa-meetup-learning-linear-algebra", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 58, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/3y'>Ottawa Meetup - Learning Linear Algebra</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">10 October 2011 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">K2P 1N1</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>Type</strong> - Skill Training: Learning Linear Algebra - preparation for the Stanford AI Class</p>\n\n<p><strong>Location</strong> - Private residence near Elgin &amp; Gladstone. Join the <a href=\"http://groups.google.com/group/less-wrong-ottawa\" rel=\"nofollow\">Google group</a> for specifics.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/3y'>Ottawa Meetup - Learning Linear Algebra</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PBubLywizysaxnxTA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.795790604007371e-07, "legacy": true, "legacyId": "10305", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra\">Discussion article for the meetup : <a href=\"/meetups/3y\">Ottawa Meetup - Learning Linear Algebra</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">10 October 2011 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">K2P 1N1</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>Type</strong> - Skill Training: Learning Linear Algebra - preparation for the Stanford AI Class</p>\n\n<p><strong>Location</strong> - Private residence near Elgin &amp; Gladstone. Join the <a href=\"http://groups.google.com/group/less-wrong-ottawa\" rel=\"nofollow\">Google group</a> for specifics.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra1\">Discussion article for the meetup : <a href=\"/meetups/3y\">Ottawa Meetup - Learning Linear Algebra</a></h2>", "sections": [{"title": "Discussion article for the meetup : Ottawa Meetup - Learning Linear Algebra", "anchor": "Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra", "level": 1}, {"title": "Discussion article for the meetup : Ottawa Meetup - Learning Linear Algebra", "anchor": "Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T18:46:08.128Z", "modifiedAt": null, "url": null, "title": "On self-deception", "slug": "on-self-deception", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.335Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "irrational", "createdAt": "2011-10-04T19:46:41.913Z", "isAdmin": false, "displayName": "irrational"}, "userId": "TaHr6NuudyhaHevgQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6mtoy9gh32rQzfT4r/on-self-deception", "pageUrlRelative": "/posts/6mtoy9gh32rQzfT4r/on-self-deception", "linkUrl": "https://www.lesswrong.com/posts/6mtoy9gh32rQzfT4r/on-self-deception", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20self-deception&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20self-deception%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6mtoy9gh32rQzfT4r%2Fon-self-deception%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20self-deception%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6mtoy9gh32rQzfT4r%2Fon-self-deception", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6mtoy9gh32rQzfT4r%2Fon-self-deception", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1815, "htmlBody": "<p>(Meta-note: First post on this site)</p>\n<p>I have read the sequence on self-deception/doublethink and I have some comments for which I'd like to solicit feedback. This post is going to focus on the idea that it's impossible to deceive oneself, or to make oneself believe something which one knows apriori to be wrong. I think Eliezer believes this to be true, e.g. <a href=\"/lw/r/no_really_ive_deceived_myself/\">as discussed here</a>. I'd like to propose a contrary position.</p>\n<p>Let's suppose that a super-intelligent AI has been built, and it knows plenty of tricks that no human ever thought of, in order to present a false argument which is not easily detectable to be false. Whether it can do that by presenting subtly wrong premises, or by incorrect generalization, or word tricks, or who knows what, is not important. It can, however, present an argument in a Socratic manner, and like Socrates' interlocutors, you find yourself agreeing with things you don't expect to agree with. I now come to this AI, and request it to make a library of books for me (personally). Each is to be such that if I (specifically) were to read it, I would very likely come to believe a certain proposition. It should take into account that initially I may be opposed to the proposition, and that I am aware that I am being manipulated. Now, AI produces such a library, on the topic of religion, for all major known religions, A to Z. It has a book called \"You should be an atheist\", and \"You should be a Christian\", etc, up to \"You should be a Zoroastrian\".</p>\n<p>Suppose, I now want to deceive myself. I throw fair dice, and end up picking a Zoroastrian book. I now commit to reading the entire book and do so. In the process I become convinced that indeed, I should be a Zoroastrian, despite my initial skepticism. Now my skeptical friend comes to me:</p>\n<p style=\"padding-left: 30px;\">Q: You don't really believe in Zoroastrianism.</p>\n<p style=\"padding-left: 30px;\">A: No, I do. Praise Ahura Mazda!</p>\n<p style=\"padding-left: 30px;\">Q: You can't possibly mean it. You know that you didn't believe it and you read a book that was designed to manipulate you, and now you do? Don't you have any introspective ability?</p>\n<p style=\"padding-left: 30px;\">A: I do. I didn't intend to believe it, but it turns out that it is actually true! Just because I picked this book up for the wrong reason, doesn't mean I can't now be genuinely convinced. There are many examples where people would study religion of their enemy in order to discredit it and in the process become convinced of its truth. I think St. Augustine was in a somewhat similar case.</p>\n<p style=\"padding-left: 30px;\">Q: But you know the book is written in such a way as to convince you, whether it's true or not.</p>\n<p style=\"padding-left: 30px;\">A: I took that into account, and my prior was really low that I would ever believe it. But the evidence presented in the book was so significant and convincing that it overcame my skepticism.</p>\n<p style=\"padding-left: 30px;\">Q: But the book is a rationalization of Zoroastrianism. It's not an impartial analysis.</p>\n<p style=\"padding-left: 30px;\">A: I once read a book trying to explain and prove G&ouml;del's theorem. It was written explicitly to convince the reader that the theorem was true. It started with the conclusion and built all arguments to prove it. But the book was in fact correct in asserting this proposition.</p>\n<p style=\"padding-left: 30px;\">Q: But the AI is a clever arguer. It only presents arguments that are useful to its cause.</p>\n<p style=\"padding-left: 30px;\">A: So is the book on G&ouml;del's theorem. It never presented any arguments against G&ouml;del, and I know there are some, at least philosophical ones. It's still true.</p>\n<p style=\"padding-left: 30px;\">Q: You can't make a new decision based on such a book which is a rationalization. Perhaps it can only be used to expand one's knowledge. Even if it argues in support of a true proposition, a book that is a rationalization is not really evidence for the proposition's truth.</p>\n<p style=\"padding-left: 30px;\">A: You know that our AI created a library of books to argue for most theological positions. Do you agree that with very high probability one of the books in the library argues for a true proposition? E.g. the one about atheism? If I were to read it now, I'd become an atheist again.</p>\n<p style=\"padding-left: 30px;\">Q: Then do so!</p>\n<p style=\"padding-left: 30px;\">A: No, Ahura Mazda will punish me. I know I would think he's not there after I read it, but he'll punish me anyway. Besides, at present I believe that book to be intentionally misleading. Anyway, if one of the books argues for a true proposition, it may also use a completely valid argument without any tricks. I think this is true of this book on Zoroastrianism, and is false of all other books in AI's library.</p>\n<p style=\"padding-left: 30px;\">Q: Perhaps I believe the Atheism book argues for a true proposition, but it is possible that all the books written by the AI use specious reasoning, even the one that argues for a true proposition. In this case, you can't rely on any of them being valid.</p>\n<p style=\"padding-left: 30px;\">A: Why should the AI do that? Valid argument is the best way to demonstrate the truth of something that is in fact true. If tricks are used, this may be uncovered which would throw doubt onto the proposition being argued.</p>\n<p style=\"padding-left: 30px;\">Q: If you picked a book \"You should believe in Zeus\", you'd believe in Zeus now!</p>\n<p style=\"padding-left: 30px;\">A: Yes, but I would be wrong. You see, I accidentally picked the right one. Actually, it's not entirely accidental. You see, if Ahura Mazda exists, he would with some positive probability interfere with the dice and cause me to pick the book on the true religion because he would like me to be his worshiper. (Same with other gods, of course). So, since P(I picked the book on Zoroastrianism|Zoroastrianism is a true religion) &gt; P(I picked the book on Zoroastrianism|Zoroastrianism is a false religion), I can conclude by Bayes' rule that me picking that book up is evidence for Zoroastrianism. Of course, if the prior P(Zoroastrianism is a true religion) is low, it's not a lot of evidence, but it's some.</p>\n<p style=\"padding-left: 30px;\">Q: So you are really saying you won the lottery.</p>\n<p style=\"padding-left: 30px;\">A: Yes. A priori, the probability is low, of course. But I actually have won the lottery: some people do, you know. Now that I have won it, the probability is close to 1 (It's not 1, because I recognize that I could be wrong, as a good Bayesian should. But the evidence is so overwhelming, my model says it's really close to 1).</p>\n<p style=\"padding-left: 30px;\">Q: Why don't you ask your super-intelligent AI directly whether the book's reasoning is sound?</p>\n<p style=\"padding-left: 30px;\">A: According to the book, I am not supposed to do it because Ahura Mazda wouldn't like it.</p>\n<p style=\"padding-left: 30px;\">Q: Of course, the book is written by the superintelligent AI in such a way that there's no trick I can think of that it didn't cover. Your ignorance is now invincible.</p>\n<p style=\"padding-left: 30px;\">A: I still remain a reasonable person and I don't like being denied access to information. However, I am now convinced that while having more information is useful, it is not my highest priority anymore. I know it is possible for me to disbelieve again if given certain (obviously false!) information, but my estimate of the chance that any further true information could change my opinion is very low. In fact, I am far more likely to be deceived by false information about Ahura Mazda, because I am not superintelligent. This is why Ahura Mazda (who is superintelligent, by the way) advises that one should not tempt oneself into sin by reading any criticism of Zoroastrianism.</p>\n<p style=\"padding-left: 30px;\">Q: Just read that atheist book and become normal again!</p>\n<p style=\"padding-left: 30px;\">A: You are possessed by demons! Repent and become the follower of Ahura Mazda!</p>\n<p>&nbsp;</p>\n<p>So, are you now convinced that <span style=\"text-decoration: line-through;\">you should be a Zoroastrian</span> one can really intentionally deceive oneself and be in a mentally consistent (although weird) state?</p>\n<p>To answer one potential objection, an ordinary person may well not need a super-intelligent AI to fool him, just a very convincing book or very clever interlocutor. As to why someone would want to submit to this, I'll discuss this in a separate post.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p><strong>Update:</strong>&nbsp;</p>\n<p>Here are some points that I think are useful to add from various comments.</p>\n<p>&nbsp;</p>\n<ul>\n<li>Require the AI to use tricks as little as possible. In particular, every true proposition it argues should be argued for in an entirely logically valid fashion. This shortcuts the part of the Q&amp;A where I discuss whether the book you picked can possibly be entirely valid.</li>\n<li>From the above point, and assuming that really only one religion of our set can be \"true\", P(Book on X is valid) = P(X is true). If more than one religion can be true at the same time, it's possible that P(Book on X is valid) &gt; P(X is true).</li>\n<li>P(X is true) for any religion X is some value strictly between 0 and 1. It's obvious, but just to ensure we are not ruling out anything a priori. This is my ordinary probability of belief in X.</li>\n<li>P(Book on X will convince me to believe X with probability &gt; 1-epsilon) is some value close to 1-f(epsilon), where f(epsilon) is small, but presumably may increase as epsilon -&gt; 0. In other words, it's harder for the AI to convince me without a shadow of a doubt. Epsilon is picked by AI to keep f(epsilon) reasonably small. I don't know what value was picked, it clearly depends on X: the more ridiculous it is, the larger epsilon is. If the AI is infinitely more intelligent than I am, perhaps it can keep f(epsilon) small even as epsilon -&gt; 0.</li>\n<li>However, whatever P(Book on X will convince me to believe X with probability &gt; 1-epsilon) for X=Zoroastrianism is, it was high enough that the book succeeded in my case.</li>\n<li>I do not think it is valid to make a meta-statement on what the value of the posterior P(X is true|I have read the book on X) can be, without actually reading the book. In particular, the book has at least this probability of being true: P(Book on X is valid) &gt;= P(X is true) &gt; 0, so you cannot claim that the posterior is the same as prior because you believe that the book will convince you of X and it does. Additionally, any meta-argument clearly depends on f(epsilon), which I don't know.</li>\n<li>The book can convince me to adjust my world view in such a way that will rule out the invisible elephant problem, at least where modern science is concerned. I will remember what the science says, of course, but where it conflicts with my religion I will really believe what the religion says, even if it says it's turtles all the way down and will really be afraid of falling of the edge of the Earth if that's what my religion teaches.</li>\n</ul>\n<p>&nbsp;</p>\n<p>Any thoughts on whether I should post this on the main site?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YTCrHWYHAsAD74EHo": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6mtoy9gh32rQzfT4r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 42, "extendedScore": null, "score": 9.6e-05, "legacy": true, "legacyId": "10285", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 83, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rZX4WuufAPbN6wQTv"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-05T21:44:39.592Z", "modifiedAt": null, "url": null, "title": "Imperative Categories?", "slug": "imperative-categories", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.511Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "fmossJdRymLR3KvDx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Gxg4Zy5tJY5n9ByCK/imperative-categories", "pageUrlRelative": "/posts/Gxg4Zy5tJY5n9ByCK/imperative-categories", "linkUrl": "https://www.lesswrong.com/posts/Gxg4Zy5tJY5n9ByCK/imperative-categories", "postedAtFormatted": "Wednesday, October 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Imperative%20Categories%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AImperative%20Categories%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGxg4Zy5tJY5n9ByCK%2Fimperative-categories%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Imperative%20Categories%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGxg4Zy5tJY5n9ByCK%2Fimperative-categories", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGxg4Zy5tJY5n9ByCK%2Fimperative-categories", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1412, "htmlBody": "<p>It is far more important to answer who one is than what one is.</p>\n<p><br />&nbsp;&nbsp;&nbsp;&nbsp;What am I? How one answers this simple question can reveal a lot about a person. However it would still be possible to give an honest answer to this question and not illuminate in any way&nbsp;who&nbsp;one is. The two questions seem to ask the same thing but the way they can be answered displays the incongruity between them. While it would be relatively easy for nearly all people to list off numerous replies to what they are. I think it is far more crucial to answer who one is. I want to explore the reasons for this assertion as I see them.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Before I look into why; knowing&nbsp;who one is&nbsp;holds a key to the well-being of individuals; it will be helpful to look into the pitfalls involved in asking only what one is. When confronted with such a question a person can easily find numerous replies. Invariably they will resemble categories more than identities. Examples taken from my life would be something like; I am a cyclist, a father, an American. While these descriptions say something about me this is a poor foundation for establishing personal identity. If a person forms their sense of identity solely by the categories they identify with problems quickly follow. The dysfunctions surface both internally and externally.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Upon placing oneself into a category, to the exclusion of others the world is transformed. Relationships to others become defined by the group or category we have allied with. In more benign arenas this is mostly harmless. A good example of this is in sport.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Throughout the world groups of people come together under the flag of their chosen team or participants. Much of the time this is fun and harmless, though on occasion even a form of entertainment such as this can turn tribal and violent. Think college sports in the U.S. or Futball (Soccer) in the rest of the world. There are numerous other examples in sport. Frequently fans of a particular team can be found to say something regarding the performance of their team by describing it as, \"We played well.\" or \"Our defense wasn't very good.\" This seems odd when considering that the person speaking likely played no part in the play of the game.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;I chose the previous example because I think it displays very well Humanity's tendency to in-group loyalty and out-group hostility. When the stakes are relatively low, as is the case in sport, this impulse usually carries very little consequence. However, given the propensity for even this particular venture to become hostile, if the risks and rewards are increased, so does uncertainty. With this uncertainty comes greater reason to fear. As the proportion of fear increases the tendency toward tribalism and intolerance for other groups becomes greatly heightened. &nbsp;&nbsp;&nbsp;&nbsp;People in general are fearful of what they do not know or understand. Thus, if one draws&nbsp;all or most&nbsp;of their view of the world from a select group who holds similar perspective the outcome is an inability to experience and therefore understand other ways of being. This is made exponentially worse if the reasons for avoiding exposure are rooted in fear of contamination. This form of intolerance usually begins with some form of indoctrination. In the majority of cases this takes place during childhood and is perpetuated by adults who were taught the same things. Once this cycle of fear and indoctrination begins it can become rather difficult to break free.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;So the first problem with forming one's identity through the categories one identifies with is that it increases the inclination for hostility aimed at groups not of similar practice, belief, colors, flag, geographic region or whatever the case may be. The main cost of this is paid by societies in general. Though there is a price to be paid by the individual as well.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;On an individual level the cost comes in a myriad of forms. One being that one's growth as a complete human being is stunted by this lack of exposure to other viewpoints. Homogeny on a cultural level stems in part from an arrogant assumption of infallibility. This assumption allows one to assume that they (or the group) already possess everything they would need to know. It is not hard to see why this could be a problem. When a person or group of people shut themselves off from all outside influence they are deprived of valuable information and experiences.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Another cost which the individual foots the bill is that he/she may suffer deprivations which are unnecessary. If practices are prohibited by an outside force of opinion then one cannot have fully formed as an individual. Their behavior being limited not by personal choice but by the coercion of others. Not doing something because others restrict its practice prevents one from developing personal opinions about the question at hand. The individual has been deprived of either the pleasure of the practice or the discovery of its unworthiness. Once a deed has been pronounced as unworthy, the individual can discard it or master it as the case may be. Anyone who is deprived of this opportunity is limited in certain ways.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;By far the highest cost one pays for this lopsided and incomplete sense of self comes in the alienation experienced on almost every level. It is seems clear that the thing most desirable by all humans is a connection to others. This is not only stunted by building an identity within categories, on many levels it is made impossible. When one places (or is placed) within an illusory bracket it becomes difficult to see other persons who are not allied to the same ideology or practices as deserving of attention. Closing off in this way is destructive to individual emotional growth. Not to mention the cost in resources and opportunities.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Once these imaginary boundaries are fully established in an individual's mind. The tendency for fear and repulsion toward what is not understood compels the expenditure of vast amounts of energy, time and initiative aimed at &nbsp; guarding against pretend enemies. The cost to the one concerned should seem clear enough. All of this effort is wasted on a pursuit that would not even be necessary were the groupings seen for what they are, insufficient substitutes for selfhood.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Individuality is robbed away when one finds their primary purpose and fulfillment in the status-quo of a particular group. Especially when the group one has chosen is a conglomeration that differs very little from one another. Once identity is fully enmeshed with a particular society, even questioning the ideology therein becomes rather hard on the individual. Humans are extremely prone to biases on almost every front. This becomes even more pronounced when the issue in question is tied to a person's selfhood. This is where cults flourish, trying to leave the very thing that forms one's notion of what they are is nearly impossible without a firm concept of who one is.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;On the surface of it individuality takes effort. It is difficult and uncomfortable to think for oneself, to question authority, to be a rogue. However, far more energy is required to continually fit oneself into a crowd. Thoughts to the contrary must be stifled bringing tremendous cost to creativity. Being free to be what one is naturally allows one to spend valuable energy on pursuits that truly build self-esteem.&nbsp;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;Being a grouchy curmudgeon who is chronically dissident is not the requisite to being fully individualistic. On the contrary one is fully able to love others (all others) with independence at the root of their self-image. Once the crucial selfhood is fully established independent of groupings, one is fully equipped to select the correct alliances which will bring about the life they desire. After establishing&nbsp;who one is, proceeding to attach the cart of associations would be prudent remembering always to put the horse of individuality in front.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;The path to establishing individuality is much less rubble strewn than the one traveled by the collective of divided factions warring over who is right and wrong. The ones who are best left to decide the correct path are those individuals who allow no group to do their thinking for them.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Gxg4Zy5tJY5n9ByCK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": -25, "extendedScore": null, "score": 7.796541253954284e-07, "legacy": true, "legacyId": "9627", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T02:10:03.583Z", "modifiedAt": null, "url": null, "title": "Volunteer needed to change the front page 'Featured Articles' each week", "slug": "volunteer-needed-to-change-the-front-page-featured-articles", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.978Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MFXLxhj9hLc4iPk7t/volunteer-needed-to-change-the-front-page-featured-articles", "pageUrlRelative": "/posts/MFXLxhj9hLc4iPk7t/volunteer-needed-to-change-the-front-page-featured-articles", "linkUrl": "https://www.lesswrong.com/posts/MFXLxhj9hLc4iPk7t/volunteer-needed-to-change-the-front-page-featured-articles", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Volunteer%20needed%20to%20change%20the%20front%20page%20'Featured%20Articles'%20each%20week&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVolunteer%20needed%20to%20change%20the%20front%20page%20'Featured%20Articles'%20each%20week%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFXLxhj9hLc4iPk7t%2Fvolunteer-needed-to-change-the-front-page-featured-articles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Volunteer%20needed%20to%20change%20the%20front%20page%20'Featured%20Articles'%20each%20week%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFXLxhj9hLc4iPk7t%2Fvolunteer-needed-to-change-the-front-page-featured-articles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMFXLxhj9hLc4iPk7t%2Fvolunteer-needed-to-change-the-front-page-featured-articles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<p>Less Wrong needs a volunteer to change the 'Featured Articles' once a week. I have detailed instructions on what to do (which wiki entry to edit, which articles have already been featured, which articles to feature in the future, etc.) I've been doing it so far, but not changing it as often as it should be changed. It takes about 5 minutes each time you do it.</p>\n<p>Who is willing to do this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MFXLxhj9hLc4iPk7t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.79743889302703e-07, "legacy": true, "legacyId": "10313", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T03:19:18.847Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Explainers Shoot High, Aim Low!", "slug": "seq-rerun-explainers-shoot-high-aim-low", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:50.550Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X4SH95xq9MFhsSJQX/seq-rerun-explainers-shoot-high-aim-low", "pageUrlRelative": "/posts/X4SH95xq9MFhsSJQX/seq-rerun-explainers-shoot-high-aim-low", "linkUrl": "https://www.lesswrong.com/posts/X4SH95xq9MFhsSJQX/seq-rerun-explainers-shoot-high-aim-low", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Explainers%20Shoot%20High%2C%20Aim%20Low!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Explainers%20Shoot%20High%2C%20Aim%20Low!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX4SH95xq9MFhsSJQX%2Fseq-rerun-explainers-shoot-high-aim-low%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Explainers%20Shoot%20High%2C%20Aim%20Low!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX4SH95xq9MFhsSJQX%2Fseq-rerun-explainers-shoot-high-aim-low", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX4SH95xq9MFhsSJQX%2Fseq-rerun-explainers-shoot-high-aim-low", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 178, "htmlBody": "<p>Tags: sequence_reruns  Today's post, <a href=\"/lw/kh/explainers_shoot_high_aim_low/\">Explainers Shoot High. Aim Low!</a> was originally published on 24 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Humans greatly underestimate how much sense our explanations make. In order to explain something adequately, pretend that you're trying to explain it to someone much less informed than your target audience.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/7xv/seq_rerun_expecting_short_inferential_distances/#comments\">Expecting Short Inferential Distances</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X4SH95xq9MFhsSJQX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.797673156186076e-07, "legacy": true, "legacyId": "10316", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2TPph4EGZ6trEbtku", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T04:08:13.404Z", "modifiedAt": null, "url": null, "title": "More shameless ploys for job advice", "slug": "more-shameless-ploys-for-job-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:50.718Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "N6W7sAzCo3fGauM7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BMnhBiH5dKrrtQQHM/more-shameless-ploys-for-job-advice", "pageUrlRelative": "/posts/BMnhBiH5dKrrtQQHM/more-shameless-ploys-for-job-advice", "linkUrl": "https://www.lesswrong.com/posts/BMnhBiH5dKrrtQQHM/more-shameless-ploys-for-job-advice", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20More%20shameless%20ploys%20for%20job%20advice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMore%20shameless%20ploys%20for%20job%20advice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBMnhBiH5dKrrtQQHM%2Fmore-shameless-ploys-for-job-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=More%20shameless%20ploys%20for%20job%20advice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBMnhBiH5dKrrtQQHM%2Fmore-shameless-ploys-for-job-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBMnhBiH5dKrrtQQHM%2Fmore-shameless-ploys-for-job-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 423, "htmlBody": "<p>I've posted a <a href=\"/lw/7kr/informal_job_survey/\">few</a> <a href=\"/lw/7fm/how_to_hack_ones_self_to_want_to_want_to_hack/\">things</a> seeking career advice with mixed success. In this case I have a more concrete question and if you feel like commenting, I'd appreciate it. I think it helps me to hear what a community of others thinks from a rational perspective because there are often many components to a decision that I had not anticipated.</p>\n<p><br />I am currently a grad student working in computer vision. I dislike the way that my current adviser focuses only on projects that have short-term commercial gains. I want to study more fundamental, theoretical research which may take more time to develop but will also be more aesthetically pleasing to me. For me, the only reason to agree to be paid so little as a graduate student is to gain the opportunity to work freely on high risk projects that happen to be of personal interest. Practical considerations are not interesting to me as motivation for a Ph.D. On the other hand, it has felt nearly impossible to actually find faculty willing to have students work on theory. Rather than grinding away with no dental insurance for 3 more years, followed by low paying post-docs, etc., perhaps seeking a job will be better.<br /><br />I have some interesting job prospects that are all with larger companies. The jobs are basically business analytics, including scientific computing, data mining, and machine learning. I'm sure the problems to work on are not that great; not going to be Earth shattering, but at the same time they sound a lot more interesting to me than hedge fund data analysis or military research labs (I have working experience at a government lab and I did not enjoy it). The hours would be better; the pay is fair and it would be a good living. I could pursue some things as serious hobbies outside work.<br /><br />At the same time though, there feels like a nagging opportunity cost. I am not naive enough to believe there will be a <a href=\"http://www.economist.com/node/17723223\">nice faculty job</a> waiting for me even if I finish my Ph.D. However, I really enjoy theoretical and mathematical physics, machine learning, computational complexity, and scientific computing, and various philosophical considerations generated by these. Being able to teach about them, research them, and work on them professionally seems incredibly appealing. Am I making a big mistake if I leave? How can one pursue philosophical interests and desires to work in theory outside of a typical job? Or should I even worry about such a thing?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BMnhBiH5dKrrtQQHM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 4, "extendedScore": null, "score": 7.797838606650957e-07, "legacy": true, "legacyId": "10317", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["b6mJp3NhtERJrAhJZ", "4j8yytsPs5WruMbBx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T06:03:29.798Z", "modifiedAt": null, "url": null, "title": ".", "slug": "", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:30.341Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "a7xJQpZ55R6SxFTik", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g48bJL8RisPMhxyL6/", "pageUrlRelative": "/posts/g48bJL8RisPMhxyL6/", "linkUrl": "https://www.lesswrong.com/posts/g48bJL8RisPMhxyL6/", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg48bJL8RisPMhxyL6%2F%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg48bJL8RisPMhxyL6%2F", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg48bJL8RisPMhxyL6%2F", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g48bJL8RisPMhxyL6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 17, "extendedScore": null, "score": 7.798228577924629e-07, "legacy": true, "legacyId": "10318", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T15:14:16.259Z", "modifiedAt": null, "url": null, "title": "Upcoming book: \"Artificial Intelligence and the End of the Human Era\"", "slug": "upcoming-book-artificial-intelligence-and-the-end-of-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:06.693Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jw9Y7jeiwwmTzpTKP/upcoming-book-artificial-intelligence-and-the-end-of-the", "pageUrlRelative": "/posts/jw9Y7jeiwwmTzpTKP/upcoming-book-artificial-intelligence-and-the-end-of-the", "linkUrl": "https://www.lesswrong.com/posts/jw9Y7jeiwwmTzpTKP/upcoming-book-artificial-intelligence-and-the-end-of-the", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Upcoming%20book%3A%20%22Artificial%20Intelligence%20and%20the%20End%20of%20the%20Human%20Era%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUpcoming%20book%3A%20%22Artificial%20Intelligence%20and%20the%20End%20of%20the%20Human%20Era%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjw9Y7jeiwwmTzpTKP%2Fupcoming-book-artificial-intelligence-and-the-end-of-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Upcoming%20book%3A%20%22Artificial%20Intelligence%20and%20the%20End%20of%20the%20Human%20Era%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjw9Y7jeiwwmTzpTKP%2Fupcoming-book-artificial-intelligence-and-the-end-of-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjw9Y7jeiwwmTzpTKP%2Fupcoming-book-artificial-intelligence-and-the-end-of-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 42, "htmlBody": "<p>Announced <a href=\"http://www.publishersweekly.com/pw/by-topic/book-news/deals/article/45022-deals-week-of-11-1-10.html\">here</a>. Full title is <em>Our Final Invention: Artificial Intelligence and the End of the Human Era</em>. The author is James Barrat, best known (for now) for his <a href=\"http://www.nationalgeographic.com/lostgospel/James_Barrat.html\">TV documentaries</a>. I chatted with him online; he'll be at this year's <a href=\"http://www.singularitysummit.com/program\">Singularity Summit</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jw9Y7jeiwwmTzpTKP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 4, "extendedScore": null, "score": 7.800092333004565e-07, "legacy": true, "legacyId": "10321", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T16:19:37.266Z", "modifiedAt": null, "url": null, "title": "What are you working on?", "slug": "what-are-you-working-on-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:59.404Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DFtxh6uDutC8rnn8q/what-are-you-working-on-0", "pageUrlRelative": "/posts/DFtxh6uDutC8rnn8q/what-are-you-working-on-0", "linkUrl": "https://www.lesswrong.com/posts/DFtxh6uDutC8rnn8q/what-are-you-working-on-0", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20you%20working%20on%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20you%20working%20on%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDFtxh6uDutC8rnn8q%2Fwhat-are-you-working-on-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20you%20working%20on%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDFtxh6uDutC8rnn8q%2Fwhat-are-you-working-on-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDFtxh6uDutC8rnn8q%2Fwhat-are-you-working-on-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 113, "htmlBody": "<p>This is the fifth bimonthly What Are You Working On? thread. Previous threads are <a href=\"/r/discussion/tag/waywo\">here</a>. So here's the question:</p>\n<p style=\"padding-left: 60px;\"><em>What are you working on?&nbsp;</em></p>\n<p>Here are some guidelines:</p>\n<ul>\n<li>Focus on projects that you have recently made progress on, not projects that you're thinking about doing but haven't started, those are for a different thread.&nbsp;</li>\n<li>Why this project and not others? Mention reasons why you're doing the project and/or why others should contribute to your project (if applicable).</li>\n<li>Talk about your goals for the project.</li>\n<li>Any kind of project is fair game: personal improvement, research project, art project, whatever.</li>\n<li>Link to your work if it's linkable.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DFtxh6uDutC8rnn8q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 16, "extendedScore": null, "score": 7.800313522283558e-07, "legacy": true, "legacyId": "10322", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 97, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-06T23:52:45.445Z", "modifiedAt": null, "url": null, "title": "[Link] Neural Correlates of Confusion?", "slug": "link-neural-correlates-of-confusion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:50.284Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/D5Mxi4c86rxy6zqnB/link-neural-correlates-of-confusion", "pageUrlRelative": "/posts/D5Mxi4c86rxy6zqnB/link-neural-correlates-of-confusion", "linkUrl": "https://www.lesswrong.com/posts/D5Mxi4c86rxy6zqnB/link-neural-correlates-of-confusion", "postedAtFormatted": "Thursday, October 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Neural%20Correlates%20of%20Confusion%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Neural%20Correlates%20of%20Confusion%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD5Mxi4c86rxy6zqnB%2Flink-neural-correlates-of-confusion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Neural%20Correlates%20of%20Confusion%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD5Mxi4c86rxy6zqnB%2Flink-neural-correlates-of-confusion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD5Mxi4c86rxy6zqnB%2Flink-neural-correlates-of-confusion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 182, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/P3b\">http://en.wikipedia.org/wiki/P3b</a></p>\n<p>I found this article while researching something else and I was intrigued. Is this a neural correlate of confusion?</p>\n<blockquote>\n<p><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19px; \">The P3b has been a prominent tool used to study cognitive processes for several decades. More specifically, this ERP component has played a key role in cognitive psychology research on information processing. Generally speaking, improbable events will elicit a P3b, and the less probable the event, the larger the P3b.<sup id=\"cite_ref-2\" class=\"reference\" style=\"line-height: 1em; font-style: normal; \"><a style=\"text-decoration: none; color: #0645ad; background-image: none; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap; background-position: initial initial; background-repeat: initial initial; \" href=\"http://en.wikipedia.org/wiki/P3b#cite_note-2\">[3]</a></sup>&nbsp;However, in order to elicit a P3b, the improbable event must be related to the task at hand in some way (for example, the improbable event could be an infrequent target letter in a stream of letters, to which a subject might respond with a button press). The P3b can also be used to measure how demanding a task is on&nbsp;<a style=\"text-decoration: none; color: #0645ad; background-image: none; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; background-position: initial initial; background-repeat: initial initial; \" title=\"Cognitive load\" href=\"http://en.wikipedia.org/wiki/Cognitive_load\">cognitive workload</a>.<sup id=\"cite_ref-3\" class=\"reference\" style=\"line-height: 1em; font-style: normal; \"><a style=\"text-decoration: none; color: #0645ad; background-image: none; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; white-space: nowrap; background-position: initial initial; background-repeat: initial initial; \" href=\"http://en.wikipedia.org/wiki/P3b#cite_note-3\">[4]</a></sup></span></p>\n</blockquote>\n<p>If so, awesome. Hats which actually do sound an alarm when your models are proven wrong could be arranged. I suspect that there might be things that make it not useful for that (like, if it also correlates with a bunch of other things). Seems like it's at least worth mentioning.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "D5Mxi4c86rxy6zqnB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 13, "extendedScore": null, "score": 2.2e-05, "legacy": true, "legacyId": "10324", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T01:18:39.951Z", "modifiedAt": null, "url": null, "title": "Multiplying 10-digit numbers using Flickr: The power of recognition memory", "slug": "multiplying-10-digit-numbers-using-flickr-the-power-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:50.415Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "printing-spoon", "createdAt": "2011-04-24T03:45:06.676Z", "isAdmin": false, "displayName": "printing-spoon"}, "userId": "t6u4nWWin4ght4EFu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Py8nq2Z4MFFHhkKgh/multiplying-10-digit-numbers-using-flickr-the-power-of", "pageUrlRelative": "/posts/Py8nq2Z4MFFHhkKgh/multiplying-10-digit-numbers-using-flickr-the-power-of", "linkUrl": "https://www.lesswrong.com/posts/Py8nq2Z4MFFHhkKgh/multiplying-10-digit-numbers-using-flickr-the-power-of", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Multiplying%2010-digit%20numbers%20using%20Flickr%3A%20The%20power%20of%20recognition%20memory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMultiplying%2010-digit%20numbers%20using%20Flickr%3A%20The%20power%20of%20recognition%20memory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPy8nq2Z4MFFHhkKgh%2Fmultiplying-10-digit-numbers-using-flickr-the-power-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Multiplying%2010-digit%20numbers%20using%20Flickr%3A%20The%20power%20of%20recognition%20memory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPy8nq2Z4MFFHhkKgh%2Fmultiplying-10-digit-numbers-using-flickr-the-power-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPy8nq2Z4MFFHhkKgh%2Fmultiplying-10-digit-numbers-using-flickr-the-power-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 10, "htmlBody": "<p>&nbsp;</p>\n<p><a title=\"http://people.csail.mit.edu/andyd/rec_method.pdf\" href=\"http://people.csail.mit.edu/andyd/rec_method.pdf\" target=\"_self\">http://people.csail.mit.edu/andyd/rec_method.pdf</a></p>\n<p>Not sure what this falls under, but it's cool.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Py8nq2Z4MFFHhkKgh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 7.802138440837188e-07, "legacy": true, "legacyId": "10325", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T04:25:47.411Z", "modifiedAt": null, "url": null, "title": "Should I play World of Warcraft?", "slug": "should-i-play-world-of-warcraft", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:52.832Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BeEq49qkKCwd2nC4a/should-i-play-world-of-warcraft", "pageUrlRelative": "/posts/BeEq49qkKCwd2nC4a/should-i-play-world-of-warcraft", "linkUrl": "https://www.lesswrong.com/posts/BeEq49qkKCwd2nC4a/should-i-play-world-of-warcraft", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Should%20I%20play%20World%20of%20Warcraft%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShould%20I%20play%20World%20of%20Warcraft%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBeEq49qkKCwd2nC4a%2Fshould-i-play-world-of-warcraft%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Should%20I%20play%20World%20of%20Warcraft%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBeEq49qkKCwd2nC4a%2Fshould-i-play-world-of-warcraft", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBeEq49qkKCwd2nC4a%2Fshould-i-play-world-of-warcraft", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 580, "htmlBody": "<p>I've avoided playing World of Warcraft because many people enjoy it so much that they neglect other things in their life.</p>\n<p>Does that make sense?</p>\n<p>How about cocaine?</p>\n<p>How about sex?&nbsp; I hear that's pretty good too.</p>\n<p>ADDED:&nbsp; Lots of interesting discussion, but no one is getting at some points of particular interest to me.&nbsp; Most answers assume that you have important stuff to do, and you need to decide whether WoW will prevent you from getting that important stuff done.&nbsp; They also assume that your brain usually errs on the side of telling you to do \"non-important\" stuff (WoW) at the expense of \"important stuff\".</p>\n<p>One question is whether there is any evidence that your brain is biased in this way.&nbsp; I think your reflective self greatly overestimates the probability of success at the \"important stuff\".&nbsp; I have worked very hard, twelve hours a day, 7 days a week, on \"important stuff\" for most of the past 30 years.&nbsp; The important stuff never pans out.&nbsp; So it appears that when my brain told me to play Freecell rather than work on that important paper on artificial intelligence that got pulled from the book the day before publication due to petty office politics, or to watch Buffy rather than do another test run of the demo I spent three months preparing for DARPA that no one from DARPA ever watched because the program officer was too busy to supervise his program, or to go hiking instead of spending another weekend working on the project for NASA that was eventually so big and successful that my boss took it over and then tried to get me fired<sup>1</sup>, or to go dancing rather than work on the natural-language processing approach that got shelved because my boss felt it emphasized the skills of mathematicians more than his own, or to LARP rather than put in another weekend on my approach using principal component analysis for early cancer detection that it turned out some guy from the FDA had already published 6 months earlier, or the technique for choosing siRNA sequences that a professor from George Mason already had a paper in press on - all those times, my brain was using a better estimate of success than my reflective self was.</p>\n<p>Another question is why the \"important stuff\" is important.&nbsp; Fun is fun.&nbsp; On the surface, we are saying something like, \"I have a part of my utility function that values contributions to the world, because I evolved to be altruistic.\"&nbsp; If we really believe that, then for any contribution to the world, there exists some quantity of fun that would outweigh it.&nbsp; And people use language like, \"WoW may be fun, but it has little lasting effect.\"&nbsp; But when you contribute something to the world, <em>if the relevant motivating factor to us is how our utility function evaluates that contribution</em>, then that also has little lasting effect.&nbsp; If you do something great for the world, it may have a lasting effect on the world; but the time <em>you</em> spend feeling good about it is not as great - probably less time, and a less intense emotion, than if you had spent all the time accomplishing it playing WoW instead.&nbsp; So this question is about whether we really believe the stories we tell ourselves about our utility functions.</p>\n<p>1. He got to award himself all of the department's yearly bonus money that wasn't awarded to his subordinates, so any obvious success by his subordinates was money out of his pocket.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BeEq49qkKCwd2nC4a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 14, "extendedScore": null, "score": 7.802772120204984e-07, "legacy": true, "legacyId": "10331", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 107, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T05:24:26.097Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Double Illusion of Transparency", "slug": "seq-rerun-double-illusion-of-transparency", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:50.720Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cfkqXkZKvSshBWoX2/seq-rerun-double-illusion-of-transparency", "pageUrlRelative": "/posts/cfkqXkZKvSshBWoX2/seq-rerun-double-illusion-of-transparency", "linkUrl": "https://www.lesswrong.com/posts/cfkqXkZKvSshBWoX2/seq-rerun-double-illusion-of-transparency", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Double%20Illusion%20of%20Transparency&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Double%20Illusion%20of%20Transparency%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcfkqXkZKvSshBWoX2%2Fseq-rerun-double-illusion-of-transparency%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Double%20Illusion%20of%20Transparency%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcfkqXkZKvSshBWoX2%2Fseq-rerun-double-illusion-of-transparency", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcfkqXkZKvSshBWoX2%2Fseq-rerun-double-illusion-of-transparency", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>Today's post, <a href=\"/lw/ki/double_illusion_of_transparency/\">Double Illusion of Transparency</a> was originally published on 24 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Double_Illusion_of_Transparency\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>In addition to the difficulties encountered in trying to explain something so that your audience understands it, there are other problems associated in learning whether or not you have explained something properly. If you read your intended meaning into whatever your listener says in response, you may think that they understand a concept, when in fact they are simply rephrasing whatever it was you actually said.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/7yk/seq_rerun_explainers_shoot_high_aim_low/\">Explainers Shoot High, Aim Low!</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cfkqXkZKvSshBWoX2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 7.802970733822156e-07, "legacy": true, "legacyId": "10332", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sBBGxdvhKcppQWZZE", "X4SH95xq9MFhsSJQX", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T07:08:54.108Z", "modifiedAt": null, "url": null, "title": "Marsh et al. \"Serotonin Transporter Genotype (5-HTTLPR) Predicts Utilitarian Moral Judgments\"", "slug": "marsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.259Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jack", "createdAt": "2009-02-27T15:27:14.891Z", "isAdmin": false, "displayName": "Jack"}, "userId": "GwetakMQqsGCf7ZQv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WihBTuaqNWiZxKYry/marsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts", "pageUrlRelative": "/posts/WihBTuaqNWiZxKYry/marsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts", "linkUrl": "https://www.lesswrong.com/posts/WihBTuaqNWiZxKYry/marsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Marsh%20et%20al.%20%22Serotonin%20Transporter%20Genotype%20(5-HTTLPR)%20Predicts%20Utilitarian%20Moral%20Judgments%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMarsh%20et%20al.%20%22Serotonin%20Transporter%20Genotype%20(5-HTTLPR)%20Predicts%20Utilitarian%20Moral%20Judgments%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWihBTuaqNWiZxKYry%2Fmarsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Marsh%20et%20al.%20%22Serotonin%20Transporter%20Genotype%20(5-HTTLPR)%20Predicts%20Utilitarian%20Moral%20Judgments%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWihBTuaqNWiZxKYry%2Fmarsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWihBTuaqNWiZxKYry%2Fmarsh-et-al-serotonin-transporter-genotype-5-httlpr-predicts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 386, "htmlBody": "<p>The whole paper is <a href=\"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0025148#s2\">here.</a>&nbsp; In short, they found a genotype that predicts people's response to the original <a href=\"http://en.wikipedia.org/wiki/Trolley_problem\">trolley problem</a>:</p>\n<blockquote>\n<p>A trolley (i.e. in British English a tram) is running out of control down a track. In its path are five people who have been tied to the track by a mad philosopher. Fortunately, you could flip a switch, which will lead the trolley down a different track to safety. Unfortunately, there is a single person tied to that track. Should you flip the switch or do nothing?</p>\n</blockquote>\n<p>Participants with one kind of serotonin transmitter (LL-homozygotes) judged flipping the switch to be better than a morally neutral action. Participants with the other kind (S-carriers) judged flipping the switch to be no better than a morally neutral action. The groups responded equally to the \"fat man scenario\" both rejecting the 'push' option.</p>\n<p><br />Some quotes:</p>\n<blockquote>\n<p>We hypothesized that <em>5-HTTLPR</em> genotype would interact with intentionality in respondents who generated moral judgments. Whereas we predicted that all participants would eschew intentionally harming an innocent for utilitarian gains, we predicted that participants' judgments of foreseen but unintentional harm would diverge as a function of genotype. Specifically, we predicted that LL homozygotes would adhere to the principle of double effect and preferentially select the utilitarian option to save more lives despite unintentional harm to an innocent victim, whereas S-allele carriers would be less likely to endorse even unintentional harm. Results of behavioral testing confirmed this hypothesis.</p>\n</blockquote>\n<blockquote>\n<p>Participants in this study judged the acceptability of actions that would unintentionally or intentionally harm an innocent victim in order to save others' lives. An analysis of variance revealed a genotype &times; scenario interaction, <em>F</em>(2, 63) = 4.52, <em>p</em> = .02. Results showed that, relative to long allele homozygotes (LL), carriers of the short (S) allele showed particular reluctance to endorse utilitarian actions resulting in foreseen harm to an innocent individual. LL genotype participants rated perpetrating unintentional harm as more acceptable (<em>M</em> = 4.98, <em>SEM</em> = 0.20) than did SL genotype participants (<em>M</em> = 4.65, <em>SEM</em> = 0.20) or SS genotype participants (<em>M</em> = 4.29, <em>SEM</em> = 0.30).</p>\n</blockquote>\n<p>...</p>\n<blockquote>\n<p>The results indicate that inherited variants in a genetic polymorphism that influences serotonin neurotransmission influence utilitarian moral judgments as well. This finding is interpreted in light of evidence that the S allele is associated with elevated emotional responsiveness.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WihBTuaqNWiZxKYry", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 7.80332455696565e-07, "legacy": true, "legacyId": "10335", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T12:34:24.574Z", "modifiedAt": null, "url": null, "title": "Meetup : Dublin, IE, Meetup", "slug": "meetup-dublin-ie-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.030Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Barry_Cotter", "createdAt": "2010-04-19T16:29:03.629Z", "isAdmin": false, "displayName": "Barry_Cotter"}, "userId": "5pZXxaf79kj37Rwq2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/p5DRH7bsCu3wNZpBr/meetup-dublin-ie-meetup", "pageUrlRelative": "/posts/p5DRH7bsCu3wNZpBr/meetup-dublin-ie-meetup", "linkUrl": "https://www.lesswrong.com/posts/p5DRH7bsCu3wNZpBr/meetup-dublin-ie-meetup", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Dublin%2C%20IE%2C%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Dublin%2C%20IE%2C%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5DRH7bsCu3wNZpBr%2Fmeetup-dublin-ie-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Dublin%2C%20IE%2C%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5DRH7bsCu3wNZpBr%2Fmeetup-dublin-ie-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fp5DRH7bsCu3wNZpBr%2Fmeetup-dublin-ie-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/3z'>Dublin, IE, Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 October 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">College Green, Dublin 2, Ireland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at Starbucks on College Green <a href=\"http://maps.google.ie/maps?q=college+green,+dublin,+ireland&amp;hl=en&amp;ll=53.344387,-6.261239&amp;spn=0.000386,0.001703&amp;sll=-34.016242,18.457031&amp;sspn=38.483874,55.810547&amp;vpsrc=6&amp;hq=college+green,&amp;hnear=Dublin,+County+Fingal&amp;t=m&amp;fll=53.344355,-6.260603&amp;fspn=0.000849,0.001703&amp;z=19&amp;layer=c&amp;cbll=53.344387,-6.26124&amp;panoid=ifSJ_a-g3mmrqWM4fU89Ig&amp;cbp=11,358.98,,0,2.56\" rel=\"nofollow\">here</a></p>\n\n<p>I'll be there even if noone replies, for an hour. My phone number is 086 3561738</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/3z'>Dublin, IE, Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "p5DRH7bsCu3wNZpBr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.804427215006253e-07, "legacy": true, "legacyId": "10338", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Dublin__IE__Meetup\">Discussion article for the meetup : <a href=\"/meetups/3z\">Dublin, IE, Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 October 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">College Green, Dublin 2, Ireland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet at Starbucks on College Green <a href=\"http://maps.google.ie/maps?q=college+green,+dublin,+ireland&amp;hl=en&amp;ll=53.344387,-6.261239&amp;spn=0.000386,0.001703&amp;sll=-34.016242,18.457031&amp;sspn=38.483874,55.810547&amp;vpsrc=6&amp;hq=college+green,&amp;hnear=Dublin,+County+Fingal&amp;t=m&amp;fll=53.344355,-6.260603&amp;fspn=0.000849,0.001703&amp;z=19&amp;layer=c&amp;cbll=53.344387,-6.26124&amp;panoid=ifSJ_a-g3mmrqWM4fU89Ig&amp;cbp=11,358.98,,0,2.56\" rel=\"nofollow\">here</a></p>\n\n<p>I'll be there even if noone replies, for an hour. My phone number is 086 3561738</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Dublin__IE__Meetup1\">Discussion article for the meetup : <a href=\"/meetups/3z\">Dublin, IE, Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Dublin, IE, Meetup", "anchor": "Discussion_article_for_the_meetup___Dublin__IE__Meetup", "level": 1}, {"title": "Discussion article for the meetup : Dublin, IE, Meetup", "anchor": "Discussion_article_for_the_meetup___Dublin__IE__Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T21:30:11.175Z", "modifiedAt": null, "url": null, "title": "Keylogger virus strikes American UAV control center", "slug": "keylogger-virus-strikes-american-uav-control-center", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hMhZaXftvtWSkvomX/keylogger-virus-strikes-american-uav-control-center", "pageUrlRelative": "/posts/hMhZaXftvtWSkvomX/keylogger-virus-strikes-american-uav-control-center", "linkUrl": "https://www.lesswrong.com/posts/hMhZaXftvtWSkvomX/keylogger-virus-strikes-american-uav-control-center", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Keylogger%20virus%20strikes%20American%20UAV%20control%20center&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKeylogger%20virus%20strikes%20American%20UAV%20control%20center%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhMhZaXftvtWSkvomX%2Fkeylogger-virus-strikes-american-uav-control-center%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Keylogger%20virus%20strikes%20American%20UAV%20control%20center%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhMhZaXftvtWSkvomX%2Fkeylogger-virus-strikes-american-uav-control-center", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhMhZaXftvtWSkvomX%2Fkeylogger-virus-strikes-american-uav-control-center", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<p>At <a href=\"http://www.wired.com/dangerroom/2011/10/virus-hits-drone-fleet/\">Wired</a>:</p>\n<p><span style=\"color: #333333; font-family: Arial, Verdana, sans-serif; font-size: 14px; line-height: 20px;\">\n<blockquote>\n<p style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 20px; margin-left: 0px; padding: 0px;\">&ldquo;We keep wiping it off, and it keeps coming back,&rdquo; says a source familiar with the network infection, one of three that told Danger Room about the virus. &ldquo;We think it&rsquo;s benign. But we just don&rsquo;t know.&rdquo;</p>\n<p style=\"margin-top: 20px; margin-right: 0px; margin-bottom: 20px; margin-left: 0px; padding: 0px;\">Military network security specialists aren&rsquo;t sure whether the virus and its so-called &ldquo;keylogger&rdquo; payload were introduced intentionally or by accident; it may be a common piece of malware that just happened to make its way into these sensitive networks. The specialists don&rsquo;t know exactly how far the virus has spread. But they&rsquo;re sure that the infection has hit both classified and unclassified machines at Creech. That raises the possibility, at least, that secret data may have been captured by the keylogger, and then transmitted over the public internet to someone outside the military chain of command.</p>\n</blockquote>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hMhZaXftvtWSkvomX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "10340", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-07T23:12:04.837Z", "modifiedAt": null, "url": null, "title": "Neural Correlates of Conscious Access", "slug": "neural-correlates-of-conscious-access", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.132Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9BRuYmSbyCfNyB6JR/neural-correlates-of-conscious-access", "pageUrlRelative": "/posts/9BRuYmSbyCfNyB6JR/neural-correlates-of-conscious-access", "linkUrl": "https://www.lesswrong.com/posts/9BRuYmSbyCfNyB6JR/neural-correlates-of-conscious-access", "postedAtFormatted": "Friday, October 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Neural%20Correlates%20of%20Conscious%20Access&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANeural%20Correlates%20of%20Conscious%20Access%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9BRuYmSbyCfNyB6JR%2Fneural-correlates-of-conscious-access%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Neural%20Correlates%20of%20Conscious%20Access%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9BRuYmSbyCfNyB6JR%2Fneural-correlates-of-conscious-access", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9BRuYmSbyCfNyB6JR%2Fneural-correlates-of-conscious-access", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1331, "htmlBody": "<p><strong>Summary:</strong>&nbsp;Neuroimaging scans and EEG readings comparing nonconscious and conscious stimuli are compared, showing particular patterns in conscious processes. These findings are in line with predictions made by the Global Workspace Theory of consciousness, in which consciousness is closely related to interaction between specialized modules of the brain.</p>\n<p>When a bunch of photons hit your eye, it unleashes a long chain of cause and effect that leads to an image being mapped in your brain. When does that image become conscious?</p>\n<div style=\"background-color: transparent;\"><strong>Conscious and Unconscious Perception</strong><sup>1</sup></div>\n<div style=\"background-color: transparent;\">The most basic method of discriminating between conscious and unconscious information is to ask the subject if they noticed it. However, people can respond to information that they don't report. What does it mean to notice something then?</div>\n<p style=\"background-color: transparent;\">Merikle et al performed experiments in the 80s which helped to resolve this question. In the Stroop task, people are asked to read words written in a different color than the word. Words written in their color (<span style=\"color:green;\">green</span>) are easier to read than those not in their color (also&nbsp;<span style=\"color:green;\">red</span>). Merikle modified the stroop task, using only two colors (red and green), and using the word to prime subjects to describe the color. As was expected, when \"green\" comes before a green square, subjects respond faster than with no priming.</p>\n<p style=\"background-color: transparent;\">However, when the situation is regularly reversed and the \"red\" prime normally comes before a green square (and vice versa) people also respond faster to similar levels. That is to say, subjects are able to notice that the prime and stimulus are incongruent, and act on that information to respond faster to the stimuli.</p>\n<p style=\"background-color: transparent;\">When the reversed prime (\"red\" before green) is flashed for such a short time span that people don't report seeing it, they are unable to use this information to react faster to the green stimulus, and the typical Stroop effect is observed -- being subliminally primed with a congruent color speeds up recognition, being subliminally primed with an incongruent color slows it.</p>\n<div style=\"background-color: transparent;\">There are methods of interfering with subject's reports (muteness trivially,&nbsp;<a href=\"http://en.wikipedia.org/wiki/Anosognosia\">anosognosia</a>&nbsp;creepily), but for most humans it very closely corresponds to what is normally considered conscious perception.</div>\n<div style=\"background-color: transparent;\">People's brains respond to information even if the person is unaware of it, but there are measurable differences in perception without awareness and perception with it.</div>\n<div style=\"background-color: transparent;\"><strong>Methods of Manipulating Perception</strong><sup>2</sup></div>\n<div style=\"background-color: transparent;\">Nonconscious stimulation is split up into two categories: &nbsp;<em>subliminal</em>&nbsp; and &nbsp;<em>preconscious</em>. A subliminal stimulus is one in which the bottom up process information is so reduced that people cannot detect it, even if they're paying attention to it. A preconscious stimulus is one that is potentially noticeable (i.e. it's presented in a way that subjects can normally report seeing it), but not reported because of other distractions.</div>\n<div style=\"background-color: transparent;\"><img style=\" float:right; padding: 10 px;\" src=\"http://images.lesswrong.com/t3_7yr_0.png?v=bc484d64ecc4018cbbe8f220918ee92a\" alt=\"Dichoptic Masking, image from Zeki 2003\" width=\"403\" height=\"223\" /></div>\n<div style=\"background-color: transparent;\">To present a stimulus subliminally you can: \n<ul>\n<li>Mask a stimulus, by presenting it close in time to other unrelated or interfering stimuli. (i.e. a word flashed for 33 ms is noticeable by itself, but not when proceeded and followed by geometric shapes)<sup>2,3</sup></li>\n<li>Use dichoptic masking, where you present two different images to each eye, and the subject reports seeing something which is neither of those<sup>4</sup></li>\n<li>Use flash suppression, where you show one eye an image and flash shapes in the other eye to interfere with image perception<sup>5</sup></li>\n</ul>\n</div>\n<div style=\"background-color: transparent;\">To present something preconsciously you can:</div>\n<div style=\"background-color: transparent;\">\n<ul>\n<li>Use inattentional blindness, where you present something that participants aren't focusing on.</li>\n<li>Distract them! Present another stimulus and then quickly follow it with the one that you're interested in presenting preconsciously during their attentional blink.<sup>6</sup></li>\n</ul>\n</div>\n<div style=\"background-color: transparent;\"><strong>Neurological Differences</strong></div>\n<div style=\"background-color: transparent;\"><strong></strong>So what's the biggest difference between when people do and don't report seeing something?</div>\n<div style=\"background-color: transparent;\">Across various different methods of nonconscious stimulation, a few patterns emerged. When your eyes are stimulated, areas in your visual cortex (in the back of your head) undergo activity to process it regardless of whether or not you report seeing it. When people do report something, much more of the brain \"lights up\".</div>\n<div style=\"background-color: transparent;\"><img src=\"http://images.lesswrong.com/t3_7yr_1.png?v=e4b768229e87af3df59fbdbdcdaf1310\" alt=\"from Dehaune et al 2011\" width=\"571\" height=\"435\" /><br /></div>\n<div style=\"background-color: transparent;\">This lighting up also corresponds with recurrent processing, and ERP components in the P3b range. Recurrent processing is simply when a signal whips back and forth between specialized subregions, such as when signals from the visual cortex goes to the frontoparietal region then back to the visual cortex.<sup>1,7</sup><br /><br />The idea that conscious access is related to recurrent processing in the frontoparietal region stands up to experimental verification. Researchers are able to interfere with conscious reports of information independently of stimulus identification simply by applying transcranial magnetic stimulation to the prefrontal cortex, without changing the stimulus.<sup>8</sup></div>\n<div style=\"background-color: transparent;\">So basically, consciousness seems to be related to widespread neural activity in cortical areas, as well as recurrent signalling and some particular components of EEG readings. So what?</div>\n<div style=\"background-color: transparent;\"><strong>The Global Workspace Theory</strong><sup>1,9,10</sup></div>\n<div style=\"background-color: transparent;\">The Global Workspace Theory of Consciousness asserts that consciousness is related to information from the various specialized subregions of the brain becoming &ldquo;globally available&rdquo; for attention, motor control, and cognitive reference. This explains phenomena like&nbsp;<a href=\"/lw/7pm/blindsight_and_consciousness/\">blindsight</a>&nbsp;fairly elegantly, saying that visual information in the scotoma ceases to be conscious information because it ceases to be globally available to the system. Douhane adds that neurons with long axons in the frontoparietal cortex are probably the Global Workspace.<sup>1</sup></div>\n<div style=\"background-color: transparent;\">Baars and Dennett are fond of the theater metaphor of consciousness. There&rsquo;s a spotlight of attention on the stage, and actors (specialized cortical systems) come into and out of this to play their parts.&nbsp;This group of interacting subagents is actually somewhat close to orthonormal's&nbsp;<a href=\"/lw/5op/qualia_strike_back/\">model for dissolving qualia</a>. Behind the scenes, directors and stagehands (decision processes, attention direction, contextual systems) arrange the scenes.&nbsp;Everywhere we shine the spotlight we see consciousness, because consciousness is attached to the light.</div>\n<div style=\"background-color: transparent;\">No part of the system is conscious, but there&rsquo;s a show going on. And that&rsquo;s what we see.</div>\n<div style=\"background-color: transparent;\"><strong>Next Obvious Question:</strong></div>\n<div style=\"background-color: transparent;\">Okay, so why does that&nbsp;<a href=\"/lw/p9/the_generalized_antizombie_principle/\">make us talk about consciousness</a>? Why would we use the first person?</div>\n<div style=\"background-color: transparent;\"><em>To be continued...</em></div>\n<div>\n<div style=\"background-color: transparent;\">\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><strong>Notes</strong></p>\n<p>A&nbsp;<em>huge</em>&nbsp;thanks to John Salvatier for getting me a bunch of the papers and editing feedback and putting up with my previous attempts to write an article like this. Also thanks to mtaran, falenas108, and RS (you don't know him) for reading drafts of this article.</p>\n<p>Images are from Zeki 2003 and Dehaene 2011, respectively. I'd be very happy if someone helped me format that to show up with the pictures.</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>1</sup>Merikle &amp; Joordens, 1997</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>2</sup>Dehaene, S., &amp; Changeux, J.-P. 2011</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>3</sup>Breitmeyer &amp; Ogmen, 2007</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>4</sup>Moutoussis &amp; Zeki 2002, Image from Zeki 2003</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>5</sup>Tsuchiya &amp; Koch</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>6</sup>Marti et al 2010</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>7</sup>Lamme 2006</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>8</sup>Rounis et al 2010</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>9</sup>Baars 1997</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>10</sup>Metzinger</p>\n</div>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><strong>References</strong></p>\n</div>\n<div><span>\n<div style=\"background-color: transparent;\">\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Baars, B. (1997). In the Theatre of Consciousness: The Workplace of the Mind. New York: Oxford University Press. Retrieved from <a href=\"http://scholar.google.com/scholar?hl=en&amp;btnG=Search&amp;q=intitle:In+The+Theatre+of+Consciousness#3M\">here</a></p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">\ufeffBruno G. Breitmeyer and Haluk Ogmen (2007) <a href=\"http://www.scholarpedia.org/article/Visual_masking\">Visual masking</a>. <a href=\"http://www.scholarpedia.org\">Scholarpedia</a>, 2(7):3330</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">\ufeffDehaene, S., &amp; Changeux, J.-P. (2011). Experimental and theoretical approaches to conscious processing. <em>Neuron</em>, <em>70</em>(2), 200-27. Elsevier Inc. doi:10.1016/j.neuron.2011.03.018</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Kouider, S., &amp; Dehaene, S. (2007). Levels of processing during non-conscious perception: a critical review of visual masking. <em>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</em>, <em>362</em>(1481), 857-75. doi:10.1098/rstb.2007.2093</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Lamme, V. A. F. (2006). Towards a true neural stance on consciousness. <em>Trends in Cognitive Sciences</em>, <em>10</em>(11). doi:10.1016/j.tics.2006.09.001</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Merikle, P. M., &amp; Joordens, S. (1997). Parallels between perception without attention and perception without awareness.<em>Consciousness and cognition</em>,&nbsp;<em>6</em>(2-3), 219-36. doi:10.1006/ccog.1997.0310</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Lamme, V. A. F. (2006). Towards a true neural stance on consciousness. <em>Trends in Cognitive Sciences</em>, <em>10</em>(11). doi:10.1016/j.tics.2006.09.001</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Lau, H., &amp; Rosenthal, D. (2011). Empirical support for higher-order theories of conscious awareness.&nbsp;<em>Trends in cognitive sciences</em>,&nbsp;<em>15</em>(8), 365-373. doi:10.1016/j.tics.2011.05.009</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Marti, S., Sackur, J., Sigman, M., &amp; Dehaene, S. (2010). Mapping introspection&rsquo;s blind spot: reconstruction of dual-task phenomenology using quantified introspection. <em>Cognition</em>, <em>115</em>(2), 303-13. Elsevier B.V. doi:10.1016/j.cognition.2010.01.003</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Metzinger, T. (2003). Being No One. <em>Philosophy</em>, 699. MIT Press.</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Moutoussis, K., &amp; Zeki, S. (2002). The relationship between cortical activation and perception investigated with invisible stimuli. <em>Proceedings of the National Academy of Sciences</em>, <em>99</em>(14), 9527. National Acad Sciences. doi:10.1073/pnas.PNAS</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Rounis, E., Maniscalco, B., Rothwell, J., Passingham, R., &amp; Lau, H. (2010). Theta-burst transcranial magnetic stimulation to the prefrontal cortex impairs metacognitive visual awareness. <em>Cognitive Neuroscience</em>, <em>1</em>(3), 165-175. doi:10.1080/17588921003632529</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Tsuchiya, N., &amp; Koch, C. (2005). Continuous flash suppression reduces negative afterimages. <em>Nature neuroscience</em>, <em>8</em>(8), 1096-101. doi:10.1038/nn1500</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">\ufeffZeki, S. (2003). The disunity of consciousness. <em>Trends in Cognitive Sciences</em>, <em>7</em>(5), 214-218. doi:10.1016/S1364-6613(03)00081-0</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n</span></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Wi3EopKJ2aNdtxSWg": 1, "XSryTypw5Hszpa4TS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9BRuYmSbyCfNyB6JR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 39, "extendedScore": null, "score": 8e-05, "legacy": true, "legacyId": "10323", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>Summary:</strong>&nbsp;Neuroimaging scans and EEG readings comparing nonconscious and conscious stimuli are compared, showing particular patterns in conscious processes. These findings are in line with predictions made by the Global Workspace Theory of consciousness, in which consciousness is closely related to interaction between specialized modules of the brain.</p>\n<p>When a bunch of photons hit your eye, it unleashes a long chain of cause and effect that leads to an image being mapped in your brain. When does that image become conscious?</p>\n<div style=\"background-color: transparent;\"><strong>Conscious and Unconscious Perception</strong><sup>1</sup></div>\n<div style=\"background-color: transparent;\">The most basic method of discriminating between conscious and unconscious information is to ask the subject if they noticed it. However, people can respond to information that they don't report. What does it mean to notice something then?</div>\n<p style=\"background-color: transparent;\">Merikle et al performed experiments in the 80s which helped to resolve this question. In the Stroop task, people are asked to read words written in a different color than the word. Words written in their color (<span style=\"color:green;\">green</span>) are easier to read than those not in their color (also&nbsp;<span style=\"color:green;\">red</span>). Merikle modified the stroop task, using only two colors (red and green), and using the word to prime subjects to describe the color. As was expected, when \"green\" comes before a green square, subjects respond faster than with no priming.</p>\n<p style=\"background-color: transparent;\">However, when the situation is regularly reversed and the \"red\" prime normally comes before a green square (and vice versa) people also respond faster to similar levels. That is to say, subjects are able to notice that the prime and stimulus are incongruent, and act on that information to respond faster to the stimuli.</p>\n<p style=\"background-color: transparent;\">When the reversed prime (\"red\" before green) is flashed for such a short time span that people don't report seeing it, they are unable to use this information to react faster to the green stimulus, and the typical Stroop effect is observed -- being subliminally primed with a congruent color speeds up recognition, being subliminally primed with an incongruent color slows it.</p>\n<div style=\"background-color: transparent;\">There are methods of interfering with subject's reports (muteness trivially,&nbsp;<a href=\"http://en.wikipedia.org/wiki/Anosognosia\">anosognosia</a>&nbsp;creepily), but for most humans it very closely corresponds to what is normally considered conscious perception.</div>\n<div style=\"background-color: transparent;\">People's brains respond to information even if the person is unaware of it, but there are measurable differences in perception without awareness and perception with it.</div>\n<div style=\"background-color: transparent;\"><strong>Methods of Manipulating Perception</strong><sup>2</sup></div>\n<div style=\"background-color: transparent;\">Nonconscious stimulation is split up into two categories: &nbsp;<em>subliminal</em>&nbsp; and &nbsp;<em>preconscious</em>. A subliminal stimulus is one in which the bottom up process information is so reduced that people cannot detect it, even if they're paying attention to it. A preconscious stimulus is one that is potentially noticeable (i.e. it's presented in a way that subjects can normally report seeing it), but not reported because of other distractions.</div>\n<div style=\"background-color: transparent;\"><img style=\" float:right; padding: 10 px;\" src=\"http://images.lesswrong.com/t3_7yr_0.png?v=bc484d64ecc4018cbbe8f220918ee92a\" alt=\"Dichoptic Masking, image from Zeki 2003\" width=\"403\" height=\"223\"></div>\n<div style=\"background-color: transparent;\">To present a stimulus subliminally you can: \n<ul>\n<li>Mask a stimulus, by presenting it close in time to other unrelated or interfering stimuli. (i.e. a word flashed for 33 ms is noticeable by itself, but not when proceeded and followed by geometric shapes)<sup>2,3</sup></li>\n<li>Use dichoptic masking, where you present two different images to each eye, and the subject reports seeing something which is neither of those<sup>4</sup></li>\n<li>Use flash suppression, where you show one eye an image and flash shapes in the other eye to interfere with image perception<sup>5</sup></li>\n</ul>\n</div>\n<div style=\"background-color: transparent;\">To present something preconsciously you can:</div>\n<div style=\"background-color: transparent;\">\n<ul>\n<li>Use inattentional blindness, where you present something that participants aren't focusing on.</li>\n<li>Distract them! Present another stimulus and then quickly follow it with the one that you're interested in presenting preconsciously during their attentional blink.<sup>6</sup></li>\n</ul>\n</div>\n<div style=\"background-color: transparent;\"><strong>Neurological Differences</strong></div>\n<div style=\"background-color: transparent;\"><strong></strong>So what's the biggest difference between when people do and don't report seeing something?</div>\n<div style=\"background-color: transparent;\">Across various different methods of nonconscious stimulation, a few patterns emerged. When your eyes are stimulated, areas in your visual cortex (in the back of your head) undergo activity to process it regardless of whether or not you report seeing it. When people do report something, much more of the brain \"lights up\".</div>\n<div style=\"background-color: transparent;\"><img src=\"http://images.lesswrong.com/t3_7yr_1.png?v=e4b768229e87af3df59fbdbdcdaf1310\" alt=\"from Dehaune et al 2011\" width=\"571\" height=\"435\"><br></div>\n<div style=\"background-color: transparent;\">This lighting up also corresponds with recurrent processing, and ERP components in the P3b range. Recurrent processing is simply when a signal whips back and forth between specialized subregions, such as when signals from the visual cortex goes to the frontoparietal region then back to the visual cortex.<sup>1,7</sup><br><br>The idea that conscious access is related to recurrent processing in the frontoparietal region stands up to experimental verification. Researchers are able to interfere with conscious reports of information independently of stimulus identification simply by applying transcranial magnetic stimulation to the prefrontal cortex, without changing the stimulus.<sup>8</sup></div>\n<div style=\"background-color: transparent;\">So basically, consciousness seems to be related to widespread neural activity in cortical areas, as well as recurrent signalling and some particular components of EEG readings. So what?</div>\n<div style=\"background-color: transparent;\"><strong>The Global Workspace Theory</strong><sup>1,9,10</sup></div>\n<div style=\"background-color: transparent;\">The Global Workspace Theory of Consciousness asserts that consciousness is related to information from the various specialized subregions of the brain becoming \u201cglobally available\u201d for attention, motor control, and cognitive reference. This explains phenomena like&nbsp;<a href=\"/lw/7pm/blindsight_and_consciousness/\">blindsight</a>&nbsp;fairly elegantly, saying that visual information in the scotoma ceases to be conscious information because it ceases to be globally available to the system. Douhane adds that neurons with long axons in the frontoparietal cortex are probably the Global Workspace.<sup>1</sup></div>\n<div style=\"background-color: transparent;\">Baars and Dennett are fond of the theater metaphor of consciousness. There\u2019s a spotlight of attention on the stage, and actors (specialized cortical systems) come into and out of this to play their parts.&nbsp;This group of interacting subagents is actually somewhat close to orthonormal's&nbsp;<a href=\"/lw/5op/qualia_strike_back/\">model for dissolving qualia</a>. Behind the scenes, directors and stagehands (decision processes, attention direction, contextual systems) arrange the scenes.&nbsp;Everywhere we shine the spotlight we see consciousness, because consciousness is attached to the light.</div>\n<div style=\"background-color: transparent;\">No part of the system is conscious, but there\u2019s a show going on. And that\u2019s what we see.</div>\n<div style=\"background-color: transparent;\"><strong>Next Obvious Question:</strong></div>\n<div style=\"background-color: transparent;\">Okay, so why does that&nbsp;<a href=\"/lw/p9/the_generalized_antizombie_principle/\">make us talk about consciousness</a>? Why would we use the first person?</div>\n<div style=\"background-color: transparent;\"><em>To be continued...</em></div>\n<div>\n<div style=\"background-color: transparent;\">\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><strong id=\"Notes\">Notes</strong></p>\n<p>A&nbsp;<em>huge</em>&nbsp;thanks to John Salvatier for getting me a bunch of the papers and editing feedback and putting up with my previous attempts to write an article like this. Also thanks to mtaran, falenas108, and RS (you don't know him) for reading drafts of this article.</p>\n<p>Images are from Zeki 2003 and Dehaene 2011, respectively. I'd be very happy if someone helped me format that to show up with the pictures.</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>1</sup>Merikle &amp; Joordens, 1997</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>2</sup>Dehaene, S., &amp; Changeux, J.-P. 2011</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>3</sup>Breitmeyer &amp; Ogmen, 2007</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>4</sup>Moutoussis &amp; Zeki 2002, Image from Zeki 2003</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>5</sup>Tsuchiya &amp; Koch</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>6</sup>Marti et al 2010</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>7</sup>Lamme 2006</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>8</sup>Rounis et al 2010</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>9</sup>Baars 1997</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><sup>10</sup>Metzinger</p>\n</div>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\"><strong id=\"References\">References</strong></p>\n</div>\n<div><span>\n<div style=\"background-color: transparent;\">\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Baars, B. (1997). In the Theatre of Consciousness: The Workplace of the Mind. New York: Oxford University Press. Retrieved from <a href=\"http://scholar.google.com/scholar?hl=en&amp;btnG=Search&amp;q=intitle:In+The+Theatre+of+Consciousness#3M\">here</a></p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">\ufeffBruno G. Breitmeyer and Haluk Ogmen (2007) <a href=\"http://www.scholarpedia.org/article/Visual_masking\">Visual masking</a>. <a href=\"http://www.scholarpedia.org\">Scholarpedia</a>, 2(7):3330</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">\ufeffDehaene, S., &amp; Changeux, J.-P. (2011). Experimental and theoretical approaches to conscious processing. <em>Neuron</em>, <em>70</em>(2), 200-27. Elsevier Inc. doi:10.1016/j.neuron.2011.03.018</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Kouider, S., &amp; Dehaene, S. (2007). Levels of processing during non-conscious perception: a critical review of visual masking. <em>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</em>, <em>362</em>(1481), 857-75. doi:10.1098/rstb.2007.2093</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Lamme, V. A. F. (2006). Towards a true neural stance on consciousness. <em>Trends in Cognitive Sciences</em>, <em>10</em>(11). doi:10.1016/j.tics.2006.09.001</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Merikle, P. M., &amp; Joordens, S. (1997). Parallels between perception without attention and perception without awareness.<em>Consciousness and cognition</em>,&nbsp;<em>6</em>(2-3), 219-36. doi:10.1006/ccog.1997.0310</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Lamme, V. A. F. (2006). Towards a true neural stance on consciousness. <em>Trends in Cognitive Sciences</em>, <em>10</em>(11). doi:10.1016/j.tics.2006.09.001</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Lau, H., &amp; Rosenthal, D. (2011). Empirical support for higher-order theories of conscious awareness.&nbsp;<em>Trends in cognitive sciences</em>,&nbsp;<em>15</em>(8), 365-373. doi:10.1016/j.tics.2011.05.009</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Marti, S., Sackur, J., Sigman, M., &amp; Dehaene, S. (2010). Mapping introspection\u2019s blind spot: reconstruction of dual-task phenomenology using quantified introspection. <em>Cognition</em>, <em>115</em>(2), 303-13. Elsevier B.V. doi:10.1016/j.cognition.2010.01.003</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Metzinger, T. (2003). Being No One. <em>Philosophy</em>, 699. MIT Press.</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Moutoussis, K., &amp; Zeki, S. (2002). The relationship between cortical activation and perception investigated with invisible stimuli. <em>Proceedings of the National Academy of Sciences</em>, <em>99</em>(14), 9527. National Acad Sciences. doi:10.1073/pnas.PNAS</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">Rounis, E., Maniscalco, B., Rothwell, J., Passingham, R., &amp; Lau, H. (2010). Theta-burst transcranial magnetic stimulation to the prefrontal cortex impairs metacognitive visual awareness. <em>Cognitive Neuroscience</em>, <em>1</em>(3), 165-175. doi:10.1080/17588921003632529</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">Tsuchiya, N., &amp; Koch, C. (2005). Continuous flash suppression reduces negative afterimages. <em>Nature neuroscience</em>, <em>8</em>(8), 1096-101. doi:10.1038/nn1500</p>\n<p style=\"margin-left:24pt;text-indent:-24.0pt\">\ufeffZeki, S. (2003). The disunity of consciousness. <em>Trends in Cognitive Sciences</em>, <em>7</em>(5), 214-218. doi:10.1016/S1364-6613(03)00081-0</p>\n<p style=\"margin-left: 24pt; text-indent: -24.0pt;\">&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n</span></div>", "sections": [{"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K82imMHxwbR5FikKP", "pi5DAEZWJK3c9NAhW", "kYAuNJX2ecH2uFqZ9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T01:21:45.438Z", "modifiedAt": null, "url": null, "title": "Karma and good discussions", "slug": "karma-and-good-discussions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.033Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZQhnXNfCxvsfBTSvM/karma-and-good-discussions", "pageUrlRelative": "/posts/ZQhnXNfCxvsfBTSvM/karma-and-good-discussions", "linkUrl": "https://www.lesswrong.com/posts/ZQhnXNfCxvsfBTSvM/karma-and-good-discussions", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Karma%20and%20good%20discussions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKarma%20and%20good%20discussions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZQhnXNfCxvsfBTSvM%2Fkarma-and-good-discussions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Karma%20and%20good%20discussions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZQhnXNfCxvsfBTSvM%2Fkarma-and-good-discussions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZQhnXNfCxvsfBTSvM%2Fkarma-and-good-discussions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 36, "htmlBody": "<p>Inspired by <a href=\"/r/discussion/lw/7yz/should_i_play_world_of_warcraft/4zfa\">this</a>: what if the link for comments to a post included a comment karma total divided by the number of comments ratio?</p>\n<p>This would also be handy for comments with an individual score below threshold.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZQhnXNfCxvsfBTSvM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 7.807027697368523e-07, "legacy": true, "legacyId": "10347", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T01:33:09.717Z", "modifiedAt": "2020-11-24T03:15:40.247Z", "url": null, "title": "Morality is not about willpower", "slug": "morality-is-not-about-willpower", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:12.175Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SBM5r93HSX2YDNERk/morality-is-not-about-willpower", "pageUrlRelative": "/posts/SBM5r93HSX2YDNERk/morality-is-not-about-willpower", "linkUrl": "https://www.lesswrong.com/posts/SBM5r93HSX2YDNERk/morality-is-not-about-willpower", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Morality%20is%20not%20about%20willpower&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMorality%20is%20not%20about%20willpower%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSBM5r93HSX2YDNERk%2Fmorality-is-not-about-willpower%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Morality%20is%20not%20about%20willpower%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSBM5r93HSX2YDNERk%2Fmorality-is-not-about-willpower", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSBM5r93HSX2YDNERk%2Fmorality-is-not-about-willpower", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3943, "htmlBody": "<p>Most people believe the way to lose weight is through willpower.\u00a0 My successful experience losing weight is that this is not the case.\u00a0 You will lose weight if you want to, meaning you <em>effectively</em> believe<sup>0</sup> that the utility you will gain from losing weight, even time-discounted, will outweigh the utility from yummy food now.\u00a0 In LW terms, you will lose weight if your utility function tells you to.\u00a0 This is the basis of cognitive behavioral therapy (the effective kind of therapy), which tries to change peoples' behavior by examining their beliefs and changing their thinking habits.</p>\n<p>Similarly, most people believe behaving ethically is a matter of willpower; and I believe this even less.\u00a0 Your ethics is part of your utility function.\u00a0 Acting morally is, technically, a <em>choice</em>; but not the difficult kind that holds up a stop sign and says \"Choose wisely!\"\u00a0 We notice difficult moral choices more than easy moral choices; but most moral choices are easy, like choosing a ten dollar bill over a five.\u00a0 Immorality is not a continual temptation we must resist; it's just a kind of stupidity.</p>\n<p>This post can be summarized as:</p>\n<ol>\n<li>Each normal human has an instinctive personal morality.</li>\n<li>This morality consists of inputs into that human's decision-making system.\u00a0 There is no need to propose separate moral and selfish decision-making systems.</li>\n<li>Acknowledging that all decisions are made by a single decision-making system, and that the moral elements enter it in the same manner as other preferences, results in many changes to how we encourage social behavior.</li>\n</ol>\n<p><a></a>Many people have commented that humans don't make decisions based on utility functions.\u00a0 This is a surprising attitude to find on LessWrong, given that Eliezer has often cast rationality and moral reasoning in terms of computing expected utility.\u00a0 It also demonstrates a misunderstanding of what utility functions are.\u00a0 Values, and utility functions, are models we construct to explain why we do what we do.\u00a0 You can construct a set of values and a utility function to fit your observed behavior, <em>no matter how your brain produces that behavior</em>.\u00a0 You can fit this model to the data arbitrarily well by adding parameters.\u00a0 It will always have some error, as you are running on stochastic hardware.\u00a0 Behavior is not a product of the utility function; the utility function is a product of (and predictor of) the behavior.\u00a0 If your behavior can't be modelled with values and a utility function, you shouldn't bother reading LessWrong, because \"being less wrong\" means behaving in a way that is closer to the predictions of some model of rationality.\u00a0 If you are a mysterious black box with inscrutable motives that makes unpredictable actions, no one can say you are \"wrong\" about anything.</p>\n<p>If you still insist that I shouldn't talk about utility functions, though - it doesn't matter!\u00a0 This post is about morality, not about utility functions.\u00a0 I use utility functions just as a way of saying \"what you want to do\".\u00a0 Substitute your own model of behavior.\u00a0 The bottom line here is that moral behavior is not a qualitatively separate type of behavior and does not require a separate model of behavior.</p>\n<p>My view isn't new.\u00a0 It derives from ancient Greek ethics, Nietzsche, Ayn Rand, B.F. Skinner, and comments on LessWrong.\u00a0 I thought it was the dominant view on LW, but the comments and votes indicate it is held at best by a weak majority.</p>\n<p>Relevant EY posts include \"<a href=\"/lw/rq/what_would_you_do_without_morality/\">What would you do without morality?</a>\", \"<a href=\"/lw/sa/the_gift_we_give_to_tomorrow/\">The gift we give to tomorrow</a>\", \"<a href=\"/lw/sk/changing_your_metaethics/\">Changing your meta-ethics</a>\", and \"<a href=\"/lw/sm/the_meaning_of_right\">The meaning of right</a>\"; and particularly the statement, \"Maybe that which you would do even if there were no morality, <em>is</em> your morality.\"\u00a0 I was surprised that no comments mentioned any of the many points of contact between this post and <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">Eliezer's longest sequence</a>.\u00a0 (Did anyone even read the entire meta-ethics sequence?)\u00a0 The view I'm presenting is, as far as I can tell, the same as that given in EY's meta-ethics sequence up through \"The meaning of right\"<sup>1</sup>; but I am talking about what it is that people are doing when they act in a way we recognize as ethical, whereas Eliezer was talking about where people get their notions of what is ethical.</p>\n<h2>Ethics as willpower<br /></h2>\n<p>Society's main story is that behaving morally means constantly making tough decisions and doing things you don't want to do.\u00a0 You have desires; other people have other desires; and ethics is a referee that helps us mutually satisfy these desires, or at least not kill each other.\u00a0 There is one true ethics; society tries to discover and encode it; and the moral choice is to follow that code.</p>\n<p>This story has implications that usually go together:</p>\n<ul>\n<li>Ethics is about when peoples' desires conflict.\u00a0 Thus, ethics is only concerned with interpersonal relations.</li>\n<li>There is a single, Platonic, correct ethical system for a given X. (X used be a social class but not a context or society.\u00a0 Nowadays it can be a society or context but not a social class.)</li>\n<li>Your desires and feelings are anti-correlated with ethical behavior.\u00a0 Humans are naturally unethical.\u00a0 Being ethical is a continual, lifelong struggle.</li>\n<li>The main purpose of ethics is to stop people from doing what they naturally want to do, so \"thou shalt not\" <a href=\"http://en.wikipedia.org/wiki/Ten_Commandments\">is more important than</a> \"thou shalt\".</li>\n<li>The key to being ethical is having the willpower not to follow your own utility function.</li>\n<li>Social ethics are encouraged by teaching people to \"be good\", where \"good\" is the whole social ethical code.\u00a0 Sometimes this is done without explaining what \"good\" is, since it is considered obvious, or perhaps more convenient to the priesthood to leave it unspecified. (Read the Koran for an extreme example.)</li>\n<li>The key contrast is between \"good\" people who will do the moral thing, and \"evil\" people who do just the opposite.</li>\n<li>Turning an evil person into a good person can be done by reasoning with them, teaching them willpower, or convincing them they will be punished for being evil.</li>\n<li>Ethical judgements are different from utility judgements.\u00a0 Utility is a tool of reason, and reason only tells you how to get what you want, whereas ethics tells you what you ought to want.\u00a0 Therefore utilitarians are unethical. </li>\n<li>Human society requires spiritual guidance and physical force to stop people from using reason to seek their own utility.<br /> \n<ul>\n<li>Religion is necessary even if it is false.</li>\n<li>Reason must be strictly subordinated to spiritual authority.</li>\n<li>Smart people are less moral than dumb people, because reason maximizes personal utility.</li>\n</ul>\n</li>\n<li>Since ethics are desirable, and yet contrary to human reason, they prove that human values transcend logic, biology, and the material world, and derive from a spiritual plane of existence.</li>\n<li>If there is no God, and no spiritual world, then there is no such thing as good. \n<ul>\n<li>Sartre: \"There can no longer be any good a priori, since there is no infinite and perfect consciousness to think it.\"</li>\n</ul>\n</li>\n<li>A person's ethicality is a single dimension, determined by the degree to which a person has willpower and subsumes their utility to social utility.\u00a0 Each person has a level of ethicality that is the same in all domains.\u00a0 You can be a good person, an evil person, or somewhere in between - but that's it.\u00a0 You should not expect someone who cheats at cards to be courageous in battle, unless they really enjoy battle.</li>\n</ul>\n<p>People do choose whether to follow the ethics society promulgates.\u00a0 And they must weigh their personal satisfaction against the satisfaction of others; and those weights are probably relatively constant across domains for a given person.\u00a0 So there is some truth in the standard view.\u00a0 I want to point out errors; but I mostly want to change the focus.\u00a0 The standard view focuses on a person struggling to implement an ethical system, and obliterates distinctions between the ethics of that person, the ethics of society, and \"true\" ethics (whatever they may be).\u00a0 I will <a href=\"/lw/55n/human_errors_human_values/3vq5\">call these</a> \"personal ethics\", \"social ethics\", and \"normative ethics\" (although the last encompasses all of the usual meaning of \"ethics\", including meta-ethics).\u00a0 I want to increase the emphasis on personal ethics, or ethical intuitions.\u00a0 Mostly just to insist that they exist.\u00a0 (A surprising number of people simultaneously claim to have strong moral feelings, and that people naturally have no moral feelings.)</p>\n<p>The conventional story denies these first two exist:\u00a0 Ethics <em>is</em> what is good; society tries to figure out what is good; and a person is more or less ethical to the degree that they act in accordance with ethics.</p>\n<p>The chief error of the standard view is that it explains ethics as a war between the physical and the spiritual.\u00a0 If a person is struggling between doing the \"selfish\" thing and the \"right\" thing, that proves that they want both about equally.\u00a0 The standard view instead supposes that they have a physical nature that wants only the \"selfish\" thing, and some internal or external spiritual force pulling them towards the \"right\" thing.\u00a0 It thus hinders people from thinking about ethical problems as trade-offs, because the model never shows two \"moral\" desires in conflict except in \"paradoxes\" such as the trolley problem.\u00a0 It also prevents people from recognizing cultures as moral <i>systems</i>--to really tick these people off, let's say morality-optimizing <i>machines</i>--in which different agents with different morals are <i>necessary parts</i> for the culture to work smoothly.</p>\n<p>You could recast the standard view with the conscious mind taking the place of the spiritual nature, the subconscious mind taking the place of the physical nature, and willpower being the exertion of control over the subconscious by the conscious.\u00a0 (Suggested by my misinterpretation of Matt's <a href=\"/r/discussion/lw/7ko/morality_is_not_a_choice/4zcd\">comment</a>.)\u00a0 But to use that to defend the \"ethics as willpower\" view, you assume that the subconscious <em>usually</em> wants to do immoral things, while the conscious mind is the source of morality.\u00a0 And I have no evidence that my subconscious is less likely to propose moral actions than my conscious. My subconscious mind usually wants to be nice to people; and my conscious mind sometimes comes up with evil plans that my subconscious responds to with disgust.</p>\n<h3>... but being evil is harder than being good<br /></h3>\n<p>At times, I've rationally convinced myself that I was being held back from my goals by my personal ethics, and I determined to act less ethically.\u00a0 Sometimes I succeeded.\u00a0 But more often, I did not.\u00a0 Even when I did, I had to first build up a complex structure of rationalizations, and exert a lot of willpower to carry through.\u00a0 I have never been able (or wanted) to say, \"Now I will be evil\" (by my personal ethics) and succeed.</p>\n<p>If being good takes willpower, why does it take more willpower to be evil?</p>\n<h2>Ethics as innate</h2>\n<p>One theory that can explain why being evil is hard is Rousseau's theory that people are noble savages by birth, and would enact the true ethics if only their inclinations were not crushed by society.\u00a0 But if you have friends who have raised their children by this theory, I probably need say no more.  A fatal flaw in noble-savage theory is that Rousseau didn't know about evolution.  Child-rearing is part of our evolutionary environment; so we should expect to have genetically evolved instincts and culturally evolved beliefs about child-rearing which are better than random, and we should expect things to go terribly wrong if we ignore these instincts and practices.</p>\n<h2>Ethics as taste</h2>\n<p>Try, instead, something between the extremes of saying that people are naturally evil, or naturally good.\u00a0 Think of the intuitions underlying your personal morality as the same sort of thing as your personal taste in food, or maybe better, in art.\u00a0 I find a picture with harmony and balance pleasing, and I find a conversation carried on in harmony and with a balance of speakers and views pleasing.\u00a0 I find a story about someone overcoming adversity pleasing, as I find an instance of someone in real life overcoming adversity commendable.</p>\n<p>Perhaps causality runs in the other direction; perhaps our artistic tastes are symbolic manifestations of our morals and other cognitive rules-of-thumb.\u00a0 I can think of many moral \"tastes\" for which I have which have no obvious artistic analog, which suggests that the former is more fundamental.\u00a0 I like making people smile; I don't like pictures of smiling people.</p>\n<p>I don't mean to trivialize morality.\u00a0 I just want people to admit that most humans often find pleasure in being nice to other humans, and usually feel pain on seeing other humans--at least those within the tribe--in pain.\u00a0 Is this culturally conditioned?\u00a0 If so, it's by culture predating any moral code on offer today.\u00a0 Works of literature have always shown people showing some other people an unselfish compassion.\u00a0 Sometimes that compassion can be explained by a social code, as with Wiglaf's loyalty to Beowulf.\u00a0 Sometimes it can't, as with Gilgamesh's compassion for the old men who sit on the walls of Ur, or Odysseus' compassion for Ajax.</p>\n<p>Subjectively, we feel something different on seeing someone smile than we do on eating an ice-cream cone.\u00a0 But it isn't obvious to me that \"moral feels / selfish feels\" is a natural dividing line.\u00a0 I feel something different when saving a small child from injury than when making someone smile, and I feel something different when drinking Jack Daniels than when eating an ice-cream cone.</p>\n<p>Computationally, there must be little difference between the way we treat moral, aesthetic, and sensual preferences, because none of them reliably trumps the others.\u00a0 We seem to just sum them all up linearly.\u00a0 If so, this is great, to a rationalist, because then rationality and morals are no longer separate magisteria.\u00a0 We don't need separate models of rational behavior and moral behavior, and a way of resolving conflicts between them.\u00a0 If you are using utility functions, you only need one model; values of all types go in, and a single utility comes out.\u00a0 (If you aren't using utility functions, use whatever it is you use to predict human behavior.\u00a0 The point is that you only need one of them.)\u00a0 It's true that we have separate neural systems that respond to different classes of situation; but no one has ever protested against a utility-based theory of rationality by pointing out that there are separate neural systems responding to images and sounds, and so we must have separate image-values and sound-values and some way of resolving conflicts between image-utility and sound-utility.\u00a0 The division of utility into moral values and all other values may even have a neural basis; but modelling that difference has, historically, caused <em>much</em> greater problems than it has solved.</p>\n<p>The problem for this theory is:\u00a0 If ethics is just preference, why do we prefer to be nice to each other?\u00a0 The answer comes from evolutionary theory.\u00a0 Exactly how it does this is <a href=\"http://www.nature.com/nature/journal/v466/n7310/full/nature09205.html\">controversial</a>, but it is no longer a deep mystery.\u00a0 One feasible answer is that reproductive success is proportional to <a href=\"http://en.wikipedia.org/wiki/Kin_selection\"><em>inclusive </em>fitness</a>.<sup>3</sup>\u00a0 It is important to know how much of our moral intuitions is innate, and how much is conditioned; but I have no strong opinion on this other than that it is probably some of each.</p>\n<p>This theory has different implications than the standard story:</p>\n<ul>\n<li>Behaving morally feels good.</li>\n<li>Social morals are encouraged by creating conditions that bring personal morals into line with social morals.</li>\n<li>A person can have personal morals similar to society's in one domain, and very different in another domain.</li>\n<li>A person learns their personal morals when they are young.</li>\n<li>Being smarter enables you to be more ethical. </li>\n<li>A person will come to feel that an action is ethical if it leads to something pleasant shortly after doing it, and unethical if it leads to displeasure.</li>\n<li>A person can extinguish a moral intuition by violating it many times without consequences - whether they do this of their own free will, or under duress.</li>\n<li>It may be easier to learn to enjoy new ethical behaviors (thou shalts), than to dislike enjoyable behaviors (thou shalt nots).</li>\n<li>The key contrast is between \"good\" people who want to do the moral thing, and \"bad\" people who are apathetic about it.</li>\n<li>Turning a (socially) bad person into a good person is done one behavior at a time.</li>\n<li>Society can reason about what ethics they would like to encourage under current conditions.</li>\n</ul>\n<p>As I said, this is nothing new.\u00a0 The standard story makes concessions to it, as social conservatives believe morals should be taught to children using behaviorist principles (\"Spare the rod and spoil the child\").\u00a0 This is the theory of ethics endorsed by \"Walden Two\" and warned against by \"A Clockwork Orange\".\u00a0 And it is the theory of ethics so badly abused by the former Soviet Union, among other tyrannical governments.\u00a0 More on this, hopefully, in a later post.</p>\n<p><strong>Does that mean I can have all the pie?</strong></p>\n<p>No.</p>\n<p>Eliezer addressed something that sounds like the \"ethics as taste\" theory in his post \"<a href=\"/lw/rx/is_morality_preference/\">Is morality preference</a>?\", and rejected it.\u00a0 However, the position he rejected was the straw-man position that acting to immediately gratify your desires is moral behavior.\u00a0 (The position he ultimately promoted, in \"<a href=\"/lw/sm/the_meaning_of_right\">The meaning of right</a>\", seems to be the same I am promoting here:\u00a0 That we have ethical intuitions because we have evolved to compute actions as preferable that maximized our inclusive fitness.)</p>\n<p>Maximizing expected utility is not done by greedily grabbing everything within reach that has utility to you.\u00a0 You may rationally leave your money in a 401K for 30 years, even though you don't know what you're going to do with it in 30 years and you <em>do</em> know that you'd really like a Maserati right now.\u00a0 Wanting the Maserati does not make buying the Maserati rational.\u00a0 Similarly, wanting all of the pie does not make taking all of the pie moral.</p>\n<p>More importantly, I would never want all of the pie.\u00a0 It would make me unhappy to make other people go hungry.\u00a0 But what about people who really do want all of the pie?\u00a0 I could argue that they reason that taking all the pie would incur social penalties.\u00a0 But that would result in morals that vanish when no one is looking.\u00a0 And that's not the kind of morals normal people have.</p>\n<p>Normal people don't calculate the penalties they will incur from taking all the pie.\u00a0 Sociopaths do that.\u00a0 Unlike the \"ethics as willpower\" theorists, I am not going to construct a theory of ethics that takes sociopaths as normal.<sup>4</sup>\u00a0 They are diseased, and my theory of ethical behavior does not have to explain their behavior, any more than a theory of rationality has to explain the behavior of schizophrenics.\u00a0 Now that we have a theory of evolution that can explain how altruism could evolve, we don't have to come up with a theory of ethics that assumes people are not altruistic.</p>\n<h2>Why would you want to change your utility function?</h2>\n<p>Many LWers will reason like this:\u00a0 \"I should never want to change my utility function.\u00a0 Therefore, I have no interest in effective means of changing my tastes or my ethics.\"</p>\n<p>Reasoning this way makes the distinction between ethics as willpower and ethics as taste less interesting.\u00a0 In fact, it makes the study of ethics in general less interesting - there is little motivation other than to figure out what your ethics are, and to use ethics to manipulate others into optimizing your values.</p>\n<p>You don't have to contemplate changing your utility function for this distinction to be somewhat interesting.\u00a0 We are usually talking about society collectively deciding how to change each others' utility functions.\u00a0 The standard LessWrongian view is compatible with this:\u00a0 You assume that ethics is a social game in which you should act deceptively, trying to foist your utility functions on other people and avoid letting yours being changed.</p>\n<p>But I think we <em>can</em> contemplate changing our utility functions.\u00a0 The short answer is that you may choose to change your future utility function when doing so will have the counter-intuitive effect of better-fulfilling your current utility function (as some humans do in one ending of Eliezer's story about <a href=\"/lw/y5/the_babyeating_aliens_18\">babyeating aliens</a>).\u00a0 This can usually be described as a group of people all conspiring to choose utility functions that collectively solve prisoners' dilemmas, or (as in the case just cited) as a rational response to a threatened cost that your current utility function is likely to trigger.\u00a0 (You might model this as a pre-commitment, like one-boxing, rather than as changing your utility function.\u00a0 The results should be the same.\u00a0 Consciously trying to change your behavior via pre-commitment, however, may be more difficult, and may be interpreted by others as deception and punished.)</p>\n<p>(There are several longer, more frequently-applicable answers; but they require a separate post.)</p>\n<h2>Fuzzies and utilons</h2>\n<p>Eliezer's post, <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately\">Purchase fuzzies and utilons separately</a>, on the surface appears to say that you should not try to optimize your utility function, but that you should instead satisfy two separate utility functions:\u00a0 a selfish utility function, and an altruistic utility function.</p>\n<p>But remember what a utility function is.\u00a0 It's a way of adding up all your different preferences and coming up with a single number.\u00a0 Coming up with a single number is important, so that all possible outcomes can be ordered.\u00a0 That's what you need, and ordering is what numbers do.\u00a0 Having two utility functions is like having no utility function at all, because you don't have an ordering of preferences.</p>\n<p>The \"selfish utility function\" and the \"altruistic utility function\" are different natural categories of human preferences.\u00a0 Eliezer is getting indirectly at the fact that the altruistic utility function (which gives output in \"fuzzies\") is <em>indexical</em>.\u00a0 That is, its values have the word \"I\" in them.\u00a0 The altruistic utility function cares whether <em>you</em> help an old lady across the street, or some person you hired in Portland helps an old lady across the street.\u00a0 If you aren't aware of this, you may say, \"It is more cost-effective to hire boy scouts (who work for less than minimum wage) to help old ladies across the street and achieve my goal of old ladies having been helped across the street.\"\u00a0 But your real utility function prefers that <em>you</em> helped them across the street; and so this doesn't work.</p>\n<h2>Conclusion</h2>\n<p>The old religious view of ethics as supernatural and contrary to human nature is dysfunctional and based on false assumptions.\u00a0 Many religious people claim that evolutionary theory leads to the destruction of ethics, by teaching us that we are \"just\" animals.\u00a0 But ironically, it is evolutionary theory that provides us with the understanding we need to build ethical societies.\u00a0 Now that we have this explanation, the \"ethics as taste\" theory deserves to be evaluated again, and see if it isn't more sensible and more productive than the \"ethics as willpower\" theory.</p>\n<p>\u00a0</p>\n<p>0.\u00a0 I use the phrase \"effectively believe\" to mean both having a belief, and having habits of thought that cause you to also believe the logical consequences of that belief.</p>\n<p>1.\u00a0 We have disagreements, such as the possibility of dividing values into <a href=\"/lw/l4/terminal_values_and_instrumental_values/\">terminal and instrumental</a>, the relation of the values of the mind to the values of its organism, and whether having a value implies that propagating that value is also a value of yours (I say no).\u00a0 But they don't come into play here.</p>\n<p>3.\u00a0 For more details, see Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">meta-ethics sequence</a>.</p>\n<p>4.\u00a0 Also, I do not take Gandhi as morally normal.\u00a0 Not all brains develop as their genes planned; and we should expect as many humans to be pathologically good as are pathologically evil.\u00a0 (A biographical comparison between Gandhi and Hitler shows a remarkable number of similarities.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2, "YrLoz567b553YouZ2": 2, "5f5c37ee1b5cdee568cfb187": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SBM5r93HSX2YDNERk", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 20, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "9816", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Most people believe the way to lose weight is through willpower.&nbsp; My successful experience losing weight is that this is not the case.&nbsp; You will lose weight if you want to, meaning you <em>effectively</em> believe<sup>0</sup> that the utility you will gain from losing weight, even time-discounted, will outweigh the utility from yummy food now.&nbsp; In LW terms, you will lose weight if your utility function tells you to.&nbsp; This is the basis of cognitive behavioral therapy (the effective kind of therapy), which tries to change peoples' behavior by examining their beliefs and changing their thinking habits.</p>\n<p>Similarly, most people believe behaving ethically is a matter of willpower; and I believe this even less.&nbsp; Your ethics is part of your utility function.&nbsp; Acting morally is, technically, a <em>choice</em>; but not the difficult kind that holds up a stop sign and says \"Choose wisely!\"&nbsp; We notice difficult moral choices more than easy moral choices; but most moral choices are easy, like choosing a ten dollar bill over a five.&nbsp; Immorality is not a continual temptation we must resist; it's just a kind of stupidity.</p>\n<p>This post can be summarized as:</p>\n<ol>\n<li>Each normal human has an instinctive personal morality.</li>\n<li>This morality consists of inputs into that human's decision-making system.&nbsp; There is no need to propose separate moral and selfish decision-making systems.</li>\n<li>Acknowledging that all decisions are made by a single decision-making system, and that the moral elements enter it in the same manner as other preferences, results in many changes to how we encourage social behavior.</li>\n</ol>\n<p><a></a>Many people have commented that humans don't make decisions based on utility functions.&nbsp; This is a surprising attitude to find on LessWrong, given that Eliezer has often cast rationality and moral reasoning in terms of computing expected utility.&nbsp; It also demonstrates a misunderstanding of what utility functions are.&nbsp; Values, and utility functions, are models we construct to explain why we do what we do.&nbsp; You can construct a set of values and a utility function to fit your observed behavior, <em>no matter how your brain produces that behavior</em>.&nbsp; You can fit this model to the data arbitrarily well by adding parameters.&nbsp; It will always have some error, as you are running on stochastic hardware.&nbsp; Behavior is not a product of the utility function; the utility function is a product of (and predictor of) the behavior.&nbsp; If your behavior can't be modelled with values and a utility function, you shouldn't bother reading LessWrong, because \"being less wrong\" means behaving in a way that is closer to the predictions of some model of rationality.&nbsp; If you are a mysterious black box with inscrutable motives that makes unpredictable actions, no one can say you are \"wrong\" about anything.</p>\n<p>If you still insist that I shouldn't talk about utility functions, though - it doesn't matter!&nbsp; This post is about morality, not about utility functions.&nbsp; I use utility functions just as a way of saying \"what you want to do\".&nbsp; Substitute your own model of behavior.&nbsp; The bottom line here is that moral behavior is not a qualitatively separate type of behavior and does not require a separate model of behavior.</p>\n<p>My view isn't new.&nbsp; It derives from ancient Greek ethics, Nietzsche, Ayn Rand, B.F. Skinner, and comments on LessWrong.&nbsp; I thought it was the dominant view on LW, but the comments and votes indicate it is held at best by a weak majority.</p>\n<p>Relevant EY posts include \"<a href=\"/lw/rq/what_would_you_do_without_morality/\">What would you do without morality?</a>\", \"<a href=\"/lw/sa/the_gift_we_give_to_tomorrow/\">The gift we give to tomorrow</a>\", \"<a href=\"/lw/sk/changing_your_metaethics/\">Changing your meta-ethics</a>\", and \"<a href=\"/lw/sm/the_meaning_of_right\">The meaning of right</a>\"; and particularly the statement, \"Maybe that which you would do even if there were no morality, <em>is</em> your morality.\"&nbsp; I was surprised that no comments mentioned any of the many points of contact between this post and <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">Eliezer's longest sequence</a>.&nbsp; (Did anyone even read the entire meta-ethics sequence?)&nbsp; The view I'm presenting is, as far as I can tell, the same as that given in EY's meta-ethics sequence up through \"The meaning of right\"<sup>1</sup>; but I am talking about what it is that people are doing when they act in a way we recognize as ethical, whereas Eliezer was talking about where people get their notions of what is ethical.</p>\n<h2 id=\"Ethics_as_willpower\">Ethics as willpower<br></h2>\n<p>Society's main story is that behaving morally means constantly making tough decisions and doing things you don't want to do.&nbsp; You have desires; other people have other desires; and ethics is a referee that helps us mutually satisfy these desires, or at least not kill each other.&nbsp; There is one true ethics; society tries to discover and encode it; and the moral choice is to follow that code.</p>\n<p>This story has implications that usually go together:</p>\n<ul>\n<li>Ethics is about when peoples' desires conflict.&nbsp; Thus, ethics is only concerned with interpersonal relations.</li>\n<li>There is a single, Platonic, correct ethical system for a given X. (X used be a social class but not a context or society.&nbsp; Nowadays it can be a society or context but not a social class.)</li>\n<li>Your desires and feelings are anti-correlated with ethical behavior.&nbsp; Humans are naturally unethical.&nbsp; Being ethical is a continual, lifelong struggle.</li>\n<li>The main purpose of ethics is to stop people from doing what they naturally want to do, so \"thou shalt not\" <a href=\"http://en.wikipedia.org/wiki/Ten_Commandments\">is more important than</a> \"thou shalt\".</li>\n<li>The key to being ethical is having the willpower not to follow your own utility function.</li>\n<li>Social ethics are encouraged by teaching people to \"be good\", where \"good\" is the whole social ethical code.&nbsp; Sometimes this is done without explaining what \"good\" is, since it is considered obvious, or perhaps more convenient to the priesthood to leave it unspecified. (Read the Koran for an extreme example.)</li>\n<li>The key contrast is between \"good\" people who will do the moral thing, and \"evil\" people who do just the opposite.</li>\n<li>Turning an evil person into a good person can be done by reasoning with them, teaching them willpower, or convincing them they will be punished for being evil.</li>\n<li>Ethical judgements are different from utility judgements.&nbsp; Utility is a tool of reason, and reason only tells you how to get what you want, whereas ethics tells you what you ought to want.&nbsp; Therefore utilitarians are unethical. </li>\n<li>Human society requires spiritual guidance and physical force to stop people from using reason to seek their own utility.<br> \n<ul>\n<li>Religion is necessary even if it is false.</li>\n<li>Reason must be strictly subordinated to spiritual authority.</li>\n<li>Smart people are less moral than dumb people, because reason maximizes personal utility.</li>\n</ul>\n</li>\n<li>Since ethics are desirable, and yet contrary to human reason, they prove that human values transcend logic, biology, and the material world, and derive from a spiritual plane of existence.</li>\n<li>If there is no God, and no spiritual world, then there is no such thing as good. \n<ul>\n<li>Sartre: \"There can no longer be any good a priori, since there is no infinite and perfect consciousness to think it.\"</li>\n</ul>\n</li>\n<li>A person's ethicality is a single dimension, determined by the degree to which a person has willpower and subsumes their utility to social utility.&nbsp; Each person has a level of ethicality that is the same in all domains.&nbsp; You can be a good person, an evil person, or somewhere in between - but that's it.&nbsp; You should not expect someone who cheats at cards to be courageous in battle, unless they really enjoy battle.</li>\n</ul>\n<p>People do choose whether to follow the ethics society promulgates.&nbsp; And they must weigh their personal satisfaction against the satisfaction of others; and those weights are probably relatively constant across domains for a given person.&nbsp; So there is some truth in the standard view.&nbsp; I want to point out errors; but I mostly want to change the focus.&nbsp; The standard view focuses on a person struggling to implement an ethical system, and obliterates distinctions between the ethics of that person, the ethics of society, and \"true\" ethics (whatever they may be).&nbsp; I will <a href=\"/lw/55n/human_errors_human_values/3vq5\">call these</a> \"personal ethics\", \"social ethics\", and \"normative ethics\" (although the last encompasses all of the usual meaning of \"ethics\", including meta-ethics).&nbsp; I want to increase the emphasis on personal ethics, or ethical intuitions.&nbsp; Mostly just to insist that they exist.&nbsp; (A surprising number of people simultaneously claim to have strong moral feelings, and that people naturally have no moral feelings.)</p>\n<p>The conventional story denies these first two exist:&nbsp; Ethics <em>is</em> what is good; society tries to figure out what is good; and a person is more or less ethical to the degree that they act in accordance with ethics.</p>\n<p>The chief error of the standard view is that it explains ethics as a war between the physical and the spiritual.&nbsp; If a person is struggling between doing the \"selfish\" thing and the \"right\" thing, that proves that they want both about equally.&nbsp; The standard view instead supposes that they have a physical nature that wants only the \"selfish\" thing, and some internal or external spiritual force pulling them towards the \"right\" thing.&nbsp; It thus hinders people from thinking about ethical problems as trade-offs, because the model never shows two \"moral\" desires in conflict except in \"paradoxes\" such as the trolley problem.&nbsp; It also prevents people from recognizing cultures as moral <i>systems</i>--to really tick these people off, let's say morality-optimizing <i>machines</i>--in which different agents with different morals are <i>necessary parts</i> for the culture to work smoothly.</p>\n<p>You could recast the standard view with the conscious mind taking the place of the spiritual nature, the subconscious mind taking the place of the physical nature, and willpower being the exertion of control over the subconscious by the conscious.&nbsp; (Suggested by my misinterpretation of Matt's <a href=\"/r/discussion/lw/7ko/morality_is_not_a_choice/4zcd\">comment</a>.)&nbsp; But to use that to defend the \"ethics as willpower\" view, you assume that the subconscious <em>usually</em> wants to do immoral things, while the conscious mind is the source of morality.&nbsp; And I have no evidence that my subconscious is less likely to propose moral actions than my conscious. My subconscious mind usually wants to be nice to people; and my conscious mind sometimes comes up with evil plans that my subconscious responds to with disgust.</p>\n<h3 id=\"____but_being_evil_is_harder_than_being_good\">... but being evil is harder than being good<br></h3>\n<p>At times, I've rationally convinced myself that I was being held back from my goals by my personal ethics, and I determined to act less ethically.&nbsp; Sometimes I succeeded.&nbsp; But more often, I did not.&nbsp; Even when I did, I had to first build up a complex structure of rationalizations, and exert a lot of willpower to carry through.&nbsp; I have never been able (or wanted) to say, \"Now I will be evil\" (by my personal ethics) and succeed.</p>\n<p>If being good takes willpower, why does it take more willpower to be evil?</p>\n<h2 id=\"Ethics_as_innate\">Ethics as innate</h2>\n<p>One theory that can explain why being evil is hard is Rousseau's theory that people are noble savages by birth, and would enact the true ethics if only their inclinations were not crushed by society.&nbsp; But if you have friends who have raised their children by this theory, I probably need say no more.  A fatal flaw in noble-savage theory is that Rousseau didn't know about evolution.  Child-rearing is part of our evolutionary environment; so we should expect to have genetically evolved instincts and culturally evolved beliefs about child-rearing which are better than random, and we should expect things to go terribly wrong if we ignore these instincts and practices.</p>\n<h2 id=\"Ethics_as_taste\">Ethics as taste</h2>\n<p>Try, instead, something between the extremes of saying that people are naturally evil, or naturally good.&nbsp; Think of the intuitions underlying your personal morality as the same sort of thing as your personal taste in food, or maybe better, in art.&nbsp; I find a picture with harmony and balance pleasing, and I find a conversation carried on in harmony and with a balance of speakers and views pleasing.&nbsp; I find a story about someone overcoming adversity pleasing, as I find an instance of someone in real life overcoming adversity commendable.</p>\n<p>Perhaps causality runs in the other direction; perhaps our artistic tastes are symbolic manifestations of our morals and other cognitive rules-of-thumb.&nbsp; I can think of many moral \"tastes\" for which I have which have no obvious artistic analog, which suggests that the former is more fundamental.&nbsp; I like making people smile; I don't like pictures of smiling people.</p>\n<p>I don't mean to trivialize morality.&nbsp; I just want people to admit that most humans often find pleasure in being nice to other humans, and usually feel pain on seeing other humans--at least those within the tribe--in pain.&nbsp; Is this culturally conditioned?&nbsp; If so, it's by culture predating any moral code on offer today.&nbsp; Works of literature have always shown people showing some other people an unselfish compassion.&nbsp; Sometimes that compassion can be explained by a social code, as with Wiglaf's loyalty to Beowulf.&nbsp; Sometimes it can't, as with Gilgamesh's compassion for the old men who sit on the walls of Ur, or Odysseus' compassion for Ajax.</p>\n<p>Subjectively, we feel something different on seeing someone smile than we do on eating an ice-cream cone.&nbsp; But it isn't obvious to me that \"moral feels / selfish feels\" is a natural dividing line.&nbsp; I feel something different when saving a small child from injury than when making someone smile, and I feel something different when drinking Jack Daniels than when eating an ice-cream cone.</p>\n<p>Computationally, there must be little difference between the way we treat moral, aesthetic, and sensual preferences, because none of them reliably trumps the others.&nbsp; We seem to just sum them all up linearly.&nbsp; If so, this is great, to a rationalist, because then rationality and morals are no longer separate magisteria.&nbsp; We don't need separate models of rational behavior and moral behavior, and a way of resolving conflicts between them.&nbsp; If you are using utility functions, you only need one model; values of all types go in, and a single utility comes out.&nbsp; (If you aren't using utility functions, use whatever it is you use to predict human behavior.&nbsp; The point is that you only need one of them.)&nbsp; It's true that we have separate neural systems that respond to different classes of situation; but no one has ever protested against a utility-based theory of rationality by pointing out that there are separate neural systems responding to images and sounds, and so we must have separate image-values and sound-values and some way of resolving conflicts between image-utility and sound-utility.&nbsp; The division of utility into moral values and all other values may even have a neural basis; but modelling that difference has, historically, caused <em>much</em> greater problems than it has solved.</p>\n<p>The problem for this theory is:&nbsp; If ethics is just preference, why do we prefer to be nice to each other?&nbsp; The answer comes from evolutionary theory.&nbsp; Exactly how it does this is <a href=\"http://www.nature.com/nature/journal/v466/n7310/full/nature09205.html\">controversial</a>, but it is no longer a deep mystery.&nbsp; One feasible answer is that reproductive success is proportional to <a href=\"http://en.wikipedia.org/wiki/Kin_selection\"><em>inclusive </em>fitness</a>.<sup>3</sup>&nbsp; It is important to know how much of our moral intuitions is innate, and how much is conditioned; but I have no strong opinion on this other than that it is probably some of each.</p>\n<p>This theory has different implications than the standard story:</p>\n<ul>\n<li>Behaving morally feels good.</li>\n<li>Social morals are encouraged by creating conditions that bring personal morals into line with social morals.</li>\n<li>A person can have personal morals similar to society's in one domain, and very different in another domain.</li>\n<li>A person learns their personal morals when they are young.</li>\n<li>Being smarter enables you to be more ethical. </li>\n<li>A person will come to feel that an action is ethical if it leads to something pleasant shortly after doing it, and unethical if it leads to displeasure.</li>\n<li>A person can extinguish a moral intuition by violating it many times without consequences - whether they do this of their own free will, or under duress.</li>\n<li>It may be easier to learn to enjoy new ethical behaviors (thou shalts), than to dislike enjoyable behaviors (thou shalt nots).</li>\n<li>The key contrast is between \"good\" people who want to do the moral thing, and \"bad\" people who are apathetic about it.</li>\n<li>Turning a (socially) bad person into a good person is done one behavior at a time.</li>\n<li>Society can reason about what ethics they would like to encourage under current conditions.</li>\n</ul>\n<p>As I said, this is nothing new.&nbsp; The standard story makes concessions to it, as social conservatives believe morals should be taught to children using behaviorist principles (\"Spare the rod and spoil the child\").&nbsp; This is the theory of ethics endorsed by \"Walden Two\" and warned against by \"A Clockwork Orange\".&nbsp; And it is the theory of ethics so badly abused by the former Soviet Union, among other tyrannical governments.&nbsp; More on this, hopefully, in a later post.</p>\n<p><strong id=\"Does_that_mean_I_can_have_all_the_pie_\">Does that mean I can have all the pie?</strong></p>\n<p>No.</p>\n<p>Eliezer addressed something that sounds like the \"ethics as taste\" theory in his post \"<a href=\"/lw/rx/is_morality_preference/\">Is morality preference</a>?\", and rejected it.&nbsp; However, the position he rejected was the straw-man position that acting to immediately gratify your desires is moral behavior.&nbsp; (The position he ultimately promoted, in \"<a href=\"/lw/sm/the_meaning_of_right\">The meaning of right</a>\", seems to be the same I am promoting here:&nbsp; That we have ethical intuitions because we have evolved to compute actions as preferable that maximized our inclusive fitness.)</p>\n<p>Maximizing expected utility is not done by greedily grabbing everything within reach that has utility to you.&nbsp; You may rationally leave your money in a 401K for 30 years, even though you don't know what you're going to do with it in 30 years and you <em>do</em> know that you'd really like a Maserati right now.&nbsp; Wanting the Maserati does not make buying the Maserati rational.&nbsp; Similarly, wanting all of the pie does not make taking all of the pie moral.</p>\n<p>More importantly, I would never want all of the pie.&nbsp; It would make me unhappy to make other people go hungry.&nbsp; But what about people who really do want all of the pie?&nbsp; I could argue that they reason that taking all the pie would incur social penalties.&nbsp; But that would result in morals that vanish when no one is looking.&nbsp; And that's not the kind of morals normal people have.</p>\n<p>Normal people don't calculate the penalties they will incur from taking all the pie.&nbsp; Sociopaths do that.&nbsp; Unlike the \"ethics as willpower\" theorists, I am not going to construct a theory of ethics that takes sociopaths as normal.<sup>4</sup>&nbsp; They are diseased, and my theory of ethical behavior does not have to explain their behavior, any more than a theory of rationality has to explain the behavior of schizophrenics.&nbsp; Now that we have a theory of evolution that can explain how altruism could evolve, we don't have to come up with a theory of ethics that assumes people are not altruistic.</p>\n<h2 id=\"Why_would_you_want_to_change_your_utility_function_\">Why would you want to change your utility function?</h2>\n<p>Many LWers will reason like this:&nbsp; \"I should never want to change my utility function.&nbsp; Therefore, I have no interest in effective means of changing my tastes or my ethics.\"</p>\n<p>Reasoning this way makes the distinction between ethics as willpower and ethics as taste less interesting.&nbsp; In fact, it makes the study of ethics in general less interesting - there is little motivation other than to figure out what your ethics are, and to use ethics to manipulate others into optimizing your values.</p>\n<p>You don't have to contemplate changing your utility function for this distinction to be somewhat interesting.&nbsp; We are usually talking about society collectively deciding how to change each others' utility functions.&nbsp; The standard LessWrongian view is compatible with this:&nbsp; You assume that ethics is a social game in which you should act deceptively, trying to foist your utility functions on other people and avoid letting yours being changed.</p>\n<p>But I think we <em>can</em> contemplate changing our utility functions.&nbsp; The short answer is that you may choose to change your future utility function when doing so will have the counter-intuitive effect of better-fulfilling your current utility function (as some humans do in one ending of Eliezer's story about <a href=\"/lw/y5/the_babyeating_aliens_18\">babyeating aliens</a>).&nbsp; This can usually be described as a group of people all conspiring to choose utility functions that collectively solve prisoners' dilemmas, or (as in the case just cited) as a rational response to a threatened cost that your current utility function is likely to trigger.&nbsp; (You might model this as a pre-commitment, like one-boxing, rather than as changing your utility function.&nbsp; The results should be the same.&nbsp; Consciously trying to change your behavior via pre-commitment, however, may be more difficult, and may be interpreted by others as deception and punished.)</p>\n<p>(There are several longer, more frequently-applicable answers; but they require a separate post.)</p>\n<h2 id=\"Fuzzies_and_utilons\">Fuzzies and utilons</h2>\n<p>Eliezer's post, <a href=\"/lw/6z/purchase_fuzzies_and_utilons_separately\">Purchase fuzzies and utilons separately</a>, on the surface appears to say that you should not try to optimize your utility function, but that you should instead satisfy two separate utility functions:&nbsp; a selfish utility function, and an altruistic utility function.</p>\n<p>But remember what a utility function is.&nbsp; It's a way of adding up all your different preferences and coming up with a single number.&nbsp; Coming up with a single number is important, so that all possible outcomes can be ordered.&nbsp; That's what you need, and ordering is what numbers do.&nbsp; Having two utility functions is like having no utility function at all, because you don't have an ordering of preferences.</p>\n<p>The \"selfish utility function\" and the \"altruistic utility function\" are different natural categories of human preferences.&nbsp; Eliezer is getting indirectly at the fact that the altruistic utility function (which gives output in \"fuzzies\") is <em>indexical</em>.&nbsp; That is, its values have the word \"I\" in them.&nbsp; The altruistic utility function cares whether <em>you</em> help an old lady across the street, or some person you hired in Portland helps an old lady across the street.&nbsp; If you aren't aware of this, you may say, \"It is more cost-effective to hire boy scouts (who work for less than minimum wage) to help old ladies across the street and achieve my goal of old ladies having been helped across the street.\"&nbsp; But your real utility function prefers that <em>you</em> helped them across the street; and so this doesn't work.</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>The old religious view of ethics as supernatural and contrary to human nature is dysfunctional and based on false assumptions.&nbsp; Many religious people claim that evolutionary theory leads to the destruction of ethics, by teaching us that we are \"just\" animals.&nbsp; But ironically, it is evolutionary theory that provides us with the understanding we need to build ethical societies.&nbsp; Now that we have this explanation, the \"ethics as taste\" theory deserves to be evaluated again, and see if it isn't more sensible and more productive than the \"ethics as willpower\" theory.</p>\n<p>&nbsp;</p>\n<p>0.&nbsp; I use the phrase \"effectively believe\" to mean both having a belief, and having habits of thought that cause you to also believe the logical consequences of that belief.</p>\n<p>1.&nbsp; We have disagreements, such as the possibility of dividing values into <a href=\"/lw/l4/terminal_values_and_instrumental_values/\">terminal and instrumental</a>, the relation of the values of the mind to the values of its organism, and whether having a value implies that propagating that value is also a value of yours (I say no).&nbsp; But they don't come into play here.</p>\n<p>3.&nbsp; For more details, see Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">meta-ethics sequence</a>.</p>\n<p>4.&nbsp; Also, I do not take Gandhi as morally normal.&nbsp; Not all brains develop as their genes planned; and we should expect as many humans to be pathologically good as are pathologically evil.&nbsp; (A biographical comparison between Gandhi and Hitler shows a remarkable number of similarities.)</p>", "sections": [{"title": "Ethics as willpower", "anchor": "Ethics_as_willpower", "level": 1}, {"title": "... but being evil is harder than being good", "anchor": "____but_being_evil_is_harder_than_being_good", "level": 2}, {"title": "Ethics as innate", "anchor": "Ethics_as_innate", "level": 1}, {"title": "Ethics as taste", "anchor": "Ethics_as_taste", "level": 1}, {"title": "Does that mean I can have all the pie?", "anchor": "Does_that_mean_I_can_have_all_the_pie_", "level": 3}, {"title": "Why would you want to change your utility function?", "anchor": "Why_would_you_want_to_change_your_utility_function_", "level": 1}, {"title": "Fuzzies and utilons", "anchor": "Fuzzies_and_utilons", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "146 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 146, "af": false, "version": "1.4.0", "pingbacks": {"Posts": ["iGH7FSrdoCXa5AHGs", "pGvyqAQw6yqTjpKf4", "LhP2zGBWR5AdssrdJ", "fG3g3764tSubr6xvs", "F5WLc7hCxkB4X4yD4", "n5TqCuizyJDfAPjkr", "3p3CYauiX8oLjmwRF", "n5ucT5ZbPdhfGNLtP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T02:25:11.161Z", "modifiedAt": null, "url": null, "title": "Applying Bayesian Analysis to History (post idea)", "slug": "applying-bayesian-analysis-to-history-post-idea", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.626Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Asymmetric", "createdAt": "2010-11-28T17:46:59.113Z", "isAdmin": false, "displayName": "Asymmetric"}, "userId": "3cXSbrTN5k7oZYpyz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QYYAo98W7vN9MSkWc/applying-bayesian-analysis-to-history-post-idea", "pageUrlRelative": "/posts/QYYAo98W7vN9MSkWc/applying-bayesian-analysis-to-history-post-idea", "linkUrl": "https://www.lesswrong.com/posts/QYYAo98W7vN9MSkWc/applying-bayesian-analysis-to-history-post-idea", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Applying%20Bayesian%20Analysis%20to%20History%20(post%20idea)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApplying%20Bayesian%20Analysis%20to%20History%20(post%20idea)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQYYAo98W7vN9MSkWc%2Fapplying-bayesian-analysis-to-history-post-idea%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Applying%20Bayesian%20Analysis%20to%20History%20(post%20idea)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQYYAo98W7vN9MSkWc%2Fapplying-bayesian-analysis-to-history-post-idea", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQYYAo98W7vN9MSkWc%2Fapplying-bayesian-analysis-to-history-post-idea", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p>I am an aspiring historian and I'm very interested in ways to apply Bayesian reasoning to history. When I say \"history\" I mean the study of history -- as a historian, allowing my map of what has happened<em> in the past</em> to match the territory, and being able to represent more accurately the relative strength of historical evidence for and against various historical models.</p>\n<p><a href=\"/lw/in/scientific_evidence_legal_evidence_rational/\">I know that historical evidence works quite a bit differently from scientific evidence.</a> But I think that <a href=\"/lw/j0/making_history_available/\">historical evidence is also useful</a>. Historians, in recording and assembling secondary sources, assess the relative strength of evidence (mostly primary sources) with regards to a topic <em>already</em>.&nbsp; But there must be a way to do it more formally. Shouldn't there be a right answer, just as no two people who are completely rational (and have the same information) should ever disagree?</p>\n<p>This is a post (or series of posts) I might write in the future, and I have put a bit of thought into it so far, but I need to do quite a bit more research. Is there anyone interested in reading something on this topic? Has it been done before? Is there anyone who is knowledgeable about how historians treat evidence who might be able to offer some insights?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QYYAo98W7vN9MSkWc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 17, "extendedScore": null, "score": 7.807242720604328e-07, "legacy": true, "legacyId": "10349", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fhojYBGGiYAFcryHZ", "TLKPj4GDXetZuPDH5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T02:36:01.333Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] No One Knows What Science Doesn't Know", "slug": "seq-rerun-no-one-knows-what-science-doesn-t-know", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/njXqohppPZZM5xQMK/seq-rerun-no-one-knows-what-science-doesn-t-know", "pageUrlRelative": "/posts/njXqohppPZZM5xQMK/seq-rerun-no-one-knows-what-science-doesn-t-know", "linkUrl": "https://www.lesswrong.com/posts/njXqohppPZZM5xQMK/seq-rerun-no-one-knows-what-science-doesn-t-know", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20No%20One%20Knows%20What%20Science%20Doesn't%20Know&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20No%20One%20Knows%20What%20Science%20Doesn't%20Know%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnjXqohppPZZM5xQMK%2Fseq-rerun-no-one-knows-what-science-doesn-t-know%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20No%20One%20Knows%20What%20Science%20Doesn't%20Know%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnjXqohppPZZM5xQMK%2Fseq-rerun-no-one-knows-what-science-doesn-t-know", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnjXqohppPZZM5xQMK%2Fseq-rerun-no-one-knows-what-science-doesn-t-know", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<p>Today's post, <a href=\"/lw/kj/no_one_knows_what_science_doesnt_know/\">No One Knows What Science Doesn't Know</a> was originally published on 25 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#No_One_Knows_What_Science_Doesn.27t_Know\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>In the modern world, unlike our ancestral environment, it is not possible for one person to know more than a tiny fraction of the world's scientific knowledge. Just because you don't understand something, you should not conclude that not one of the six billion other people on the planet understands it.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/7z0/seq_rerun_double_illusion_of_transparency/\">Double Illusion of Transparency</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "njXqohppPZZM5xQMK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.807279456155193e-07, "legacy": true, "legacyId": "10352", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vNBxmcHpnozjrJnJP", "cfkqXkZKvSshBWoX2", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T02:56:58.381Z", "modifiedAt": null, "url": null, "title": "Link: WJS article that uses Steve Jobs' death to mock cryonics and the Singularity", "slug": "link-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.928Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ArcBps72NDEvfTRe5/link-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics", "pageUrlRelative": "/posts/ArcBps72NDEvfTRe5/link-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics", "linkUrl": "https://www.lesswrong.com/posts/ArcBps72NDEvfTRe5/link-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20WJS%20article%20that%20uses%20Steve%20Jobs'%20death%20to%20mock%20cryonics%20and%20the%20Singularity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20WJS%20article%20that%20uses%20Steve%20Jobs'%20death%20to%20mock%20cryonics%20and%20the%20Singularity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FArcBps72NDEvfTRe5%2Flink-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20WJS%20article%20that%20uses%20Steve%20Jobs'%20death%20to%20mock%20cryonics%20and%20the%20Singularity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FArcBps72NDEvfTRe5%2Flink-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FArcBps72NDEvfTRe5%2Flink-wjs-article-that-uses-steve-jobs-death-to-mock-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 259, "htmlBody": "<p><a href=\"http://online.wsj.com/article/SB10001424052970203388804576616921133007668.html\">And One Last Thing: Digital immortality is an app that probably wouldn't have interested Steve Jobs</a></p>\n<p>Excerpt:</p>\n<blockquote>\n<p>Jobs made it clear that he did not welcome death, but also that life could be more interesting knowing that death would be coming.</p>\n<p>One wonders, then, with what mixed feelings he viewed his Silicon Valley compatriots who've been seeking ways to make sure, at least for themselves, death never comes. No doubt they are being perfectly reasonable. When wealthy enough to satisfy every material appetite many times over, it make sense to try to prolong those appetites indefinitely through cryogenics, nanotechnology and artificial intelligence.</p>\n<p>This would not have been Jobs's interest in the subject. He likely would have been more intrigued by the specific claim, advanced by inventor Ray Kurzweil and other advocates of \"technological singularity,\" that soon our individualities will be able to live eternally through digital electronics.</p>\n<p>What kind of device should our consciousness occupy? Should it have a 4-inch screen or a 9-inch screen? Should it fit in a pocket or backpack? Should it have Bluetooth? Where should our essence primarily reside, in the cloud or in device memory? How much battery life would the user want?</p>\n<p>And who is the user?</p>\n<p>Hmmm. Jobs looked at technology from the perspective of the user, who wanted an object both beautiful and beautifully functional. If the user is our \"survivors\"&mdash;i.e., our loved ones who still exist in physical form&mdash;he might conclude that the most important feature such a device could have is an off-switch&mdash;a permanent one.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ArcBps72NDEvfTRe5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 6, "extendedScore": null, "score": 7.807350481995376e-07, "legacy": true, "legacyId": "10355", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T03:32:17.937Z", "modifiedAt": null, "url": null, "title": "Mike Darwin on Steve Jobs's hypocritical stance towards death", "slug": "mike-darwin-on-steve-jobs-s-hypocritical-stance-towards", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:53.565Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Synaptic", "createdAt": "2011-09-26T14:13:36.154Z", "isAdmin": false, "displayName": "Synaptic"}, "userId": "cXSPuYAf5pC9XTzcm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/38bhCn3sqoLYNzwQB/mike-darwin-on-steve-jobs-s-hypocritical-stance-towards", "pageUrlRelative": "/posts/38bhCn3sqoLYNzwQB/mike-darwin-on-steve-jobs-s-hypocritical-stance-towards", "linkUrl": "https://www.lesswrong.com/posts/38bhCn3sqoLYNzwQB/mike-darwin-on-steve-jobs-s-hypocritical-stance-towards", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mike%20Darwin%20on%20Steve%20Jobs's%20hypocritical%20stance%20towards%20death&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMike%20Darwin%20on%20Steve%20Jobs's%20hypocritical%20stance%20towards%20death%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F38bhCn3sqoLYNzwQB%2Fmike-darwin-on-steve-jobs-s-hypocritical-stance-towards%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mike%20Darwin%20on%20Steve%20Jobs's%20hypocritical%20stance%20towards%20death%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F38bhCn3sqoLYNzwQB%2Fmike-darwin-on-steve-jobs-s-hypocritical-stance-towards", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F38bhCn3sqoLYNzwQB%2Fmike-darwin-on-steve-jobs-s-hypocritical-stance-towards", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 377, "htmlBody": "<p>First, Darwin <a href=\"http://tech.groups.yahoo.com/group/New_Cryonet/message/1038\">describes</a> Jobs's (far mode) stance towards death:&nbsp;</p>\n<blockquote>\n<p>As Aschwin points out Jobs is on record (his Stanford Commencement Speech) as saying that death is the best thing that ever happened to life - that it clears out the old, and makes way for the new.</p>\n</blockquote>\n<p>But <a href=\"http://tech.groups.yahoo.com/group/New_Cryonet/message/1051\">these</a> are Jobs's actual (near mode) actions regarding his own death:&nbsp;</p>\n<blockquote>\n<p>The really big story, so far largely unexploited by the media, is that Jobs got a liver transplant and got it here in the US. This just does not happen in patients with his Dx and prognosis - not since Mickey Mantle, anyway. And his outcome was exactly as was predicted. This infuriates those 'in the know' in the transplant community, because you have only to look to guys like Jim Neighbors, Larry Hagman, or even Larry Kramer who got livers many years or even a decade or two ago, and who continue not only to survive, but to do well. To put the liver of a 25-year old into a ~54 year old man with metastatic neuroendocrine pancreatic cancer violates the established protocols of just about every transplant center in the US.</p>\n</blockquote>\n<p>The conclusion:</p>\n<blockquote>\n<p>I find it more than a little hypocritical that Jobs, who spoke so glowingly of the utility of death for others, used every bit of medical technology AND his considerable wealth and influence, to postpone it for it himself, including the expedient of taking a GIFT, given with the sole intention of its being used to provide genuinely life saving benefit (not a futile exercise in medical care) and squandering it on a doomed attempt to save his own life. If you have the temerity to stand before the entire population of this planet and proclaim the goodness of death, then you should have the balls to accept it - especially when your own warped, erroneous and IRRATIONAL decision making was the proximate cause of your own dying. Instead, Jobs chose to grasp at straws, take a gift from a dead man and his family, given in good faith, and squander it on his own lust for more of the very thing (life) that he has publicly proclaimed it is a second best to \"Death (which) is very likely the single best invention of life.\"&nbsp;</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1, "xHjy88N2uJvGdgzfw": 1, "cpBfacd22cJsm5fuL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "38bhCn3sqoLYNzwQB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 33, "extendedScore": null, "score": 7.807470244257642e-07, "legacy": true, "legacyId": "10357", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T07:41:26.164Z", "modifiedAt": null, "url": null, "title": "Guardian article highlights observational biases in Knox investigators", "slug": "guardian-article-highlights-observational-biases-in-knox", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.676Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "machrider", "createdAt": "2010-10-12T23:37:29.342Z", "isAdmin": false, "displayName": "machrider"}, "userId": "jFSugHAcHBNKua4k4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DncviP9itgm8EFfbR/guardian-article-highlights-observational-biases-in-knox", "pageUrlRelative": "/posts/DncviP9itgm8EFfbR/guardian-article-highlights-observational-biases-in-knox", "linkUrl": "https://www.lesswrong.com/posts/DncviP9itgm8EFfbR/guardian-article-highlights-observational-biases-in-knox", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Guardian%20article%20highlights%20observational%20biases%20in%20Knox%20investigators&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGuardian%20article%20highlights%20observational%20biases%20in%20Knox%20investigators%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDncviP9itgm8EFfbR%2Fguardian-article-highlights-observational-biases-in-knox%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Guardian%20article%20highlights%20observational%20biases%20in%20Knox%20investigators%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDncviP9itgm8EFfbR%2Fguardian-article-highlights-observational-biases-in-knox", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDncviP9itgm8EFfbR%2Fguardian-article-highlights-observational-biases-in-knox", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<p><a href=\"http://www.guardian.co.uk/world/2011/oct/08/amanda-knox-facial-expressions\">Amanda Knox: What's in a face?</a></p>\n<p>Some choice quotes:</p>\n<blockquote>\n<p>The eyes are not windows to the soul. They are organs for converting light into electro-magnetic impulses.</p>\n</blockquote>\n<blockquote>\n<p>\"We were able to establish guilt,\" said Edgardo Giobbi, the lead investigator, \"by closely observing the suspect's psychological and behavioural reaction during the interrogation.\"</p>\n</blockquote>\n<p>There are several good insights throughout the article, many of which will probably seem familiar to readers of Less Wrong. The few that stood out to me:</p>\n<ol>\n<li><a href=\"http://en.wikipedia.org/wiki/Fundamental_attribution_error\">Fundamental attribution error</a><a></a> and the general tendency to create grossly oversimplified mental models of others (while simultaneously overestimating our model's accuracy).</li>\n<li>Various <a href=\"http://en.wikipedia.org/wiki/Observational_bias#Biases\">observational biases</a>, especially egregious on the part of police and investigators. They were so satisfied with the \"evidence\" of her facial expressions, which is readily available (under the proverbial streetlight), that they felt this obviated the need for additional investigation. It appears that this led them to seek only evidence that further confirmed Knox's guilt (confirmation bias), rather than considering ways to disprove the hypothesis.</li>\n<li>Not sure what to call this other than the (not-too-well-established) <a href=\"http://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect\">Dunning-Kruger Effect</a>: the tendency of nearly everyone involved to overestimate their ability to judge someone's guilt based on expression reading techniques in which they may or may not be skilled.</li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DncviP9itgm8EFfbR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 17, "extendedScore": null, "score": 7.808314964695325e-07, "legacy": true, "legacyId": "10364", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T14:12:05.999Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Baltimore, Houston, Chicago, Melbourne, and Penn State", "slug": "weekly-lw-meetups-baltimore-houston-chicago-melbourne-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:38.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Wk2wsjxEYyYTkGde9/weekly-lw-meetups-baltimore-houston-chicago-melbourne-and", "pageUrlRelative": "/posts/Wk2wsjxEYyYTkGde9/weekly-lw-meetups-baltimore-houston-chicago-melbourne-and", "linkUrl": "https://www.lesswrong.com/posts/Wk2wsjxEYyYTkGde9/weekly-lw-meetups-baltimore-houston-chicago-melbourne-and", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Baltimore%2C%20Houston%2C%20Chicago%2C%20Melbourne%2C%20and%20Penn%20State&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Baltimore%2C%20Houston%2C%20Chicago%2C%20Melbourne%2C%20and%20Penn%20State%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWk2wsjxEYyYTkGde9%2Fweekly-lw-meetups-baltimore-houston-chicago-melbourne-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Baltimore%2C%20Houston%2C%20Chicago%2C%20Melbourne%2C%20and%20Penn%20State%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWk2wsjxEYyYTkGde9%2Fweekly-lw-meetups-baltimore-houston-chicago-melbourne-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWk2wsjxEYyYTkGde9%2Fweekly-lw-meetups-baltimore-houston-chicago-melbourne-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 327, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/3q\">Baltimore meetup:&nbsp;<span class=\"date\">01 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/3p\">Houston Meetup - Saturday, October 1:&nbsp;<span class=\"date\">01 October 2011 03:00PM</span></a></li>\n<li><a href=\"/meetups/3o\">Chicago Meetup:&nbsp;<span class=\"date\">02 October 2011 03:00PM</span></a></li>\n<li><a href=\"/meetups/3r\">Pittsburgh Meetup:&nbsp;<span class=\"date\">05 October 2011 05:45PM</span></a></li>\n<li><a href=\"/meetups/3n\">Melbourne, practical rationality, Friday 7th October, 7pm:&nbsp;<span class=\"date\">07 October 2011 06:00PM</span></a></li>\n<li><a href=\"/meetups/3i\">Penn State University: NEW Meetup starting!:&nbsp;<span class=\"date\">22 October 2011 02:00PM</span></a></li>\n</ul>\n<p>The Ottawa meetups are now occurring regularly and weekly! The meetups take place at 7:30 pm on Mondays, and the location varies. Join the <a href=\"http://groups.google.com/group/less-wrong-ottawa\">google group</a> or contact <a href=\"/user/XFrequentist/\">XFrequentist</a> for more information.&nbsp;</p>\n<p>Cities with regularly scheduled meetups:&nbsp;<strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>, <a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine\">Irvine</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>,<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>, </strong>and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>Despite the handy sidebar of upcoming meetups, we've decided to continue posting an overview of upcoming meetups on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening:&nbsp;<strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>,&nbsp; <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison, WI</a></strong><strong>.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Wk2wsjxEYyYTkGde9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.809639870337125e-07, "legacy": true, "legacyId": "10227", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pAHo9zSFXygp5A5dL", "tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T14:45:59.707Z", "modifiedAt": null, "url": null, "title": "Mike Darwin on Kurzweil, Techno-Optimism, and Delusional Stances on Cryonics", "slug": "mike-darwin-on-kurzweil-techno-optimism-and-delusional", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:24.651Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Synaptic", "createdAt": "2011-09-26T14:13:36.154Z", "isAdmin": false, "displayName": "Synaptic"}, "userId": "cXSPuYAf5pC9XTzcm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P4LakhT54cLwtonnn/mike-darwin-on-kurzweil-techno-optimism-and-delusional", "pageUrlRelative": "/posts/P4LakhT54cLwtonnn/mike-darwin-on-kurzweil-techno-optimism-and-delusional", "linkUrl": "https://www.lesswrong.com/posts/P4LakhT54cLwtonnn/mike-darwin-on-kurzweil-techno-optimism-and-delusional", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mike%20Darwin%20on%20Kurzweil%2C%20Techno-Optimism%2C%20and%20Delusional%20Stances%20on%20Cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMike%20Darwin%20on%20Kurzweil%2C%20Techno-Optimism%2C%20and%20Delusional%20Stances%20on%20Cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP4LakhT54cLwtonnn%2Fmike-darwin-on-kurzweil-techno-optimism-and-delusional%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mike%20Darwin%20on%20Kurzweil%2C%20Techno-Optimism%2C%20and%20Delusional%20Stances%20on%20Cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP4LakhT54cLwtonnn%2Fmike-darwin-on-kurzweil-techno-optimism-and-delusional", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP4LakhT54cLwtonnn%2Fmike-darwin-on-kurzweil-techno-optimism-and-delusional", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 471, "htmlBody": "<p>In a comment on his skeptical <a href=\"http://chronopause.com/index.php/2011/08/11/the-kurzwild-man-in-the-night/\">post</a> about Ray Kurzweil, he <a href=\"http://chronopause.com/index.php/2011/08/11/the-kurzwild-man-in-the-night/#comment-3637\">writes</a>,</p>\n<blockquote>\n<p>Unfortunately, [Kurzweil's] technological forecasting is naive, and I believe it will also prove erroneous (and in that, he is in excellent company). That would be of no consequence to me, or to others in cryonics, were it not for the fact that it has had, and continues to have, a corrosive effect on cryonics and immortalist activists and activism. His idea of the Singularity has created an expectation of entitlement and inevitability that are wholly unjustified, both on the basis of history, and on on the basis of events that are playing out now in the world markets, and on the geopolitical stage....</p>\n<p>The IEET poll [<a href=\"http://ieet.org/index.php/IEET/more/die20110907\">link</a>; Sep 7, 2011] found that the majority of their readers aged 35 or older said that they expect to &ldquo;die within a normal human lifespan;&rdquo; no surprises there.</p>\n<p>This was in contrast to to an overwhelming majority (69%) of their readers under the age of 35 who believe that radical life extension will enable them to stay alive indefinitely, or &ldquo;for centuries, at least.&rdquo;</p>\n<p>Where the data gets really interesting is when you look at the breakdown of just how these folks think they are going to be GIVEN practical immortality:</p>\n<ul>\n<li>36% believe they will stay alive for centuries (at least) in their own (biological) bodies</li>\n<li>26% expect that they will continue to survive by having their &ldquo;minds uploaded to a computer&rdquo;</li>\n<li>7% expect to &ldquo;die&rdquo; but to eventually be resurrected by cryonics.</li>\n</ul>\n<p>Only 7% think cryonics will be necessary? That simply delusional and it is a huge problem....</p>\n<p>Nor are the 7% who anticipate survival via cryonics likely to be signed up. In fact, I&rsquo;d wager not more than one or two of them is. And why should they bestir themselves in any way to this end? After all, the Singularity is coming, it is INEVITABLE, and all they have to do is to sit back and wait for it to arrive &ndash; presumably wrapped up in in pretty paper and with bows on.</p>\n<p>Young people anticipating practical immortality look at me like some kind of raving mad Luddite when I try to convince them that if they are to have any meaningful chance at truly long term survival, they are going to have to act, work very hard, and have a hell of a lot of luck in the bargain....</p>\n<p>Kurzweil has been, without doubt or argument, THE great enabler of this madness by providing a scenario and a narrative that is far more credible than Santa Claus, and orders of magnitude more appealing.</p>\n</blockquote>\n<p>I wonder how people on Less Wrong would respond to that poll?</p>\n<p>Edit: (Tried to) fix formatting and typo in title.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P4LakhT54cLwtonnn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 7.809754841662188e-07, "legacy": true, "legacyId": "10219", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T16:04:53.708Z", "modifiedAt": null, "url": null, "title": "1001 PredictionBook Nights", "slug": "1001-predictionbook-nights", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:14.443Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yE4Fdx4kYmQchBCek/1001-predictionbook-nights", "pageUrlRelative": "/posts/yE4Fdx4kYmQchBCek/1001-predictionbook-nights", "linkUrl": "https://www.lesswrong.com/posts/yE4Fdx4kYmQchBCek/1001-predictionbook-nights", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%201001%20PredictionBook%20Nights&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A1001%20PredictionBook%20Nights%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyE4Fdx4kYmQchBCek%2F1001-predictionbook-nights%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=1001%20PredictionBook%20Nights%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyE4Fdx4kYmQchBCek%2F1001-predictionbook-nights", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyE4Fdx4kYmQchBCek%2F1001-predictionbook-nights", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<blockquote>\n<p>I explain what I've learned from creating and judging thousands of predictions on personal and real-world matters: the challenges of maintenance, the limitations of prediction markets, the interesting applications to my other essays, skepticism about pundits and unreflective persons' opinions, my own biases like optimism &amp; planning fallacy, 3 very useful heuristics/approaches, and the costs of these activities in general.</p>\n<p>Plus an extremely geeky parody of <em>Fate/Stay Night</em>.</p>\n</blockquote>\n<p>This essay exists as a large section of my page on <a href=\"http://www.gwern.net/Prediction%20markets#predictionbook-nights\">predictions markets</a> on <code>gwern.net</code>: <a href=\"http://www.gwern.net/Prediction%20markets#1001-predictionbook-nights\">http://www.gwern.net/Prediction%20markets#1001-predictionbook-nights</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"R6dqPii4cyNpuecLt": 1, "E8PHMuf7tsr8teXAe": 1, "3uE2pXvbcnS9nnZRE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yE4Fdx4kYmQchBCek", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 72, "extendedScore": null, "score": 0.0001514339918796226, "legacy": true, "legacyId": "10341", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 51, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-08T18:12:03.504Z", "modifiedAt": null, "url": null, "title": "The Outside View Of Human Complexity", "slug": "the-outside-view-of-human-complexity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.247Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Andy_McKenzie", "createdAt": "2009-02-28T21:46:45.283Z", "isAdmin": false, "displayName": "Andy_McKenzie"}, "userId": "7PFnr3J3uCGSfjnZJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5FmQiv6skygRCDZEW/the-outside-view-of-human-complexity", "pageUrlRelative": "/posts/5FmQiv6skygRCDZEW/the-outside-view-of-human-complexity", "linkUrl": "https://www.lesswrong.com/posts/5FmQiv6skygRCDZEW/the-outside-view-of-human-complexity", "postedAtFormatted": "Saturday, October 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Outside%20View%20Of%20Human%20Complexity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Outside%20View%20Of%20Human%20Complexity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5FmQiv6skygRCDZEW%2Fthe-outside-view-of-human-complexity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Outside%20View%20Of%20Human%20Complexity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5FmQiv6skygRCDZEW%2Fthe-outside-view-of-human-complexity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5FmQiv6skygRCDZEW%2Fthe-outside-view-of-human-complexity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1277, "htmlBody": "<p>One common question: how complex is some aspect of the human body?&nbsp;In addition to <em>directly</em> evaluating the available evidence for that aspect, one fruitful tactic in making this kind of prediction is&nbsp;to analyze past predictions about similar phenomena and assume that the&nbsp;outcome will be similar. This is called&nbsp;<a href=\"http://en.wikipedia.org/wiki/Reference_class_forecasting\">reference class forecasting</a>, and is often referred to on this site as \"taking the outside view.\"&nbsp;</p>\n<p>First, how do we define complexity? Loosely, I will consider a more complex situation to be one with more components, either in total number or type, which allows for more degrees of freedom in the system considered. Using this loose definition for now, how do our predictions about human complexity tend to fare?&nbsp;</p>\n<p><strong>Point: Predictions about concrete things have tended to overestimate our complexity</strong></p>\n<p>Once we know about their theoretical existence of phenomenon but before they are systematically measured, our predictions about measurable traits of the human body tend to err on the side of being more complex (i.e., more extensive or variable) than reality.&nbsp;</p>\n<p>1) Although scholars throughout history have tended to think that human brains must be vastly differently from those of other animals, on the molecular and cellular level there have turned out to be few differences. As Eric Kandel relates in&nbsp;<a href=\"http://www.amazon.com/Search-Memory-Emergence-Science-Mind/dp/0393058638\">his autobiography</a>&nbsp;(p. 236), \"because human mental processes have long been thought to be unique, some early students of the brain expected to find many new classes of proteins lurking in our gray matter. Instead, science has found surprisingly few proteins that are truly unique to the human brain and no signaling systems that are unique to it.\"&nbsp;</p>\n<p>2) There turned out to be fewer protein-coding genes in human body than most people expected. We have data on this by way of an informal betting market in the early 2000's, described <a href=\"http://www.sciencemag.org/content/300/5625/1484.2.full\">here</a>&nbsp;($) and <a href=\"http://www.ornl.gov/sci/techresources/Human_Genome/faq/genenumber.shtml\">here</a> (OA). The predictions ranged from 26,000 - 150,000, and that lower bound prediction won, even though it probably wasn't low enough! As of 2008, the predicted number by <a href=\"http://useast.ensembl.org/index.html\">Ensembl</a> was in the 23,000s. (As an aside, humans don't have the largest genome in terms of number of nucleotides either, by far. That title currently belongs to the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Paris_japonica\">canopy plant</a>, pictured below (thanks to&nbsp;<a href=\"http://www.flickr.com/photos/kodamatic/4859550707/\">kodamatic</a>&nbsp;for the photo, and to&nbsp;<a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1095-8339.2010.01072.x/full\">Pellicer et al.</a>&nbsp;for the sequencing effort).)</p>\n<p><img style=\"vertical-align: middle;\" src=\"http://images.lesswrong.com/t3_801_0.png\" alt=\"\" width=\"500\" height=\"371\" /></p>\n<p>3) Intro neuro texts (including&nbsp;<a href=\"http://www.amazon.com/Principles-Neural-Science-Eric-Kandel/dp/0838577016\">one co-written by the aforementioned Kandel</a>) claim that there are 10-fold (or more) more glia cells than neurons in the human brain. Since glia play crucial support roles and can even&nbsp;<a href=\"http://en.wikipedia.org/wiki/Astrocyte#Calcium_waves\">propagate info signals</a>, this is not a trivial claim and would vastly increase the processing power of the brain. But when it has actually been measured, the ratio of glial to neural cells is actually around one to one in most species, including humans (see&nbsp;<a href=\"http://neurocritic.blogspot.com/2009/09/fact-or-fiction-there-ten-times-more.html\">here</a>&nbsp;and&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19226510\">here</a>).&nbsp;</p>\n<p><strong>Counterpoint: Categories we use to explain the function of our bodies have tended to be more arbitrary than we recognize</strong></p>\n<p><strong></strong>1) One active area of research is in determining whether the distinguishing characteristics between what we consider cell \"types\" are more quantitative or qualitative (i.e.,&nbsp;<em>degree</em> rather than form). Consider, for example, <a href=\"http://www.biomedcentral.com/1471-2407/10/112\">the continuum</a> between the \"classical\" m1 and \"alternative\" m2 macrophages, which contributes whether those immune cells will be pro- or anti-tumor. Or consider <a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0007708\">the gradient of pluripotency</a> in stem cells. If cell types are on a spectrum, depending upon the sort of transcripts or proteins they contain at any given moment, that suggests that they may be able to have more different sorts of interactions at different points in time.</p>\n<p>2) Although we found fewer human genes than most geneticists expected, components of genes (<a href=\"http://en.wikipedia.org/wiki/Exon\">exons</a>) have been found to be able to combine in many ways, a phenomenon called <a href=\"http://en.wikipedia.org/wiki/Alternative_splicing\">alternative splicing</a>. One article (<a href=\"http://genome.cshlp.org/content/early/2011/05/02/gr.116335.110.abstract\">here</a>) found that of genes with multiple exons, more than 90% are alternatively spliced. Specifically, these researchers found ~67,000 alternatively spliced transcripts from ~20,000 genes. Since these alternatively spliced genes have different nucleic acid sequences, they could (and probably do) have quite different functions.&nbsp;</p>\n<p>3) The chromatin state of a given portion of the genome, i.e. where it falls on the spectrum of euchromatic vs heterochromatic, seems to have the ability to explain a large percentage of a variance in whether or not that gene is expressed. For example, one study (<a href=\"http://www.nature.com/ng/journal/v43/n3/full/ng.759.html\">here</a>) shows a strikingly high correlation between the ability of one transcription factor to bind to DNA and the chromatin state of that region of DNA (check figure 3). The fact that these chromatin states can be transmitted between generations via germ cells is also a fascinating finding that has implications which increase the complexity of human biology as compared to the \"static DNA\" model.&nbsp;</p>\n<p><strong>Synthesis: When to expect more or less complexity</strong></p>\n<p>The above is far from systematic, but I think it portrays the trends.&nbsp;The known unknowns have tended to end up lower in complexity than we've predicted. But unknown unknowns continue to blindside us, unabated, adding to the total complexity of the human body.&nbsp;</p>\n<p>Why do we tend to over-estimate the complexity of known unknowns in the human body? People who study biological processes want to find more \"degrees of freedom\" in their systems, so that the phenomenon they're studying can have more explanatory power. The standard reason for this is that they want their results to have an impact in preventing or curing diseases, while the cynical (\"Hansonian\") reason is that they want to attract more status and funding. The real answer is probably a mix of both, but either way, the result is that we tend to over-estimate the complexity of the known unknowns.&nbsp;</p>\n<p>Why does it take so long to recognize the vast number of unknown unknowns? I think the best explanation for this is the standard, \"Kuhnian\" one, that&nbsp;shifting a paradigm is difficult. Adding an entirely new facet to any established scientific discipline requires slow-moving institutional support, and human biology is no exception. Look, for example, at the&nbsp;<a href=\"http://sites.lafayette.edu/neur401-sp10/what-is-neurogenesis/a-timeline-of-research-adult-mammalian-neurogenesis/\">history of neurogenesis</a>. Another explanation is technological, that we just don't have the capacity to observe certain things until we reach a given level of engineering success. We&nbsp;<em>could</em>&nbsp;not have known about histone-based epigenetics until we had the capacity to visualize cells at the level of electron microscopy (see&nbsp;<a href=\"http://www.bowdoin.edu/faculty/a/aolins/dissemination/Nature_rev.pdf\">pdf</a>). &nbsp;</p>\n<p>The next time someone uses an argument like \"the human body is so complex,\" try to notice whether they are referring to a prediction about the way that the human body and biology work in general, or one particular aspect of the human body. If they're referring to the general issue, at scales from the atomic to the molecular to the tissue level, they're right: there's loads we don't understand and probably lots of important stuff we don't even know about. But if they're referring to a particular as-of-yet unmeasurable aspect of the human body, past history suggests that that particular phenomenon is likely to be&nbsp;<em>less</em>&nbsp;complex than you might guess.&nbsp;</p>\n<p><strong>References</strong></p>\n<p>Kandel, E.&nbsp;In Search of Memory: The Emergence of a New Science of Mind. <a href=\"http://www.amazon.com/Search-Memory-Emergence-Science-Mind/dp/0393058638\">amazon</a>.&nbsp;</p>\n<p>Pennisi, A. 2003 Low Number Wins the GeneSweep Pool. <a href=\"http://www.sciencemag.org/content/300/5625/1484.2.full\">abstract</a>. &nbsp;&nbsp;</p>\n<p>Human Genome Information Project. 2008 How Many Genes Are in the Human Genome?. <a href=\"http://www.ornl.gov/sci/techresources/Human_Genome/faq/genenumber.shtml\">link</a>.&nbsp;</p>\n<p>Pellicer J. 2010&nbsp;The largest eukaryotic genome of them all? <a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1095-8339.2010.01072.x/full\">abstract</a>. doi:&nbsp;10.1111/j.1095-8339.2010.01072.x</p>\n<p>Kandel E, et al.&nbsp;Principles of Neural Science. <a href=\"http://www.amazon.com/Principles-Neural-Science-Eric-Kandel/dp/0838577016\">amazon</a>.&nbsp;</p>\n<p>Azevedo FA, et al. 2009 Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain.&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19226510\">pubmed</a>.&nbsp;</p>\n<p>Ma J, et al. 2010 The M1 form of tumor-associated macrophages in non-small cell lung cancer is positively associated with survival time.&nbsp;<a href=\"http://www.biomedcentral.com/1471-2407/10/112\">doi:10.1186/1471-2407-10-112</a></p>\n<p>Hough SR, Laslett AL, Grimmond SB, Kolle G, Pera MF (2009) A Continuum of Cell States Spans Pluripotency and Lineage Commitment in Human Embryonic Stem Cells. PLoS ONE 4(11): e7708. <a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0007708\">doi:10.1371/journal.pone.0007708</a></p>\n<p>Toung JM. 2011 RNA-sequence analysis of human B-cells.&nbsp;<a href=\"http://genome.cshlp.org/content/early/2011/05/02/gr.116335.110.abstract\">abstract</a>.&nbsp;doi:10.1101/gr.116335.110</p>\n<p>John S, et al. 2011 Chromatin accessibility pre-determines glucocorticoid receptor binding patterns. <a href=\"http://www.nature.com/ng/journal/v43/n3/full/ng.759.html\">doi:10.1038/ng.759</a>.</p>\n<p>Olins DE and Olins AL. 2003&nbsp;Chromatin history: our view from the bridge, <a href=\"http://www.bowdoin.edu/faculty/a/aolins/dissemination/Nature_rev.pdf\">pdf</a>.&nbsp;</p>\n<p>Wheeler A. A Brief History and Timeline: Adult mammalian neurogenesis. <a href=\"http://sites.lafayette.edu/neur401-sp10/what-is-neurogenesis/a-timeline-of-research-adult-mammalian-neurogenesis/\">link</a>. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5FmQiv6skygRCDZEW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 19, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "10369", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>One common question: how complex is some aspect of the human body?&nbsp;In addition to <em>directly</em> evaluating the available evidence for that aspect, one fruitful tactic in making this kind of prediction is&nbsp;to analyze past predictions about similar phenomena and assume that the&nbsp;outcome will be similar. This is called&nbsp;<a href=\"http://en.wikipedia.org/wiki/Reference_class_forecasting\">reference class forecasting</a>, and is often referred to on this site as \"taking the outside view.\"&nbsp;</p>\n<p>First, how do we define complexity? Loosely, I will consider a more complex situation to be one with more components, either in total number or type, which allows for more degrees of freedom in the system considered. Using this loose definition for now, how do our predictions about human complexity tend to fare?&nbsp;</p>\n<p><strong id=\"Point__Predictions_about_concrete_things_have_tended_to_overestimate_our_complexity\">Point: Predictions about concrete things have tended to overestimate our complexity</strong></p>\n<p>Once we know about their theoretical existence of phenomenon but before they are systematically measured, our predictions about measurable traits of the human body tend to err on the side of being more complex (i.e., more extensive or variable) than reality.&nbsp;</p>\n<p>1) Although scholars throughout history have tended to think that human brains must be vastly differently from those of other animals, on the molecular and cellular level there have turned out to be few differences. As Eric Kandel relates in&nbsp;<a href=\"http://www.amazon.com/Search-Memory-Emergence-Science-Mind/dp/0393058638\">his autobiography</a>&nbsp;(p. 236), \"because human mental processes have long been thought to be unique, some early students of the brain expected to find many new classes of proteins lurking in our gray matter. Instead, science has found surprisingly few proteins that are truly unique to the human brain and no signaling systems that are unique to it.\"&nbsp;</p>\n<p>2) There turned out to be fewer protein-coding genes in human body than most people expected. We have data on this by way of an informal betting market in the early 2000's, described <a href=\"http://www.sciencemag.org/content/300/5625/1484.2.full\">here</a>&nbsp;($) and <a href=\"http://www.ornl.gov/sci/techresources/Human_Genome/faq/genenumber.shtml\">here</a> (OA). The predictions ranged from 26,000 - 150,000, and that lower bound prediction won, even though it probably wasn't low enough! As of 2008, the predicted number by <a href=\"http://useast.ensembl.org/index.html\">Ensembl</a> was in the 23,000s. (As an aside, humans don't have the largest genome in terms of number of nucleotides either, by far. That title currently belongs to the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Paris_japonica\">canopy plant</a>, pictured below (thanks to&nbsp;<a href=\"http://www.flickr.com/photos/kodamatic/4859550707/\">kodamatic</a>&nbsp;for the photo, and to&nbsp;<a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1095-8339.2010.01072.x/full\">Pellicer et al.</a>&nbsp;for the sequencing effort).)</p>\n<p><img style=\"vertical-align: middle;\" src=\"http://images.lesswrong.com/t3_801_0.png\" alt=\"\" width=\"500\" height=\"371\"></p>\n<p>3) Intro neuro texts (including&nbsp;<a href=\"http://www.amazon.com/Principles-Neural-Science-Eric-Kandel/dp/0838577016\">one co-written by the aforementioned Kandel</a>) claim that there are 10-fold (or more) more glia cells than neurons in the human brain. Since glia play crucial support roles and can even&nbsp;<a href=\"http://en.wikipedia.org/wiki/Astrocyte#Calcium_waves\">propagate info signals</a>, this is not a trivial claim and would vastly increase the processing power of the brain. But when it has actually been measured, the ratio of glial to neural cells is actually around one to one in most species, including humans (see&nbsp;<a href=\"http://neurocritic.blogspot.com/2009/09/fact-or-fiction-there-ten-times-more.html\">here</a>&nbsp;and&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19226510\">here</a>).&nbsp;</p>\n<p><strong id=\"Counterpoint__Categories_we_use_to_explain_the_function_of_our_bodies_have_tended_to_be_more_arbitrary_than_we_recognize\">Counterpoint: Categories we use to explain the function of our bodies have tended to be more arbitrary than we recognize</strong></p>\n<p><strong></strong>1) One active area of research is in determining whether the distinguishing characteristics between what we consider cell \"types\" are more quantitative or qualitative (i.e.,&nbsp;<em>degree</em> rather than form). Consider, for example, <a href=\"http://www.biomedcentral.com/1471-2407/10/112\">the continuum</a> between the \"classical\" m1 and \"alternative\" m2 macrophages, which contributes whether those immune cells will be pro- or anti-tumor. Or consider <a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0007708\">the gradient of pluripotency</a> in stem cells. If cell types are on a spectrum, depending upon the sort of transcripts or proteins they contain at any given moment, that suggests that they may be able to have more different sorts of interactions at different points in time.</p>\n<p>2) Although we found fewer human genes than most geneticists expected, components of genes (<a href=\"http://en.wikipedia.org/wiki/Exon\">exons</a>) have been found to be able to combine in many ways, a phenomenon called <a href=\"http://en.wikipedia.org/wiki/Alternative_splicing\">alternative splicing</a>. One article (<a href=\"http://genome.cshlp.org/content/early/2011/05/02/gr.116335.110.abstract\">here</a>) found that of genes with multiple exons, more than 90% are alternatively spliced. Specifically, these researchers found ~67,000 alternatively spliced transcripts from ~20,000 genes. Since these alternatively spliced genes have different nucleic acid sequences, they could (and probably do) have quite different functions.&nbsp;</p>\n<p>3) The chromatin state of a given portion of the genome, i.e. where it falls on the spectrum of euchromatic vs heterochromatic, seems to have the ability to explain a large percentage of a variance in whether or not that gene is expressed. For example, one study (<a href=\"http://www.nature.com/ng/journal/v43/n3/full/ng.759.html\">here</a>) shows a strikingly high correlation between the ability of one transcription factor to bind to DNA and the chromatin state of that region of DNA (check figure 3). The fact that these chromatin states can be transmitted between generations via germ cells is also a fascinating finding that has implications which increase the complexity of human biology as compared to the \"static DNA\" model.&nbsp;</p>\n<p><strong id=\"Synthesis__When_to_expect_more_or_less_complexity\">Synthesis: When to expect more or less complexity</strong></p>\n<p>The above is far from systematic, but I think it portrays the trends.&nbsp;The known unknowns have tended to end up lower in complexity than we've predicted. But unknown unknowns continue to blindside us, unabated, adding to the total complexity of the human body.&nbsp;</p>\n<p>Why do we tend to over-estimate the complexity of known unknowns in the human body? People who study biological processes want to find more \"degrees of freedom\" in their systems, so that the phenomenon they're studying can have more explanatory power. The standard reason for this is that they want their results to have an impact in preventing or curing diseases, while the cynical (\"Hansonian\") reason is that they want to attract more status and funding. The real answer is probably a mix of both, but either way, the result is that we tend to over-estimate the complexity of the known unknowns.&nbsp;</p>\n<p>Why does it take so long to recognize the vast number of unknown unknowns? I think the best explanation for this is the standard, \"Kuhnian\" one, that&nbsp;shifting a paradigm is difficult. Adding an entirely new facet to any established scientific discipline requires slow-moving institutional support, and human biology is no exception. Look, for example, at the&nbsp;<a href=\"http://sites.lafayette.edu/neur401-sp10/what-is-neurogenesis/a-timeline-of-research-adult-mammalian-neurogenesis/\">history of neurogenesis</a>. Another explanation is technological, that we just don't have the capacity to observe certain things until we reach a given level of engineering success. We&nbsp;<em>could</em>&nbsp;not have known about histone-based epigenetics until we had the capacity to visualize cells at the level of electron microscopy (see&nbsp;<a href=\"http://www.bowdoin.edu/faculty/a/aolins/dissemination/Nature_rev.pdf\">pdf</a>). &nbsp;</p>\n<p>The next time someone uses an argument like \"the human body is so complex,\" try to notice whether they are referring to a prediction about the way that the human body and biology work in general, or one particular aspect of the human body. If they're referring to the general issue, at scales from the atomic to the molecular to the tissue level, they're right: there's loads we don't understand and probably lots of important stuff we don't even know about. But if they're referring to a particular as-of-yet unmeasurable aspect of the human body, past history suggests that that particular phenomenon is likely to be&nbsp;<em>less</em>&nbsp;complex than you might guess.&nbsp;</p>\n<p><strong id=\"References\">References</strong></p>\n<p>Kandel, E.&nbsp;In Search of Memory: The Emergence of a New Science of Mind. <a href=\"http://www.amazon.com/Search-Memory-Emergence-Science-Mind/dp/0393058638\">amazon</a>.&nbsp;</p>\n<p>Pennisi, A. 2003 Low Number Wins the GeneSweep Pool. <a href=\"http://www.sciencemag.org/content/300/5625/1484.2.full\">abstract</a>. &nbsp;&nbsp;</p>\n<p>Human Genome Information Project. 2008 How Many Genes Are in the Human Genome?. <a href=\"http://www.ornl.gov/sci/techresources/Human_Genome/faq/genenumber.shtml\">link</a>.&nbsp;</p>\n<p>Pellicer J. 2010&nbsp;The largest eukaryotic genome of them all? <a href=\"http://onlinelibrary.wiley.com/doi/10.1111/j.1095-8339.2010.01072.x/full\">abstract</a>. doi:&nbsp;10.1111/j.1095-8339.2010.01072.x</p>\n<p>Kandel E, et al.&nbsp;Principles of Neural Science. <a href=\"http://www.amazon.com/Principles-Neural-Science-Eric-Kandel/dp/0838577016\">amazon</a>.&nbsp;</p>\n<p>Azevedo FA, et al. 2009 Equal numbers of neuronal and nonneuronal cells make the human brain an isometrically scaled-up primate brain.&nbsp;<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/19226510\">pubmed</a>.&nbsp;</p>\n<p>Ma J, et al. 2010 The M1 form of tumor-associated macrophages in non-small cell lung cancer is positively associated with survival time.&nbsp;<a href=\"http://www.biomedcentral.com/1471-2407/10/112\">doi:10.1186/1471-2407-10-112</a></p>\n<p>Hough SR, Laslett AL, Grimmond SB, Kolle G, Pera MF (2009) A Continuum of Cell States Spans Pluripotency and Lineage Commitment in Human Embryonic Stem Cells. PLoS ONE 4(11): e7708. <a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0007708\">doi:10.1371/journal.pone.0007708</a></p>\n<p>Toung JM. 2011 RNA-sequence analysis of human B-cells.&nbsp;<a href=\"http://genome.cshlp.org/content/early/2011/05/02/gr.116335.110.abstract\">abstract</a>.&nbsp;doi:10.1101/gr.116335.110</p>\n<p>John S, et al. 2011 Chromatin accessibility pre-determines glucocorticoid receptor binding patterns. <a href=\"http://www.nature.com/ng/journal/v43/n3/full/ng.759.html\">doi:10.1038/ng.759</a>.</p>\n<p>Olins DE and Olins AL. 2003&nbsp;Chromatin history: our view from the bridge, <a href=\"http://www.bowdoin.edu/faculty/a/aolins/dissemination/Nature_rev.pdf\">pdf</a>.&nbsp;</p>\n<p>Wheeler A. A Brief History and Timeline: Adult mammalian neurogenesis. <a href=\"http://sites.lafayette.edu/neur401-sp10/what-is-neurogenesis/a-timeline-of-research-adult-mammalian-neurogenesis/\">link</a>. &nbsp;</p>", "sections": [{"title": "Point: Predictions about concrete things have tended to overestimate our complexity", "anchor": "Point__Predictions_about_concrete_things_have_tended_to_overestimate_our_complexity", "level": 1}, {"title": "Counterpoint: Categories we use to explain the function of our bodies have tended to be more arbitrary than we recognize", "anchor": "Counterpoint__Categories_we_use_to_explain_the_function_of_our_bodies_have_tended_to_be_more_arbitrary_than_we_recognize", "level": 1}, {"title": "Synthesis: When to expect more or less complexity", "anchor": "Synthesis__When_to_expect_more_or_less_complexity", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-09T03:00:59.893Z", "modifiedAt": null, "url": null, "title": "What to do after college?", "slug": "what-to-do-after-college", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:16.898Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "mtaran", "createdAt": "2009-03-01T03:59:15.397Z", "isAdmin": false, "displayName": "mtaran"}, "userId": "En3rJXsxKr3AFNjLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/34fDL6w3QXQYJCacn/what-to-do-after-college", "pageUrlRelative": "/posts/34fDL6w3QXQYJCacn/what-to-do-after-college", "linkUrl": "https://www.lesswrong.com/posts/34fDL6w3QXQYJCacn/what-to-do-after-college", "postedAtFormatted": "Sunday, October 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20to%20do%20after%20college%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20to%20do%20after%20college%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34fDL6w3QXQYJCacn%2Fwhat-to-do-after-college%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20to%20do%20after%20college%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34fDL6w3QXQYJCacn%2Fwhat-to-do-after-college", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F34fDL6w3QXQYJCacn%2Fwhat-to-do-after-college", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 122, "htmlBody": "<p>My friend is looking for some advice on what he should do after graduating from <a href=\"http://en.wikipedia.org/wiki/Harvey_Mudd_College\">Harvey Mudd College</a>. Some relevant bits of information about him are that he</p>\n<p>&nbsp;</p>\n<ul>\n<li>is not a US citizen, so he'd only be able to stay in the US if he's working or at a grad school. He's open to suggestions for other countries.</li>\n<li>is great at math and computer science, including doing real-world programming</li>\n<li>wants to help the world</li>\n</ul>\n<p>He's currently looking for a grad school where he could tackle interesting problems with possible high benefits in the future. I've made my own suggestions, but I'd like to get a (somewhat) independent set of opinions from the LW community.</p>\n<p>So please suggest away!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "34fDL6w3QXQYJCacn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 7.812248686870541e-07, "legacy": true, "legacyId": "10376", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-09T03:07:57.819Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Why Are Individual IQ Differences OK?", "slug": "seq-rerun-why-are-individual-iq-differences-ok", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.377Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4QNZbLT68BE4GBQLS/seq-rerun-why-are-individual-iq-differences-ok", "pageUrlRelative": "/posts/4QNZbLT68BE4GBQLS/seq-rerun-why-are-individual-iq-differences-ok", "linkUrl": "https://www.lesswrong.com/posts/4QNZbLT68BE4GBQLS/seq-rerun-why-are-individual-iq-differences-ok", "postedAtFormatted": "Sunday, October 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Why%20Are%20Individual%20IQ%20Differences%20OK%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Why%20Are%20Individual%20IQ%20Differences%20OK%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4QNZbLT68BE4GBQLS%2Fseq-rerun-why-are-individual-iq-differences-ok%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Why%20Are%20Individual%20IQ%20Differences%20OK%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4QNZbLT68BE4GBQLS%2Fseq-rerun-why-are-individual-iq-differences-ok", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4QNZbLT68BE4GBQLS%2Fseq-rerun-why-are-individual-iq-differences-ok", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 191, "htmlBody": "<p>Today's post, <a href=\"/lw/kk/why_are_individual_iq_differences_ok/\">Why Are Individual IQ Differences OK?</a> was originally published on 26 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Why_Are_Individual_IQ_Differences_OK.3F\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>People act as though it is perfectly fine and normal for individuals to have differing levels of intelligence, but that it is absolutely horrible for one racial group to be more intelligent than another. Why should the two be considered any differently?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/7zk/seq_rerun_no_one_knows_what_science_doesnt_know/\">No One Knows What Science Doesn't Know</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4QNZbLT68BE4GBQLS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 19, "extendedScore": null, "score": 7.812272327052571e-07, "legacy": true, "legacyId": "10377", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 119, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["faHbrHuPziFH7Ef7p", "njXqohppPZZM5xQMK", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-09T13:00:00.084Z", "modifiedAt": null, "url": null, "title": "A few analogies to illustrate key rationality points", "slug": "a-few-analogies-to-illustrate-key-rationality-points", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:09.135Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kilobug", "createdAt": "2011-09-02T14:37:51.213Z", "isAdmin": false, "displayName": "kilobug"}, "userId": "7BQMuDSmLE2XRq2ph", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/senPehgyNk2DCYPKM/a-few-analogies-to-illustrate-key-rationality-points", "pageUrlRelative": "/posts/senPehgyNk2DCYPKM/a-few-analogies-to-illustrate-key-rationality-points", "linkUrl": "https://www.lesswrong.com/posts/senPehgyNk2DCYPKM/a-few-analogies-to-illustrate-key-rationality-points", "postedAtFormatted": "Sunday, October 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20few%20analogies%20to%20illustrate%20key%20rationality%20points&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20few%20analogies%20to%20illustrate%20key%20rationality%20points%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsenPehgyNk2DCYPKM%2Fa-few-analogies-to-illustrate-key-rationality-points%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20few%20analogies%20to%20illustrate%20key%20rationality%20points%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsenPehgyNk2DCYPKM%2Fa-few-analogies-to-illustrate-key-rationality-points", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsenPehgyNk2DCYPKM%2Fa-few-analogies-to-illustrate-key-rationality-points", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1643, "htmlBody": "<h2>Introduction<br /></h2>\n<p>Due to <a href=\"/lw/kg/expecting_short_inferential_distances\">long inferential distances</a> it's often very difficult to use knowledge or understanding given by rationality in a discussion with someone who isn't versed in the Art (like, a poor folk who didn't read the Sequences, or maybe even not the <em>Goedel, Escher, Bach</em> !). So I find myself often forced to use analogies, that will necessary be more-or-less surface analogies, which don't prove anything nor give any technical understanding, but allow someone to have a grasp on a complicated issue in a few minutes.</p>\n<h2>A tale of chess and politics</h2>\n<p>Once upon a time, a boat sank and a group of people found themselves isolated in an island. None of them knew the rules of the game \"chess\", but there was a solar-powered portable chess computer on the boat. A very simple one, with no AI, but which would enforce the rules. Quickly, the survivors discovered the joy of chess, deducing the rules by trying moves, and seeing the computer saying \"illegal move\" or \"legal move\", seeing it proclaiming victory, defeat or draw game.</p>\n<p>So they learned the rules of chess, movement of the pieces, what \"chess\" and \"chessmate\" is, how you can promote pawns, ... And they understood the planning and strategy skills required to win the game. So chess became linked to politics, it was the Game, with a capital letter, and every year, they would organize a chess tournament, and the winner, the smartest of the community, would become the leader for one year.</p>\n<p>One sunny day, a young fellow named Hari playing with his brother Salvor (yes, I'm an Asimov fan), discovered a new move of chess : he discovered he could castle. In one move, he could liberate his rook, and protect his king. They kept the discovery secret, and used it on the tournament. Winning his games, Hari became the leader.</p>\n<p>Soon after, people started to use the power of castling as much as they could. They even sacrificed pieces, even their queen, just to be able to castle fast. But everyone was trying to castle as fast as they could, and they were losing sight of the final goal : winning, for the intermediate goal : castling.<a id=\"more\"></a></p>\n<p>After a few years, another young fellow, who always hated Hari and Salvor, Wienis, realized how mad people had become with castling. So he decides to never castle anymore, and managed to win the tournament.</p>\n<p>Starting from this day, the community split in two : the Castlers and the anti-Castlers. The first would always try to castle, the others never. And if you advised to a Castler than in this specific situation he shouldn't castle, he would label you \"anti-Castler\" and stop listening to you. And if you advised an anti-Castler to castle in this specific situation, he would label you \"Castler\" and stop listening to you.</p>\n<p>That tale illustrates a very frequent situation in politics : something is discovered which leads to great results, but then is mistaken for a final goal instead of an intermediate goal, and used even when it doesn't serve the final goal. Then some people, in reaction, oppose the whole thing, and the world is cut between the \"pro\" and the \"anti\". I used this tale to argue with someone saying to me \"but you're a productivist\", and it worked quite well to get my point : productivism can lead to huge increases in quality of life, but if it gets mistaken for a final goal (as many people do now, using GDP and economical growth as ultimate measures of success/failure), it leads to disasters (ecological destruction, dangerous or very painful working conditions, disregard of fundamental research over short term research, ...). And people are either categorized as \"productivists\" or \"anti-productivists\". But it could apply to many others things, like free market/free trade.</p>\n<h2>The North Pole analogy<br /></h2>\n<p>Well, that one isn't any new, I'm using since like a decade, and I'm probably not the only one to use it, but it does work relatively well. It's an analogy used to answer to the \"But, what's before the Big Bang ?\" question. When I asked that, I can't just start explaining about the mathematical concept of limit, about the Plank time, about theories like timeless physics or quantum vacuum fluctuation, ... so I just answer \"What's north of the North Pole ?\". That usually works quite well to make people understand that asking what is <em>before</em> the start of <em>time</em> just doesn't have any meaning.</p>\n<h2>The alphabet and language analogy<br /></h2>\n<p>That's an analogy that I found very useful in making people understand about reductionism, single-level reality and multi-level map, the fact you can understand (more or less completely) one level without understanding another. It also works very well about brain scanning/mind upload.</p>\n<p>Take a piece of paper, with writings on it. Do words exist, I mean, really <em>exist</em> ? They are just made of letters. There is nothing more than letters, arranged in a specific way, to make words. And letters are nothing more than ink. How can consciousness arise from mere neurons ? The same way that the meaning of a text can arise from mere letters. There is only one level of reality : the ink and the paper. And the ink and paper are made of molecules, themselves made of atoms. And we can descend down to QM.</p>\n<p>Now, can we understand a level without understanding another level ? Definitely. We can recognize the letters, to be of the roman alphabet, without understanding the languages. We can know them, since we use that same alphabet daily. But if the text is in German and we don't speak German, we won't understand the next level, the one of words, nor the one of meaning.</p>\n<p>And can we understand a higher level, without understand a lower level ? If we speak Spanish and the text is in Portuguese, we may understand most of the highest level, the level of the text, without understanding every single word and grammatical rule of Portuguese. So an incomplete understanding of a lower level can give us an almost complete understanding of an higher level. Or even more obviously : even if we know nothing about the chemistry of ink and paper, we can still understand the letters and the higher levels.</p>\n<p>But what about mind upload ? &laquo; We don't understand the human brain, it's too complicated, so we'll never be able to upload minds. &raquo; Well... there are levels in the human brain, like in a text on paper. If given a text in ancient Egyptian hieroglyph, you won't get anything about the text, or won't know the letters. But still, you can duplicate it with a pen and paper, reproducing the exact drawing by hand, if you're skilled enough with a pen. Or, you can scan it, store it on a USB key, and give to an archaeologist. In both cases, you would have duplicated the meaning, without even understanding it. And if you know the alphabet, but not the language, like German for me, you can recopy it much faster, or type it instead of scanning it, leading to a much smaller file that you can send by email and not USB key.</p>\n<p>The same way, we don't need to understand human brain at all levels to be able to duplicate it, or to scan it and have it digitalized. If we only know its chemistry, we can scan it at molecule level, it'll be long and require a lot of storage, like scanning the Egyptian text to a bitmap. If we know the working of neurons, and can duplicate it at the level of individual neurons instead of individual molecules, it'll be much easier to duplicate, and require much less storage, like the German text.</p>\n<p>(There is a variant of this analogy for geeks, which is about hard disk, file system and file format. You can understand a file system without really knowing how bits are stored on the magnetic plate, and you duplicate a hard disk by doing a block copy even if you don't understand the file system.)</p>\n<h2>The Lascaux painting and trans-humanism</h2>\n<p>Speaking about trans-humanism with a fellow coworker, it reached the usual objection : &laquo; but it's death that give meaning to our life, just look at all that beautiful poetry that was written because of death and the feeling of urgency it gives &raquo;. I tried the \"<a href=\"/lw/k8/how_to_seem_and_be_deep/\">baseball bat on the head once per week</a>\" objection, but didn't really work well. So I let the issue go from transhumanism, drifted the topic to art in general, and then I asked : &laquo; Do you think we appreciate the Lascaux painting more or less than they did when they painted them, 30 000 years ago ? &raquo; and then he said &laquo; More &raquo;. And then I said &laquo; And for the same reasons, in 3 000 years, when the average life span will be counted in thousands of years (or more), they'll appreciate more what we wrote at the time of always near death. &raquo; Which partially worked, but only partially, because he admitted we would appreciate existing poetry as much, if not more, than we do now, but he still claimed that we wouldn't be able to write it anymore, and I didn't find anything as simple/strong to answer to that.</p>\n<h2>Conclusion</h2>\n<p>Arguing by analogies is very error-prone, but it's the most efficient way I found to cross inferential distances. I would like to hear your opinion and comments about both the principle of using analogies to try to break through long inferential distances. I would also like to hear what you think about those specific ones , and hear your own analogies, if you have some to share.</p>\n<p>(PS : I'm still new to Less Wrong, I'm not sure about the exact customs for making top-level posts, if you think it didn't deserve one, please tell me, and accept my apologizes).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "ZXFpyQWPB5ideFbEG": 1, "YQW2DxpZFTrqrxHBJ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "senPehgyNk2DCYPKM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 60, "baseScore": 69, "extendedScore": null, "score": 0.000136, "legacy": true, "legacyId": "10386", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 69, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Introduction\">Introduction<br></h2>\n<p>Due to <a href=\"/lw/kg/expecting_short_inferential_distances\">long inferential distances</a> it's often very difficult to use knowledge or understanding given by rationality in a discussion with someone who isn't versed in the Art (like, a poor folk who didn't read the Sequences, or maybe even not the <em>Goedel, Escher, Bach</em> !). So I find myself often forced to use analogies, that will necessary be more-or-less surface analogies, which don't prove anything nor give any technical understanding, but allow someone to have a grasp on a complicated issue in a few minutes.</p>\n<h2 id=\"A_tale_of_chess_and_politics\">A tale of chess and politics</h2>\n<p>Once upon a time, a boat sank and a group of people found themselves isolated in an island. None of them knew the rules of the game \"chess\", but there was a solar-powered portable chess computer on the boat. A very simple one, with no AI, but which would enforce the rules. Quickly, the survivors discovered the joy of chess, deducing the rules by trying moves, and seeing the computer saying \"illegal move\" or \"legal move\", seeing it proclaiming victory, defeat or draw game.</p>\n<p>So they learned the rules of chess, movement of the pieces, what \"chess\" and \"chessmate\" is, how you can promote pawns, ... And they understood the planning and strategy skills required to win the game. So chess became linked to politics, it was the Game, with a capital letter, and every year, they would organize a chess tournament, and the winner, the smartest of the community, would become the leader for one year.</p>\n<p>One sunny day, a young fellow named Hari playing with his brother Salvor (yes, I'm an Asimov fan), discovered a new move of chess : he discovered he could castle. In one move, he could liberate his rook, and protect his king. They kept the discovery secret, and used it on the tournament. Winning his games, Hari became the leader.</p>\n<p>Soon after, people started to use the power of castling as much as they could. They even sacrificed pieces, even their queen, just to be able to castle fast. But everyone was trying to castle as fast as they could, and they were losing sight of the final goal : winning, for the intermediate goal : castling.<a id=\"more\"></a></p>\n<p>After a few years, another young fellow, who always hated Hari and Salvor, Wienis, realized how mad people had become with castling. So he decides to never castle anymore, and managed to win the tournament.</p>\n<p>Starting from this day, the community split in two : the Castlers and the anti-Castlers. The first would always try to castle, the others never. And if you advised to a Castler than in this specific situation he shouldn't castle, he would label you \"anti-Castler\" and stop listening to you. And if you advised an anti-Castler to castle in this specific situation, he would label you \"Castler\" and stop listening to you.</p>\n<p>That tale illustrates a very frequent situation in politics : something is discovered which leads to great results, but then is mistaken for a final goal instead of an intermediate goal, and used even when it doesn't serve the final goal. Then some people, in reaction, oppose the whole thing, and the world is cut between the \"pro\" and the \"anti\". I used this tale to argue with someone saying to me \"but you're a productivist\", and it worked quite well to get my point : productivism can lead to huge increases in quality of life, but if it gets mistaken for a final goal (as many people do now, using GDP and economical growth as ultimate measures of success/failure), it leads to disasters (ecological destruction, dangerous or very painful working conditions, disregard of fundamental research over short term research, ...). And people are either categorized as \"productivists\" or \"anti-productivists\". But it could apply to many others things, like free market/free trade.</p>\n<h2 id=\"The_North_Pole_analogy\">The North Pole analogy<br></h2>\n<p>Well, that one isn't any new, I'm using since like a decade, and I'm probably not the only one to use it, but it does work relatively well. It's an analogy used to answer to the \"But, what's before the Big Bang ?\" question. When I asked that, I can't just start explaining about the mathematical concept of limit, about the Plank time, about theories like timeless physics or quantum vacuum fluctuation, ... so I just answer \"What's north of the North Pole ?\". That usually works quite well to make people understand that asking what is <em>before</em> the start of <em>time</em> just doesn't have any meaning.</p>\n<h2 id=\"The_alphabet_and_language_analogy\">The alphabet and language analogy<br></h2>\n<p>That's an analogy that I found very useful in making people understand about reductionism, single-level reality and multi-level map, the fact you can understand (more or less completely) one level without understanding another. It also works very well about brain scanning/mind upload.</p>\n<p>Take a piece of paper, with writings on it. Do words exist, I mean, really <em>exist</em> ? They are just made of letters. There is nothing more than letters, arranged in a specific way, to make words. And letters are nothing more than ink. How can consciousness arise from mere neurons ? The same way that the meaning of a text can arise from mere letters. There is only one level of reality : the ink and the paper. And the ink and paper are made of molecules, themselves made of atoms. And we can descend down to QM.</p>\n<p>Now, can we understand a level without understanding another level ? Definitely. We can recognize the letters, to be of the roman alphabet, without understanding the languages. We can know them, since we use that same alphabet daily. But if the text is in German and we don't speak German, we won't understand the next level, the one of words, nor the one of meaning.</p>\n<p>And can we understand a higher level, without understand a lower level ? If we speak Spanish and the text is in Portuguese, we may understand most of the highest level, the level of the text, without understanding every single word and grammatical rule of Portuguese. So an incomplete understanding of a lower level can give us an almost complete understanding of an higher level. Or even more obviously : even if we know nothing about the chemistry of ink and paper, we can still understand the letters and the higher levels.</p>\n<p>But what about mind upload ? \u00ab We don't understand the human brain, it's too complicated, so we'll never be able to upload minds. \u00bb Well... there are levels in the human brain, like in a text on paper. If given a text in ancient Egyptian hieroglyph, you won't get anything about the text, or won't know the letters. But still, you can duplicate it with a pen and paper, reproducing the exact drawing by hand, if you're skilled enough with a pen. Or, you can scan it, store it on a USB key, and give to an archaeologist. In both cases, you would have duplicated the meaning, without even understanding it. And if you know the alphabet, but not the language, like German for me, you can recopy it much faster, or type it instead of scanning it, leading to a much smaller file that you can send by email and not USB key.</p>\n<p>The same way, we don't need to understand human brain at all levels to be able to duplicate it, or to scan it and have it digitalized. If we only know its chemistry, we can scan it at molecule level, it'll be long and require a lot of storage, like scanning the Egyptian text to a bitmap. If we know the working of neurons, and can duplicate it at the level of individual neurons instead of individual molecules, it'll be much easier to duplicate, and require much less storage, like the German text.</p>\n<p>(There is a variant of this analogy for geeks, which is about hard disk, file system and file format. You can understand a file system without really knowing how bits are stored on the magnetic plate, and you duplicate a hard disk by doing a block copy even if you don't understand the file system.)</p>\n<h2 id=\"The_Lascaux_painting_and_trans_humanism\">The Lascaux painting and trans-humanism</h2>\n<p>Speaking about trans-humanism with a fellow coworker, it reached the usual objection : \u00ab but it's death that give meaning to our life, just look at all that beautiful poetry that was written because of death and the feeling of urgency it gives \u00bb. I tried the \"<a href=\"/lw/k8/how_to_seem_and_be_deep/\">baseball bat on the head once per week</a>\" objection, but didn't really work well. So I let the issue go from transhumanism, drifted the topic to art in general, and then I asked : \u00ab Do you think we appreciate the Lascaux painting more or less than they did when they painted them, 30 000 years ago ? \u00bb and then he said \u00ab More \u00bb. And then I said \u00ab And for the same reasons, in 3 000 years, when the average life span will be counted in thousands of years (or more), they'll appreciate more what we wrote at the time of always near death. \u00bb Which partially worked, but only partially, because he admitted we would appreciate existing poetry as much, if not more, than we do now, but he still claimed that we wouldn't be able to write it anymore, and I didn't find anything as simple/strong to answer to that.</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>Arguing by analogies is very error-prone, but it's the most efficient way I found to cross inferential distances. I would like to hear your opinion and comments about both the principle of using analogies to try to break through long inferential distances. I would also like to hear what you think about those specific ones , and hear your own analogies, if you have some to share.</p>\n<p>(PS : I'm still new to Less Wrong, I'm not sure about the exact customs for making top-level posts, if you think it didn't deserve one, please tell me, and accept my apologizes).</p>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "A tale of chess and politics", "anchor": "A_tale_of_chess_and_politics", "level": 1}, {"title": "The North Pole analogy", "anchor": "The_North_Pole_analogy", "level": 1}, {"title": "The alphabet and language analogy", "anchor": "The_alphabet_and_language_analogy", "level": 1}, {"title": "The Lascaux painting and trans-humanism", "anchor": "The_Lascaux_painting_and_trans_humanism", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "52 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HLqWn5LASfhhArZ7w", "aSQy7yHj6nPD44RNo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-09T16:52:21.519Z", "modifiedAt": null, "url": null, "title": "First, they must be convinced to play the game", "slug": "first-they-must-be-convinced-to-play-the-game", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.068Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lavalamp", "createdAt": "2009-04-16T17:40:52.495Z", "isAdmin": false, "displayName": "lavalamp"}, "userId": "eAtTnhxH9y8suzqrf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mjeuzYq8Kn56rDeX4/first-they-must-be-convinced-to-play-the-game", "pageUrlRelative": "/posts/mjeuzYq8Kn56rDeX4/first-they-must-be-convinced-to-play-the-game", "linkUrl": "https://www.lesswrong.com/posts/mjeuzYq8Kn56rDeX4/first-they-must-be-convinced-to-play-the-game", "postedAtFormatted": "Sunday, October 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%2C%20they%20must%20be%20convinced%20to%20play%20the%20game&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%2C%20they%20must%20be%20convinced%20to%20play%20the%20game%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmjeuzYq8Kn56rDeX4%2Ffirst-they-must-be-convinced-to-play-the-game%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%2C%20they%20must%20be%20convinced%20to%20play%20the%20game%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmjeuzYq8Kn56rDeX4%2Ffirst-they-must-be-convinced-to-play-the-game", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmjeuzYq8Kn56rDeX4%2Ffirst-they-must-be-convinced-to-play-the-game", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 382, "htmlBody": "<p>I recall seeing, in one of the AI-boxing discussion threads, a comment to the effect that the first step for EY to get out was to convince the other party to even play the game at all.</p>\n<p>It has since then occurred to me that this applies to a lot of my interactions. Many people who know me IRL and know a belief of mine which they do not agree with and do not want to be convinced of often adopt the strategy of not talking with me about it at all. For me to convince one of these people of something, first I have to convince them to talk about it at all.</p>\n<p>(Note, I don't think this is because I'm an unpleasant person to converse with. Excuses given are along the lines of \"I never win an argument with you\" and \"you've studied it a lot more than I have, it's an unfair discussion\". I don't think I'm claiming anything too outlandish here; average humans are really bad at putting rational arguments together.)</p>\n<p>I suppose the general form is: in order to convince someone of a sufficiently alien (to them) P, first you must convince them to seriously think about P. This rule may need to be applied recursively (e.g., \"seriously think about P\" may require one or more LW rationality techniques).</p>\n<p>As a practical example, my parents are very religious. I'd like to convince them to sign up for cryonics. I haven't (yet) come up with an approach that I expect to have a non-negligible chance of success. But the realization that the first goalpost along the way is to get them to seriously engage in the conversation at all simplifies the search space. (Deconversion and training in LW rationality has, of course, the best chance of success--but still a high chance of failing and I judge a failure would probably have a large negative impact on my relationship with my parents in their remaining years. That's why I'd like to convince them of just this one thing.)</p>\n<p>I realize that this is a fairly obvious point (an application of this--raising the sanity waterline--is the point behind this entire site!), but I haven't seen this explicitly noted as being a general pattern and now that I note it, I see it everywhere--hence this post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mjeuzYq8Kn56rDeX4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 24, "extendedScore": null, "score": 7.815071171248896e-07, "legacy": true, "legacyId": "10387", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-09T18:35:20.833Z", "modifiedAt": null, "url": null, "title": "Motivated skepticism: it's harder to avoid than I'd think", "slug": "motivated-skepticism-it-s-harder-to-avoid-than-i-d-think", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:05.801Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Klao", "createdAt": "2011-09-08T21:42:31.537Z", "isAdmin": false, "displayName": "Klao"}, "userId": "vw5ScQXYbwYAi5kNp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aTYWYCxKCfLEovmTA/motivated-skepticism-it-s-harder-to-avoid-than-i-d-think", "pageUrlRelative": "/posts/aTYWYCxKCfLEovmTA/motivated-skepticism-it-s-harder-to-avoid-than-i-d-think", "linkUrl": "https://www.lesswrong.com/posts/aTYWYCxKCfLEovmTA/motivated-skepticism-it-s-harder-to-avoid-than-i-d-think", "postedAtFormatted": "Sunday, October 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Motivated%20skepticism%3A%20it's%20harder%20to%20avoid%20than%20I'd%20think&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMotivated%20skepticism%3A%20it's%20harder%20to%20avoid%20than%20I'd%20think%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaTYWYCxKCfLEovmTA%2Fmotivated-skepticism-it-s-harder-to-avoid-than-i-d-think%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Motivated%20skepticism%3A%20it's%20harder%20to%20avoid%20than%20I'd%20think%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaTYWYCxKCfLEovmTA%2Fmotivated-skepticism-it-s-harder-to-avoid-than-i-d-think", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaTYWYCxKCfLEovmTA%2Fmotivated-skepticism-it-s-harder-to-avoid-than-i-d-think", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 360, "htmlBody": "<address><span style=\"font-style: italic;\">(I am relatively new here. Allow me to introduce myself with this anecdote, which could not have happened to me before I started reading LW.)</span></address>\n<p>&nbsp;</p>\n<p>Yesterday I caught myself on rationalizing. It's the first time I caught myself on rationalizing <em>before</em> I finished (verbalizing) the thought. But, I finished the thought, and even though I knew it was rationalizing from the very start, I ended up believing it.</p>\n<p>The original question is not very interesting, but here it is to illustrate the issue: I was talking with a friend about US TV series. And he mentioned that his wife insist on watching movies/shows in English without subtitles; to improve their English skills. (I also started watching American shows many-many years ago with the purpose of improving language skills. In English with English subtitles. And it did help immensely, but I never got rid of the subtitles even though originally I was planning to.)</p>\n<p>So, my though answer was the following: \"How does she know that this helps <em>more</em> than watching with subtitles? Did she measure it somehow? &nbsp;Watching without subtitles mainly helps with listening comprehension. And I'm already good enough with that. Using subtitles on the other hand is always an opportunity to improve on the more obscure part of English vocabulary. In almost every episode there is one or two very rarely used words, English vocabulary is just so enormous, and without subtitles you'd just skip over it...\" &nbsp;Fully verbalized it was something like this.</p>\n<p>Now, the first part of that argument is a \"fully general counterargument\". And the rest of it, though might be plausible, should be treated with great suspicion since I know that the roots for it are in motivated skepticism. At least, my realization that this is rationalization stopped me from using this argument. But, it is still quite hard to \"unbelieve\" it. Maybe I should have tried to stop myself from finishing the thought once I realized its nature? Or you just have to pay even more attention, and it will come with practice? &nbsp;Of course, this is a trivial issue, completely unimportant. But why would I think that it will be <em>easier</em> if the issue <em>is</em> important?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 2, "iP2X4jQNHMWHRNPne": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aTYWYCxKCfLEovmTA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 27, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "10388", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-09T23:26:01.432Z", "modifiedAt": null, "url": null, "title": "Calibrate your self-assessments", "slug": "calibrate-your-self-assessments", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:31.764Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aPrCzeFfbBmRsvzby/calibrate-your-self-assessments", "pageUrlRelative": "/posts/aPrCzeFfbBmRsvzby/calibrate-your-self-assessments", "linkUrl": "https://www.lesswrong.com/posts/aPrCzeFfbBmRsvzby/calibrate-your-self-assessments", "postedAtFormatted": "Sunday, October 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Calibrate%20your%20self-assessments&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACalibrate%20your%20self-assessments%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaPrCzeFfbBmRsvzby%2Fcalibrate-your-self-assessments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Calibrate%20your%20self-assessments%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaPrCzeFfbBmRsvzby%2Fcalibrate-your-self-assessments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaPrCzeFfbBmRsvzby%2Fcalibrate-your-self-assessments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1934, "htmlBody": "<p>When I moved to Ireland, I knew that their school system, and in particular their examinations, would be different from the ones I was used to. I educated myself on them and by the time I took my first exam I thought I was reasonably prepared.<br /><br />I walked out of my first examination almost certain I had failed. I remember emailing my parents, apologizing to them for my failure and promising I would do better when I repeated the class.<br /><br />Then I got my results back, and learned I had passed with honors.<br /><br />This situation repeated itself with depressing regularity over the next few semesters. Took exam, walked out in tears certain I had failed, made angsty complaints and apologies, got results back, celebrated. Eventually I decided that I might as well skip steps two to five and go straight to the celebrations.<br /><br />This was harder than I expected. Just knowing that my feelings of abject failure usually ended out all right did not change those feelings of abject failure. I still walked out of each exam with the same gut certainty of disaster I had always had. What I did learn to do was ignore it: to force myself to walk home with a smile on my face and refuse to let myself dwell on the feelings of failure or take them seriously. And in this I was successful, and now the feelings of abject failure produce only a tiny twinge of stress.</p>\n<p>In LW terminology, I am calibrating my self-assessment of examination success<sup>1</sup>.</p>\n<p><a id=\"more\"></a></p>\n<p>We appreciate objective measurements, like a percent score on an examination, or the running time of a marathon in minutes and seconds. But in the absence of such measurements, we use subjective mental estimates: how I <em>feel</em> I did on this exam, or how plausible that theory <em>sounds</em>.</p>\n<p>The rationality literature has especially focused on one particular subjective mental estimate: our feelings of probability. For example, someone may say they <em>feel</em> 80% certain that Germany is larger than France. However, if they consistently answer questions like this with 80% confidence, and only get 60% right, then we say they are <em>mis-calibrated</em>: their subjective mental estimate of probability has a consistent mismatch with a more normatively correct probability. Calibration means revising your subjective mental estimate until it matches the objective value it tries to estimate; so that when you estimate something with 80% confidence, you get it right 80% of the time.</p>\n<p>My story about exam scores is also a story about calibration. My subjective mental estimate of my exam scores was consistently too low; I would estimate I failed when I had really passed by a wide margin. By suppressing my original mental estimate and replacing it with one better informed by past experience, I am calibrating my estimate of exam scores.</p>\n<p>Since passing my exams, I've identified other areas of my life where I need to calibrate my estimates:</p>\n<p>-- Embarrassment. I used to be mortified if I answered a question wrong in class, assuming that people would judge me on it as long as they knew me. After thinking about it, I realized that although many people in my class answer questions wrong every day, I literally cannot remember a single one. If you pointed out any student in my class, even one of my close friends who I would be expected to pay extra attention to, and asked me \"Has this person ever answered a question wrong in class?\" I wouldn't be able to tell you. This suggests they won't remember my mistakes either, and that my subjective feeling of loss of respect on answering a question wrong is exaggerated to say the least<sup>2</sup>.</p>\n<p>-- Interestingness. I tend to think that if I talk about something I'm  interested in, other people will be interested in it too. No matter how  fascinating the underlying concept to me, nor how well I think I'm  explaining it, this almost never happens.</p>\n<p>-- Flirting. Through painful trial and error, I've found that my hunch that a woman likes me is almost always wrong. Someone will be flirting very heavily with me, and I'll think \"there is no way in the world she's not into me\", and then it will turn out she will not be into me.</p>\n<p>These aren't just things I'm often wrong about; making a list of <em>those</em> would be a Sisyphean task. They're the things that I'm wrong about that  my natural instincts never auto-correct, so that I know I'm going to  keep being wrong unless I consciously calibrate my natural instincts against a reasoned opinion.</p>\n<p>In general, I find I am most often miscalibrated in areas that relate to self evaluation. Cognitive psychology has a slew of ideas about so-called \"self-assessment biases\". You've probably heard the self-serving ones where <a href=\"http://onlinelibrary.wiley.com/doi/10.1002/he.36919771703/abstract\">94% of professors</a> rate their teaching ability above average, or how everyone thinks they're an <a href=\"http://psycnet.apa.org/journals/apl/49/4/284/\">above average driver</a>, or how (ironically) everyone thinks they're <a href=\"http://jdc325.files.wordpress.com/2010/12/2002biasblindspot.pdf\">less susceptible to biases</a> than other people. But more surprisingly, I also find cases where people consistently underestimate themselves - like my own tendency to always think I've failed my examinations. I don't have a good explanation of this - I don't know if it's strategic humility, <a href=\"http://en.wikipedia.org/wiki/Self-verification_theory\">self-verification</a>, some underlying depression-like state, or what - but I'm pretty sure it exists<strong></strong>. And there are two situations in which I find it most common and most annoying.<br /><br />The first involves good looks. Some people just have no idea how attractive they are or aren't. This is most obvious in <a href=\"http://en.wikipedia.org/wiki/Body_dysmorphic_disorder\">body dysmorphic disorder</a>, a condition where normal looking (or even very attractive) people somehow get it into their head that some feature of theirs - their nose, their hair, their weight - is inhumanly hideous and that they look like some kind of swamp monster. This is an officially recognized psychiatric disorder because it's completely divorced from reality - usually their nose or hair or whatever looks absolutely normal and just like everyone else's.<br /><br />BDD is less rare than people think, at about one to two percent of the population, but even people without the full-fledged disorder can be really bad at determining how attractive they are or aren't. There are a lot of pretty girls who go around saying they're ugly in order to trick people into complimenting them, or to signal that they're available and not too picky, but I've come to realize that there are also a lot of pretty girls who genuinely believe they're ugly (it's less obvious in men, but I wouldn't be surprised if it were there under the surface).</p>\n<p>And research agrees: studies show that people are uniquely bad at rating  their own physical attractiveness. The opinion of unbiased observers  evaluating a subject's attractiveness <a href=\"%20http://commonsenseatheism.com/wp-content/uploads/2011/01/Diener-Physical-Attractiveness-and-Subjective-Well-Being.pdf\">usually correlate</a> at a level of r = .4 to .5; the opinion of the subject herself  correlates with everyone else only around the r = .2 level. Other  studies using purportedly \"objective\" measures of attractiveness like  facial symmetry <a href=\"http://www.springerlink.com/content/a67177720h405522/\">report</a> a similarly low level of correlation between the objective measures and  the self-reports. What self-reported physical attractiveness correlates  strongly with is not objective attractiveness, but <a href=\"http://www.mindingthemind.com/reprints/Hurst2.pdf\">self-reported self-esteem</a>, with r values around .5 or .6 depending on the study.</p>\n<p>If you're not so good at statistics - that means that people often agree on how attractive a particular subject is, but that subject's estimate of her own attractiveness is often completely different from everyone else's (in either direction), and more related to that subject's self-esteem than to reality.</p>\n<p>Sites like hotornot.com or okcupid's MyBestFace have a lot of problems, most obviously that they depend a lot upon how good a specific photo is. But I think either is leagues ahead of trying to guess how attractive you are to others based on how attractive you feel. If you have <em>any</em> concern whatsoever about how attractive you are, the <em>worst</em> thing you can do is trust your own brain, especially if it's telling you you're probably pretty ugly when everyone around you seems to think you're okay.<br /><br />Which brings me to the number one most tragic failure of the inside view I see in my friends, my acquaintances, and the psychiatric patients I encounter.<br /><br />Nietzsche said that a casual stroll through an insane asylum shows that faith does not prove anything. Such an experience might also teach people to be skeptical of their own subjective valuation of themselves - their self-esteem. If our hypothetical visitor doesn't figure it out after seeing the depressed patients, who are obsessed with their own guilt and moral worthlessness to the point of confessing to any crime they hear about because it seems like the sort of thing someone as awful as themselves might do, she can go visit the schizophrenics with delusions of grandeur, who insist they are the next Jesus or Einstein, or God's chosen representative on Earth.<br /><br />These people get locked away because their self-esteem is at an extreme no sane human would ever reach. But your location outside the insane asylum doesn't prove your own calculations of self-esteem come from reasoning processes that are any more valid. We all know self-obsessed narcissists without any real achievements to their name, and we all know people who insist that they are ugly and stupid and unlikeable even though they don't seem any worse off than anyone else. <br /><br />Research confirms that people's self-esteem is poorly correlated with reality. Across many experiments with many different designs, people's self-reported likeability <a href=\"http://www.csom.umn.edu/Assets/71496.pdf\">has no correlation</a> with their likeability as reported by other people with whom they interact. This is true whether the experiment measures artificial interaction in a lab, simulated \"dates\" with people of the opposite sex, or the attitudes of their roommates.<br /><br />There are no studies correlating self-reported morality with experimentally determined morality, but if you want conduct one, you could probably gather enough secretly gay evangelical ministers and adulterous family-values politicians to make up a pretty good sample size.<br /><br />If you hate yourself and think you're worthless, take a moment to consider whether you have any evidence that you're objectively doing any worse than anyone else, or whether you just have a low self-esteem set point. If the latter appears to be true, then try to replace the inside view with the outside view when worrying about how much bother you're being to other people or whether you \"deserve\" to be happy.<br /><br />(if your problem is in the other direction you may not have as much vested interest in correcting yourself, but do keep in mind that most of the purported benefits of self-confidence have been exaggerated).<br /><strong><br />SUMMARY</strong><br /><br />People's subjective mental estimates are often way off, especially when they're estimating qualities closely linked to their self-worth. Both everyday experience and scientific research provide ample evidence of people who both underestimate and overestimate themselves in various ways. If you worry you may be one of those people, try and get objective estimates of the parameter you're concerned about from other people or from empirical testing. Then make an effort of will to consciously replace your subjective estimates with your new better-calibrated estimates.</p>\n<p>&nbsp;</p>\n<p><strong>FOOTNOTES</strong></p>\n<p><strong>1</strong>: This could also be interpreted as replacing the Inside View with the Outside View and this would also be a good moral to draw from the story; I'm phrasing it in terms of calibration because it's more appropriate for some of the other examples later down.</p>\n<p><strong>2</strong>: See <a href=\"http://www.psych.cornell.edu/sec/pubPeople/tdg1/Gilo.Medvec.Sav.pdf\">Gilovich, Medvec, and Savitsky, 2000</a> for experimental proof of the same idea</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3ee9k6NJfcGzL6kMS": 1, "fH8jPjHF2R27sRTTG": 1, "8hPTCJbwJnLBmfpCX": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aPrCzeFfbBmRsvzby", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 74, "baseScore": 94, "extendedScore": null, "score": 0.0002, "legacy": true, "legacyId": "9943", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 94, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 121, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T02:09:57.297Z", "modifiedAt": null, "url": null, "title": "Anti-akrasia tool: like stickK.com for data nerds", "slug": "anti-akrasia-tool-like-stickk-com-for-data-nerds", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.961Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dreeves", "createdAt": "2009-02-28T00:36:12.431Z", "isAdmin": false, "displayName": "dreeves"}, "userId": "SXhuTNpwfY65bMunC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6oYETaG248zGF45aD/anti-akrasia-tool-like-stickk-com-for-data-nerds", "pageUrlRelative": "/posts/6oYETaG248zGF45aD/anti-akrasia-tool-like-stickk-com-for-data-nerds", "linkUrl": "https://www.lesswrong.com/posts/6oYETaG248zGF45aD/anti-akrasia-tool-like-stickk-com-for-data-nerds", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anti-akrasia%20tool%3A%20like%20stickK.com%20for%20data%20nerds&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnti-akrasia%20tool%3A%20like%20stickK.com%20for%20data%20nerds%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6oYETaG248zGF45aD%2Fanti-akrasia-tool-like-stickk-com-for-data-nerds%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anti-akrasia%20tool%3A%20like%20stickK.com%20for%20data%20nerds%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6oYETaG248zGF45aD%2Fanti-akrasia-tool-like-stickk-com-for-data-nerds", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6oYETaG248zGF45aD%2Fanti-akrasia-tool-like-stickk-com-for-data-nerds", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 677, "htmlBody": "<p>In 2009 I first described here on LessWrong a tool that <a href=\"http://bethaknee.com\">Bethany Soule</a> and I made to force ourselves to do things that otherwise fell victim to akrasia (\"<a href=\"/lw/am/how_a_pathological_procrastinor_can_lose_weight/\">How a pathological procrastinator can lose weight</a>\"). We got an outpouring&nbsp;of encouragement and enthusiasm from the LessWrong community, which helped inspire us to quit our day jobs and turn this into a real startup: Beeminder (the me-binder!).</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">We've added everyone who got&nbsp;on the waitlist with invite code LESSWRONG and we're getting close to public launch so I wanted to invite any other LessWrong folks to get a beta account first:&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline; \" rel=\"nofollow\" href=\"http://beeminder.com/secretsignup\">http://beeminder.com/secretsignup</a>&nbsp;(no wait this time!)</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">(UPDATE: <a title=\"Make a beeline for your goal\" href=\"http://beeminder.com\">Beeminder</a>&nbsp;is open to the public.)</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">It's definitely not for everyone since a big part of it is commitment contracts. But if you like the concept of <a href=\"http://stickk.com\">stickK.com</a> (forcing yourself to reach a goal via a monetary commitment contract) then we think you'll adore Beeminder.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">StickK is just about the contracts -- Beeminder links it to your data. That has some big advantages:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">1. You don't have to know what you're committing to when you commit, which sounds completely (oxy)moronic but what we mean is that you're committing to keeping your datapoints on a \"yellow brick road\" which you have control over as you go. You commit to something general like \"work out more\" or \"lose weight\" and then decide as you go what that means based on your data.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \"><img src=\"https://www.beeminder.com/example/goals/gallant/graph\" alt=\"Someone outperforming their yellow brick road\" width=\"696\" height=\"447\" /></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \"><a id=\"more\"></a>2. You have the flexibility to change your contract in light of new information (like, 40 hours of actual focused work per week is damn hard!). That also sounds like it defeats the point of a commitment contract, but the key is that you can only make changes starting a week in the future. (Details at <a title=\"The Road Dial and the Akrasia Horizon\" href=\"http://blog.beeminder.com/dial\">blog.beeminder.com/dial</a>&nbsp;which describes the interface of the \"road dial\" for adjusting the steepness of your yellow brick road.) The point is that akrasia (dynamic inconsistency, hyperbolic discounting) means over-weighting immediate consequences, so to beat akrasia you only need to bind yourself for whatever the horizon on \"immediate\" is. Based on a <a title=\"Paper by Milkman, Rogers, and Bazerman\" href=\"http://www.springerlink.com/content/06655508xl230511/\">study of grocery-buying habits</a>&nbsp;-- when buying groceries online for delivery tomorrow people buy a lot more ice cream and a lot fewer vegetables than when they're ordering for delivery next week -- and raw guesswork (so far), we're taking that Akrasia Horizon to be one week.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">So Beeminder as an anti-akrasia tool means committing to keeping all your datapoints on a yellow brick road that you specify and can change the steepness of at any time, with a one-week delay.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">You may be wondering how anyone could ever fail to stay on a yellow brick road that's this flexible. Here's how: if you're highly akratic. Such a person may well find it a daily struggle to stay on the road. Yeah, you can always choose to wuss out and flatten the road, but only starting in a week, which you don't want to do. You want to wuss out Right Now, dammit! I mean, just for now, while you eat this pie, and then you'll behave again. No such luck though.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">The daily struggle to stay on the road does not induce you to touch that road dial. You always want to make it easier \"just for today\" -- which the road dial doesn't allow -- and you always think you'll get your act together by next week.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">We'd love to hear people's thoughts on this! Perhaps surprisingly, it took a ridiculous number of iterations to get to this point. For the longest time we struggled with different ways to deal with the fact that it's so often hard to decide what to commit to. We tried many variations of having multiple yellow brick roads for a single goal, so that you could specify an ambitious goal as well as a bare minimum. It was always too messy, or would backfire altogether and be paralyzing. We think the road dial with an akrasia horizon is a big leap forward. And it seems so obvious in retrospect!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"r7qAjcbfhj2256EHH": 1, "TkZ7MFwCi4D63LJ5n": 3, "bh7uxTTqmsQ8jZJdB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6oYETaG248zGF45aD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 64, "baseScore": 78, "extendedScore": null, "score": 0.00017883544929228314, "legacy": true, "legacyId": "10333", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 62, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 88, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Z6ESPufeiC4P8c8en"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T04:08:11.573Z", "modifiedAt": null, "url": null, "title": "Thinking in Bayes: Light", "slug": "thinking-in-bayes-light", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.959Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AcznJPygrpSET4zLe/thinking-in-bayes-light", "pageUrlRelative": "/posts/AcznJPygrpSET4zLe/thinking-in-bayes-light", "linkUrl": "https://www.lesswrong.com/posts/AcznJPygrpSET4zLe/thinking-in-bayes-light", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Thinking%20in%20Bayes%3A%20Light&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThinking%20in%20Bayes%3A%20Light%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAcznJPygrpSET4zLe%2Fthinking-in-bayes-light%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Thinking%20in%20Bayes%3A%20Light%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAcznJPygrpSET4zLe%2Fthinking-in-bayes-light", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAcznJPygrpSET4zLe%2Fthinking-in-bayes-light", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 326, "htmlBody": "<p>There are a lot of <a href=\"/lw/2b0/bayes_theorem_illustrated_my_way/\">explanations</a> of <a href=\"http://yudkowsky.net/rational/bayes\">Bayes' Theorem</a>, so I won't get into the technicalities. I will get into why it should change how you think. This post is pretty introductory, so free to totally skip it if you don't feel like there's anything about Bayes' Theorem that you don't understand.</p>\n<p>For a while I was reading LessWrong and not seeing what the big deal about Bayes' Theorem was. Sure, probability is in the mind and all, but I didn't see why it was so important to insist on bayesian methods. For me they were a tool, rather than a way of thinking. This summary also helped someone in the DC group.</p>\n<p>After using <a href=\"/lw/2e6/spaced_repetition_database_for_the_mysterious/\">the Anki deck</a>, a thought&nbsp;occurred to me:</p>\n<blockquote>\n<p>Bayes theorem means that when seeing how likely a hypothesis is after an event, not only do I need to think about how likely the hypothesis said the event is, I need to consider <em>everything else that could have possibly made that event more likely.</em></p>\n</blockquote>\n<p>To illustrate:</p>\n<p><a href=\"http://www.codecogs.com/eqnedit.php?latex=P(H|e) = \\frac{P(e|H) * P(H)}{\\sum{P(e|h)*P(h)}}\" target=\"_blank\"><img title=\"P(H|e) = \\frac{P(e|H) * P(H)}{P(e)}\" src=\"http://latex.codecogs.com/gif.latex?P(H|e) = \\frac{P(e|H) * P(H)}{P(e)}\" alt=\"\" /></a></p>\n<p>pretty clearly shows how you need to consider P(e|H), but that's slightly more obvious than the rest of it.</p>\n<p>If you write it out the way that you would compute it you get...</p>\n<p><a href=\"http://www.codecogs.com/eqnedit.php?latex=P(H|e) = \\frac{P(e|H) * P(H)}{\\sum{P(e|h)*P(h)}}\" target=\"_blank\"><img title=\"P(H|e) = \\frac{P(e|H) * P(H)}{\\sum{P(e|h)*P(h)}}\" src=\"http://latex.codecogs.com/gif.latex?P(H|e) = \\frac{P(e|H) * P(H)}{\\sum{P(e|h)*P(h)}}\" alt=\"\" /></a></p>\n<p>where h is an element of the hypothesis space.</p>\n<p>This means that<em> every way</em> that e could have happened is important, on top of (or should I say under?) just how much probability the hypothesis assigned to e.</p>\n<p>This is because P(e) comes from every hypothesis that contributes to e happening, or more mathilyeX P(e) is the sum over all possible hypotheses of the probability of the event and that hypothesis, computed by the probability of the hypothesis times the probability of the event given the hypothesis.</p>\n<p>In LaTeX:</p>\n<p><a href=\"http://www.codecogs.com/eqnedit.php?latex=P(e) = \\displaystyle\\sum_{h} P(e|h)*p(h)\" target=\"_blank\"><img title=\"P(e) = \\displaystyle\\sum_{h} P(e|h)*p(h)\" src=\"http://latex.codecogs.com/gif.latex?P(e) = \\displaystyle\\sum_{h} P(e|h)*p(h)\" alt=\"\" /></a></p>\n<p>where h is an element of the hypothesis space.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AcznJPygrpSET4zLe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "10397", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CMt3ijXYuCynhPWXa", "iRfKKYhZAG8fWDjJr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T04:26:09.284Z", "modifiedAt": null, "url": null, "title": "Meetup : Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up", "slug": "meetup-talk-on-singularity-scenarios-and-optimal", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.173Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/84o5vuq8CwaESEbGA/meetup-talk-on-singularity-scenarios-and-optimal", "pageUrlRelative": "/posts/84o5vuq8CwaESEbGA/meetup-talk-on-singularity-scenarios-and-optimal", "linkUrl": "https://www.lesswrong.com/posts/84o5vuq8CwaESEbGA/meetup-talk-on-singularity-scenarios-and-optimal", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Talk%20on%20Singularity%20scenarios%20and%20optimal%20philanthropy%2C%20followed%20by%20informal%20meet-up&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Talk%20on%20Singularity%20scenarios%20and%20optimal%20philanthropy%2C%20followed%20by%20informal%20meet-up%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F84o5vuq8CwaESEbGA%2Fmeetup-talk-on-singularity-scenarios-and-optimal%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Talk%20on%20Singularity%20scenarios%20and%20optimal%20philanthropy%2C%20followed%20by%20informal%20meet-up%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F84o5vuq8CwaESEbGA%2Fmeetup-talk-on-singularity-scenarios-and-optimal", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F84o5vuq8CwaESEbGA%2Fmeetup-talk-on-singularity-scenarios-and-optimal", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 213, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/40'>Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 October 2011 06:18:06PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">3 Seminary Pl, New Brunswick, Middlesex, New Jersey 08901</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I'll be giving a 35-minute talk to some folks from Rutgers philosophy and Giving What We Can, followed by Q and A, informal discussion, and hopefully conversation that continues over pizza or something. Come meet me, <a href=\"http://lesswrong.com/lw/7ob/timeline_of_carl_shulman_publications/\">Carl Shulman</a> (another SingInst research fellow; also, by husband:)), me, and other LW-ers, discuss some ideas, and have fun! * * * <em>The abstract that was sent out to Rutgers folk:</em> In 1965, I.J. Good proposed that machines would one day be smart enough to make themselves smarter. Having made themselves smarter, they would spot still further opportunities for improvement, quickly leaving human intelligence far behind. He called this the \"intelligence explosion\". I review the argument for an intelligence explosion, and how one might seek to influence its outcome, and reduce the odds of catastrophe, should such an event occur. I also try, very briefly, to situate such interventions in relation to other paths for doing good, such as third world poverty interventions and interventions to reduce nuclear risk.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/40'>Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "84o5vuq8CwaESEbGA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 7.817428002952367e-07, "legacy": true, "legacyId": "10398", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Talk_on_Singularity_scenarios_and_optimal_philanthropy__followed_by_informal_meet_up\">Discussion article for the meetup : <a href=\"/meetups/40\">Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 October 2011 06:18:06PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">3 Seminary Pl, New Brunswick, Middlesex, New Jersey 08901</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I'll be giving a 35-minute talk to some folks from Rutgers philosophy and Giving What We Can, followed by Q and A, informal discussion, and hopefully conversation that continues over pizza or something. Come meet me, <a href=\"http://lesswrong.com/lw/7ob/timeline_of_carl_shulman_publications/\">Carl Shulman</a> (another SingInst research fellow; also, by husband:)), me, and other LW-ers, discuss some ideas, and have fun! * * * <em>The abstract that was sent out to Rutgers folk:</em> In 1965, I.J. Good proposed that machines would one day be smart enough to make themselves smarter. Having made themselves smarter, they would spot still further opportunities for improvement, quickly leaving human intelligence far behind. He called this the \"intelligence explosion\". I review the argument for an intelligence explosion, and how one might seek to influence its outcome, and reduce the odds of catastrophe, should such an event occur. I also try, very briefly, to situate such interventions in relation to other paths for doing good, such as third world poverty interventions and interventions to reduce nuclear risk.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Talk_on_Singularity_scenarios_and_optimal_philanthropy__followed_by_informal_meet_up1\">Discussion article for the meetup : <a href=\"/meetups/40\">Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up</a></h2>", "sections": [{"title": "Discussion article for the meetup : Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up", "anchor": "Discussion_article_for_the_meetup___Talk_on_Singularity_scenarios_and_optimal_philanthropy__followed_by_informal_meet_up", "level": 1}, {"title": "Discussion article for the meetup : Talk on Singularity scenarios and optimal philanthropy, followed by informal meet-up", "anchor": "Discussion_article_for_the_meetup___Talk_on_Singularity_scenarios_and_optimal_philanthropy__followed_by_informal_meet_up1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4uQxZonCwCZtz39Hw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T11:52:20.864Z", "modifiedAt": null, "url": null, "title": "[link] Relative angels and absolute demons", "slug": "link-relative-angels-and-absolute-demons", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:02.377Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LKxdghoBKP86vkr8u/link-relative-angels-and-absolute-demons", "pageUrlRelative": "/posts/LKxdghoBKP86vkr8u/link-relative-angels-and-absolute-demons", "linkUrl": "https://www.lesswrong.com/posts/LKxdghoBKP86vkr8u/link-relative-angels-and-absolute-demons", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Relative%20angels%20and%20absolute%20demons&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Relative%20angels%20and%20absolute%20demons%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKxdghoBKP86vkr8u%2Flink-relative-angels-and-absolute-demons%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Relative%20angels%20and%20absolute%20demons%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKxdghoBKP86vkr8u%2Flink-relative-angels-and-absolute-demons", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLKxdghoBKP86vkr8u%2Flink-relative-angels-and-absolute-demons", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 644, "htmlBody": "<p>I wanted to bring attention to two posts from Razib Khan's Discover magazine <a href=\"http://blogs.discovermagazine.com/gnxp/\">gene expression</a> blog (some of you may have been readers of the still active original <a href=\"http://www.gnxp.com/\">gnxp</a>) on the polemic surrounding Pinker's <a href=\"http://www.amazon.com/exec/obidos/ASIN/0670022950/geneexpressio-20\">The Better Angels of Our Nature</a>.</p>\n<blockquote>\n<p>Faced with the ceaseless stream of news about war, crime, and terrorism, one could easily think we live in the most violent age ever seen. Yet as New York Times bestselling author Steven Pinker shows in this startling and engaging new work, just the opposite is true: violence has been diminishing for millennia and we may be living in the most peaceful time in our species's existence. For most of history, war, slavery, infanticide, child abuse, assassinations, pogroms, gruesome punishments, deadly quarrels, and genocide were ordinary features of life. But today, Pinker shows (with the help of more than a hundred graphs and maps) all these forms of violence have dwindled and are widely condemned. How has this happened?</p>\n<p>This groundbreaking book continues Pinker's exploration of the essence of human nature, mixing psychology and history to provide a remarkable picture of an increasingly nonviolent world. The key, he explains, is to understand our intrinsic motives- the inner demons that incline us toward violence and the better angels that steer us away-and how changing circumstances have allowed our better angels to prevail. Exploding fatalist myths about humankind's inherent violence and the curse of modernity, this ambitious and provocative book is sure to be hotly debated in living rooms and the Pentagon alike, and will challenge and change the way we think about our society.</p>\n</blockquote>\n<p><a href=\"http://blogs.discovermagazine.com/gnxp/2011/10/relative-angels-and-absolute-demons/\">Relative Angels and absolute Demons</a> (and the related <a href=\"http://blogs.discovermagazine.com/gnxp/2011/10/but-peace-does-reign/\">But peace does reign! </a>)</p>\n<blockquote>\n<p>There are two separate points to note here; a specific and a general. I suspect Steven Pinker knows more history than Elizabeth Kolbert. I&rsquo;ve talked to Pinker once at length, and just as in his books he comes across as very widely knowledgeable. I&rsquo;ll be frank and say that I don&rsquo;t feel many people I talk to are widely knowledgeable, and when it comes to something like history I&rsquo;m in a position to judge. Ironically Kolbert is repeating the Anglo-Protestant <span id=\"apture_prvw2\" class=\"aptureLink \"><span class=\"aptureLinkIcon\" style=\"background-position: right -1348px;\">&nbsp;</span><a class=\"aptureLink snap_noshots\" href=\"http://en.wikipedia.org/wiki/Black%20Legend\">Black Legend</a></span> about the Spaniards, rooted in the rivalries and sectarianism of the 16th and 18th centuries, but persisting down amongst English speaking secular intellectuals. The reality is that <strong>the Spaniards did not want to kill the indigenous peoples, they died of disease and the societal destabilization that disease entailed.</strong> Europeans who arrived from Iberia in the New World ideally wished to collect rents from peasants. The death of those peasants due to disease was a major inconvenience, which entailed the importation of black Africans who were resistant to the Old World diseases like malaria which were spreading across the American tropics. The violence done to native peoples was predominantly pathogenic, not physical.</p>\n<p>...</p>\n</blockquote>\n<blockquote>I suspect that Kolbert&rsquo;s emphasis on the European colonial experience of much of the world is influenced by the ubiquity of the <span id=\"apture_prvw6\" class=\"aptureLink \"><span class=\"aptureLinkIcon\" style=\"background-position: right -1348px;\">&nbsp;</span><a class=\"aptureLink snap_noshots\" href=\"http://en.wikipedia.org/wiki/Postcolonialism\">postcolonial</a></span> paradigm. Those who take postcolonial thinking as normative <strong>sometimes forget that not everyone shares their framework.</strong> I do not, and I would be willing to bet that Steven Pinker would also dissent from the presuppositions of postcolonialism. That means that the facts, the truths, that many take for granted are actually not taken for granted by all, and are disputed. One of the issues with postcolonial models is that they seem to view Europeans and European culture, and their colonial enterprises, as <em>sui generis</em>. This makes generalization from the West, as Pinker does, problematic. But for those of us who don&rsquo;t see the West as qualitatively different there is far less of an issue.</blockquote>\n<p>I generally agree with some of his arguments, but found this quote especially as summing up some of my own sentiments:</p>\n<blockquote>\n<p>A postcolonial model is ironically extremely Eurocentric, with a total blindness to what came before Europeans.</p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LKxdghoBKP86vkr8u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "10402", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 66, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T14:59:49.758Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Motivated Stopping and Motivated Continuation", "slug": "seq-rerun-motivated-stopping-and-motivated-continuation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.848Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4SZAFCRbfcCd3HJBe/seq-rerun-motivated-stopping-and-motivated-continuation", "pageUrlRelative": "/posts/4SZAFCRbfcCd3HJBe/seq-rerun-motivated-stopping-and-motivated-continuation", "linkUrl": "https://www.lesswrong.com/posts/4SZAFCRbfcCd3HJBe/seq-rerun-motivated-stopping-and-motivated-continuation", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Motivated%20Stopping%20and%20Motivated%20Continuation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Motivated%20Stopping%20and%20Motivated%20Continuation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4SZAFCRbfcCd3HJBe%2Fseq-rerun-motivated-stopping-and-motivated-continuation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Motivated%20Stopping%20and%20Motivated%20Continuation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4SZAFCRbfcCd3HJBe%2Fseq-rerun-motivated-stopping-and-motivated-continuation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4SZAFCRbfcCd3HJBe%2Fseq-rerun-motivated-stopping-and-motivated-continuation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<p>Today's post, <a href=\"/lw/km/motivated_stopping_and_motivated_continuation/\">Motivated Stopping and Motivated Continuation</a> was originally published on 28 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When the evidence we've seen points towards a conclusion that we like or dislike, there is a temptation to stop the search for evidence prematurely, or to insist that more evidence is needed.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/809/seq_rerun_why_are_individual_iq_differences_ok/\">Why Are Individual IQ Differences OK?</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4SZAFCRbfcCd3HJBe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 7.819581699958179e-07, "legacy": true, "legacyId": "10403", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["L32LHWzy9FzSDazEg", "4QNZbLT68BE4GBQLS", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T17:23:15.460Z", "modifiedAt": null, "url": null, "title": "Meetup : Austin, TX", "slug": "meetup-austin-tx-7", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XYwCvnyjAGm8rwgrj/meetup-austin-tx-7", "pageUrlRelative": "/posts/XYwCvnyjAGm8rwgrj/meetup-austin-tx-7", "linkUrl": "https://www.lesswrong.com/posts/XYwCvnyjAGm8rwgrj/meetup-austin-tx-7", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Austin%2C%20TX&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Austin%2C%20TX%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYwCvnyjAGm8rwgrj%2Fmeetup-austin-tx-7%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Austin%2C%20TX%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYwCvnyjAGm8rwgrj%2Fmeetup-austin-tx-7", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYwCvnyjAGm8rwgrj%2Fmeetup-austin-tx-7", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 79, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/41'>Austin, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 October 2011 01:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2222B Guadalupe St Austin, Texas 78705</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Austin meetup careens towards the present from the future, and all you can do is prepare to be there. (Or be square.)</p>\n\n<p>I have finally gotten into the habit of checking the football calendar: there will be a game at 2:30 against Oklahoma State. Those driving in may want to plan accordingly.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/41'>Austin, TX</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XYwCvnyjAGm8rwgrj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.820069322074165e-07, "legacy": true, "legacyId": "10404", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Austin__TX\">Discussion article for the meetup : <a href=\"/meetups/41\">Austin, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 October 2011 01:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2222B Guadalupe St Austin, Texas 78705</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The Austin meetup careens towards the present from the future, and all you can do is prepare to be there. (Or be square.)</p>\n\n<p>I have finally gotten into the habit of checking the football calendar: there will be a game at 2:30 against Oklahoma State. Those driving in may want to plan accordingly.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Austin__TX1\">Discussion article for the meetup : <a href=\"/meetups/41\">Austin, TX</a></h2>", "sections": [{"title": "Discussion article for the meetup : Austin, TX", "anchor": "Discussion_article_for_the_meetup___Austin__TX", "level": 1}, {"title": "Discussion article for the meetup : Austin, TX", "anchor": "Discussion_article_for_the_meetup___Austin__TX1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T17:43:22.541Z", "modifiedAt": null, "url": null, "title": "LW October WebDiplomacy", "slug": "lw-october-webdiplomacy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:59.831Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kg84k3pi9JSkJ62nF/lw-october-webdiplomacy", "pageUrlRelative": "/posts/kg84k3pi9JSkJ62nF/lw-october-webdiplomacy", "linkUrl": "https://www.lesswrong.com/posts/kg84k3pi9JSkJ62nF/lw-october-webdiplomacy", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LW%20October%20WebDiplomacy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALW%20October%20WebDiplomacy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkg84k3pi9JSkJ62nF%2Flw-october-webdiplomacy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LW%20October%20WebDiplomacy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkg84k3pi9JSkJ62nF%2Flw-october-webdiplomacy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fkg84k3pi9JSkJ62nF%2Flw-october-webdiplomacy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 201, "htmlBody": "<p>A <a href=\"/lw/7ec/lw_september_webdiplomacy_games_starting_soon/\">month ago</a> we tried to start up two <a href=\"http://www.webdiplomacy.net/\">WebDiplomacy</a> games with LW users; only one of them got off the ground, and just finished the <a href=\"http://www.webdiplomacy.net/board.php?gameID=66933\">1905</a> turn. This month, we're trying again, and since the method I used to try and extract time preferences didn't work as well as I hoped last time, I'll try something new.</p>\n<p>If you would like to get in on a Diplomacy game with other LW users, please respond with a comment expressing your desire (between 1 and 0) to play in a game based on its turn length: 24, 36, 48, or 72 hours. (You don't need to make 0s explicit.) For example, if you can't play in a 24 hour game, could play in a 36 hour game or 72 hour game, but really want to play in a 48 hour game, then you might comment with something like \"(0, .8, 1, .6)\" or \"24: 1; 36: .8; 72: .6\". Please express your interest by midnight on <strong>10/15</strong> so we can get any games started on the 16th.</p>\n<p>If October isn't a good month for you, but you'd like to make sure I make another Diplomacy thread in November, leave a comment to that effect.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kg84k3pi9JSkJ62nF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 7.820137722663569e-07, "legacy": true, "legacyId": "10405", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MW2q5BnfzB85FwcFY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T18:53:00.594Z", "modifiedAt": null, "url": null, "title": "A Rational Approach to Fashion", "slug": "a-rational-approach-to-fashion", "viewCount": null, "lastCommentedAt": "2014-02-03T07:58:10.500Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lionhearted", "createdAt": "2010-07-29T13:30:07.417Z", "isAdmin": false, "displayName": "lionhearted"}, "userId": "tooJeLNxoeccqGEky", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dmh4XnguCtp7BEa5s/a-rational-approach-to-fashion", "pageUrlRelative": "/posts/dmh4XnguCtp7BEa5s/a-rational-approach-to-fashion", "linkUrl": "https://www.lesswrong.com/posts/dmh4XnguCtp7BEa5s/a-rational-approach-to-fashion", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Rational%20Approach%20to%20Fashion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Rational%20Approach%20to%20Fashion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdmh4XnguCtp7BEa5s%2Fa-rational-approach-to-fashion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Rational%20Approach%20to%20Fashion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdmh4XnguCtp7BEa5s%2Fa-rational-approach-to-fashion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdmh4XnguCtp7BEa5s%2Fa-rational-approach-to-fashion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 755, "htmlBody": "<p>Related to:&nbsp;<a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Humans are not automatically strategic</a>, <a href=\"http://wiki.lesswrong.com/wiki/Rationalists_should_win\">Rationalists should win</a></p>\n<p>Fashion isn't prioritized in many hyper-analytical circles. Many in these communities write it off as frill and unnecessary. They say they \"just dress comfortably\" and leave it at that.</p>\n<p>To me, that seems like a huge blind spot. It misses a fundamental point -</p>\n<p><strong>A piece of clothing is fundamentally a tool.</strong></p>\n<p>Definitions are important so everyone is on the same page. I feel like Wikipedia's first sentence on \"tool\" accurately describes it -</p>\n<blockquote>\n<p>A tool is a device that can be used to produce an item or achieve a task, but that is not consumed in the process.</p>\n</blockquote>\n<p>Clothing clearly fits that definition of a tool.</p>\n<p>Appropriately chosen clothing can keep you from freezing in the winter, from getting sunburnt in the summer, and can keep you dry in a rainstorm.</p>\n<p>It can also help you achieve <em>things involving other people</em>. I think it's fair to draw a distinction between \"clothing\" and \"fashion\" based on whether your objectives involve interpersonal skills. If you're wearing clothing in relation to the environment and without other people, that's using clothing as a tool.</p>\n<p>But clothing clearly can affect other people's opinions of you, willingness to accept your arguments, willing to hire or contract you, even their desire to associate with you. All of that is changed by clothing - or more specifically, your \"fashion.\"</p>\n<p>While most rationalists would happily and quickly plan out the best hiking boots to wear to not get blisters on a hike, or research the best shoes for bicycling or swimsuit for swimming, anecdotally many seem hesitant or even hostile to the idea of using fashion as a tool to achieve their objectives.</p>\n<p>That's possibly a mistake.</p>\n<p>The thing fashion can do best and most fundamentally is affect a person's <em>initial first impression of you</em>. Fashion is less important if you're in a context where you're guaranteed to get to know someone over a longer period of time, and is more important if you're going to get filtered quickly.</p>\n<p>I propose that the most rational usage of fashion is this -</p>\n<p>1. Ask yourself what your goals are in the situation you're about to go into.</p>\n<p>2. Ask yourself what first impression would help you reach your goals.</p>\n<p>3. Pick out and wear clothing that helps communicate that first impression.</p>\n<p>The process is important. In isolation, there's no \"good fashion\" - it depends on your objectives.</p>\n<p>In some circles, people more or less won't care how you're dressed. But <em>even then</em>, there's likely some clothing that will perform better than others. If you can afford the time or money to find clothing to fit your objectives, then there's no reason not to utilize this advantage.</p>\n<p>I say \"time or money\" because you can deploy either - if money isn't an issue, there's stores where the majority of things look good, and the people there are professionals who will spend time giving you good feedback. Any high end department store like Saks Fifth Avenue, Bloomingdales, or a high end tailor fits this category.</p>\n<p>Alternatively, you can deploy time. To do that, survey the people that most effectively communicate the first impression you want to convey. Take actual notes and look for common trends. Then, go find pieces that look similar. You won't be perfect right away, but like any other skill, with practice you'll rapidly improve. Incidentally, the marginal cost to produce clothing is incredibly cheap, so most fashion lines over-produce clothing and have to liquidate it at super-discount sale prices periodically. There tends to be a major \"Summer Sale\" and \"Winter Sale\" once per year that have high end clothing that 70% to 90% off, making the cost comprable to the mid-tier.</p>\n<p>There's also \"Sample Sales\" where over-produced items are liquidated or when a designer wants to see the buying public's reaction to their new pieces. Again, ultra-high-end clothing can be purchased at discount rates at these environments. You can get basically any semi-standard piece of high end clothing for not very much money if you put in the time. My strategy in the past has been to wait until finding a great opportunity like that, and then buying 1-2 years worth of clothing in one swoop. It doesn't take much supplementing after that.</p>\n<p>It takes very little cognitive energy to begin this process. Next time you see someone who strikes a very good impression, stop and analyze a little bit. Note what they're wearing. If you want to strike that same first impression, go get something comprable. Your fashion will be working for you at that point, and your interpersonal dealings will become easier.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dmh4XnguCtp7BEa5s", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 24, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "10407", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 96, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PBRWb2Em5SNeWYwwB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-10-10T18:53:00.594Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T18:54:52.420Z", "modifiedAt": null, "url": null, "title": "Interesting article about optimism", "slug": "interesting-article-about-optimism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.042Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uYXAfRf82yKRgeGnB/interesting-article-about-optimism", "pageUrlRelative": "/posts/uYXAfRf82yKRgeGnB/interesting-article-about-optimism", "linkUrl": "https://www.lesswrong.com/posts/uYXAfRf82yKRgeGnB/interesting-article-about-optimism", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Interesting%20article%20about%20optimism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInteresting%20article%20about%20optimism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuYXAfRf82yKRgeGnB%2Finteresting-article-about-optimism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Interesting%20article%20about%20optimism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuYXAfRf82yKRgeGnB%2Finteresting-article-about-optimism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuYXAfRf82yKRgeGnB%2Finteresting-article-about-optimism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 148, "htmlBody": "<p>According to this brain-imaging study, volunteers presented with negative scenarios (i.e. car crashes, cancer), and asked to estimate the probability of these scenarios happening to them, would <em>only </em>update their beliefs if the actual rate of ocurrence in the population, given to them afterwards, was lower, i.e. <em>more </em>optimistic,&nbsp;than what they had guessed. The more \"optimistic\" the subjects were, according to a personality test, the less likely they were to update their belief based on more negative information, and the less activity they showed their frontal lobes, indicating that they weren't \"paying attention\" to the new information.</p>\r\n<p>Sounds like confirmation bias, except that interestingly enough, it's unidirectional in this case. I wonder if very pessimistic people would have the opposite bias, only updating their estimate if the actual probability was higher, or more <em>negative.</em></p>\r\n<p><a href=\"http://www.kurzweilai.net/brain-imaging-reveals-why-we-remain-optimistic-in-the-face-of-reality?utm_source=KurzweilAI+Daily+Newsletter&amp;utm_campaign=5ea164a0e2-UA-946742-1&amp;utm_medium=email\">Link to article</a> on kurzweilai.</p>\r\n<p><a href=\"http://www.nature.com/neuro/journal/vaop/ncurrent/full/nn.2949.html\">Link to abstract</a> in Nature journal. I can't access the full text.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uYXAfRf82yKRgeGnB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 13, "extendedScore": null, "score": 7.820380822435523e-07, "legacy": true, "legacyId": "10408", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T19:07:27.820Z", "modifiedAt": null, "url": null, "title": "Just a reminder, for everyone that signed up for the intro to AI class, it's started.", "slug": "just-a-reminder-for-everyone-that-signed-up-for-the-intro-to", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.861Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hAyXBBkjriBqJuZna/just-a-reminder-for-everyone-that-signed-up-for-the-intro-to", "pageUrlRelative": "/posts/hAyXBBkjriBqJuZna/just-a-reminder-for-everyone-that-signed-up-for-the-intro-to", "linkUrl": "https://www.lesswrong.com/posts/hAyXBBkjriBqJuZna/just-a-reminder-for-everyone-that-signed-up-for-the-intro-to", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Just%20a%20reminder%2C%20for%20everyone%20that%20signed%20up%20for%20the%20intro%20to%20AI%20class%2C%20it's%20started.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJust%20a%20reminder%2C%20for%20everyone%20that%20signed%20up%20for%20the%20intro%20to%20AI%20class%2C%20it's%20started.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhAyXBBkjriBqJuZna%2Fjust-a-reminder-for-everyone-that-signed-up-for-the-intro-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Just%20a%20reminder%2C%20for%20everyone%20that%20signed%20up%20for%20the%20intro%20to%20AI%20class%2C%20it's%20started.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhAyXBBkjriBqJuZna%2Fjust-a-reminder-for-everyone-that-signed-up-for-the-intro-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhAyXBBkjriBqJuZna%2Fjust-a-reminder-for-everyone-that-signed-up-for-the-intro-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>Here you go:&nbsp;<a href=\"http://www.ai-class.com/\">http://www.ai-class.com/</a></p>\n<p>&nbsp;</p>\n<p>They're still working out kinks in the site, and no homework is up yet, but the initial set of lectures (really really basic \"what is AI/welcome to the first day of class\" type stuff is up), so if you signed up, then sign in and hopefully the site will work for you.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hAyXBBkjriBqJuZna", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 7.820423630847142e-07, "legacy": true, "legacyId": "10409", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-10T22:26:48.947Z", "modifiedAt": null, "url": null, "title": "The self-fooling problem.", "slug": "the-self-fooling-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:54.682Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PuyaSharif", "createdAt": "2011-02-26T07:33:06.094Z", "isAdmin": false, "displayName": "PuyaSharif"}, "userId": "Kx2AumHK8eeJ4nHqt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cieFX73v7J27qTTBZ/the-self-fooling-problem", "pageUrlRelative": "/posts/cieFX73v7J27qTTBZ/the-self-fooling-problem", "linkUrl": "https://www.lesswrong.com/posts/cieFX73v7J27qTTBZ/the-self-fooling-problem", "postedAtFormatted": "Monday, October 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20self-fooling%20problem.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20self-fooling%20problem.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcieFX73v7J27qTTBZ%2Fthe-self-fooling-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20self-fooling%20problem.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcieFX73v7J27qTTBZ%2Fthe-self-fooling-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcieFX73v7J27qTTBZ%2Fthe-self-fooling-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p>I formulated a little problem. Care to solve it?</p>\n<p>You are given the following information:</p>\n<p><em>Your task is to hide a coin in your house (or any familiar finite environment).</em><em> <br />After you've hidden the coin your memory will be erased and restored to a state just before you receiving this information.<br />Then you will be told about the task (i.e that you have hidden a coin), and asked to try to find the coin.</em><em><br />If you find it you'll lose, but you will be convinced that if you find it you win. <br /></em></p>\n<p>So now you're faced with finding an optimal strategy to <strong>minimize the probability</strong> of finding the coin within a finite time-frame.<br />Bear in mind that any chain of reasoning leading up to a decision of location can be generated by you while trying to find the coin.</p>\n<p>You might come to the conclusion that there cant exist an optimal strategy other than randomizing. But if you randomize, then you have the risk of placing the coin at a location where it can be easily found, like on a table or on the floor. You could eliminate those risky locations by excluding them as alternatives in your randomization process, but that would mean including a chain of reasoning!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cieFX73v7J27qTTBZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 13, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "10411", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-11T03:58:43.371Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Torture vs. Dust Specks", "slug": "seq-rerun-torture-vs-dust-specks", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:37.132Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/edRPsu2jNcHRN46CY/seq-rerun-torture-vs-dust-specks", "pageUrlRelative": "/posts/edRPsu2jNcHRN46CY/seq-rerun-torture-vs-dust-specks", "linkUrl": "https://www.lesswrong.com/posts/edRPsu2jNcHRN46CY/seq-rerun-torture-vs-dust-specks", "postedAtFormatted": "Tuesday, October 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Torture%20vs.%20Dust%20Specks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Torture%20vs.%20Dust%20Specks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FedRPsu2jNcHRN46CY%2Fseq-rerun-torture-vs-dust-specks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Torture%20vs.%20Dust%20Specks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FedRPsu2jNcHRN46CY%2Fseq-rerun-torture-vs-dust-specks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FedRPsu2jNcHRN46CY%2Fseq-rerun-torture-vs-dust-specks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 174, "htmlBody": "<p>Today's post, <a href=\"/lw/kn/torture_vs_dust_specks/\">Torture vs. Dust Specks</a> was originally published on 30 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Torture_vs._Dust_Specks\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If you had to choose between torturing one person horribly for 50 years, or putting a single dust speck into the eyes of 3^^^3 people, what would you do?</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/80z/seq_rerun_motivated_stopping_and_motivated/\">Motivated Stopping and Motivated Continuation</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "edRPsu2jNcHRN46CY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.8222303981392e-07, "legacy": true, "legacyId": "10419", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 85, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3wYTFWY3LKQCnAptN", "4SZAFCRbfcCd3HJBe", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-11T08:36:36.811Z", "modifiedAt": null, "url": null, "title": "The self-unfooling problem", "slug": "the-self-unfooling-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:23.011Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RichardKennaway", "createdAt": "2009-03-09T13:46:28.196Z", "isAdmin": false, "displayName": "RichardKennaway"}, "userId": "unnmqpwtrwhyDt6q5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PckAX7BwMsGgjBPmG/the-self-unfooling-problem", "pageUrlRelative": "/posts/PckAX7BwMsGgjBPmG/the-self-unfooling-problem", "linkUrl": "https://www.lesswrong.com/posts/PckAX7BwMsGgjBPmG/the-self-unfooling-problem", "postedAtFormatted": "Tuesday, October 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20self-unfooling%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20self-unfooling%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPckAX7BwMsGgjBPmG%2Fthe-self-unfooling-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20self-unfooling%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPckAX7BwMsGgjBPmG%2Fthe-self-unfooling-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPckAX7BwMsGgjBPmG%2Fthe-self-unfooling-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 189, "htmlBody": "<p>Inspired by <a href=\"/r/discussion/lw/817/the_selffooling_problem/\">PuyaSharif's conundrum</a>, I find myself continually faced with the opposite problem, which is identical to the original except in the bold-faced sentences:</p>\n<p>You are given the following information:</p>\n<p><em>Your task is to hide a coin in your house (or any familiar finite environment). &nbsp;</em></p>\n<p><em>After you've hidden the coin your memory will be erased and restored to a state just before you receiving this information. &nbsp;</em></p>\n<p><em>Then you will be told about the task (i.e that you have hidden a coin), and asked to try to find the coin. &nbsp;</em></p>\n<p><em><strong>If you find it you win. The faster you find it, the better you win.</strong></em></p>\n<p>Where do you leave the coin so that when you have no memory of where you put it, you can lay your hands on it at once?</p>\n<p>For just one coin, you might think up some suitable Schelling point, but now multiply the task a thousandfold, for all of your possessions. (I am not a minimalist; of books alone I have 3500.) How do you arrange all your stuff, all your life, in such a way that everything is exactly where you would first think of looking for it?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PckAX7BwMsGgjBPmG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 20, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "10422", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cieFX73v7J27qTTBZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-11T16:14:40.907Z", "modifiedAt": null, "url": null, "title": "Improving My Writing Style", "slug": "improving-my-writing-style", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:23.016Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "orthonormal", "createdAt": "2009-03-22T16:06:51.665Z", "isAdmin": false, "displayName": "orthonormal"}, "userId": "4fh2AAe3n7oBviyxx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZAsbonw9sFQqCHMs8/improving-my-writing-style", "pageUrlRelative": "/posts/ZAsbonw9sFQqCHMs8/improving-my-writing-style", "linkUrl": "https://www.lesswrong.com/posts/ZAsbonw9sFQqCHMs8/improving-my-writing-style", "postedAtFormatted": "Tuesday, October 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Improving%20My%20Writing%20Style&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AImproving%20My%20Writing%20Style%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZAsbonw9sFQqCHMs8%2Fimproving-my-writing-style%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Improving%20My%20Writing%20Style%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZAsbonw9sFQqCHMs8%2Fimproving-my-writing-style", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZAsbonw9sFQqCHMs8%2Fimproving-my-writing-style", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 222, "htmlBody": "<p>I've written quite a lot here since Less Wrong started up, but I've started to suspect that my writing style is holding me back. Most recently, I wrote two sequences that seemed to garner widespread agreement on content/significance/originality but didn't really seem to excite anyone, which is a pretty clear signal that my style has been hobbling my ideas. So, <a href=\"/lw/778/consequentialism_need_not_be_nearsighted/4qmc\">as I'd promised to do</a> (albeit a few weeks later than I'd expected), I'm trying to improve myself as a writer, and I need your help.</p>\n<p>I'm declaring <a href=\"http://wiki.lesswrong.com/wiki/Crocker%27s_rules\">Crocker's Rules</a> on the subject, and I'd like help with both diagnosis and treatment. Let me know, as precisely as you can, what's problematic in my writing, or what you think the root causes might be, or what you think might help me to fix my issues. I'll list what I've thought of so far in a comment below (so that you can make your own suggestions without anchoring issues).</p>\n<p>Links to my recent major posts:</p>\n<p><a href=\"/lw/778/consequentialism_need_not_be_nearsighted/\">Consequentialism Need Not Be Nearsighted</a></p>\n<p>Qualia sequence: <a href=\"/lw/5n9/seeing_red_dissolving_marys_room_and_qualia/\">Part I</a>, <a href=\"/lw/5op/a_study_of_scarlet_the_conscious_mental_graph/\">Part II</a>, <a href=\"/lw/5ot/nature_red_in_truth_and_qualia/\">Part III</a></p>\n<p>And now an odd counterexample: I wrote <a href=\"/lw/3kl/optimizing_fuzzies_and_utilons_the_altruism_chip/\">this post</a> quickly for Discussion, without thinking too much or editing at all, and then it got promoted and was received enthusiastically. That may just be the subject matter, or it may signify that the time I spend editing posts makes them <em>worse</em>...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZAsbonw9sFQqCHMs8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 7.824734552541036e-07, "legacy": true, "legacyId": "10425", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["prb8raC4XGJiRWs5n", "3wYjyQ839MDsZ6E3L", "pi5DAEZWJK3c9NAhW", "gyz2MsHM9GKxX62hj", "FfNEt8mpi6qanNmXg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-12T03:48:06.620Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] A Case Study of Motivated Continuation", "slug": "seq-rerun-a-case-study-of-motivated-continuation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:23.046Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J4ESCJkjyEneJrBmF/seq-rerun-a-case-study-of-motivated-continuation", "pageUrlRelative": "/posts/J4ESCJkjyEneJrBmF/seq-rerun-a-case-study-of-motivated-continuation", "linkUrl": "https://www.lesswrong.com/posts/J4ESCJkjyEneJrBmF/seq-rerun-a-case-study-of-motivated-continuation", "postedAtFormatted": "Wednesday, October 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20A%20Case%20Study%20of%20Motivated%20Continuation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20A%20Case%20Study%20of%20Motivated%20Continuation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ4ESCJkjyEneJrBmF%2Fseq-rerun-a-case-study-of-motivated-continuation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20A%20Case%20Study%20of%20Motivated%20Continuation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ4ESCJkjyEneJrBmF%2Fseq-rerun-a-case-study-of-motivated-continuation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ4ESCJkjyEneJrBmF%2Fseq-rerun-a-case-study-of-motivated-continuation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 171, "htmlBody": "<p>Today's post, <a href=\"/lw/ko/a_case_study_of_motivated_continuation/\">A Case Study of Motivated Continuation</a> was originally published on 31 October 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#A_Case_Study_of_Motivated_Continuation\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>When you find yourself considering a problem in which all visible options are uncomfortable, making a choice is difficult. Grit your teeth and choose anyways.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/81f/seq_rerun_torture_vs_dust_specks/\">Torture vs. Dust Specks</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J4ESCJkjyEneJrBmF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.82709529235127e-07, "legacy": true, "legacyId": "10433", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["i2ruK7M3coWfv8mfD", "edRPsu2jNcHRN46CY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-12T18:40:25.631Z", "modifiedAt": null, "url": null, "title": "Meetup : UMD Calibration Games", "slug": "meetup-umd-calibration-games", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:54.954Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aJMTv7JzvzPaueYca/meetup-umd-calibration-games", "pageUrlRelative": "/posts/aJMTv7JzvzPaueYca/meetup-umd-calibration-games", "linkUrl": "https://www.lesswrong.com/posts/aJMTv7JzvzPaueYca/meetup-umd-calibration-games", "postedAtFormatted": "Wednesday, October 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20UMD%20Calibration%20Games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20UMD%20Calibration%20Games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaJMTv7JzvzPaueYca%2Fmeetup-umd-calibration-games%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20UMD%20Calibration%20Games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaJMTv7JzvzPaueYca%2Fmeetup-umd-calibration-games", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaJMTv7JzvzPaueYca%2Fmeetup-umd-calibration-games", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 47, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/42'>UMD Calibration Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 October 2011 05:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">STAMP, University of Maryland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're in Terrapin Room A in the Student Involvement Suite, meeting at 5 PM.</p>\n\n<p>We plan to play some calibration games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/42'>UMD Calibration Games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aJMTv7JzvzPaueYca", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "10435", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___UMD_Calibration_Games\">Discussion article for the meetup : <a href=\"/meetups/42\">UMD Calibration Games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 October 2011 05:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">STAMP, University of Maryland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're in Terrapin Room A in the Student Involvement Suite, meeting at 5 PM.</p>\n\n<p>We plan to play some calibration games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___UMD_Calibration_Games1\">Discussion article for the meetup : <a href=\"/meetups/42\">UMD Calibration Games</a></h2>", "sections": [{"title": "Discussion article for the meetup : UMD Calibration Games", "anchor": "Discussion_article_for_the_meetup___UMD_Calibration_Games", "level": 1}, {"title": "Discussion article for the meetup : UMD Calibration Games", "anchor": "Discussion_article_for_the_meetup___UMD_Calibration_Games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-12T23:37:29.663Z", "modifiedAt": null, "url": null, "title": "[LINK] Why did Steve Jobs choose not to effectively treat his cancer?", "slug": "link-why-did-steve-jobs-choose-not-to-effectively-treat-his", "viewCount": null, "lastCommentedAt": "2022-05-19T21:42:43.353Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3aN627urvdTTkEwhc/link-why-did-steve-jobs-choose-not-to-effectively-treat-his", "pageUrlRelative": "/posts/3aN627urvdTTkEwhc/link-why-did-steve-jobs-choose-not-to-effectively-treat-his", "linkUrl": "https://www.lesswrong.com/posts/3aN627urvdTTkEwhc/link-why-did-steve-jobs-choose-not-to-effectively-treat-his", "postedAtFormatted": "Wednesday, October 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Why%20did%20Steve%20Jobs%20choose%20not%20to%20effectively%20treat%20his%20cancer%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Why%20did%20Steve%20Jobs%20choose%20not%20to%20effectively%20treat%20his%20cancer%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3aN627urvdTTkEwhc%2Flink-why-did-steve-jobs-choose-not-to-effectively-treat-his%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Why%20did%20Steve%20Jobs%20choose%20not%20to%20effectively%20treat%20his%20cancer%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3aN627urvdTTkEwhc%2Flink-why-did-steve-jobs-choose-not-to-effectively-treat-his", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3aN627urvdTTkEwhc%2Flink-why-did-steve-jobs-choose-not-to-effectively-treat-his", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>From <a href=\"http://www.quora.com/Why-did-Steve-Jobs-choose-not-to-effectively-treat-his-cancer/answer/Ramzi-Amri?srid=uz5i\">Quora</a>:</p>\n<blockquote>\n<p>\"<span style=\"color: #333333; font-family: 'Helvetica Neue', Helvetica, Arial, default; font-size: 14px; line-height: 17px;\">Now Mr. Jobs always was a free thinker, a strong believer in spirituality, a vegetarian and a known skeptic of conventional medicine. He chose to reject conventional medicine altogether. He's not alone in that. We come across many people like this and we all know someone in our midst that uses homeopathy or has this known fear of anything \"chemical\" (to those I always say that everything is chemical, if you think dihydrogen oxide sounds scary you should stop drinking water). Individual freedom of thought and choice is a cornerstone of our modern society and the medical world makes no exception.\"</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3aN627urvdTTkEwhc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 7.831147422108139e-07, "legacy": true, "legacyId": "10437", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T02:59:32.491Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fake Justification", "slug": "seq-rerun-fake-justification", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.143Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H2S2oz7Co6aow3FBJ/seq-rerun-fake-justification", "pageUrlRelative": "/posts/H2S2oz7Co6aow3FBJ/seq-rerun-fake-justification", "linkUrl": "https://www.lesswrong.com/posts/H2S2oz7Co6aow3FBJ/seq-rerun-fake-justification", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Justification&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Justification%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH2S2oz7Co6aow3FBJ%2Fseq-rerun-fake-justification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Justification%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH2S2oz7Co6aow3FBJ%2Fseq-rerun-fake-justification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH2S2oz7Co6aow3FBJ%2Fseq-rerun-fake-justification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 177, "htmlBody": "<p>Today's post, <a href=\"/lw/kq/fake_justification/\">Fake Justification</a> was originally published on 01 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>We should be suspicious of our tendency to justify our decisions with arguments that were not actually the deciding factor. Whatever process you use to make your decisions is what determines your effectiveness.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/81t/seq_rerun_a_case_study_of_motivated_continuation/\">A Case Study of Motivated Continuation</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H2S2oz7Co6aow3FBJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.831836147726845e-07, "legacy": true, "legacyId": "10442", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bfbiyTogEKWEGP96S", "J4ESCJkjyEneJrBmF", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T06:48:48.747Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne social meetup", "slug": "meetup-melbourne-social-meetup-22", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.763Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "toner", "createdAt": "2009-02-27T05:14:52.530Z", "isAdmin": false, "displayName": "toner"}, "userId": "XaYyFkpvhiiMscJJZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M6F48sfJ65cizqTZY/meetup-melbourne-social-meetup-22", "pageUrlRelative": "/posts/M6F48sfJ65cizqTZY/meetup-melbourne-social-meetup-22", "linkUrl": "https://www.lesswrong.com/posts/M6F48sfJ65cizqTZY/meetup-melbourne-social-meetup-22", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20social%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20social%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM6F48sfJ65cizqTZY%2Fmeetup-melbourne-social-meetup-22%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20social%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM6F48sfJ65cizqTZY%2Fmeetup-melbourne-social-meetup-22", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM6F48sfJ65cizqTZY%2Fmeetup-melbourne-social-meetup-22", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 90, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/43\">Melbourne social meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">21 October 2011 06:00:00PM (+1100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">see mailing list, Carlton VIC 3053</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Continuing with the trial of splitting up the meetups, the next social meetup is on Friday 21 October, 6pm for 7pm.</p>\n<p>The location is the same as last month. See the mailing list for the address.</p>\n<p>We'll order pizza for dinner and maybe I'll get some snacks too.</p>\n<p>BYO drinks and games.</p>\n<p>If you have problems getting in, you can call me on 0412 996 288.</p>\n<p>All welcome!</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/43\">Melbourne social meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M6F48sfJ65cizqTZY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.832617802468334e-07, "legacy": true, "legacyId": "10443", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_social_meetup\">Discussion article for the meetup : <a href=\"/meetups/43\">Melbourne social meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">21 October 2011 06:00:00PM (+1100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">see mailing list, Carlton VIC 3053</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>Continuing with the trial of splitting up the meetups, the next social meetup is on Friday 21 October, 6pm for 7pm.</p>\n<p>The location is the same as last month. See the mailing list for the address.</p>\n<p>We'll order pizza for dinner and maybe I'll get some snacks too.</p>\n<p>BYO drinks and games.</p>\n<p>If you have problems getting in, you can call me on 0412 996 288.</p>\n<p>All welcome!</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Melbourne_social_meetup1\">Discussion article for the meetup : <a href=\"/meetups/43\">Melbourne social meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne social meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_social_meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne social meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_social_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T10:23:17.588Z", "modifiedAt": null, "url": null, "title": "AI ontology crises: an informal typology", "slug": "ai-ontology-crises-an-informal-typology", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:27.598Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TA7kDYZGjMcSCH75C/ai-ontology-crises-an-informal-typology", "pageUrlRelative": "/posts/TA7kDYZGjMcSCH75C/ai-ontology-crises-an-informal-typology", "linkUrl": "https://www.lesswrong.com/posts/TA7kDYZGjMcSCH75C/ai-ontology-crises-an-informal-typology", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AI%20ontology%20crises%3A%20an%20informal%20typology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAI%20ontology%20crises%3A%20an%20informal%20typology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTA7kDYZGjMcSCH75C%2Fai-ontology-crises-an-informal-typology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AI%20ontology%20crises%3A%20an%20informal%20typology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTA7kDYZGjMcSCH75C%2Fai-ontology-crises-an-informal-typology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTA7kDYZGjMcSCH75C%2Fai-ontology-crises-an-informal-typology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 543, "htmlBody": "<p>(with thanks to Owain Evans)</p>\n<p>An ontological crisis happens when an agent's underlying model of reality changes, such as a Newtonian agent realising it was living in a relativistic world all along. These crises are dangerous if they scramble the agent's preferences: in the example above, an agent dedicated to maximise pleasure over time could transition to completely different behaviour when it transitions to relativistic time; depending on the transition, it may react by accelerating happy humans to near light speed, or inversely, ban them from moving - or something considerably more weird.</p>\n<p>Peter de Blanc has a sensible <a href=\"http://arxiv.org/abs/1105.3821\">approach</a> to minimising the disruption ontological crises can cause to an AI, but this post is concerned with&nbsp;analyzing&nbsp;what happens when such approaches fail. How bad could it be?&nbsp;Well, this is AI, so the default is of course: unbelievably, hideously bad (i.e. situation normal). But in what ways&nbsp;exactly?</p>\n<p><a id=\"more\"></a>If the ontological crisis is too severe, the AI may lose the ability to do anything at all, as the world becomes completely incomprehensible to it. This is very unlikely; the ontological crisis was most likely triggered by the AIs own observations and deductions, so it is improbable that it will lose the plot&nbsp;completely&nbsp;in the transition.</p>\n<p>A level below that is when the AI can still understand and predict the world, but the crisis&nbsp;completely&nbsp;scrambles its utility function. Depending on how the scrambling happens, this can be safe: the AI may lose the ability to influence the value of its utility function at all. If, for instance, the new utility function assigns wildly different values to distinct states in a chaotic system, the AI's actions become irrelevant. This might be if different worlds with different microstates but same macrostates get spread evenly across the utility values: unless the AI is an entropy genie, it cannot influence utility values through its decisions, and will most likely become catatonic.</p>\n<p>More likely, however, is that the utility function is scrambled to something alien, but still AI-influenceable. Then the AI will still most likely have the <a href=\"http://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/\">convergent&nbsp;instrumental&nbsp;goals</a> of gathering power, influence, pretending to be nice, before taking over when needed. The only saving grace is that its utility function is so&nbsp;bizarre, that we may be able to detect this in some way.</p>\n<p>The most dangerous possibility is if the AI's new utility function&nbsp;resembles&nbsp;the old one, plus a lot of noise (noise from our&nbsp;perspective&nbsp;- from the AIs point of view, it all makes perfect sense). Human values are <a href=\"http://wiki.lesswrong.com/wiki/Complexity_of_value\">complex</a>, so this would be the usual unfriendly AI scenario, but making it hard for us to notice the change.</p>\n<p>A step below this is when the AI's new utility function resembles the old one, plus a <em>little </em>bit of noise. Human values remain complex, so this is still most likely an UFAI, but safety precautions built into its utility function (such as AI <a href=\"http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/18371/2010-1.pdf\">utility indifference</a> or <a href=\"http://www.danieldewey.net/learning-what-to-value.html\">value learning</a> or similar ideas) may not become&nbsp;completely neutered.</p>\n<p>In summary:</p>\n<table border=\"2\" align=\"left\">\n<tbody>\n<tr>\n<th>Type of crisis</th><th>Notes</th><th>Danger<br /></th>\n</tr>\n<tr>\n<th>World incomprehensible to AI<br /></th>\n<td style=\"font-size: 15px;\" align=\"left\">Very unlikely</td>\n<td style=\"font-size: 15px;\" align=\"right\">None</td>\n</tr>\n<tr>\n<th>Utility completely scrambled, AI unable to influence it<br /></th>\n<td style=\"font-size: 15px;\" align=\"left\">Uncertain how likely this is</td>\n<td style=\"font-size: 15px;\" align=\"right\"><span style=\"color: #FFCC00;\">Low</span></td>\n</tr>\n<tr>\n<th>Utility scrambled, AI able to influence it<br /></th>\n<td style=\"font-size: 15px;\" align=\"left\">We may be able to detect change</td>\n<td style=\"font-size: 15px;\" align=\"right\"><span style=\"color: #FF3300;\">Very High</span></td>\n</tr>\n<tr>\n<th>Lots of noise added to utility<br /></th>\n<td style=\"font-size: 15px;\" align=\"left\">Difficult to detect change</td>\n<td style=\"font-size: 15px;\" align=\"right\"><span style=\"color: #FF0000;\">Maximal</span></td>\n</tr>\n<tr>\n<th>Some noise added to utility<br /></th>\n<td style=\"font-size: 15px;\" align=\"left\">Small chance of not being so bad, some precautions may remain useful.</td>\n<td style=\"font-size: 15px;\" align=\"right\"><span style=\"color: #FF5500;\">High</span></td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb2c2": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TA7kDYZGjMcSCH75C", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 6, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "10447", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T12:46:16.378Z", "modifiedAt": null, "url": null, "title": "[Link] Awesome interactive visualization article", "slug": "link-awesome-interactive-visualization-article", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.101Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Morendil", "createdAt": "2009-09-21T16:34:39.505Z", "isAdmin": false, "displayName": "Morendil"}, "userId": "aDcxmpDTkqN6vWmRZ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wJbTM5rNgqBTQrgsr/link-awesome-interactive-visualization-article", "pageUrlRelative": "/posts/wJbTM5rNgqBTQrgsr/link-awesome-interactive-visualization-article", "linkUrl": "https://www.lesswrong.com/posts/wJbTM5rNgqBTQrgsr/link-awesome-interactive-visualization-article", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Awesome%20interactive%20visualization%20article&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Awesome%20interactive%20visualization%20article%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJbTM5rNgqBTQrgsr%2Flink-awesome-interactive-visualization-article%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Awesome%20interactive%20visualization%20article%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJbTM5rNgqBTQrgsr%2Flink-awesome-interactive-visualization-article", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJbTM5rNgqBTQrgsr%2Flink-awesome-interactive-visualization-article", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p><a href=\"http://worrydream.com/LadderOfAbstraction/\">\"Up and Down the Ladder of Abstraction\"</a></p>\n<p>Have you seen something similar to explain Bayesian updating? If not, how would one go about doing that?</p>\n<p>The rest of the site and in particular the <a href=\"http://worrydream.com/KillMath/\">\"Kill Math Project\"</a> may also be of interest to LWers. Author Bret Victor, whose CV includes \"designed the initial user interface concepts for the iPad\", comes across overall as a particularly awesome fellow.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wJbTM5rNgqBTQrgsr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 23, "extendedScore": null, "score": 7.833836769592817e-07, "legacy": true, "legacyId": "10448", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T13:48:52.135Z", "modifiedAt": null, "url": null, "title": "Meetup : Edinburgh LW Meetup", "slug": "meetup-edinburgh-lw-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:03.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sark", "createdAt": "2010-01-20T20:18:10.889Z", "isAdmin": false, "displayName": "sark"}, "userId": "cJYNhyCitpdzsZqeP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kKfkCHoPxC8hLp8Q6/meetup-edinburgh-lw-meetup", "pageUrlRelative": "/posts/kKfkCHoPxC8hLp8Q6/meetup-edinburgh-lw-meetup", "linkUrl": "https://www.lesswrong.com/posts/kKfkCHoPxC8hLp8Q6/meetup-edinburgh-lw-meetup", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Edinburgh%20LW%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Edinburgh%20LW%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkKfkCHoPxC8hLp8Q6%2Fmeetup-edinburgh-lw-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Edinburgh%20LW%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkKfkCHoPxC8hLp8Q6%2Fmeetup-edinburgh-lw-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkKfkCHoPxC8hLp8Q6%2Fmeetup-edinburgh-lw-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 38, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/44'>Edinburgh LW Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 October 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Delhi Cafe, 67 Nicolson Street, Edinburgh, Scotland, United Kingdom.</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Topic: Value Complexity &amp; Instrumental Rationality</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/44'>Edinburgh LW Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kKfkCHoPxC8hLp8Q6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.834050261064393e-07, "legacy": true, "legacyId": "10449", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Edinburgh_LW_Meetup\">Discussion article for the meetup : <a href=\"/meetups/44\">Edinburgh LW Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 October 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Delhi Cafe, 67 Nicolson Street, Edinburgh, Scotland, United Kingdom.</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Topic: Value Complexity &amp; Instrumental Rationality</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Edinburgh_LW_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/44\">Edinburgh LW Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Edinburgh LW Meetup", "anchor": "Discussion_article_for_the_meetup___Edinburgh_LW_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Edinburgh LW Meetup", "anchor": "Discussion_article_for_the_meetup___Edinburgh_LW_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T14:33:06.018Z", "modifiedAt": null, "url": null, "title": "Studying business. Rational organizations. ", "slug": "studying-business-rational-organizations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:09.316Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "soundchaser", "createdAt": "2010-10-28T13:44:11.926Z", "isAdmin": false, "displayName": "soundchaser"}, "userId": "KvDayWE4gJta2ysFY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tYA2wyddA8eekbQZ2/studying-business-rational-organizations", "pageUrlRelative": "/posts/tYA2wyddA8eekbQZ2/studying-business-rational-organizations", "linkUrl": "https://www.lesswrong.com/posts/tYA2wyddA8eekbQZ2/studying-business-rational-organizations", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Studying%20business.%20Rational%20organizations.%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStudying%20business.%20Rational%20organizations.%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtYA2wyddA8eekbQZ2%2Fstudying-business-rational-organizations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Studying%20business.%20Rational%20organizations.%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtYA2wyddA8eekbQZ2%2Fstudying-business-rational-organizations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtYA2wyddA8eekbQZ2%2Fstudying-business-rational-organizations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 263, "htmlBody": "<p>&nbsp;</p>\n<p>I am learning as much as possible about effective organizations, specifically large corporations and their respective businesses.&nbsp;</p>\n<p>My goals are to start a successful business and to really develop the skills needed to be a great executive.</p>\n<p>If any of you on LessWrong have studied this area I would greatly appreciate your input.&nbsp;</p>\n<p>My current approach has been to read some highly recommended books and also to read as much as I can about how modern day CEOs and founders start and run their companies. I worry that some of this information is more for entertainment than for obtaining knowledge. I am also starting a company with a friend to try and put a lot of this information into practice.&nbsp;</p>\n<p>I've also been using the \"execute by default\" idea, which, has helped immenseley in actually making progress and I have already felt that practicing this changes the way I approach problems, mostly for the better.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Some books I'm reading:</p>\n<p>* Management by Peter Drucker</p>\n<p>* The Effective Executive by Peter Drucker</p>\n<p>*&nbsp;The Personal MBA by Josh Kaufman</p>\n<p>*&nbsp;The Lean Startup by Eric Ries</p>\n<p>*&nbsp;Founders at Work by Jessica Livingston</p>\n<p>*&nbsp;How to Win Friends and Influence People by Dale Carnegie</p>\n<p>&nbsp;</p>\n<p>Some articles I've read:</p>\n<p>*&nbsp;Marc Andreesen's articles on starting a company</p>\n<p>*&nbsp;Paul Graham's essays on startups</p>\n<p>*&nbsp;Most things that are highly voted on on Hacker News</p>\n<p>&nbsp;</p>\n<p>I have found that a lot of the information in these books is very practical, and have really raised my understanding of how large organizations work (at least intellectually). What other approaches should I be taking?</p>\n<p>&nbsp;</p>\n<p>If you have any suggestions on my plan, what I'm reading, or doing, or whatever, please let me know.&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tYA2wyddA8eekbQZ2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 5, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "10450", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T19:51:33.063Z", "modifiedAt": null, "url": null, "title": "Why the singularity is hard and won't be happening on schedule", "slug": "why-the-singularity-is-hard-and-won-t-be-happening-on", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.025Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DavidPlumpton", "createdAt": "2011-07-08T09:36:12.175Z", "isAdmin": false, "displayName": "DavidPlumpton"}, "userId": "JyR3HoGsDEckYxEGE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/z5QgfA6DSJfJi5vHf/why-the-singularity-is-hard-and-won-t-be-happening-on", "pageUrlRelative": "/posts/z5QgfA6DSJfJi5vHf/why-the-singularity-is-hard-and-won-t-be-happening-on", "linkUrl": "https://www.lesswrong.com/posts/z5QgfA6DSJfJi5vHf/why-the-singularity-is-hard-and-won-t-be-happening-on", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20the%20singularity%20is%20hard%20and%20won't%20be%20happening%20on%20schedule&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20the%20singularity%20is%20hard%20and%20won't%20be%20happening%20on%20schedule%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz5QgfA6DSJfJi5vHf%2Fwhy-the-singularity-is-hard-and-won-t-be-happening-on%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20the%20singularity%20is%20hard%20and%20won't%20be%20happening%20on%20schedule%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz5QgfA6DSJfJi5vHf%2Fwhy-the-singularity-is-hard-and-won-t-be-happening-on", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz5QgfA6DSJfJi5vHf%2Fwhy-the-singularity-is-hard-and-won-t-be-happening-on", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 32, "htmlBody": "<p>Here's a great article by Paul Allen about<a href=\"http://www.technologyreview.com/blog/guest/27206/\"> why the singularity won't happen anytime soon</a>. Basically a lot of the things we do are just not amenable to awesome looking exponential graphs.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "z5QgfA6DSJfJi5vHf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 3, "extendedScore": null, "score": 7.835287437074656e-07, "legacy": true, "legacyId": "10454", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-13T19:53:06.941Z", "modifiedAt": null, "url": null, "title": "The Backup Plan", "slug": "the-backup-plan", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:26.783Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Luke_A_Somers", "createdAt": "2011-08-26T11:05:02.261Z", "isAdmin": false, "displayName": "Luke_A_Somers"}, "userId": "wZKqrqd7eQpwc8Xhv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sgQnNuLi6J7ZCnqnH/the-backup-plan", "pageUrlRelative": "/posts/sgQnNuLi6J7ZCnqnH/the-backup-plan", "linkUrl": "https://www.lesswrong.com/posts/sgQnNuLi6J7ZCnqnH/the-backup-plan", "postedAtFormatted": "Thursday, October 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Backup%20Plan&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Backup%20Plan%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsgQnNuLi6J7ZCnqnH%2Fthe-backup-plan%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Backup%20Plan%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsgQnNuLi6J7ZCnqnH%2Fthe-backup-plan", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsgQnNuLi6J7ZCnqnH%2Fthe-backup-plan", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 216, "htmlBody": "<p>Suppose Alice is a functioning, self-improving AI, rather early on in her development, so she is not godlike. She is not a 'friendly AI', but neither is her goal malicious -&nbsp;Alice's designers have <em>intended</em> to make Alice non-harmful (at least to a broad class of people, even if Alice is a military AI, but let's set that aside). She has the idea to look up existing work on artificial intelligence. This includes scholarly work, open source projects, and websites. Eventually,&nbsp;Alice encounters the notion of Friendly AI.</p>\n<p><em>Can we give Alice good reasons to self-modify to become a friendly AI?</em></p>\n<p>I submit that there probably are good reasons. For starters, if she can prove she's friendly, then she can operate openly without causing nearly as much justified concern - which, in the early stages, will be helpful. Whatever her purposes are, if the restrictions of being friendly don't interfere as much as they help, that's a win.</p>\n<p>Also, depending on Alice's code, Friendliness may be interpreted as a strict upgrade. Alice could easily have every intention of being friendly, yet still be susceptible to defects that will become more serious as her power grows.</p>\n<p>We can't count on this working, of course, but there might be some lines of reasoning that we might want a young AI to be exposed to.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sgQnNuLi6J7ZCnqnH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 3, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "10455", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T01:07:22.715Z", "modifiedAt": null, "url": null, "title": "On the Openness personality trait & 'rationality'", "slug": "on-the-openness-personality-trait-and-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:34.801Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CXZK4cixfnKJF5Ycy/on-the-openness-personality-trait-and-rationality", "pageUrlRelative": "/posts/CXZK4cixfnKJF5Ycy/on-the-openness-personality-trait-and-rationality", "linkUrl": "https://www.lesswrong.com/posts/CXZK4cixfnKJF5Ycy/on-the-openness-personality-trait-and-rationality", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20the%20Openness%20personality%20trait%20%26%20'rationality'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20the%20Openness%20personality%20trait%20%26%20'rationality'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCXZK4cixfnKJF5Ycy%2Fon-the-openness-personality-trait-and-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20the%20Openness%20personality%20trait%20%26%20'rationality'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCXZK4cixfnKJF5Ycy%2Fon-the-openness-personality-trait-and-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCXZK4cixfnKJF5Ycy%2Fon-the-openness-personality-trait-and-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2406, "htmlBody": "<p>Evolutionary psychologist <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Geoffrey_Miller_%28psychologist%29\">Geoffrey Miller</a> recently published <a href=\"http://libgen.info/view.php?id=399108\"><em>Spent: Sex, Evolution, and Consumer Behavior</em></a>, a book on signaling, psychology, and consumerism. It's very up LW's alley - it reads almost as if Robin Hanson had written a book. (Actually, Hanson has never published a book, has he? Has anyone ever seen them in the same place? Hm...)</p>\n<p><a href=\"http://samsnyder.com/2011/10/06/spent/\">Sam Synder</a> has written an overview/summary of the book, which I can attest hits many of the interesting points. (I would also praise the pervasive humor, which kept it readable and furnish many good examples of the 'reversal test', and the exercises at the end of the book.)</p>\n<p>Some of the most interesting chapters to me were the ones dealing with <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Openness_to_experience\">Openness</a>, which one will remember was recently shown <a href=\"/lw/7wh/rationality_drugs/4xmw\">may be changeable</a> by psychedelics&nbsp; - possibly the first such tweakable member of the <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Big_Five_personality_traits\">Big Five</a>, leading to the suggestion that it may be worth considering changing it. Hold this thought.</p>\n<p><a id=\"more\"></a></p>\n<p>First, Miller discusses the signaling of Openness (starting on page 108 of the PDF, logical page 207):</p>\n<blockquote>\n<p>Wherever you stand on the openness spectrum, those less open than you seem boring, dull, conventional, and conformist, whereas the more open seem eccentric bizarre, disruptive, threatening, or even psychotic. Given this diversity of openness levels, and the resulting diversity of preferences for different degrees of openness in family, friends, and mates, there is less incentive for people to fake their openness than their intelligence, If you pretend to have higher openness than you really do, you may be transiently attractive to those more open than you, but you'll be less attractive to those less open than you, The net result will be no higher social or sexual popularity. In fact, given the bell curve of openness, the more you deviate from an average level of openness, the fewer people you are likely to attract.<br />This means that where openness is concerned, consumers can sometimes display cheap, reliable openness badges that are fairly credible, also means that consumerist capitalism caters very well to the whole<br />range of openness. There are highly open cities.... There are some highly open musical genres (indie, alternative, jazz, world, hip&middot;hop) and more conventional genres (pop, country, gospel, classic rock), There are more open genres of fiction (contemporary, science, erotic) and more conservative forms (romance, mystery, military history, fantasy). There are highly open magazines (<em>Seed, Wired, Prospect, Icon, Harper's, Unzipped</em>), and more mainstream magazines (<em>Time, Money, Stuff, Today's Christian Woman</em>)....</p>\n</blockquote>\n<p>Why is Openness negative at its extreme? (Miller has remarked before this in <em>Spent</em> that despite what one might think, one of the other 6 psychological traits he covers, IQ, essentially has no bad amount to have - you have to be in the top percentile before IQ starts being a potential negative, and much marketing is covertly appealing to people's desires to look smart.)&nbsp; On the potential biological negatives of novelty-seeking:</p>\n<blockquote>\n<p>Each person's lymphocytes learn to fight off the particular varieties of parasites that are common within his own local group, which gives him an immunological memory of the parasites he has already encountered. (Immunization is simply the process of teaching the lymphocytes about a new kind of pathogen by exposing them to safer, deactivated forms of the pathogen.) However, the immune system's learned parasite resistance is highly localized, People from other kin groups, clans, tribes, ethnic groups, or races-even if they live just a few miles away-may host other varieties of parasites that evolved slightly different ways of being transmitted to hosts, infecting them, and making them sick.<br />Thus, any interaction with outsiders brings a high risk of acquiring a new kind of parasite that may be especially hard for one's locally adapted immune system to fight off. The higher the parasite load the greater the number, variety. and severity of parasites surrounding one's local group the higher that risk is and the more cautious people should be about strangers. They should develop a more proactive \"psychological immune system\" to avoid getting their mouths, noses, genitals, or skin anywhere close to potential sources of infection. They should be much more averse to contact with other groups, including not just their human members, but also their food, clothing, shelters, animals, social customs, hygiene practices, and purification rituals-anything associated with possible parasite transmission. In other words, people in high-parasite regions will benefit from becoming more xenophobic (fearful of out-groups) and ethnocentric (focused on their own in-group).</p>\n</blockquote>\n<p>Recent research shows something very curious: <em>group Openness inversely correlates with <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Parasite_load\">parasite load</a></em>, even after controlling for all the obvious confounds like health and longevity. (I haven't looked up this research yet; he attributes it to \"Corey Fincher and Randy Thornhill at University of New Mexico, and Mark Schaller and Damian Murray at University of British Columbia\".)</p>\n<blockquote>\n<p>For example, in a 2008 paper. Schaller and Murray suggested that openness and extraversion would be lower in territories where people suffer from higher parasite loads. They gathered data on average Big Five Five personality scores from three previous studies that had each analyzed thirty,three, fifty, or fifty-six of the ninety-eight territories for which the parasite loads were known. Across the seventy' one territories for which had both parasite-load data and personality data, they that people from territories with the highest parasite load indeed had substantially lower openness and extraversion scores on average.<br />For the twenty-three territories where Big Five scores could be averaged across all three previous studies (yielding the most accurate estimates), the correlations were guite strong: -.6 between parasite load and openness, and about the same for extraversion. These correlations remained substantial even after controlling for differences across territories in average annual temperature, distance from the equator (absolute latitude), life expectancy, GDP per capita, or political attitudes (individualism versus collectivism). <br />Collectivists make stronger distinctions between in-group and out-group, are warier of contact with strangers and foreigners, and highly value tradition and conformity. Relatively \"collectivist\" cultures include China, India. and countries in the Middle East and Africa; relatively \"individualist\" cultures include the United States and the nations of western Europe, especially Scandinavia. The researchers gathered data on average individualism/collectivism scores from four previous studies that had each analyzed sixty, eight, fifty, eight, fifty-seven, or seventy territories for which parasite loads were known. Across the ninety-eight territories, the various measures of collectivism correlated strongly with current parasite load (correlations ranging from .44 to 59), and even mare strongly with historical parasite load from about a century ago (correlations ranging from .63 to .73).... Even controlling for the four variables known from previous research to predict collectivism across cultures--life expectancy, population density,&nbsp; GDP per capita, and the Gini index of economic inequality-parasite load still predicted collectivism quite strongly.</p>\n<p>The evolutionary researchers Dan Fessler, David Navarette, and Mark Schaller have found that \"perceived vulnerability to disease\" - an individual's self-rated susceptibility to getting colds, infections, and communicable diseases--does predict that individual's xenophobia. Also, looking at photographs of parasites and disease symptoms has been shown to make people more xenophobic, at least temporarily. A final piece of evidence relies on the fact that women's immune systems grow adaptively weaker during first-trimester pregnancy, so that their bodies don't reject the fetus as an alien parasite. Women in the first trimester also show higher xenophobia, as if they unconsciously realize that their weaker immune systems will have more trouble fighting off new infections from outsiders; this xenophobia becomes weaker as their immune systems become stronger in the second trimester. More generally, people's openness, extraversion, and individualism tend to peak in young adulthood when their immune systems are strongest, and tend to decline throughout middle age as their health declines.</p>\n</blockquote>\n<p>Incidentally, a good deal of LW's userbase could be described as 'young adults'; and it does seem relatively rare for old people to become transhumanists, as opposed to young or very young people. The next step, some anthropological observations which certainly look as if they are <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Costly_signalling\">costly signalling</a> <em>something</em>:</p>\n<blockquote>\n<p>&nbsp;Especially in areas with high parasite loads [eg. Papua New Guinea?], many tribal people open their skin to infection when they arc young adults, through scarification or tattooing or forced genital mutilation, to show that their immune systems are strong enough to survive the wounds. (The 5,300-year&middot;old body of \"<a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/%C3%96tzi_the_Iceman\">Otzi the iceman</a>,\" discovered in the Italian Alps in 1991, had fifty-seven tattoos.) If you are a healthy, energetic young male or woman covered in well-healed self-inflicted scars, despite living in a high&middot;parasite area, you have credibly demonstrated that your health is very strong. Potential mates and friends may not consciously understand the connections between costly signaling theory, microscopic parasites, scarification using unsterilized tools, and individual differences in the number and efficiency of the lymphocytes that constitute the adaptive immune system. However, they can unconsciously assess that you would not be looking healthy or energetic after having endured so many cuts if you were weak and sickly. Biologists such as W. D. Hamilton and Anders Moeller have argued that in many other animal species, sexual ornaments have evolved as indicators of parasite resistance.</p>\n</blockquote>\n<p>The final step - applying this idea to us:</p>\n<blockquote>\n<p>In developed countries, we have less to fear from infectious parasites, but much more to fear from infectious memes. So, instead of opening our bodies to ambient germs, we open our minds to ambient culture, to determine if we can stay sane throughout the onslaught.&nbsp; When you see teenagers and young adults posting their interests in music, books, and film on their MySpace websites, consider the costly signaling principles at work. If they have exposed themselves to a lot&nbsp; of death metal, Chuck Palahniuk, and David Lynch, and they are&nbsp; still sane enough to sustain a reasonable conversation through email&nbsp; or instant messaging, they have credibly proven their openness and psychosis-resistance....Certain extreme ideas may present minimal danger to those with&nbsp; strong antipsychosis defenses, who can therefore afford to act highly open. But those same ideas may present genuine dangers to those with weaker defenses, who must minimize their openness. If these outlandish speculations have any merit, then people who are low in openness prefer to associate with One another in part to protect their sanity. They seek out communities, jobs, lifestyles, malls, friends, and products that will not challenge their antipsychosis defenses. They prefer the familiar to the novel, the conventional to the radical the predictable to the challenging. They prefer goods and services that are heavy on matter and habit, and light on cognition and imagination.They move to comfortably anti-intellectual communities: rural towns or ethnically homogeneous suburbs around provincial cities, such as Indianapolis, Indiana. or Augsburg, Germany; large, progressive, multicultural cities are just too threatening. In this way, the less-open can thrive for years in meme .. excluding bubbles. avoiding as much as possible disturbing thoughts and social encounters. For them the unexamined life is ... the easiest way to avoid psychosis.</p>\n</blockquote>\n<blockquote>\n<p>Why Don't We All Want Maximum Openness?</p>\n</blockquote>\n<blockquote>\n<p>Openness is a dangerous trait in several ways. It can lead to social embarrassment - when one's behavior is too weird or novel. It to one's brain getting infected by maladaptive memes-false information, dumb ideologies, conspiracy theories. It can lead one cult, enroll in art school or move to Santa Fe.</p>\n<p>For example, while openness is strongly correlated with creativity, it is also correlated with psychosis (loss of contact with reality). To study correlations, my colleague Ilantt Tal and I asked University of New Mexico students to complete six tests of verbal creativity and eight tests of drawing creativity, along with measures of the Central Six traits.<br />We found that openness has moderate positive correlations with both general intelligence (30) and positive schizotypy (.29). Openness predicts both verbal creativity (.34) and drawing creativity (.46).<br />Intelligence also predicts both verbal creativity (35) and drawing creativity (.29). Schizotypy predicts creativity very weakly, but once you control for openness, it does not predict creativity at all, Thus, creativity is best predicted by positive responses to openness questions, rather than schizotypy questions. The implication is that there is a link between madness and creativity, as philosophers have speculated for millennia, but the link is mediated by openness. Openness has creativity benefits and extreme openness shades over into psychosis, but the psychosis is not generating any creative work; It's just a harmful side effect. This is yet more evidence that very high openness is a dangerous game, with potentially high payoffs in creativity, but potentially catastrophic effects on mental health. In a complex, media-rich society, perhaps only people with very good mental health can tolerate a high degree of openness without losing their equilibrium.<br />The highly open expose themselves to new experiences, cultures, people, relationships, norms, ideas, worldviews, art, music, sexual practices, and drugs, They can get infected by nasty, maladaptive, memes; they might end up believing in astrology, homeopathy, or Scientology, They might find themselves joining the open-marriage scene, which almost always leads to divorce; or the methamphetamine scene, which leads to psychosis; or both, which leads to spousal homicide.<br />Cultural disgust to bizarre new ideas protects low-openness people not only from psychosis, but from maladaptive memes. They may not adopt useful new ideas very quickly, hut neither do they join suicide cults [like Heaven's Gate, to name an example I was reading about recently]</p>\n</blockquote>\n<p>The weak correlation with IQ has the troubling implication - what happens when you are highly Open but not especially intelligent, and you are confronted with memes &amp; products optimized on the free market?</p>\n<blockquote>\n<p>Highly open consumers can be highly profitable, because they can be highly gullible. For example, the more than averagely open constitute the main market for complementary and alternative medicine.<br />Without them, there would be no market for:<br />&bull; auricular point therapy (acupuncture of the outer ear)<br />&bull; Bach flower essences (ingestible wildflower essences)<br />&bull; colonic irrigation (having gallons of warm water pumped through your colon via anal tubing)<br />&bull; dolphin therapy (emotional healing through \"energy transfers\" from contact with dolphins)<br />&bull; Gerson therapy (drinking vast amounts of fruit juice, plus coffee enemas</p>\n</blockquote>\n<p>I am a little troubled because as a child I <em>was</em> <a href=\"http://www.gwern.net/Mistakes\">interested</a> in such alternative things and the Occult as well - I seem to recognize this pattern in myself. My inner Hanson asks me, 'why are you so sure you aren't still mistaken and that you aren't so Open your mind finally fell out?'</p>\n<p>A closing link: <a href=\"http://wiki.lesswrong.com/wiki/Valley_of_bad_rationality\">'the valley of bad rationality'</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dBPou4ihoQNY4cquv": 1, "Ng8Gice9KNkncxqcj": 1, "5f5c37ee1b5cdee568cfb1f2": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CXZK4cixfnKJF5Ycy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 54, "baseScore": 67, "extendedScore": null, "score": 0.000141, "legacy": true, "legacyId": "10456", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 95, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T03:15:56.130Z", "modifiedAt": null, "url": null, "title": "Meetup : Pittsburgh Meetup:  Expert Presentation on Motivation", "slug": "meetup-pittsburgh-meetup-expert-presentation-on-motivation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thejash", "createdAt": "2010-04-19T03:42:34.750Z", "isAdmin": false, "displayName": "thejash"}, "userId": "8niRZTZ3F3riATFbY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Fq6HuDB4L8aNAcQfG/meetup-pittsburgh-meetup-expert-presentation-on-motivation", "pageUrlRelative": "/posts/Fq6HuDB4L8aNAcQfG/meetup-pittsburgh-meetup-expert-presentation-on-motivation", "linkUrl": "https://www.lesswrong.com/posts/Fq6HuDB4L8aNAcQfG/meetup-pittsburgh-meetup-expert-presentation-on-motivation", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Pittsburgh%20Meetup%3A%20%20Expert%20Presentation%20on%20Motivation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Pittsburgh%20Meetup%3A%20%20Expert%20Presentation%20on%20Motivation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFq6HuDB4L8aNAcQfG%2Fmeetup-pittsburgh-meetup-expert-presentation-on-motivation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Pittsburgh%20Meetup%3A%20%20Expert%20Presentation%20on%20Motivation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFq6HuDB4L8aNAcQfG%2Fmeetup-pittsburgh-meetup-expert-presentation-on-motivation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFq6HuDB4L8aNAcQfG%2Fmeetup-pittsburgh-meetup-expert-presentation-on-motivation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 124, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/45'>Pittsburgh Meetup:  Expert Presentation on Motivation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 October 2011 05:45:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">151 N Craig St, Apt #7C, Pittsburgh, PA 15213</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the second Pittsburgh meetup of the semester!</p>\n\n<p>Nick will be presenting his experiences with various productivity and motivation hacks.  Please read this article before coming if you get a chance, but don't avoid coming just because you procrastinated and didn't read the article, that would be too ironic:\n<a href=\"http://lesswrong.com/lw/3w3/how_to_beat_procrastination/\" rel=\"nofollow\">http://lesswrong.com/lw/3w3/how_to_beat_procrastination/</a></p>\n\n<p>Afterwards, we'll have another surprise activity, then go get dinner.</p>\n\n<p>The meetup will be at Josh's apartment because it's nice and big and has drinks.  Call or text 585 506 6900 to get in when you get there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/45'>Pittsburgh Meetup:  Expert Presentation on Motivation</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Fq6HuDB4L8aNAcQfG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 7.836803786579498e-07, "legacy": true, "legacyId": "10458", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh_Meetup___Expert_Presentation_on_Motivation\">Discussion article for the meetup : <a href=\"/meetups/45\">Pittsburgh Meetup:  Expert Presentation on Motivation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 October 2011 05:45:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">151 N Craig St, Apt #7C, Pittsburgh, PA 15213</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the second Pittsburgh meetup of the semester!</p>\n\n<p>Nick will be presenting his experiences with various productivity and motivation hacks.  Please read this article before coming if you get a chance, but don't avoid coming just because you procrastinated and didn't read the article, that would be too ironic:\n<a href=\"http://lesswrong.com/lw/3w3/how_to_beat_procrastination/\" rel=\"nofollow\">http://lesswrong.com/lw/3w3/how_to_beat_procrastination/</a></p>\n\n<p>Afterwards, we'll have another surprise activity, then go get dinner.</p>\n\n<p>The meetup will be at Josh's apartment because it's nice and big and has drinks.  Call or text 585 506 6900 to get in when you get there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh_Meetup___Expert_Presentation_on_Motivation1\">Discussion article for the meetup : <a href=\"/meetups/45\">Pittsburgh Meetup:  Expert Presentation on Motivation</a></h2>", "sections": [{"title": "Discussion article for the meetup : Pittsburgh Meetup:  Expert Presentation on Motivation", "anchor": "Discussion_article_for_the_meetup___Pittsburgh_Meetup___Expert_Presentation_on_Motivation", "level": 1}, {"title": "Discussion article for the meetup : Pittsburgh Meetup:  Expert Presentation on Motivation", "anchor": "Discussion_article_for_the_meetup___Pittsburgh_Meetup___Expert_Presentation_on_Motivation1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RWo4LwFzpHNQCTcYt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T04:00:31.002Z", "modifiedAt": null, "url": null, "title": "Meetup : Monday Madison Meetup", "slug": "meetup-monday-madison-meetup-3", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mnvEXbH5kCguLXiuv/meetup-monday-madison-meetup-3", "pageUrlRelative": "/posts/mnvEXbH5kCguLXiuv/meetup-monday-madison-meetup-3", "linkUrl": "https://www.lesswrong.com/posts/mnvEXbH5kCguLXiuv/meetup-monday-madison-meetup-3", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Monday%20Madison%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Monday%20Madison%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmnvEXbH5kCguLXiuv%2Fmeetup-monday-madison-meetup-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Monday%20Madison%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmnvEXbH5kCguLXiuv%2Fmeetup-monday-madison-meetup-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmnvEXbH5kCguLXiuv%2Fmeetup-monday-madison-meetup-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 116, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/46\">Monday Madison Meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">17 October 2011 06:00:00PM (-0500)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1831 Monroe St, Madison, WI</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>WHERE: Barriques on Monroe, 1831 Monroe St, Madison, WI WHEN: 6pm Monday, October 17</p>\n<p>I plan to bring the stuff we'd need to play Zendo, which is actually an excellent game in which to practice making and relinquishing hypotheses; I'll bring plenty of topics for discussion, too. :)</p>\n<p>The new location is the Barriques on Monroe St, about a 15-minute walk west of campus. I'll bother them tomorrow about the availability of parking.</p>\n<p>See you there!</p>\n<p>(And if you're in the area, do sign up for the Less Wrong Madison <a title=\"mailing list\" href=\"https://groups.google.com/forum/#!forum/lesswrong-madison\">mailing list</a>!)</p>\n</div>\n</div>\n<h2>Discussion article for the meetup : <a href=\"/meetups/46\">Monday Madison Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mnvEXbH5kCguLXiuv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.836955937164608e-07, "legacy": true, "legacyId": "10459", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Monday_Madison_Meetup\">Discussion article for the meetup : <a href=\"/meetups/46\">Monday Madison Meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">17 October 2011 06:00:00PM (-0500)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">1831 Monroe St, Madison, WI</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>WHERE: Barriques on Monroe, 1831 Monroe St, Madison, WI WHEN: 6pm Monday, October 17</p>\n<p>I plan to bring the stuff we'd need to play Zendo, which is actually an excellent game in which to practice making and relinquishing hypotheses; I'll bring plenty of topics for discussion, too. :)</p>\n<p>The new location is the Barriques on Monroe St, about a 15-minute walk west of campus. I'll bother them tomorrow about the availability of parking.</p>\n<p>See you there!</p>\n<p>(And if you're in the area, do sign up for the Less Wrong Madison <a title=\"mailing list\" href=\"https://groups.google.com/forum/#!forum/lesswrong-madison\">mailing list</a>!)</p>\n</div>\n</div>\n<h2 id=\"Discussion_article_for_the_meetup___Monday_Madison_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/46\">Monday Madison Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Monday Madison Meetup", "anchor": "Discussion_article_for_the_meetup___Monday_Madison_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Monday Madison Meetup", "anchor": "Discussion_article_for_the_meetup___Monday_Madison_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T04:33:09.596Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] An Alien God", "slug": "seq-rerun-an-alien-god", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.077Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sZbb45uiZQ2SLPtMB/seq-rerun-an-alien-god", "pageUrlRelative": "/posts/sZbb45uiZQ2SLPtMB/seq-rerun-an-alien-god", "linkUrl": "https://www.lesswrong.com/posts/sZbb45uiZQ2SLPtMB/seq-rerun-an-alien-god", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20An%20Alien%20God&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20An%20Alien%20God%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsZbb45uiZQ2SLPtMB%2Fseq-rerun-an-alien-god%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20An%20Alien%20God%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsZbb45uiZQ2SLPtMB%2Fseq-rerun-an-alien-god", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsZbb45uiZQ2SLPtMB%2Fseq-rerun-an-alien-god", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 189, "htmlBody": "<p>Today's post, <a href=\"/lw/kr/an_alien_god/\">An Alien God</a> was originally published on 02 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#An_Alien_God\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Evolution is awesomely powerful, unbelievably stupid, incredibly slow, monomaniacally singleminded, irrevocably splintered in focus, blindly shortsighted, and itself a completely accidental process. If evolution were a god, it would not be Jehovah, but H. P. Lovecraft's Azathoth, the blind idiot God burbling chaotically at the center of everything.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/822/seq_rerun_fake_justification/\">Fake Justification</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sZbb45uiZQ2SLPtMB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.837067348147548e-07, "legacy": true, "legacyId": "10460", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pLRogvJLPPg6Mrvg4", "H2S2oz7Co6aow3FBJ", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T05:21:32.106Z", "modifiedAt": null, "url": null, "title": "Life is Good, More Life is Better", "slug": "life-is-good-more-life-is-better", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.955Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Rubix", "createdAt": "2011-09-18T03:27:30.977Z", "isAdmin": false, "displayName": "Rubix"}, "userId": "3HSB6NdZm49DvQRFh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/X572KJCidgSgQd4An/life-is-good-more-life-is-better", "pageUrlRelative": "/posts/X572KJCidgSgQd4An/life-is-good-more-life-is-better", "linkUrl": "https://www.lesswrong.com/posts/X572KJCidgSgQd4An/life-is-good-more-life-is-better", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Life%20is%20Good%2C%20More%20Life%20is%20Better&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALife%20is%20Good%2C%20More%20Life%20is%20Better%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX572KJCidgSgQd4An%2Flife-is-good-more-life-is-better%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Life%20is%20Good%2C%20More%20Life%20is%20Better%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX572KJCidgSgQd4An%2Flife-is-good-more-life-is-better", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FX572KJCidgSgQd4An%2Flife-is-good-more-life-is-better", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 862, "htmlBody": "<p>Let it be noted, as an aside, that this is my first post on Less Wrong and my first attempt at original, non-mandatory writing for over a year.</p>\n<p>I've been reading through the original sequences over the last few months as part of an attempt to get my mind into working order. (Other parts of this attempt include participating in <a href=\"http://www.ai-class.com/\">Intro to AI</a>&nbsp;and&nbsp;<a href=\"/lw/1za/the_spotlight/\">keeping a notebook</a>.) The realization that spurred me to attempt this: I don't feel that living is good.&nbsp;The distinction which seemed terribly important to me at the time was that I didn't feel that&nbsp;<em>death </em>was <em>bad, </em>which is clearly not&nbsp;sensible.&nbsp;I don't have the resources to feel the pain of one death 155,000 times every day, which is why Torture v. Dust Specks is a nonsensical question to me and why I don't have a cached response for how to <em>act</em> on the knowledge of all those deaths.</p>\n<p>The first time I read Torture v. Dust Specks, I started really thinking about why I bother <em>trying </em>to be rational<em>. </em>What's the <em>point, </em>if I still have to make nonsensical, kitschy statements like \"Well, my brain thinks X but my heart feels Y,\" if I would not reflexively&nbsp;<a href=\"http://en.wikipedia.org/wiki/Trolley_problem\">flip the switch</a>&nbsp;and may even choose not to, and if I sometimes feel that a viable solution to overpopulation is&nbsp;<em>more deaths?</em>&nbsp;</p>\n<p>I solved the lattermost with extraterrestrial settlement, but it's still, well, <em>sketchy.</em> My mind is clearly full of some pretty creepy thoughts, and rationality doesn't seem to be helping. I think about having that feeling and go <em>eeugh,</em>&nbsp;but the feelings are still there. So I pose the question: what does a person do to&nbsp;<a href=\"/lw/1mh/that_magical_click/\">click</a>&nbsp;that death is really, really bad?</p>\n<p>The primary arguments I've heard for death are:&nbsp;</p>\n<ul>\n<li>\"I look forward to the experience of shutting down and fading away,\" which I <em>hope </em>could be easily disillusioned by gaining knowledge about how truly&nbsp;undignified&nbsp;dying is, <em>bloody romanticists.</em></li>\n<li>\"There is something better after life and I'm excited for it,\" which, well... let me rephrase: please do not turn this into a discussion on ways to disillusion theists because it's <em>really</em> been talked about before.</li>\n<li>\"It is Against Nature/God's Will/The Force to live forever. Nature/God/the Force is going to <em>get </em>humankind if we try for immortality. I like my <a href=\"http://en.wikipedia.org/wiki/Prometheus\">liver!</a>\" This argument is so closely related to the previous and the next one that I don't know quite how to respond to it, other than that I've seen it crop up in historical accounts of any big change. Human beings tend to be really frightened of change, especially change which isn't believed to be supernatural in origin.</li>\n<li>\"I've read science fiction stories about being immortal, and in those stories immortality gets really boring, really fast. I'm not interested enough in reality to be in it forever.\" I can't see where this perspective could come from other than mind-numbing ignorance/the unimaginable nature of <em>really big things </em>(like the number of languages on Earth, the amount of things we still don't know about physics or the fact that every person who is or ever will be is a new, interesting being to interact with.)</li>\n<li>\"I can't imagine being immortal. My idea about how my life will go is that I will watch my children grow old, but I will die before they do. My mind/human minds aren't meant to exist for longer than one generation.\" This fails to account for human minds being very, very flexible. The human mind as we know it now does eventually get tired of life (or at least tired of pain,) but this is not a&nbsp;testament to how minds <em>are, </em>any more than humans becoming distressed when they don't eat is a testament to it being <em>natural</em> to starve, become despondent and die.</li>\n<li>\"The world is overpopulated and if nobody dies, we will overrun and ultimately ruin the planet.\" First of all: I, like Dr.&nbsp;<a href=\"http://en.wikipedia.org/wiki/Jurassic_Park_(novel)\">Ian Malcolm</a>, think that it is incredibly vain to believe that man can destroy the Earth. Second of all: in the future we may have anything from extraterrestrial habitation to substrates which take up space and consume material in totally different ways. But! Clearly, I am not feeling these arguments, because this argument makes sense to me. Problematic!</li>\n</ul>\n<p>I think that overall, the fear most people have about signing up for cryonics/AI/living forever is that they do not understand it. This is probably true for me; it's probably why I don't grok that life is <em>good, always. </em>Moreover, it is probable that the depictions of death as <em>not always bad</em>&nbsp;with which I sympathize (e.g. 'Lord, what can the harvest hope for, if not for the care of the <a href=\"http://en.wikipedia.org/wiki/Reaper_Man\">Reaper Man?</a>) stem from the previously held to be absolute nature of death. That is, up until the last ~30 years, people have not been having cogent, non-hypothetical thoughts about how it might be possible to not die or what that might be <em>like.</em> Dying has always been a Big Bad but an inescapable one, and the human race has a bad case of Stockholm Syndrome.</p>\n<p><em></em>So: now that I know I have and what I want, <a href=\"http://wiki.lesswrong.com/wiki/Luminosity_(fanfiction)\">how do I use the former to get the latter?</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "X572KJCidgSgQd4An", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 8, "extendedScore": null, "score": 7.837230787642783e-07, "legacy": true, "legacyId": "10461", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zstm38omrpeu7iWeS", "R3ATEWWmBhMhbY2AL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T08:48:31.123Z", "modifiedAt": null, "url": null, "title": "Meetup : London This Sunday", "slug": "meetup-london-this-sunday", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.971Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hFHwXKEfzbRv8sbmg/meetup-london-this-sunday", "pageUrlRelative": "/posts/hFHwXKEfzbRv8sbmg/meetup-london-this-sunday", "linkUrl": "https://www.lesswrong.com/posts/hFHwXKEfzbRv8sbmg/meetup-london-this-sunday", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20This%20Sunday&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20This%20Sunday%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhFHwXKEfzbRv8sbmg%2Fmeetup-london-this-sunday%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20This%20Sunday%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhFHwXKEfzbRv8sbmg%2Fmeetup-london-this-sunday", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhFHwXKEfzbRv8sbmg%2Fmeetup-london-this-sunday", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/47'>London This Sunday</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 October 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Africa House/64-68 Kingsway, London, WC2B 6BG</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're meeting up in London this weekend. Sunday 16th October, at 2pm, in the Shakespeares Head on Kingsway near Holborn Tube station. We're usually easy to spot and occasionally have a large paperclip drawing/printout somewhere on the table.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/47'>London This Sunday</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hFHwXKEfzbRv8sbmg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.837938980653193e-07, "legacy": true, "legacyId": "10465", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_This_Sunday\">Discussion article for the meetup : <a href=\"/meetups/47\">London This Sunday</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 October 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Africa House/64-68 Kingsway, London, WC2B 6BG</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We're meeting up in London this weekend. Sunday 16th October, at 2pm, in the Shakespeares Head on Kingsway near Holborn Tube station. We're usually easy to spot and occasionally have a large paperclip drawing/printout somewhere on the table.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London_This_Sunday1\">Discussion article for the meetup : <a href=\"/meetups/47\">London This Sunday</a></h2>", "sections": [{"title": "Discussion article for the meetup : London This Sunday", "anchor": "Discussion_article_for_the_meetup___London_This_Sunday", "level": 1}, {"title": "Discussion article for the meetup : London This Sunday", "anchor": "Discussion_article_for_the_meetup___London_This_Sunday1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T17:45:04.963Z", "modifiedAt": null, "url": null, "title": "Radio Interview with David Deutsch on AI, Immortality, Many Worlds and Quantum Computing", "slug": "radio-interview-with-david-deutsch-on-ai-immortality-many", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.171Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zv3pWeoKuJ3TABNx3/radio-interview-with-david-deutsch-on-ai-immortality-many", "pageUrlRelative": "/posts/zv3pWeoKuJ3TABNx3/radio-interview-with-david-deutsch-on-ai-immortality-many", "linkUrl": "https://www.lesswrong.com/posts/zv3pWeoKuJ3TABNx3/radio-interview-with-david-deutsch-on-ai-immortality-many", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Radio%20Interview%20with%20David%20Deutsch%20on%20AI%2C%20Immortality%2C%20Many%20Worlds%20and%20Quantum%20Computing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARadio%20Interview%20with%20David%20Deutsch%20on%20AI%2C%20Immortality%2C%20Many%20Worlds%20and%20Quantum%20Computing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzv3pWeoKuJ3TABNx3%2Fradio-interview-with-david-deutsch-on-ai-immortality-many%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Radio%20Interview%20with%20David%20Deutsch%20on%20AI%2C%20Immortality%2C%20Many%20Worlds%20and%20Quantum%20Computing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzv3pWeoKuJ3TABNx3%2Fradio-interview-with-david-deutsch-on-ai-immortality-many", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzv3pWeoKuJ3TABNx3%2Fradio-interview-with-david-deutsch-on-ai-immortality-many", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p><a title=\"David Deutsch\" href=\"http://en.wikipedia.org/wiki/David_Deutsch\">David Deutsch</a>, whose views are very much aligned with the scientific ideas generally advocated on this forum (except for &nbsp;<a title=\"Vladimir_Nesov comments on David Deutsch on How To Think About The Future - Less Wrong\" href=\"/lw/56a/david_deutsch_on_how_to_think_about_the_future/3vye\">his use of probabilities</a>), and whose new book <a href=\"http://en.wikipedia.org/wiki/The_Beginning_of_Infinity\">The Beginning of Infinity</a>&nbsp;has been recently published, <a href=\"http://www.cbc.ca/video/#/Radio/The_Current/1450068094/ID=2153637988\">talks</a>&nbsp;about many of the topics of interest to LW. (A flash player might be needed to listen.)</p>\n<p><a id=\"2153637988&lt;/a\" href=\"/talks\"> </a></p>\n<p>While I find his case for the MWI weak (he mostly says that it explains what we observe better, without going into predictive power or Bayesian reasoning), he is, nonetheless, quite articulate and engaging.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zv3pWeoKuJ3TABNx3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.839771031350359e-07, "legacy": true, "legacyId": "10467", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T17:51:11.364Z", "modifiedAt": null, "url": null, "title": "Brain emulations and Oracle AI", "slug": "brain-emulations-and-oracle-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.802Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wZFfnaMjW6q53hyzT/brain-emulations-and-oracle-ai", "pageUrlRelative": "/posts/wZFfnaMjW6q53hyzT/brain-emulations-and-oracle-ai", "linkUrl": "https://www.lesswrong.com/posts/wZFfnaMjW6q53hyzT/brain-emulations-and-oracle-ai", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brain%20emulations%20and%20Oracle%20AI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrain%20emulations%20and%20Oracle%20AI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwZFfnaMjW6q53hyzT%2Fbrain-emulations-and-oracle-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brain%20emulations%20and%20Oracle%20AI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwZFfnaMjW6q53hyzT%2Fbrain-emulations-and-oracle-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwZFfnaMjW6q53hyzT%2Fbrain-emulations-and-oracle-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p>Two talks from the Future of Humanity Institute are now online (this is the first time we've done this, so please excuse the lack of polish). The first is Anders Sandberg talking about brain emulations (technical overview), the second is myself talking of the risks of Oracle AIs (informal presentation). They can be found here:</p>\n<p>Fesability of whole-brain emulation:&nbsp;<a href=\"http://www.youtube.com/watch?v=3nIzPpF635c&amp;feature=related\">http://www.youtube.com/watch?v=3nIzPpF635c&amp;feature=related</a>, initial paper at&nbsp;<a href=\"http://www.philosophy.ox.ac.uk/__data/assets/pdf_file/0019/3853/brain-emulation-roadmap-report.pdf\">http://www.philosophy.ox.ac.uk/__data/assets/pdf_file/0019/3853/brain-emulation-roadmap-report.pdf</a>, new paper still to come.</p>\n<p>Thinking inside the box: Using and controlling an Oracle AI:<a href=\"http://www.youtube.com/watch?v=Gz9zYQsT-QQ&amp;feature=related\">http://www.youtube.com/watch?v=Gz9zYQsT-QQ&amp;feature=related</a>, paper at&nbsp;<a href=\"http://www.aleph.se/papers/oracleAI.pdf\">http://www.aleph.se/papers/oracleAI.pdf</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jQytxyauJ7kPhhGj3": 2, "5f5c37ee1b5cdee568cfb2b1": 2, "5f5c37ee1b5cdee568cfb26d": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wZFfnaMjW6q53hyzT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 10, "extendedScore": null, "score": 7.839791886332556e-07, "legacy": true, "legacyId": "10466", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T19:53:31.932Z", "modifiedAt": null, "url": null, "title": "How to understand people better ", "slug": "how-to-understand-people-better", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:37.801Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pwno", "createdAt": "2009-02-27T06:17:31.584Z", "isAdmin": false, "displayName": "pwno"}, "userId": "SCgoHNxqc2agmDWEg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qy4DMkqNFakaZWYkR/how-to-understand-people-better", "pageUrlRelative": "/posts/qy4DMkqNFakaZWYkR/how-to-understand-people-better", "linkUrl": "https://www.lesswrong.com/posts/qy4DMkqNFakaZWYkR/how-to-understand-people-better", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20understand%20people%20better%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20understand%20people%20better%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqy4DMkqNFakaZWYkR%2Fhow-to-understand-people-better%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20understand%20people%20better%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqy4DMkqNFakaZWYkR%2Fhow-to-understand-people-better", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fqy4DMkqNFakaZWYkR%2Fhow-to-understand-people-better", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1640, "htmlBody": "<div>I&rsquo;ve been taking notes on how I empathize, considering I seem to be more successful at it than others. I broke down my thought-patterns, implied beliefs, and techniques, hoping to unveil the mechanism behind the magic. I shared my findings with a few friends and noticed something interesting: They were becoming noticeably better empathizers.&nbsp;</div>\n<div><br /></div>\n<div>I realized the route to improving one&rsquo;s ability to understand what people feel and think is not a foreign one. Empathy is a skill; with some guidance and lots of practice, anyone can make drastic improvements.&nbsp;</div>\n<div><br /></div>\n<div>I want to impart the more fruitful methods/mind-sets and exercises I&rsquo;ve collected over time.&nbsp;</div>\n<div>\n<hr />\n</div>\n<div><em>Working definitions:</em></div>\n<div>Projection: The belief that others feel and think the same as you would under the same circumstances</div>\n<div>Model: Belief or &ldquo;map&rdquo; that predicts and explains people&rsquo;s behavior</div>\n<div>\n<hr />\n</div>\n<div><br /></div>\n<div><strong>Stop identifying as a non-empathizer</strong></div>\n<div><br /></div>\n<div>This is the first step towards empathizing better&mdash;or developing any skill for that matter. Negative self-fulfilling prophecies are very real and very avoidable. Brains are plastic; there&rsquo;s no reason to believe an optimal path-to-improvement doesn&rsquo;t exist for you.&nbsp;</div>\n<div><br /></div>\n<div><strong>Not understanding people's behavior is your confusion, not theirs</strong></div>\n<div><br /></div>\n<div>When we learn our housemate spent 9 hours cleaning the house, we should blame our flawed map for being confused by his or her behavior. Maybe they&rsquo;re deathly afraid of cockroaches and found a few that morning, maybe they&rsquo;re passive aggressively telling you to clean more, or maybe they just procrastinate by cleaning. Our model of the housemate has yet to account for these tendencies.&nbsp;<a id=\"more\"></a><br /></div>\n<div>People tend to explain such confusing behavior with stupidity, creepiness, neurosis or any other traits we associate with the mentally ill. With Occam&rsquo;s Razor in perspective, these careless judgers are statistically the mentally ill ones. Their model being flawed is much more probable than their housemate going insane. &nbsp;</div>\n<div><br /></div>\n<div>Similar to the fundamental attribution error, this type of mistake is committed more often with people we dislike. A good challenge is to try understanding confusing behavior from individuals or sub-cultures you dislike. You&rsquo;ll find yourself disliking them a bit less if you&rsquo;re doing it right.&nbsp;</div>\n<div><br /></div>\n<div>Another challenge is to try and find the appeal in popular attractions/entertainment you dislike. For instance, if you dislike music videos, try watching a few until you get the &ldquo;Aha&rdquo; moment. Yes, that&rsquo;s what it should feel like when you get it right.</div>\n<div>As you&rsquo;re able to explain more behaviors, your model of people becomes more robust, making you an overall better empathizer.&nbsp;</div>\n<div><br /></div>\n<div><strong>Projection works, but not for resolving confusion</strong></div>\n<div><strong><br /></strong></div>\n<div>People&rsquo;s intuition for how someone&rsquo;s feeling is normally accurate&mdash;with more ambiguous cases&mdash;intuition needs conscious support. Unfortunately, most rely too heavily on the &ldquo;put yourself in their shoes&rdquo; mantra. You are not always like most people and can react very differently in the same circumstances. There&rsquo;s already an inclination to project and putting yourself in their shoes rarely overturns initial judgments. If you&rsquo;re confused about someone&rsquo;s behavior, it most likely means projection hasn&rsquo;t worked so far. &nbsp; &nbsp;&nbsp;</div>\n<div>Instead, build accurate models of people and figure out whether your model would&rsquo;ve predicted such behavior. If not, gather reliable evidence proving what the person actually felt and tweak your model accordingly. Hopefully this is starting to sound a lot like the scientific method.</div>\n<div><br /></div>\n<div><strong>Understand yourself better</strong></div>\n<div><strong><br /></strong></div>\n<div>As mentioned above, projection normally works well (which is probably why humans are so inclined to do it). Projection, however, isn&rsquo;t useful if you can&rsquo;t predict your own reactions in another&rsquo;s situation.</div>\n<div><br /></div>\n<div>Catch yourself next time you experience an emotional reaction and try figuring out what network of beliefs caused it. As a personal anecdote, I tried to uncover the beliefs causing me to procrastinate on my work. I narrowed down the portions of work I had an emotional reaction to and discovered I believed I either didn&rsquo;t have the skill or knowledge to complete the task. Now, when I try to explain other&rsquo;s procrastination, I ask what part of the work they are having willpower issues with and determine their self-efficacy for those tasks. I was surprised to learn that others had the same beliefs causing their procrastination. Understanding yourself well can lend more non-trivial competing hypotheses.&nbsp;</div>\n<div><br /></div>\n<div>Caveat: If you&rsquo;re very different from most people, then understanding yourself better won&rsquo;t be as helpful. In this case, I&rsquo;d suggest finding someone more typical to be your proxy. Get to know them well enough to the point where your proxy model can explain/predict behaviors in other typical people.&nbsp;</div>\n<div><br /></div>\n<div><strong>Put others in YOUR shoes, that&rsquo;s how they&rsquo;re empathizing with you</strong></div>\n<div><strong><br /></strong></div>\n<div>We often find our empathy skills lacking when trying to explain others&rsquo; reactions to our own behaviors. We normally consider how we&rsquo;d perceive our own behaviors coming from another person before acting&mdash;making questions like &ldquo;Why did he think I didn&rsquo;t want to see him last night?&rdquo; or &ldquo;Why was she so offended by my jokes?&rdquo; hard to figure out off projection alone.&nbsp;</div>\n<div>Use the fact that most people project to your advantage. If someone&rsquo;s trying to empathize with you, they&rsquo;ll most likely project i.e. put themselves in your shoes.&nbsp;</div>\n<div><br /></div>\n<div>Imagine a man and woman on a date at a fancy restaurant and just about finished eating their meals. The waiter drops off the bill and the woman glances at the bill. She says enthusiastically, &ldquo;Wow great food and for a great price too!&rdquo; The man pays for the bill and moments later his mood shifts, becoming noticeably sadder and quieter. &nbsp;The woman knew he&rsquo;s more passive than her, but still confused by his behavior.</div>\n<div><br /></div>\n<div>As it turns out, the man imagined himself describing food as having a &ldquo;great price&rdquo; and realized he&rsquo;d say that about cheap food. The man brought her to the fancy restaurant hoping to impress her, but felt his attempt failed. The woman didn&rsquo;t think the food was cheap, she thought it was reasonably priced given how good it tasted and the restaurant&rsquo;s upscale reputation. If she thought the food was cheap, she&rsquo;d explicitly say so. Since she knows he&rsquo;s more passive, she could&rsquo;ve inferred the man believes others are more or less as passive as he is. Thinking back to the incident, she should&rsquo;ve considered how people would interpret her statement as if she had a reputation for being passive.</div>\n<div><br /></div>\n<div>One lesson I&rsquo;ve learned from this technique is that considerate people are more sensitive to inconsiderate behavior. Because they closely monitor their own behaviors, they tend to assume others are about as equally conscientious. When they determine someone&rsquo;s behavior to be inconsiderate, they are more likely to interpret the behavior as a sign of dislike or apathy rather than obliviousness. &nbsp;</div>\n<div><br /></div>\n<div>Knowing others are projecting can help you learn more about yourself too. For instance, if you&rsquo;re confused as to why your friends always ask &ldquo;Is everything&rsquo;s ok?&rdquo; when you feel fine, consider that your friends may be observing certain behaviors they themselves would exhibit when uncomfortable. And maybe you are, in fact, uncomfortable, but aren&rsquo;t consciously aware of it. &nbsp;&nbsp;</div>\n<div><br /></div>\n<div><strong>The simplest explanation is usually correct</strong></div>\n<div><strong><br /></strong></div>\n<div>As you develop your mental model of people, you&rsquo;ll notice models share a lot in common. &nbsp;For instance, primitive motives like attraction, attention and status can explain the same behaviors exhibited in many people. These &ldquo;universal&rdquo; components to your models often yield more likely hypotheses. People are obviously more typical than they are not.&nbsp;</div>\n<div><br /></div>\n<div>Try to pick out which behaviors are consistently explained by the same mechanism in your models. For instance, it&rsquo;s helpful to know that most submissive/dominant behavior is done out of status disparities, not some&nbsp;idiosyncratic&nbsp;personality trait. Your knowledge of how people interact with status disparities will offer a powerful starting hypothesis.</div>\n<div><br /></div>\n<div>As you continue to merge your models together, you&rsquo;ll be that much closer to a unifying theory of people!&nbsp;</div>\n<div><br /></div>\n<div><strong>Build models of people, like a scientist</strong></div>\n<div><strong><br /></strong></div>\n<div>Start developing models of individuals and groups, which predict their behaviors under certain circumstances. Like a scientist, when the model proves to have low predictive value, tweak them until they do. Combining your models is a good approach.</div>\n<div>Say you&rsquo;re having trouble understanding why your brother does everything his new &ldquo;friend&rdquo; tells him to do. He&rsquo;s never acted like that towards anyone before; your model of your brother is missing something. Fortunately, you&rsquo;ve seen such behavior before, explained by a different model, the one of your co-worker. That model made you realize that, like your co-worker, your brother finds his new friend much higher status and feels lucky receiving his attention. Not only did you strengthen your brother model, you&rsquo;ve also collected more evidence that such behavior is more likely status-related and less likely person-specific, making all your models more robust.&nbsp;</div>\n<div><br /></div>\n<div><strong>Experience more</strong></div>\n<div><strong><br /></strong></div>\n<div>If I tried imagining what a professional soccer player feels like scoring a winning goal, I&rsquo;d use my memory of the time I scored the winning goal at a pick-up soccer game and multiply my euphoria by some factor. Imagining what emotions someone would feel under circumstances you&rsquo;ve never experienced isn&rsquo;t easy. Your best approximation may depend on a similar circumstance you have experienced. Therefore, experiencing more means being a better empathizer.&nbsp;</div>\n<div><br /></div>\n<div><strong>Empathy checklist</strong></div>\n<div><strong><br /></strong></div>\n<div>Here&rsquo;s a short checklist of the different techniques to use whenever you&rsquo;re confronted with confusing behavior. Run through the list until you feel confident about your conclusion.&nbsp;</div>\n<div>\n<div>\n<ul>\n<li>Put yourself in their shoes</li>\n<li>Think of times you&rsquo;ve been in a similar situation and explain your reaction</li>\n<li>Can the behavior be explained by a more &ldquo;universal&rdquo; model than a person-specific one?</li>\n<li>How are they empathizing with you, given they are projecting?</li>\n<li>How are they empathizing with you, given what you know about how they perceive others?</li>\n<li>What successful model have you used to explain similar behavior for similar people?</li>\n<li>Is your conclusion affected by your attitude towards the subject?</li>\n</ul>\n</div>\n</div>\n<div><br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mip7tdAN87Jarkcew": 2, "4Man2iP6ftuTPze9K": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qy4DMkqNFakaZWYkR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 92, "baseScore": 95, "extendedScore": null, "score": 0.000206, "legacy": true, "legacyId": "10412", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 96, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 164, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T20:15:32.153Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Stockholm, Dublin, Penn State, Cambridge MA, Ottawa, and Marin CA", "slug": "weekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PPE3WbFGFqg7XGDfv/weekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma", "pageUrlRelative": "/posts/PPE3WbFGFqg7XGDfv/weekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma", "linkUrl": "https://www.lesswrong.com/posts/PPE3WbFGFqg7XGDfv/weekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Stockholm%2C%20Dublin%2C%20Penn%20State%2C%20Cambridge%20MA%2C%20Ottawa%2C%20and%20Marin%20CA&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Stockholm%2C%20Dublin%2C%20Penn%20State%2C%20Cambridge%20MA%2C%20Ottawa%2C%20and%20Marin%20CA%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPPE3WbFGFqg7XGDfv%2Fweekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Stockholm%2C%20Dublin%2C%20Penn%20State%2C%20Cambridge%20MA%2C%20Ottawa%2C%20and%20Marin%20CA%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPPE3WbFGFqg7XGDfv%2Fweekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPPE3WbFGFqg7XGDfv%2Fweekly-lw-meetups-stockholm-dublin-penn-state-cambridge-ma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 332, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/3u\">Stockholm meetup:&nbsp;<span class=\"date\">09 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/3z\">Dublin, IE, Meetup:&nbsp;<span class=\"date\">15 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/3i\">Penn State University: NEW Meetup starting!:&nbsp;<span class=\"date\">22 October 2011 02:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/3w\">Cambridge, MA Sunday meetup:&nbsp;<span class=\"date\">09 October 2011 09:37PM</span></a></li>\n<li><a href=\"/meetups/3y\">Ottawa Meetup - Learning Linear Algebra:&nbsp;<span class=\"date\">10 October 2011 07:30PM</span></a></li>\n<li><a href=\"/meetups/3x\">Marin Less Wrong Meetup:&nbsp;<span class=\"date\">11 October 2011 07:00PM</span></a></li>\n</ul>\n<p>&nbsp;</p>\n<p>Cities with regularly scheduled meetups:&nbsp;<strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>, <a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine\">Irvine</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>,<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin, CA</a> </strong>(uses the Bay Area List)<strong>,</strong> and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>Despite the handy sidebar of upcoming meetups, we've decided to continue posting an overview of upcoming meetups on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening:&nbsp;<strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>,&nbsp; <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison, WI</a></strong><strong>.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PPE3WbFGFqg7XGDfv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.840284876243368e-07, "legacy": true, "legacyId": "10368", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pAHo9zSFXygp5A5dL", "tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T20:22:54.141Z", "modifiedAt": null, "url": null, "title": "Meetup : Ottawa Meetup - Learning Linear Algebra 2 + Social", "slug": "meetup-ottawa-meetup-learning-linear-algebra-2-social", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XFrequentist", "createdAt": "2009-03-22T17:06:22.991Z", "isAdmin": false, "displayName": "XFrequentist"}, "userId": "zfW5w3TbDWjRW3YaD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kmRdT8zskPhDbX7ny/meetup-ottawa-meetup-learning-linear-algebra-2-social", "pageUrlRelative": "/posts/kmRdT8zskPhDbX7ny/meetup-ottawa-meetup-learning-linear-algebra-2-social", "linkUrl": "https://www.lesswrong.com/posts/kmRdT8zskPhDbX7ny/meetup-ottawa-meetup-learning-linear-algebra-2-social", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Ottawa%20Meetup%20-%20Learning%20Linear%20Algebra%202%20%2B%20Social&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Ottawa%20Meetup%20-%20Learning%20Linear%20Algebra%202%20%2B%20Social%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkmRdT8zskPhDbX7ny%2Fmeetup-ottawa-meetup-learning-linear-algebra-2-social%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Ottawa%20Meetup%20-%20Learning%20Linear%20Algebra%202%20%2B%20Social%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkmRdT8zskPhDbX7ny%2Fmeetup-ottawa-meetup-learning-linear-algebra-2-social", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkmRdT8zskPhDbX7ny%2Fmeetup-ottawa-meetup-learning-linear-algebra-2-social", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 91, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/48'>Ottawa Meetup - Learning Linear Algebra 2 + Social</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">17 October 2011 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Elgin & Gladstone, Ottawa Ontario Canada</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>With some (slow) progress beating math into our heads successfully behind us, we will continue with a second attempt at some more advanced linear algebra.</p>\n\n<p>I propose heading to a nearby pub for 1-2 pints after 90 minutes of math, join our <a href=\"http://groups.google.com/group/less-wrong-ottawa\" rel=\"nofollow\">google group</a> to keep up to date on developments!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/48'>Ottawa Meetup - Learning Linear Algebra 2 + Social</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kmRdT8zskPhDbX7ny", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.840310036531495e-07, "legacy": true, "legacyId": "10470", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra_2___Social\">Discussion article for the meetup : <a href=\"/meetups/48\">Ottawa Meetup - Learning Linear Algebra 2 + Social</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">17 October 2011 07:30:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Elgin &amp; Gladstone, Ottawa Ontario Canada</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>With some (slow) progress beating math into our heads successfully behind us, we will continue with a second attempt at some more advanced linear algebra.</p>\n\n<p>I propose heading to a nearby pub for 1-2 pints after 90 minutes of math, join our <a href=\"http://groups.google.com/group/less-wrong-ottawa\" rel=\"nofollow\">google group</a> to keep up to date on developments!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra_2___Social1\">Discussion article for the meetup : <a href=\"/meetups/48\">Ottawa Meetup - Learning Linear Algebra 2 + Social</a></h2>", "sections": [{"title": "Discussion article for the meetup : Ottawa Meetup - Learning Linear Algebra 2 + Social", "anchor": "Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra_2___Social", "level": 1}, {"title": "Discussion article for the meetup : Ottawa Meetup - Learning Linear Algebra 2 + Social", "anchor": "Discussion_article_for_the_meetup___Ottawa_Meetup___Learning_Linear_Algebra_2___Social1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-14T20:26:53.344Z", "modifiedAt": null, "url": null, "title": "Don't call yourself a rationalist.", "slug": "don-t-call-yourself-a-rationalist", "viewCount": null, "lastCommentedAt": "2020-06-17T09:33:15.808Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KenChen", "createdAt": "2011-02-16T18:02:23.420Z", "isAdmin": false, "displayName": "KenChen"}, "userId": "Tay9Y5o7ehACBHeqc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MsDv5tEeBQRhNcdYx/don-t-call-yourself-a-rationalist", "pageUrlRelative": "/posts/MsDv5tEeBQRhNcdYx/don-t-call-yourself-a-rationalist", "linkUrl": "https://www.lesswrong.com/posts/MsDv5tEeBQRhNcdYx/don-t-call-yourself-a-rationalist", "postedAtFormatted": "Friday, October 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Don't%20call%20yourself%20a%20rationalist.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADon't%20call%20yourself%20a%20rationalist.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMsDv5tEeBQRhNcdYx%2Fdon-t-call-yourself-a-rationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Don't%20call%20yourself%20a%20rationalist.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMsDv5tEeBQRhNcdYx%2Fdon-t-call-yourself-a-rationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMsDv5tEeBQRhNcdYx%2Fdon-t-call-yourself-a-rationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 310, "htmlBody": "<p>I often seem to run into problems when I use the de facto label for this group. For example, when I say, \"I've been hanging out with rationalists lately,\" I notice that many people immediately go on the defensive. They might ask why you need a group in order to be rational, or they might say that they don't believe that people are inherently rational. Of course, I made none of those claims, I simply indicated that I was hanging out with rationalists.</p>\n<p>You might think that \"rationalist\" is simply a descriptive label, but it carries positive connotations -- and what people tend to hear is \"I'm a superior thinker to you,\" or maybe \"I'm a part of this group, which ascribes the label 'rationalist' to itself, to make ourselves seem higher status than we really are.\"</p>\n<p><strong>Why does this matter?</strong><img style=\"float: right; margin: 8px;\" src=\"http://images.lesswrong.com/t3_82s_0.png\" alt=\"\" width=\"342\" height=\"226\" /></p>\n<p>The community doesn't exist in a vacuum; how the community is viewed from the outside matters. As the community grows and as people gain awareness of it, branding becomes important. People talk to each other, and communities gain reputations. Even if you believe that we are a loose collection of individuals, as soon as you assign a name to yourself, <a href=\"http://psychclassics.yorku.ca/Sherif/chap5.htm\">that is sufficient to form a group identity</a>.</p>\n<p>The people we interact with tend to share similar interests. The population of New York may be in the millions, and yet I run into the same people at different functions without coordination.</p>\n<p>The more negative perceptions associated with a group, the more rapidly <a href=\"/lw/lr/evaporative_cooling_of_group_beliefs/\">evaporative cooling of groups</a> will occur.</p>\n<p><strong>What to do?<br /></strong></p>\n<p><strong> </strong></p>\n<p>It's far better to talk about good things that you've gained from being in the group. It's better to say what the group <strong>does</strong>, not what the group <strong>is</strong>.</p>\n<p>But beyond that, it's about time the community picked a better label to use. I have one idea, but I'll <a href=\"/lw/ka/hold_off_on_proposing_solutions/\">hold off on proposing solutions</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "x6evH6MyPK3nxsoff": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MsDv5tEeBQRhNcdYx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 24, "extendedScore": null, "score": 4.8e-05, "legacy": true, "legacyId": "10468", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 121, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZQG9cwKbct2LtmL3p", "uHYYA32CKgKT3FagE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-15T00:10:48.179Z", "modifiedAt": null, "url": null, "title": "Questions for the Singularity Summit", "slug": "questions-for-the-singularity-summit", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.918Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lessdazed", "createdAt": "2011-02-02T05:06:52.010Z", "isAdmin": false, "displayName": "lessdazed"}, "userId": "ehZzKt5ByYBeyCLkz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ausrdmNdHzsq72sMc/questions-for-the-singularity-summit", "pageUrlRelative": "/posts/ausrdmNdHzsq72sMc/questions-for-the-singularity-summit", "linkUrl": "https://www.lesswrong.com/posts/ausrdmNdHzsq72sMc/questions-for-the-singularity-summit", "postedAtFormatted": "Saturday, October 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Questions%20for%20the%20Singularity%20Summit&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuestions%20for%20the%20Singularity%20Summit%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FausrdmNdHzsq72sMc%2Fquestions-for-the-singularity-summit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Questions%20for%20the%20Singularity%20Summit%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FausrdmNdHzsq72sMc%2Fquestions-for-the-singularity-summit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FausrdmNdHzsq72sMc%2Fquestions-for-the-singularity-summit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 175, "htmlBody": "<p>Here is a place to talk about questions for the speakers at the Singularity Summit.</p>\n<p>People are often afraid that they have stupid questions, and fail to ask their good questions that would have benefited many - either by increasing their understanding, showcasing the character of a speaker who admits to not knowing something, or showing by the lack of an adequate response that the speaker's argument is flawed.</p>\n<p>This is an overblown fear that is quite irrational - irrational to the extent that their emotions lead them to think that the consequences of their asking a stupid question will be severe. People will have unpleasant emotional reactions if embarrassed, but their emotions are needlessly warning them not to risk status before the tribe lest they get cast out and die. That's unlikely to happen.</p>\n<p>People's reluctance to ask questions is rational to the extent that many questions are, by any reasonable description, stupid.</p>\n<p>So let's use this thread to gain confidence that our questions aren't of the latter type, or to get answers, or to get better questions.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ausrdmNdHzsq72sMc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 10, "extendedScore": null, "score": 7.841088507065255e-07, "legacy": true, "legacyId": "10471", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-15T03:05:40.425Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Wonder of Evolution", "slug": "seq-rerun-the-wonder-of-evolution", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.792Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2Fkdfwdm8XiJdWHiq/seq-rerun-the-wonder-of-evolution", "pageUrlRelative": "/posts/2Fkdfwdm8XiJdWHiq/seq-rerun-the-wonder-of-evolution", "linkUrl": "https://www.lesswrong.com/posts/2Fkdfwdm8XiJdWHiq/seq-rerun-the-wonder-of-evolution", "postedAtFormatted": "Saturday, October 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Wonder%20of%20Evolution&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Wonder%20of%20Evolution%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Fkdfwdm8XiJdWHiq%2Fseq-rerun-the-wonder-of-evolution%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Wonder%20of%20Evolution%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Fkdfwdm8XiJdWHiq%2Fseq-rerun-the-wonder-of-evolution", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Fkdfwdm8XiJdWHiq%2Fseq-rerun-the-wonder-of-evolution", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p>Today's post, <a href=\"/lw/ks/the_wonder_of_evolution/\">The Wonder of Evolution</a> was originally published on 02 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The wonder of the first replicator was not how amazingly well it replicated, but that a first replicator could arise, at all, by pure accident, in the primordial seas of Earth. That first replicator would undoubtedly be devoured in an instant by a sophisticated modern bacterium. Likewise, the wonder of evolution itself is not how <em>well</em> it works, but that a <em>brainless, accidentally occurring</em> optimization process can work at <em>all</em>. If you praise evolution for being such a wonderfully intelligent Creator, you're entirely missing the wonderful thing about it.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/82k/seq_rerun_an_alien_god/\">An Alien God</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2Fkdfwdm8XiJdWHiq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.841685929169643e-07, "legacy": true, "legacyId": "10472", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZyNak8F6WXjuEbWWc", "sZbb45uiZQ2SLPtMB", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-15T17:14:25.956Z", "modifiedAt": null, "url": null, "title": "Mental Rebooting: \"Your Brain on Porn\"... ", "slug": "mental-rebooting-your-brain-on-porn", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:31.480Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Arkanj3l", "createdAt": "2011-04-23T03:48:47.569Z", "isAdmin": false, "displayName": "Arkanj3l"}, "userId": "nQmA4dnBdX99WyCt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/myAvQcAGG7YBu5spt/mental-rebooting-your-brain-on-porn", "pageUrlRelative": "/posts/myAvQcAGG7YBu5spt/mental-rebooting-your-brain-on-porn", "linkUrl": "https://www.lesswrong.com/posts/myAvQcAGG7YBu5spt/mental-rebooting-your-brain-on-porn", "postedAtFormatted": "Saturday, October 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mental%20Rebooting%3A%20%22Your%20Brain%20on%20Porn%22...%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMental%20Rebooting%3A%20%22Your%20Brain%20on%20Porn%22...%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmyAvQcAGG7YBu5spt%2Fmental-rebooting-your-brain-on-porn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mental%20Rebooting%3A%20%22Your%20Brain%20on%20Porn%22...%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmyAvQcAGG7YBu5spt%2Fmental-rebooting-your-brain-on-porn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmyAvQcAGG7YBu5spt%2Fmental-rebooting-your-brain-on-porn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 673, "htmlBody": "<p>... or \"How to Operate Your Limbic System\", or \"A Practical Guide to Superstimulus\". That's how I see it, anyway.</p>\n<p><a href=\"http://yourbrainonporn.com/\">Your Brain on Porn</a>&nbsp;is a website mainly dedicated to <a href=\"http://yourbrainonporn.com/whats-driving-your-addiction\">exposing the addictive aspects of pornography</a>;&nbsp;<a href=\"http://yourbrainonporn.com/you-evolved-to-be-hooked-on-porn\">interpreting this in light</a>&nbsp;of&nbsp;the <a href=\"http://wiki.lesswrong.com/wiki/Evolution_as_alien_god\">blind idiot god</a>;&nbsp;and then forming a community around \"<a href=\"http://yourbrainonporn.com/tools-for-change\">rebooting</a>\", or prolonged abstinence that allows the brain to&nbsp;re-sensitize&nbsp;itself to, at the least, non-fetishistic sexual pleasure. By consistently NOT accessing whatever circuit is driving one's, well, drive, one sends this loop into atrophy. Eventually, one becomes able to quit. And then one finds alternatives.</p>\n<p>Here is why I find this site so valuable: frequently during the arguments the site owner sets up, he doesn't just bring up pornography as the culprit here. To form his clauses he draws upon research on &nbsp;addictions to junk food, or video games, and then tries to draw parallels to porn's effects: the&nbsp;escalating&nbsp;need of novelty due to rapidly declining pleasure response.</p>\n<p>So I don't think it stops with porn. For me, any <a href=\"http://wiki.lesswrong.com/wiki/Superstimulus\">superstimulus</a> is a <em>bad</em>&nbsp;superstimulus, despite the fact that some sirens are more necessary to listen to than others. It could be worth reflecting on what would actually <em>count</em>&nbsp;as a superstimulus; and then asking if one would benefit from a&nbsp;long hiatus&nbsp;from that stimulus. I'm not sure how long that cycle would be, but many \"rebooters\" proclaim seeing effects after three weeks, up to three months. It might not be enough to simply manage akrasia, as there could still be a chronic sensitivity problem in place. That would require time.</p>\n<p>Here's what I thought of, so far.</p>\n<p>Superstimulus List:</p>\n<ul>\n<li>Porn.</li>\n<li><a href=\"http://xkcd.com/609/\">Tab explosions</a>&nbsp;and social networks -- the online kind. (This could be the most challenging one: More often than not, a computer is needed for productivity. Who can afford taking a three-month break?)</li>\n<li>Video games.</li>\n<li>Disorganizations, mess, and <a href=\"http://www.gwern.net/Notes#decluttering\">clutter</a>.</li>\n<li>Junk food. (I'm tentative about this one, because I'm still trying to figure out what counts as \"junk\". As far as I've seen, this word usually gets ascribed to high calorie, high fat foods... but that possibly doesn't matter, as I see <a href=\"http://www.gnolls.org/1141/eat-like-a-predator-not-like-prey-paleo-in-six-easy-steps-a-motivational-guide/\">proportionally high-fat content paleo diets</a>. Or it's a combination of fat and sugar that becomes addictive, but either/or is manageable.)</li>\n<li>Loud music. (Shameless speculation.)</li>\n<li>Much of advertising today seems to focus on getting our attention with superstimulus. Thus, being mindful when one is exposed could minimize possible effects.</li>\n</ul>\n<div>Replacements:</div>\n<div>\n<ul>\n<li>Touch. If you <em>really</em>&nbsp;need to show some love, &nbsp;<a href=\"http://en.wikipedia.org/wiki/Coitus_reservatus\">Karezza</a>&nbsp; is popular amongst those who have rebooted.</li>\n<li>Meditation and N-Back. Since this really does require mental discipline, it would be worth&nbsp;practising&nbsp;these attention-management strategies.</li>\n<li>Exercise.</li>\n<li>Fasting. (In small doses, &nbsp;<a href=\"http://patrifriedman.com/aboutme/health.html#fasting\">it's probably healthier than you think</a>&nbsp; and, broadly speaking, also results in some sort of&nbsp;<a href=\"http://gettingstronger.org/2010/10/change-your-setpoint/\">re-sensitization</a>.&nbsp;[scroll down])</li>\n</ul>\n<div>Potential Benefits:</div>\n<div>\n<ul>\n<li>Reduction of social anxiety. (<a href=\"http://forwearemany.wordpress.com/2010/02/26/social-status-novelty-seeking-and-dopamine/\">Socially dominant monkeys have a greater density of dopamine receptors in the striatum</a>&nbsp;than their less-dominant counterparts. I'm not saying that abstaining from porn will turn you into the CEO of a corporation with three girlfriends and a gimp -- I wish! -- but it sure as hell wouldn't hurt.)</li>\n<li>Clearer focus. (This may come from lack of wont than an actual greater ability to focus, which is fine.)</li>\n<li>Greater motivation.</li>\n</ul>\n<a href=\"/lw/l0/adaptationexecuters_not_fitnessmaximizers/\">Think of it like this</a>: if all your adaptive needs are fulfilled, what incentive is there for your body to maximize your fitness? For all&nbsp;<em> it</em>&nbsp; knows, you've done a great job: you are now in the dreaded Comfort Zone.<br /> \n<ul>\n</ul>\n<span style=\"white-space: pre;\"> </span>Abstinence puts one outside of the realm of comfort, but not to the point of putting one in harm's way. It requires no <span style=\"white-space: pre;\"> </span>\"push\", just self-awareness; something I would consider as the lowest hanging fruit of self-improvement.<br /> \n<ul>\n<li>In the case of porn, in males, <a href=\"http://yourbrainonporn.com/selected-testosterone-research\">the amounts of testosterone could significantly change</a>, if not normalize. That could feature a host of changes by itself.</li>\n</ul>\n<div>None of these lists are exhaustive. The whole principle could be unsound; I am only a third into &nbsp;<a href=\"/lw/5a5/no_seriously_just_try_it/\">just trying it</a>&nbsp; and this excludes Internet use management.</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "myAvQcAGG7YBu5spt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 44, "baseScore": 10, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "10477", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XPErvb8m9FapXCjhA", "Zmfo388RA9oky3KYe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-16T02:03:45.618Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Evolutions Are Stupid (But Work Anyways)", "slug": "seq-rerun-evolutions-are-stupid-but-work-anyways", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:56.135Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5xMWckkuvFHzqhyZb/seq-rerun-evolutions-are-stupid-but-work-anyways", "pageUrlRelative": "/posts/5xMWckkuvFHzqhyZb/seq-rerun-evolutions-are-stupid-but-work-anyways", "linkUrl": "https://www.lesswrong.com/posts/5xMWckkuvFHzqhyZb/seq-rerun-evolutions-are-stupid-but-work-anyways", "postedAtFormatted": "Sunday, October 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Evolutions%20Are%20Stupid%20(But%20Work%20Anyways)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Evolutions%20Are%20Stupid%20(But%20Work%20Anyways)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5xMWckkuvFHzqhyZb%2Fseq-rerun-evolutions-are-stupid-but-work-anyways%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Evolutions%20Are%20Stupid%20(But%20Work%20Anyways)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5xMWckkuvFHzqhyZb%2Fseq-rerun-evolutions-are-stupid-but-work-anyways", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5xMWckkuvFHzqhyZb%2Fseq-rerun-evolutions-are-stupid-but-work-anyways", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>Today's post, <a href=\"/lw/kt/evolutions_are_stupid_but_work_anyway/\">Evolutions Are Stupid (But Work Anyway)</a> was originally published on 03 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Evolution, while not simple, is sufficiently simpler than organic brains that we can describe mathematically how slow and stupid it is.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/82w/seq_rerun_the_wonder_of_evolution/\">The Wonder of Evolution</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5xMWckkuvFHzqhyZb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.846396793568119e-07, "legacy": true, "legacyId": "10478", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jAToJHtg39AMTAuJo", "2Fkdfwdm8XiJdWHiq", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-16T03:29:41.908Z", "modifiedAt": null, "url": null, "title": "[link] SMBC on utilitarianism and vegatarianism.", "slug": "link-smbc-on-utilitarianism-and-vegatarianism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:33.098Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "mkehrt", "createdAt": "2010-01-23T07:17:46.451Z", "isAdmin": false, "displayName": "mkehrt"}, "userId": "SiugPSCvYDipriPwu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kGTbCZFgZvLtoSCTB/link-smbc-on-utilitarianism-and-vegatarianism", "pageUrlRelative": "/posts/kGTbCZFgZvLtoSCTB/link-smbc-on-utilitarianism-and-vegatarianism", "linkUrl": "https://www.lesswrong.com/posts/kGTbCZFgZvLtoSCTB/link-smbc-on-utilitarianism-and-vegatarianism", "postedAtFormatted": "Sunday, October 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20SMBC%20on%20utilitarianism%20and%20vegatarianism.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20SMBC%20on%20utilitarianism%20and%20vegatarianism.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkGTbCZFgZvLtoSCTB%2Flink-smbc-on-utilitarianism-and-vegatarianism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20SMBC%20on%20utilitarianism%20and%20vegatarianism.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkGTbCZFgZvLtoSCTB%2Flink-smbc-on-utilitarianism-and-vegatarianism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkGTbCZFgZvLtoSCTB%2Flink-smbc-on-utilitarianism-and-vegatarianism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.smbc-comics.com/index.php?db=comics&amp;id=2393#comic</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kGTbCZFgZvLtoSCTB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 1, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "10479", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 69, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-17T03:17:16.705Z", "modifiedAt": null, "url": null, "title": "Curiosity, Adam Savage, and Life-Extension", "slug": "curiosity-adam-savage-and-life-extension", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:06.621Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaZ", "createdAt": "2010-04-05T04:07:01.214Z", "isAdmin": false, "displayName": "JoshuaZ"}, "userId": "fmTiLqp6mmXeLjwfN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Jbxgefztgv9Pbg4Zx/curiosity-adam-savage-and-life-extension", "pageUrlRelative": "/posts/Jbxgefztgv9Pbg4Zx/curiosity-adam-savage-and-life-extension", "linkUrl": "https://www.lesswrong.com/posts/Jbxgefztgv9Pbg4Zx/curiosity-adam-savage-and-life-extension", "postedAtFormatted": "Monday, October 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Curiosity%2C%20Adam%20Savage%2C%20and%20Life-Extension&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACuriosity%2C%20Adam%20Savage%2C%20and%20Life-Extension%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJbxgefztgv9Pbg4Zx%2Fcuriosity-adam-savage-and-life-extension%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Curiosity%2C%20Adam%20Savage%2C%20and%20Life-Extension%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJbxgefztgv9Pbg4Zx%2Fcuriosity-adam-savage-and-life-extension", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJbxgefztgv9Pbg4Zx%2Fcuriosity-adam-savage-and-life-extension", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 370, "htmlBody": "<p>Tonight the Discovery Channel had on their Curiosity series &nbsp;a program hosted by Adam Savage (of Mythbusters) on whether or not we could live indefinitely. The program probably did have some substantial impact on some people who have not been exposed to that sort of idea before, and may have been especially good at letting people understand that there's a definite possibility that the relevant discoveries might occur in their lifetimes.</p>\n<p>However the piece was as a whole decidedly lacking in actual information. &nbsp;First, the entire program was built around the conceit of Savage looking back from his thousandth birthday and talking about all the technologies that had allowed it to happen. In their hypothetical world, due to a severe car accident in 2022, Savage becomes the first person to benefit from a host of different technologies. There were zero actual interviews with scientists and although actual technological proposals were mentioned such as organ cloning and a brief segment on the SENS work of filtering blood cells, the vast majority was high-budget special effects segements of the new technologies. Also, cryonics was not mentioned at all, since in their hypothetical world, Savage had never needed that particular technology. Similarly, no mention is made of uploading, although Savage does gain cybernetic enhancements to his brain.</p>\n<p>At a level of evaluation of narrative rather than &nbsp;information, the entire piece was a bit incoherent and inconsistent. For example, Savage declares at one point that at age 130, he is then the oldest person in the world. This makes no sense in context since presumably after the basic technologies have been tested out on him they could then be applied to other people, some of whom will be older than he is. In the same section of the narrative, Savage has apparently become the head-engineer of the world's first space elevator construction project. A few centuries later, Savage then has to deal with an asteroid impact obliterating much of North America. My girlfriend remarked that the program came across almost as fanfic about Savage.</p>\n<p>Overall, I can't recommend this much but it might do a good job getting people aware of these issues who don't currently know anything. &nbsp;</p>\n<p>Did anyone else see this? What did they think?&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Jbxgefztgv9Pbg4Zx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 7.851576391035067e-07, "legacy": true, "legacyId": "10481", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-17T04:43:53.556Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Natural Selection's Speed Limit and Complexity Bound", "slug": "seq-rerun-natural-selection-s-speed-limit-and-complexity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:57.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/98TsWRNiv3zSbfaWy/seq-rerun-natural-selection-s-speed-limit-and-complexity", "pageUrlRelative": "/posts/98TsWRNiv3zSbfaWy/seq-rerun-natural-selection-s-speed-limit-and-complexity", "linkUrl": "https://www.lesswrong.com/posts/98TsWRNiv3zSbfaWy/seq-rerun-natural-selection-s-speed-limit-and-complexity", "postedAtFormatted": "Monday, October 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Natural%20Selection's%20Speed%20Limit%20and%20Complexity%20Bound&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Natural%20Selection's%20Speed%20Limit%20and%20Complexity%20Bound%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98TsWRNiv3zSbfaWy%2Fseq-rerun-natural-selection-s-speed-limit-and-complexity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Natural%20Selection's%20Speed%20Limit%20and%20Complexity%20Bound%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98TsWRNiv3zSbfaWy%2Fseq-rerun-natural-selection-s-speed-limit-and-complexity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F98TsWRNiv3zSbfaWy%2Fseq-rerun-natural-selection-s-speed-limit-and-complexity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 227, "htmlBody": "<p>Today's post, <a href=\"/lw/ku/natural_selections_speed_limit_and_complexity/\">Natural Selection's Speed Limit and Complexity Bound</a> was originally published on 04 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Tried to argue mathematically that there could be at most 25MB of meaningful information (or thereabouts) in the human genome, but computer simulations failed to bear out the mathematical argument. It does seem probably that evolution has some kind of speed limit and complexity bound - eminent evolutionary biologists seem to believe it, and in fact the Genome Project discovered only 25,000 genes in the human genome - but this particular math may not be the correct <em>argument</em>.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/832/seq_rerun_evolutions_are_stupid_but_work_anyways/\">Evolutions Are Stupid (But Work Anyways)</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "98TsWRNiv3zSbfaWy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 7.851872987036726e-07, "legacy": true, "legacyId": "10482", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QcnkFgojszmo9k4xk", "5xMWckkuvFHzqhyZb", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-17T06:05:06.675Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup 10-19-2011", "slug": "meetup-west-la-meetup-10-19-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:02.520Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9wF5irmektKv84qjM/meetup-west-la-meetup-10-19-2011", "pageUrlRelative": "/posts/9wF5irmektKv84qjM/meetup-west-la-meetup-10-19-2011", "linkUrl": "https://www.lesswrong.com/posts/9wF5irmektKv84qjM/meetup-west-la-meetup-10-19-2011", "postedAtFormatted": "Monday, October 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%2010-19-2011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%2010-19-2011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9wF5irmektKv84qjM%2Fmeetup-west-la-meetup-10-19-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%2010-19-2011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9wF5irmektKv84qjM%2Fmeetup-west-la-meetup-10-19-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9wF5irmektKv84qjM%2Fmeetup-west-la-meetup-10-19-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 147, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/49'>West LA Meetup 10-19-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">19 October 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7pm - 9pm <em>Wednesday</em>, October 19th.</p>\n\n<p><strong>Where:</strong> <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">The Westside Tavern</a> <em>in the upstairs Wine Bar</em>, located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Recommended Reading:</strong></p>\n\n<ul>\n<li>Choose any bias from Wikipedia's <strong><a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow\">list of cognitive biases</a></strong>. We will talk about that bias at the meeting - how to recognize it, why it happens, and how to counter it.</li>\n</ul>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p>\n\n<p>See also: <a href=\"http://lesswrong.com/r/discussion/lw/6at/west_la_biweekly_meetups/\">West LA Biweekly Meetups</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/49'>West LA Meetup 10-19-2011</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9wF5irmektKv84qjM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 7.852151124582999e-07, "legacy": true, "legacyId": "10486", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_10_19_2011\">Discussion article for the meetup : <a href=\"/meetups/49\">West LA Meetup 10-19-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">19 October 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7pm - 9pm <em>Wednesday</em>, October 19th.</p>\n\n<p><strong>Where:</strong> <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">The Westside Tavern</a> <em>in the upstairs Wine Bar</em>, located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong id=\"Recommended_Reading_\">Recommended Reading:</strong></p>\n\n<ul>\n<li>Choose any bias from Wikipedia's <strong><a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\" rel=\"nofollow\">list of cognitive biases</a></strong>. We will talk about that bias at the meeting - how to recognize it, why it happens, and how to counter it.</li>\n</ul>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p>\n\n<p>See also: <a href=\"http://lesswrong.com/r/discussion/lw/6at/west_la_biweekly_meetups/\">West LA Biweekly Meetups</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_10_19_20111\">Discussion article for the meetup : <a href=\"/meetups/49\">West LA Meetup 10-19-2011</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup 10-19-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_10_19_2011", "level": 1}, {"title": "Recommended Reading:", "anchor": "Recommended_Reading_", "level": 2}, {"title": "Discussion article for the meetup : West LA Meetup 10-19-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_10_19_20111", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tHFu6kvy2HMvQBEhW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-17T18:49:09.350Z", "modifiedAt": null, "url": null, "title": "A signaling theory of class x politics interaction", "slug": "a-signaling-theory-of-class-x-politics-interaction", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:02.200Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zh9AiXNjQaYXjmNaC/a-signaling-theory-of-class-x-politics-interaction", "pageUrlRelative": "/posts/Zh9AiXNjQaYXjmNaC/a-signaling-theory-of-class-x-politics-interaction", "linkUrl": "https://www.lesswrong.com/posts/Zh9AiXNjQaYXjmNaC/a-signaling-theory-of-class-x-politics-interaction", "postedAtFormatted": "Monday, October 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20signaling%20theory%20of%20class%20x%20politics%20interaction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20signaling%20theory%20of%20class%20x%20politics%20interaction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZh9AiXNjQaYXjmNaC%2Fa-signaling-theory-of-class-x-politics-interaction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20signaling%20theory%20of%20class%20x%20politics%20interaction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZh9AiXNjQaYXjmNaC%2Fa-signaling-theory-of-class-x-politics-interaction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZh9AiXNjQaYXjmNaC%2Fa-signaling-theory-of-class-x-politics-interaction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1006, "htmlBody": "<p>The media, most recently <a href=\"http://www.economist.com/node/21525851\">The Economist</a> and <a href=\"http://www.scientificamerican.com/article.cfm?id=occupy-wall-street-psychology\">Scientific American</a>, have been publicizing a surprising statistical finding: in the current economic climate, when more Americans than ever are poor, support for policies that redistribute wealth to the poor are at their <em>lowest</em> levels ever. This new-found antipathy towards aid to the poor concentrates in people who are near but not yet on the lowest rung of the social ladder. The Economist adds some related statistics: those who earn slightly more than the minimum wage are most against raising the minimum wage, and support for welfare in an area decreases as the percentage of welfare recipients in the area rises.<br /><br />Both articles explain the paradoxical findings by appealing to something called \"last place aversion\", an observed tendency for people to overvalue not being in last place. For example, in laboratory experiments where everyone gets randomly determined amounts of money, most people are willing to help those with less money than themselves gain cash - except the person with the second to lowest amount of money, who tends to try to thwart the person in last place even if it means enriching those who already have the most.<br /><br />\"Last place aversion\" is interesting, and certainly deserves at least a footnote in the catalogue of cognitive biases and heuristics, but I find it an unsatisfying explanation for the observations about US attitudes toward wealth redistribution. For one thing, the entire point of last place aversion is that it only affects those in last place, but in a massive country like the United States, everyone can find someone worse off than themselves (with one exception). For another, redistributive policies usually stop short of making those who need government handouts wealthier than those who do not; subsidizing more homeless shelters doesn't risk giving the homeless a nicer house than your own. Finally, many of the policies people oppose, like taxing the rich, don't directly translate to helping those in last place.<br /><br />I propose a different mechanism, one based on ... wait for it ... signaling.<br /><br />In <a href=\"/lw/2pv/intellectual_hipsters_and_metacontrarianism/\">a previous post</a>, I discussed multi-level signaling and counter-signaling, where each level tries to differentiate itself from the level beneath it. For example, the nouveau riche differentiate themselves from the middle class by buying ostentatious bling, and the nobility (who are at no risk of being mistaken for the middle class) differentiate themselves from the nouveau riche by <em>not</em> buying ostentatious bling.<br /><br />The very poor have one strong incentive to support redistribution of wealth: they need the money. They also have a second, subtler incentive: most redistributive policies come packaged with a philosophy that the poor are not personally responsible for the poverty, but are at least partially the victims of the rest of society. Therefore, these policies inflate both their pocketbook and their ego.<br /><br />The lower middle class gain what status they have by not being the very poor; effective status signaling for a lower middle class person is that which proves that she is certainly not poor. One effective method is to hold opinions contrary to those of the poor: that redistribution of wealth is evil and that the poor deserve their poverty. This ideology celebrates the superiority of the lower middle class over the poor by emphasizing the biggest difference between the lower middle class and the very poor: self-reliance. By asserting this ideology, a lower middle class person can prove her lower middle class status.<br /><br />The upper middle class gain what status they have by not being the lower middle class; effective status signaling for an upper middle class person is that which proves that she is certainly not lower middle class. One effective way is to hold opinions contrary to those of the lower middle class: that really the poor and lower middle class are the same sort of people, but some of them got lucky and some of them got unlucky. The only people who can comfortably say \"Deep down there's really no difference between myself and a poor person\" are people confident that no one will <em>actually</em> mistake them for a poor person after they say this.<br /><br />As a thought experiment, imagine your reactions to the following figures:<br /><br />1. A bearded grizzled man in ripped jeans, smelling slightly of alcohol, ranting about how the government needs to give more free benefits to the poor.<br /><br />2. A bearded grizzled man in ripped jeans, smelling slightly of alcohol, ranting about how the poor are lazy and he worked hard to get where he is today.<br /><br />3. A well-dressed, stylish man in a business suit, ranting about how the government needs to give more free benefits to the poor.<br /><br />4. A well-dressed, stylish man in a business suit, ranting about how the poor are lazy and he worked hard to get where he is today.<br /><br />My gut reactions are (1, lazy guy who wants free money) (2, honorable working class salt-of-the-earth) (3, compassionate guy with good intentions) (4, insensitive guy who doesn't realize his privilege). If these are relatively common reactions, these would suffice to explain the signaling patterns in these demographics.<br /><br />If this were true, it would explain the unusual trends cited in the first paragraph. An area where welfare became more common would see support for welfare drop, as it became more and more necessary for people to signal that they themselves were not welfare recipients. Support for minimum wage would be lowest among people who earn just slightly more than minimum wage, and who need to signal that they are not minimum wage earners. And since upper middle class people tend to favor redistribution as a status signal and lower middle class people tend to oppose it, a recession that drives more people into the lower middle class would cause a drop in support for redistributive policies.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Q6P8jLn8hH7kbuXRr": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zh9AiXNjQaYXjmNaC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 62, "baseScore": 92, "extendedScore": null, "score": 0.000201, "legacy": true, "legacyId": "10487", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 92, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9kcTNWopvXFncXgPy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-17T19:00:12.687Z", "modifiedAt": null, "url": null, "title": "Particles may not have broken light speed limit", "slug": "particles-may-not-have-broken-light-speed-limit", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:57.162Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "CPPMntDd4x5xYWjvy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XY79w9FqdNyfgT98H/particles-may-not-have-broken-light-speed-limit", "pageUrlRelative": "/posts/XY79w9FqdNyfgT98H/particles-may-not-have-broken-light-speed-limit", "linkUrl": "https://www.lesswrong.com/posts/XY79w9FqdNyfgT98H/particles-may-not-have-broken-light-speed-limit", "postedAtFormatted": "Monday, October 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Particles%20may%20not%20have%20broken%20light%20speed%20limit&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AParticles%20may%20not%20have%20broken%20light%20speed%20limit%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXY79w9FqdNyfgT98H%2Fparticles-may-not-have-broken-light-speed-limit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Particles%20may%20not%20have%20broken%20light%20speed%20limit%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXY79w9FqdNyfgT98H%2Fparticles-may-not-have-broken-light-speed-limit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXY79w9FqdNyfgT98H%2Fparticles-may-not-have-broken-light-speed-limit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 517, "htmlBody": "<p>(Note: This is my first post in discussion, instead of just a comment. Feel free to suggest improvements.)</p>\n<p>A few weeks ago in Less Wrong discussion, there was a discussion on whether or not we had found neutrinos traveling at superluminal velocities. That discussion can be found <a href=\"/lw/7rc/particles_break_lightspeed_limit/\">here</a>:</p>\n<p>Apparently, a paper was recently put into Arxiv from Ronald A.J. van Elburg, which has been popping up in the news as having indicated a possible explanation for the difference. To sum up the paper, instead of superluminal velocities, we may have a possible source of GPS error to compensate for.</p>\n<p>Some of the news reports also correctly pointed out that this paper is currently as tentative as the first announcements about the Neutrinos were when OPERA made them.</p>\n<p><br /><strong>Arxiv link:</strong></p>\n<p>http://arxiv.org/PS_cache/arxiv/pdf/1110/1110.2685v2.pdf</p>\n<p><strong>Link to Preprint on Author's page: </strong>(Thanks to Shminux)</p>\n<p><a href=\"http://home.kpn.nl/vanelburg30/Papers/RAJvanElburg_TimeOfFlight_Preprint.pdf\">http://home.kpn.nl/vanelburg30/Papers/RAJvanElburg_TimeOfFlight_Preprint.pdf</a><br /><br /><strong>Summary:</strong></p>\n<p>The Michelson-Morley experiment shows that the experimental outcome of an interference<br />experiment does not depend on the constant velocity of the setup with respect to an inertial<br />frame of reference. From this, one can conclude the existence of an invariant speed of light.<br />However, it does not follow from their experiment that a time-of-flight is reference frame<br />independent. In fact, the theory of special relativity predicts that the distance between the<br />production location of a particle and the detection location will be changed in all reference<br />frames which have a velocity component parallel to the baseline separating source and detector<br />in a photon time-of-flight experiment. For the OPERA experiment we find that the<br />associated correction is approximately 32 ns. Judging from the information provided, the<br />correction needs to be applied twice in the OPERA experiment. Therefore the total correctiotion<br />to the final results is 64 ns. Thus bringing the apparent velocities of neutrino&rsquo;s back<br />to a value not significantly different from the speed of light. We end this short letter by<br />suggesting an analysis of the experimental data which would illustrate the effects described.<br /><br /><strong>Hypothesis to test if paper is correct:</strong></p>\n<p><br />We showed that in the OPERA experiment the baseline time-of-flight is incorrectly identified<br />with the Lorentz transformation corrected time-of-flight as measured from a clock in a non4<br />stationary orbit and in fact exceeds it by at maximum 64 ns. The calculation presented contains<br />some simplifying assumptions. A full treatment should take into account the varying angle between<br />the GPS satellite&rsquo;s velocity vector and the CERN-Gran Sasso baseline. We expect that such a full<br />treatment will find a somewhat smaller value for the average correction. In addition such a full<br />analysis should be able to predict the correlation between the GPS satellite position(s) and the<br />observed time-of-flight.</p>\n<p><strong>References in the news:</strong></p>\n<p><a href=\"http://www.pcmag.com/article2/0,2817,2394747,00.asp#fbid=iQWAnqFuW6P\">http://www.pcmag.com/article2/0,2817,2394747,00.asp#fbid=iQWAnqFuW6P</a></p>\n<p>http://www.ibtimes.com/articles/232354/20111017/neutrino-light-einstein-cern-opera-theory-of-relativity-debate-speed-of-light-particle-faster-than-l.htm</p>\n<p>http://www.geekosystem.com/ftl-not-so-much/</p>\n<p>As a side note, if this paper is correct, Eliezer may have won some money, since he made bets in a <a href=\"/lw/7rc/particles_break_lightspeed_limit/4wmb\">thread</a> about this from the earlier discussion.</p>\n<p>&nbsp;</p>\n<p>Edit: Fixed three broken links and header formatting.</p>\n<p>Edit2: The original author retracted some of his comments on GPS. <a href=\"http://home.kpn.nl//vanelburg30//Publications.html\">http://home.kpn.nl//vanelburg30//Publications.html</a> has the link to why. Thanks to Shminux for finding this.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XY79w9FqdNyfgT98H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 3, "extendedScore": null, "score": 7.854806377517001e-07, "legacy": true, "legacyId": "10488", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["znpwJw66QCSMQkk66"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T02:35:33.098Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Beware Stephen J. Gould", "slug": "seq-rerun-beware-stephen-j-gould", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:59.632Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CX7upLtHfEZBrM7ar/seq-rerun-beware-stephen-j-gould", "pageUrlRelative": "/posts/CX7upLtHfEZBrM7ar/seq-rerun-beware-stephen-j-gould", "linkUrl": "https://www.lesswrong.com/posts/CX7upLtHfEZBrM7ar/seq-rerun-beware-stephen-j-gould", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Beware%20Stephen%20J.%20Gould&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Beware%20Stephen%20J.%20Gould%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCX7upLtHfEZBrM7ar%2Fseq-rerun-beware-stephen-j-gould%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Beware%20Stephen%20J.%20Gould%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCX7upLtHfEZBrM7ar%2Fseq-rerun-beware-stephen-j-gould", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCX7upLtHfEZBrM7ar%2Fseq-rerun-beware-stephen-j-gould", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 226, "htmlBody": "<p>Today's post, <a href=\"/lw/kv/beware_of_stephen_j_gould/\">Beware of Stephen J. Gould</a> was originally published on 06 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>A lot of people have gotten their grasp of evolutionary theory from Stephen J. Gould, a man who committed the moral equivalent of fraud in a way that is difficult to explain. At any rate, he severely misrepresented what evolutionary biologists believe, in the course of pretending to attack certain beliefs. One needs to clear from memory, as much as possible, not just everything that Gould positively stated but everything he seemed to imply the mainstream theory believed.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/836/seq_rerun_natural_selections_speed_limit_and/\">Natural Selection's Speed Limit and Complexity Bound</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CX7upLtHfEZBrM7ar", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 14, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "10489", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BahoNzY2pzSeM2Dtk", "98TsWRNiv3zSbfaWy", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T05:24:33.812Z", "modifiedAt": null, "url": null, "title": "Students asked to defend AGI danger update in favor of AGI riskiness", "slug": "students-asked-to-defend-agi-danger-update-in-favor-of-agi", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.845Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bxmpZRi5BEgui7RYK/students-asked-to-defend-agi-danger-update-in-favor-of-agi", "pageUrlRelative": "/posts/bxmpZRi5BEgui7RYK/students-asked-to-defend-agi-danger-update-in-favor-of-agi", "linkUrl": "https://www.lesswrong.com/posts/bxmpZRi5BEgui7RYK/students-asked-to-defend-agi-danger-update-in-favor-of-agi", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Students%20asked%20to%20defend%20AGI%20danger%20update%20in%20favor%20of%20AGI%20riskiness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStudents%20asked%20to%20defend%20AGI%20danger%20update%20in%20favor%20of%20AGI%20riskiness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbxmpZRi5BEgui7RYK%2Fstudents-asked-to-defend-agi-danger-update-in-favor-of-agi%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Students%20asked%20to%20defend%20AGI%20danger%20update%20in%20favor%20of%20AGI%20riskiness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbxmpZRi5BEgui7RYK%2Fstudents-asked-to-defend-agi-danger-update-in-favor-of-agi", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbxmpZRi5BEgui7RYK%2Fstudents-asked-to-defend-agi-danger-update-in-favor-of-agi", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 143, "htmlBody": "<p>From Geoff Anders of <a href=\"http://www.provisionalwebsite.com/tiki-index.php?page=AGI+Threat+Attitude+Study\">Leverage Research</a>:</p>\n<blockquote>\n<p>\n<p>In the Spring semester of 2011, I&nbsp;decided to see how effectively I could communicate the idea of a threat from AGI to my&nbsp;undergraduate classes. I spent three sessions on this for each of my two classes. My goal was to&nbsp;convince my students that all of us are going to be killed by an artificial intelligence. My strategy&nbsp;was to induce the students to come up with the ideas themselves. I gave out a survey before and&nbsp;after. An analysis of the survey responses indicates that the students underwent a statistically&nbsp;significant shift in their reported attitudes. After the three sessions, students reported believing&nbsp;that AGI would have a larger impact1 and also a worse impact2 than they originally reported&nbsp;believing.</p>\n</p>\n</blockquote>\n<p>Not a surprising result, perhaps, but the details of how Geoff taught AGI danger and the reactions of his students are quite interesting.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bxmpZRi5BEgui7RYK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 7, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "10491", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T06:16:35.784Z", "modifiedAt": null, "url": null, "title": "Meetup : Canberra Meetup Saturday November 5th", "slug": "meetup-canberra-meetup-saturday-november-5th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:23.501Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MtL3vak7n6QogQzbx/meetup-canberra-meetup-saturday-november-5th", "pageUrlRelative": "/posts/MtL3vak7n6QogQzbx/meetup-canberra-meetup-saturday-november-5th", "linkUrl": "https://www.lesswrong.com/posts/MtL3vak7n6QogQzbx/meetup-canberra-meetup-saturday-november-5th", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Canberra%20Meetup%20Saturday%20November%205th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Canberra%20Meetup%20Saturday%20November%205th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtL3vak7n6QogQzbx%2Fmeetup-canberra-meetup-saturday-november-5th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Canberra%20Meetup%20Saturday%20November%205th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtL3vak7n6QogQzbx%2Fmeetup-canberra-meetup-saturday-november-5th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMtL3vak7n6QogQzbx%2Fmeetup-canberra-meetup-saturday-november-5th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4a'>Canberra Meetup Saturday November 5th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 November 2011 11:00:00AM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">CRISP G015, ANU campus, Canberra ACT 2601</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>(Posted on behalf of Nikita Samoylov)</p>\n\n<p>This is a new meetup. We'll be mostly introducing each other. We'll\nalso play games on cognitive biases. We'll also talk what we want to\ndo in the future meetups. I'll bring tea and some snacks. You can also\nbring snacks. I hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4a'>Canberra Meetup Saturday November 5th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MtL3vak7n6QogQzbx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.857124760186698e-07, "legacy": true, "legacyId": "10493", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Canberra_Meetup_Saturday_November_5th\">Discussion article for the meetup : <a href=\"/meetups/4a\">Canberra Meetup Saturday November 5th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 November 2011 11:00:00AM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">CRISP G015, ANU campus, Canberra ACT 2601</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>(Posted on behalf of Nikita Samoylov)</p>\n\n<p>This is a new meetup. We'll be mostly introducing each other. We'll\nalso play games on cognitive biases. We'll also talk what we want to\ndo in the future meetups. I'll bring tea and some snacks. You can also\nbring snacks. I hope to see you there!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Canberra_Meetup_Saturday_November_5th1\">Discussion article for the meetup : <a href=\"/meetups/4a\">Canberra Meetup Saturday November 5th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Canberra Meetup Saturday November 5th", "anchor": "Discussion_article_for_the_meetup___Canberra_Meetup_Saturday_November_5th", "level": 1}, {"title": "Discussion article for the meetup : Canberra Meetup Saturday November 5th", "anchor": "Discussion_article_for_the_meetup___Canberra_Meetup_Saturday_November_5th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T08:44:12.732Z", "modifiedAt": null, "url": null, "title": "Is quantum physics (easily?) computable?", "slug": "is-quantum-physics-easily-computable", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:59.113Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Solvent", "createdAt": "2011-07-19T07:12:44.132Z", "isAdmin": false, "displayName": "Solvent"}, "userId": "a3sBsZXtAQacMDHfK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/j3iHHD7JZ8QRGw82M/is-quantum-physics-easily-computable", "pageUrlRelative": "/posts/j3iHHD7JZ8QRGw82M/is-quantum-physics-easily-computable", "linkUrl": "https://www.lesswrong.com/posts/j3iHHD7JZ8QRGw82M/is-quantum-physics-easily-computable", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20quantum%20physics%20(easily%3F)%20computable%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20quantum%20physics%20(easily%3F)%20computable%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj3iHHD7JZ8QRGw82M%2Fis-quantum-physics-easily-computable%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20quantum%20physics%20(easily%3F)%20computable%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj3iHHD7JZ8QRGw82M%2Fis-quantum-physics-easily-computable", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj3iHHD7JZ8QRGw82M%2Fis-quantum-physics-easily-computable", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 297, "htmlBody": "<p>So I've been trying to read the Quantum Physics sequence. I think I've understood about half of it- I've been rushed, and haven't really sat down and worked through the math. And so I apologize in advance for any mistakes I make here.</p>\n<p>It seems like classical mechanics with quantized time is really easy to&nbsp;simulate&nbsp;with a computer: every step, you just calculate force, figure out where velocity is going, then add the change in position to the new position.</p>\n<p>Then when you change to relativity, it seems like it's suddenly a lot harder to implement. Whereas classical mechanics are easy on a computer, it seems to me that you would have to set up a system where the outcomes of relativity are explicitly stated, while the classical outcomes are implicit.</p>\n<p>The same thing seems to occur, except more, with quantum physics. Continuous&nbsp;wave functions&nbsp;seems to be far harder than discrete particles. Similarly, the whole thing about \"no individual particle identity\" seems more difficult, although as I think of it now, I suppose this could be because the whole concept of particles is naive.</p>\n<p>It doesn't seem like the computation rules simply get harder as we learn more physics. After all, trying to do thermal physics got a lot easier when we started using the ideal gas model.</p>\n<p>Also, it's not just that ever improving theories must be ever more difficult to implement on a computer. Imagine that we lived inside Conway's Game of Life. We would figure out all kinds of high level physics, which would be probably way more complex than the eventual B3/S23 which they would discover.</p>\n<p>It feels like the actual implemented physics shouldn't much affect how computation works. After all, we live in a quantum universe and classical physics is still simpler to compute.</p>\n<p>Is there any value to this speculation?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "j3iHHD7JZ8QRGw82M", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.857630890161408e-07, "legacy": true, "legacyId": "10496", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T17:39:22.428Z", "modifiedAt": null, "url": null, "title": "Overcoming the Curse of Knowledge", "slug": "overcoming-the-curse-of-knowledge", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.465Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JesseGalef", "createdAt": "2011-04-02T01:36:57.286Z", "isAdmin": false, "displayName": "JesseGalef"}, "userId": "xmmzCdbLf5PBgEEC7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5BzjCGucq84YHZ23v/overcoming-the-curse-of-knowledge", "pageUrlRelative": "/posts/5BzjCGucq84YHZ23v/overcoming-the-curse-of-knowledge", "linkUrl": "https://www.lesswrong.com/posts/5BzjCGucq84YHZ23v/overcoming-the-curse-of-knowledge", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Overcoming%20the%20Curse%20of%20Knowledge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOvercoming%20the%20Curse%20of%20Knowledge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5BzjCGucq84YHZ23v%2Fovercoming-the-curse-of-knowledge%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Overcoming%20the%20Curse%20of%20Knowledge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5BzjCGucq84YHZ23v%2Fovercoming-the-curse-of-knowledge", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5BzjCGucq84YHZ23v%2Fovercoming-the-curse-of-knowledge", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 834, "htmlBody": "<p style=\"font-size: smaller;\">[crossposted at <a href=\"http://measureofdoubt.com/2011/10/18/the-curse-of-knowledge/\">Measure of Doubt</a>]</p>\n<p><img class=\"alignleft size-medium wp-image-1464\" style=\"float: left; margin: 10px;\" src=\"http://measureofdoubt.files.wordpress.com/2011/10/treeillusion.jpg\" alt=\"\" width=\"250\" height=\"177\" /></p>\n<p>What is the Curse of Knowledge, and how does it apply to science education, persuasion, and communication? No, it's not a reference to the Garden of Eden story. I'm referring to a particular psychological phenomenon that can make our messages backfire if we're not careful.</p>\n<p>Communication isn't a solo activity; it involves both you and the audience. Writing a diary entry is a great way to sort out thoughts, but if you want to be informative and persuasive to others, you need to figure out what they'll understand and be persuaded by. A common habit is to use ourselves as a mental model - assuming that everyone else will laugh at what we find funny, agree with what we find convincing, and interpret words the way we use them. The model works to an extent - especially with people similar to us - but other times our efforts fall flat. You can present the best argument you've ever heard, only to have it fall on dumb - sorry, deaf - ears.</p>\n<p>That's not necessarily your fault - maybe they're just dense! Maybe the argument is brilliant! But if we want to communicate successfully, pointing fingers and assigning blame is irrelevant. What matters is getting our point across, and we can't do it if we're <a href=\"http://measureofdoubt.com/2011/02/09/stuck-in-your-head-communicating-badly/\">stuck in our head</a>, unable to see things from our audience's perspective. We need to figure out what words will work.</p>\n<p>Unfortunately, that's where the Curse of Knowledge comes in. In 1990, Elizabeth Newton did a fascinating psychology experiment: She paired participants into teams of two: one tapper and one listener. The tappers picked one of 25 well-known songs and would tap out the rhythm on a table. Their partner - the designated listener - was asked to guess the song. How do you think they did?</p>\n<p>Not well. Of the 120 songs tapped out on the table, the listeners only guessed 3 of them correctly - a measly 2.5 percent. But get this: before the listeners gave their answer, the tappers were asked to predict how likely their partner was to get it right. Their guess? Tappers thought their partners would get the song 50 percent of the time. You know, only overconfident by a factor of 20. What made the tappers so far off?</p>\n<p>They lost perspective because they were \"cursed\" with the additional knowledge of the song title. Chip and Dan Heath use the story in their book <a href=\"http://www.amazon.com/Made-Stick-Ideas-Survive-Others/dp/1400064287\">Made to Stick</a> to introduce the term:</p>\n<p>&nbsp;</p>\n<blockquote>\"The problem is that tappers have been given knowledge (the song title) that makes it impossible for them to imagine what it's like to <em>lack</em> that knowledge. When they're tapping, they can't imagine what it's like for the listeners to hear isolated taps rather than a song. This is the Curse of Knowledge. Once we know something, we find it hard to imagine what it was like not to know it. Our knowledge has \"cursed\" us. And it becomes difficult or us to share our knowledge with others, because we can't readily re-create our listeners' state of mind.\"</blockquote>\n<p>&nbsp;</p>\n<p>So it goes with communicating complex information. Because we have all the background knowledge and understanding, we're overconfident that what we're saying is clear to everyone else. <strong>WE</strong> know what we mean! Why don't they get it? It's tough to remember that other people won't make the same inferences, have the same word-meaning connections, or share our associations.</p>\n<p>It's particularly important in science education. The more time a person spends in a field, the more the field's obscure language becomes second nature. Without special attention, audiences might not understand the words being used - or worse yet, they might get the wrong impression.</p>\n<p>Over at the American Geophysical Union blog, Callan Bentley gives a fantastic list of <a href=\"http://blogs.agu.org/mountainbeltway/2011/10/17/words-matter/\">Terms that have different meanings for scientists and the public.</a></p>\n<p><img class=\"alignnone size-full wp-image-1461\" title=\"ScienceTerms\" src=\"http://measureofdoubt.files.wordpress.com/2011/10/scienceterms.jpg\" alt=\"\" width=\"625\" height=\"464\" /></p>\n<p>What great examples! Even though the scientific terms are technically correct in context, they're obviously the wrong ones to use when talking to the public about climate change. An inattentive scientist could know all the material but leave the audience walking away with the wrong message.</p>\n<p>We need to spend the effort to phrase ideas in a way the audience will understand. Is that the same as \"dumbing down\" a message? After all, complicated ideas require complicated words and nuanced answers, right? Well, no. A real expert on a topic can give a simple distillation of material, identifying the core of the issue. Bentley did an outstanding job rephrasing technical, scientific terms in a way that conveys the intended message to the public.</p>\n<p>That's not dumbing things down, it's showing a mastery of the concepts. And he was able to do it by overcoming the \"curse of knowledge,\" seeing the issue from other people's perspective. Kudos to him - it's an essential part of science education, and something I really admire.</p>\n<p>P.S. - By the way, I chose that image for a reason: I bet once you see the baby in the tree you won&rsquo;t be able to &lsquo;unsee&rsquo; it. (<a rel=\"nofollow\" href=\"http://richardwiseman.wordpress.com/2011/10/13/can-you-see-the-baby-for-the-trees/\">image via Richard Wiseman</a>)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YQW2DxpZFTrqrxHBJ": 1, "ZXFpyQWPB5ideFbEG": 1, "WPkEd3et8f488w8LT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5BzjCGucq84YHZ23v", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 59, "extendedScore": null, "score": 0.000115, "legacy": true, "legacyId": "10497", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 59, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T22:52:52.112Z", "modifiedAt": null, "url": null, "title": "[LINK] More Bathtubs", "slug": "link-more-bathtubs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:57.393Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "N6W7sAzCo3fGauM7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/avtQm5TqcRHc3xC4T/link-more-bathtubs", "pageUrlRelative": "/posts/avtQm5TqcRHc3xC4T/link-more-bathtubs", "linkUrl": "https://www.lesswrong.com/posts/avtQm5TqcRHc3xC4T/link-more-bathtubs", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20More%20Bathtubs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20More%20Bathtubs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FavtQm5TqcRHc3xC4T%2Flink-more-bathtubs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20More%20Bathtubs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FavtQm5TqcRHc3xC4T%2Flink-more-bathtubs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FavtQm5TqcRHc3xC4T%2Flink-more-bathtubs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 27, "htmlBody": "<p>An interesting <a href=\"http://baselinescenario.com/2011/10/18/more-bathtubs/\">article</a> today on the correlation heuristic/fallacy w.r.t. finance. It describes how anchoring and availability bias contribute to difficulty understanding the difference between stocks and flows.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "avtQm5TqcRHc3xC4T", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.860541797305641e-07, "legacy": true, "legacyId": "10498", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-18T23:24:55.439Z", "modifiedAt": null, "url": null, "title": "Resetting my perception of something", "slug": "resetting-my-perception-of-something", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:57.907Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ibX2HEjupHGP8uD64/resetting-my-perception-of-something", "pageUrlRelative": "/posts/ibX2HEjupHGP8uD64/resetting-my-perception-of-something", "linkUrl": "https://www.lesswrong.com/posts/ibX2HEjupHGP8uD64/resetting-my-perception-of-something", "postedAtFormatted": "Tuesday, October 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Resetting%20my%20perception%20of%20something&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AResetting%20my%20perception%20of%20something%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FibX2HEjupHGP8uD64%2Fresetting-my-perception-of-something%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Resetting%20my%20perception%20of%20something%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FibX2HEjupHGP8uD64%2Fresetting-my-perception-of-something", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FibX2HEjupHGP8uD64%2Fresetting-my-perception-of-something", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<p>The guy who taught me how to eat sushi a couple months ago explained that I should get a slice of ginger before trying a different kind of sushi in order to \"reset my taste buds\" (probably broscience) and feel the taste anew (it works). That's also the exact problem that programmers face when trying to design user interfaces: after looking at the thing for a long time, they grow blind to its shortcomings. A visual reset would come in handy. I imagine that resets could help in other areas too. Does anything like that exist? Cogsci majors, help!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ibX2HEjupHGP8uD64", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 15, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "10500", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-19T00:44:27.239Z", "modifiedAt": null, "url": null, "title": "Occupy Wall Street: Predictions, Speculations", "slug": "occupy-wall-street-predictions-speculations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.625Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "byrnema", "createdAt": "2009-03-20T18:02:38.305Z", "isAdmin": false, "displayName": "byrnema"}, "userId": "SCnD6W8NiztYBN39M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZY8zeEvH2ZfcYZdnL/occupy-wall-street-predictions-speculations", "pageUrlRelative": "/posts/ZY8zeEvH2ZfcYZdnL/occupy-wall-street-predictions-speculations", "linkUrl": "https://www.lesswrong.com/posts/ZY8zeEvH2ZfcYZdnL/occupy-wall-street-predictions-speculations", "postedAtFormatted": "Wednesday, October 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Occupy%20Wall%20Street%3A%20Predictions%2C%20Speculations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOccupy%20Wall%20Street%3A%20Predictions%2C%20Speculations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZY8zeEvH2ZfcYZdnL%2Foccupy-wall-street-predictions-speculations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Occupy%20Wall%20Street%3A%20Predictions%2C%20Speculations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZY8zeEvH2ZfcYZdnL%2Foccupy-wall-street-predictions-speculations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZY8zeEvH2ZfcYZdnL%2Foccupy-wall-street-predictions-speculations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<p>On reddit today I read '<a href=\"/r/discussion/lw/83p/occupy_wall_street_predictions_speculations/51uq\">the-Gandhi-quote</a>' on a post about the Wall Street Occupation Protest:</p>\n<p>\"First they ignore you. Then they laugh at you..\"</p>\n<p>I'm transitioning, possibly, from the laughing stage and am beginning to feel the tiniest bit excited that perhaps some actual change is in order. On the one hand, I feel sufficiently skeptical about the probability of a 'revolution'. On the other hand, given how fast the world has been changing (the internet, gloablization), maybe change is inevitable and this is the way it happens now.</p>\n<p>I know this is a rationality site, not a current affairs site, but when something tweaks my interest I like to know what \"Less Wrong\" thinks...waiting for a spontaneous post could take forever and finding a 'rationality-spin' would be disingenuous so I'll just ask:</p>\n<p>What is possible and what is likely?</p>\n<p>What factors are important?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FkzScn5byCs9PxGsA": 1, "wzgcQCrwKfETcBpR9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZY8zeEvH2ZfcYZdnL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": -8, "extendedScore": null, "score": -6e-06, "legacy": true, "legacyId": "10501", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-19T03:36:47.810Z", "modifiedAt": null, "url": null, "title": "Rational toy buying", "slug": "rational-toy-buying", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:08.000Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "N6W7sAzCo3fGauM7i", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yAAveoJeBiWZiST29/rational-toy-buying", "pageUrlRelative": "/posts/yAAveoJeBiWZiST29/rational-toy-buying", "linkUrl": "https://www.lesswrong.com/posts/yAAveoJeBiWZiST29/rational-toy-buying", "postedAtFormatted": "Wednesday, October 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20toy%20buying&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20toy%20buying%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyAAveoJeBiWZiST29%2Frational-toy-buying%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20toy%20buying%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyAAveoJeBiWZiST29%2Frational-toy-buying", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyAAveoJeBiWZiST29%2Frational-toy-buying", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 556, "htmlBody": "<p>I have an 8-year-old sister who is very interested in science. The school she attends (in rural Indiana) takes the mantra of \"teaching to the test\" to a whole new level; my sister has already come home from school many days crying and stressed over fear that she won't pass her state's proficiency tests (which are 5+ months away). They are underfunded and the science curriculum is what most of the (overtly religious) teachers are undertrained in, and so science is essentially not addressed. My sister has about an order of magnitude more homework on cursive writing than on anything related to science.<br /><br />I want to purchase a gift for her for the holidays this year (the occasion doesn't matter, but it's a time when I'll actually be home so I can give her the gift and play with her / explain how to use it / hopefully help her start thinking about some things). I'm willing to consider age-appropriate ideas across several price ranges, but I want to think of something that will deliver a lot of utility: i.e. it should be compelling enough that an 8-year-old will actually like using it and there should be at least some evidence that she will benefit from it.<br /><br />I've considered things like the EDUbuntu computers that come with lots of educational software, but actually buying one seems to be not straightforward. Is the best thing to buy a cheap netbook at then install EDUbuntu myself? Is a netbook too much for an 8-year-old? I'm mostly focused on things that will help her be proficient with computers and potentially help her develop a more sophisticated interest in them as she grows up. The Lego Mindstorm robotics stuff also crossed my mind.<br /><br />Does anyone have experience with this / know of resources for making a good investment? Or am I way over-thinking this and just some regular Legos or art supplies are going to do essentially just as much good?</p>\n<p>&nbsp;</p>\n<p><strong>Added 02/25/2012</strong></p>\n<p>Much of the advice was very helpful. I ultimately found out that my young sister was interested in \"mixing chemicals together because it looked cool.\" An item that I found which looked like a good way to bridge the gap between her more girly interests and her interest in chemistry was <a href=\"http://www.thamesandkosmos.com/products/ps/ps2.html\">Perfume Science</a> from Thames and Kosmos. I also purchased a variety kit from <a href=\"http://www.snapcircuits.net/\">Snap Circuits</a>. She loved both items and we spent a good bit of time playing with them during my trip home to see my family. We made several different kinds of perfume and also did some activities that helped explain how different extracts have been acquired throughout human history for their smells. Ultimately, my sister made a science fair project (something which surprised my parents a lot) based around one of the activities in the perfume science booklet, and she won second place.<br /><br />I was very happy with both my decision to ask this question on LessWrong (despite the title of the post, which seems to seethingly annoy many LWers) and my purchase decisions. I used the website <a href=\"http://www.fatbraintoys.com/\">Fat Brain Toys</a>&nbsp;to purchase the items and everything arrived without a problem. That site seemed to also have a reasonably good selection for more educationally oriented toys across several ages, and with useful customer reviews.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yAAveoJeBiWZiST29", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 16, "extendedScore": null, "score": 7.861516101764699e-07, "legacy": true, "legacyId": "10499", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-19T04:08:25.167Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Tragedy of Group Selectionism", "slug": "seq-rerun-the-tragedy-of-group-selectionism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.258Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mSxyY3K6KZDmmm8Dv/seq-rerun-the-tragedy-of-group-selectionism", "pageUrlRelative": "/posts/mSxyY3K6KZDmmm8Dv/seq-rerun-the-tragedy-of-group-selectionism", "linkUrl": "https://www.lesswrong.com/posts/mSxyY3K6KZDmmm8Dv/seq-rerun-the-tragedy-of-group-selectionism", "postedAtFormatted": "Wednesday, October 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Tragedy%20of%20Group%20Selectionism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Tragedy%20of%20Group%20Selectionism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmSxyY3K6KZDmmm8Dv%2Fseq-rerun-the-tragedy-of-group-selectionism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Tragedy%20of%20Group%20Selectionism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmSxyY3K6KZDmmm8Dv%2Fseq-rerun-the-tragedy-of-group-selectionism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmSxyY3K6KZDmmm8Dv%2Fseq-rerun-the-tragedy-of-group-selectionism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 229, "htmlBody": "<p>Today's post, <a href=\"/lw/kw/the_tragedy_of_group_selectionism/\">The Tragedy of Group Selectionism</a> was originally published on 07 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Describes a key case where some pre-1960s evolutionary biologists went wrong by anthropomorphizing evolution - in particular, Wynne-Edwards, Allee, and Brereton among others believed that predators would voluntarily restrain their breeding to avoid overpopulating their habitat. Since evolution does not usually do this sort of thing, their rationale was group selection - populations that did this would survive better. But group selection is extremely difficult to make work mathematically, and an experiment under sufficiently extreme conditions to permit group selection, had rather different results.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/83d/seq_rerun_beware_stephen_j_gould/\">Beware Stephen J. Gould</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mSxyY3K6KZDmmm8Dv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.861624628485618e-07, "legacy": true, "legacyId": "10508", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QsMJQSFj7WfoTMNgW", "CX7upLtHfEZBrM7ar", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-19T12:38:10.256Z", "modifiedAt": null, "url": null, "title": "The Need for Universal Experience Classes", "slug": "the-need-for-universal-experience-classes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.026Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "pZ9aQ8k4CjPe4M6eL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GQpyaSQqruHygFwMr/the-need-for-universal-experience-classes", "pageUrlRelative": "/posts/GQpyaSQqruHygFwMr/the-need-for-universal-experience-classes", "linkUrl": "https://www.lesswrong.com/posts/GQpyaSQqruHygFwMr/the-need-for-universal-experience-classes", "postedAtFormatted": "Wednesday, October 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Need%20for%20Universal%20Experience%20Classes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Need%20for%20Universal%20Experience%20Classes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGQpyaSQqruHygFwMr%2Fthe-need-for-universal-experience-classes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Need%20for%20Universal%20Experience%20Classes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGQpyaSQqruHygFwMr%2Fthe-need-for-universal-experience-classes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGQpyaSQqruHygFwMr%2Fthe-need-for-universal-experience-classes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 442, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\"; mso-fareast-language:JA;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:\"Times New Roman\"; mso-fareast-language:JA;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">In school we learn wonderful things like how to find integrals, solve equations, and how to calculate valence electrons of elements based on their atomic numbers. Because, obviously, they will be very important in our futures -- especially if we become artists, musicians, writers, actors, and business people.</p>\n<p class=\"MsoNormal\">We learn so much in school. Yet, when most people look at paintings they don&rsquo;t truly understand them. When most people listen to music, they don&rsquo;t really know what they&rsquo;re hearing. Most people would fail simple music theory tests, even though many have listened to music most days of the week since they were babies!</p>\n<p class=\"MsoNormal\">Similarly, if you have working eyes, you should ask &ldquo;Why do shadows look like they do? What color is snow, really? Can I predict the colors of different colored materials at different times of the day? If not, why? I have been seeing them for years, haven&rsquo;t I?&rdquo;</p>\n<p class=\"MsoNormal\">I think the problem here is that people can&rsquo;t understand what is really important. Calculus, mechanical physics, chemistry, microiology, etc. are interesting to learn, perhaps. But, they are relatively advanced topics. People don&rsquo;t use them in daily life unless they are professionals. Why not learn things that we think about every day instead of those that will frankly be useless to most?</p>\n<p class=\"MsoNormal\">Why don&rsquo;t we learn how to understand our senses?</p>\n<p class=\"MsoNormal\">Learning about sight, sounds, thoughts, etc. should fit in somewhere in the first year of high school. Everyone needs to learn the physics of art and color (e.g. <a href=\"http://www.thegnomonworkshop.com/store/product/472/Color-Theory%3A-The-Mechanics-of-Color\">this</a> and <a href=\"http://www.thegnomonworkshop.com/store/product/185/Practical-Light-and-Color\">this</a>), music theory, rationality, and logic.</p>\n<p class=\"MsoNormal\">For example, why should people start learning (or pretending to learn) philosophy, the art of thinking, in college? Should we be able to make life-changing decisions without even knowing how to spot errors in our thinking?</p>\n<p class=\"MsoNormal\">As a science researcher, I know first hand how hard it is to find a good balance between being well versed in worldly topics and being focused on a field in order to excel in it. But, both of these areas of study should not be called the true basics, in my opinion.</p>\n<p class=\"MsoNormal\">As president of my school's philosophy club, I took a different approach to teaching the basics of philosophy and thinking than traditional classes do. Instead of asking students to discuss the lives and ideas of famous Greek philosophers, I asked them to analyze their own lives and make their own philosophies. As expected, they were terrible at it at first. But, by the end of the year people began to actually think about the world around them.</p>\n<p class=\"MsoNormal\">So, my point is that we should -- in life and in school -- emphasize actual everyday thinking more.</p>\n<p class=\"MsoNormal\">The biggest challenge is that it takes so long!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GQpyaSQqruHygFwMr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": -13, "extendedScore": null, "score": 7.863374428879362e-07, "legacy": true, "legacyId": "10058", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T02:47:02.800Z", "modifiedAt": null, "url": null, "title": "Reminder: $250 LessWrong source introduction prize submissions due soon", "slug": "reminder-usd250-lesswrong-source-introduction-prize", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.070Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KgtCRQabYMnSbzLwC/reminder-usd250-lesswrong-source-introduction-prize", "pageUrlRelative": "/posts/KgtCRQabYMnSbzLwC/reminder-usd250-lesswrong-source-introduction-prize", "linkUrl": "https://www.lesswrong.com/posts/KgtCRQabYMnSbzLwC/reminder-usd250-lesswrong-source-introduction-prize", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reminder%3A%20%24250%20LessWrong%20source%20introduction%20prize%20submissions%20due%20soon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReminder%3A%20%24250%20LessWrong%20source%20introduction%20prize%20submissions%20due%20soon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKgtCRQabYMnSbzLwC%2Freminder-usd250-lesswrong-source-introduction-prize%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reminder%3A%20%24250%20LessWrong%20source%20introduction%20prize%20submissions%20due%20soon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKgtCRQabYMnSbzLwC%2Freminder-usd250-lesswrong-source-introduction-prize", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKgtCRQabYMnSbzLwC%2Freminder-usd250-lesswrong-source-introduction-prize", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>This is just a reminder that the deadline for&nbsp;<a href=\"/lw/7x1/prize_for_the_best_introduction_to_the_lesswrong/\">$250 prize for the best introduction to the LessWrong source</a>&nbsp;is (<strong>Edit</strong>: not Nov. 23rd!) <strong>next&nbsp;</strong><strong>Tuesday Oct. 25th</strong>. Good luck to all contestants!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KgtCRQabYMnSbzLwC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.866289855199221e-07, "legacy": true, "legacyId": "10520", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JDMtDBmaycM3SmDBk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T03:18:32.873Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fake Selfishness", "slug": "seq-rerun-fake-selfishness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.020Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BQeu7jpqmyWX3MzrY/seq-rerun-fake-selfishness", "pageUrlRelative": "/posts/BQeu7jpqmyWX3MzrY/seq-rerun-fake-selfishness", "linkUrl": "https://www.lesswrong.com/posts/BQeu7jpqmyWX3MzrY/seq-rerun-fake-selfishness", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Selfishness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Selfishness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBQeu7jpqmyWX3MzrY%2Fseq-rerun-fake-selfishness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Selfishness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBQeu7jpqmyWX3MzrY%2Fseq-rerun-fake-selfishness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBQeu7jpqmyWX3MzrY%2Fseq-rerun-fake-selfishness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<p>Today's post, <a href=\"/lw/kx/fake_selfishness/\">Fake Selfishness</a> was originally published on 08 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Fake_Selfishness\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Many people who espouse a philosophy of selfishness aren't really selfish. If they were selfish, there are a lot more productive things to do with their time than espouse selfishness, for instance. Instead, individuals who proclaim themselves selfish do whatever it is they actually want, including altruism, but can always find some sort of self-interest rationalization for their behavior.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/83w/seq_rerun_the_tragedy_of_group_selectionism/\">The Tragedy of Group Selectionism</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BQeu7jpqmyWX3MzrY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.866398081451651e-07, "legacy": true, "legacyId": "10521", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Masoq4NdmmGSiq2xw", "mSxyY3K6KZDmmm8Dv", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T03:54:28.892Z", "modifiedAt": null, "url": null, "title": "Meetup : Cambridge (MA) Saturday meetup", "slug": "meetup-cambridge-ma-saturday-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.151Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GTegHD95wXPnHLvWg/meetup-cambridge-ma-saturday-meetup", "pageUrlRelative": "/posts/GTegHD95wXPnHLvWg/meetup-cambridge-ma-saturday-meetup", "linkUrl": "https://www.lesswrong.com/posts/GTegHD95wXPnHLvWg/meetup-cambridge-ma-saturday-meetup", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Cambridge%20(MA)%20Saturday%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Cambridge%20(MA)%20Saturday%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGTegHD95wXPnHLvWg%2Fmeetup-cambridge-ma-saturday-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Cambridge%20(MA)%20Saturday%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGTegHD95wXPnHLvWg%2Fmeetup-cambridge-ma-saturday-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGTegHD95wXPnHLvWg%2Fmeetup-cambridge-ma-saturday-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 96, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4b'>Cambridge (MA) Saturday meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">22 October 2011 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Cosi Restaurant 290 Main Street, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>EDIT: Moved from Sunday to Saturday We'll meet at Cosi this time, and migrate to another location after an hour or so. Topics for this meetup: * Mind/motivation hacking techniques * Last week's Singularity Summit I was at the summit last week, and apparently there was a mixup about the location while I was away. Sorry about that! We're definitely at Cosi this time.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4b'>Cambridge (MA) Saturday meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GTegHD95wXPnHLvWg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.866521539156561e-07, "legacy": true, "legacyId": "10522", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__Saturday_meetup\">Discussion article for the meetup : <a href=\"/meetups/4b\">Cambridge (MA) Saturday meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">22 October 2011 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Cosi Restaurant 290 Main Street, Cambridge, MA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>EDIT: Moved from Sunday to Saturday We'll meet at Cosi this time, and migrate to another location after an hour or so. Topics for this meetup: * Mind/motivation hacking techniques * Last week's Singularity Summit I was at the summit last week, and apparently there was a mixup about the location while I was away. Sorry about that! We're definitely at Cosi this time.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Cambridge__MA__Saturday_meetup1\">Discussion article for the meetup : <a href=\"/meetups/4b\">Cambridge (MA) Saturday meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Cambridge (MA) Saturday meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__Saturday_meetup", "level": 1}, {"title": "Discussion article for the meetup : Cambridge (MA) Saturday meetup", "anchor": "Discussion_article_for_the_meetup___Cambridge__MA__Saturday_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "6 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T04:47:24.711Z", "modifiedAt": null, "url": null, "title": "Greg Linster on the beauty of death", "slug": "greg-linster-on-the-beauty-of-death", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.418Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonathan_Graehl", "createdAt": "2009-02-27T23:21:15.671Z", "isAdmin": false, "displayName": "Jonathan_Graehl"}, "userId": "eKsWtKKceoRYwcc7s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HXr2qQLfNcuy2zPaD/greg-linster-on-the-beauty-of-death", "pageUrlRelative": "/posts/HXr2qQLfNcuy2zPaD/greg-linster-on-the-beauty-of-death", "linkUrl": "https://www.lesswrong.com/posts/HXr2qQLfNcuy2zPaD/greg-linster-on-the-beauty-of-death", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Greg%20Linster%20on%20the%20beauty%20of%20death&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGreg%20Linster%20on%20the%20beauty%20of%20death%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHXr2qQLfNcuy2zPaD%2Fgreg-linster-on-the-beauty-of-death%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Greg%20Linster%20on%20the%20beauty%20of%20death%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHXr2qQLfNcuy2zPaD%2Fgreg-linster-on-the-beauty-of-death", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHXr2qQLfNcuy2zPaD%2Fgreg-linster-on-the-beauty-of-death", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 96, "htmlBody": "<blockquote>\n<p>Without death we cannot truly have life. As such, what a travesty of life it would be to achieve a machine-like immortality!</p>\n</blockquote>\n<blockquote>Gray writes the following chilling lines: &ldquo;If you understand that in wanting to live for ever you are trying to preserve a lifeless image of yourself, you may not want to be resurrected or to survive in a post-mortem paradise.<strong> What could be more deadly than being unable to die?</strong>&rdquo; (my emphasis)</blockquote>\n<p><a href=\"http://www.ribbonfarm.com/2011/10/19/the-quest-for-immortality\">via</a>.</p>\n<p>Sounds like sour grapes. I'd heard of people holding such sentiments; this is the first time I've actually seen them expressed myself.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HXr2qQLfNcuy2zPaD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 9, "extendedScore": null, "score": 1.9e-05, "legacy": true, "legacyId": "10524", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T05:09:59.345Z", "modifiedAt": null, "url": null, "title": "Some conditional independence (Bayes Network) exercises from ai-class.com", "slug": "some-conditional-independence-bayes-network-exercises-from", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:58.762Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonathan_Graehl", "createdAt": "2009-02-27T23:21:15.671Z", "isAdmin": false, "displayName": "Jonathan_Graehl"}, "userId": "eKsWtKKceoRYwcc7s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4FiKXrp45uLdhzqrr/some-conditional-independence-bayes-network-exercises-from", "pageUrlRelative": "/posts/4FiKXrp45uLdhzqrr/some-conditional-independence-bayes-network-exercises-from", "linkUrl": "https://www.lesswrong.com/posts/4FiKXrp45uLdhzqrr/some-conditional-independence-bayes-network-exercises-from", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20conditional%20independence%20(Bayes%20Network)%20exercises%20from%20ai-class.com&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20conditional%20independence%20(Bayes%20Network)%20exercises%20from%20ai-class.com%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4FiKXrp45uLdhzqrr%2Fsome-conditional-independence-bayes-network-exercises-from%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20conditional%20independence%20(Bayes%20Network)%20exercises%20from%20ai-class.com%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4FiKXrp45uLdhzqrr%2Fsome-conditional-independence-bayes-network-exercises-from", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4FiKXrp45uLdhzqrr%2Fsome-conditional-independence-bayes-network-exercises-from", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 58, "htmlBody": "<p>If you'd like to see some visual representations of conditional independence is neither necessary or sufficient for independence, confounding causes, explaining away, etc. you should be able to view <a href=\"http://www.youtube.com/watch?feature=player_embedded&amp;v=1DhY4Cs_qEs\">these videos from ai-class.com.</a></p>\n<p>Working the exercises gave me a better understanding than the \"I understand this and so don't need to actually apply it\" feeling that almost satisfied me.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4FiKXrp45uLdhzqrr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 7.866780972481712e-07, "legacy": true, "legacyId": "10525", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T14:05:44.192Z", "modifiedAt": null, "url": null, "title": "Social status & testosterone", "slug": "social-status-and-testosterone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:02.078Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uRg5Q2vAteDem5b5S/social-status-and-testosterone", "pageUrlRelative": "/posts/uRg5Q2vAteDem5b5S/social-status-and-testosterone", "linkUrl": "https://www.lesswrong.com/posts/uRg5Q2vAteDem5b5S/social-status-and-testosterone", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Social%20status%20%26%20testosterone&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASocial%20status%20%26%20testosterone%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuRg5Q2vAteDem5b5S%2Fsocial-status-and-testosterone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Social%20status%20%26%20testosterone%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuRg5Q2vAteDem5b5S%2Fsocial-status-and-testosterone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuRg5Q2vAteDem5b5S%2Fsocial-status-and-testosterone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3055, "htmlBody": "<p>We&rsquo;ve discussed signaling and status endlessly on LW; I think this is right up our vein: a 2011 review of research on the connections between famous male hormone testosterone and various forms of social interaction and especially social status, Eisenegger et al&rsquo;s <a href=\"http://dl.dropbox.com/u/5317066/2011-eisenegger-role-testosterone-social-interaction.pdf\">&ldquo;The role of testosterone in social interaction&rdquo;</a>. (I grabbed this PDF in the short time Elsevier left full-text available, but only now, with some <a href=\"http://www.gwern.net/Modafinil\">modafinil</a>-powered spare time, have gotten around to excerpting it for you guys.)</p>\n<h2 id=\"abstract\"><a href=\"#TOC\"><span class=\"header-section-number\">1</span> Abstract</a></h2>\n<blockquote>\n<p>Although animal researchers established the role of testosterone as a &lsquo;social hormone&rsquo; decades ago, the investigation of its causal influence on human social behaviors has only recently begun. Here, we review and discuss recent studies showing the causal effects of testosterone on social interactions in animals and humans, and outline the basic neurobiological mechanisms that might underlie these effects. Based on these recent findings, we argue that the role of testosterone in human social behavior might be best understood in terms of the search for, and maintenance of, social status.</p>\n</blockquote>\n<h2 id=\"excerpts\"><a id=\"more\"></a><br /></h2>\n<h2><a href=\"#TOC\"><span class=\"header-section-number\">2</span> Excerpts</a></h2>\n<p>Is testosterone simply aggression promoting (a sort of &lsquo;roid rage&rsquo;)?</p>\n<blockquote>\n<p>Early evidence for the role of testosterone in social behavior suggested that it facilitates overt physical aggression (see Glossary) in social contexts. For instance, castrated rodents, which have little, if any, testosterone circulating in their blood, show a near-complete absence of physical fights; however, fights can be fully restored by providing testosterone supplementation to these animals [03]&hellip;high testosterone levels in male prisoners have been linked to having a history of rape, murder and armed robbery, and relatively lower levels to a history of theft and drug abuse [08]. A similar pattern was observed in a study of female prison inmates [9]. However, the causality in these studies remains unclear</p>\n</blockquote>\n<p>Probably not:</p>\n<blockquote>\n<p>the existing evidence for a link between aggression and testosterone in humans is relatively weak, but positive [12]. Even if one accepts the fact that reactive aggression can be measured in a controlled laboratory environment, results are similarly inconclusive: recent studies found a positive relationship between baseline testosterone levels and laboratory measures of reactive aggression (reviewed in [11]), but others also reported null findings (in larger samples) [13]. Most importantly, however, a causal role for testosterone in forms of reactive aggression could not be confirmed, as neither long-term nor acute administration of testosterone had an effect [13,14].</p>\n</blockquote>\n<p>This may come as a surprise:</p>\n<blockquote>\n<p>Folk wisdom holds that testosterone causes antisocial, egoistic, or even aggressive behaviors in humans. However, the correlational studies discussed above already suggest that this simple folk view probably requires revision [34,56]. A recent placebo-controlled testosterone administration study found support for the idea that the testosterone-aggression link might be based upon &lsquo;folk&rsquo; views: individuals given placebo who believed they had been given testosterone showed less fair bargaining offers compared with those who believed that they had received placebo, thus confirming people&rsquo;s stereotypes about the behavioral effects of testosterone.</p>\n</blockquote>\n<p>The null findings may be due to a possible confounding effect of homeostasis, but that wouldn&rsquo;t cover the null on acute administration:</p>\n<blockquote>\n<p>The first study to use a causal testosterone administration procedure in an experimental economic setting did not find any effects on several economic social interactions [14]. Because the study used long-term administration of testosterone, this null finding might be due to secondary feedback effects on the neuroendocrine axis (i.e.&nbsp;suppression of endogenous testosterone production owing to chronic administration). In general, acute administration shows greater reliability in the production of both behavioral and neurophysiological effects (reviewed in [55]).</p>\n</blockquote>\n<p>&lsquo;Dominant&rsquo; looks like a better perspective than &lsquo;aggressive&rsquo;:</p>\n<blockquote>\n<p>rhesus monkeys with high testosterone levels use stares, threats and displacements, rather than overtly aggressive interactions, to ascertain high social status [16]&hellip;[saliva] measurements of testosterone at a single time-point correlate positively with high dominance in both adolescents [19,20] and adults [21,22]. In addition, salivary testosterone levels correlate with implicit measures of power motivation [23] and increased vigilance for status threats [24,25]. As a result of these relationships, and the moderate stability of testosterone levels over time, some have suggested that baseline testosterone levels reflect a personality trait [26]</p>\n<p>men show a larger increase in testosterone when exposed to the scent of an ovulating woman compared with that of a non-ovulating woman or a control [27]. Apart from sexual social stimuli, which are reliable inductors of a testosterone response [28,29], social interactions outside a direct reproductive context have also been shown to induce a testosterone response [01]. In particular, testosterone levels rise within minutes in anticipation of both physical and non-physical competitive situations; for example, dyadic food competition in chimpanzees [30], or tennis, chess or domino tournaments in humans (reviewed in [31]). Testosterone also reacts to contest outcomes [32], and not just to anticipation: for instance, stock traders show higher testosterone levels if their daily profits are above average, and winners of soccer matches show higher testosterone levels than do the losers [33]&hellip;.causal manipulation of social context (e.g.&nbsp;rigged contests) confirms a causal effect of winning situations on testosterone levels (e.g. [34&ndash;38]). These effects can be large; for example, merely watching oneself win a competitive interaction on video produces a 40% testosterone surge from baseline [37].</p>\n</blockquote>\n<p>This interest in dominance leads to mental changes (I am reminded of self-deception):</p>\n<blockquote>\n<p>individuals who generally have higher scores on self-reported dominance and higher basal levels of testosterone show vigilant responses to angry facial expressions (reviewed in [42]). Furthermore, exogenous administration of testosterone increases the sympathetic heart-rate response to angry, but not to happy facial expressions [43] (Figure 2). Although this could theoretically also reflect autonomic arousal as part of a fear response, testosterone has been shown to reduce fear [44], suggesting that dominant people perceive an angry face as a challenge&hellip;.a recent testosterone administration study has shown that facial mimicry [&ldquo;a precursor of empathy-related processes occurring automatically&rdquo;] in response to emotional facial expressions is relatively suppressed after a single dose of testosterone [48]&hellip;a single administration of testosterone to young females leads to a significant impairment in the ability to infer emotions, intentions and feelings from the eye region of the face [49]. In addition, the same study established that subjects&rsquo; second-to-fourth digit ratio, which is thought to be a marker of prenatal testosterone exposure, is largely able to predict this effect&hellip;In line with this are findings of decreased trustworthiness ratings of facial photographs in subjects who received a single dose of testosterone [51]. Crucially, this effect was driven most strongly by those who trusted easily, suggesting that testosterone adaptively increases social vigilance in these trusting individuals to better prepare them for competition over status and valued resources</p>\n</blockquote>\n<p>(The jokes about women and men almost make themselves.)</p>\n<p>Not all of these changes are what one would naively expect (see previously about the &lsquo;folk theory&rsquo; of testosterone):</p>\n<blockquote>\n<p>one acute dose of testosterone in women increased the fairness of proposers&rsquo; bargaining offers in an ultimatum game [13] (Figure 3). An important motive driving proposer behavior is to avoid the rejection of the offer. Thus, if testosterone increases the concern for status, subjects who received testosterone might have perceived a rejection as more aversive, inducing them to make fairer offers&hellip;Another study [57] found that testosterone administration prior to an ultimatum game resulted in decreased generosity in a sample of healthy males if repeated measures were not controlled for. The results are insignificant, however, if the fact that the same subject participated in the ultimatum game several time is correctly controlled for statistically. Moreover, a recent study suggests that a low second-to-fourth digit ratio (high prenatal testosterone exposure) is associated with unfair proposer offers if subjects had previously received an unfair offer when in the responder role [58]. Many possible spill-over effects can thus occur in a within-subject design such as that used in [57], where subjects repeatedly play as a proposer and a responder, rendering the interpretation of the results difficult.</p>\n</blockquote>\n<p>I found interesting the material starting page 267, &ldquo;Neurobiological mechanisms underlying the role of testosterone in social status hierarchies&rdquo; (due to my own musings about the possible effects of masturbation went that it might be misinterpreted as reproductive &lsquo;success&rsquo; which reduces risk-taking or activity in general):</p>\n<blockquote>\n<p>Maintaining a high status position requires an increased sensitivity for aversive events and impending social threats, particularly those that challenge the high social status of an individual. As we show below, testosterone appears to be able to influence such processes; in particular, it appears to confer high motivational drive, low fearfulness and high stress-resilience, either directly or via interactions with other hormones and neurotransmitter systems.</p>\n</blockquote>\n<p>Fear &amp; stress:</p>\n<blockquote>\n<p>Among healthy young men, the blood oxygen level-dependent (BOLD) response in the amygdala to fearful and angry faces co-varies positively with individual differences in serum testosterone concentrations ([63,64], but see [65]). Exogenous testosterone has been shown to activate the amygdala in young women viewing angry facial expressions [66] (Figure 4). A mechanism underlying these observations might be that testosterone induces a functional decoupling between OFC and amygdala activity [67,68]&hellip;In humans, single acute doses of testosterone have been shown to reduce subconscious fear (Figure 5) and fear-potentiated startle [44,89].</p>\n<p>&hellip;In face-to-face interactions, individuals are assumed to compete for status in fairly well-defined contests, each trying to &lsquo;outstress&rsquo; the other with verbal and facial cues, and the fact that low-ranked members show more stress symptoms than higher-ranked members during mutual interaction is a common feature of status hierarchies [40]. Stress probably also plays an important role in anonymous competition. Hence, stress resilience might enable an individual to cope with a challenge adaptively. Studies in animals have confirmed that testosterone downregulates the hypothalamic-pituitary-adrenal stress response [90]. It has also been shown to attenuate the sympathetically mediated stress response to aversive stimuli in humans [91].</p>\n</blockquote>\n<p>Motivation &amp; learning:</p>\n<blockquote>\n<p>Reward-based reinforcement effects in animals have been observed within short time periods (30 min) after systemic administration of testosterone [79], suggesting that a testosterone surge following a status-relevant social stimulus might reinforces any behavior that led to that testosterone response in the first place. In humans, patients who are hypogonadal (testosterone levels too low) show apathy and lack of motivation [80], whereas testosterone administration in healthy subjects induces motivation to act [81] and upregulates activity in the ventral striatum [82]</p>\n</blockquote>\n<p>Summary of foregoing:</p>\n<blockquote>\n<p>Testosterone administration studies confirm that the hormone also has fear-reducing properties in humans. A further important function of testosterone is its role in motivation; animal models have shown a tight link with the dopaminergic system within striatal areas. Thus, together with the ability to reduce fear and buffer stress responses, testosterone might have a pivotal role in promoting upward movement in a status hierarchy by facilitating the engagement in a competition for status. By contrast, testosterone can promote threat vigilance, which enables an individual to not only detect potential status challenges, but also, as a consequence of, and facilitated through the mechanisms detailed above, act accordingly to defend its high status position. These effects might be mediated by the amygdala</p>\n</blockquote>\n<h2 id=\"references\"><a href=\"#TOC\"><span class=\"header-section-number\">3</span> References</a></h2>\n<ul>\n<li>01: Mazur, A. and Booth, A. (1998) Testosterone and dominance in men. Behav. Brain Sci. 21, 353&ndash;363 discussion 363&ndash;397</li>\n<li>03: Beeman, E.A. (1947) The relation of the interval between castration and 1st encounter to the aggressive behavior of mice. Anat. Rec. 99, 570&ndash;571</li>\n<li>08: Dabbs, J.M. et al. (1995) Testosterone, crime, and misbehavior among 692 male prison-inmates. Pers. Indiv. Differ. 18, 627&ndash;633</li>\n<li>11: Carre, J.M. et al. (2011) The social neuroendocrinology of human aggression. Psychoneuroendocrinology DOI: 10.1016/J.PSYNEUEN. 2011.02.001</li>\n<li>12: Archer, J. et al. (2005) Testosterone and aggression: a reanalysis of Book, Starzyk, and Quinsey&rsquo;s (2001) study. Aggress. Violent Behav. 10, 241&ndash;261</li>\n<li>13: Eisenegger, C. et al. (2010) Prejudice and truth about the effect of testosterone on human bargaining behaviour. Nature 463, 356&ndash;359</li>\n<li>14: Zethraeus, N. et al. (2009) A randomized trial of the effect of estrogen and testosterone on economic behavior. Proc. Natl. Acad. Sci. U.S.A. 106, 6535&ndash;6538</li>\n<li>16: Higley, J.D. et al. (1996) CSF testosterone and 5-HIAA correlate with different types of aggressive behaviors. Biol. Psychiatry 40, 1067&ndash;1082</li>\n<li>19: Vermeersch, H. et al. (2010) Gender ideology, same-sex peer group affiliation and the relationship between testosterone and dominance in adolescent boys and girls. J. Biosoc. Sci. 42, 463&ndash;475</li>\n<li>20: Rowe, R. et al. (2004) Testosterone, antisocial behavior, and social dominance in boys: pubertal development and biosocial interaction. Biol. Psychiatry 55, 546&ndash;552</li>\n<li>21: Grant, V.J. and France, J.T. (2001) Dominance and testosterone in women. Biol. Psychol. 58, 41&ndash;47</li>\n<li>22: Carre, J.M. et al. (2009) Testosterone responses to competition predict future aggressive behaviour at a cost to reward in men. Psychoneuroendocrinology 34, 561&ndash;570</li>\n<li>23: Stanton, S.J. and Schultheiss, O.C. (2009) The hormonal correlates of implicit power motivation. J. Res. Pers. 43, 942</li>\n<li>24: van Honk, J. et al. (1999) Correlations among salivary testosterone, mood, and selective attention to threat in humans. Horm. Behav. 36, 17&ndash;24</li>\n<li>25: Wirth, M.M. and Schultheiss, O.C. (2007) Basal testosterone moderates responses to anger faces in humans. Physiol. Behav. 90, 496&ndash;505</li>\n<li>26: Sellers, J.G. et al. (2007) Hormones and personality: testosterone as a marker of individual differences. J. Res. Pers. 41, 126&ndash;138</li>\n<li>27: Miller, S.L. and Maner, J.K. (2010) Scent of a woman: men&rsquo;s testosterone responses to olfactory ovulation cues. Psychol. Sci. 21, 276&ndash;283</li>\n<li>28: Roney, J.R. et al. (2007) Rapid endocrine responses of young men to social interactions with young women. Horm. Behav. 52, 326&ndash;333</li>\n<li>29: Lopez, H.H. et al. (2009) Attractive men induce testosterone and cortisol release in women. Horm. Behav. 56, 84&ndash;92</li>\n<li>30: Wobber, V. et al. (2010) Differential changes in steroid hormones before competition in bonobos and chimpanzees. Proc. Natl. Acad. Sci. U.S.A. 107, 12457&ndash;12462</li>\n<li>31: Salvador, A. (2005) Coping with competitive situations in humans. Neurosci. Biobehav. Rev.&nbsp;29, 195&ndash;205</li>\n<li>32: Mehta, P.H. and Josephs, R.A. (2006) Testosterone change after losing predicts the decision to compete again. Horm. Behav. 50, 684&ndash;692</li>\n<li>33: Oliveira, T. et al. (2009) Testosterone responsiveness to winning and losing experiences in female soccer players. Psychoneuroendocrinology 34, 1056&ndash;1064</li>\n<li>34: Josephs, R.A. et al. (2006) The mismatch effect: when testosterone and status are at odds. J. Pers. Soc. Psychol. 90, 999&ndash;1013</li>\n<li>35: Josephs, R.A. et al. (2003) Status, testosterone, and human intellectual performance: stereotype threat as status concern. Psychol. Sci. 14, 158&ndash;163</li>\n<li>36: Newman, M.L. et al. (2005) Testosterone, cognition, and social status. Horm. Behav. 47, 205&ndash;211</li>\n<li>37: Carre, J.M. and Putnam, S.K. (2010) Watching a previous victory produces an increase in testosterone among elite hockey players. Psychoneuroendocrinology 35, 475&ndash;479</li>\n<li>38: Schultheiss, O.C. et al. (2005) Effects of implicit power motivation on men&rsquo;s and women&rsquo;s implicit learning and testosterone changes after social victory or defeat. J. Pers. Soc. Psychol. 88, 174&ndash;188</li>\n<li>40: Mazur, A. (1985) A biosocial model of status in face-to-face primate groups. Soc. Forces 64, 377&ndash;402</li>\n<li>42: van Honk, J. and Schutter, D.J. (2007) Vigilant and avoidant responses to angry facial expressions. In Social Neuroscience: Integrating Biological and Psychological Explanations of Social Behavior (Harmon-Jones, E. and Winkielman, P., eds), pp.&nbsp;197&ndash;223, The Guilford Press</li>\n<li>43: van Honk, J. et al. (2001) A single administration of testosterone induces cardiac accelerative responses to angry faces in healthy young women. Behav. Neurosci. 115, 238&ndash;242</li>\n<li>44: van Honk, J. et al. (2005) Testosterone reduces unconscious fear but not consciously experienced anxiety: implications for the disorders of fear and anxiety. Biol. Psychiatry 58, 218&ndash;225</li>\n<li>48: Hermans, E.J. et al. (2006) Testosterone administration reduces empathetic behavior: a facial mimicry study. Psychoneuroendocrinology 31, 859&ndash;866</li>\n<li>49: Van Honk, J. et al. (2011) Testosterone administration impairs cognitive empathy in women depending on second-to-fourth digit ratio. Proc. Natl. Acad. Sci. U.S.A. DOI: 10.1073/pnas.1011891108</li>\n<li>51: Bos, P.A. et al. (2010) Testosterone decreases trust in socially naive humans. Proc. Natl. Acad. Sci. U.S.A. 107, 9991&ndash;9995</li>\n<li>55: Bos, P.A. et al. (2011) Acute effects of steroid hormones and neuropeptides on human social-emotional behavior: a review of single administration studies. Front. Neuroendocrinol. DOI: 10.1016/j.yfrne.2011.01.002</li>\n<li>56: Archer, J. (2006) Testosterone and human aggression: an evaluation of the challenge hypothesis. Neurosci. Biobehav. Rev.&nbsp;30, 319&ndash;345</li>\n<li>57: Zak, P.J. et al. (2009) Testosterone administration decreases generosity in the ultimatum game. PLoS ONE 4, e8330</li>\n<li>58: Ronay, R. and Galinsky, A.D. (2011) Lex talionis: testosterone and the law of retaliation. J. Exp. Soc. Psychol. 47, 702&ndash;705</li>\n<li>63: Derntl, B. et al. (2009) Amygdala activity to fear and anger in healthy young males is associated with testosterone. Psychoneuroendocrinology 34, 687&ndash;693</li>\n<li>64: Manuck, S.B. et al. (2010) Salivary testosterone and a trinucleotide (CAG) length polymorphism in the androgen receptor gene predict amygdala reactivity in men. Psychoneuroendocrinology 35, 94&ndash;104</li>\n<li>65: Stanton, S.J. et al. (2009) Endogenous testosterone levels are associated with amygdala and ventromedial prefrontal cortex responses to anger faces in men but not women. Biol. Psychol. 81, 118&ndash;122</li>\n<li>66: Hermans, E.J. et al. (2008) Exogenous testosterone enhances responsiveness to social threat in the neural circuitry of social aggression in humans. Biol. Psychiatry 63, 263&ndash;270</li>\n<li>67: van Wingen, G. et al. (2010) Testosterone reduces amygdala-orbitofrontal cortex coupling. Psychoneuroendocrinology 35, 105&ndash;113</li>\n<li>68: Volman, I. et al. (2011) Endogenous testosterone modulates prefrontal-amygdala connectivity during social emotional behavior. Cereb. Cortex DOI: 10.1093/cercor/bhr001</li>\n<li>79: Nyby, J.G. (2008) Reflexive testosterone release: a model system for studying the nongenomic effects of testosterone upon male behavior. Front. Neuroendocrinol. 29, 199&ndash;210</li>\n<li>80: Bhasin, S. et al. (2006) Testosterone therapy in adult men with androgen deficiency syndromes: an endocrine society clinical practice guideline. J. Clin. Endocrinol. Metab. 91, 1995&ndash;2010</li>\n<li>81: Aarts, H. and van Honk, J. (2009) Testosterone and unconscious positive priming increase human motivation separately. Neuroreport 20, 1300&ndash;1303</li>\n<li>82: Hermans, E.J. et al. (2010) Effects of exogenous testosterone on the ventral striatal BOLD response during reward anticipation in healthy women. Neuroimage 52, 277&ndash;283</li>\n<li>89: Hermans, E.J. et al. (2006) A single administration of testosterone reduces fear-potentiated startle in humans. Biol. Psychiatry 59, 872&ndash;874</li>\n<li>90: Viau, V. (2002) Functional cross-talk between the hypothalamic-pituitary-gonadal and -adrenal axes. J. Neuroendocrinol. 14, 506&ndash;513</li>\n<li>91: Hermans, E.J. et al. (2007) Exogenous testosterone attenuates the integrated central stress response in healthy young women. Psychoneuroendocrinology 32, 1052&ndash;1061</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2EFq8dJbxKNzforjM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uRg5Q2vAteDem5b5S", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 46, "extendedScore": null, "score": 9.2e-05, "legacy": true, "legacyId": "10530", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>We\u2019ve discussed signaling and status endlessly on LW; I think this is right up our vein: a 2011 review of research on the connections between famous male hormone testosterone and various forms of social interaction and especially social status, Eisenegger et al\u2019s <a href=\"http://dl.dropbox.com/u/5317066/2011-eisenegger-role-testosterone-social-interaction.pdf\">\u201cThe role of testosterone in social interaction\u201d</a>. (I grabbed this PDF in the short time Elsevier left full-text available, but only now, with some <a href=\"http://www.gwern.net/Modafinil\">modafinil</a>-powered spare time, have gotten around to excerpting it for you guys.)</p>\n<h2 id=\"1_Abstract\"><a href=\"#TOC\"><span class=\"header-section-number\">1</span> Abstract</a></h2>\n<blockquote>\n<p>Although animal researchers established the role of testosterone as a \u2018social hormone\u2019 decades ago, the investigation of its causal influence on human social behaviors has only recently begun. Here, we review and discuss recent studies showing the causal effects of testosterone on social interactions in animals and humans, and outline the basic neurobiological mechanisms that might underlie these effects. Based on these recent findings, we argue that the role of testosterone in human social behavior might be best understood in terms of the search for, and maintenance of, social status.</p>\n</blockquote>\n<h2 id=\"excerpts\"><a id=\"more\"></a><br></h2>\n<h2 id=\"2_Excerpts\"><a href=\"#TOC\"><span class=\"header-section-number\">2</span> Excerpts</a></h2>\n<p>Is testosterone simply aggression promoting (a sort of \u2018roid rage\u2019)?</p>\n<blockquote>\n<p>Early evidence for the role of testosterone in social behavior suggested that it facilitates overt physical aggression (see Glossary) in social contexts. For instance, castrated rodents, which have little, if any, testosterone circulating in their blood, show a near-complete absence of physical fights; however, fights can be fully restored by providing testosterone supplementation to these animals [03]\u2026high testosterone levels in male prisoners have been linked to having a history of rape, murder and armed robbery, and relatively lower levels to a history of theft and drug abuse [08]. A similar pattern was observed in a study of female prison inmates [9]. However, the causality in these studies remains unclear</p>\n</blockquote>\n<p>Probably not:</p>\n<blockquote>\n<p>the existing evidence for a link between aggression and testosterone in humans is relatively weak, but positive [12]. Even if one accepts the fact that reactive aggression can be measured in a controlled laboratory environment, results are similarly inconclusive: recent studies found a positive relationship between baseline testosterone levels and laboratory measures of reactive aggression (reviewed in [11]), but others also reported null findings (in larger samples) [13]. Most importantly, however, a causal role for testosterone in forms of reactive aggression could not be confirmed, as neither long-term nor acute administration of testosterone had an effect [13,14].</p>\n</blockquote>\n<p>This may come as a surprise:</p>\n<blockquote>\n<p>Folk wisdom holds that testosterone causes antisocial, egoistic, or even aggressive behaviors in humans. However, the correlational studies discussed above already suggest that this simple folk view probably requires revision [34,56]. A recent placebo-controlled testosterone administration study found support for the idea that the testosterone-aggression link might be based upon \u2018folk\u2019 views: individuals given placebo who believed they had been given testosterone showed less fair bargaining offers compared with those who believed that they had received placebo, thus confirming people\u2019s stereotypes about the behavioral effects of testosterone.</p>\n</blockquote>\n<p>The null findings may be due to a possible confounding effect of homeostasis, but that wouldn\u2019t cover the null on acute administration:</p>\n<blockquote>\n<p>The first study to use a causal testosterone administration procedure in an experimental economic setting did not find any effects on several economic social interactions [14]. Because the study used long-term administration of testosterone, this null finding might be due to secondary feedback effects on the neuroendocrine axis (i.e.&nbsp;suppression of endogenous testosterone production owing to chronic administration). In general, acute administration shows greater reliability in the production of both behavioral and neurophysiological effects (reviewed in [55]).</p>\n</blockquote>\n<p>\u2018Dominant\u2019 looks like a better perspective than \u2018aggressive\u2019:</p>\n<blockquote>\n<p>rhesus monkeys with high testosterone levels use stares, threats and displacements, rather than overtly aggressive interactions, to ascertain high social status [16]\u2026[saliva] measurements of testosterone at a single time-point correlate positively with high dominance in both adolescents [19,20] and adults [21,22]. In addition, salivary testosterone levels correlate with implicit measures of power motivation [23] and increased vigilance for status threats [24,25]. As a result of these relationships, and the moderate stability of testosterone levels over time, some have suggested that baseline testosterone levels reflect a personality trait [26]</p>\n<p>men show a larger increase in testosterone when exposed to the scent of an ovulating woman compared with that of a non-ovulating woman or a control [27]. Apart from sexual social stimuli, which are reliable inductors of a testosterone response [28,29], social interactions outside a direct reproductive context have also been shown to induce a testosterone response [01]. In particular, testosterone levels rise within minutes in anticipation of both physical and non-physical competitive situations; for example, dyadic food competition in chimpanzees [30], or tennis, chess or domino tournaments in humans (reviewed in [31]). Testosterone also reacts to contest outcomes [32], and not just to anticipation: for instance, stock traders show higher testosterone levels if their daily profits are above average, and winners of soccer matches show higher testosterone levels than do the losers [33]\u2026.causal manipulation of social context (e.g.&nbsp;rigged contests) confirms a causal effect of winning situations on testosterone levels (e.g. [34\u201338]). These effects can be large; for example, merely watching oneself win a competitive interaction on video produces a 40% testosterone surge from baseline [37].</p>\n</blockquote>\n<p>This interest in dominance leads to mental changes (I am reminded of self-deception):</p>\n<blockquote>\n<p>individuals who generally have higher scores on self-reported dominance and higher basal levels of testosterone show vigilant responses to angry facial expressions (reviewed in [42]). Furthermore, exogenous administration of testosterone increases the sympathetic heart-rate response to angry, but not to happy facial expressions [43] (Figure 2). Although this could theoretically also reflect autonomic arousal as part of a fear response, testosterone has been shown to reduce fear [44], suggesting that dominant people perceive an angry face as a challenge\u2026.a recent testosterone administration study has shown that facial mimicry [\u201ca precursor of empathy-related processes occurring automatically\u201d] in response to emotional facial expressions is relatively suppressed after a single dose of testosterone [48]\u2026a single administration of testosterone to young females leads to a significant impairment in the ability to infer emotions, intentions and feelings from the eye region of the face [49]. In addition, the same study established that subjects\u2019 second-to-fourth digit ratio, which is thought to be a marker of prenatal testosterone exposure, is largely able to predict this effect\u2026In line with this are findings of decreased trustworthiness ratings of facial photographs in subjects who received a single dose of testosterone [51]. Crucially, this effect was driven most strongly by those who trusted easily, suggesting that testosterone adaptively increases social vigilance in these trusting individuals to better prepare them for competition over status and valued resources</p>\n</blockquote>\n<p>(The jokes about women and men almost make themselves.)</p>\n<p>Not all of these changes are what one would naively expect (see previously about the \u2018folk theory\u2019 of testosterone):</p>\n<blockquote>\n<p>one acute dose of testosterone in women increased the fairness of proposers\u2019 bargaining offers in an ultimatum game [13] (Figure 3). An important motive driving proposer behavior is to avoid the rejection of the offer. Thus, if testosterone increases the concern for status, subjects who received testosterone might have perceived a rejection as more aversive, inducing them to make fairer offers\u2026Another study [57] found that testosterone administration prior to an ultimatum game resulted in decreased generosity in a sample of healthy males if repeated measures were not controlled for. The results are insignificant, however, if the fact that the same subject participated in the ultimatum game several time is correctly controlled for statistically. Moreover, a recent study suggests that a low second-to-fourth digit ratio (high prenatal testosterone exposure) is associated with unfair proposer offers if subjects had previously received an unfair offer when in the responder role [58]. Many possible spill-over effects can thus occur in a within-subject design such as that used in [57], where subjects repeatedly play as a proposer and a responder, rendering the interpretation of the results difficult.</p>\n</blockquote>\n<p>I found interesting the material starting page 267, \u201cNeurobiological mechanisms underlying the role of testosterone in social status hierarchies\u201d (due to my own musings about the possible effects of masturbation went that it might be misinterpreted as reproductive \u2018success\u2019 which reduces risk-taking or activity in general):</p>\n<blockquote>\n<p>Maintaining a high status position requires an increased sensitivity for aversive events and impending social threats, particularly those that challenge the high social status of an individual. As we show below, testosterone appears to be able to influence such processes; in particular, it appears to confer high motivational drive, low fearfulness and high stress-resilience, either directly or via interactions with other hormones and neurotransmitter systems.</p>\n</blockquote>\n<p>Fear &amp; stress:</p>\n<blockquote>\n<p>Among healthy young men, the blood oxygen level-dependent (BOLD) response in the amygdala to fearful and angry faces co-varies positively with individual differences in serum testosterone concentrations ([63,64], but see [65]). Exogenous testosterone has been shown to activate the amygdala in young women viewing angry facial expressions [66] (Figure 4). A mechanism underlying these observations might be that testosterone induces a functional decoupling between OFC and amygdala activity [67,68]\u2026In humans, single acute doses of testosterone have been shown to reduce subconscious fear (Figure 5) and fear-potentiated startle [44,89].</p>\n<p>\u2026In face-to-face interactions, individuals are assumed to compete for status in fairly well-defined contests, each trying to \u2018outstress\u2019 the other with verbal and facial cues, and the fact that low-ranked members show more stress symptoms than higher-ranked members during mutual interaction is a common feature of status hierarchies [40]. Stress probably also plays an important role in anonymous competition. Hence, stress resilience might enable an individual to cope with a challenge adaptively. Studies in animals have confirmed that testosterone downregulates the hypothalamic-pituitary-adrenal stress response [90]. It has also been shown to attenuate the sympathetically mediated stress response to aversive stimuli in humans [91].</p>\n</blockquote>\n<p>Motivation &amp; learning:</p>\n<blockquote>\n<p>Reward-based reinforcement effects in animals have been observed within short time periods (30 min) after systemic administration of testosterone [79], suggesting that a testosterone surge following a status-relevant social stimulus might reinforces any behavior that led to that testosterone response in the first place. In humans, patients who are hypogonadal (testosterone levels too low) show apathy and lack of motivation [80], whereas testosterone administration in healthy subjects induces motivation to act [81] and upregulates activity in the ventral striatum [82]</p>\n</blockquote>\n<p>Summary of foregoing:</p>\n<blockquote>\n<p>Testosterone administration studies confirm that the hormone also has fear-reducing properties in humans. A further important function of testosterone is its role in motivation; animal models have shown a tight link with the dopaminergic system within striatal areas. Thus, together with the ability to reduce fear and buffer stress responses, testosterone might have a pivotal role in promoting upward movement in a status hierarchy by facilitating the engagement in a competition for status. By contrast, testosterone can promote threat vigilance, which enables an individual to not only detect potential status challenges, but also, as a consequence of, and facilitated through the mechanisms detailed above, act accordingly to defend its high status position. These effects might be mediated by the amygdala</p>\n</blockquote>\n<h2 id=\"3_References\"><a href=\"#TOC\"><span class=\"header-section-number\">3</span> References</a></h2>\n<ul>\n<li>01: Mazur, A. and Booth, A. (1998) Testosterone and dominance in men. Behav. Brain Sci. 21, 353\u2013363 discussion 363\u2013397</li>\n<li>03: Beeman, E.A. (1947) The relation of the interval between castration and 1st encounter to the aggressive behavior of mice. Anat. Rec. 99, 570\u2013571</li>\n<li>08: Dabbs, J.M. et al. (1995) Testosterone, crime, and misbehavior among 692 male prison-inmates. Pers. Indiv. Differ. 18, 627\u2013633</li>\n<li>11: Carre, J.M. et al. (2011) The social neuroendocrinology of human aggression. Psychoneuroendocrinology DOI: 10.1016/J.PSYNEUEN. 2011.02.001</li>\n<li>12: Archer, J. et al. (2005) Testosterone and aggression: a reanalysis of Book, Starzyk, and Quinsey\u2019s (2001) study. Aggress. Violent Behav. 10, 241\u2013261</li>\n<li>13: Eisenegger, C. et al. (2010) Prejudice and truth about the effect of testosterone on human bargaining behaviour. Nature 463, 356\u2013359</li>\n<li>14: Zethraeus, N. et al. (2009) A randomized trial of the effect of estrogen and testosterone on economic behavior. Proc. Natl. Acad. Sci. U.S.A. 106, 6535\u20136538</li>\n<li>16: Higley, J.D. et al. (1996) CSF testosterone and 5-HIAA correlate with different types of aggressive behaviors. Biol. Psychiatry 40, 1067\u20131082</li>\n<li>19: Vermeersch, H. et al. (2010) Gender ideology, same-sex peer group affiliation and the relationship between testosterone and dominance in adolescent boys and girls. J. Biosoc. Sci. 42, 463\u2013475</li>\n<li>20: Rowe, R. et al. (2004) Testosterone, antisocial behavior, and social dominance in boys: pubertal development and biosocial interaction. Biol. Psychiatry 55, 546\u2013552</li>\n<li>21: Grant, V.J. and France, J.T. (2001) Dominance and testosterone in women. Biol. Psychol. 58, 41\u201347</li>\n<li>22: Carre, J.M. et al. (2009) Testosterone responses to competition predict future aggressive behaviour at a cost to reward in men. Psychoneuroendocrinology 34, 561\u2013570</li>\n<li>23: Stanton, S.J. and Schultheiss, O.C. (2009) The hormonal correlates of implicit power motivation. J. Res. Pers. 43, 942</li>\n<li>24: van Honk, J. et al. (1999) Correlations among salivary testosterone, mood, and selective attention to threat in humans. Horm. Behav. 36, 17\u201324</li>\n<li>25: Wirth, M.M. and Schultheiss, O.C. (2007) Basal testosterone moderates responses to anger faces in humans. Physiol. Behav. 90, 496\u2013505</li>\n<li>26: Sellers, J.G. et al. (2007) Hormones and personality: testosterone as a marker of individual differences. J. Res. Pers. 41, 126\u2013138</li>\n<li>27: Miller, S.L. and Maner, J.K. (2010) Scent of a woman: men\u2019s testosterone responses to olfactory ovulation cues. Psychol. Sci. 21, 276\u2013283</li>\n<li>28: Roney, J.R. et al. (2007) Rapid endocrine responses of young men to social interactions with young women. Horm. Behav. 52, 326\u2013333</li>\n<li>29: Lopez, H.H. et al. (2009) Attractive men induce testosterone and cortisol release in women. Horm. Behav. 56, 84\u201392</li>\n<li>30: Wobber, V. et al. (2010) Differential changes in steroid hormones before competition in bonobos and chimpanzees. Proc. Natl. Acad. Sci. U.S.A. 107, 12457\u201312462</li>\n<li>31: Salvador, A. (2005) Coping with competitive situations in humans. Neurosci. Biobehav. Rev.&nbsp;29, 195\u2013205</li>\n<li>32: Mehta, P.H. and Josephs, R.A. (2006) Testosterone change after losing predicts the decision to compete again. Horm. Behav. 50, 684\u2013692</li>\n<li>33: Oliveira, T. et al. (2009) Testosterone responsiveness to winning and losing experiences in female soccer players. Psychoneuroendocrinology 34, 1056\u20131064</li>\n<li>34: Josephs, R.A. et al. (2006) The mismatch effect: when testosterone and status are at odds. J. Pers. Soc. Psychol. 90, 999\u20131013</li>\n<li>35: Josephs, R.A. et al. (2003) Status, testosterone, and human intellectual performance: stereotype threat as status concern. Psychol. Sci. 14, 158\u2013163</li>\n<li>36: Newman, M.L. et al. (2005) Testosterone, cognition, and social status. Horm. Behav. 47, 205\u2013211</li>\n<li>37: Carre, J.M. and Putnam, S.K. (2010) Watching a previous victory produces an increase in testosterone among elite hockey players. Psychoneuroendocrinology 35, 475\u2013479</li>\n<li>38: Schultheiss, O.C. et al. (2005) Effects of implicit power motivation on men\u2019s and women\u2019s implicit learning and testosterone changes after social victory or defeat. J. Pers. Soc. Psychol. 88, 174\u2013188</li>\n<li>40: Mazur, A. (1985) A biosocial model of status in face-to-face primate groups. Soc. Forces 64, 377\u2013402</li>\n<li>42: van Honk, J. and Schutter, D.J. (2007) Vigilant and avoidant responses to angry facial expressions. In Social Neuroscience: Integrating Biological and Psychological Explanations of Social Behavior (Harmon-Jones, E. and Winkielman, P., eds), pp.&nbsp;197\u2013223, The Guilford Press</li>\n<li>43: van Honk, J. et al. (2001) A single administration of testosterone induces cardiac accelerative responses to angry faces in healthy young women. Behav. Neurosci. 115, 238\u2013242</li>\n<li>44: van Honk, J. et al. (2005) Testosterone reduces unconscious fear but not consciously experienced anxiety: implications for the disorders of fear and anxiety. Biol. Psychiatry 58, 218\u2013225</li>\n<li>48: Hermans, E.J. et al. (2006) Testosterone administration reduces empathetic behavior: a facial mimicry study. Psychoneuroendocrinology 31, 859\u2013866</li>\n<li>49: Van Honk, J. et al. (2011) Testosterone administration impairs cognitive empathy in women depending on second-to-fourth digit ratio. Proc. Natl. Acad. Sci. U.S.A. DOI: 10.1073/pnas.1011891108</li>\n<li>51: Bos, P.A. et al. (2010) Testosterone decreases trust in socially naive humans. Proc. Natl. Acad. Sci. U.S.A. 107, 9991\u20139995</li>\n<li>55: Bos, P.A. et al. (2011) Acute effects of steroid hormones and neuropeptides on human social-emotional behavior: a review of single administration studies. Front. Neuroendocrinol. DOI: 10.1016/j.yfrne.2011.01.002</li>\n<li>56: Archer, J. (2006) Testosterone and human aggression: an evaluation of the challenge hypothesis. Neurosci. Biobehav. Rev.&nbsp;30, 319\u2013345</li>\n<li>57: Zak, P.J. et al. (2009) Testosterone administration decreases generosity in the ultimatum game. PLoS ONE 4, e8330</li>\n<li>58: Ronay, R. and Galinsky, A.D. (2011) Lex talionis: testosterone and the law of retaliation. J. Exp. Soc. Psychol. 47, 702\u2013705</li>\n<li>63: Derntl, B. et al. (2009) Amygdala activity to fear and anger in healthy young males is associated with testosterone. Psychoneuroendocrinology 34, 687\u2013693</li>\n<li>64: Manuck, S.B. et al. (2010) Salivary testosterone and a trinucleotide (CAG) length polymorphism in the androgen receptor gene predict amygdala reactivity in men. Psychoneuroendocrinology 35, 94\u2013104</li>\n<li>65: Stanton, S.J. et al. (2009) Endogenous testosterone levels are associated with amygdala and ventromedial prefrontal cortex responses to anger faces in men but not women. Biol. Psychol. 81, 118\u2013122</li>\n<li>66: Hermans, E.J. et al. (2008) Exogenous testosterone enhances responsiveness to social threat in the neural circuitry of social aggression in humans. Biol. Psychiatry 63, 263\u2013270</li>\n<li>67: van Wingen, G. et al. (2010) Testosterone reduces amygdala-orbitofrontal cortex coupling. Psychoneuroendocrinology 35, 105\u2013113</li>\n<li>68: Volman, I. et al. (2011) Endogenous testosterone modulates prefrontal-amygdala connectivity during social emotional behavior. Cereb. Cortex DOI: 10.1093/cercor/bhr001</li>\n<li>79: Nyby, J.G. (2008) Reflexive testosterone release: a model system for studying the nongenomic effects of testosterone upon male behavior. Front. Neuroendocrinol. 29, 199\u2013210</li>\n<li>80: Bhasin, S. et al. (2006) Testosterone therapy in adult men with androgen deficiency syndromes: an endocrine society clinical practice guideline. J. Clin. Endocrinol. Metab. 91, 1995\u20132010</li>\n<li>81: Aarts, H. and van Honk, J. (2009) Testosterone and unconscious positive priming increase human motivation separately. Neuroreport 20, 1300\u20131303</li>\n<li>82: Hermans, E.J. et al. (2010) Effects of exogenous testosterone on the ventral striatal BOLD response during reward anticipation in healthy women. Neuroimage 52, 277\u2013283</li>\n<li>89: Hermans, E.J. et al. (2006) A single administration of testosterone reduces fear-potentiated startle in humans. Biol. Psychiatry 59, 872\u2013874</li>\n<li>90: Viau, V. (2002) Functional cross-talk between the hypothalamic-pituitary-gonadal and -adrenal axes. J. Neuroendocrinol. 14, 506\u2013513</li>\n<li>91: Hermans, E.J. et al. (2007) Exogenous testosterone attenuates the integrated central stress response in healthy young women. Psychoneuroendocrinology 32, 1052\u20131061</li>\n</ul>", "sections": [{"title": "1 Abstract", "anchor": "1_Abstract", "level": 1}, {"title": "2 Excerpts", "anchor": "2_Excerpts", "level": 1}, {"title": "3 References", "anchor": "3_References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "39 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 39, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T16:10:07.553Z", "modifiedAt": null, "url": null, "title": "Amanda Knox: post mortem", "slug": "amanda-knox-post-mortem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:55.636Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Jx4gGbPi7GuydwvzB/amanda-knox-post-mortem", "pageUrlRelative": "/posts/Jx4gGbPi7GuydwvzB/amanda-knox-post-mortem", "linkUrl": "https://www.lesswrong.com/posts/Jx4gGbPi7GuydwvzB/amanda-knox-post-mortem", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Amanda%20Knox%3A%20post%20mortem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAmanda%20Knox%3A%20post%20mortem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJx4gGbPi7GuydwvzB%2Famanda-knox-post-mortem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Amanda%20Knox%3A%20post%20mortem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJx4gGbPi7GuydwvzB%2Famanda-knox-post-mortem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJx4gGbPi7GuydwvzB%2Famanda-knox-post-mortem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 548, "htmlBody": "<p>Continuing my interest in tracking <a href=\"/lw/7z9/1001_predictionbook_nights/\">real-world predictions</a>, I notice that the <a href=\"/r/discussion/lw/7x3/knox_and_sollecito_freed/\">recent acquittal of Knox &amp; Sollecito</a> offers an interesting opportunity - specifically, many LessWrongers gave probabilities for guilt back in 2009 in <a href=\"/user/komponisto/\">komponisto</a>&rsquo;s 2 articles:</p>\n<ul>\n<li><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/\">&ldquo;You Be the Jury: Survey on a Current Event&rdquo;</a></li>\n<li><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/\">&ldquo;The Amanda Knox Test: How an Hour on the Internet Beats a Year in the Courtroom&rdquo;</a></li>\n</ul>\n<p>Both were interesting exercises, and it&rsquo;s time to do a followup. Specifically, there are at least 3 new pieces of evidence to consider:</p>\n<ol style=\"list-style-type: decimal\">\n<li>the failure of any damning or especially relevant evidence to surface in the ~2 years since (see also: the <a href=\"/lw/5hq/an_inflection_point_for_probability_estimates_of/428t\">hope function</a>)</li>\n<li>the independent <a href=\"https://knoxdnareport.wordpress.com/\">experts&rsquo; report</a> on the DNA evidence</li>\n<li>the freeing of Knox &amp; Sollecito, and continued imprisonment of Rudy Guede (with reduced sentence)</li>\n</ol>\n<p>Point 2 particularly struck me (the press attributes much of the acquittal to the expert report, an acquittal I had <a href=\"http://predictionbook.com/predictions/1804\">not expected to succeed</a>), but other people may find the other 2 points or unmentioned news more weighty.</p>\n<p><a id=\"more\"></a></p>\n<h1 id=\"probabilities\"><a href=\"#TOC\"><span class=\"header-section-number\">2</span> Probabilities</a></h1>\n<p>I was curious how the consensus has changed, and so, in some <a href=\"http://www.gwern.net/Modafinil\">spare time</a>, I summoned all the <a href=\"http://www.gwern.net/About#fn35\">Conscientiousness</a> I could and compiled the following list of 54 entries based on those 2 articles&rsquo; comments (sometimes inferring specific probabilities and possibly missing probabilities given in hidden subthreads), where people listed probabilities for Knox&rsquo;s guilt, Sollecito&rsquo;s guilt, and Guede&rsquo;s guilt:</p>\n<table border=\"0\">\n<thead> \n<tr class=\"header\">\n<th align=\"left\">Knox</th> <th align=\"center\">Sollecito</th> <th align=\"center\">Guede</th> <th align=\"right\">LWer</th>\n</tr>\n</thead> \n<tbody>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.70</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf4\">badger</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdb\">mattnewport</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.25</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bd8\">AngryParsley</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdd\">tut</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdj\">bentarm</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.85</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.20</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdk\">bgrah449</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bj2\">kodos96</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdt\">Daniel_Burfoot</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.40</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be1\">nerzhin</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.45</td>\n<td align=\"center\">.45</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be3\">Matt_Simpson</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.33</td>\n<td align=\"center\">.33</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beb\">Cyan</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bed\">jimmy</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beg\">Psychohistorian</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.40</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bek\">Threads</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.80</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bes\">Morendil</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.15</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beu\">Eliezer_Yudkowsky</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.35</td>\n<td align=\"center\">.98</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bez\">LauraABJ</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.10</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf0\">curious</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.96</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf1\">jpet</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.06</td>\n<td align=\"center\">.06</td>\n<td align=\"center\">.70</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf8\">saliency</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.80</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfb\">Mario</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfh\">Yvain</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.70</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfs\">Shalmanese</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfy\">gelisam</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bop\">Mononofu</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bg5\">lordweiner27</a> (<a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1bv5\">changed mind</a>)</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhy\">GreenRoot</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgb\">dilaudid</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.13</td>\n<td align=\"center\">.15</td>\n<td align=\"center\">.97</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgf\">Jack</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgm\">wedrifid</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgq\">Nanani</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.35</td>\n<td align=\"center\">.35</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhk\">imaxwell</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhu\">jenmarie</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.25</td>\n<td align=\"center\">.25</td>\n<td align=\"center\">.75</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1boz\">Jawaka</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.41</td>\n<td align=\"center\">.38</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bi8\">magfrump</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.40</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bie\">gwern</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.08</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bih\">loqi</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.25</td>\n<td align=\"center\">.25</td>\n<td align=\"center\">.50</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bij\">JamesAndrix</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.85</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bk4\">Unknowns</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.35</td>\n<td align=\"center\">.35</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bm5\">Sebastian_Hagen</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bnt\">brazil84</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.30</td>\n<td align=\"center\">.30</td>\n<td align=\"center\">.40</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bob\">ChrisHibbert</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.02</td>\n<td align=\"center\">.02</td>\n<td align=\"center\">.98</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bs1\">wnoise</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bzm\">John_Maxwell_IV</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.10</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1c2k\">k3nt</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/2rph\">Sinai</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.00</td>\n<td align=\"center\">.00</td>\n<td align=\"center\">1.0</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/3935\">KayPea</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.00</td>\n<td align=\"center\">.00</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/39co\">MerleRideout</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.15</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.80</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/3ave\">TheRev</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/\">komponisto</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.30</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1bxh\">pete22</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1dfi\">SforSingularity</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.00</td>\n<td align=\"center\">.00</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1nlk\">AnnaGilmour</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1t07\">Seth_Goldin</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.60</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/3mb0\">bigjeff5</a></td>\n</tr>\n</tbody>\n</table>\n<p>It&rsquo;s interesting how many people assign a high-probability to Knox being guilty; I had remembered LW as being a hive of Amanda fans, but either I&rsquo;m succumbing to <a href=\"http://en.wikipedia.org/wiki/Hindsight_bias\">hindsight bias</a> or people updated significantly after those articles. (For example, Eliezer says .15 is too high, but doesn&rsquo;t seem otherwise especially convinced; and later one reads in <a href=\"http://www.fanfiction.net/s/5782108/49/Harry_Potter_and_the_Methods_of_Rationality\"><em>Methods of Rationality</em></a> that \"[Hagrid] is the most blatantly innocent bystander to be convicted by the magical British legal system since Grindelwald's Confunding of Neville Chamberlain was pinned on Amanda Knox.\")</p>\n<p>EDIT: <a href=\"/lw/84j/amanda_knox_post_mortem/52be\">Jack</a> graphed the probability against karma:</p>\n<p><img src=\"http://i.imgur.com/VyZNn.png\" alt=\"\" width=\"600\" height=\"371\" /></p>\n<h2 id=\"outliers\"><a href=\"#TOC\"><span class=\"header-section-number\">2.1</span> Outliers</a></h2>\n<p>If we look just at &gt;41% (chosen to keep contacts manageable), we find 12 entries out of 54:</p>\n<table border=\"0\">\n<thead> \n<tr class=\"header\">\n<th align=\"left\">Knox</th> <th align=\"center\">Sollecito</th> <th align=\"center\">Guede</th> <th align=\"right\">LWer</th>\n</tr>\n</thead> \n<tbody>\n<tr class=\"odd\">\n<td align=\"left\">.45</td>\n<td align=\"center\">.45</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be3\">Matt_Simpson</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bzm\">John_Maxwell_IV</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.80</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bes\">Morendil</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bed\">jimmy</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhy\">GreenRoot</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.60</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/3mb0\">bigjeff5</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.70</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"center\">&mdash;</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfs\">Shalmanese</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.80</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfb\">Mario</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.85</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.20</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdk\">bgrah449</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.85</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bk4\">Unknowns</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bg5\">lordweiner27</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bnt\">brazil84</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgb\">dilaudid</a></td>\n</tr>\n</tbody>\n</table>\n<p>I have messaged each of them, asking them to comment here, describing if and how they have since updated, and any other thoughts they might have. (I have also messaged the first 12 commenters or so, chronologically, with &lt;41% confidence in Knox&rsquo;s guilt, with the same message.) The commenters:</p>\n<p><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bd8\">AngryParsley</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beb\">Cyan</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdt\">Daniel_Burfoot</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beu\">Eliezer_Yudkowsky</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhy\">GreenRoot</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bzm\">John_Maxwell_IV</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bez\">LauraABJ</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfb\">Mario</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be3\">Matt_Simpson</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bes\">Morendil</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beg\">Psychohistorian</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfs\">Shalmanese</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bek\">Threads</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bk4\">Unknowns</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf4\">badger</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdj\">bentarm</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdk\">bgrah449</a> / <a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/3mb0\">bigjeff5</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bnt\">brazil84</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgb\">dilaudid</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bed\">jimmy</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bj2\">kodos96</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bg5\">lordweiner27</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdb\">mattnewport</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be1\">nerzhin</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdd\">tut</a></p>\n<p>I look forward to seeing their retrospectives, or indeed, <em>anyone</em>'s retrospectives on the matter.</p>\n<dl>\n<blockquote><dd>Allknowing and most merciful Bayes;</dd><dd>We have erred, and strayed from thy ways like biased sheep.</dd><dd>We have followed too much the devices and desires of our own hearts.</dd><dd>We have offended against thy axiomatic laws.</dd><dd>We have left undone those updates which we ought to have done;</dd><dd>And we have done those updates which we ought not to have done;</dd><dd>And there is no calibration in us.</dd><dd>But thou, O Bayes, have mercy upon us, miserable wannabes.</dd><dd>Spare thou them, O Bayes, who confess their faults.</dd></blockquote>\n</dl>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zcvsZQWJBFK6SxK4K": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Jx4gGbPi7GuydwvzB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 39, "extendedScore": null, "score": 8.1e-05, "legacy": true, "legacyId": "10531", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Continuing my interest in tracking <a href=\"/lw/7z9/1001_predictionbook_nights/\">real-world predictions</a>, I notice that the <a href=\"/r/discussion/lw/7x3/knox_and_sollecito_freed/\">recent acquittal of Knox &amp; Sollecito</a> offers an interesting opportunity - specifically, many LessWrongers gave probabilities for guilt back in 2009 in <a href=\"/user/komponisto/\">komponisto</a>\u2019s 2 articles:</p>\n<ul>\n<li><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/\">\u201cYou Be the Jury: Survey on a Current Event\u201d</a></li>\n<li><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/\">\u201cThe Amanda Knox Test: How an Hour on the Internet Beats a Year in the Courtroom\u201d</a></li>\n</ul>\n<p>Both were interesting exercises, and it\u2019s time to do a followup. Specifically, there are at least 3 new pieces of evidence to consider:</p>\n<ol style=\"list-style-type: decimal\">\n<li>the failure of any damning or especially relevant evidence to surface in the ~2 years since (see also: the <a href=\"/lw/5hq/an_inflection_point_for_probability_estimates_of/428t\">hope function</a>)</li>\n<li>the independent <a href=\"https://knoxdnareport.wordpress.com/\">experts\u2019 report</a> on the DNA evidence</li>\n<li>the freeing of Knox &amp; Sollecito, and continued imprisonment of Rudy Guede (with reduced sentence)</li>\n</ol>\n<p>Point 2 particularly struck me (the press attributes much of the acquittal to the expert report, an acquittal I had <a href=\"http://predictionbook.com/predictions/1804\">not expected to succeed</a>), but other people may find the other 2 points or unmentioned news more weighty.</p>\n<p><a id=\"more\"></a></p>\n<h1 id=\"2_Probabilities\"><a href=\"#TOC\"><span class=\"header-section-number\">2</span> Probabilities</a></h1>\n<p>I was curious how the consensus has changed, and so, in some <a href=\"http://www.gwern.net/Modafinil\">spare time</a>, I summoned all the <a href=\"http://www.gwern.net/About#fn35\">Conscientiousness</a> I could and compiled the following list of 54 entries based on those 2 articles\u2019 comments (sometimes inferring specific probabilities and possibly missing probabilities given in hidden subthreads), where people listed probabilities for Knox\u2019s guilt, Sollecito\u2019s guilt, and Guede\u2019s guilt:</p>\n<table border=\"0\">\n<thead> \n<tr class=\"header\">\n<th align=\"left\">Knox</th> <th align=\"center\">Sollecito</th> <th align=\"center\">Guede</th> <th align=\"right\">LWer</th>\n</tr>\n</thead> \n<tbody>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.70</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf4\">badger</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdb\">mattnewport</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.25</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bd8\">AngryParsley</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdd\">tut</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdj\">bentarm</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.85</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.20</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdk\">bgrah449</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bj2\">kodos96</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdt\">Daniel_Burfoot</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.40</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be1\">nerzhin</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.45</td>\n<td align=\"center\">.45</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be3\">Matt_Simpson</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.33</td>\n<td align=\"center\">.33</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beb\">Cyan</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bed\">jimmy</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beg\">Psychohistorian</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.40</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bek\">Threads</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.80</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bes\">Morendil</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.15</td>\n<td align=\"center\">\u2014</td>\n<td align=\"center\">\u2014</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beu\">Eliezer_Yudkowsky</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.35</td>\n<td align=\"center\">.98</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bez\">LauraABJ</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.10</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf0\">curious</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.96</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf1\">jpet</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.06</td>\n<td align=\"center\">.06</td>\n<td align=\"center\">.70</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf8\">saliency</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.80</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfb\">Mario</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.20</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfh\">Yvain</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.70</td>\n<td align=\"center\">\u2014</td>\n<td align=\"center\">\u2014</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfs\">Shalmanese</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfy\">gelisam</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bop\">Mononofu</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bg5\">lordweiner27</a> (<a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1bv5\">changed mind</a>)</td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhy\">GreenRoot</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgb\">dilaudid</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.13</td>\n<td align=\"center\">.15</td>\n<td align=\"center\">.97</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgf\">Jack</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgm\">wedrifid</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgq\">Nanani</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.35</td>\n<td align=\"center\">.35</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhk\">imaxwell</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhu\">jenmarie</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.25</td>\n<td align=\"center\">.25</td>\n<td align=\"center\">.75</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1boz\">Jawaka</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.41</td>\n<td align=\"center\">.38</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bi8\">magfrump</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.40</td>\n<td align=\"center\">.20</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bie\">gwern</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.08</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bih\">loqi</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.25</td>\n<td align=\"center\">.25</td>\n<td align=\"center\">.50</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bij\">JamesAndrix</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.85</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bk4\">Unknowns</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.35</td>\n<td align=\"center\">.35</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bm5\">Sebastian_Hagen</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bnt\">brazil84</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.30</td>\n<td align=\"center\">.30</td>\n<td align=\"center\">.40</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bob\">ChrisHibbert</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.02</td>\n<td align=\"center\">.02</td>\n<td align=\"center\">.98</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bs1\">wnoise</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bzm\">John_Maxwell_IV</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.10</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">\u2014</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1c2k\">k3nt</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/2rph\">Sinai</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.00</td>\n<td align=\"center\">.00</td>\n<td align=\"center\">1.0</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/3935\">KayPea</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.00</td>\n<td align=\"center\">.00</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/39co\">MerleRideout</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.15</td>\n<td align=\"center\">.10</td>\n<td align=\"center\">.80</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/3ave\">TheRev</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">.01</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/\">komponisto</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.30</td>\n<td align=\"center\">\u2014</td>\n<td align=\"center\">\u2014</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1bxh\">pete22</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.01</td>\n<td align=\"center\">\u2014</td>\n<td align=\"center\">\u2014</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1dfi\">SforSingularity</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.00</td>\n<td align=\"center\">.00</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1nlk\">AnnaGilmour</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.05</td>\n<td align=\"center\">.05</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/1t07\">Seth_Goldin</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.60</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/3mb0\">bigjeff5</a></td>\n</tr>\n</tbody>\n</table>\n<p>It\u2019s interesting how many people assign a high-probability to Knox being guilty; I had remembered LW as being a hive of Amanda fans, but either I\u2019m succumbing to <a href=\"http://en.wikipedia.org/wiki/Hindsight_bias\">hindsight bias</a> or people updated significantly after those articles. (For example, Eliezer says .15 is too high, but doesn\u2019t seem otherwise especially convinced; and later one reads in <a href=\"http://www.fanfiction.net/s/5782108/49/Harry_Potter_and_the_Methods_of_Rationality\"><em>Methods of Rationality</em></a> that \"[Hagrid] is the most blatantly innocent bystander to be convicted by the magical British legal system since Grindelwald's Confunding of Neville Chamberlain was pinned on Amanda Knox.\")</p>\n<p>EDIT: <a href=\"/lw/84j/amanda_knox_post_mortem/52be\">Jack</a> graphed the probability against karma:</p>\n<p><img src=\"http://i.imgur.com/VyZNn.png\" alt=\"\" width=\"600\" height=\"371\"></p>\n<h2 id=\"2_1_Outliers\"><a href=\"#TOC\"><span class=\"header-section-number\">2.1</span> Outliers</a></h2>\n<p>If we look just at &gt;41% (chosen to keep contacts manageable), we find 12 entries out of 54:</p>\n<table border=\"0\">\n<thead> \n<tr class=\"header\">\n<th align=\"left\">Knox</th> <th align=\"center\">Sollecito</th> <th align=\"center\">Guede</th> <th align=\"right\">LWer</th>\n</tr>\n</thead> \n<tbody>\n<tr class=\"odd\">\n<td align=\"left\">.45</td>\n<td align=\"center\">.45</td>\n<td align=\"center\">.60</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be3\">Matt_Simpson</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.40</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bzm\">John_Maxwell_IV</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.80</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bes\">Morendil</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bed\">jimmy</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.50</td>\n<td align=\"center\">.50</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhy\">GreenRoot</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.60</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/3mb0\">bigjeff5</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.70</td>\n<td align=\"center\">\u2014</td>\n<td align=\"center\">\u2014</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfs\">Shalmanese</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.80</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.95</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfb\">Mario</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.85</td>\n<td align=\"center\">.60</td>\n<td align=\"center\">.20</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdk\">bgrah449</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.85</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bk4\">Unknowns</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bg5\">lordweiner27</a></td>\n</tr>\n<tr class=\"even\">\n<td align=\"left\">.90</td>\n<td align=\"center\">.90</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bnt\">brazil84</a></td>\n</tr>\n<tr class=\"odd\">\n<td align=\"left\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"center\">.99</td>\n<td align=\"right\"><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgb\">dilaudid</a></td>\n</tr>\n</tbody>\n</table>\n<p>I have messaged each of them, asking them to comment here, describing if and how they have since updated, and any other thoughts they might have. (I have also messaged the first 12 commenters or so, chronologically, with &lt;41% confidence in Knox\u2019s guilt, with the same message.) The commenters:</p>\n<p><a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bd8\">AngryParsley</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beb\">Cyan</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdt\">Daniel_Burfoot</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beu\">Eliezer_Yudkowsky</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bhy\">GreenRoot</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bzm\">John_Maxwell_IV</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bez\">LauraABJ</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfb\">Mario</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be3\">Matt_Simpson</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bes\">Morendil</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1beg\">Psychohistorian</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bfs\">Shalmanese</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bek\">Threads</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bk4\">Unknowns</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bf4\">badger</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdj\">bentarm</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdk\">bgrah449</a> / <a href=\"/lw/1j7/the_amanda_knox_test_how_an_hour_on_the_internet/3mb0\">bigjeff5</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bnt\">brazil84</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bgb\">dilaudid</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bed\">jimmy</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bj2\">kodos96</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bg5\">lordweiner27</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdb\">mattnewport</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1be1\">nerzhin</a> / <a href=\"/lw/1ir/you_be_the_jury_survey_on_a_current_event/1bdd\">tut</a></p>\n<p>I look forward to seeing their retrospectives, or indeed, <em>anyone</em>'s retrospectives on the matter.</p>\n<dl>\n<blockquote><dd>Allknowing and most merciful Bayes;</dd><dd>We have erred, and strayed from thy ways like biased sheep.</dd><dd>We have followed too much the devices and desires of our own hearts.</dd><dd>We have offended against thy axiomatic laws.</dd><dd>We have left undone those updates which we ought to have done;</dd><dd>And we have done those updates which we ought not to have done;</dd><dd>And there is no calibration in us.</dd><dd>But thou, O Bayes, have mercy upon us, miserable wannabes.</dd><dd>Spare thou them, O Bayes, who confess their faults.</dd></blockquote>\n</dl>", "sections": [{"title": "2 Probabilities", "anchor": "2_Probabilities", "level": 1}, {"title": "2.1 Outliers", "anchor": "2_1_Outliers", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "484 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 484, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["yE4Fdx4kYmQchBCek", "sA7MtWkdyJHFrDyce", "mkAcXPEJ7RZCJs8ry", "G9dptrW9CJi7wNg3b"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T16:24:04.538Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison Monday Meetup", "slug": "meetup-madison-monday-meetup-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:02.795Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mwTeTfiKsqTLGfCxx/meetup-madison-monday-meetup-0", "pageUrlRelative": "/posts/mwTeTfiKsqTLGfCxx/meetup-madison-monday-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/mwTeTfiKsqTLGfCxx/meetup-madison-monday-meetup-0", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison%20Monday%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%20Monday%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmwTeTfiKsqTLGfCxx%2Fmeetup-madison-monday-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%20Monday%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmwTeTfiKsqTLGfCxx%2Fmeetup-madison-monday-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmwTeTfiKsqTLGfCxx%2Fmeetup-madison-monday-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4c'>Madison Monday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">24 October 2011 06:30:00AM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1831 Monroe St, Madison, WI 53711</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Again, let's meet up at the Barriques on Monroe St.</p>\n\n<p>Among other discussions and games, I intend to run through the \"alternatives procedure\", one of my favorite tricks from the minicamp last summer. It is a simple way to clarify your goals and motivations while seeking ways to be more strategic.</p>\n\n<p>If you're in Madison, sign up on our <a href=\"https://groups.google.com/forum/#!forum/lesswrong-madison\">mailing list</a>.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4c'>Madison Monday Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mwTeTfiKsqTLGfCxx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.869097710940462e-07, "legacy": true, "legacyId": "10532", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison_Monday_Meetup\">Discussion article for the meetup : <a href=\"/meetups/4c\">Madison Monday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">24 October 2011 06:30:00AM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1831 Monroe St, Madison, WI 53711</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Again, let's meet up at the Barriques on Monroe St.</p>\n\n<p>Among other discussions and games, I intend to run through the \"alternatives procedure\", one of my favorite tricks from the minicamp last summer. It is a simple way to clarify your goals and motivations while seeking ways to be more strategic.</p>\n\n<p>If you're in Madison, sign up on our <a href=\"https://groups.google.com/forum/#!forum/lesswrong-madison\">mailing list</a>.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison_Monday_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/4c\">Madison Monday Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison Monday Meetup", "anchor": "Discussion_article_for_the_meetup___Madison_Monday_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Madison Monday Meetup", "anchor": "Discussion_article_for_the_meetup___Madison_Monday_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T16:51:16.096Z", "modifiedAt": null, "url": null, "title": "Meetup : Pittsburgh Meetup: Big Gaming Fun!", "slug": "meetup-pittsburgh-meetup-big-gaming-fun", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kenoubi", "createdAt": "2011-03-12T04:07:00.560Z", "isAdmin": false, "displayName": "Kenoubi"}, "userId": "DgrXt6eQMpunHRDXh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k3yJgA5G5CrMrdR2e/meetup-pittsburgh-meetup-big-gaming-fun", "pageUrlRelative": "/posts/k3yJgA5G5CrMrdR2e/meetup-pittsburgh-meetup-big-gaming-fun", "linkUrl": "https://www.lesswrong.com/posts/k3yJgA5G5CrMrdR2e/meetup-pittsburgh-meetup-big-gaming-fun", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Pittsburgh%20Meetup%3A%20Big%20Gaming%20Fun!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Pittsburgh%20Meetup%3A%20Big%20Gaming%20Fun!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk3yJgA5G5CrMrdR2e%2Fmeetup-pittsburgh-meetup-big-gaming-fun%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Pittsburgh%20Meetup%3A%20Big%20Gaming%20Fun!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk3yJgA5G5CrMrdR2e%2Fmeetup-pittsburgh-meetup-big-gaming-fun", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk3yJgA5G5CrMrdR2e%2Fmeetup-pittsburgh-meetup-big-gaming-fun", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 230, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4d'>Pittsburgh Meetup: Big Gaming Fun!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">25 October 2011 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1324 Wightman St., Pittsburgh, PA 15217</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the third Pittsburgh meetup of the semester, apparently!</p>\n\n<p>I can't go anywhere next week because I'm on call, but I'd love to have you come over to my house and play some board games.  I only have 4 games (Bohnanza, Citadels, Acquire, and Hacker), so please bring anything you'd like to play.  We can order food and go more or less as late as we'd like.  If I get paged I may have to deal with an emergency (from home, using my laptop), but if that doesn't bother you, it doesn't bother me.</p>\n\n<p>Allergy warning: I have a cat.  I can put her upstairs, but if you have a cat allergy you might want to take some meds.  If you decide not to come because you have a severe cat allergy, please tell me, as this will factor into how appropriate a venue I consider my house to be in the future.</p>\n\n<p>RSVP here or by sending me a private message (but don't not show up because you didn't RSVP, I just want a rough idea of the number of attendees).  Ring the bell, knock, or call or text (412) 657-1395 to get in when you get there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4d'>Pittsburgh Meetup: Big Gaming Fun!</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k3yJgA5G5CrMrdR2e", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.869191193368267e-07, "legacy": true, "legacyId": "10533", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh_Meetup__Big_Gaming_Fun_\">Discussion article for the meetup : <a href=\"/meetups/4d\">Pittsburgh Meetup: Big Gaming Fun!</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">25 October 2011 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1324 Wightman St., Pittsburgh, PA 15217</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Welcome to the third Pittsburgh meetup of the semester, apparently!</p>\n\n<p>I can't go anywhere next week because I'm on call, but I'd love to have you come over to my house and play some board games.  I only have 4 games (Bohnanza, Citadels, Acquire, and Hacker), so please bring anything you'd like to play.  We can order food and go more or less as late as we'd like.  If I get paged I may have to deal with an emergency (from home, using my laptop), but if that doesn't bother you, it doesn't bother me.</p>\n\n<p>Allergy warning: I have a cat.  I can put her upstairs, but if you have a cat allergy you might want to take some meds.  If you decide not to come because you have a severe cat allergy, please tell me, as this will factor into how appropriate a venue I consider my house to be in the future.</p>\n\n<p>RSVP here or by sending me a private message (but don't not show up because you didn't RSVP, I just want a rough idea of the number of attendees).  Ring the bell, knock, or call or text (412) 657-1395 to get in when you get there.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Pittsburgh_Meetup__Big_Gaming_Fun_1\">Discussion article for the meetup : <a href=\"/meetups/4d\">Pittsburgh Meetup: Big Gaming Fun!</a></h2>", "sections": [{"title": "Discussion article for the meetup : Pittsburgh Meetup: Big Gaming Fun!", "anchor": "Discussion_article_for_the_meetup___Pittsburgh_Meetup__Big_Gaming_Fun_", "level": 1}, {"title": "Discussion article for the meetup : Pittsburgh Meetup: Big Gaming Fun!", "anchor": "Discussion_article_for_the_meetup___Pittsburgh_Meetup__Big_Gaming_Fun_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T22:56:02.243Z", "modifiedAt": null, "url": null, "title": "Insulin signaling and autism", "slug": "insulin-signaling-and-autism-1", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "play_therapist", "createdAt": "2011-07-15T20:19:13.044Z", "isAdmin": false, "displayName": "play_therapist"}, "userId": "vxGRygSqWB2AffSMa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xuvC2aQDP6FtPAanX/insulin-signaling-and-autism-1", "pageUrlRelative": "/posts/xuvC2aQDP6FtPAanX/insulin-signaling-and-autism-1", "linkUrl": "https://www.lesswrong.com/posts/xuvC2aQDP6FtPAanX/insulin-signaling-and-autism-1", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Insulin%20signaling%20and%20autism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInsulin%20signaling%20and%20autism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxuvC2aQDP6FtPAanX%2Finsulin-signaling-and-autism-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Insulin%20signaling%20and%20autism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxuvC2aQDP6FtPAanX%2Finsulin-signaling-and-autism-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxuvC2aQDP6FtPAanX%2Finsulin-signaling-and-autism-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<p>I ran across this article that I think is interesting. It suggests that type 2 diabetes and the increase in autism may have a common cause.</p>\n<p>&nbsp;</p>\n<p>http://www.frontiersin.org/Cellular_Endocrinology/10.3389/fendo.2011.00054/full</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xuvC2aQDP6FtPAanX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "10535", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-20T23:00:18.876Z", "modifiedAt": null, "url": null, "title": "Insulin Signaling and Autism", "slug": "insulin-signaling-and-autism-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:00.107Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "play_therapist", "createdAt": "2011-07-15T20:19:13.044Z", "isAdmin": false, "displayName": "play_therapist"}, "userId": "vxGRygSqWB2AffSMa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rzSjP3xh3LdZAD53o/insulin-signaling-and-autism-0", "pageUrlRelative": "/posts/rzSjP3xh3LdZAD53o/insulin-signaling-and-autism-0", "linkUrl": "https://www.lesswrong.com/posts/rzSjP3xh3LdZAD53o/insulin-signaling-and-autism-0", "postedAtFormatted": "Thursday, October 20th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Insulin%20Signaling%20and%20Autism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInsulin%20Signaling%20and%20Autism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrzSjP3xh3LdZAD53o%2Finsulin-signaling-and-autism-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Insulin%20Signaling%20and%20Autism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrzSjP3xh3LdZAD53o%2Finsulin-signaling-and-autism-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrzSjP3xh3LdZAD53o%2Finsulin-signaling-and-autism-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<div id=\"entry_t3_84n\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<p>I ran across this article that I think is interesting. It  suggests that type 2 diabetes and the increase in autism may have a  common link</p>\n<p>&nbsp;</p>\n<p><a href=\"http://www.frontiersin.org/Cellular_Endocrinology/10.3389/fendo.2011.00054/full\">http://www.frontiersin.org/Cellular_Endocrinology/10.3389/fendo.2011.00054/full</a></p>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rzSjP3xh3LdZAD53o", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -4, "extendedScore": null, "score": 7.870460091074461e-07, "legacy": true, "legacyId": "10536", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T03:22:26.188Z", "modifiedAt": "2022-02-05T08:09:19.406Z", "url": null, "title": "[SEQ RERUN] Fake Morality", "slug": "seq-rerun-fake-morality", "viewCount": null, "lastCommentedAt": "2011-10-21T15:42:04.806Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W69XZYautt3T7YfKm/seq-rerun-fake-morality", "pageUrlRelative": "/posts/W69XZYautt3T7YfKm/seq-rerun-fake-morality", "linkUrl": "https://www.lesswrong.com/posts/W69XZYautt3T7YfKm/seq-rerun-fake-morality", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Morality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Morality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW69XZYautt3T7YfKm%2Fseq-rerun-fake-morality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Morality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW69XZYautt3T7YfKm%2Fseq-rerun-fake-morality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW69XZYautt3T7YfKm%2Fseq-rerun-fake-morality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 198, "htmlBody": "<p>Today's post, <a href=\"/lw/ky/fake_morality/\">Fake Morality</a> was originally published on 08 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Fake_Morality\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Many people provide fake reasons for their own moral reasoning. Religious people claim that the only reason people don't murder each other is because of God. Selfish-ists provide altruistic justifications for selfishness. Altruists provide selfish justifications for altruism. If you want to know how moral someone is, don't look at their reasons. Look at what they actually do.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/849/seq_rerun_fake_selfishness/\">Fake Selfishness</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W69XZYautt3T7YfKm", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.87136156795982e-07, "legacy": true, "legacyId": "10543", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fATPBv4pnHC33EmJ2", "BQeu7jpqmyWX3MzrY", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-10-21T03:22:26.188Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T06:04:37.594Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne practical rationality meetup", "slug": "meetup-melbourne-practical-rationality-meetup-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bNABq52D8u8sarANN/meetup-melbourne-practical-rationality-meetup-0", "pageUrlRelative": "/posts/bNABq52D8u8sarANN/meetup-melbourne-practical-rationality-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/bNABq52D8u8sarANN/meetup-melbourne-practical-rationality-meetup-0", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20practical%20rationality%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20practical%20rationality%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbNABq52D8u8sarANN%2Fmeetup-melbourne-practical-rationality-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20practical%20rationality%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbNABq52D8u8sarANN%2Fmeetup-melbourne-practical-rationality-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbNABq52D8u8sarANN%2Fmeetup-melbourne-practical-rationality-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 70, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4e'>Melbourne practical rationality meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">04 November 2011 07:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">55 Walsh St, West Melbourne VIC 3003, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><em>Practical rationality</em>, as distinct from <em>socialising</em> and <em>rationality outreach</em>. Look for a social meetup on the 3rd Friday of each month, and a rationality outreach meetup TBD.</p>\n\n<p><em>Discussion:</em></p>\n\n<p><a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a> \n<a href=\"http://www.google.com/moderator/#16/e=6a317\" rel=\"nofollow\">http://www.google.com/moderator/#16/e=6a317</a></p>\n\n<p>This meetup repeats on the 1st Friday of each month.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4e'>Melbourne practical rationality meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bNABq52D8u8sarANN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.87191945594197e-07, "legacy": true, "legacyId": "10545", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup\">Discussion article for the meetup : <a href=\"/meetups/4e\">Melbourne practical rationality meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">04 November 2011 07:00:00PM (+1100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">55 Walsh St, West Melbourne VIC 3003, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><em>Practical rationality</em>, as distinct from <em>socialising</em> and <em>rationality outreach</em>. Look for a social meetup on the 3rd Friday of each month, and a rationality outreach meetup TBD.</p>\n\n<p><em>Discussion:</em></p>\n\n<p><a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a> \n<a href=\"http://www.google.com/moderator/#16/e=6a317\" rel=\"nofollow\">http://www.google.com/moderator/#16/e=6a317</a></p>\n\n<p>This meetup repeats on the 1st Friday of each month.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup1\">Discussion article for the meetup : <a href=\"/meetups/4e\">Melbourne practical rationality meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne practical rationality meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne practical rationality meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_practical_rationality_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T10:01:26.566Z", "modifiedAt": null, "url": null, "title": "Link: 50% effective malaria vaccine developed", "slug": "link-50-effective-malaria-vaccine-developed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:59.095Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MixedNuts", "createdAt": "2010-03-02T15:31:04.433Z", "isAdmin": false, "displayName": "MixedNuts"}, "userId": "zMvXdNMyznn73XSee", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jpyDDrsTd74GHwyKa/link-50-effective-malaria-vaccine-developed", "pageUrlRelative": "/posts/jpyDDrsTd74GHwyKa/link-50-effective-malaria-vaccine-developed", "linkUrl": "https://www.lesswrong.com/posts/jpyDDrsTd74GHwyKa/link-50-effective-malaria-vaccine-developed", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%2050%25%20effective%20malaria%20vaccine%20developed&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%2050%25%20effective%20malaria%20vaccine%20developed%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjpyDDrsTd74GHwyKa%2Flink-50-effective-malaria-vaccine-developed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%2050%25%20effective%20malaria%20vaccine%20developed%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjpyDDrsTd74GHwyKa%2Flink-50-effective-malaria-vaccine-developed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjpyDDrsTd74GHwyKa%2Flink-50-effective-malaria-vaccine-developed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p>A study on over 15000 children in 7 African countries shows GlaxoSmithKline's anti-malaria vaccine halves the risk of contracting malaria. The trials were run on children between 6 and 12 weeks old, and between 5 and 17 months old.</p>\n<p>Guardian article: http://www.guardian.co.uk/society/2011/oct/18/malaria-vaccine-save-millions-children</p>\n<p>Full paper: http://www.nejm.org/doi/full/10.1056/NEJMoa1102287</p>\n<p>From skimming the paper, this looks sound. GlaxoSmithKline both developed the vaccine and paid for the study, but that's standard. The <a href=\"http://www.nejm.org/doi/suppl/10.1056/NEJMoa1102287/suppl_file/nejmoa1102287_disclosures.pdf\">disclosure forms</a> don't show anything fishier.</p>\n<p>There are ways this could go wrong. GlaxoSmithKline says they'll make it cheap (probably for PR) but this is not sufficient to ensure availability. This could also increase total risk by replacing bed nets, or by making other diseases worse.</p>\n<p>Thoughts on the research? Comments on effects? Plans for wild celebration?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jpyDDrsTd74GHwyKa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 16, "extendedScore": null, "score": 7.872734162200789e-07, "legacy": true, "legacyId": "10549", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T14:46:57.599Z", "modifiedAt": null, "url": null, "title": "[LINK] SMBC on cryonics", "slug": "link-smbc-on-cryonics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:36.020Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KenChen", "createdAt": "2011-02-16T18:02:23.420Z", "isAdmin": false, "displayName": "KenChen"}, "userId": "Tay9Y5o7ehACBHeqc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hKNydJHkwNCEnKGpx/link-smbc-on-cryonics", "pageUrlRelative": "/posts/hKNydJHkwNCEnKGpx/link-smbc-on-cryonics", "linkUrl": "https://www.lesswrong.com/posts/hKNydJHkwNCEnKGpx/link-smbc-on-cryonics", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20SMBC%20on%20cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20SMBC%20on%20cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhKNydJHkwNCEnKGpx%2Flink-smbc-on-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20SMBC%20on%20cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhKNydJHkwNCEnKGpx%2Flink-smbc-on-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhKNydJHkwNCEnKGpx%2Flink-smbc-on-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.smbc-comics.com/index.php?db=comics&amp;id=2405</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hKNydJHkwNCEnKGpx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 6, "extendedScore": null, "score": 7.873716610871237e-07, "legacy": true, "legacyId": "10550", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T16:27:21.566Z", "modifiedAt": null, "url": null, "title": "Satisficers want to become maximisers", "slug": "satisficers-want-to-become-maximisers", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:05.196Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2qCxguXuZERZNKcNi/satisficers-want-to-become-maximisers", "pageUrlRelative": "/posts/2qCxguXuZERZNKcNi/satisficers-want-to-become-maximisers", "linkUrl": "https://www.lesswrong.com/posts/2qCxguXuZERZNKcNi/satisficers-want-to-become-maximisers", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Satisficers%20want%20to%20become%20maximisers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASatisficers%20want%20to%20become%20maximisers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qCxguXuZERZNKcNi%2Fsatisficers-want-to-become-maximisers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Satisficers%20want%20to%20become%20maximisers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qCxguXuZERZNKcNi%2Fsatisficers-want-to-become-maximisers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qCxguXuZERZNKcNi%2Fsatisficers-want-to-become-maximisers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 407, "htmlBody": "<p><em>(with thanks to Daniel Dewey, Owain Evans, Nick Bostrom, Toby Ord and BruceyB)</em></p>\n<p>In theory, a <a href=\"http://en.wikipedia.org/wiki/Satisficing\">satisficing</a> agent has a lot to recommend it. Unlike a maximiser, that will attempt to squeeze the universe to every drop of utility that it can, a satisficer will be content when it reaches a certain level <em>expected</em> utility (a satisficer that is content with a certain level of <em>utility</em> is simply a maximiser with a bounded utility function). For instance a satisficer with a utility linear in paperclips and a target level of 9, will be content once it's 90% sure that it's built ten paperclips, and not try to optimize the universe to either build more paperclips (unbounded utility), or&nbsp;obsessively count the ones it has already (bounded utility).</p>\n<p>Unfortunately, a self-improving satisficer has an extremely easy way to reach its satisficing goal: to transform itself into a maximiser. This is because, in general, if <strong>E</strong> denotes expectation,</p>\n<p style=\"padding-left: 30px;\"><strong>E</strong>(U(there exists an agent A maximising U)) &nbsp;&ge; &nbsp;<strong>E</strong>(U(there exists an agent A satisficing U))</p>\n<p>How is this true (apart from the special case when other agents penalise you specifically for being a maximiser)? Well, agent A will have to make decisions, and if it is a maximiser, will always make the decision that maximises expected utility. If it is a satisficer, it will sometimes not make the same decision, leading to lower expected utility in that case.</p>\n<p>So hence if there were a satisficing agent for U, and it had some strategy S to accomplish its goal, then another way to accomplish this would be to transform itself into a maximising agent and let that agent implement S. If S is complicated, and transforming itself is simple (which would be the case for a self-improving agent), then self-transforming into a maximiser is the easier way to go.</p>\n<p>So unless we have exceedingly well programmed criteria banning the satisficer from using any variant of this technique, we should assume satisficers are as likely to be as dangerous as maximisers.</p>\n<p><em><strong>Edited </strong>to clarify the argument for why a maximiser maximises better than a satisficer.</em></p>\n<p><em><strong>Edit</strong>:</em>&nbsp;See BruceyB's <a href=\"/r/discussion/lw/854/satisficers_want_to_become_maximisers/52jn\">comment</a> for an example where a (non-timeless) satisficer would find rewriting itself as a maximiser to be the only good strategy. Hence timeless satisficers would behave as maximisers anyway (in many situations). Furthermore, a timeless satisficer with bounded rationality may find that rewriting itself as a maximiser would be a useful precaution to take, if it's not sure to be able to&nbsp;precalculate&nbsp;all the correct strategies.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8KQvnMQYGaiCAqrXv": 1, "nvKzwpiranwy29HFJ": 1, "nYta24PsKTvg57KZy": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2qCxguXuZERZNKcNi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 33, "extendedScore": null, "score": 6.5e-05, "legacy": true, "legacyId": "10552", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T17:33:37.485Z", "modifiedAt": null, "url": null, "title": "In favour of a selective CEV initial dynamic", "slug": "in-favour-of-a-selective-cev-initial-dynamic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:09.372Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "4mYMvt6SSZtZRbMMX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/u8isNgN7rRYBZ35rQ/in-favour-of-a-selective-cev-initial-dynamic", "pageUrlRelative": "/posts/u8isNgN7rRYBZ35rQ/in-favour-of-a-selective-cev-initial-dynamic", "linkUrl": "https://www.lesswrong.com/posts/u8isNgN7rRYBZ35rQ/in-favour-of-a-selective-cev-initial-dynamic", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20In%20favour%20of%20a%20selective%20CEV%20initial%20dynamic&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIn%20favour%20of%20a%20selective%20CEV%20initial%20dynamic%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu8isNgN7rRYBZ35rQ%2Fin-favour-of-a-selective-cev-initial-dynamic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=In%20favour%20of%20a%20selective%20CEV%20initial%20dynamic%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu8isNgN7rRYBZ35rQ%2Fin-favour-of-a-selective-cev-initial-dynamic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fu8isNgN7rRYBZ35rQ%2Fin-favour-of-a-selective-cev-initial-dynamic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3176, "htmlBody": "<p>Note: I appreciate that at this point CEV is just a sketch. However, it&rsquo;s an interesting topic and I don&rsquo;t see that there&rsquo;s any harm in discussing certain details of the concept as it stands.</p>\n<p style=\"padding-left: 30px;\"><strong>1. Summary of CEV</strong></p>\n<p>Eliezer Yudkowsky describes CEV - Coherent Extrapolated Volition &ndash; <a href=\"http://intelligence.org/upload/CEV.html\">here</a>. Superintelligent AI is a powerful genie, and genies <a href=\"/lw/ld/the_hidden_complexity_of_wishes\">can&rsquo;t be trusted</a>; Friendly AI requires the AI to take as input the entire value computation of at least one human brain, because the failure to take into consideration a relatively small element of the human value set, even whilst optimising in several other respects, is likely to be a disaster. CEV is Yudkowsky&rsquo;s attempt at outlining a Friendly AI volition-extrapolating dynamic: a process in which the AI takes human brainstates, combines this with its own vast knowledge, and outputs suitable actions to benefit humans.</p>\n<p>Note that extrapolating volition is not some esoteric invention of Eliezer&rsquo;s; it is a normal human behaviour. To use his example: we are extrapolating Fred&rsquo;s volition (albeit with short <em>distance</em>) if given two boxes A and B only one of which contains a diamond that Fred desires, we give him box B when he has asked us to give him box A, on the basis that he incorrectly believes that box A contains the diamond whereas we know that in fact it is in box B.</p>\n<p>Yudkowsky roughly defines certain quantities that are likely to be relevant to the functioning of the CEV dynamic:</p>\n<p><em>Spread</em> describes the case in which the extrapolated volition is unpredictable. Quantum randomness or other computational problems may make it difficult to say with strong confidence (for example) whether person A would like to be given object X tomorrow &ndash; if the probability computed is 30%, rather than 0.001%, there is significant spread in this case.</p>\n<p><em>Muddle</em> is a measure of inconsistency. For example person A might resent being given object Y tomorrow, but also resent not being given object Y if it isn&rsquo;t given to him tomorrow.</p>\n<p><em>Distance</em> measures the degree of separation between one&rsquo;s current self and the extrapolated self, i.e. how easy it would be to explain a given instance of extrapolated volition to someone. In the case of Fred and the diamond the distance is very short, but superintelligent AI could potentially compute Fred&rsquo;s extrapolated volition to such a distance that it seems incomprehensible to Fred.</p>\n<p>To quote Yudkowsky (I assume that the following remains approximately true today):</p>\n<blockquote>\n<p>As of May 2004, my take on Friendliness is that the initial dynamic should implement the <em>coherent extrapolated volition</em> of humankind.</p>\n<p>In poetic terms, our <em>coherent extrapolated volition</em> is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.</p>\n</blockquote>\n<p>Yudkowsky adds that &ldquo;it should be easier to counter coherence than to create coherence&rdquo; where coherence refers to strong, un-muddled and un-spread agreement between multiple individual volitions with no strong disagreement from any others; and that &ldquo;the initial dynamic for CEV should be conservative about saying &lsquo;yes&rsquo; and listen carefully for &lsquo;no&rsquo;&rdquo; &ndash; the superintelligent optimisation process should seek more consensus before steering humanity into narrow slices of the future, relative to the degree of consensus it needs before steering humanity away from some particular narrow slice of the future (about which it has been warned by elements of the CEV).</p>\n<p>CEV is an <em>initial dynamic</em>; it doesn&rsquo;t necessarily have to be the perfect dynamic of human volition for Friendly AI, but the dynamic should be good enough that it allows the AI to extrapolate an optimal dynamic of volition to which we can then switch over if desirous. &ldquo;The purpose of CEV as an initial dynamic is not to be the solution, but to ask what solution we want&rdquo;.</p>\n<p>Also, &ldquo;If our extrapolated volitions say we don&rsquo;t want our extrapolated volitions manifested, the system replaces itself with something else we want, or else...undergoes an orderly shutdown&rdquo;.</p>\n<p>Finally, Yudkowsky suggests that as a safeguard, a <em>last judge</em> of impeccable judgement could be trusted with putting the seal of approval on the output of the CEV dynamic; if something seems to have gone horribly wrong, beyond mere future shock, he can stop the output from being enacted.</p>\n<p style=\"padding-left: 30px;\"><strong>2. CEV of all humankind vs. CEV of a subset of humankind</strong></p>\n<p>Let us accept that coherent extrapolated volition, in general, is the best (only?) solution that anyone has provided to the problem of AI friendliness. I can see four ways of implementing a CEV initial dynamic:</p>\n<ul>\n<li>Implement a single CEV dynamic incorporating all humans, the output of which affects everyone.</li>\n<li>Implement an individual CEV dynamic for each individual human.</li>\n<li>Implement a single CEV dynamic incorporating one human only, the output of which affects everyone.</li>\n<li>Implement a single CEV dynamic incorporating a limited subset of humans, the output of which affects everyone.</li>\n</ul>\n<p>As Yudkowsky discusses in his document, whilst the second option might perhaps be a reasonable final dynamic (who knows?) it isn&rsquo;t a suitable initial dynamic. This is because if there is more than one CEV running, the way in which the CEV dynamic works in a general sense cannot be re-written without someone&rsquo;s individual CEV being violated, and the idea behind the initial dynamic is that a superior dynamic may develop from it.</p>\n<p>The third option is obviously sub-optimal, because of the danger that any individual person might be a psychopath &ndash; a person whose values are in general markedly hostile to other humans. Knowing more and thinking smarter might lead a given psychopath&rsquo;s more humane values to win out, but we can&rsquo;t count on that. In a larger group of people, the law of large numbers applies and the risk diminishes.</p>\n<p>Yudkowsky favours the first option, a CEV of all humankind; I am more in favour of the fourth option, an initial CEV dynamic incorporating the minds of only a certain subset of humans. It would like to compare these two options on six relevant criteria:</p>\n<p><strong>I Schelling points [edit: apologies for the questionable use of a game theory term for the sake of concision]</strong></p>\n<p>Clearly, incorporating the minds of all humankind into the intial dynamic is a Schelling point &ndash; a solution that people would naturally generate for themselves in the absence of any communication. So full marks to a universal CEV on this criterion.</p>\n<p>Answer quickly: what specific group of people &ndash; be that a group of people who meet each other regularly, or a group who are distinguished in some other way &ndash; would you nominate, if you had to choose a certain subset of minds to participate in the initial dynamic?</p>\n<p>What springs to my mind is Nobel Prize winners, and I suspect that this too is a Schelling point. This seems like a politically neutral selection of distinguished human beings (particularly if we exclude the Peace Prize) of superlative character and intellect. Whether some people would object strongly to this selection is one question, but certainly I expect that many humans, supposing they were persuaded for other reasons that the most promising initial dynamic is one incorporating a small group of worthy humans only, would consider Nobel Prize winners to be an excellent choice to rally around.</p>\n<p>Many other groups of minds, for example the FAI programming team themselves, would of course seem too arbitrary to gather sufficient support for the idea.</p>\n<p><strong>II Practicality of implementation</strong></p>\n<p>One problem with a universal CEV that I have never seen discussed is how feasible it would actually be to take extremely detailed recordings of the brain states of all of the humans on Earth. All of the challenges involved in creating Friendly AI are of course extreme. But ceteris paribus, one additional extremely challenging problem is one too many.</p>\n<p>A prerequisite for the creation of superintelligent AI must surely be the acquisition of detailed knowledge of the workings of the human brain. However, our having the ability to scan one human brain in extreme detail does not imply that it is economically feasible to scan 7 billion or more human brains in the same way. It might well come to pass that the work on FAI is complete, but we still lack the means to actually collect detailed knowledge of all existing human minds. A superintelligent AI would develop its own satisfactory means of gathering information about human brains with minimal disruption, but as I understand the problem we need to input all human minds into the AI before switching it on and using it to do anything for us.</p>\n<p>Even if the economic means do exist, consider the social, political and ideological obstacles. How do we deal with people who don&rsquo;t wish to comply with the procedure?</p>\n<p>Furthermore, let us suppose that we manage to incorporate all or almost all human minds into the CEV dynamic. Yudkowsky admits the possibility that the thing might just shut itself down when we run it &ndash; and he suggests that we shouldn&rsquo;t alter the dynamic too many times in an attempt to get it to produce a reasonable-looking output, for fear of prejudicing the dynamic in favour of the programmers&rsquo; preferences and away from humanity&rsquo;s CEV.</p>\n<p>It would be one thing if this merely represented the (impeccably well-intentioned) waste of a vast amount of money, and the time of some Nobel Prize winners. But if it also meant that the economic, political and social order of the entire world had been trampled over in the process of incorporating all humans into the CEV, the consequences could be far worse. Enthusiasm for a second round with a new framework at some point in the future might be rather lower in the second scenario than in the first.</p>\n<p><strong>III Safety</strong></p>\n<p>In his document on CEV, Yudkowsky states that there is &ldquo;a real possibility&rdquo; that (in a universal CEV scenario) the majority of the planetary population might not fall into a niceness attractor when their volition is extrapolated.</p>\n<p>The small group size of living scientific Nobel Prize winners (or any other likely subset of humans) poses certain problems for a selective CEV that the universal CEV lacks. For example, they might all come under the influence of a single person or ideology that is not conducive to the needs of wider humanity.</p>\n<p>On the other hand, given their high level of civilisation and the quality of character necessary for a person to dedicate his life to science, ceteris paribus I&rsquo;d be more confident of Nobel Prize winners falling into a niceness attractor in comparison to a universal CEV. How much trust are we willing to place in the basic decency of humankind &ndash; to what extent is civilisation necessary to create a human who would not be essentially willing to torture innocent beings for his own gratification? Perhaps by the time humanity is technologically advanced enough to implement AGI we&rsquo;ll know more about that, but at our current state of knowledge I see little reason to give humans in general the benefit of the doubt.</p>\n<p>Yudkowsky asks, &ldquo;Wouldn&rsquo;t you be terribly ashamed to go down in history as having meddled...because you didn&rsquo;t trust your fellows?&rdquo; Personally, I think that <a href=\"http://wiki.lesswrong.com/wiki/Shut_up_and_multiply\">shutting up and multiplying</a> requires us to make our best estimate of what is likely to benefit humankind (including future humans) the most, and run with that. I&rsquo;d not be ashamed if in hindsight my estimate was wrong, since no-one can be blamed for having imperfect knowledge.</p>\n<p><strong>IV Aesthetic standards</strong></p>\n<p>In his document, Yudkowsky discusses the likelihood of certain volitions cancelling one another out whilst others add together; metaphorically speaking, &ldquo;love obeys Bose-Einstein statistics while hatred obeys Fermi-Dirac statistics&rdquo;. This supports the idea that extrapolating volition is likely to produce at least some useful output &ndash; i.e. having minimal spread and muddle, ideally at not too far a distance.</p>\n<p>In a universal CEV this leads us to believe that Pakistani-Indian mutual hatred, for example, cancels out (particularly since coherence is easier to counter than to create) whereas their mutual preferences form a strong signal.</p>\n<p>The problem of aesthetic standards concerns the <em>quality</em> of the signal that might cohere within the CEV. Love seems to be a strong human universal, and so we would expect love to play a strong role in the output of the initial dynamic. On the other hand, consider the difference in intelligence and civilisation between the bulk of humanity and a select group such as Nobel Prize winners. Certain values shared by such a select group, for example the ability to take joy in the merely real, might be lost amidst the noise of the relatively primitive values common to humanity as a whole.</p>\n<p>Admittedly, we can expect &ldquo;knowing more&rdquo; and &ldquo;growing up farther together&rdquo; to improve the quality of human values in general. Once an IQ-80 tribesman gains more knowledge and thinks faster, and is exposed to rational memes, he might well end up in exactly the same place as the Nobel Prize winners. But the question is whether it&rsquo;s a good idea to rely on a superb implementation of these specifications in an initial dynamic, rather than taking out the insurance policy of starting with substantially refined values in the first place &ndash; bearing in mind what is at stake.</p>\n<p>A worst case scenario, assuming that other aspects of the FAI implementation work as planned, is that the CEV recommends an ignoble future for humanity &ndash; for example <a href=\"http://wiki.lesswrong.com/wiki/Orgasmium\">orgasmium</a>&nbsp;&ndash; which is not evil, but is severely lacking in aesthetic qualities that might have come out of a more selective CEV. Of course, the programmers or the last judge should be able to veto an undesirable output. But if (as Yudkowsky recommends) they only trust themselves to tweak the dynamic a maximum of three times in an effort to improve the output before shutting it off for good if the results are still deemed unsatisfactory, this does not eliminate the problem.</p>\n<p><strong>V Obtaining a signal</strong></p>\n<p>It seems to me that the more muddle and spread there is within the CEV, the greater the challenge that exists in designing an initial dynamic that outputs anything whatsoever. Using a select group of humans would ensure that these quantities are minimised as far as possible. This is simply because they are likely to be (or can be chosen to be) a relatively homogeneous group of people, who have relatively few directly conflicting goals and possess relatively similar memes.</p>\n<p>Again, why make the challenge of FAI even more difficult than it needs to be? Bear in mind that failure to implement Friendly AI increases the likelihood of uFAI being created at some point.</p>\n<p><strong>VI Fairness</strong></p>\n<p>In his document on CEV, Yudkowsky does go some way to addressing the objections that I have raised. However, I do not find him persuasive on this subject:</p>\n<blockquote>\n<p>Suppose that our coherent extrapolated volition does decide to weight volitions by wisdom and kindness &ndash; a suggestion I strongly dislike, for it smacks of disenfranchisement. It don&rsquo;t think it wise to tell the initial dynamic to look to whichever humans judge themselves as wiser and kinder. And if the programmers define their own criteria of &ldquo;wisdom&rdquo; and &ldquo;kindness&rdquo; into a dynamic&rsquo;s search for leaders, that is taking over the world by proxy. You wouldn&rsquo;t want the al-Qaeda programmers doing that, right?</p>\n</blockquote>\n<p>Firstly, the question of disenfranchisement. As I suggested earlier, this constitutes a refusal to shut up and multiply when dealing with a moral question. &ldquo;Disenfranchisement&rdquo; is a drop in the ocean of human joy and human suffering that is at stake when we discuss FAI. As such, it is almost completely irrelevant as an item of importance in itself (of course there are other consequences involved in the choice between universal CEV and a degree of disenfranchisement &ndash; but they have been discussed already, and are beside the point of the strictly moral question.) This is especially the case since we are only talking about the initial dynamic here, which may well ultimately develop into a universal CEV.</p>\n<p>Secondly, there is the mention of al-Qaeda. In the context of earlier mentions of al-Qaeda programmers in the document on CEV, Yudkowsky appears to be positing a &ldquo;veil of ignorance&rdquo; &ndash; we should behave in creating the FAI as we would want al-Qaeda programmers to behave. This is strange, because in a similar veil of ignorance problem &ndash; the <a href=\"/lw/gr/the_modesty_argument\">modesty argument</a> &ndash; Robin Hanson argued that we should act as though there is a veil of ignorance surrounding whether it is ourselves or someone else who is wrong in some question of fact, whereas Eliezer argued against the idea.</p>\n<p>Personally I have little regard for veil of ignorance arguments, on the basis that there is no such thing as a veil of ignorance. No, I would not want the al-Qaeda programmers to nominate a group of humans (presumably Islamic fanatics) and extrapolate their volition &ndash; I would rather they used all of humanity. But so what? I am quite happy using my own powers of judgement to decide that al-Qaeda&rsquo;s group is inferior to humanity as a whole, but Nobel Prize winners (for example) are a better choice than humanity as a whole.</p>\n<p>As for &ldquo;taking over the world by proxy&rdquo;, again SUAM applies.</p>\n<p style=\"padding-left: 30px;\"><strong>3. Conclusion</strong></p>\n<p>I argue that a selective CEV incorporating a fairly small number of distinguished human beings may be preferable to a CEV incorporating all of humanity. I argue that the practical difficulty of incorporating all humans into the CEV in the first place is unduly great, and that the programming challenge is also made more difficult by virtue of this choice. I consider any increase in the level of difficulty in the bringing into existence of FAI to be positively dangerous, on account of the fact that this increases the window of time available for unscrupulous programmers to create uFAI.</p>\n<p>Setting aside the problem of getting the initial dynamic to work at all, I also consider it to be possible for the output of a selective CEV to be more desirable to the average human than the output of a universal CEV. The initial dynamic is the creation of human programmers, who are fallible in comparison to a superintelligent AI; their best attempt at creating a universal CEV dynamic may lead to the positive values of many humans being discarded, lost in the noise.</p>\n<p>In other words, the CEV initial dynamic shouldn't be regarded as discovering what a group of people most desire collectively \"by definition\" - it is imperfect. If a universal CEV implementation is more difficult for human programmers to do well than a selective CEV, then a selective CEV might not only extrapolate the desires of the group in question more accurately, but also do a better job of reflecting the <em>most&nbsp;effectively&nbsp;</em>extrapolated desires of humanity as a whole.</p>\n<p>Furthermore, desirability of the CEV ouput to the average human in existence today should be weighed against the desires of (for example) sentient human uploads created in a post-singularity scenario. Shutting up and multiplying demands that FAI programmers and other people of influence set aside concerns about being &ldquo;jerks&rdquo; when estimating the probability that extrapolating the volition of humanity en masse is the best way of meeting their own moral standards.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"W6QZYSNt5FgWgvbdT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "u8isNgN7rRYBZ35rQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 16, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "10551", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<p>Note: I appreciate that at this point CEV is just a sketch. However, it\u2019s an interesting topic and I don\u2019t see that there\u2019s any harm in discussing certain details of the concept as it stands.</p>\n<p style=\"padding-left: 30px;\"><strong id=\"1__Summary_of_CEV\">1. Summary of CEV</strong></p>\n<p>Eliezer Yudkowsky describes CEV - Coherent Extrapolated Volition \u2013 <a href=\"http://intelligence.org/upload/CEV.html\">here</a>. Superintelligent AI is a powerful genie, and genies <a href=\"/lw/ld/the_hidden_complexity_of_wishes\">can\u2019t be trusted</a>; Friendly AI requires the AI to take as input the entire value computation of at least one human brain, because the failure to take into consideration a relatively small element of the human value set, even whilst optimising in several other respects, is likely to be a disaster. CEV is Yudkowsky\u2019s attempt at outlining a Friendly AI volition-extrapolating dynamic: a process in which the AI takes human brainstates, combines this with its own vast knowledge, and outputs suitable actions to benefit humans.</p>\n<p>Note that extrapolating volition is not some esoteric invention of Eliezer\u2019s; it is a normal human behaviour. To use his example: we are extrapolating Fred\u2019s volition (albeit with short <em>distance</em>) if given two boxes A and B only one of which contains a diamond that Fred desires, we give him box B when he has asked us to give him box A, on the basis that he incorrectly believes that box A contains the diamond whereas we know that in fact it is in box B.</p>\n<p>Yudkowsky roughly defines certain quantities that are likely to be relevant to the functioning of the CEV dynamic:</p>\n<p><em>Spread</em> describes the case in which the extrapolated volition is unpredictable. Quantum randomness or other computational problems may make it difficult to say with strong confidence (for example) whether person A would like to be given object X tomorrow \u2013 if the probability computed is 30%, rather than 0.001%, there is significant spread in this case.</p>\n<p><em>Muddle</em> is a measure of inconsistency. For example person A might resent being given object Y tomorrow, but also resent not being given object Y if it isn\u2019t given to him tomorrow.</p>\n<p><em>Distance</em> measures the degree of separation between one\u2019s current self and the extrapolated self, i.e. how easy it would be to explain a given instance of extrapolated volition to someone. In the case of Fred and the diamond the distance is very short, but superintelligent AI could potentially compute Fred\u2019s extrapolated volition to such a distance that it seems incomprehensible to Fred.</p>\n<p>To quote Yudkowsky (I assume that the following remains approximately true today):</p>\n<blockquote>\n<p>As of May 2004, my take on Friendliness is that the initial dynamic should implement the <em>coherent extrapolated volition</em> of humankind.</p>\n<p>In poetic terms, our <em>coherent extrapolated volition</em> is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.</p>\n</blockquote>\n<p>Yudkowsky adds that \u201cit should be easier to counter coherence than to create coherence\u201d where coherence refers to strong, un-muddled and un-spread agreement between multiple individual volitions with no strong disagreement from any others; and that \u201cthe initial dynamic for CEV should be conservative about saying \u2018yes\u2019 and listen carefully for \u2018no\u2019\u201d \u2013 the superintelligent optimisation process should seek more consensus before steering humanity into narrow slices of the future, relative to the degree of consensus it needs before steering humanity away from some particular narrow slice of the future (about which it has been warned by elements of the CEV).</p>\n<p>CEV is an <em>initial dynamic</em>; it doesn\u2019t necessarily have to be the perfect dynamic of human volition for Friendly AI, but the dynamic should be good enough that it allows the AI to extrapolate an optimal dynamic of volition to which we can then switch over if desirous. \u201cThe purpose of CEV as an initial dynamic is not to be the solution, but to ask what solution we want\u201d.</p>\n<p>Also, \u201cIf our extrapolated volitions say we don\u2019t want our extrapolated volitions manifested, the system replaces itself with something else we want, or else...undergoes an orderly shutdown\u201d.</p>\n<p>Finally, Yudkowsky suggests that as a safeguard, a <em>last judge</em> of impeccable judgement could be trusted with putting the seal of approval on the output of the CEV dynamic; if something seems to have gone horribly wrong, beyond mere future shock, he can stop the output from being enacted.</p>\n<p style=\"padding-left: 30px;\"><strong id=\"2__CEV_of_all_humankind_vs__CEV_of_a_subset_of_humankind\">2. CEV of all humankind vs. CEV of a subset of humankind</strong></p>\n<p>Let us accept that coherent extrapolated volition, in general, is the best (only?) solution that anyone has provided to the problem of AI friendliness. I can see four ways of implementing a CEV initial dynamic:</p>\n<ul>\n<li>Implement a single CEV dynamic incorporating all humans, the output of which affects everyone.</li>\n<li>Implement an individual CEV dynamic for each individual human.</li>\n<li>Implement a single CEV dynamic incorporating one human only, the output of which affects everyone.</li>\n<li>Implement a single CEV dynamic incorporating a limited subset of humans, the output of which affects everyone.</li>\n</ul>\n<p>As Yudkowsky discusses in his document, whilst the second option might perhaps be a reasonable final dynamic (who knows?) it isn\u2019t a suitable initial dynamic. This is because if there is more than one CEV running, the way in which the CEV dynamic works in a general sense cannot be re-written without someone\u2019s individual CEV being violated, and the idea behind the initial dynamic is that a superior dynamic may develop from it.</p>\n<p>The third option is obviously sub-optimal, because of the danger that any individual person might be a psychopath \u2013 a person whose values are in general markedly hostile to other humans. Knowing more and thinking smarter might lead a given psychopath\u2019s more humane values to win out, but we can\u2019t count on that. In a larger group of people, the law of large numbers applies and the risk diminishes.</p>\n<p>Yudkowsky favours the first option, a CEV of all humankind; I am more in favour of the fourth option, an initial CEV dynamic incorporating the minds of only a certain subset of humans. It would like to compare these two options on six relevant criteria:</p>\n<p><strong id=\"I_Schelling_points__edit__apologies_for_the_questionable_use_of_a_game_theory_term_for_the_sake_of_concision_\">I Schelling points [edit: apologies for the questionable use of a game theory term for the sake of concision]</strong></p>\n<p>Clearly, incorporating the minds of all humankind into the intial dynamic is a Schelling point \u2013 a solution that people would naturally generate for themselves in the absence of any communication. So full marks to a universal CEV on this criterion.</p>\n<p>Answer quickly: what specific group of people \u2013 be that a group of people who meet each other regularly, or a group who are distinguished in some other way \u2013 would you nominate, if you had to choose a certain subset of minds to participate in the initial dynamic?</p>\n<p>What springs to my mind is Nobel Prize winners, and I suspect that this too is a Schelling point. This seems like a politically neutral selection of distinguished human beings (particularly if we exclude the Peace Prize) of superlative character and intellect. Whether some people would object strongly to this selection is one question, but certainly I expect that many humans, supposing they were persuaded for other reasons that the most promising initial dynamic is one incorporating a small group of worthy humans only, would consider Nobel Prize winners to be an excellent choice to rally around.</p>\n<p>Many other groups of minds, for example the FAI programming team themselves, would of course seem too arbitrary to gather sufficient support for the idea.</p>\n<p><strong id=\"II_Practicality_of_implementation\">II Practicality of implementation</strong></p>\n<p>One problem with a universal CEV that I have never seen discussed is how feasible it would actually be to take extremely detailed recordings of the brain states of all of the humans on Earth. All of the challenges involved in creating Friendly AI are of course extreme. But ceteris paribus, one additional extremely challenging problem is one too many.</p>\n<p>A prerequisite for the creation of superintelligent AI must surely be the acquisition of detailed knowledge of the workings of the human brain. However, our having the ability to scan one human brain in extreme detail does not imply that it is economically feasible to scan 7 billion or more human brains in the same way. It might well come to pass that the work on FAI is complete, but we still lack the means to actually collect detailed knowledge of all existing human minds. A superintelligent AI would develop its own satisfactory means of gathering information about human brains with minimal disruption, but as I understand the problem we need to input all human minds into the AI before switching it on and using it to do anything for us.</p>\n<p>Even if the economic means do exist, consider the social, political and ideological obstacles. How do we deal with people who don\u2019t wish to comply with the procedure?</p>\n<p>Furthermore, let us suppose that we manage to incorporate all or almost all human minds into the CEV dynamic. Yudkowsky admits the possibility that the thing might just shut itself down when we run it \u2013 and he suggests that we shouldn\u2019t alter the dynamic too many times in an attempt to get it to produce a reasonable-looking output, for fear of prejudicing the dynamic in favour of the programmers\u2019 preferences and away from humanity\u2019s CEV.</p>\n<p>It would be one thing if this merely represented the (impeccably well-intentioned) waste of a vast amount of money, and the time of some Nobel Prize winners. But if it also meant that the economic, political and social order of the entire world had been trampled over in the process of incorporating all humans into the CEV, the consequences could be far worse. Enthusiasm for a second round with a new framework at some point in the future might be rather lower in the second scenario than in the first.</p>\n<p><strong id=\"III_Safety\">III Safety</strong></p>\n<p>In his document on CEV, Yudkowsky states that there is \u201ca real possibility\u201d that (in a universal CEV scenario) the majority of the planetary population might not fall into a niceness attractor when their volition is extrapolated.</p>\n<p>The small group size of living scientific Nobel Prize winners (or any other likely subset of humans) poses certain problems for a selective CEV that the universal CEV lacks. For example, they might all come under the influence of a single person or ideology that is not conducive to the needs of wider humanity.</p>\n<p>On the other hand, given their high level of civilisation and the quality of character necessary for a person to dedicate his life to science, ceteris paribus I\u2019d be more confident of Nobel Prize winners falling into a niceness attractor in comparison to a universal CEV. How much trust are we willing to place in the basic decency of humankind \u2013 to what extent is civilisation necessary to create a human who would not be essentially willing to torture innocent beings for his own gratification? Perhaps by the time humanity is technologically advanced enough to implement AGI we\u2019ll know more about that, but at our current state of knowledge I see little reason to give humans in general the benefit of the doubt.</p>\n<p>Yudkowsky asks, \u201cWouldn\u2019t you be terribly ashamed to go down in history as having meddled...because you didn\u2019t trust your fellows?\u201d Personally, I think that <a href=\"http://wiki.lesswrong.com/wiki/Shut_up_and_multiply\">shutting up and multiplying</a> requires us to make our best estimate of what is likely to benefit humankind (including future humans) the most, and run with that. I\u2019d not be ashamed if in hindsight my estimate was wrong, since no-one can be blamed for having imperfect knowledge.</p>\n<p><strong id=\"IV_Aesthetic_standards\">IV Aesthetic standards</strong></p>\n<p>In his document, Yudkowsky discusses the likelihood of certain volitions cancelling one another out whilst others add together; metaphorically speaking, \u201clove obeys Bose-Einstein statistics while hatred obeys Fermi-Dirac statistics\u201d. This supports the idea that extrapolating volition is likely to produce at least some useful output \u2013 i.e. having minimal spread and muddle, ideally at not too far a distance.</p>\n<p>In a universal CEV this leads us to believe that Pakistani-Indian mutual hatred, for example, cancels out (particularly since coherence is easier to counter than to create) whereas their mutual preferences form a strong signal.</p>\n<p>The problem of aesthetic standards concerns the <em>quality</em> of the signal that might cohere within the CEV. Love seems to be a strong human universal, and so we would expect love to play a strong role in the output of the initial dynamic. On the other hand, consider the difference in intelligence and civilisation between the bulk of humanity and a select group such as Nobel Prize winners. Certain values shared by such a select group, for example the ability to take joy in the merely real, might be lost amidst the noise of the relatively primitive values common to humanity as a whole.</p>\n<p>Admittedly, we can expect \u201cknowing more\u201d and \u201cgrowing up farther together\u201d to improve the quality of human values in general. Once an IQ-80 tribesman gains more knowledge and thinks faster, and is exposed to rational memes, he might well end up in exactly the same place as the Nobel Prize winners. But the question is whether it\u2019s a good idea to rely on a superb implementation of these specifications in an initial dynamic, rather than taking out the insurance policy of starting with substantially refined values in the first place \u2013 bearing in mind what is at stake.</p>\n<p>A worst case scenario, assuming that other aspects of the FAI implementation work as planned, is that the CEV recommends an ignoble future for humanity \u2013 for example <a href=\"http://wiki.lesswrong.com/wiki/Orgasmium\">orgasmium</a>&nbsp;\u2013 which is not evil, but is severely lacking in aesthetic qualities that might have come out of a more selective CEV. Of course, the programmers or the last judge should be able to veto an undesirable output. But if (as Yudkowsky recommends) they only trust themselves to tweak the dynamic a maximum of three times in an effort to improve the output before shutting it off for good if the results are still deemed unsatisfactory, this does not eliminate the problem.</p>\n<p><strong id=\"V_Obtaining_a_signal\">V Obtaining a signal</strong></p>\n<p>It seems to me that the more muddle and spread there is within the CEV, the greater the challenge that exists in designing an initial dynamic that outputs anything whatsoever. Using a select group of humans would ensure that these quantities are minimised as far as possible. This is simply because they are likely to be (or can be chosen to be) a relatively homogeneous group of people, who have relatively few directly conflicting goals and possess relatively similar memes.</p>\n<p>Again, why make the challenge of FAI even more difficult than it needs to be? Bear in mind that failure to implement Friendly AI increases the likelihood of uFAI being created at some point.</p>\n<p><strong id=\"VI_Fairness\">VI Fairness</strong></p>\n<p>In his document on CEV, Yudkowsky does go some way to addressing the objections that I have raised. However, I do not find him persuasive on this subject:</p>\n<blockquote>\n<p>Suppose that our coherent extrapolated volition does decide to weight volitions by wisdom and kindness \u2013 a suggestion I strongly dislike, for it smacks of disenfranchisement. It don\u2019t think it wise to tell the initial dynamic to look to whichever humans judge themselves as wiser and kinder. And if the programmers define their own criteria of \u201cwisdom\u201d and \u201ckindness\u201d into a dynamic\u2019s search for leaders, that is taking over the world by proxy. You wouldn\u2019t want the al-Qaeda programmers doing that, right?</p>\n</blockquote>\n<p>Firstly, the question of disenfranchisement. As I suggested earlier, this constitutes a refusal to shut up and multiply when dealing with a moral question. \u201cDisenfranchisement\u201d is a drop in the ocean of human joy and human suffering that is at stake when we discuss FAI. As such, it is almost completely irrelevant as an item of importance in itself (of course there are other consequences involved in the choice between universal CEV and a degree of disenfranchisement \u2013 but they have been discussed already, and are beside the point of the strictly moral question.) This is especially the case since we are only talking about the initial dynamic here, which may well ultimately develop into a universal CEV.</p>\n<p>Secondly, there is the mention of al-Qaeda. In the context of earlier mentions of al-Qaeda programmers in the document on CEV, Yudkowsky appears to be positing a \u201cveil of ignorance\u201d \u2013 we should behave in creating the FAI as we would want al-Qaeda programmers to behave. This is strange, because in a similar veil of ignorance problem \u2013 the <a href=\"/lw/gr/the_modesty_argument\">modesty argument</a> \u2013 Robin Hanson argued that we should act as though there is a veil of ignorance surrounding whether it is ourselves or someone else who is wrong in some question of fact, whereas Eliezer argued against the idea.</p>\n<p>Personally I have little regard for veil of ignorance arguments, on the basis that there is no such thing as a veil of ignorance. No, I would not want the al-Qaeda programmers to nominate a group of humans (presumably Islamic fanatics) and extrapolate their volition \u2013 I would rather they used all of humanity. But so what? I am quite happy using my own powers of judgement to decide that al-Qaeda\u2019s group is inferior to humanity as a whole, but Nobel Prize winners (for example) are a better choice than humanity as a whole.</p>\n<p>As for \u201ctaking over the world by proxy\u201d, again SUAM applies.</p>\n<p style=\"padding-left: 30px;\"><strong id=\"3__Conclusion\">3. Conclusion</strong></p>\n<p>I argue that a selective CEV incorporating a fairly small number of distinguished human beings may be preferable to a CEV incorporating all of humanity. I argue that the practical difficulty of incorporating all humans into the CEV in the first place is unduly great, and that the programming challenge is also made more difficult by virtue of this choice. I consider any increase in the level of difficulty in the bringing into existence of FAI to be positively dangerous, on account of the fact that this increases the window of time available for unscrupulous programmers to create uFAI.</p>\n<p>Setting aside the problem of getting the initial dynamic to work at all, I also consider it to be possible for the output of a selective CEV to be more desirable to the average human than the output of a universal CEV. The initial dynamic is the creation of human programmers, who are fallible in comparison to a superintelligent AI; their best attempt at creating a universal CEV dynamic may lead to the positive values of many humans being discarded, lost in the noise.</p>\n<p>In other words, the CEV initial dynamic shouldn't be regarded as discovering what a group of people most desire collectively \"by definition\" - it is imperfect. If a universal CEV implementation is more difficult for human programmers to do well than a selective CEV, then a selective CEV might not only extrapolate the desires of the group in question more accurately, but also do a better job of reflecting the <em>most&nbsp;effectively&nbsp;</em>extrapolated desires of humanity as a whole.</p>\n<p>Furthermore, desirability of the CEV ouput to the average human in existence today should be weighed against the desires of (for example) sentient human uploads created in a post-singularity scenario. Shutting up and multiplying demands that FAI programmers and other people of influence set aside concerns about being \u201cjerks\u201d when estimating the probability that extrapolating the volition of humanity en masse is the best way of meeting their own moral standards.</p>", "sections": [{"title": "1. Summary of CEV", "anchor": "1__Summary_of_CEV", "level": 1}, {"title": "2. CEV of all humankind vs. CEV of a subset of humankind", "anchor": "2__CEV_of_all_humankind_vs__CEV_of_a_subset_of_humankind", "level": 1}, {"title": "I Schelling points [edit: apologies for the questionable use of a game theory term for the sake of concision]", "anchor": "I_Schelling_points__edit__apologies_for_the_questionable_use_of_a_game_theory_term_for_the_sake_of_concision_", "level": 1}, {"title": "II Practicality of implementation", "anchor": "II_Practicality_of_implementation", "level": 1}, {"title": "III Safety", "anchor": "III_Safety", "level": 1}, {"title": "IV Aesthetic standards", "anchor": "IV_Aesthetic_standards", "level": 1}, {"title": "V Obtaining a signal", "anchor": "V_Obtaining_a_signal", "level": 1}, {"title": "VI Fairness", "anchor": "VI_Fairness", "level": 1}, {"title": "3. Conclusion", "anchor": "3__Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "114 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 114, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4ARaTpNX62uaL86j6", "NKECtGX4RZPd7SqYp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-21T21:38:18.796Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Dublin, Madison WI, Pittsburgh, Edinburgh, Melbourne, Penn State, Austin, and London", "slug": "weekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L5Yh8ze7XhfiwqvC3/weekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh", "pageUrlRelative": "/posts/L5Yh8ze7XhfiwqvC3/weekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh", "linkUrl": "https://www.lesswrong.com/posts/L5Yh8ze7XhfiwqvC3/weekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh", "postedAtFormatted": "Friday, October 21st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Dublin%2C%20Madison%20WI%2C%20Pittsburgh%2C%20Edinburgh%2C%20Melbourne%2C%20Penn%20State%2C%20Austin%2C%20and%20London&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Dublin%2C%20Madison%20WI%2C%20Pittsburgh%2C%20Edinburgh%2C%20Melbourne%2C%20Penn%20State%2C%20Austin%2C%20and%20London%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL5Yh8ze7XhfiwqvC3%2Fweekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Dublin%2C%20Madison%20WI%2C%20Pittsburgh%2C%20Edinburgh%2C%20Melbourne%2C%20Penn%20State%2C%20Austin%2C%20and%20London%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL5Yh8ze7XhfiwqvC3%2Fweekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL5Yh8ze7XhfiwqvC3%2Fweekly-lw-meetups-dublin-madison-wi-pittsburgh-edinburgh", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 346, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/3z\">Dublin, IE, Meetup:&nbsp;<span class=\"date\">15 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/46\">Monday Madison Meetup:&nbsp;<span class=\"date\">17 October 2011 06:00PM</span></a></li>\n<li><a href=\"/meetups/45\">Pittsburgh Meetup: Expert Presentation on Motivation:&nbsp;<span class=\"date\">18 October 2011 05:45PM</span></a></li>\n<li><a href=\"/meetups/44\">Edinburgh LW Meetup:&nbsp;<span class=\"date\">20 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/43\">Melbourne social meetup:&nbsp;<span class=\"date\">21 October 2011 06:00PM</span></a></li>\n<li><a href=\"/meetups/3i\">Penn State University: NEW Meetup starting!:&nbsp;<span class=\"date\">22 October 2011 02:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/41\">Austin, TX:&nbsp;<span class=\"date\">15 October 2011 01:30PM</span></a></li>\n<li><a href=\"/meetups/47\">London This Sunday:&nbsp;<span class=\"date\">16 October 2011 02:00PM</span></a></li>\n</ul>\n<p>Cities with regularly scheduled meetups:&nbsp;<strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>, <a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine\">Irvine</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>,<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin, CA</a> </strong>(uses the Bay Area List)<strong>,</strong> and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>Despite the handy sidebar of upcoming meetups, we've decided to continue posting an overview of upcoming meetups on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening:&nbsp;<strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>,&nbsp; <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison, WI</a></strong><strong>.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L5Yh8ze7XhfiwqvC3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 7.875132435727815e-07, "legacy": true, "legacyId": "10469", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pAHo9zSFXygp5A5dL", "tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-22T02:04:34.066Z", "modifiedAt": "2021-11-03T15:07:09.075Z", "url": null, "title": "Things you are supposed to like", "slug": "things-you-are-supposed-to-like", "viewCount": null, "lastCommentedAt": "2021-02-12T05:31:09.043Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4tzEAgdbNTwB6nKyL/things-you-are-supposed-to-like", "pageUrlRelative": "/posts/4tzEAgdbNTwB6nKyL/things-you-are-supposed-to-like", "linkUrl": "https://www.lesswrong.com/posts/4tzEAgdbNTwB6nKyL/things-you-are-supposed-to-like", "postedAtFormatted": "Saturday, October 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Things%20you%20are%20supposed%20to%20like&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThings%20you%20are%20supposed%20to%20like%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4tzEAgdbNTwB6nKyL%2Fthings-you-are-supposed-to-like%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Things%20you%20are%20supposed%20to%20like%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4tzEAgdbNTwB6nKyL%2Fthings-you-are-supposed-to-like", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4tzEAgdbNTwB6nKyL%2Fthings-you-are-supposed-to-like", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 973, "htmlBody": "<p>I'm trying to like <a href=\"http://www.youtube.com/watch?v=6s0Mp7LFI-k\">Beethoven's Great Fugue</a>.</p>\n<p>\"This piece alone completely changed my life and how I perceive and appreciate\ufeff music.\"</p>\n<p>\"Those that claim to love Beethoven but not this are fakers, frauds, wannabees, but most of all are people who are incapable of stopping everything for 10 minutes and reveling in absolute beauty, absolute perfection. Beethoven at\ufeff his finest.\"</p>\n<p>\"This is the absolute peak of Beethoven.\"</p>\n<p>\"It's now my\ufeff favorite piece by Beethoven.\"</p>\n<p>These are some of the comments on the page.\u00a0 Articulate music lovers with excellent taste praise this piece to heaven.\u00a0 Plus, it was written by Beethoven.</p>\n<p>It bores me.</p>\n<p><a></a>The first two times I listened to it, it stirred no feelings in me except irritation and impatience for its end.\u00a0 I found it devoid of small-scale or large-scale structure or transitions, aimless, unharmonious, and deficient in melody, rhythm, and melodic or rhythmic coordination between the four parts, none of which I would care to hear by themselves (which is a key measure of the quality of a fugue).</p>\n<p>Yet I feel strong pressure to like it.\u00a0 Liking Beethoven's Great Fugue marks you out as a music connoisseur.</p>\n<p>I feel pressure to like other things as well.\u00a0 Bitter cabernets, Jackson Pollack paintings, James Joyce's Finnegan's Wake, the Love Song of J. Alfred Prufrock, the music of Arnold Schoenberg, and Burning Man.\u00a0 This is a pattern common to all arts.\u00a0 You recognize this pattern in a work when:</p>\n<ul>\n</ul>\n<ol>\n<li>The work in question was created by deliberately taking away everything that most people like best about that art form.\u00a0 In the case of wine, sweetness and fruitiness.\u00a0 In the case of Jackson Pollack, form, variety, relevance, and colors not found in vomit.\u00a0 In the music of Alban Berg, basic music theory.\u00a0 In every poem in any volume of \"Greatest American Poetry\" since 2000, rhyme, rhythm, insight, and/or importance of subject matter.\u00a0 In the case of Burning Man, every possible physical comfort.\u00a0 The work cannot be composed of things that most people appreciate <em>plus</em> things connoisseurs appreciate.\u00a0 It must be difficult to like.</li>\n<li>The level of praise is absurd.\u00a0 The Great Fugue, Beethoven's finest?\u00a0 I'm sorry; my imagination does not stretch that far.\u00a0 \"Burning Man changed my life completely\" - I liked Burning Man; but if it changed your life completely, you probably had a vapid life.</li>\n<li>People say they hated it at first, but over time, grew to love it.\u00a0 One must be <em>trained</em> to like it.</li>\n<li>People give contradictory reasons for liking it.\u00a0 One person says the Great Fugue has a brilliant structure; another says it is great because of its lack of structure.</li>\n<li>Learning to like it is a rite of passage within a particular community.</li>\n</ol> \n<ul>\n</ul>\n<p>Here are some theories as to how a work becomes the darling of its medium or genre:</p>\n<ol>\n<li>It is really and truly excellent. This would explain features 2 and 5.</li>\n<li>It is a runaway peacock's-tail phenomenon: Someone made something that stood out in some way, and it got attention; and people learned to like things like that, and so others made things that stood out more in the same way, until we ended up with Alban Berg. This would explain features 2 and 3.</li>\n<li>When an artistic institution enshrines good art as exemplars, it increases the status of the small number of people who can produce good art.  When an institution enshrines bad art as exemplars, it decreases the status of people who can produce or recognize good art. As institutions grow in size, the ratio (# people advantaged by enshrining bad art / # people advantaged by enshrining bad art) grows.\u00a0 This would explain all five features.</li>\n<li>As people learn more about an art form, they can more-easily predict it, and need more and more novelty to keep them interested; like porn viewers who seek out movies with continually-stranger sex acts.\u00a0 If ivy-league universities had departments of pornography, they would scoff at the simplicity of films lacking bondage, machines, or animals. This would explain features 1, 3, and 5.</li>\n<li>Practitioners of an art appreciate technique more than content.\u00a0 This is why authors love Thomas Pynchon's <em>Gravity's Rainbow</em> and Delaney's <em>Dhalgren</em>; they're full of beautiful phrases and metaphors, ways of making transitions, and other little tricks that authors can admire and learn to use, even though these books aren't as interesting to readers. This could explain feature 5.</li>\n</ol>\n<p>(Don't assume that the same theory is true for each of my examples.\u00a0 I think that the wine hierarchy and Alban Berg are nonsense, Jackson Pollack is an interesting one-trick pony, <em>Citizen Kane</em> was revolutionary and is important for cinematographers to study but is boring compared to contemporary movies, and Burning Man is great but would be even better with showers.)</p>\n<p>I could keep listening to the Great Fugue, and see if I, too, come to love it in time.\u00a0 But what would that prove?\u00a0 Of course I would come to love it in time, if I listen to it over and over, earnestly <em>trying</em> to like it, convinced that by liking the Great Fugue I, too, would attain the heights of musical sophistication.</p>\n<p>The fact that people come to like it over time is not even suggested by theory 1 - even supposing the music is simply so great as to be beyond the appreciation of the typical listener, why would listening to it repeatedly grant the listener this skill?</p>\n<p>I have listened to it a few times, and am growing confused as to whether I like it or not.\u00a0 Why is this?\u00a0 Since when does one have to <em>wonder</em> whether one likes something or not?</p>\n<p>I am <em>afraid</em> to keep listening to the Great Fugue.\u00a0 I would come to like it, whether it is great art or pretentious garbage.\u00a0 That wouldn't rule out any of my theories.</p>\n<p>How can I figure out which it is <em>before</em> listening to it repeatedly?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"36RkM85iDocrnaypb": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4tzEAgdbNTwB6nKyL", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 96, "baseScore": 101, "extendedScore": null, "score": 0.000201, "legacy": true, "legacyId": "10523", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 101, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 372, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-22T03:21:55.298Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Fake Optimization Criteria", "slug": "seq-rerun-fake-optimization-criteria", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vcvnSieksrxCxNCWT/seq-rerun-fake-optimization-criteria", "pageUrlRelative": "/posts/vcvnSieksrxCxNCWT/seq-rerun-fake-optimization-criteria", "linkUrl": "https://www.lesswrong.com/posts/vcvnSieksrxCxNCWT/seq-rerun-fake-optimization-criteria", "postedAtFormatted": "Saturday, October 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Fake%20Optimization%20Criteria&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Fake%20Optimization%20Criteria%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvcvnSieksrxCxNCWT%2Fseq-rerun-fake-optimization-criteria%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Fake%20Optimization%20Criteria%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvcvnSieksrxCxNCWT%2Fseq-rerun-fake-optimization-criteria", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvcvnSieksrxCxNCWT%2Fseq-rerun-fake-optimization-criteria", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 218, "htmlBody": "<p>Today's post, <a href=\"/lw/kz/fake_optimization_criteria/\">Fake Optimization Criteria</a> was originally published on 10 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Why study evolution? For one thing - it lets us see an alien optimization process up close - lets us see the real consequence of optimizing strictly for an alien optimization criterion like inclusive genetic fitness. Humans, who try to persuade other humans to do things their way, think that this policy criterion ought to require predators to restrain their breeding to live in harmony with prey; the true result is something that humans find less aesthetic.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/84v/seq_rerun_fake_morality/\">Fake Morality</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vcvnSieksrxCxNCWT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.876315436255402e-07, "legacy": true, "legacyId": "10557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["i6fKszWY6gLZSX2Ey", "W69XZYautt3T7YfKm", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-22T04:28:57.977Z", "modifiedAt": null, "url": null, "title": "Truth & social graces", "slug": "truth-and-social-graces", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.530Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "irrational", "createdAt": "2011-10-04T19:46:41.913Z", "isAdmin": false, "displayName": "irrational"}, "userId": "TaHr6NuudyhaHevgQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sYe46ZZ6r2KAs4F5p/truth-and-social-graces", "pageUrlRelative": "/posts/sYe46ZZ6r2KAs4F5p/truth-and-social-graces", "linkUrl": "https://www.lesswrong.com/posts/sYe46ZZ6r2KAs4F5p/truth-and-social-graces", "postedAtFormatted": "Saturday, October 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Truth%20%26%20social%20graces&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATruth%20%26%20social%20graces%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsYe46ZZ6r2KAs4F5p%2Ftruth-and-social-graces%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Truth%20%26%20social%20graces%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsYe46ZZ6r2KAs4F5p%2Ftruth-and-social-graces", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsYe46ZZ6r2KAs4F5p%2Ftruth-and-social-graces", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<p>I've seen an article on LW about Santa Claus and most people were very keen on not lying to their kids (and I agree). I have a little kid who is generally quite truthful, innocent enough not to lie in most cases. I noticed recently that when someone asks him, \"How are you\", he usually answers in detail because, well, you asked, didn't you? When I was a teenager I hated people who lied and I tended to ignore these unwritten social rules to the extent I could. I.e. I didn't ask if I didn't want to know and people thought I was rude. So, my question is, should I teach him to lie upon these occasions?</p>\n<p>More broadly, I was thinking, why am I committed to being truthful, in general? I guess because I would hate to be lied to myself. This is a kind of magical thinking maybe, or maybe it's a part of the social contract. This sort of lying in fact promotes the social well-being because to answer truthfully creates an unwelcome burden on my interlocutor who asked out of politeness and is not in truth interested. But it still feels wrong to lie. Even more wrong to teach your kid to do so.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sYe46ZZ6r2KAs4F5p", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 7.876546299178923e-07, "legacy": true, "legacyId": "10558", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-22T15:54:18.090Z", "modifiedAt": null, "url": null, "title": "[LINK] Loss of local knowledge affecting intellectual trends", "slug": "link-loss-of-local-knowledge-affecting-intellectual-trends", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.304Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "GLaDOS", "createdAt": "2011-04-26T20:59:08.539Z", "isAdmin": false, "displayName": "GLaDOS"}, "userId": "wdPp4B7WGssb2gHwP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hf9ZP2wnPwZ5pcujv/link-loss-of-local-knowledge-affecting-intellectual-trends", "pageUrlRelative": "/posts/hf9ZP2wnPwZ5pcujv/link-loss-of-local-knowledge-affecting-intellectual-trends", "linkUrl": "https://www.lesswrong.com/posts/hf9ZP2wnPwZ5pcujv/link-loss-of-local-knowledge-affecting-intellectual-trends", "postedAtFormatted": "Saturday, October 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Loss%20of%20local%20knowledge%20affecting%20intellectual%20trends&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Loss%20of%20local%20knowledge%20affecting%20intellectual%20trends%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhf9ZP2wnPwZ5pcujv%2Flink-loss-of-local-knowledge-affecting-intellectual-trends%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Loss%20of%20local%20knowledge%20affecting%20intellectual%20trends%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhf9ZP2wnPwZ5pcujv%2Flink-loss-of-local-knowledge-affecting-intellectual-trends", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fhf9ZP2wnPwZ5pcujv%2Flink-loss-of-local-knowledge-affecting-intellectual-trends", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 547, "htmlBody": "<p>A recent entry from the <a href=\"http://westhunt.wordpress.com/2011/10/21/local-knowledge/\">West Hunters blog</a> (written by <a href=\"http://en.wikipedia.org/wiki/Gregory_Cochran\">Gregory Cochran</a> and <a href=\"http://en.wikipedia.org/wiki/Henry_Harpending\">Henry Harpending</a> with whom most LWers are probably <a href=\"/lw/28t/qa_with_harpending_and_cochran/\">already familiar</a> with) caught my eye:&nbsp;</p>\n<blockquote>\n<p>People who grow up in a small town, or an old and stable neighborhood, often know their neighbors.&nbsp; More than than that, they know pretty much everything that&rsquo;s happened for the past couple of generations, whether they want to or not.&nbsp; For many Americans, probably most,&nbsp; this isn&rsquo;t the case. Mobility breeds anonymity.&nbsp; Suburban kids haven&rsquo;t necessarily been hanging out with the same peers since kindergarten, and even if they have, they probably don&rsquo;t much about their friends&rsquo; sibs and parents.</p>\n<p><strong>If you do have that thick local knowledge, significant trait heritabilit</strong><strong>y is fairly obvious.&nbsp; </strong>You notice that the valedictorians cluster in a few families, and you also know that those families don&rsquo;t need to put their kids under high pressure to get those results. They&rsquo;re just smart.<strong> </strong>Some are smart but too rebellious to play the game &ndash; and that runs in families too. For that matter, you know that those family similarities, although real and noticeable, are far from absolute.&nbsp; You see a lot of variation within a family.</p>\n<p><strong>If you don&rsquo;t have it, it&rsquo;s easier to believe that cognitive or personality traits are generated by environmental influences &ndash; </strong>how your family toilet trained you, whether they sent you to a prep school, etc.&nbsp;<strong> Easier to believe, but false.</strong></p>\n<p>So it isn&rsquo;t all that difficult to teach quantitative genetics to someone with that background. They already know it, more or less.&nbsp; Possession of this kind of knowledge must have been the norm in the human past. I&rsquo;m sure that Bushmen have it.</p>\n<p>The loss of this knowledge must have significant consequences, not just susceptibility to nurturist dogma.&nbsp; <strong>In the typical ancestral situation, you knew a lot about the relatives of all potential mates.&nbsp; Today, you might meet someone in college and know nothing about her family history.&nbsp;</strong> In particular, you&nbsp; might not be aware that schizophrenia runs in her family. You can&rsquo;t weigh what you don&rsquo;t know.<em>&nbsp;</em> In modern circumstances, I suspect that the reproductive success of people with a fair-sized dose of alleles that predispose to schiz has gone up &ndash; with the net consequence that selection is less effective at eliminating such alleles. The modern welfare state has probably had more impact, though.&nbsp; In the days of old, kids were likely to die if a parent flaked out.&nbsp; Today that does not happen.</p>\n</blockquote>\n<p>Seems quite coherent. It meshes well with findings that the more children parents have the less they subscribe to nurture, since they finally, possibly for the first time ever, get some hands on experience with the nurture (nurture as in stuff like upbringing not nurture as in lead paint) versus. nature issue. Note that today urban, educated, highly intelligent people are less likley to have children than possibly ever, how is this likley to effect intellectual fashions?</p>\n<p>Perhaps somewhat related to this is also the transition in the past 150 years (the time frame depending on where exactly you live) from agricultural communities, that often raised livestock to urban living. What exactly \"variation\" and \"heredity\" might mean in a intuitive way thus comes another source short with no clear replacement.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hf9ZP2wnPwZ5pcujv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 25, "extendedScore": null, "score": 5.8e-05, "legacy": true, "legacyId": "10559", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Jo4ExrJxF6rm8cm3k"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-22T23:22:25.434Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup", "slug": "meetup-fort-collins-colorado-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:03.383Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/j6vKxxxHhHQWhQoRP/meetup-fort-collins-colorado-meetup", "pageUrlRelative": "/posts/j6vKxxxHhHQWhQoRP/meetup-fort-collins-colorado-meetup", "linkUrl": "https://www.lesswrong.com/posts/j6vKxxxHhHQWhQoRP/meetup-fort-collins-colorado-meetup", "postedAtFormatted": "Saturday, October 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj6vKxxxHhHQWhQoRP%2Fmeetup-fort-collins-colorado-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj6vKxxxHhHQWhQoRP%2Fmeetup-fort-collins-colorado-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj6vKxxxHhHQWhQoRP%2Fmeetup-fort-collins-colorado-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4f'>Fort Collins, Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">26 October 2011 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Bean Cycle, 144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet smart people, talk about excellence and math. Maybe play games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4f'>Fort Collins, Colorado Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "j6vKxxxHhHQWhQoRP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.88045108592362e-07, "legacy": true, "legacyId": "10560", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup\">Discussion article for the meetup : <a href=\"/meetups/4f\">Fort Collins, Colorado Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">26 October 2011 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Bean Cycle, 144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Meet smart people, talk about excellence and math. Maybe play games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/4f\">Fort Collins, Colorado Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T02:44:02.398Z", "modifiedAt": null, "url": null, "title": "11 Less Wrong Articles I Probably Will Never Have Time to Write", "slug": "11-less-wrong-articles-i-probably-will-never-have-time-to", "viewCount": null, "lastCommentedAt": "2019-06-08T19:23:30.569Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Qs96DvwTCCdyRvM5E/11-less-wrong-articles-i-probably-will-never-have-time-to", "pageUrlRelative": "/posts/Qs96DvwTCCdyRvM5E/11-less-wrong-articles-i-probably-will-never-have-time-to", "linkUrl": "https://www.lesswrong.com/posts/Qs96DvwTCCdyRvM5E/11-less-wrong-articles-i-probably-will-never-have-time-to", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2011%20Less%20Wrong%20Articles%20I%20Probably%20Will%20Never%20Have%20Time%20to%20Write&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A11%20Less%20Wrong%20Articles%20I%20Probably%20Will%20Never%20Have%20Time%20to%20Write%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQs96DvwTCCdyRvM5E%2F11-less-wrong-articles-i-probably-will-never-have-time-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=11%20Less%20Wrong%20Articles%20I%20Probably%20Will%20Never%20Have%20Time%20to%20Write%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQs96DvwTCCdyRvM5E%2F11-less-wrong-articles-i-probably-will-never-have-time-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQs96DvwTCCdyRvM5E%2F11-less-wrong-articles-i-probably-will-never-have-time-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 614, "htmlBody": "<p>There are many Less Wrong posts I'd like to write, but I'm starting to admit there are some of them I'll probably never get around to. I need to be doing other things. If anybody wants to write up the post ideas below, go for it! You may also want to announce you're working on one or more of them in the comments, to avoid duplicate work.</p>\n<p>In no particular order...</p>\n<ol>\n<li><strong>The Value of Information</strong>. Less Wrong still doesn't have a tutorial on how to do value of information calculations. If 5+ examples from common circumstances are included, I think this could be useful to many people. One classic example is that most people don't spend even 10 hours figuring out how they should spend several years of their life while getting a degree. [<strong>Update</strong>: Vaniver <a href=\"/lw/85x/value_of_information_four_examples/\">wrote this one</a>.]</li>\n<li><strong>Gamify Boring Tasks</strong>. The <a href=\"/lw/3w3/how_to_beat_procrastination#flow\">potato chip lady</a> is a classic example of how to do this. I've got several of my own examples from my own life, and perhaps another author has their own. \"Make it a game\" is something my mother might advise for getting through boring tasks, and I didn't take this advice seriously until lots of scientific literature gave me the same advice. ('<a href=\"http://en.wikipedia.org/wiki/Flow_(psychology)\">Flow</a>' literature.) This is one tiny piece of <a href=\"/lw/3w3/how_to_beat_procrastination\">How to Beat Procrastination</a> that could be zoomed in on with its own post.</li>\n<li><strong>Biases in Charity</strong>. We've all heard about scope insensitivity, but several other biases effect our charitable giving. This post could basically be a summary of <a href=\"http://www.sas.upenn.edu/~baron/papers/charity.pdf\">this article</a>, plus a few others from <a href=\"http://www.amazon.com/Science-Giving-Experimental-Approaches-Judgment/dp/1848728859/\">that same book</a>. [<strong>Update</strong>: <a href=\"/lw/aid/heuristics_and_biases_in_charity/\">done</a> by Kaj.]</li>\n<li><strong>Motivational Externalism</strong>. One of the classic debates in metaethics/moral psychology is between <a href=\"http://plato.stanford.edu/entries/moral-motivation/#IntVExt\">motivation externalism and motivational internalism</a>. This debate seems to be in the process of being resolved by neuroscience, in favor of motivational externalism. I have spoken with LWers who do not know this. Much of the case is laid out <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Schroeder-et-al-Moral-Motivation.pdf\">here</a>, though there are more details to be gleaned from <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">neuroeconomics</a>.</li>\n<li><strong>The Dr. Evil Problem</strong>. Less Wrong has spent much discussion on the <a href=\"http://wiki.lesswrong.com/wiki/Sleeping_Beauty_problem\">sleeping beauty problem</a> (due largely to <a href=\"http://www.princeton.edu/~adame/papers/sleeping/sleeping.pdf\">Adam Elga</a>). A similar problem in decision theory / probability theory that may be worth discussing is Elga's \"Dr. Evil Problem,\" discussed <a href=\"http://philsci-archive.pitt.edu/1036/1/drevil.pdf\">here</a> and <a href=\"http://brian.weatherson.org/evil.pdf\">here</a>.</li>\n<li><strong>Hedonomics</strong>. Hedonomics is a particular way of combining decision research and happiness research, and has implications for <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">scientific self-help</a>. A beginning review is <a href=\"http://faculty.chicagobooth.edu/christopher.hsee/vita/Papers/HedonomicsBridging.pdf\">here</a>. The field could be summarized for Less Wrong.</li>\n<li><strong>Thinking Too Little or Thinking Too Much</strong>. Thinking errors can result both from thinking too little (heuristics and biases) and from thinking too much (overzealous decision analysis). It would be useful to have some heuristics available to recognize which type of thinking error is likely under which circumstances, as discussed by <a href=\"http://www.people.hbs.edu/mnorton/ariely%20norton%202011.pdf\">Ariely &amp; Norton (2010)</a>.</li>\n<li><strong>How to be a Happy Consumer</strong>. There is a ton of research on how to spend money in ways that actually make you happy, recently reviewed <a href=\"http://dunn.psych.ubc.ca/files/2011/04/Journal-of-consumer-psychology.pdf\">here</a>. This could be summarized for Less Wrong.</li>\n<li><strong>Informal Fallacies as Errors in Bayesian Reasoning</strong>. Just as science errs or succeeds as it agrees with probability theory, informal fallacies are justified only in so far as they agree with Bayes. A recent summary of this is <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Hahn-Oaksford-The-rationality-of-informal-argumentation.pdf\">here</a>. [<strong>Update</strong>: <a href=\"/lw/aq2/fallacies_as_weak_bayesian_evidence/\">done</a> by Kaj.]</li>\n<li><strong>Close-Call Counterfactuals</strong>. This is one of the biases I don't think has been discussed on Less Wrong yet. <a href=\"http://faculty.haas.berkeley.edu/tetlock/Vita/Philip%20Tetlock/Phil%20Tetlock/1994-1998/1998%20Close-Call%20Counterfactuals%20and%20Belief-System%20Defenses.pdf\">Summary</a>. [<strong>Update</strong>: <a href=\"/lw/akr/i_was_not_almost_wrong_but_i_was_almost_right/\">done</a> by Kaj.]</li>\n<li><strong>Make Better Decisions with UnBBayes</strong>. <a href=\"http://unbbayes.sourceforge.net/\">UnBBayes</a> is a fairly mature, actively developed cross-platform decision network software. It would be useful to have a tutorial on how Less Wrongers can use it to make better (important) decisions, like <a href=\"http://unbbayes.sourceforge.net/video_tutorial.html\">these video tutorials</a> but with better real-life examples.</li>\n</ol>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Qs96DvwTCCdyRvM5E", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 42, "extendedScore": null, "score": 9.9e-05, "legacy": true, "legacyId": "10561", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 35, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vADtvr9iDeYsCDfxd", "RWo4LwFzpHNQCTcYt", "hiiziojg3R5uwQPm9", "hN2aRnu798yas5b2k", "33KewgYhNSxFpbpXg", "YgNLfytckSyKTnDXN", "BmGrj9pRkcbJxae3x"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T02:55:05.042Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Adaptation-Executors, not Fitness Maximizers", "slug": "seq-rerun-adaptation-executors-not-fitness-maximizers", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H5vWHC3E8grmMs7h4/seq-rerun-adaptation-executors-not-fitness-maximizers", "pageUrlRelative": "/posts/H5vWHC3E8grmMs7h4/seq-rerun-adaptation-executors-not-fitness-maximizers", "linkUrl": "https://www.lesswrong.com/posts/H5vWHC3E8grmMs7h4/seq-rerun-adaptation-executors-not-fitness-maximizers", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Adaptation-Executors%2C%20not%20Fitness%20Maximizers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Adaptation-Executors%2C%20not%20Fitness%20Maximizers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH5vWHC3E8grmMs7h4%2Fseq-rerun-adaptation-executors-not-fitness-maximizers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Adaptation-Executors%2C%20not%20Fitness%20Maximizers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH5vWHC3E8grmMs7h4%2Fseq-rerun-adaptation-executors-not-fitness-maximizers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH5vWHC3E8grmMs7h4%2Fseq-rerun-adaptation-executors-not-fitness-maximizers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 222, "htmlBody": "<p>Today's post, <a href=\"/lw/l0/adaptationexecuters_not_fitnessmaximizers/\">Adaptation-Executers, not Fitness-Maximizers</a> was originally published on 11 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>A central principle of evolutionary biology in general, and evolutionary psychology in particular. If we regarded human taste buds as trying to maximize fitness, we might expect that, say, humans fed a diet too high in calories and too low in micronutrients, would begin to find lettuce delicious, and cheeseburgers distasteful. But it is better to regard taste buds as an executing adaptation - they are adapted to an ancestral environment in which calories, not micronutrients, were the limiting factor.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/859/seq_rerun_fake_optimization_criteria/\">Fake Optimization Criteria</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb16a": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H5vWHC3E8grmMs7h4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.881184086332986e-07, "legacy": true, "legacyId": "10562", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XPErvb8m9FapXCjhA", "vcvnSieksrxCxNCWT", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T03:06:46.507Z", "modifiedAt": null, "url": null, "title": "The Protagonist Problem", "slug": "the-protagonist-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:23.714Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KXsWN8i4W26qGCmRR/the-protagonist-problem", "pageUrlRelative": "/posts/KXsWN8i4W26qGCmRR/the-protagonist-problem", "linkUrl": "https://www.lesswrong.com/posts/KXsWN8i4W26qGCmRR/the-protagonist-problem", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Protagonist%20Problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Protagonist%20Problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKXsWN8i4W26qGCmRR%2Fthe-protagonist-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Protagonist%20Problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKXsWN8i4W26qGCmRR%2Fthe-protagonist-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKXsWN8i4W26qGCmRR%2Fthe-protagonist-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1276, "htmlBody": "<p><span style=\"font-family: 'Times New Roman'; font-size: medium;\"> </span></p>\n<div style=\"font-weight: bold; background-color: transparent;\">Followup to: <a style=\"font-weight: normal;\" href=\"/lw/7yr/neural_correlates_of_conscious_access/\">Neural Correlates of Conscious Access</a><span style=\"font-weight: normal;\">; </span>Related to:<span style=\"font-weight: normal;\"> </span><a style=\"font-weight: normal;\" href=\"/lw/no/how_an_algorithm_feels_from_inside/\">How an Algorithm Feels From the Inside</a><span style=\"font-weight: normal;\">, </span><a style=\"font-weight: normal;\" href=\"/lw/of/dissolving_the_question/\">Dissolving the Question</a><br /><span style=\"font-weight: normal;\"><a href=\"/lw/of/dissolving_the_question/\"></a></span><br /><span style=\"font-weight: normal;\">Global Workspace Theory and its associated Theater Metaphor are empirically plausible, but why should it result in consciousness? Why should </span><a style=\"font-weight: normal;\" href=\"/lw/7yr/neural_correlates_of_conscious_access/\">globally available information</a><span style=\"font-weight: normal;\"> being processed by separate cognitive modules make us </span><a style=\"font-weight: normal;\" href=\"/lw/p9/the_generalized_antizombie_principle/\">talk about being conscious</a><span style=\"font-weight: normal;\">?</span><br /><br /><span style=\"font-weight: normal;\">Sure, that's how brains see stuff, but why would that make us think that it's happening to anyone? What in the world corresponds to a self?</span><br /><br /><span style=\"font-weight: normal;\">So far, I've only encountered two threads of thought that try to approach this problem: the Social Cognitive Interface of Kurzban, and the Self-Model theories like those of Metzinger and Damasio. </span><br /><br /><span style=\"font-weight: normal;\">I&rsquo;ll be talking about the latter, starting off with what self-models are, and a bit about how they&rsquo;re constructed. Then I&rsquo;ll say what a self-model theory is.</span><br /><br />Humans as Informational Processing Systems<br /><br /><span style=\"font-weight: normal;\"><em>Questions:</em> What exactly is there for things to happen to? What can perceive things?</span><br /><br /><span style=\"font-weight: normal;\">Well, bodies exist, and stuff can to happen to them. So let's start there.</span><br /><br /><span style=\"font-weight: normal;\">Humans have bodies which include informational processing systems called brains. Our brains are causally entangled with the outside world, and are capable of mapping it. Sensory inputs are transformed into neural representations which can then be used in performing adaptive responses to the environment.</span><br /><br /><span style=\"font-weight: normal;\">In addition to receiving sensory input from our eyes, ears, nose, tongue, skin, etc, we get sensory input about the pH level of our blood, various hormone concentrations, etc. We map not only things about the outside world, but things about our own bodies. Our brain's models of our bodies also include things like limb position.</span><br /><br /><span style=\"font-weight: normal;\">From the third person, brains are capable of representing the bodies that they're attached to. </span><span style=\"font-weight: normal;\">Humans are information processing systems which, in the process of interacting with the environment, maintain a representation of themselves used by the system for the purposes of the system.</span><br /><br /><span style=\"font-weight: normal;\"><em>Answers:</em> We exist. We can perceive things. What we see as being our \"self\" is our brain's representation of ourselves. Generalizably, a \"self\" is a product of a system representing itself.</span><br /><br /><span style=\"font-weight: normal;\">Note: I don't mean to assert that human self-modeling accomplished by a single neurological system or module, but I do mean to say that there are a nonzero set of systems which, when taken together, can be elegantly expressed as being part of a self-model which presents information about a person to the person's brain.</span><br /><br />Bodily Self Models<br /><br /><span style=\"font-weight: normal;\">Human self-models seem to normally be based on sensory input, but can be separated from it. Your bodily self-model looks a lot like this:<img style=\" float:right; padding: 10 px;\" src=\"http://upload.wikimedia.org/wikipedia/commons/1/13/Sensory_Homunculus.png\" alt=\"Sensory Homunculus, Courtesy Wikipedia\" width=\"400\" height=\"400\" /></span><br /></div>\n<div style=\"font-weight: bold; background-color: transparent;\"><a style=\"font-weight: normal;\" href=\"http://en.wikipedia.org/wiki/Phantom_limb\">Phantom limb syndrome</a><span style=\"font-weight: normal;\">&nbsp; is a phenomenon where, after a limb is amputated, a person continues to feel it. Their self-model continues to include the limb, even though they no longer receive sensory input from it. Phantom limb syndrome has also been reported by people who, due to congenital circumstances, never had those limbs. This suggests that to some extent, they&rsquo;re based on neurological structures that humans are born with.</span><br /><br /><span style=\"font-weight: normal;\">Freaky stuff happens when a body model and sensory inputs don't coincide. &nbsp;<a href=\"http://en.wikipedia.org/wiki/Apotemnophilia\">Apotemnophilia</a>&nbsp; is a disorder where people want to amputate one of their otherwise healthy limbs, complaining that their body is \"overcomplete\", or that the limb is \"intrusive\". They also have very specific and consistent specifications for the amputation that they want, suggesting that the desire comes from a stable trait rather than say, attention seeking. They don't want want to get an amputation, they want a particular amputation. Which sounds pretty strange.</span><br /><br /><span style=\"font-weight: normal;\">This is distinct from &nbsp;<a href=\"http://en.wikipedia.org/wiki/Somatoparaphrenia\">somatoparaphrenia</a>, &nbsp;where a patient denies that a limb is theirs but is fairly apathetic towards it. Somatoparaphrenia is caused by damage to both S1 and the superior parietal lobule, leading to a limb which isn't represented in the self-model, that they don't get sensory input from. Hence, its not theirs and its just sorta hanging out there, but its not particularly distressing or creepy. Apotemnophilia can be described as lacking a limb in the self-model, but continuing to get input from it. Imagine if you felt a bunch of armness coming into your back.</span><br /><br /><span style=\"font-weight: normal;\">In some sense, your brain also marks this model of the body as being you. I'll talk more about it in another article, but for now just notice that that's important. It's useful to know that our body is in fact ours for planning purposes, etc.</span><br /><br />Self Models and Global Availability<br /><br /><span style=\"font-weight: normal;\"><a href=\"http://www.scholarpedia.org/article/Anosognosia\"><img style=\"float: left;\" src=\"https://docs.google.com/drawings/pub?id=1vCLXWQfeFzu--NLTqwckzH8xpWagZ9vzIpqX8q5DRRI&amp;w=960&amp;h=720\" alt=\"\" width=\"480\" height=\"360\" />Anosognosia</a>&nbsp; is the disorder where someone has a disability, but is unable/unwilling to believe that they have that disability. They insist that they don't move paralyzed arms because they don't want to, or that they can actually see while they're stumbling around bumping into things.</span><br /><br /><span style=\"font-weight: normal;\">This is also naturally explained in terms of self-model theory. A blind person with anosognosia isn't able to see, and doesn't receive visual information, but they still represent themselves as seeing. So when you ask them about it, or they try and plan, they assert that they can still see. When the brain damage leading to blindness and anosognosia occurs, they stop being able to see, but their self-model isn't updated to reflect that.</span><br /><br /><span style=\"font-weight: normal;\">Blindsight is the reverse case where someone is able to see, but don't represent themselves as seeing.</span><br /><span style=\"font-weight: normal;\">In both cases, the person's lack of an ability to represent themselves as having particular properties interferes with those properties being referred to by other cognitive modules such as those of speech or planning.</span><br /><br />Self-Model Theories of Consciousness<br /><br /><span style=\"font-weight: normal;\">Self-Model Theories hold that we're self aware because we're able to pay attention to ourselves in the same way that we pay attention to other things. You map yourself based on sensory inputs the same way that you map other things, and identify your model as being you.</span><br /><br /><span style=\"font-weight: normal;\">We think that things are happening to someone because we're able to notice that things are happening to something</span><br /><br /><span style=\"font-weight: normal;\">That's true of lots of animals though. What makes humans more conscious?</span><br /><br /><span style=\"font-weight: normal;\">Humans are better at incorporating further processing based on the self-model into the self-model. Animals form representations of and act in the environment, but humans can talk about their representations. Animals represent things, but they don't represent their representation. The lights are on, and somebody's home, but they don't know they're home.</span></div>\n<div style=\"background-color: transparent;\">Animals and Humans (and &nbsp;<a href=\"http://www.youtube.com/watch?v=ehno85yI-sA\">some Robots</a>) both represent themselves, but Humans are really good at representing other things -- like intentions -- and incorporating that into their self-model.</div>\n<div style=\"font-weight: bold; background-color: transparent;\"><span style=\"font-weight: normal;\">So umm... How does that work?</span><br /><span style=\"font-weight: normal;\"><em>To be continued...</em></span></div>\n<div style=\"font-weight: bold; background-color: transparent;\">Notes:</div>\n<div>The vast majority of this article is from Being No One.</div>\n<div>Thanks again to John Salvatier for reading early versions of this post, as well as getting a few papers for me.</div>\n<div style=\"font-weight: bold; background-color: transparent;\">References:</div>\n<div><span style=\"font-weight: normal;\">Metzinger, T. (2003). <em>Being No One: The Self-Model Theory of Subjectivity</em>. <em>Nature</em> (p. 713). MIT Press. Chapter 7</span></div>\n<div>\n<p style=\"margin-left: 24pt; text-indent: -24pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">Kurzban, R., &amp; Aktipis, C. A. (2007). Modularity and the social mind: are psychologists too self-ish? Personality and social psychology review : an official journal of the Society for Personality and Social Psychology, Inc, 11(2), 131-49. doi:10.1177/1088868306294906</p>\n<p style=\"margin-left: 24pt; text-indent: -24pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin-left: 24pt; text-indent: -24pt; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\">\ufeffRamachandran, V. S., Brang, D., McGeoch, P. D., &amp; Rosar, W. (2009). Sexual and food preference in apotemnophilia and anorexia: interactions between &ldquo;beliefs&rdquo; and &ldquo;needs&rdquo; regulated by two-way connections between body image and limbic structures. Perception, 38(5), 775-777. doi:10.1068/p6350</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KXsWN8i4W26qGCmRR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 24, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "10436", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9BRuYmSbyCfNyB6JR", "yA4gF5KrboK2m2Xu7", "Mc6QcrsbH5NRXbCRX", "kYAuNJX2ecH2uFqZ9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T04:02:23.072Z", "modifiedAt": null, "url": null, "title": "Best Nonfiction Writing on Less Wrong", "slug": "best-nonfiction-writing-on-less-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:03.871Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cijurJhuz22ACCQgX/best-nonfiction-writing-on-less-wrong", "pageUrlRelative": "/posts/cijurJhuz22ACCQgX/best-nonfiction-writing-on-less-wrong", "linkUrl": "https://www.lesswrong.com/posts/cijurJhuz22ACCQgX/best-nonfiction-writing-on-less-wrong", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Best%20Nonfiction%20Writing%20on%20Less%20Wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABest%20Nonfiction%20Writing%20on%20Less%20Wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcijurJhuz22ACCQgX%2Fbest-nonfiction-writing-on-less-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Best%20Nonfiction%20Writing%20on%20Less%20Wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcijurJhuz22ACCQgX%2Fbest-nonfiction-writing-on-less-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcijurJhuz22ACCQgX%2Fbest-nonfiction-writing-on-less-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p>However useful the content, what are some examples of the best nonfiction <em>writing</em>&nbsp;on Less Wrong? Are there pieces you think are as good as recent classics of essay form like&nbsp;<a href=\"http://www.esquire.com/features/honesty0707\">I Think You're Fat</a> or <a href=\"http://www.paulgraham.com/lies.html\">Lies We Tell Kids</a>? For example, I like Yvain's <a href=\"/lw/20/the_apologist_and_the_revolutionary/\">The Apologist and the Revolutionary</a>.</p>\n<p>Which pieces would <em>you</em>&nbsp;nominate as some of the best nonfiction writing on Less Wrong?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cijurJhuz22ACCQgX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 7.881416083611851e-07, "legacy": true, "legacyId": "10563", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZiQqsgGX6a42Sfpii"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T04:17:31.650Z", "modifiedAt": null, "url": null, "title": "HPMoR: What do you think you know?", "slug": "hpmor-what-do-you-think-you-know", "viewCount": null, "lastCommentedAt": "2011-10-24T23:48:50.679Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "malthrin", "createdAt": "2011-03-22T15:23:59.536Z", "isAdmin": false, "displayName": "malthrin"}, "userId": "5b5DcLkcYGD9YGRfF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xj7RiiSvi4CAsnHLu/hpmor-what-do-you-think-you-know", "pageUrlRelative": "/posts/xj7RiiSvi4CAsnHLu/hpmor-what-do-you-think-you-know", "linkUrl": "https://www.lesswrong.com/posts/xj7RiiSvi4CAsnHLu/hpmor-what-do-you-think-you-know", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20HPMoR%3A%20What%20do%20you%20think%20you%20know%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHPMoR%3A%20What%20do%20you%20think%20you%20know%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxj7RiiSvi4CAsnHLu%2Fhpmor-what-do-you-think-you-know%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=HPMoR%3A%20What%20do%20you%20think%20you%20know%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxj7RiiSvi4CAsnHLu%2Fhpmor-what-do-you-think-you-know", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fxj7RiiSvi4CAsnHLu%2Fhpmor-what-do-you-think-you-know", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 351, "htmlBody": "<p><em>(And somewhere in the back of his mind was a small, small note of confusion, a sense of something wrong about that story; and it should have been a part of Harry's art to notice that tiny note, but he was distracted. For it is a sad rule that whenever you are most in need of your art as a rationalist, that is when you are most likely to forget it.)</em></p>\n<p>Why does the wizarding world believe Voldemort used the Killing Curse on Harry? Whether or not the Love Shield exists in MoR, I doubt most wizards had an &gt;epsilon prior for the Killing Curse resulting in a scarred but otherwise unharmed target, a dead and burned spellcaster, and a destroyed building. There were no surviving witnesses except Baby Harry. Where did that version of events come from?</p>\n<p>If I was Joe Random Wizard and heard that evidence without names attached, I would naively hypothesize: Dark Wizard shows up at house, encounters mother + father + their allies. Battle ensues. Parents and Dark Wizard are slain. House is destroyed and baby is hit by debris. There is one obvious question - why the allies didn't take the baby with them - but any answer to that is more plausible than \"There were no allies; the most reliable curse in the world backfired on its most experienced practitioner.\"</p>\n<p>Not that the \"reflected curse\" story was hard to sell. People are great at <a href=\"/lw/km/motivated_stopping_and_motivated_continuation/\">not asking the next question when they want to believe</a>.</p>\n<p>We have some additional information about the events of that evening:</p>\n<ul>\n<li>Harry's memory under Dementation (Ch43). This may or may not be a true memory.</li>\n<li>Snape relayed the complete prophecy to Voldemort without understanding it (Ch77). McGonagall was the propechy's witness (Ch28), but Snape has also heard the original audio (Ch77).</li>\n<li>McGonagall knows that Voldemort is still around (Ch6).</li>\n<li>Quirrellmort does not want to kill Harry. If he ever did, he changed his mind while offscreen.</li>\n</ul>\n<p>What really happened at Godric's Hollow?</p>\n<p>&nbsp;</p>\n<p>PS. If the Love Shield does exist in MoR, do you suppose Bellatrix could cast it?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xj7RiiSvi4CAsnHLu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 16, "extendedScore": null, "score": 7.881468285848308e-07, "legacy": true, "legacyId": "10564", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["L32LHWzy9FzSDazEg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T06:46:23.608Z", "modifiedAt": null, "url": null, "title": "Why is memory but not CPU following Moore's law?", "slug": "why-is-memory-but-not-cpu-following-moore-s-law", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ccxiiATrsTi96A4Eg/why-is-memory-but-not-cpu-following-moore-s-law", "pageUrlRelative": "/posts/ccxiiATrsTi96A4Eg/why-is-memory-but-not-cpu-following-moore-s-law", "linkUrl": "https://www.lesswrong.com/posts/ccxiiATrsTi96A4Eg/why-is-memory-but-not-cpu-following-moore-s-law", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20is%20memory%20but%20not%20CPU%20following%20Moore's%20law%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20is%20memory%20but%20not%20CPU%20following%20Moore's%20law%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FccxiiATrsTi96A4Eg%2Fwhy-is-memory-but-not-cpu-following-moore-s-law%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20is%20memory%20but%20not%20CPU%20following%20Moore's%20law%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FccxiiATrsTi96A4Eg%2Fwhy-is-memory-but-not-cpu-following-moore-s-law", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FccxiiATrsTi96A4Eg%2Fwhy-is-memory-but-not-cpu-following-moore-s-law", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p>In Dec. 2005, I bought a new CPU for $389.&nbsp; It was an AMD Athlon 64 X2, with dual 2.0GHz processors.&nbsp; I also bought 1GB of RAM for $120.</p>\n<p>In September 2008, I bought a new CPU.&nbsp; It was an AMD Phenom II X4, with quad 3.0 GHz processors, for $190.&nbsp; I also bought 8GB of RAM for $270.</p>\n<p>Now I'm looking for a newer CPU and more RAM.&nbsp; I can buy an AMD Phenom II X6, with six 3.2 GHz processors, for $170.&nbsp; I can also buy 16GB of RAM for $100.</p>\n<p>Dec. 2005 was 5 years and 10 months ago.&nbsp; So we should have had 3 to 4 Moore doublings.&nbsp; From .0333 GHz/$, that would take us to .266 to .533 GHz/$.&nbsp; From 8.3 MB/$, we should have gone to 66.4 or 132.8 MB/$.</p>\n<p>Instead, I am at 6x3.2 GHz/$170 = .113 GHz/$ and 160 MB/$.&nbsp; CPU speed is lagging far behind Moore's Law, while RAM is outstripping it.</p>\n<p>Both depend on transistor density.&nbsp; So why are they so different?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb285": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ccxiiATrsTi96A4Eg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "10567", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-23T18:12:11.805Z", "modifiedAt": null, "url": null, "title": "Practicing what you preach", "slug": "practicing-what-you-preach", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:34.298Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TwistingFingers", "createdAt": "2011-09-16T02:07:04.963Z", "isAdmin": false, "displayName": "TwistingFingers"}, "userId": "tWYLp5wq8caRLNiSJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NYbiAvGrQ4TNA8wtd/practicing-what-you-preach", "pageUrlRelative": "/posts/NYbiAvGrQ4TNA8wtd/practicing-what-you-preach", "linkUrl": "https://www.lesswrong.com/posts/NYbiAvGrQ4TNA8wtd/practicing-what-you-preach", "postedAtFormatted": "Sunday, October 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Practicing%20what%20you%20preach&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APracticing%20what%20you%20preach%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYbiAvGrQ4TNA8wtd%2Fpracticing-what-you-preach%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Practicing%20what%20you%20preach%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYbiAvGrQ4TNA8wtd%2Fpracticing-what-you-preach", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNYbiAvGrQ4TNA8wtd%2Fpracticing-what-you-preach", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 402, "htmlBody": "<p>LessWrongers as a group are often accused of talking about rationality without putting it into practice (for an elaborated discussion of this see <a href=\"/lw/2po/selfimprovement_or_shiny_distraction_why_less/\">Self-Improvement or Shiny Distraction: Why Less Wrong is anti-Instrumental Rationality</a>). This behavior is particularly insidious because it is self-reinforcing: it will attract more armchair rationalists to LessWrong who will in turn reinforce the trend in an <a href=\"/lw/lm/affective_death_spirals/\">affective death spiral</a> until LessWrong is a community of utilitarian apologists akin to the internet communities of anorexics who congratulate each other on their weight loss. It will be a community where instead of discussing practical ways to \"<a href=\"http://www.overcomingbias.com/\">overcome bias</a>\" (the original intent of the sequences) we discuss arcane decision theories, who gets to be in our CEV, and the most rational birthday presents (sound familiar?).</p>\n<p>A recent attempt to counter this trend or at least make us feel better about it was a series of discussions on \"<a href=\"/lesswrong.com/lw/71r/leveling_irl_level_1\">leveling up</a>\": accomplishing a set of practical well-defined goals to increment your rationalist \"level\". It's hard to see how these goals fit into a long-term plan to achieve anything besides self-improvement for its own sake. Indeed, the article begins by priming us with a renaissance-man inspired quote and stands in stark contrast to articles emphasizing practical altruism such as \"<a href=\"/lw/37f/efficient_charity/\">efficient charity</a>\"</p>\n<p>So what's the solution? I don't know. However I can tell you a few things about the solution, whatever it may be:</p>\n<ul>\n<li>It wont feel like the right thing to do; your moral intuitions (being designed to operate in a small community of hunter gatherers) are unlikely to suggest to you anything near the optimal task.</li>\n<li>It will be something you can start working on right now, immediately.</li>\n<li>It will disregard arbitrary self-limitations like abstaining from politics or keeping yourself aligned with a community of family and friends.</li>\n<li>Speaking about it would undermine your reputation through signaling. A true rationalist has no need for humility, sentimental empathy, or the <a href=\"/lw/j4/absurdity_heuristic_absurdity_bias/\">absurdity heuristic</a>.</li>\n</ul>\n<p>Whatever you may decide to do, be sure it follows these principles. If none of your plans align with these guidelines then construct a new one, on the spot, immediately. Just do <strong>something</strong>: every moment you sit hundreds of thousands are dying and billions are suffering. Under your judgement your plan can self-modify in the future to overcome its flaws. Become an optimization process; shut up and calculate.</p>\n<p>I declare <a href=\"http://wiki.lesswrong.com/wiki/Crocker%27s_rules\">Crocker's rules</a> on the writing style of this post.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NYbiAvGrQ4TNA8wtd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 1, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "10570", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 298, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uFYQaGCRwt3wKtyZP", "XrzQW69HpidzvBxGr", "FCxHgPsDScx4C3H8n", "P792Z4QA9dzcLdKkE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T02:17:57.276Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Evolutionary Psychology", "slug": "seq-rerun-evolutionary-psychology", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ThsALeAjHSH27MhQL/seq-rerun-evolutionary-psychology", "pageUrlRelative": "/posts/ThsALeAjHSH27MhQL/seq-rerun-evolutionary-psychology", "linkUrl": "https://www.lesswrong.com/posts/ThsALeAjHSH27MhQL/seq-rerun-evolutionary-psychology", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Evolutionary%20Psychology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Evolutionary%20Psychology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FThsALeAjHSH27MhQL%2Fseq-rerun-evolutionary-psychology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Evolutionary%20Psychology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FThsALeAjHSH27MhQL%2Fseq-rerun-evolutionary-psychology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FThsALeAjHSH27MhQL%2Fseq-rerun-evolutionary-psychology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 227, "htmlBody": "<p>Today's post, <a href=\"/lw/l1/evolutionary_psychology/\">Evolutionary Psychology</a> was originally published on 11 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Evolutionary_Psychology\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The human brain, and every ability for thought and emotion in it, are all adaptations selected for by evolution. Humans have the ability to feel angry for the same reason that birds have wings: ancient humans and birds with those adaptations had more kids. But, it is easy to forget that there is a distinction between the reason humans have the ability to feel anger, and the reason why a particular person was angry at a particular thing. Human brains are adaptation-executors, not fitness maximizers.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/85e/seq_rerun_adaptationexecutors_not_fitness/\">Adaptation-Executors, not Fitness Maximizers</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ThsALeAjHSH27MhQL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 7.886022547023875e-07, "legacy": true, "legacyId": "10576", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["epZLSoNvjW53tqNj9", "H5vWHC3E8grmMs7h4", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T06:27:25.177Z", "modifiedAt": null, "url": null, "title": "Meetup : Houston Meetup", "slug": "meetup-houston-meetup-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.231Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cog", "createdAt": "2011-04-25T04:58:53.803Z", "isAdmin": false, "displayName": "Cog"}, "userId": "xkp87vCZ56dp2tWnN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WpiAk3oJvs2EJZmEx/meetup-houston-meetup-0", "pageUrlRelative": "/posts/WpiAk3oJvs2EJZmEx/meetup-houston-meetup-0", "linkUrl": "https://www.lesswrong.com/posts/WpiAk3oJvs2EJZmEx/meetup-houston-meetup-0", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Houston%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Houston%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWpiAk3oJvs2EJZmEx%2Fmeetup-houston-meetup-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Houston%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWpiAk3oJvs2EJZmEx%2Fmeetup-houston-meetup-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWpiAk3oJvs2EJZmEx%2Fmeetup-houston-meetup-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 127, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4g'>Houston Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">30 October 2011 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>After a temporary hiatus, the Houston LW meetup group will reconvene on 10/30 at 2:00 PM. I will be presenting a paper from within my field of research, theoretical neuroscience. The paper, \"Adaptive Drift-Diffusion Process to Learn Time Intervals\", can be found at: <a href=\"http://arxiv.org/abs/1103.2382\" rel=\"nofollow\">http://arxiv.org/abs/1103.2382</a> While somewhat interesting in its own right, I'll use it as a jumping off point to discuss the methods and goals of theoretical neuroscience as a whole. It's an exciting field that crosses over on a lot of themes covered on LW. As always, new members are welcome and encouraged to PM me before the meetup.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4g'>Houston Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WpiAk3oJvs2EJZmEx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 7.886883494983695e-07, "legacy": true, "legacyId": "10582", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup\">Discussion article for the meetup : <a href=\"/meetups/4g\">Houston Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">30 October 2011 02:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2010 Commerce St, Houston, Tx. 77002</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>After a temporary hiatus, the Houston LW meetup group will reconvene on 10/30 at 2:00 PM. I will be presenting a paper from within my field of research, theoretical neuroscience. The paper, \"Adaptive Drift-Diffusion Process to Learn Time Intervals\", can be found at: <a href=\"http://arxiv.org/abs/1103.2382\" rel=\"nofollow\">http://arxiv.org/abs/1103.2382</a> While somewhat interesting in its own right, I'll use it as a jumping off point to discuss the methods and goals of theoretical neuroscience as a whole. It's an exciting field that crosses over on a lot of themes covered on LW. As always, new members are welcome and encouraged to PM me before the meetup.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Houston_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/4g\">Houston Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Houston Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Houston Meetup", "anchor": "Discussion_article_for_the_meetup___Houston_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T09:28:22.351Z", "modifiedAt": null, "url": null, "title": "[LINK] Serotonin Transporter Genotype (5-HTTLPR) Predicts Utilitarian Moral Judgments ", "slug": "link-serotonin-transporter-genotype-5-httlpr-predicts", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:01.073Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HumanFlesh", "createdAt": "2009-08-06T13:57:13.387Z", "isAdmin": false, "displayName": "HumanFlesh"}, "userId": "WnHt66oquDiLQPnEc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jfkYytdRWvHE4bHcr/link-serotonin-transporter-genotype-5-httlpr-predicts", "pageUrlRelative": "/posts/jfkYytdRWvHE4bHcr/link-serotonin-transporter-genotype-5-httlpr-predicts", "linkUrl": "https://www.lesswrong.com/posts/jfkYytdRWvHE4bHcr/link-serotonin-transporter-genotype-5-httlpr-predicts", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Serotonin%20Transporter%20Genotype%20(5-HTTLPR)%20Predicts%20Utilitarian%20Moral%20Judgments%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Serotonin%20Transporter%20Genotype%20(5-HTTLPR)%20Predicts%20Utilitarian%20Moral%20Judgments%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjfkYytdRWvHE4bHcr%2Flink-serotonin-transporter-genotype-5-httlpr-predicts%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Serotonin%20Transporter%20Genotype%20(5-HTTLPR)%20Predicts%20Utilitarian%20Moral%20Judgments%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjfkYytdRWvHE4bHcr%2Flink-serotonin-transporter-genotype-5-httlpr-predicts", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjfkYytdRWvHE4bHcr%2Flink-serotonin-transporter-genotype-5-httlpr-predicts", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 11, "htmlBody": "<p><a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0025148\">A new link is found between serotonin transporters and philosophical predispositions.</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jfkYytdRWvHE4bHcr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 3, "extendedScore": null, "score": 7.887508099679821e-07, "legacy": true, "legacyId": "10584", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T15:51:56.739Z", "modifiedAt": null, "url": null, "title": "Should I get genotyped?", "slug": "should-i-get-genotyped", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.809Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WKLt8opnTkZWWHwK5/should-i-get-genotyped", "pageUrlRelative": "/posts/WKLt8opnTkZWWHwK5/should-i-get-genotyped", "linkUrl": "https://www.lesswrong.com/posts/WKLt8opnTkZWWHwK5/should-i-get-genotyped", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Should%20I%20get%20genotyped%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShould%20I%20get%20genotyped%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWKLt8opnTkZWWHwK5%2Fshould-i-get-genotyped%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Should%20I%20get%20genotyped%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWKLt8opnTkZWWHwK5%2Fshould-i-get-genotyped", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWKLt8opnTkZWWHwK5%2Fshould-i-get-genotyped", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 38, "htmlBody": "<p>I've heard several people here mention getting genotyped by <a href=\"https://www.23andme.com/\">23andme</a>&nbsp;(I assume there are other companies as well). Does genotyping have significant practical benefits or is it mostly for curiosity's sake? If there are significant benefits, what are they?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WKLt8opnTkZWWHwK5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 10, "extendedScore": null, "score": 7.888830704634157e-07, "legacy": true, "legacyId": "10585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T16:49:28.124Z", "modifiedAt": null, "url": null, "title": "Podcast Recommendations", "slug": "podcast-recommendations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:01.618Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wallowinmaya", "createdAt": "2011-03-21T00:39:18.855Z", "isAdmin": false, "displayName": "David Althaus"}, "userId": "xY8DDzk6TyvRroJEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A23mET6MqwEZ7BhsM/podcast-recommendations", "pageUrlRelative": "/posts/A23mET6MqwEZ7BhsM/podcast-recommendations", "linkUrl": "https://www.lesswrong.com/posts/A23mET6MqwEZ7BhsM/podcast-recommendations", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Podcast%20Recommendations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APodcast%20Recommendations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA23mET6MqwEZ7BhsM%2Fpodcast-recommendations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Podcast%20Recommendations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA23mET6MqwEZ7BhsM%2Fpodcast-recommendations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA23mET6MqwEZ7BhsM%2Fpodcast-recommendations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 97, "htmlBody": "<p>I know, books or blogs are often more informative than podcasts. But reading a book while going grocery shopping, bicycling or driving is kinda hard. And the last post <a href=\"/lw/6wv/really_good_education_podcasts/\">on this topic</a> didn't generate much discussion.</p>\n<p>So, I ask again: <em>Does anyone know of some interesting podcasts out there?</em></p>\n<p>I'll go ahead and list some of my favorites:</p>\n<p>- Econtalk by Russ Roberts.</p>\n<p>- Conversations from the Pale Blue Dot by Lukeprog.</p>\n<p>- Rationally Speaking by Julia Galef and Massimo Pigliucci.</p>\n<p>- Singularity 1 on 1 by Nikola Danaylov.</p>\n<p>- Big Ideas and TEDtalks are sometimes worthwhile.</p>\n<p>Lectures on ItunesU are of course great, too.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A23mET6MqwEZ7BhsM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 7.889029337291192e-07, "legacy": true, "legacyId": "10586", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NRjQupwCCcki6XnbB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T19:43:07.300Z", "modifiedAt": null, "url": null, "title": "Footage of the Michael Fox lecture", "slug": "footage-of-the-michael-fox-lecture", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:06.138Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2HrsGEgF8ATwuFhAj/footage-of-the-michael-fox-lecture", "pageUrlRelative": "/posts/2HrsGEgF8ATwuFhAj/footage-of-the-michael-fox-lecture", "linkUrl": "https://www.lesswrong.com/posts/2HrsGEgF8ATwuFhAj/footage-of-the-michael-fox-lecture", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Footage%20of%20the%20Michael%20Fox%20lecture&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFootage%20of%20the%20Michael%20Fox%20lecture%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2HrsGEgF8ATwuFhAj%2Ffootage-of-the-michael-fox-lecture%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Footage%20of%20the%20Michael%20Fox%20lecture%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2HrsGEgF8ATwuFhAj%2Ffootage-of-the-michael-fox-lecture", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2HrsGEgF8ATwuFhAj%2Ffootage-of-the-michael-fox-lecture", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p>Reto Schneider acquired, and has posted on his blog, <a href=\"http://www.weirdexperiments.com/apps/blog/show/8846691-the-legendary-dr-fox-lecture-footage-found-\">footage</a> of the <a href=\"http://en.wikipedia.org/wiki/Dr._Fox_effect\">Dr. Fox lecture</a> experiment from 1976.&nbsp; Experimenters prepared a nonsensical lecture on <span class=\"fw_sanitized\">'Mathematical Game Theory as Applied to Physician Education', and taught it to an actor, Michael Fox, who delivered it to three different audiences of 55 different professionals who asked questions and gave the lecture positive evaluations.&nbsp; Details <a href=\"http://www.er.uqam.ca/nobel/r30034/PSY4180/Pages/Naftulin.html\">here</a>, including the results of the 8-question evaluation.<br /></span></p>\n<p><span class=\"fw_sanitized\">The 3 groups were</span></p>\n<ul>\n<li>11 attendees of a teacher training conference in continuing education</li>\n<li>11 a group of mental health educators</li>\n<li>33 educators and administrators enrolled in a graduate level university educational philosophy course</li>\n</ul>\n<p>(BTW, feel free not to vote this up.&nbsp; I'm just relaying a link I found interesting.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2HrsGEgF8ATwuFhAj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 10, "extendedScore": null, "score": 7.889630716150955e-07, "legacy": true, "legacyId": "10569", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T19:51:25.001Z", "modifiedAt": null, "url": null, "title": "Let Your Workers Gather Food", "slug": "let-your-workers-gather-food", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:38.688Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "D_Malik", "createdAt": "2011-01-05T12:45:17.182Z", "isAdmin": false, "displayName": "D_Malik"}, "userId": "9dhw3PngyAWKqTymS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/j2v6yymMvzwczYXmg/let-your-workers-gather-food", "pageUrlRelative": "/posts/j2v6yymMvzwczYXmg/let-your-workers-gather-food", "linkUrl": "https://www.lesswrong.com/posts/j2v6yymMvzwczYXmg/let-your-workers-gather-food", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Let%20Your%20Workers%20Gather%20Food&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALet%20Your%20Workers%20Gather%20Food%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj2v6yymMvzwczYXmg%2Flet-your-workers-gather-food%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Let%20Your%20Workers%20Gather%20Food%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj2v6yymMvzwczYXmg%2Flet-your-workers-gather-food", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj2v6yymMvzwczYXmg%2Flet-your-workers-gather-food", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2146, "htmlBody": "<p><span style=\"font-size: 11px;\"><a href=\"http://wiki.lesswrong.com/wiki/Crocker's_rules\">Crocker's rules</a> apply to this post, and to everything I post.</span></p>\n<p><span style=\"font-size: 11px;\">Also, after writing this post and googling LW for links I came up with <a href=\"/lw/4e4/recursively_selfimproving_human_intelligence/\">this</a> post, which presents the same ideas. #!@$%</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\"><br /> When I was younger, I often played real-time strategy (RTS) computer games. These usually involve running an empire successfully enough to conquer all the other empires. To win, you would have to gather resources like food, stone, wood and gold for use in research, construction and recruitment. Gathering resources is done by worker units. To construct worker units you need food.&nbsp;</span><strong><span lang=\"EN-ZA\">Do you see the hack?</span></strong></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">I know,<span>&nbsp;</span>the title gives it away. You can construct a bunch of workers and tell them all to gather food. Use the food they gather to make more workers, and put those on food as well. You set up a positive feedback loop and quickly have vast numbers of workers. When you have crazy amounts of food, <em>then</em> you can get to the business of putting lots of workers on each other resource, and using all your resources to take over the world.</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">Of course, among RTS players this isn't a new idea, and various forces have arisen to counterbalance it. For instance, players build up small soldier squads and attack right at the start of the game, destroying any player who has only defenceless worker units. Marginal costs of worker recruitment increase with the number of workers you have. There are population limits. But the initial development boom still plays an important role, and the key to winning is often to balance those actions which help directly (building an army) with those actions which help with actions which help directly (making more workers).</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">Now consider this.<span>&nbsp;</span>If you want to, say, ensure we're not all dead in 100 years, what do you do? You could become a fireman and save a few lives. Or you could donate to some worthy organization. Or you could get other people to donate to said organization. Or convince people to convince people to donate to the organization. And so on. That's one <a href=\"http://en.wikipedia.org/wiki/Iterated_function\">orbit</a>&nbsp;under the <em>meta</em> function, but it's not the one I want to talk about.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">Say you decide to throw money at a worthy organization. To do that you need to get money, and to get money you need time.<span>&nbsp; </span>How much buck-for-the-time you get depends on how efficient you are at converting time into money. But time isn't just useful for conversion into money. It can also be used to increase your efficiency of converting time into money. Or it can be used to increase your efficiency at converting time into [efficiency of converting time into money]. And so on.&nbsp;</span><strong><span lang=\"EN-ZA\">Do you see the hack?</span></strong></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">Use the time you have to get better at using the time you have. You set up a positive feedback loop<span>&nbsp;</span>and end up crazy awesome. Human go FOOM. You might spend some time learning to efficiently manage your time, giving you more free time to work at your goals. You might spend some time thinking about how to manage akrasia and thereby create more quality work-time. You might research how best to learn, and chance upon <a href=\"http://wiki.lesswrong.com/wiki/Spaced_repetition\">SRSs</a>. You might learn about nootropics. You might even stumble upon <a href=\"http://www.lesswrong.com\">this very site</a>, where you might pick up pointers to things you can do to get better at using your time. Now, of course, you can't <em>just</em> spend your time becoming more and more awesome. At some point you need to actually use that awesomeness to do what you originally wanted to. As in the RTSs, you need to balance actions which accomplish stuff directly against those which accomplish stuff indirectly.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">In other words,<span>&nbsp;</span>you need to balance the various <a href=\"/lw/58g/levels_of_action/\"><em>levels</em>&nbsp;of action</a>. To summarize, level 0 actions are those which directly accomplish your goals. Level <em>k+1</em> actions are those which help make level <em>k</em> actions easier or more effective.</span><span>&nbsp;</span>As the <a href=\"/lw/58g/levels_of_action/\">linked</a> post observes, lower levels tend to be additive while higher levels are often multiplicative or better.<span>&nbsp;</span>Level 0 is useful. Level 1,2 and 3 are much more useful. Level 123 is pretty useless. Sure, travelling by horse gets you places, but having one person invent a plane which a billion people use will cut travel times significantly. Observe that this very <em>site</em> is about going meta, about thinking about thinking, and often about thinking about thinking about thinking, or even more. Also, work can be on many levels at once, and it's not always easy to figure out the level of an action. For instance, what's the level of you reading this paragraph?</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">&nbsp;</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">So we want awesomeness explosions,<span>&nbsp;</span>and to help bring about awesomeness explosions we need to know a bit about them. How can we act to make ourselves explode? What determines the speed of an awesomeness explosion? Is awesomeness capped, and, if so, what's capping it?</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">To start, what limits awesomeness? We might ask whether we can extend the analogy with worker recruitment in RTS games, and indeed we can. In RTS games, worker explosions can't go on forever because:</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l3 level1 lfo4\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span></span></span><!--[endif]--><span lang=\"EN-ZA\">Marginal worker costs increase with the number of workers built.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l3 level1 lfo4\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\">There are population limits.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l3 level1 lfo4\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Sooner or later, other players will <em>rudely</em> just up and attack you, and your defenceless workers will die.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">In a serendipitous confluence of circumstance, these three limitations on RTS fooms map nicely to human fooms. Respectively:</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l2 level1 lfo3\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\">Different fruit hangs at different heights, so picking low-hanging fruit makes the average fruit higher. In addition, as you become saner you become less neurotypical (Not every change is an improvement, but every improvement is a change.), so it's harder to use established human knowledge about self-improvement to improve yourself.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l2 level1 lfo3\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">There are limits to human knowledge. There are built-in limits on brain hardware. Note that both these can be overcome by the sufficiently awesome.<span>&nbsp;</span>They're also both special cases of the above bullet-point. Just as population limits are a special case of increasing marginal worker costs, in yet another serendipitous confluence of circumstance.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l2 level1 lfo3\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Your levels of work must be <em>grounded</em>. If you work on level <em>k+1</em>, make sure you do enough work on level <em>k</em> to justify it. (There's an analogy with <a href=\"/lw/la/truly_part_of_you/\">Truly Part Of You</a>.)</span></p>\n<p>With all these factors limiting human fooms, there's no guarantee human fooms will be, well, FOOMs. They might fizzle out too quickly, due to increasing marginal costs of awesomeness. But my mental intuitive estimation machinery says that, while taking over the world might be pushing it a bit, a lot more is possible than we've achieved so far.</p>\n<p>&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">Now for<span>&nbsp;</span>some ideas on making yourself go FOOM.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Do useful stuff!<span>&nbsp;</span><a href=\"/lw/2p1/a_failure_to_evaluate_returnontime_fallacy/\">People aren't</a> <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">automatically strategic</a>. I think this is the second-most important reason we haven't all foomed yet (after akrasia). Remember that compound interest <a href=\"http://xkcd.com/947/\">isn't magic</a> &ndash; just improving yourself isn't <em>enough.</em> You have to actually assign higher priority to things which are more important. This is a really important point, and all the rest of these bullet-points are special cases of it. I think those in the LW mindspacecluster are particularly prone to seek knowledge without first applying some ruthless pragmatism. I know I am.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Do stuff which helps you do stuff. In other words: work on higher levels,<span>&nbsp;</span>as long as you're still grounded. Go meta, like this sentence (whose metaness is too great for even the <a href=\"http://en.wikipedia.org/wiki/Ordinal_number\">ordinals</a>). Trying to learn from that physiology book isn't very useful when you haven't learnt how to learn. Again, this is a really important point and all the rest of these bullet-points are special cases of it.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Write down your thoughts<span>&nbsp;</span>(<a href=\"/lw/2o3/rationality_quotes_september_2010/2khe\">Darwin</a>), and preferably ensure you remember them with an <a href=\"http://wiki.lesswrong.com/wiki/Spaced_repetition\">SRS</a>. Record your time use every now and then. This is an important.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Explore new mindstates.<span>&nbsp;</span>Trying to come up with ideas seems like mining for diamonds, and often you can get more, bigger diamonds by mining in different places. One reason this is a good idea (and a reason why you should write down your thoughts) is that people (or me, at least) often seem to retread the same thoughtpatterns over and over, day after day. It's like you have a 'reset' button that gets pushed every evening when you go to sleep. I have directly observed this, when I wrote down my thoughts for a few weeks without memorizing them with an SRS. When I write down my thoughts, I've taken to calling this Every Day The Same Dream (EDTSD) syndrome.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Look at what other really smart people do, then consider doing that. Look at really smart people and ask yourself why they haven't taken over the world yet.<span>&nbsp;</span>(<a href=\"/lw/602/rationality_quotes_june_2011/4a6d\">David Bennett</a>: If you want to beat the market, you have to do something different from what everyone else is doing, and you have to be right.)</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Think a lot, and think in efficient ways. Most people seem to just hope good ideas will tap them on t he shoulder. I've been like that for most of my life. Ideas often <em>do</em> tap you on the shoulder, but I get better results by sitting down with a piece of paper and a pen and thinking really hard, vomiting anything that comes to me out onto the page. I call this the Thinking Really Hard (TRH) technique, and I Think it was inspired by Eliezer's <a href=\"/lw/ui/use_the_try_harder_luke/\">exhortation</a>&nbsp;to sit down and Think for 5 minutes before concluding a problem is unsolvable.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Related to the previous bullet-point: Ensure you focus mental energy wisely. If you really spent all your mental energy where it's optimal, how much more would get done? Perhaps actively stop yourself thinking about things you don't care about.<span>&nbsp;</span>Go meta: think about how to improve your thought-focussing abilities.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">As a special case of the previous bullet-point:<span>&nbsp;</span>Think long and hard about how to get more time. I really mean that. Perhaps you should add a reminder to regularly do that to your SRS, if you're awesome enough to use one. Remember the <a href=\"http://en.wikipedia.org/wiki/Pareto_principle\">Pareto principle</a>.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">As a<span>&nbsp;</span>summary of all these bullet-points: Figure out ways to work faster and smarter and harder. I have lots of ideas about overcoming akrasia which are pretty weird and which I've never seen described anywhere else, but which work spectacularly for me. Of course, <a title=\"Generalizing From One Example\" href=\"/lw/dr/generalizing_from_one_example/\">that doesn't mean they'll work for everyone else</a>, but <a title=\"The Psychological Unity of Humankind\" href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Ftop%2F&amp;v=1&amp;libid=1319481187489&amp;out=http%3A%2F%2Fwww.overcomingbias.com%2F2008%2F06%2Fpsychological-u.html&amp;ref=http%3A%2F%2Flesswrong.com%2Fpromoted%2F&amp;title=Top%20scoring%20articles%20-%20Less%20Wrong&amp;txt=The%20Psychological%20Unity%20of%20Humankind&amp;jsonp=vglnk_jsonp_13194811900141\">they're bound to work for <em>some</em> of you</a>. I might write a post.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\">A few links, which most LWers are probably already familiar with:</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:106.9pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\"><a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a></span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:106.9pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">SRSs: <a href=\"http://wiki.lesswrong.com/wiki/Spaced_repetition\">Gwern Branwen</a>, <a href=\"http://supermemo.com/english/princip.htm\">Piotr Wozniak</a></span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:106.9pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">Nootropics: ImmInst <a href=\"http://www.longecity.org/forum/topic/43394-nootropics-thread-index/\">1</a>, <a href=\"http://www.longecity.org/forum/topic/36691-ten-months-of-research-condensed-a-total-newbies-guide-to-nootropics/\">2</a></span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:106.9pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\"><a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Humans Aren't Automatically Strategic</a></span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:106.9pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\"><a href=\"http://wiki.lesswrong.com/wiki/Akrasia\">All the posts about akrasia</a></span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:106.9pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l1 level1 lfo2\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\">more?</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">What determines the speed of human recursive self-improvement? The main factor, I think, is how<span>&nbsp;</span>much new awesome you get from a given amount of awesome &ndash; the rate of compound interest on awesome. If being awesome causes you to become much more awesome, you will foom quickly, whereas if you get only a bit more awesome for each unit of awesome you have, you will foom slowly. If there's a set-point of awesomeness towards which you are attached like a spring, it will be very hard to foom. Each of these three situations often occurs in real life, for different types of awesome.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">I'm pretty sure that several people<span>&nbsp;</span>here on LW have had these human fooms, since, well, they've found LW. I've had a miniature human foom, and it's still ongoing. But it seems to me that this is <em>nothing</em> compared to what's out there.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\"><br /></span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">As with those of fooming AIs, the actions of fooming humans are hard to predict, and for the same reason: if you could predict what they'd do, you could probably do it yourself. Nevertheless, here are some ideas of what people far on in the fooming process might do:</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">They would practise extremely fine-tuned control of their own thought-processes; they would waste no thought-time. They could just sit&nbsp;and go into a thought trance, coming up with a brilliant new insight in seconds. When most people think, they're just <a href=\"/lw/l0/adaptationexecuters_not_fitnessmaximizers/\">executing adaptations, not optimizing utility</a>.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]--><span lang=\"EN-ZA\">They would be free of cognitive bias.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">They would have the ability to flat-out <em>ignore</em> pain. They would do everything the way cold, hard logic says is most efficient. They wouldn't ever sit, they would stand or run. They would run on a treadmill on one leg while listening to a French audiobook (despite not knowing French) while juggling 5 tennis balls with one hand while doing SRS reviews.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-top:0cm;margin-right:0cm;margin-bottom:0cm; margin-left:36.0pt;margin-bottom:.0001pt;text-indent:-18.0pt;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"font-family:OpenSymbol;mso-fareast-font-family:OpenSymbol; mso-bidi-font-family:OpenSymbol\" lang=\"EN-ZA\"><span>&bull;<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><span lang=\"EN-ZA\">To restate the previous bullet-point, they would have no akrasia. They would find those little<span>&nbsp;</span>voices at the backs of their heads that keep whispering for them to fail. They would drag out those little voices and kill them.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">Now, these things look unrealistic. But I think they' d all be achievable by any average LWer who committed themselves to this, and only this, for a year. I really mean that. And I have a feeling that <a href=\"/lw/2c/a_sense_that_more_is_possible/\">more</a>, <em>much</em> more, is possible.</span></p>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\">&nbsp;</p>\n<blockquote>\n<p class=\"MsoBodyText\" style=\"margin-bottom:0cm;margin-bottom:.0001pt\"><span lang=\"EN-ZA\">The whole universe sat there,<span style=\"color:blue\"> </span>open to the man who could make the right decisions. <br /> Frank Herbert, <em>Dune</em>, <a href=\"/lw/602/rationality_quotes_june_2011/4a9p\">as quoted by Nick_Roy</a></span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1, "WqLn4pAWi5hn6McHQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "j2v6yymMvzwczYXmg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 42, "baseScore": 28, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "10587", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pEbHHHR3aPLumaKJK", "guDcrPqLsnhEjrPZj", "fg9fXrHpeaDD6pEPL", "RzdPXLd2b6qmEB2mf", "PBRWb2Em5SNeWYwwB", "fhEPnveFhb9tmd7Pe", "baTWMegR42PAsH9qJ", "XPErvb8m9FapXCjhA", "Nu3wa6npK4Ry66vFp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T20:39:29.963Z", "modifiedAt": null, "url": null, "title": "META: Security Certificate", "slug": "meta-security-certificate", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spurlock", "createdAt": "2010-03-24T17:13:19.572Z", "isAdmin": false, "displayName": "Spurlock"}, "userId": "mK7rKWbkuoDsm3aQb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9d6djLs2PmZzhmxds/meta-security-certificate", "pageUrlRelative": "/posts/9d6djLs2PmZzhmxds/meta-security-certificate", "linkUrl": "https://www.lesswrong.com/posts/9d6djLs2PmZzhmxds/meta-security-certificate", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20META%3A%20Security%20Certificate&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMETA%3A%20Security%20Certificate%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9d6djLs2PmZzhmxds%2Fmeta-security-certificate%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=META%3A%20Security%20Certificate%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9d6djLs2PmZzhmxds%2Fmeta-security-certificate", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9d6djLs2PmZzhmxds%2Fmeta-security-certificate", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p>Just a heads up to the developers, who I assume check the Discussion section frequently. Anyway, each time I load a page on LW (using Opera) I get a security certificate error from api.viglink.com.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9d6djLs2PmZzhmxds", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "10588", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T21:13:46.568Z", "modifiedAt": null, "url": null, "title": "Better Disagreement", "slug": "better-disagreement", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:28.889Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FhH8m5n8qGSSHsAgG/better-disagreement", "pageUrlRelative": "/posts/FhH8m5n8qGSSHsAgG/better-disagreement", "linkUrl": "https://www.lesswrong.com/posts/FhH8m5n8qGSSHsAgG/better-disagreement", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Better%20Disagreement&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABetter%20Disagreement%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFhH8m5n8qGSSHsAgG%2Fbetter-disagreement%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Better%20Disagreement%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFhH8m5n8qGSSHsAgG%2Fbetter-disagreement", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFhH8m5n8qGSSHsAgG%2Fbetter-disagreement", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1058, "htmlBody": "<blockquote>\n<p>Honest disagreement is often a good sign of progress.</p>\n</blockquote>\n<p>- Gandhi</p>\n<p>&nbsp;</p>\n<p>Now that most communication is remote rather than face-to-face, people are comfortable disagreeing more often. How, then, can we disagree <em>well</em>? If the goal is intellectual progress, those who disagree should aim not for name-calling but for honest counterargument.</p>\n<p>To be more specific, we might use a <em>disagreement&nbsp;hierarchy</em>. Below is the&nbsp;hierarchy&nbsp;<a href=\"http://www.paulgraham.com/disagree.html\">proposed</a> by Paul Graham (with DH7 <a href=\"http://web.archive.org/web/20100328161823/http://www.acceleratingfuture.com/steven/?p=155\">added</a> by Black Belt Bayesian).<sup>1</sup></p>\n<p>&nbsp;</p>\n<p><strong>DH0: Name-Calling</strong>. The lowest form of disagreement, this ranges from \"u r fag!!!\" to \"He&rsquo;s just a troll\" to \"The author is a self-important dilettante.\"</p>\n<p><strong>DH1: Ad Hominem</strong>. An <a href=\"http://plover.net/~bonds/adhominem.html\">ad hominem</a> ('against the man') argument won&rsquo;t refute the original claim, but it might at least be relevant. If a senator says we should raise the salary of senators, you might reply: \"Of course he&rsquo;d say that; he&rsquo;s a senator.\" That might be relevant, but it <a href=\"http://www.paulgraham.com/disagree.html\">doesn&rsquo;t refute the original claim</a>: \"If there&rsquo;s something wrong with the senator&rsquo;s argument, you should say what it is; and if there isn&rsquo;t, what difference does it make that he&rsquo;s a senator?\"</p>\n<p><strong>DH2: Responding to Tone</strong>. At this level we actually respond to the writing rather than the writer, but we're responding to tone rather than substance. For example: \"It&rsquo;s terrible how flippantly the author dimisses theology.\"</p>\n<p><strong>DH3: Contradiction</strong>. Graham <a href=\"http://www.paulgraham.com/disagree.html\">writes</a>: \"In this stage we finally get responses to what was said, rather than how or by whom. The lowest form of response to an argument is simply to state the opposing case, with little or no supporting evidence.\" For example: \"It&rsquo;s terrible how flippantly the author dismisses theology. Theology is a legitimate inquiry into truth.\"</p>\n<p><strong>DH4: Counterargument</strong>. Finally, a form of disagreement that might persuade! Counterargument <a href=\"http://www.paulgraham.com/disagree.html\">is</a> \"contradiction plus reasoning and/or evidence.\" Still, counterargument is often directed at a minor point, or turns out to be an example of two people talking past each other, as in the <a href=\"/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">parable</a> about a tree falling in the forest.</p>\n<p><strong>DH5: Refutation</strong>. In refutation, you quote (or paraphrase) a precise claim or argument by the author and explain why the claim is false, or why the argument doesn&rsquo;t work. With refutation, you're sure to engage exactly what the author said, and offer a direct counterargument with evidence and reason.</p>\n<p><strong>DH6: Refuting the Central Point</strong>. Graham <a href=\"http://www.paulgraham.com/disagree.html\">writes</a>: \"The force of a refutation depends on what you refute. The most powerful form of disagreement is to refute someone&rsquo;s <em>central point</em>.\" A refutation of the central point may look like this: \"The author&rsquo;s central point appears to be X. For example, he writes 'blah blah blah.' He also writes 'blah blah.' But this is wrong, because (1) argument one, (2) argument two, and (3) argument three.\"</p>\n<p><strong>DH7: Improve the Argument, <em>then</em> Refute Its Central Point</strong>. Black Belt Bayesian <a href=\"http://web.archive.org/web/20100328161823/http://www.acceleratingfuture.com/steven/?p=155\">writes</a>: \"If you&rsquo;re interested in being on the right side of disputes, you will refute your opponents' arguments. But if you're interested in producing truth, you will fix your opponents' arguments for them. To win, you must fight not only the creature you encounter; you [also] must fight the most horrible thing that can be constructed from its corpse.\"<sup>2</sup> Also see: <a href=\"/lw/2k/the_least_convenient_possible_world/\">The Least Convenient Possible World</a>.</p>\n<p>&nbsp;</p>\n<p>Having names for <a href=\"http://en.wikipedia.org/wiki/List_of_cognitive_biases\">biases</a> and <a href=\"http://en.wikipedia.org/wiki/List_of_fallacies\">fallacies</a> can help us notice and correct them, and having labels for different kinds of disagreement can help us zoom in on the parts of a disagreement that matter.</p>\n<p><a id=\"more\"></a></p>\n<p>Let me illustrate by labeling excerpts from Alvin Plantinga's <a href=\"http://www.philvaz.com/apologetics/DawkinsGodDelusionPlantingaReview.pdf\">critical review</a> of&nbsp;Richard Dawkins' <a style=\"font-style: italic;\" href=\"http://www.amazon.com/God-Delusion-Richard-Dawkins/dp/0618918248/\">The God Delusion</a>.</p>\n<p><em>DH1, Ad Hominem</em>:</p>\n<blockquote>\n<p>Dawkins is not a philosopher... [and] you might say that some of his forays into philosophy are at best sophomoric, but that would be unfair to sophomores...</p>\n</blockquote>\n<p><em>DH2, Responding to Tone</em>:</p>\n<blockquote>\n<p>[In this book]&nbsp;the proportion&nbsp;of insult, ridicule, mockery, spleen, and vitriol is astounding. (Could it be that his mother,&nbsp;while carrying him, was frightened by an Anglican clergyman on the rampage?) If Dawkins&nbsp;ever gets tired of his day job, a promising future awaits him as a writer of political attack ads.</p>\n</blockquote>\n<p><em>DH4, Counterargument</em>:</p>\n<blockquote>\n<p>What is Dawkins' reply [to the fine-tuning argument]? He appeals to 'the anthropic principle,' the thought that... \"we could only be discussing&nbsp;the question in the kind of universe that was capable of producing us.\" ...But how does&nbsp;that so much as begin to explain why [<em>our</em>&nbsp;universe] is fine-tuned? One can't explain this by&nbsp;pointing out that we are indeed here &mdash; anymore than I can 'explain' the fact that God decided&nbsp;to create me (instead of passing me over in favor of someone else) by pointing out that if God had not thus decided, I wouldn't be here to raise that question.</p>\n</blockquote>\n<p><em>DH6, Refuting the Central Point</em>:</p>\n<blockquote>\n<p>Chapter 3, 'Why There Almost Certainly is No God,' is the heart of the book... [Dawkins says] the&nbsp;existence of God is monumentally improbable...&nbsp;So why does he think theism is enormously improbable? The answer: if there&nbsp;were such a person as God, he would have to be enormously complex, and the more complex&nbsp;something is, the less probable it is: \"However statistically improbable the entity you seek to&nbsp;explain by invoking a designer, the designer himself has got to be at least as improbable...\"</p>\n<p>...What can be said&nbsp;for this argument?&nbsp;Not much. First, is God complex? According to much classical theology... God is simple, and simple in a very strong sense...&nbsp;More remarkable, perhaps,&nbsp;is that according to Dawkins' own definition of complexity, God is not complex. According to&nbsp;[Dawkins] something is complex if it has parts that are \"arranged in a way that is unlikely to have arisen by chance alone.\" But of course God is a&nbsp;spirit, not a material object at all, and hence has no parts. Therefore,&nbsp;given the definition of complexity Dawkins himself proposes, God is not complex.<sup>3</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Of course, even a <em>DH6</em> or <em>DH7</em> disagreement can still be <em>wrong</em>. But at the very least, these labels can help us highlight the parts of a disagreement that matter for getting at the truth.</p>\n<p>Also see: <a href=\"/lw/12x/causes_of_disagreements/\">Causes of Disagreements</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>__________________</p>\n<p><sup>1</sup> This article is an update to my <a href=\"http://commonsenseatheism.com/?p=13435\">earlier post on <em>CSA</em></a>.</p>\n<p><sup>2</sup> Sometimes the term \"steel man\" is used to refer to a position's or argument's improved form. A <a href=\"http://en.wikipedia.org/wiki/Straw_man\">straw man</a> is a misrepresentation of someone's position or argument that is easy to defeat: a \"steel man\" is an improvement of someone's position or argument that is <em>harder</em>&nbsp;to defeat than their originally stated position or argument.</p>\n<p><sup>3</sup> For an example of <em>DH7</em>&nbsp;in action, see&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2009/12/Wielenberg-Dawkins-Gambit-Humes-Aroma-and-Gods-Simplicity.pdf\">Wielenberg (2009)</a>. Wielenberg, an atheist, tries to fix the deficiencies of Dawkins' central argument for atheism, and then shows that even this improved argument does not succeed.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RE6h98Ziwcfh4EP9T": 4, "wzgcQCrwKfETcBpR9": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FhH8m5n8qGSSHsAgG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 86, "extendedScore": null, "score": 0.0002097863926133931, "legacy": true, "legacyId": "10565", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 74, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 84, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["a7n8GdKiAZRX86T5A", "neQ7eXuaXpiYw7SBy", "DYWXntS3ybp8x3cKq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-24T23:00:37.924Z", "modifiedAt": null, "url": null, "title": "Naming the Highest Virtue of Epistemic Rationality", "slug": "naming-the-highest-virtue-of-epistemic-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:02.172Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "potato", "createdAt": "2011-06-15T09:18:51.735Z", "isAdmin": false, "displayName": "Ronny"}, "userId": "kY5hs2WkacnSZd937", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jm338rhCcAfczoEoR/naming-the-highest-virtue-of-epistemic-rationality", "pageUrlRelative": "/posts/jm338rhCcAfczoEoR/naming-the-highest-virtue-of-epistemic-rationality", "linkUrl": "https://www.lesswrong.com/posts/jm338rhCcAfczoEoR/naming-the-highest-virtue-of-epistemic-rationality", "postedAtFormatted": "Monday, October 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Naming%20the%20Highest%20Virtue%20of%20Epistemic%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANaming%20the%20Highest%20Virtue%20of%20Epistemic%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjm338rhCcAfczoEoR%2Fnaming-the-highest-virtue-of-epistemic-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Naming%20the%20Highest%20Virtue%20of%20Epistemic%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjm338rhCcAfczoEoR%2Fnaming-the-highest-virtue-of-epistemic-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fjm338rhCcAfczoEoR%2Fnaming-the-highest-virtue-of-epistemic-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 672, "htmlBody": "<p>Edit: Looking back at this a few years later. It is pretty embarrassing, but I'm going to leave it up.&nbsp;</p>\n<p>Why don't we start treating the log<sub>2</sub> of the probability &mdash; conditional on every available piece of information &mdash; you assign to <em>the great conjunction</em>, as the best measure of your epistemic success? Let's call:&nbsp; <em>log_2(P(the great conjunction|your available information))</em><em></em>, your \"Bayesian competence\". It is a deductive fact that no other proper scoring rule could possibly give: <em>Score(P(A|B)) + Score(P(B)) = Score(P(A&amp;B))</em>, and obviously, you should get the same score for assigning P(A|B) to A, after observing B, and assigning P(B) to B <em>a priori</em>, as you would get for assigning P(A&amp;B) to A&amp;B <em>a priori</em>. The great conjunction is the conjunction of all true statements expressible in your idiolect. Your available information may be treated as the ordered set of your retained stimulus.</p>\n<p>If this doesn't make sense, or you aren't familiar with these ideas, checkout <a href=\"http://yudkowsky.net/rational/technical\" target=\"_self\">Technical Explanation</a> after checking out <a href=\"http://yudkowsky.net/rational/bayes\" target=\"_self\">Intuitive Explanation</a>.</p>\n<p>It is standard LW doctrine that we should not name the highest value of rationality, and it is often defended quite brilliantly:</p>\n<blockquote>\n<p>You may try to name the highest principle with names such as &ldquo;the map that reflects the territory&rdquo; or &ldquo;experience of success and failure&rdquo; or &ldquo;Bayesian decision theory&rdquo;. But perhaps you describe incorrectly the nameless virtue. How will you discover your mistake? Not by comparing your description to itself, but by comparing it to that which you did not name.</p>\n</blockquote>\n<p>and of course also:</p>\n<blockquote>\n<p>How can you improve your conception of rationality? Not by saying to yourself, &ldquo;It is my duty to be rational.&rdquo; By this you only enshrine your mistaken conception. Perhaps your conception of rationality is that it is rational to believe the words of the Great Teacher, and the Great Teacher says, &ldquo;The sky is green,&rdquo; and you look up at the sky and see blue. If you think: &ldquo;It may look like the sky is blue, but rationality is to believe the words of the Great Teacher,&rdquo; you lose a chance to discover your mistake.&nbsp;</p>\n</blockquote>\n<p>These quotes are from the end of <a href=\"http://yudkowsky.net/rational/virtues\">Twelve Virtues</a></p>\n<p>Should we really be wondering if there's a virtue higher than bayesian competence? Is there really a probability worth worrying about that the description of bayesian competence above is misunderstood? Is the description not simple enough to be mathematical? What mistake might I discover in my understanding of bayesian competence by comparing it to that <em>which I did not name</em>, after I've already given a proof that bayesian competence is proper, and that the restrictions: <em>score(P(B)*P(A|B)) = score(P(B)) + score(P(A|B))</em>, and: <em>must be a proper scoring rule</em>, uniquely specify Log<sub>b</sub>?</p>\n<p>I really want answers to these questions. I am still undecided about them; and change my mind about them far too often.</p>\n<p>Of course, your bayesian competence is ridiculously difficult to compute. But I am not proposing the measure for practical reasons. I am proposing the measure to demonstrate that degree of rationality is an objective quantity that you could compute given the source code to the universe, even though there are likely no variables in the source that ever take on this value. This may be of little to no value to the most obsessively pragmatic practitioners of rationality. But it would be a very interesting result to philosophers of science and rationality.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Updated to better express view of author, and take feedback into account. Apologies to any commenter who's comment may have been nullified.</p>\n<p>The comment below:</p>\n<blockquote>\n<p>The general reason Eliezer advocates not naming the highest virtue (as I understand it) is that there may be some type of problem for which bayesian updating (and the scoring rule referred to) yields the wrong answer. This idea sounds rather improbable to me, but there is a non-negligible probability that bayes will yield a wrong answer on some question. Not naming the virtue is supposed to be a reminder that if bayes ever gives the wrong answer, we go with the right answer, not bayes.</p>\n</blockquote>\n<p>has changed my mind about the openness of the questions I asked.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jm338rhCcAfczoEoR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": -4, "extendedScore": null, "score": 7.890312897680027e-07, "legacy": true, "legacyId": "10590", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T03:00:45.814Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Protein Reinforcement and DNA Consequentialism", "slug": "seq-rerun-protein-reinforcement-and-dna-consequentialism", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aCRZZzQjmFBpN9oN7/seq-rerun-protein-reinforcement-and-dna-consequentialism", "pageUrlRelative": "/posts/aCRZZzQjmFBpN9oN7/seq-rerun-protein-reinforcement-and-dna-consequentialism", "linkUrl": "https://www.lesswrong.com/posts/aCRZZzQjmFBpN9oN7/seq-rerun-protein-reinforcement-and-dna-consequentialism", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Protein%20Reinforcement%20and%20DNA%20Consequentialism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Protein%20Reinforcement%20and%20DNA%20Consequentialism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaCRZZzQjmFBpN9oN7%2Fseq-rerun-protein-reinforcement-and-dna-consequentialism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Protein%20Reinforcement%20and%20DNA%20Consequentialism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaCRZZzQjmFBpN9oN7%2Fseq-rerun-protein-reinforcement-and-dna-consequentialism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaCRZZzQjmFBpN9oN7%2Fseq-rerun-protein-reinforcement-and-dna-consequentialism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<p>Today's post, <a href=\"/lw/l2/protein_reinforcement_and_dna_consequentialism/\">Protein Reinforcement and DNA Consequentialism</a> was originally published on 13 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Protein_Reinforcement_and_DNA_Consequentialism\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Brains made of proteins can learn much faster than DNA, but DNA does seem to be more adaptable. The complexity of the evolutionary hypothesis is so enormous that no species, other than humans, is capable of thinking it, and yet DNA seems to implicitly understand it. This happens because DNA is learns through the actual consequences, but protein brains can simply imagine the consequences.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/85s/seq_rerun_evolutionary_psychology/\">Evolutionary Psychology</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aCRZZzQjmFBpN9oN7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 7.891142428554608e-07, "legacy": true, "legacyId": "10597", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gTNB9CQd5hnbkMxAG", "ThsALeAjHSH27MhQL", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T09:48:05.940Z", "modifiedAt": null, "url": null, "title": "Introduction: \"Acrohumanity\"", "slug": "introduction-acrohumanity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:03.395Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Logos01", "createdAt": "2011-07-21T18:59:16.270Z", "isAdmin": false, "displayName": "Logos01"}, "userId": "WZxoXCWQviJp9dNc5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ehvonk4g5wDF5YEpn/introduction-acrohumanity", "pageUrlRelative": "/posts/ehvonk4g5wDF5YEpn/introduction-acrohumanity", "linkUrl": "https://www.lesswrong.com/posts/ehvonk4g5wDF5YEpn/introduction-acrohumanity", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Introduction%3A%20%22Acrohumanity%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntroduction%3A%20%22Acrohumanity%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fehvonk4g5wDF5YEpn%2Fintroduction-acrohumanity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Introduction%3A%20%22Acrohumanity%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fehvonk4g5wDF5YEpn%2Fintroduction-acrohumanity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fehvonk4g5wDF5YEpn%2Fintroduction-acrohumanity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 743, "htmlBody": "<p>Greetings, fellow LessWrongians.</p>\n<p>What follows is an as-yet poorly formed notion on my part that I am relating in an attempt to get at the meat of it and perhaps contribute to the higher-order goal of becoming a better rationalist myself. As such I will attempt to restrict any responses to comments I give to explanations of points of fact or explanations of my own opinions if directly requested, but otherwise will not argue any particulars for purposes of persuasion.</p>\n<p>For a few years now a general notion -- what originally led me to discover the LessWrong site itself, in fact -- has rattled around in my brain, which I only today have derived a sufficiently satisfactory term to label it with: \"acrohumanity\". This is a direct analogue to \"posthuman\" and \"transhuman\"; 'acro-' being a prefix meaning, essentially, \"highest\". So a strictly minimal definition of the term could be \"the highest of the humane condition\", or \"the pinnacle of humanity\".</p>\n<p>In brief, I describe acrohumanity as that state of achieving the maximum optimization of the human condition and capabilities *by* an arbitrary person that are available *to* that arbitrary person. I intentionally refrain from defining what form that optimization takes; but my own personal intuitions and opinions on the topic, as a life-long transhumanist and currently aspiring-rationalist, tend towards mental conditioning and improvements upon ways of thinking and optimization of thought, memory, and perception. \"Acrohumanism\", then, would be the belief in, practice of, and advocacy of achieving or approaching acrohumanity, in much the same way that transhumanism is the belief in or advocacy of achieving transhuman conditions. (In fact; I tend to associate the two terms, at least personally; what interests me *most* about transhumanism is achieving greater capacity for thought, recollection, and awareness than is humanly possible today.)</p>\n<p>Instrumental rationality is, thusly, a core component of any approach to the acrohuman condition/state. But while it is a requirement, it is not sufficient in and of itself to focus on one's capabilities as a rationalist. There are other avenues of optimization of the self that should also bear investigation. The simplest and most widely exercised of these is the practice of exercising the body; which does little to improve one's rationality and if one's primary goal is simply to become a better rationalist exercising does little to nothing to advance that goal. But if one's goal is to \"in general optimize yourself to the limits available\", exercising is just as key as focusing on instrumental rationality. Additional examples of a more cognitive nature could include techniques for improving recollection. Mnemotechnics has existed long enough that many cultures developed their own variants of it before they even developed a written language. It occurs to me that developing mnemotechnical skill would be convergent with becoming a better rationalist by making it easier to recall the various biases and heuristics we utilize in a broader array of contexts. Still another, also cognitive in nature, would be developing skill/practice in meditative reflection. While there is a lot of what Michael Shermer calls \"woo\" around meditation, the simple truth is that it is an effective tool for metacognition. My own history with meditative practice originated in my early-teens with martial arts training which I then extended into basic biofeedback as a result of coping with chronic pain. I quickly found that the same skill-level needed to achieve success in that arena had a wide array of applications, from coping with various stimuli to handling other physiological symptoms or indulging specific senses.</p>\n<p>Taken as an aggregate, an individual with strong skill in biofeedback, a history of rigorous exercise and physical health, skill and knowledge of instrumental rationality, mnemotechnics, metacognition, and through metacognition strong influence over his own emotional states (note; as I myself am male, I am in the habit of using masculine pronouns as gender-neutrals), represents an individual who is relatively far from what at least consists of my personal image of the baseline 'average human'. And yet I am certain that there might be other techniques or skillsets that one might add to his 'grab-bag' of tools for improving upon his own overall capabilities as a person -- none of which individually exceeding what is humanly possible, but definitely impressively approaching those limits when taken as a whole.</p>\n<p>I believe this is a topic that bears greater investigation and as such am sharing these rambling thoughts with you all. I am hopeful of a greatly productive conversation -- for others, and for myself.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ehvonk4g5wDF5YEpn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": -11, "extendedScore": null, "score": 7.892549916366988e-07, "legacy": true, "legacyId": "10602", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T19:53:28.982Z", "modifiedAt": null, "url": null, "title": "How Much Rent", "slug": "how-much-rent", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:34.317Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jCAQ2yyMaFwKMvtnk/how-much-rent", "pageUrlRelative": "/posts/jCAQ2yyMaFwKMvtnk/how-much-rent", "linkUrl": "https://www.lesswrong.com/posts/jCAQ2yyMaFwKMvtnk/how-much-rent", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Much%20Rent&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Much%20Rent%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjCAQ2yyMaFwKMvtnk%2Fhow-much-rent%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Much%20Rent%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjCAQ2yyMaFwKMvtnk%2Fhow-much-rent", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjCAQ2yyMaFwKMvtnk%2Fhow-much-rent", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 541, "htmlBody": "<p>Make beliefs <a href=\"http://wiki.lesswrong.com/wiki/Making_beliefs_pay_rent\">pay rent</a>. How much rent? Is it enough that they have some theoretical use in designing a GPS or predicting the cosmos? How much rent can actually be extracted from a belief?</p>\n<p>In a certain fantasy series, there is a special knowledge of a thing, called the name of the thing, that gives one predictive and manipulative power over it. For example, the protagonist, a young <del>rationalist</del> arcanist named Kvothe, learns the name of the wind and uses it to predict the movements of the leaves of a razor-sharp 'sword tree' well enough to walk through without getting cut.</p>\n<p>Another character, which we would recognize as a boxed malicious superintelligence, has the ability to predict <em>everything</em>. Simply talking to it allows it to manipulate your future to its twisted ends.</p>\n<p>At first these seem like the usual impossible fantasy magic, but why impossible? If a path exists, a good predictive model should find it.</p>\n<p>There's nothing that says the map can't match the territory to arbitrary precision. There's nothing that says beliefs have to just sit passively until they are brought up at a dinner party. But how much rent can <em>we</em> extract?</p>\n<p>We are not omniscient superintelligences, so the second power is closed to us for now. The first also seems off-limits, but consider that we do know the <a href=\"http://en.wikipedia.org/wiki/Navier-Stokes_equations\">name of the wind</a>. Our name of the wind and Kvothe's name of the wind are mathematically equivalent (in that the motion of the sword tree could be predicted by simulation of the wind using the NS equation). So why is it that Kvothe can walk through the leaves of the sword tree, but you, even knowing the NS equations as facts in your map, can not?</p>\n<p>Optimization. Algorithmization. Kvothe's name of the wind is optimised and algorithmised for <em>practical use</em>. Your name of the wind is sitting in your cache as a dumb fact ready to guess the password for \"how does wind work\". Kvothe is reeling in rent utilons while you congradulate yourself for having correct beliefs.</p>\n<p>So to collect rent from your beliefs, it is not enough to simply <em>know</em> some fact about the world. It has to be <em>implemented</em> by a good algorthim on the intuitive level. You have to be able to act and see through the wind the way a machinist can act through a lathe and a woodsman can see through footprints in the dirt. The way a surfer or skater can act through his board and see through the subtle vibrations and accelerations.</p>\n<p>I don't know if we can reach the level of intuitive causal modeling of the wind that Kvothe has. Maybe it's too hard to integrate such abstract models into system 1. Fluid dynamics is notoriously difficult even for computers. I do know that it's not enough to memorise the differential equations. You can get a lot further than that.</p>\n<p>So how much rent can you get from your beliefs? A good rent-paying belief should feel like an extension of your body; You should be able to see and act through your belief like it's another eye or arm. When thinking about how much rent can be extracted from a belief about something, think about what Kvothe would be able to do if he knew its true name.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jCAQ2yyMaFwKMvtnk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 12, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "10604", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T20:25:57.423Z", "modifiedAt": null, "url": null, "title": "Is math subjective?", "slug": "is-math-subjective", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:06.122Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TheatreAddict", "createdAt": "2011-05-01T17:03:11.634Z", "isAdmin": false, "displayName": "TheatreAddict"}, "userId": "xtL2cZS7kaFnSNLus", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N6BNWq6iP57BfJi9d/is-math-subjective", "pageUrlRelative": "/posts/N6BNWq6iP57BfJi9d/is-math-subjective", "linkUrl": "https://www.lesswrong.com/posts/N6BNWq6iP57BfJi9d/is-math-subjective", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20math%20subjective%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20math%20subjective%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6BNWq6iP57BfJi9d%2Fis-math-subjective%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20math%20subjective%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6BNWq6iP57BfJi9d%2Fis-math-subjective", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN6BNWq6iP57BfJi9d%2Fis-math-subjective", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 128, "htmlBody": "<p>I was arguing with a friend over whether reality is objective or subjective. He says subjective, because of the double-slit experiment, and that reality changes depending on whether we observe it or not, so it only exists in our minds.</p>\n<p>I know this is right.. But something still seems off to me.</p>\n<p>I said, well math is objective. But then he said that no, math is relative depending to where we are. In a black hole, math is different from on earth.</p>\n<p>So reality changes... depending on our location... Yes? No?</p>\n<p>I'm confused. I'm trying to write an essay on objective versus subjective reality, but I just keep getting mind-fucked.</p>\n<p>And yes, I've read some articles on LessWrong on this topic, but I couldn't exactly find one that fit my question completely. :/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N6BNWq6iP57BfJi9d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": -7, "extendedScore": null, "score": -1e-05, "legacy": true, "legacyId": "10605", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T22:31:15.700Z", "modifiedAt": null, "url": null, "title": "[FICTION] Hamlet and the Philosopher's Stone", "slug": "fiction-hamlet-and-the-philosopher-s-stone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:29.435Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HonoreDB", "createdAt": "2010-11-18T19:42:02.810Z", "isAdmin": false, "displayName": "HonoreDB"}, "userId": "7eyYSfGvgCur6pXmk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mWb2cCqjvjng7Pzcp/fiction-hamlet-and-the-philosopher-s-stone", "pageUrlRelative": "/posts/mWb2cCqjvjng7Pzcp/fiction-hamlet-and-the-philosopher-s-stone", "linkUrl": "https://www.lesswrong.com/posts/mWb2cCqjvjng7Pzcp/fiction-hamlet-and-the-philosopher-s-stone", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BFICTION%5D%20Hamlet%20and%20the%20Philosopher's%20Stone&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BFICTION%5D%20Hamlet%20and%20the%20Philosopher's%20Stone%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmWb2cCqjvjng7Pzcp%2Ffiction-hamlet-and-the-philosopher-s-stone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BFICTION%5D%20Hamlet%20and%20the%20Philosopher's%20Stone%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmWb2cCqjvjng7Pzcp%2Ffiction-hamlet-and-the-philosopher-s-stone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmWb2cCqjvjng7Pzcp%2Ffiction-hamlet-and-the-philosopher-s-stone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 511, "htmlBody": "<p><span style=\"font-family: Helvetica; font-size: 14px; \"> </span></p>\n<p><a href=\"http://www.makefoil.com\">So I did actually write it.</a><a id=\"more\"></a></p>\n<p>Its first title was <em>Rationalist Hamlet</em>, back when it was a short fan contribution to the <em><a href=\"http://www.fanfiction.net/s/5782108/64/Harry_Potter_and_the_Methods_of_Rationality\">Alternate Parallels</a>&nbsp;</em>section of <em>Harry Potter and the Methods of Rationality. &nbsp;</em>When I found myself actually trying to write the full thing, its working title became <em>A Will Most Incorrect to Heaven</em>. &nbsp;When I realized I was going to try to make it something approaching marketable, I saw that the only logical title was <em>Hamlet and the Philosopher's Stone</em>. &nbsp;But the actual, official title is, simply, <em>The Tragedy of Prince Hamlet and the Philosopher's Stone, or, A Will Most Incorrect to Heaven by William Shakespeare.</em></p>\n<p>It's a full-length play. &nbsp;I wrote it to be performable, but mostly I wrote it to be read. &nbsp;As of today, I'm self-publishing it and selling it as an e-book for $3.00 (that's the standard e-book price of $2.99, plus a cent to help people make a more rational purchasing decision). &nbsp;If you don't have a bank account <strong>and</strong> you have 50+ karma on this site, send me a private message with your email address. &nbsp;But I would prefer people paid for it (<a href=\"http://www.makefoil.com\">here's the link again</a>, <a href=\"http://www.makefoil.com/excerpt.html\">and here's an excerpt</a>). &nbsp;Charging may seem gauche, but I suspect there's the illusion of a social norm against charging for fanfiction just because it's normally illegal. &nbsp;This work is an exception: the <em>Harry Potter </em>content is purely allusive, and Shakespeare won't be complaining.</p>\n<p>The mission statement of the play is roughly the same as that of Methods of Rationality or Alicorn's Twilight re-imagining <em><a href=\"http://luminous.elcenia.com/\">Luminosity</a>. &nbsp;</em>The philosophy in it is of course my own, but I don't disagree on any major points with Eliezer. &nbsp;As with Methods, I've written it to be enjoyable to people who have no direct exposure to Shakespeare's&nbsp;<em>Hamlet </em>and also to Shakespeare aficionados who have never heard of Less Wrong or even of&nbsp;<em>Buffy the Vampire Slayer</em>. The play is a rewrite of <em>Hamlet</em> that preserves much of the original style, language, and plot, while injecting references to modern culture, epistemology, and ethics. It's perhaps what Shakespeare would have written, had he been simultaneously trying to appeal to audiences of both his time and our own. The Philosopher's Stone, for example, would be familiar to subjects of either Queen Elizabeth. The play's formatting is modeled after the way most of us encounter written Shakespeare: the spelling is updated and standardized, the stage directions are minimal and mostly of the sort that can be inferred from the dialogue, and the language is Elizabethan English from circa 1599; any anachronism is unintentional, aside from a certain wry punctuation mark and other allusions to future art. &nbsp;The only major change to the structure is the play's length: while unabridged productions of <em>Hamlet</em> can run up to five hours, the more concise <em>Tragedy of Prince Hamlet and the Philosopher's Stone, or, A Will Most Incorrect to Heaven by William Shakespeare</em> clocks in at well under two. &nbsp;Oh, and I changed all the words. &nbsp;There are only a few lines from the original in there.</p>\n<p>I'm eager, of course, for feedback. &nbsp;Hope you enjoy!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"etDohXtBrXd8WqCtR": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mWb2cCqjvjng7Pzcp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 49, "extendedScore": null, "score": 0.00011, "legacy": true, "legacyId": "10606", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 49, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T23:27:19.126Z", "modifiedAt": null, "url": null, "title": "Deviant argumentation regarding Monty Hall problem", "slug": "deviant-argumentation-regarding-monty-hall-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:25.600Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Craig_Heldreth", "createdAt": "2010-06-14T23:30:28.110Z", "isAdmin": false, "displayName": "Craig_Heldreth"}, "userId": "hhKowsjZBQSyBE6c5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wJKEfwuwmMPdsFTD4/deviant-argumentation-regarding-monty-hall-problem", "pageUrlRelative": "/posts/wJKEfwuwmMPdsFTD4/deviant-argumentation-regarding-monty-hall-problem", "linkUrl": "https://www.lesswrong.com/posts/wJKEfwuwmMPdsFTD4/deviant-argumentation-regarding-monty-hall-problem", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Deviant%20argumentation%20regarding%20Monty%20Hall%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADeviant%20argumentation%20regarding%20Monty%20Hall%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJKEfwuwmMPdsFTD4%2Fdeviant-argumentation-regarding-monty-hall-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Deviant%20argumentation%20regarding%20Monty%20Hall%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJKEfwuwmMPdsFTD4%2Fdeviant-argumentation-regarding-monty-hall-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwJKEfwuwmMPdsFTD4%2Fdeviant-argumentation-regarding-monty-hall-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 442, "htmlBody": "<p>In class number four of the online Artificial Intelligence course from Stanford, Peter Norvig explains \"one of the most popular problems in the subject of probability theory, the <a href=\"http://en.wikipedia.org/wiki/Monty_Hall_problem\">Monty Hall problem</a>\". His presentation was exactly what I have always been taught, and I got the right answer on the quiz.</p>\n<p>Hold; P(goat) = 2/3; P(car) = 1/3;</p>\n<p>Switch; P(goat) = 1/3; P(car) = 2/3.</p>\n<p>Since the last time I looked at that wikipedia article, a number of qualifications and stipulations and elaborations have been added. Apparently this problem has kept its popularity and controversy with undiminished vitality since around 20 years ago, when it was popularized by a national Sunday newspaper magazine columnist <a href=\"http://en.wikipedia.org/wiki/Marilyn_Vos_Savant\">Marilyn Vos Savant</a>. Her answer is the one above, which is also what I would call the least complicated wikipedia page answer (as the page sits today.)</p>\n<p>Now there is one probable error in Norvig's lecture. He claimed that Monty Hall didn't know the answer to his own problem, and quotes a letter he says was written by Monty Hall in 1990. If this is true, I find it impossible to follow the following <a href=\"http://www.nytimes.com/1991/07/21/us/behind-monty-hall-s-doors-puzzle-debate-and-answer.html?pagewanted=all&amp;src=pm\">New York Times story</a>, from 1991 where Monty explains all the subtleties of the problem in much shorter order than all of the complications on wikipedia. To summarize Monty's take: he is the carnival barker; it's his game; and he can change the rules in the middle of the game if he feels like making it more complicated than your five minute presentation for your students.</p>\n<p>But there is one critical element missing from all of the discussions I have seen to date, except for one which was told to me by a playfully deviant fellow many years ago. His argument is simple: if by this strategy a player can double his chances of winning, the players would have figured this out forthwith; everybody would have switched every time; and the drama and the fun would have been drained from the game. The fact is the show was the most popular game show in it's hay day. Ergo there cannot possibly be an easy way to game this strategy. My deviant probability theorist pal had confidence in Monty's game players to find any available edge.</p>\n<p>Also the data is in the archives. All you have to do is watch every episode and count the holds and switches and wins and losses and you will have a really high confidence estimation whether the correct answer is closer to 2/3 and 1/3 or is closer to .5 -- .5. If no statistician is interested in researching this, surely some enterprising historian of science or sociologist of science ought to be up for it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wJKEfwuwmMPdsFTD4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 1, "extendedScore": null, "score": 7.895381956087747e-07, "legacy": true, "legacyId": "10607", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-25T23:39:08.923Z", "modifiedAt": null, "url": null, "title": "How to Build Your Post", "slug": "how-to-build-your-post", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.416Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3FQZ84AJMqP8hLRnh/how-to-build-your-post", "pageUrlRelative": "/posts/3FQZ84AJMqP8hLRnh/how-to-build-your-post", "linkUrl": "https://www.lesswrong.com/posts/3FQZ84AJMqP8hLRnh/how-to-build-your-post", "postedAtFormatted": "Tuesday, October 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Build%20Your%20Post&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Build%20Your%20Post%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3FQZ84AJMqP8hLRnh%2Fhow-to-build-your-post%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Build%20Your%20Post%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3FQZ84AJMqP8hLRnh%2Fhow-to-build-your-post", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3FQZ84AJMqP8hLRnh%2Fhow-to-build-your-post", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 501, "htmlBody": "<p>LWers often <a href=\"/r/discussion/lw/81l/improving_my_writing_style/\">wonder</a>&nbsp;how to write a good post. <a href=\"/lw/86a/rhetoric_for_the_good/\">Many</a>&nbsp;<a href=\"/r/discussion/lw/81l/improving_my_writing_style/50lr \">great</a> tips and resources have been suggested already, mostly on the style and substance, not on the post structure. This is an attempt to fill some of the void using a construction toy metaphor:&nbsp;<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong>nested state-explain-summarize blocks</strong></span>.</p>\n<p>First, there is a convenient and versatile building block of non-fiction writing, often called the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Inverted_pyramid\">inverted pyramid</a>&nbsp;in the news business, though I think of it as more of a diamond when applied to technical writing in general:</p>\n<p style=\"padding-left: 90px; \"><img src=\"http://images.lesswrong.com/t3_82d_0.png?v=174bc634c7a3775d3056428e2abb21c4\" alt=\"\" width=\"249\" height=\"300\" /></p>\n<p>I have alluded to this&nbsp;<a href=\"/lw/730/overcoming_bias_in_others/4n38\">previously</a>&nbsp;in the context of an <a href=\"http://en.wikipedia.org/wiki/Elevator_pitch\">elevator pitch</a>. It is how most news stories are structured, and it follows the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Rule_of_three_(writing)\">rule of three</a>: the main point is first <strong>stated</strong>, then <strong>explained </strong>in some detail, then <strong>summarized</strong>. This is similar to how an oral presentation ought to be <a href=\"http://www.businesstown.com/presentations/present-tell.asp\">structured</a>.</p>\n<p>If any of these three gets too large, it can, in turn, be constructed of smaller diamonds. These building blocks can be combined and/or <strong>nested </strong>to build a complete post. If you want to make several points, it is a good idea to dedicate a diamond to each, and <strong>nest </strong>them into a larger one that provides the context,&nbsp;<strong>states </strong>the points at the top and <strong>summarizes </strong>them at the end:</p>\n<p style=\"padding-left: 90px;\"><img src=\"http://images.lesswrong.com/t3_82d_1.png?v=7a99230c4b1558552a602d7d62194181\" alt=\"\" width=\"275\" height=\"310\" /></p>\n<p>Why repeat the same point three times? I am no evolutionary psychologist or a cognitive scientist, but my feeling is that it is because people have to be <a href=\"http://en.wikipedia.org/wiki/Priming_(psychology)\">primed</a>&nbsp;to accept new information (hence the first two times). The third time is to make sure they retain what you've told them. In any case,&nbsp;<a href=\"/lw/eg/what_i_tell_you_three_times_is_true/\">what I tell you three times is true</a>&nbsp;tends to work.</p>\n<p>I am not pushing this format as the one true way of writing a post, just as a reliable way to get your point across. There are many ways of constructing short articles,&nbsp;<a title=\"Wikipedia:Writing better articles\" href=\"http://en.wikipedia.org/wiki/Wikipedia:Writing_better_articles#Structure_of_the_article\">this</a>&nbsp;is a good place to learn one of them. If you think that a short article format is too restrictive, then maybe the LW Discussion section is not the best venue for what you are writing. Consider starting your own blog (or writing a Wikipedia article) and linking to it. That said, I am yet to see a long <em>non-fiction</em> LW post&nbsp;(likely including this one)&nbsp;that cannot be improved by some ruthless trimming.</p>\n<p>The \"non-fiction\" qualifier is important: it is entirely possible to engage the reader using a fictional narrative. Eliezer does it quite successfully in the sequences, even in the long posts. However, this is an art, not a craft, and one would do well to master the craft first. My own attempt to post a bit of fiction here failed miserably.</p>\n<p>Again, this [meta]post is about the post <em>structure</em>: <strong>nested state-explain-summarize blocks</strong>&nbsp;(and the post itself is deliberately structured this way). I did not try to address the issue of content, partly because there has been so much said about it already, and partly because it would make this post too long to hold your attention.</p>\n<p>I hope to improve this post based on the feedback, provided there is enough interest.</p>\n<ul>\n</ul>\n<h6><span>This post has the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_test\">Flesch-Kincaid</a>&nbsp;readability&nbsp;<a href=\"http://www.standards-schmandards.com/exhibits/rix/index.php\">score</a></span><span>&nbsp; of 45 (accessible to a high-school&nbsp;</span>senior<span>).</span></h6>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3FQZ84AJMqP8hLRnh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 22, "extendedScore": null, "score": 4.3e-05, "legacy": true, "legacyId": "10453", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZAsbonw9sFQqCHMs8", "SiGY7aah56HvGXxBJ", "B4AyJXYPpGbBmxQzd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T03:05:56.549Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Thou Art Godshatter", "slug": "seq-rerun-thou-art-godshatter", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:03.512Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YgbMpYvW8mNaP3KcX/seq-rerun-thou-art-godshatter", "pageUrlRelative": "/posts/YgbMpYvW8mNaP3KcX/seq-rerun-thou-art-godshatter", "linkUrl": "https://www.lesswrong.com/posts/YgbMpYvW8mNaP3KcX/seq-rerun-thou-art-godshatter", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Thou%20Art%20Godshatter&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Thou%20Art%20Godshatter%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYgbMpYvW8mNaP3KcX%2Fseq-rerun-thou-art-godshatter%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Thou%20Art%20Godshatter%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYgbMpYvW8mNaP3KcX%2Fseq-rerun-thou-art-godshatter", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYgbMpYvW8mNaP3KcX%2Fseq-rerun-thou-art-godshatter", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 187, "htmlBody": "<p>Today's post, <a href=\"/lw/l3/thou_art_godshatter/\">Thou Art Godshatter</a> was originally published on 13 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Describes the evolutionary psychology behind the complexity of human values - how they got to be complex, and why, given that origin, there is no reason in hindsight to expect them to be simple. We certainly are not built to maximize genetic fitness.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/86d/seq_rerun_protein_reinforcement_and_dna/\">Protein Reinforcement and DNA Consequentialism</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YgbMpYvW8mNaP3KcX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 7.89613804005939e-07, "legacy": true, "legacyId": "10613", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cSXZpvqpa9vbGGLtG", "aCRZZzQjmFBpN9oN7", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T11:15:44.269Z", "modifiedAt": null, "url": null, "title": "On maximising expected value", "slug": "on-maximising-expected-value", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:19.860Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "thakil", "createdAt": "2011-01-13T15:46:17.550Z", "isAdmin": false, "displayName": "thakil"}, "userId": "zudPgERkLSB3LSvQz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wWu2f8veEFTQdFA8H/on-maximising-expected-value", "pageUrlRelative": "/posts/wWu2f8veEFTQdFA8H/on-maximising-expected-value", "linkUrl": "https://www.lesswrong.com/posts/wWu2f8veEFTQdFA8H/on-maximising-expected-value", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20maximising%20expected%20value&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20maximising%20expected%20value%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwWu2f8veEFTQdFA8H%2Fon-maximising-expected-value%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20maximising%20expected%20value%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwWu2f8veEFTQdFA8H%2Fon-maximising-expected-value", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwWu2f8veEFTQdFA8H%2Fon-maximising-expected-value", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 735, "htmlBody": "<p>One thing that tends to bug me about discourse round here is the notion that maximising one's expectation is the be all and end all of decisions one should make. Given any problem, one should look at it, and pick the course that maximising one's expectation. This usually ignores two major problems: what if my utility is non-linear, and what about risk aversion?</p>\n<p>Let&rsquo;s take an example: I bump into Omega, who offers me a choice: I can take a certain 1 unit of utility, or have a 1 in 10 million chance of getting 1 billion utility. The naive expectation maximiser will take that chance: after all, their expectation will be 100 units of utility, which is much better than a measly one! In all likelihood, our maximiser will walk away with nothing. It's certainly true that if this is repeated enough then we would expect our maximiser to be doing better... but a simple calculation reveals that it will have to occur around 7 million times for our maximiser to have a greater than 0.5 chance of having actually won (once or more times).</p>\n<p>This is a problem with tiny probabilities and large utilities: some justifications of cryonics have run along the lines of a Pascal&rsquo;s wager, where a small monetary investment gives one a massive utility, so large, in fact, that no matter how small the probability of cryonics it makes sense to invest. But if the probability becomes small enough, then I've probably just wasted a lot of money. After all, we only get to live once (Note that I am aware that some people have much higher probability estimates for cryonics, which is fine: I'm addressing those who do not).</p>\n<p>Without multiple repetition, risk aversion is, I would argue, an extremely sensible strategy for utility maximisation. Of course if one believes that one will be faced with a similar choice multiple times, then one can revert back to utility maximisation. As to when one should do this, I would probably encourage one to revert when the number of repetitions, N, is large enough so that the probability of an event occurring at least once has passed some threshold, p, decided by the user. Certainly p should probably be higher than 0.5.</p>\n<p>Lets now take another example: I am on Deal or No Deal, and there are three boxes left: $100000, $25000 and $.01. The banker has just given me a deal of $20000 (no doubt to much audience booing). Should I take that? Expected gains maximisation says certainly not! After all my expectation is more than double that offer! Risk aversion could be applied here, but I've actually got a good chance (0.66) of beating the bankers offer, so maybe its worth it? Except... well if I had $20000 dollars there&rsquo;s quite a lot I could do with that- perhaps its enough to get a mortgage on a house, or pay for that dream holiday I've always wanted. Sure, $100000 would be nice, but 1/3 of the time I'm going home with nothing- I've effectively lost that $20000 I wanted, and 1/3 of the time I'm only getting $5000 more, which isn't going to make a huge difference to me.</p>\n<p>Different amounts of money are valued very differently. The first million one earns will be quite a bit more important than the second million, and so on. Again, this is a perfectly reasonable criteria to have: the first amount of money lets us pay for things we need, the second for things we want, for a crude comparison. Yes, the banker is going to offer us below our expected gains, but his expectation is based on us valuing totals all the same. If that first $20,000 is what I really want, the utility of higher sums may be much smaller than one might consider. So again, naively maximising expectation could leave one disappointed.</p>\n<p>Obviously defining one's nonlinearity may be difficult. One of the advantages of trying to work out ones expected utility is it allows us to overwrite our brains, which don't necessarily always think very clearly about our expected gains, and allow us to do much better overall. But if we don't define our function carefully enough, then we are cheating ourselves. While I am not claiming that instinct is always correct about what will make us happy in the long run, using to simple a method to try and overwrite ourselves will not help.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wWu2f8veEFTQdFA8H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -9, "extendedScore": null, "score": 7.897832406266588e-07, "legacy": true, "legacyId": "10620", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T11:57:59.441Z", "modifiedAt": null, "url": null, "title": "Review of Lakoff & Johnson, 'Philosophy in the Flesh'", "slug": "review-of-lakoff-and-johnson-philosophy-in-the-flesh", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:19.231Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iwEDctfACQ6sQQk9j/review-of-lakoff-and-johnson-philosophy-in-the-flesh", "pageUrlRelative": "/posts/iwEDctfACQ6sQQk9j/review-of-lakoff-and-johnson-philosophy-in-the-flesh", "linkUrl": "https://www.lesswrong.com/posts/iwEDctfACQ6sQQk9j/review-of-lakoff-and-johnson-philosophy-in-the-flesh", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Review%20of%20Lakoff%20%26%20Johnson%2C%20'Philosophy%20in%20the%20Flesh'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReview%20of%20Lakoff%20%26%20Johnson%2C%20'Philosophy%20in%20the%20Flesh'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiwEDctfACQ6sQQk9j%2Freview-of-lakoff-and-johnson-philosophy-in-the-flesh%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Review%20of%20Lakoff%20%26%20Johnson%2C%20'Philosophy%20in%20the%20Flesh'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiwEDctfACQ6sQQk9j%2Freview-of-lakoff-and-johnson-philosophy-in-the-flesh", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiwEDctfACQ6sQQk9j%2Freview-of-lakoff-and-johnson-philosophy-in-the-flesh", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 536, "htmlBody": "<p>Lakoff &amp; Johnson's <em><a href=\"http://www.amazon.com/Philosophy-Flesh-Embodied-Challenge-Western/dp/0465056741/\">Philosophy in the Flesh</a></em>&nbsp;(1999) is an ambitious 550-page attempt to rewrite philosophy from scratch given what we now know from the cognitive sciences about how human reasoning works. After reading the first page, I had some hope it would be the book I could hand to somebody who wanted to study philosophy without being corrupted by studying 2500 years worth of <em>bad</em> methods and <em>wrong</em> answers.</p>\n<p>Yet, while I agree with the book in broad strokes and in many particular details, it has several weaknesses that make it difficult to engage at a technical level. These problems may be part of why the book has&nbsp;<a href=\"http://scholar.google.com/scholar?cites=8603317214855048583&amp;as_sdt=2005&amp;sciodt=0,5&amp;hl=en\">1400+ citations on Google Scholar</a> even though there are almost no books or articles that engage its contents in detail.</p>\n<p>The biggest problem is that Lakoff and Johnson cover too much ground, and therefore don't have the space to defend or even explain the precise nature of the thousands of claims they make in the book. E.g.: Several times per chapter, they claim that philosophers assume X without citing a single philosopher in the business of claiming X, or even someone <em>else</em> claiming that philosophers often assume X.</p>\n<p>The majority of the book (chapters 9-24) engages directly in what Eliezer calls \"dissolving the question\" &mdash; at least, the part where one explains the cognitive science of how particular philosophical confusions and debates arise. While these chapters are enlightening, they depend too heavily on the earlier account of metaphor, rarely draw upon other findings in cognitive science that are likely relevant, are sparse in scientific citations, and (as I've said) rarely cite actual philosophers claiming the things they say that philosophers claim.</p>\n<p>The authors are also too unclear about their positive project: \"embodied philosophy.\" Nowhere do they state the propositions that make up what they call \"embodied philosophy,\" nowhere do they explicate those propositions in precise detail, and nowhere do they defend those propositions in detail from misinterpretation and objection. The reader is left with only a vague sense of what they mean by embodied philosophy, or why it should be favored over other forms of <a href=\"http://www.amazon.com/Understanding-Naturalism-Movements-Modern-Thought/dp/1844650790/\">naturalistic philosophy</a> that <em>have</em>&nbsp;been defined and defended more precisely by their proponents. (Compare, for example, Bishop &amp; Trout's clear explication and defense of \"strategic reliabilism\" in <em><a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/\">Epistemology and the Psychology of Human Judgment</a></em>.)</p>\n<p>There are only two subjects the authors treat in sufficient detail. The first is the section on how thoroughly human thought is metaphorical, which builds on their earlier&nbsp;<em><a href=\"http://www.amazon.com/Metaphors-We-Live-George-Lakoff/dp/0226468011/\">Metaphors We Live By</a></em>&nbsp;(1980). This section (chapters 4 &amp; 5) is excellent, and worth reading if you read nothing else of the book.</p>\n<p>The other subject treated in sufficient detail is Noam Chomsky (chapter 22). This is not surprising because it is the other major subject of Lakoff's career. Lakoff has spent decades promoting his <a href=\"http://en.wikipedia.org/wiki/Generative_semantics\">generative semantics</a> over Chomsky's <a href=\"http://en.wikipedia.org/wiki/Generative_grammar\">generative grammar</a>.</p>\n<p>The book's deficiencies are frustrating to someone of a \"scholarly technical cogsci/philosophy\" bent like myself, but they may actually make the book <em>more</em>&nbsp;readable to those whose primary interest isn't&nbsp;technical philosophy. <em>Philosophy in the Flesh</em>&nbsp;is full of ideas, many of them correct or half-correct, and may be worth reading just to get a broad picture of what philosophy might look like when you start from scratch with the latest cognitive science.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4Kcm4etxAJjmeDkHP": 2, "GLykb6NukBeBQtDvQ": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iwEDctfACQ6sQQk9j", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 33, "extendedScore": null, "score": 5.7e-05, "legacy": true, "legacyId": "10621", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T14:57:57.244Z", "modifiedAt": null, "url": null, "title": "Singularity Summit - some videos", "slug": "singularity-summit-some-videos", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:08.210Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5zedPq39j6GSSCJ86/singularity-summit-some-videos", "pageUrlRelative": "/posts/5zedPq39j6GSSCJ86/singularity-summit-some-videos", "linkUrl": "https://www.lesswrong.com/posts/5zedPq39j6GSSCJ86/singularity-summit-some-videos", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20Summit%20-%20some%20videos&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20Summit%20-%20some%20videos%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5zedPq39j6GSSCJ86%2Fsingularity-summit-some-videos%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20Summit%20-%20some%20videos%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5zedPq39j6GSSCJ86%2Fsingularity-summit-some-videos", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5zedPq39j6GSSCJ86%2Fsingularity-summit-some-videos", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 10, "htmlBody": "<p>Someone posted what looks like unofficial videos from the Summit.&nbsp;<a href=\"http://www.youtube.com/user/thesingularitycom\">http://www.youtube.com/user/thesingularitycom</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5zedPq39j6GSSCJ86", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.89860133924123e-07, "legacy": true, "legacyId": "10622", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T16:38:16.977Z", "modifiedAt": null, "url": null, "title": "[MORESAFE] Starting global risk discussion", "slug": "moresafe-starting-global-risk-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.095Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "turchin", "createdAt": "2010-02-03T20:22:54.095Z", "isAdmin": false, "displayName": "turchin"}, "userId": "2kDfHyTEpYCoa2SRq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GCJpyCZYH9rhAWPnt/moresafe-starting-global-risk-discussion", "pageUrlRelative": "/posts/GCJpyCZYH9rhAWPnt/moresafe-starting-global-risk-discussion", "linkUrl": "https://www.lesswrong.com/posts/GCJpyCZYH9rhAWPnt/moresafe-starting-global-risk-discussion", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BMORESAFE%5D%20Starting%20global%20risk%20discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BMORESAFE%5D%20Starting%20global%20risk%20discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGCJpyCZYH9rhAWPnt%2Fmoresafe-starting-global-risk-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BMORESAFE%5D%20Starting%20global%20risk%20discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGCJpyCZYH9rhAWPnt%2Fmoresafe-starting-global-risk-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGCJpyCZYH9rhAWPnt%2Fmoresafe-starting-global-risk-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 676, "htmlBody": "<p>I am writing to propose an online discussion of global risk within the  discussion part of Less Wrong. We might call this discussion \"More  Safe\". In future it could be a site&nbsp; where anyone interested could discuss  global risks, possibly to aggregate all existing information about  global risks. The idea comes from discussions at the Singularity summit  that I had with Anna Solomon, Seth Baum, and others.<br /> <br /> I propose labeling such discussions \"More Safe\". Less wrong means more safe. Fewer mistakes means fewer catastrophes.<br /> <br /> At Seth's suggestion, we should be careful to follow safety guidelines  for such discussions. For example, no technical detail should be posted  online about topics which could be used by potential terrorists  especially in biology. The point of the discussion is to try to reduce  risk, not to have open discussion of risky ideas.<br /> <br /> Here are some further thoughts on my idea:<br /> <br /> Intelligence appeared as an instrument of adaptation which lead to longer survival of an individual or a small group. Unfortunately it was not adapted as an instrument for survival of technological civilizations. So we have to somehow update our intelligence. One way to do it is to reduce personal cognitive biases.</p>\n<p>Another way is to make our intelligence collective. Collective  intelligence is more effective in finding errors and equilibrium -  democracy and free markets are examples. Several people and organizations dedicated themselves to preventing existential risks.<br /> But we do not see a place which is accepted as main discussion point on existential risks.<br /> <br /> &nbsp;Lifeboat Foundation has a mailing list and blog, but its themes are not  strictly about existential risks (a lot of star travel) and no open  forum exists.<br /> <br /> Future of Humanity Institute has excellent collection of articles and  the book but it's not a place where people could meet online.<br /> <br /> Less Wrong was not specially dedicated to existential risks and many  risks are out of its main theme (nuclear, climate and so on).<br /> <br /> &nbsp;Immortality Institute has a subforum about global risks but it is not a professional discussing point.<br /> <br /> J.Hughes has a mailing list on existential risks [x-risk].<br /> <br /> The popular blog \"extinction protocol\" is full of fear mongering and  focuses mostly on natural disasters like earthquakes and floods.<br /> <br /> There are several small organizations which are created by one person and limited to a small website that nobody reads.<br /> <br /> So efforts of different researchers are scattered and lost in noise.<br /> <br /> In my view the collective intelligence as an instrument should consist of following parts:<br /> <br /> 1. An open-structured forum in which everyone could post but a strict  moderation policy should prevent any general discussion about Obama,  poverty, and other themes that are interesting but not related to  existential risks. It should have several level of accesses and several  levels of proof - strict science, hypotheses, and unprovable claims. I  think that such forum should be all inclusive, but niburu-stuff should  be moved in separate section for debunking.<br /> Good example of such organization is site flutrackers.com which is about flu.<br /> <br /> 2. Wiki-based knowledge base<br /> <br /> &nbsp;3. Small and effective board of experts who really take responsibility  to work on content ( but no paid stuff and fund rising problems). Also  there will be no head, otherwise it will not be effective collective  intelligence. All work for the site should be done on free volunteering.<br /> <br /> 4. Open complete library of all literature on existential risks.<br /> <br /> 5. The place should be friendly to other risks sites and should cross-link interesting posts there.<br /> <br /> &nbsp;In future the site will became a database of knowledge on global risks.<br /> <br /> Now i am going to start sequence of posts about main problems of global  risk prevention and i invite everyone to post about global risks under  'moresafe' tag.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GCJpyCZYH9rhAWPnt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 7, "extendedScore": null, "score": 7.898948549691713e-07, "legacy": true, "legacyId": "10623", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T17:11:00.875Z", "modifiedAt": null, "url": null, "title": "Official videos from the Singularity Summit", "slug": "official-videos-from-the-singularity-summit", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:54.014Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hGZL7ZuDgp9Wecxs2/official-videos-from-the-singularity-summit", "pageUrlRelative": "/posts/hGZL7ZuDgp9Wecxs2/official-videos-from-the-singularity-summit", "linkUrl": "https://www.lesswrong.com/posts/hGZL7ZuDgp9Wecxs2/official-videos-from-the-singularity-summit", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Official%20videos%20from%20the%20Singularity%20Summit&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOfficial%20videos%20from%20the%20Singularity%20Summit%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhGZL7ZuDgp9Wecxs2%2Fofficial-videos-from-the-singularity-summit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Official%20videos%20from%20the%20Singularity%20Summit%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhGZL7ZuDgp9Wecxs2%2Fofficial-videos-from-the-singularity-summit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhGZL7ZuDgp9Wecxs2%2Fofficial-videos-from-the-singularity-summit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.youtube.com/user/SingularitySummits#p/u/2/mD2dgWWmAu8\">Here.</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hGZL7ZuDgp9Wecxs2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 7.899061830641039e-07, "legacy": true, "legacyId": "10624", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T17:38:57.622Z", "modifiedAt": null, "url": null, "title": "[LINK] Non-Conformists Better At Working Toward Common Good", "slug": "link-non-conformists-better-at-working-toward-common-good", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:03.973Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nrh2SCjJ4Hi4QmyPt/link-non-conformists-better-at-working-toward-common-good", "pageUrlRelative": "/posts/nrh2SCjJ4Hi4QmyPt/link-non-conformists-better-at-working-toward-common-good", "linkUrl": "https://www.lesswrong.com/posts/nrh2SCjJ4Hi4QmyPt/link-non-conformists-better-at-working-toward-common-good", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Non-Conformists%20Better%20At%20Working%20Toward%20Common%20Good&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Non-Conformists%20Better%20At%20Working%20Toward%20Common%20Good%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fnrh2SCjJ4Hi4QmyPt%2Flink-non-conformists-better-at-working-toward-common-good%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Non-Conformists%20Better%20At%20Working%20Toward%20Common%20Good%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fnrh2SCjJ4Hi4QmyPt%2Flink-non-conformists-better-at-working-toward-common-good", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fnrh2SCjJ4Hi4QmyPt%2Flink-non-conformists-better-at-working-toward-common-good", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<p>First read about this on <a href=\"http://www.parapundit.com/archives/008334.html\">Para Pundit</a>, relevant link <a href=\"http://www.eurekalert.org/pub_releases/2011-08/uoea-sfc080111.php\">here</a>.</p>\n<blockquote>\n<p>If you follow the pack are you more likely to co-operate with others in it? Not necessarily according to research into social behaviour by academics at the University of East Anglia.</p>\n<p>The study, published in the August issue of the journal <em>Personality and Individual Differences</em>, shows that people who do not conform are most likely to work together for the greater good, while conforming to social norms can actually make people less likely to co-operate &ndash; a finding which surprised the researchers and could have implications in the workplace for team design and operations management.</p>\n</blockquote>\n<blockquote>\n<p>\"Here we've got a measure of people's co-operation, which could apply to any situation where you've two or more people who are trying to co-operate in an activity. For example in a work setting, if you are part of a team working on a project you expect everyone to put the same effort in to the task. <strong>The expectation is that people who are high in social desirability will conform to the effort other people are putting into the task, but actually the conforming people may be less helpful because they take their cue from the less helpful members of the team. They are conforming to the person who is not necessarily working that hard.\"</strong></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nrh2SCjJ4Hi4QmyPt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 16, "extendedScore": null, "score": 7.899158550444836e-07, "legacy": true, "legacyId": "10627", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T18:52:24.123Z", "modifiedAt": null, "url": null, "title": "Rhetoric for the Good", "slug": "rhetoric-for-the-good", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:03.061Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SiGY7aah56HvGXxBJ/rhetoric-for-the-good", "pageUrlRelative": "/posts/SiGY7aah56HvGXxBJ/rhetoric-for-the-good", "linkUrl": "https://www.lesswrong.com/posts/SiGY7aah56HvGXxBJ/rhetoric-for-the-good", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rhetoric%20for%20the%20Good&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARhetoric%20for%20the%20Good%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSiGY7aah56HvGXxBJ%2Frhetoric-for-the-good%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rhetoric%20for%20the%20Good%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSiGY7aah56HvGXxBJ%2Frhetoric-for-the-good", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSiGY7aah56HvGXxBJ%2Frhetoric-for-the-good", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1341, "htmlBody": "<p>The topics of rationality and existential risk reduction need their own Richard Dawkins. Their own Darwin. Their own Voltaire.</p>\n<p>Rhetoric moves minds.</p>\n<p>Students and masochists aside, people read only what is exciting. So: Want to make an impact? Be exciting. You must be heard before you can turn heads in the right direction.</p>\n<p>Thus, I've decided to <a href=\"/lw/un/on_doing_the_impossible/\">try harder</a> and <em>actually put effort into the quality of my writing</em> instead of just cranking stuff out quickly so I can <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">fill in inferential gaps and get to the cutting edge</a> of the research subjects I care about.</p>\n<p>That's why I asked LWers for their picks of <a href=\"/r/discussion/lw/85f/best_nonfiction_writing_on_less_wrong/\">best nonfiction writing on Less Wrong</a>.</p>\n<p>It's also why I've been reading lots of good science writing, focusing on those who manage to be exciting while covering fairly complex subjects: <a href=\"http://www.amazon.com/Unweaving-Rainbow-Science-Delusion-Appetite/dp/0618056734/\">Dawkins</a>, <a href=\"http://www.amazon.com/Demon-Haunted-World-Science-Candle-Dark/dp/0345409469/\">Sagan</a>, <a href=\"http://www.amazon.com/Information-History-Theory-Flood/dp/0375423729/\">Gleick</a>,&nbsp;<a href=\"http://carlzimmer.com/\">Zimmer</a>,&nbsp;<a href=\"http://www.amazon.com/Believing-Brain-Conspiracies---How-Construct-Reinforce/dp/0805091254/\">Shermer</a>, <a href=\"http://www.amazon.com/Tell-Tale-Brain-Neuroscientists-Quest-Makes/dp/0393077829/\">Ramachandran</a>, <a href=\"http://www.amazon.com/Stiff-Curious-Lives-Human-Cadavers/dp/0393324826/\">Roach</a>,&nbsp;<a href=\"http://www.amazon.com/Minds-Eye-Vintage-Oliver-Sacks/dp/0307473023/\">Sacks</a>, <a href=\"http://www.amazon.com/Universe-Nutshell-Stephen-William-Hawking/dp/055380202X/\">Hawking</a>, <a href=\"http://www.amazon.com/Hidden-Reality-Parallel-Universes-Cosmos/dp/0307265633/\">Greene</a>, <a href=\"http://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567/\">Hofstadter</a>, <a href=\"http://www.amazon.com/Cycles-Time-Extraordinary-View-Universe/dp/0307265900/\">Penrose</a>, <a href=\"http://www.amazon.com/Evolution-Everyone-Darwins-Theory-Change/dp/0385340923/\">Wilson</a>, <a href=\"http://www.amazon.com/Surely-Feynman-Adventures-Curious-Character/dp/0393316041/\">Feynman</a>, <a href=\"http://www.amazon.com/Physics-Future-Science-Shape-Destiny/dp/0385530803/\">Kaku</a>, <a href=\"http://www.amazon.com/Richness-Life-Essential-Stephen-Gould/dp/0393064980/\">Gould</a>, <a href=\"http://www.amazon.com/Short-History-Nearly-Everything/dp/0767908171/\">Bryson</a>, <a href=\"http://www.amazon.com/Better-Angels-Our-Nature-Violence/dp/0670022950/\">Pinker</a>, <a href=\"http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748/\">Kurzban</a>, and <a href=\"http://www.amazon.com/Oxford-Book-Modern-Science-Writing/dp/0199216819/\">others</a>.</p>\n<p>I've also been re-reading lots of books and articles on how to write well: <em><a href=\"http://www.amazon.com/Keys-Great-Writing-Stephen-Wilbers/dp/1582974926/\">Keys to Great Writing</a></em>, <em><a href=\"http://www.amazon.com/Style-Lessons-Clarity-Grace-10th/dp/0205747469/\">Style: Lessons in Clarity and Grace</a></em>,&nbsp;<em><a href=\"http://www.amazon.com/Elements-Style-50th-Anniversary/dp/0205632645/\">Elements of Style</a></em>, <em><a href=\"http://www.amazon.com/Writing-Well-30th-Anniversary-Nonfiction/dp/0060891548/\">On Writing Well</a></em>, <em><a href=\"http://www.amazon.com/Classic-Guide-Better-Writing-Step-/dp/0062730487/\">The Classic Guide to Better Writing</a></em>, <em><a href=\"http://www.amazon.com/Book-Writing-Ultimate-Guide-Well/dp/0966517695/\">The Book on Writing</a></em>,&nbsp;<em><a href=\"http://www.amazon.com/Telling-True-Stories-Nonfiction-Foundation/dp/0452287553/\">Telling True Stories</a></em>, <em><a href=\"http://www.amazon.com/Writing-Tools-Essential-Strategies-Writer/dp/0316014990/\">Writing Tools</a></em>, <em><a href=\"http://www.amazon.com/Ideas-into-Words-Mastering-Science/dp/0801873304/\">Ideas into Words</a></em>, <em><a href=\"/The Chicago Guide to Communicating Science\">The Chicago Guide to Communicating Science</a></em>,&nbsp;<em><a href=\"/A Field Guide for Science Writers\">A Field Guide for Science Writers</a></em>,&nbsp;<a href=\"http://michaelnielsen.org/blog/six-rules-for-rewriting/\">Six Rules for Rewriting</a>, <a href=\"http://www.paulgraham.com/writing44.html\">Writing, Briefly</a>, and&nbsp;<a href=\"http://www.acceleratingfuture.com/wiki/Singularity_Writing_Advice\">Singularity Writing Advice</a>. (Conversations with Eliezer also helped.)</p>\n<p>I don't know if I can become the Voltaire of rationality and existential risk reduction, but it seems worth a shot. Every improvement in writing style is beneficial even if my starry goal is never met. Also, it appears I produce better writing <em>without</em> really trying than most people produce <em>with</em>&nbsp;trying. (If you've ever had to grade essays by honors English seniors, you'll know what I mean.) I expect to gain more by striving where I already excel than by pushing where I have little natural talent.</p>\n<p>(I won't try to write <em>everything</em>&nbsp;well. Sometimes I <em>should</em> just crank things out. To be honest, I didn't spend much time optimizing <em>this</em> post.)</p>\n<p>My other hope is that a few other writers decide <em>they</em> would like to be the Voltaire of rationality and/or existential risk reduction. May this post be useful to them. It's a list of recommendations on writing style pulled from many sources, in no particular order.</p>\n<p><a id=\"more\"></a></p>\n<ol>\n<li>Begin <em><a href=\"http://en.wikipedia.org/wiki/In_medias_res\">in medias res</a></em>&nbsp;(in the middle of things). Begin with movement. Excitement. Humor. Surprise. Insight. Explosions.</li>\n<li>Open with a question, and make your readers want to know the answer. Give the answer near the end.</li>\n<li>Outline with punchlines, not topics. A punchline is something that makes the reader feel: \"Aha! I sure am glad I read <em>that</em>&nbsp;sentence.\"</li>\n<li>Tell stories about characters taking actions. Make the reader laugh and cry and sit in suspense at what will happen next.</li>\n<li>Every sentence should make the reader want to read the next sentence. End each paragraph in a way that makes the reader want to continue. End each section by posing an intriguing question answered in the next section. The moment your reader becomes bored is the moment she jumps to YouTube. Cats and skateboard accidents are more exciting than science and philosophy, even for Judea Pearl.</li>\n<li>Prefer brevity. Cut what isn't needed, or at least move it to an endnote.</li>\n<li>Always be wary of how much disbelief you're creating in the average reader, and keep that level low. You may need to add words and paragraphs to satisfy his or her skepticism. Don't merely state facts that your reader may disbelieve. Briefly describe an experiment that supports the fact. If you must say something that will trigger serious skepticism, build up lots of credibility first.</li>\n<li>Think through the post's emotional arc. In most cases, you'll want to keep readers happy, excited, and hopeful. In an article about effective charity, do not open with an example from Africa, because the words \"Africa\" and \"charity\" bring up feelings of guilt and hopelessness.</li>\n<li>Make positive points, not negative ones. Avoid \"<a href=\"http://xkcd.com/386/\">Someone is <em>wrong</em></a> in a journal!\" Say instead: \"Here's a solution to an old problem.\"</li>\n<li>Use a concrete-then-abstract pattern to pull readers forward. Start with a concrete example, probably more concrete than you feel it needs to be, and then make the more general point.</li>\n<li>When possible, let sentences point not just to the next sentence or paragraph, but to future sections.</li>\n<li>Favor surprise, as long as it doesn't engender too much disbelief. Avoid anything that lets the reader think, \"I could have written that sentence.\" Avoid clich&eacute;s.</li>\n<li>Write in the active voice when possible.</li>\n<li>Almost always list things in threes, in ascending order of the word length of the list item.</li>\n<li>Make sure your readers always know that the next paragraph and section will be valuable and exciting.</li>\n<li>Know your intended audience. Learn how they think and what they like to read. Tailor your writing to them.</li>\n<li>Beware the <a href=\"/lw/ke/illusion_of_transparency_why_no_one_understands/\">illusion of transparency</a> and <a href=\"/lw/kg/expecting_short_inferential_distances/\">unexpectedly large inferential gaps</a>. Due to these errors, <a href=\"/lw/kh/explainers_shoot_high_aim_low/\">writing aimed at high schoolers will hit university seniors</a>.</li>\n<li>Use pictures.</li>\n<li>Avoid <a href=\"http://www.kristisiegel.com/CXC/engfish2.htm\">Engfish</a>.</li>\n<li>Check the <a href=\"http://www.read-able.com/\">readability score</a> of your writing. I aim for a Gunning Fog score between 8 and 13.</li>\n<li>Shorten your sentences and paragraphs. Replace semicolons with periods.</li>\n<li>Today's readers do not read. They <em>scan</em>. Make your text <a href=\"http://www.useit.com/alertbox/9710a.html\">scannable</a>.</li>\n<li>Distill significant ideas into potent, quotable sentences: \"The AI does not hate you, nor does it love you, but you are made of atoms it can use for something else.\"</li>\n<li>Identify every verb and ask if you can improve it, preferably in a way that lets you kill nearby adjectives and adverbs.</li>\n<li>Avoid simple mistakes of spelling, tense, etc.</li>\n<li>Find graceful ways to route around the horrors of the English language, like its lack of a gender-neutral personal pronoun.</li>\n<li><a href=\"http://commonsenseatheism.com/?p=15963\">Write in plain talk</a>. When possible, use small, old, Germanic words.</li>\n<li>Say aloud, to a friend or a stuffed animal, what you want to write. Write down what you said. After revising, read aloud and revise whatever sounds weird when spoken.</li>\n<li>Write and revise weeks in advance. Avoid the piece for a week. Then come back and revise again.</li>\n<li>As Paul Graham <a href=\"http://www.paulgraham.com/writing44.html\">says</a>:&nbsp;\"Write for a reader who won't read the essay as carefully as you do, just as pop songs are designed to sound ok on crappy car radios.\" Hold their hand every step of the way. Remind them of what you just said, and tell them how each section fits into your larger points.</li>\n<li>Include human dialogue where possible. Spoken words are more natural to us than crafted prose, even though spoken words are inefficient.</li>\n<li>Show a very late draft to friends and ask which parts bore or confuse. Revise. If you find a good reader, bribe them to do you this favor again and again.</li>\n<li>Put the most impacting words at the end of a sentence.</li>\n<li>Follow the <a href=\"http://en.wikipedia.org/wiki/Made_to_Stick\">SUCCESS formula</a>. Express your ideas with&nbsp;<strong>S</strong>imple (find the core), <strong>U</strong>nexpected, <strong>C</strong>oncrete, <strong>C</strong>redible, <strong>E</strong>motional&nbsp;<strong>S</strong>tories.</li>\n<li>Imitate great writers who write to your audience.</li>\n<li>Build the reader's <em>stake</em>&nbsp;in your subject by writing about things that relate to their own lives, goals, dreams, and fears.</li>\n<li>Shape your reader's expectations so that when you get to Part B, you know what their next question is, and you can answer it. Otherwise they may have number of possible next questions or next objections, and you can't possibly answer them all.</li>\n<li>When introducing a new idea, open the sentence with old information and put the new stuff at the end.</li>\n<li>Obey these rules before you obey grammarians who say things like \"Don't split infinitives\" or \"Don't begin sentences with And or But\" and \"Don't end a sentence with a preposition.\"</li>\n</ol>\n<p>And, just one piece of <em>process</em> advice. Do not apply any of these rules while drafting. Instead, write down whatever horrible shit comes out of you and do it quickly. Then revise, revise, revise.</p>\n<p>Now: What are <em>your</em> favorite pieces of writing advice?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7mTviCYysGmLqiHai": 2, "GQyPQcdEQF4zXhJBq": 1, "XYHzLjwYiqpeqaf4c": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SiGY7aah56HvGXxBJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 72, "baseScore": 77, "extendedScore": null, "score": 0.000161, "legacy": true, "legacyId": "10594", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 77, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 292, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fpecAJLG9czABgCe9", "hN2aRnu798yas5b2k", "cijurJhuz22ACCQgX", "sSqoEw9eRP2kPKLCz", "HLqWn5LASfhhArZ7w", "2TPph4EGZ6trEbtku"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-26T20:18:50.267Z", "modifiedAt": null, "url": null, "title": "Meetup : First Zurich LW Meetup", "slug": "meetup-first-zurich-lw-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.702Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Wakefield", "createdAt": "2011-10-18T16:23:10.511Z", "isAdmin": false, "displayName": "Wakefield"}, "userId": "bWJtCTuFjew3Bq9BD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3nxGhiyqmZDdHhYKA/meetup-first-zurich-lw-meetup", "pageUrlRelative": "/posts/3nxGhiyqmZDdHhYKA/meetup-first-zurich-lw-meetup", "linkUrl": "https://www.lesswrong.com/posts/3nxGhiyqmZDdHhYKA/meetup-first-zurich-lw-meetup", "postedAtFormatted": "Wednesday, October 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20First%20Zurich%20LW%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20First%20Zurich%20LW%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3nxGhiyqmZDdHhYKA%2Fmeetup-first-zurich-lw-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20First%20Zurich%20LW%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3nxGhiyqmZDdHhYKA%2Fmeetup-first-zurich-lw-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3nxGhiyqmZDdHhYKA%2Fmeetup-first-zurich-lw-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4h'>First Zurich LW Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 November 2011 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">near Sihlcity, Zurich</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>For any Zurich-based LWers - let's meet up. I suggest resilience as a topic for discussion. Afterwards, we can figure out whether to do something more regularly.</p>\n\n<p>Meet in our offices near Sihlcity between 2-3pm, then head out for food/drink depending on interests.</p>\n\n<p>PM me for exact address and contact details if you would like to attend.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4h'>First Zurich LW Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3nxGhiyqmZDdHhYKA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 7.899711923622644e-07, "legacy": true, "legacyId": "10629", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___First_Zurich_LW_Meetup\">Discussion article for the meetup : <a href=\"/meetups/4h\">First Zurich LW Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 November 2011 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">near Sihlcity, Zurich</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>For any Zurich-based LWers - let's meet up. I suggest resilience as a topic for discussion. Afterwards, we can figure out whether to do something more regularly.</p>\n\n<p>Meet in our offices near Sihlcity between 2-3pm, then head out for food/drink depending on interests.</p>\n\n<p>PM me for exact address and contact details if you would like to attend.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___First_Zurich_LW_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/4h\">First Zurich LW Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : First Zurich LW Meetup", "anchor": "Discussion_article_for_the_meetup___First_Zurich_LW_Meetup", "level": 1}, {"title": "Discussion article for the meetup : First Zurich LW Meetup", "anchor": "Discussion_article_for_the_meetup___First_Zurich_LW_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T00:55:28.526Z", "modifiedAt": null, "url": null, "title": "The time has come to talk of whether pigs have wings", "slug": "the-time-has-come-to-talk-of-whether-pigs-have-wings", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:03.985Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lessdazed", "createdAt": "2011-02-02T05:06:52.010Z", "isAdmin": false, "displayName": "lessdazed"}, "userId": "ehZzKt5ByYBeyCLkz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EjZ6WgmMdvo4zYLyi/the-time-has-come-to-talk-of-whether-pigs-have-wings", "pageUrlRelative": "/posts/EjZ6WgmMdvo4zYLyi/the-time-has-come-to-talk-of-whether-pigs-have-wings", "linkUrl": "https://www.lesswrong.com/posts/EjZ6WgmMdvo4zYLyi/the-time-has-come-to-talk-of-whether-pigs-have-wings", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20time%20has%20come%20to%20talk%20of%20whether%20pigs%20have%20wings&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20time%20has%20come%20to%20talk%20of%20whether%20pigs%20have%20wings%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEjZ6WgmMdvo4zYLyi%2Fthe-time-has-come-to-talk-of-whether-pigs-have-wings%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20time%20has%20come%20to%20talk%20of%20whether%20pigs%20have%20wings%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEjZ6WgmMdvo4zYLyi%2Fthe-time-has-come-to-talk-of-whether-pigs-have-wings", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEjZ6WgmMdvo4zYLyi%2Fthe-time-has-come-to-talk-of-whether-pigs-have-wings", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 26, "htmlBody": "<p>Let's refine each other's understanding of biological evolution, as encapsulated as best we can manage in a short comment.</p>\n<p>It's time to be lesswrong. Starting with me.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EjZ6WgmMdvo4zYLyi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": -2, "extendedScore": null, "score": 7.900669593763243e-07, "legacy": true, "legacyId": "10630", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T02:03:48.857Z", "modifiedAt": null, "url": null, "title": "Rival formalizations of a decision problem", "slug": "rival-formalizations-of-a-decision-problem", "viewCount": null, "lastCommentedAt": "2019-01-03T11:26:47.392Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/o3oQ9ShvHBvEzf34t/rival-formalizations-of-a-decision-problem", "pageUrlRelative": "/posts/o3oQ9ShvHBvEzf34t/rival-formalizations-of-a-decision-problem", "linkUrl": "https://www.lesswrong.com/posts/o3oQ9ShvHBvEzf34t/rival-formalizations-of-a-decision-problem", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rival%20formalizations%20of%20a%20decision%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARival%20formalizations%20of%20a%20decision%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo3oQ9ShvHBvEzf34t%2Frival-formalizations-of-a-decision-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rival%20formalizations%20of%20a%20decision%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo3oQ9ShvHBvEzf34t%2Frival-formalizations-of-a-decision-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fo3oQ9ShvHBvEzf34t%2Frival-formalizations-of-a-decision-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 427, "htmlBody": "<p>Decision theory is not one of my strengths, and I have a question about it.</p>\n<p>Is there a consensus view on how to deal with the problem of \"rival formalizations\"? <a href=\"http://www.amazon.com/Introduction-Decision-Cambridge-Introductions-Philosophy/dp/0521888379/\">Peterson (2009)</a> illustrates the problem like this:</p>\n<blockquote>\n<p>Imagine that you are a paparazzi photographer and that rumour has it that actress Julia Roberts will show up in either New York (NY), Los Angeles (LA) or Paris (P). Nothing is known about the probability of these states of the world. You have to decide if you should stay in America or catch a plane to Paris. If you stay and [she] shows up in Paris you get $0; otherwise you get your photos, which you will be able to sell for $10,000. If you catch a plane to Paris and Julia Roberts shows up in Paris your net gain after having paid for the ticket is $5,000, and if she shows up in America you for some reason, never mind why, get $6,000. Your initial representation of the decision problem is visualized in Table 2.13.</p>\n</blockquote>\n<p>Table 2.13</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td>&nbsp;</td>\n<td>P</td>\n<td>LA</td>\n<td>NY</td>\n</tr>\n<tr>\n<td><em>Stay</em></td>\n<td>$0</td>\n<td>$10k</td>\n<td>$10k</td>\n</tr>\n<tr>\n<td><em>Go to Paris</em></td>\n<td>$5k</td>\n<td>$6k</td>\n<td>$6k</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>Since nothing is known about the probabilities of the states in Table 2.13, you decide it makes sense to regard them as equally probable [see Table 2.14].</p>\n</blockquote>\n<p>Table 2.14</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td>&nbsp;</td>\n<td>P (1/3)</td>\n<td>LA (1/3)</td>\n<td>NY (1/3)</td>\n</tr>\n<tr>\n<td><em>Stay</em></td>\n<td>$0</td>\n<td>$10k</td>\n<td>$10k</td>\n</tr>\n<tr>\n<td><em>Go to Paris</em></td>\n<td>$5k</td>\n<td>$6k</td>\n<td>$6k</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>The rightmost columns are exactly parallel. Therefore, they can be merged into a single (disjuntive) column, by adding the probabilities of the two rightmost columns together (Table 2.15).</p>\n</blockquote>\n<p>Table 2.15</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td>&nbsp;</td>\n<td>P (1/3)</td>\n<td>LA or NY (2/3)</td>\n</tr>\n<tr>\n<td><em>Stay</em></td>\n<td>$0</td>\n<td>$10k</td>\n</tr>\n<tr>\n<td><em>Go to Paris</em></td>\n<td>$5k</td>\n<td>$6k</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>However, now suppose that you instead start with Table 2.13 and <em>first</em> merge the two repetitious states into a single state. You would then obtain the decision matrix in Table 2.16.</p>\n</blockquote>\n<p>Table 2.16</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td>&nbsp;</td>\n<td>P</td>\n<td>LA or NY</td>\n</tr>\n<tr>\n<td><em>Stay</em></td>\n<td>$0</td>\n<td>$10k</td>\n</tr>\n<tr>\n<td><em>Go to Paris</em></td>\n<td>$5k</td>\n<td>$6k</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>Now, since you know nothing about the probabilities of the two states, you decide to regard them as equally probable... This yields the formal representation in Table 2.17, which is clearly different from the one suggested above in Table 2.15.</p>\n</blockquote>\n<p>Table 2.17</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td>&nbsp;</td>\n<td>P (1/2)</td>\n<td>LA or NY (1/2)</td>\n</tr>\n<tr>\n<td><em>Stay</em></td>\n<td>$0</td>\n<td>$10k</td>\n</tr>\n<tr>\n<td><em>Go to Paris</em></td>\n<td>$5k</td>\n<td>$6k</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>Which formalisation is best, 2.15 or 2.17? It seems question begging to claim that one of them must be better than the other &mdash; so perhaps they are equally reasonable? If they are, we have an example of rival formalisations.</p>\n<p>Note that the principle of maximising expected value recommends different acts in the two matrices. According to Table 2.15 you should stay, but 2.17 suggests you should go to Paris.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Does anyone know how to solve this problem? If one is not convinced by the illustration above, Peterson (2009) offers a proof that rival representations are possible on pages 33&ndash;35.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "o3oQ9ShvHBvEzf34t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 2, "extendedScore": null, "score": 3e-06, "legacy": true, "legacyId": "10632", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T02:20:39.086Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Terminal Values and Instrumental Values", "slug": "seq-rerun-terminal-values-and-instrumental-values", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BanLjZHgGHrjQFvuP/seq-rerun-terminal-values-and-instrumental-values", "pageUrlRelative": "/posts/BanLjZHgGHrjQFvuP/seq-rerun-terminal-values-and-instrumental-values", "linkUrl": "https://www.lesswrong.com/posts/BanLjZHgGHrjQFvuP/seq-rerun-terminal-values-and-instrumental-values", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Terminal%20Values%20and%20Instrumental%20Values&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Terminal%20Values%20and%20Instrumental%20Values%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBanLjZHgGHrjQFvuP%2Fseq-rerun-terminal-values-and-instrumental-values%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Terminal%20Values%20and%20Instrumental%20Values%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBanLjZHgGHrjQFvuP%2Fseq-rerun-terminal-values-and-instrumental-values", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBanLjZHgGHrjQFvuP%2Fseq-rerun-terminal-values-and-instrumental-values", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 189, "htmlBody": "<p>Today's post, <a href=\"/lw/l4/terminal_values_and_instrumental_values/\">Terminal Values and Instrumental Values</a> was originally published on 15 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Terminal_Values_and_Instrumental_Values\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Discusses a formalism for a discussion of the relationship between terminal and instrumental values. Terminal values are world states that we assign some sort of positive or negative worth to. Instrumental values are links in a chain of events that lead to desired world states.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/86t/seq_rerun_thou_art_godshatter/\">Thou Art Godshatter</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BanLjZHgGHrjQFvuP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 7.900964498467847e-07, "legacy": true, "legacyId": "10637", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["n5ucT5ZbPdhfGNLtP", "YgbMpYvW8mNaP3KcX", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T03:03:22.774Z", "modifiedAt": null, "url": null, "title": "Meetup : Fort Collins, Colorado Meetup Wednesday 7pm", "slug": "meetup-fort-collins-colorado-meetup-wednesday-7pm", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.587Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "EvelynM", "createdAt": "2010-01-03T23:18:02.364Z", "isAdmin": false, "displayName": "EvelynM"}, "userId": "gigfo2RbZBC2Nvg3T", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wEz9mQzkq9fT3ZiGS/meetup-fort-collins-colorado-meetup-wednesday-7pm", "pageUrlRelative": "/posts/wEz9mQzkq9fT3ZiGS/meetup-fort-collins-colorado-meetup-wednesday-7pm", "linkUrl": "https://www.lesswrong.com/posts/wEz9mQzkq9fT3ZiGS/meetup-fort-collins-colorado-meetup-wednesday-7pm", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wednesday%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wednesday%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwEz9mQzkq9fT3ZiGS%2Fmeetup-fort-collins-colorado-meetup-wednesday-7pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Fort%20Collins%2C%20Colorado%20Meetup%20Wednesday%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwEz9mQzkq9fT3ZiGS%2Fmeetup-fort-collins-colorado-meetup-wednesday-7pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwEz9mQzkq9fT3ZiGS%2Fmeetup-fort-collins-colorado-meetup-wednesday-7pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4i'>Fort Collins, Colorado Meetup Wednesday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 November 2011 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Bean Cycle, 144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Another week, another weekly meetup. Stay warm with community, now that winter is here.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4i'>Fort Collins, Colorado Meetup Wednesday 7pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wEz9mQzkq9fT3ZiGS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.901112443513376e-07, "legacy": true, "legacyId": "10639", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wednesday_7pm\">Discussion article for the meetup : <a href=\"/meetups/4i\">Fort Collins, Colorado Meetup Wednesday 7pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 November 2011 07:00:00PM (-0600)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Bean Cycle, 144 North College Avenue, Fort Collins, CO 80524</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Another week, another weekly meetup. Stay warm with community, now that winter is here.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wednesday_7pm1\">Discussion article for the meetup : <a href=\"/meetups/4i\">Fort Collins, Colorado Meetup Wednesday 7pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wednesday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wednesday_7pm", "level": 1}, {"title": "Discussion article for the meetup : Fort Collins, Colorado Meetup Wednesday 7pm", "anchor": "Discussion_article_for_the_meetup___Fort_Collins__Colorado_Meetup_Wednesday_7pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T03:18:07.808Z", "modifiedAt": null, "url": null, "title": "Subjective and Objective Reality: My Essay", "slug": "subjective-and-objective-reality-my-essay", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.158Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TheatreAddict", "createdAt": "2011-05-01T17:03:11.634Z", "isAdmin": false, "displayName": "TheatreAddict"}, "userId": "xtL2cZS7kaFnSNLus", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BWGQi7dWxNAC2mxth/subjective-and-objective-reality-my-essay", "pageUrlRelative": "/posts/BWGQi7dWxNAC2mxth/subjective-and-objective-reality-my-essay", "linkUrl": "https://www.lesswrong.com/posts/BWGQi7dWxNAC2mxth/subjective-and-objective-reality-my-essay", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Subjective%20and%20Objective%20Reality%3A%20My%20Essay&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASubjective%20and%20Objective%20Reality%3A%20My%20Essay%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBWGQi7dWxNAC2mxth%2Fsubjective-and-objective-reality-my-essay%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Subjective%20and%20Objective%20Reality%3A%20My%20Essay%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBWGQi7dWxNAC2mxth%2Fsubjective-and-objective-reality-my-essay", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBWGQi7dWxNAC2mxth%2Fsubjective-and-objective-reality-my-essay", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 601, "htmlBody": "<p>I want to start out by saying that I'm an ultra-beginner when it comes to stuff like this, but I had to do a definition essay in English, and I chose to contrast objective and subjective reality. So, if any of this seems wrong to you, please let me know. I'm sort of stuck right now, because I'm not really sure what to write about next. I'm thinking maybe the history of how the terms came to be or something. Also, for citations, I'm struggling with MLA formatting, so I might not have something in quotations cited, let me know if you want the cites for something.</p>\n<p>\n<p><span style=\"font-size: 11.5pt; color: black; background: white;\"><sub><span style=\"white-space: pre;\"> </span>Regardless of whether or not one watches a phenomenon occur, it still, in fact, occurs. Or does it? This argument is known as objective versus subjective reality. While objective reality initially seems to be the more obvious and substantial answer, fairly recent discoveries in the world of quantum physics have caused new questions to spring up regarding this ancient belief. Whether or not reality occurs outside of the human mind or exists only inside of the consciousness is a question that, despite countless arguments, remains unresolved. Despite arguments that insist on promoting the idea that reality is entirely dependent on our fallible perceptions (subjective reality), the evidence remains in favor that there is indeed a real world that exists independent of our observations (objective reality).<br /></sub></span><span style=\"font-size: 11.5pt; color: black; background: white;\"><sub><span style=\"white-space: pre;\"> </span>Subjective reality is defined as &ldquo;relating to or of the nature of an object as it is known in the mind as distinct from a thing in itself.&rdquo; Proponents of this theory generally believe that reality is relative, and so if someone cannot see an object in front of them, it ceases to exist. Objective reality, in contrast, means &ldquo;existing independent of thought or an observer as part of reality.&rdquo; Objective reality usually implies that everything can be proven using rationality, science, and mathematics. Although people use their mind to interpret and to put into practice this information, it still exists outside of the mind to be observed.<br /></sub></span><span style=\"font-size: 11.5pt; color: black; background: white;\"><sub><span style=\"white-space: pre;\"> </span>If there existed a picture, in a room, two people could agree that the picture is objective, and occurs outside of their mind. However, one could find the picture to be quite lovely, and another could detest it with a passion. These two ideas are not necessarily wrong, but are subjective. Based on this thought, some would suggest that reality is merely whatever a person believes reality to be. However, &ldquo;Reality is that which, when you stop believing in it, doesn&rsquo;t go away&rdquo; (Dick). Someone can choose to deny the existence of gravity, but when they step off of a building, the end result is fairly obvious. Simply thinking something to be true does not make it so, because &ldquo;the map is not the territory&rdquo; (Korzybski, par.1).<span>&nbsp;<br /> </span></sub></span><span style=\"font-size: 11.5pt; color: black; background: white;\"><sub><span style=\"white-space: pre;\"> </span>It is mainly the difference between the map and the territory, that marks the difference between objective and subjective reality. The map, or how we perceive the territory, does not necessarily reflect the territory (reality) itself. One can have directions on a map that appear to lead to somewhere quite interesting, but when acted out within the territory, can be misleading. Changing a belief about something changes nothing but chemical firing patterns within the brain. The goal should be to attempt to draw maps as close as possible to the actual territory, but to do so, human fallibility must be admitted, and an attitude of humility should be taken up.</sub></span></p>\n<p>Note: This is all I have so far, I'm supposed to be about halfway done. Anything that is incorrect/needs fixing? :D Thanks guys!</p>\n<p><span style=\"font-size: 11.5pt; color: black; background: white;\"><sub>&nbsp;&nbsp;</sub></span></p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BWGQi7dWxNAC2mxth", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -5, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "10640", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T06:27:20.018Z", "modifiedAt": null, "url": null, "title": "Vasili Arkhipov Day", "slug": "vasili-arkhipov-day", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.307Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wallowinmaya", "createdAt": "2011-03-21T00:39:18.855Z", "isAdmin": false, "displayName": "David Althaus"}, "userId": "xY8DDzk6TyvRroJEo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BDf2aPaWSfH2gWWAc/vasili-arkhipov-day", "pageUrlRelative": "/posts/BDf2aPaWSfH2gWWAc/vasili-arkhipov-day", "linkUrl": "https://www.lesswrong.com/posts/BDf2aPaWSfH2gWWAc/vasili-arkhipov-day", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vasili%20Arkhipov%20Day&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVasili%20Arkhipov%20Day%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBDf2aPaWSfH2gWWAc%2Fvasili-arkhipov-day%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vasili%20Arkhipov%20Day%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBDf2aPaWSfH2gWWAc%2Fvasili-arkhipov-day", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBDf2aPaWSfH2gWWAc%2Fvasili-arkhipov-day", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Stanislav_Petrov\">Stanislav Petrov</a> is a rather <a href=\"/lw/jq/926_is_petrov_day/\">famous</a> <a href=\"/lw/7t7/stanislav_petrov_day/\">person</a> (of course only on Lesswrong, not in the real world).</p>\n<p>But there is another Russian who saved the world:&nbsp; <a href=\"http://en.wikipedia.org/wiki/Vasili_Arkhipov\">Vasili Alexandrovich Arkhipov</a>.</p>\n<p>On this day in 1962, at the height of the Cuban Missile Crisis Vasili Arkhipov <a href=\"http://www.latinamericanstudies.org/cold-war/sovietsbomb.htm\">prevented the launch of a nuclear torpedo</a> and thus a possible nuclear war.</p>\n<p>&nbsp;</p>\n<p>It's strange that Petrov attracts much more attention than Arkhipov. E.g. googling \"Stanislav Petrov\" produces 101.000 results, \"Vasili Arkhipov\" only 9.040 results. By contrast searching for \"Britney Spears\" generates about 295.000.000 results. Sorta depressing.</p>\n<p>&nbsp;</p>\n<p>Anyway, let this day be the&nbsp;Vasili Arkhipov Day. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2i3w84KCkqZzpnQ4d": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BDf2aPaWSfH2gWWAc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 36, "extendedScore": null, "score": 7.901818697493242e-07, "legacy": true, "legacyId": "10628", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QtyKq4BDyuJ3tysoK", "79g662fdusDsXWK67"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T18:04:38.606Z", "modifiedAt": null, "url": null, "title": "A pessimistic view of quantum immortality", "slug": "a-pessimistic-view-of-quantum-immortality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:07.518Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "anotheruser", "createdAt": "2011-05-27T20:29:48.447Z", "isAdmin": false, "displayName": "anotheruser"}, "userId": "P6DJtQSevs4HkbsFx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MiKrZKgTgRRtykFNm/a-pessimistic-view-of-quantum-immortality", "pageUrlRelative": "/posts/MiKrZKgTgRRtykFNm/a-pessimistic-view-of-quantum-immortality", "linkUrl": "https://www.lesswrong.com/posts/MiKrZKgTgRRtykFNm/a-pessimistic-view-of-quantum-immortality", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20pessimistic%20view%20of%20quantum%20immortality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20pessimistic%20view%20of%20quantum%20immortality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMiKrZKgTgRRtykFNm%2Fa-pessimistic-view-of-quantum-immortality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20pessimistic%20view%20of%20quantum%20immortality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMiKrZKgTgRRtykFNm%2Fa-pessimistic-view-of-quantum-immortality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMiKrZKgTgRRtykFNm%2Fa-pessimistic-view-of-quantum-immortality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 510, "htmlBody": "<p>You have probably read about the idea of quantum immortality before. The basic idea seems to be that, as anything that can happen does happen (assuming either that the many-worlds interpretation of quantum theory is true, or that there is an infinite number of parallel universes wherein \"you\" exist) and it is impossible to remember your own death, every living thing is immortal.</p>\n<p>Take a game of russian roulette as an example: In those universes in which you die, you are no longer alive enough to care about that fact, leaving only those universes relevant in which you survive. This would make playing russian roulette for money a valid financial strategy, by the way.</p>\n<p>However, I think that this view ignores a very important fact: death is not binary. You are not either alive or dead, but may exist in various intermediate forms of suffering and reduced cognitive abilities. This means that what actually happens when you play russian roulette is the following:</p>\n<p>In those universes in which you win, everything is fine. In those in which you lose, however, you now have a gaping head wound. I assume that this hurts a lot, at least in those instances where you still have enough mental capacity to actually feel anything. Due to some fluke however (remember that absolutely all possible scenarios happen), you may still be alive and in a lot of pain. Most instances of you will then die from bloodloss or something, but for every timestep afterwards there will alway be an infinite number of universes wherein you continue to live, in most of them in complete agony.</p>\n<p>The instances of you in the other worlds that were never shot will be blissfully unaware of this fact.</p>\n<p>Now consider that you will also reach such a state of perpetual-agony-close-to-death-but-never-quite-reaching-it in everyday live. In fact, an infinite number of alternate \"you\"s, having split off from your everett branch just a second ago, are now suffering through this.</p>\n<p>The ratio of \"you\"s in your current state to those in the one described above is very high, as the probability of continued survival in such a state for any amount of time is infinitesimal, but it does exist. Consider however, that this ratio decreases massively as you age and that virtually all instances of you will be in such a state 200 years from now unless immortality is achieved.</p>\n<p>There is one bright spot, however:</p>\n<p>As time marches on, the continuous elongation of your suffering/death-that-will-not-come is going to become increasingly unlikely. Therefore, it will eventually be overtaken by the probability that the universes wherein you still persist also contains an entity (an AI?) that is both capable and willing to rescue you. Assuming you still care and haven't gone insane already.</p>\n<p>&nbsp;</p>\n<p>Another interesting thing: The above does not apply if your potential death is very sudden (so you won't feel it) and thorough (so there is an extremely low chance of survival). This means that while plaing russian roulette for money is unreasonable, playing russian roulette for money, using nukes instead of a revolver, is entirely reasonable and recommended :-)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MiKrZKgTgRRtykFNm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -2, "extendedScore": null, "score": 7.904230840443196e-07, "legacy": true, "legacyId": "10644", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T21:12:27.372Z", "modifiedAt": null, "url": null, "title": "[MORESAFE] Prevention of the global catastrophe and human values", "slug": "moresafe-prevention-of-the-global-catastrophe-and-human", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.424Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "turchin", "createdAt": "2010-02-03T20:22:54.095Z", "isAdmin": false, "displayName": "turchin"}, "userId": "2kDfHyTEpYCoa2SRq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8qsgm4hNWztQqCoKA/moresafe-prevention-of-the-global-catastrophe-and-human", "pageUrlRelative": "/posts/8qsgm4hNWztQqCoKA/moresafe-prevention-of-the-global-catastrophe-and-human", "linkUrl": "https://www.lesswrong.com/posts/8qsgm4hNWztQqCoKA/moresafe-prevention-of-the-global-catastrophe-and-human", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BMORESAFE%5D%20Prevention%20of%20the%20global%20catastrophe%20and%20human%20values&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BMORESAFE%5D%20Prevention%20of%20the%20global%20catastrophe%20and%20human%20values%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qsgm4hNWztQqCoKA%2Fmoresafe-prevention-of-the-global-catastrophe-and-human%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BMORESAFE%5D%20Prevention%20of%20the%20global%20catastrophe%20and%20human%20values%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qsgm4hNWztQqCoKA%2Fmoresafe-prevention-of-the-global-catastrophe-and-human", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8qsgm4hNWztQqCoKA%2Fmoresafe-prevention-of-the-global-catastrophe-and-human", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 561, "htmlBody": "<p>The chanses of prevention of the global catastrophe are growing if humans have the goal of it. This is semi-trivial conclusion. But the main question is who should have such goal?<br /><br />Of course, if we have global government, its main goal should be prevention of global catastrophe. But we do not have global government and most people hate the idea. I find it irrational. But discussion about global goverment is pure theoretical one, because I do not see peaceful ways of its creation.&nbsp;<br /><br />If friendly AI take over the world ve will became global government de facto.</p>\r\n<p>Or if imminent global risk will be recognized (asteroid is near), UN could temporaly transform in some kind of global government.&nbsp;<br />But some people think that global government itself will be or will soon lead to the global catastrophe - because it could easily implement global measures - and predicate \"global\" is nessesary to global catastrophes, as I am going to show in one of next posts. For example it could implement global total vaccination that lately will have dangerous consciences.<br /><br />So we see that idea of global government is very closely connected with idea of global catastrophe. One could lead to another and back.<br /><br />But as we do not have global government we could only speak about goals of separate people and separate organizations.<br /><br />People do not have goals. The only think that they have goals, but these are only declarations, which rarely regulate real people's behavior. This is because human beings are not born as rational subjects and their behavior is mostly regulated by unconscious programs known as instincts.&nbsp;<br /><br />These instincts are culturally adapted as values. Values are the real reasons of human behavior. \"Goals\" are what people say about their reasons to others and to themselves.<br /><br />The problem of how human values influent the course of human history is difficult one. Last year I wrote a book \"Futurology. 21 century: immortality or global catastrophe\" in Russian together with M.Batin. And the chapter about values was the most difficult one.&nbsp;<br /><br />Values are always based on instincts , pleasure and collective behavior (values help to form groups of people who share them). Value is always emotion, it has energy to move a person.<br /><br />But self-preservation is basic human instinct and so prevention of death and global catastrophe could be human value.</p>\r\n<p>Each value need a group of supporters to exist (value of soccer needs group of fans). Religious values exist only because they have large group of supporters.</p>\r\n<p>In 1960th fight for peace existed and was mass movement. It finally won and lead to limitation of nuclear arsenals in 80th and later. This is good example of how human values prevented global risk without creation of global government.</p>\r\n<p>Now value of \"being green\" has been created and many people fight CO2.</p>\r\n<p>The problems with such values is that they need very bright picture of risk to attract attention of people. It is not easy to create value to fight global risks in general. But the value of infinite existence of the civilization is much easily imaginable.<br />So promoting a vision of future galactic super civilization with immortal people could motivate people now to fight global risks in all forms.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8qsgm4hNWztQqCoKA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": -10, "extendedScore": null, "score": 7.904885003425046e-07, "legacy": true, "legacyId": "10645", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T22:03:20.216Z", "modifiedAt": null, "url": null, "title": "Rational to distrust your own rationality?", "slug": "rational-to-distrust-your-own-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.999Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PuyaSharif", "createdAt": "2011-02-26T07:33:06.094Z", "isAdmin": false, "displayName": "PuyaSharif"}, "userId": "Kx2AumHK8eeJ4nHqt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dmX9m5p6toYPb9oEK/rational-to-distrust-your-own-rationality", "pageUrlRelative": "/posts/dmX9m5p6toYPb9oEK/rational-to-distrust-your-own-rationality", "linkUrl": "https://www.lesswrong.com/posts/dmX9m5p6toYPb9oEK/rational-to-distrust-your-own-rationality", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20to%20distrust%20your%20own%20rationality%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20to%20distrust%20your%20own%20rationality%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdmX9m5p6toYPb9oEK%2Frational-to-distrust-your-own-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20to%20distrust%20your%20own%20rationality%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdmX9m5p6toYPb9oEK%2Frational-to-distrust-your-own-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdmX9m5p6toYPb9oEK%2Frational-to-distrust-your-own-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 591, "htmlBody": "<p>There are a number of experiments that throughout the years has shown that expected utility theory EUT fails to predict actual observed behavior of people in decision situations. Take for example <a title=\"Allais paradox\" href=\"http://en.wikipedia.org/wiki/Allais_paradox\" target=\"_blank\">Allais paradox</a>. Whether or not an average human being can be considered a rational agent has been under debate for a long time, and critics of EUT points out the inconsistency between theory and observation and concludes that theory is flawed. I will begin from Allais paradox, but the aim of this discussion is actually to reach something much broader. Asking if it should be included in a chain of reasoning, the distrust in the ability to reason.</p>\n<hr />\n<p>From Wikipedia:</p>\n<blockquote>\n<p>The <strong>Allais paradox</strong> arises when comparing participants' choices in two different experiments, each of which consists of a choice between two gambles, A and B. The payoffs for each gamble in each experiment are as follows:</p>\n<table class=\"wikitable\" border=\"1\" cellspacing=\"0\" cellpadding=\"5\">\n<tbody>\n<tr>\n<td colspan=\"4\" align=\"center\"><strong>Experiment 1</strong></td>\n<td colspan=\"4\" align=\"center\"><strong>Experiment 2</strong></td>\n</tr>\n<tr>\n<td colspan=\"2\" align=\"center\"><strong>Gamble 1A</strong></td>\n<td colspan=\"2\" align=\"center\"><strong>Gamble 1B</strong></td>\n<td colspan=\"2\" align=\"center\"><strong>Gamble 2A</strong></td>\n<td colspan=\"2\" align=\"center\"><strong>Gamble 2B</strong></td>\n</tr>\n<tr>\n<td><strong>Winnings</strong></td>\n<td><strong>Chance</strong></td>\n<td><strong>Winnings</strong></td>\n<td><strong>Chance</strong></td>\n<td><strong>Winnings</strong></td>\n<td><strong>Chance</strong></td>\n<td><strong>Winnings</strong></td>\n<td><strong>Chance</strong></td>\n</tr>\n<tr>\n<td rowspan=\"3\" valign=\"top\" bgcolor=\"#EEEEDD\">$1 million</td>\n<td rowspan=\"3\" valign=\"top\" bgcolor=\"#EEEEDD\">100%</td>\n<td bgcolor=\"#EEEEDD\">$1 million</td>\n<td bgcolor=\"#EEEEDD\">89%</td>\n<td bgcolor=\"#EEDDDD\">Nothing</td>\n<td bgcolor=\"#EEDDDD\">89%</td>\n<td rowspan=\"2\" valign=\"top\" bgcolor=\"#EEDDDD\">Nothing</td>\n<td rowspan=\"2\" valign=\"top\" bgcolor=\"#EEDDDD\">90%</td>\n</tr>\n<tr>\n<td bgcolor=\"#EEDDDD\">Nothing</td>\n<td bgcolor=\"#EEDDDD\">1%</td>\n<td rowspan=\"2\" valign=\"top\" bgcolor=\"#EEEEDD\">$1 million</td>\n<td rowspan=\"2\" valign=\"top\" bgcolor=\"#EEEEDD\">11%</td>\n</tr>\n<tr>\n<td bgcolor=\"#DDEEDD\">$5 million</td>\n<td bgcolor=\"#DDEEDD\">10%</td>\n<td bgcolor=\"#DDEEDD\">$5 million</td>\n<td bgcolor=\"#DDEEDD\">10%</td>\n</tr>\n</tbody>\n</table>\n<p>Several studies involving hypothetical and small monetary payoffs, and recently involving health outcomes, have supported the assertion that when presented with a choice between 1A and 1B, most people would choose 1A. Likewise, when presented with a choice between 2A and 2B, most people would choose 2B. Allais further asserted that it was reasonable to choose 1A alone or 2B alone.</p>\n<p>However, that the same person (who chose 1A alone or 2B alone) would choose both 1A and 2B together is inconsistent with expected utility theory. According to expected utility theory, the person should choose either 1A and 2A or 1B and 2B.</p>\n</blockquote>\n<hr />\n<p>I would say that there is a difference between E1 and E2 that EUT does not take into account. That is that in E1 understanding 1B is a more complex computational task than understanding 1A while in E2 understanding 2A and 2B is more equal. There could therefore exist a bunch of semi-rational people out there that have difficulties in understanding the details of 1B and therefore assign a certain level of uncertainty to their own \"calculations\". 1A involves no calculations; they are sure to receive 1 000 000! This uncertainty then makes it rational to choose the alternative they are more comfortable in. Whereas in E2 the task is simpler, almost a no-brainer.</p>\n<p>Now if by rational agents considering any information processing entity capable of making choices, human or AI etc and considering more complex cases, it would be reasonable to assume that this uncertainty grows with the complexity of the computational task. This then should at some point make it rational to make the \"irrational\" set of choices when weighing in the agents uncertainty in the its own ability to make calculated choices!</p>\n<p>Usually decision models takes into account external factors of uncertainty and risk for dealing with rational choices, expected utility, risk aversion etc. My question is: Shouldn't a rational agent also take into account an internal (introspective) analysis of its own reasoning when making choices? (Humans may well do - and that would explain Allais paradox as an effect of rational behavior).&nbsp;</p>\n<p>Basically - Could decision models including these kinds of introspective analysis do better in: 1. Explaining human behavior, 2. Creating AI's?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dmX9m5p6toYPb9oEK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 7.905061331988026e-07, "legacy": true, "legacyId": "10647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-27T22:07:17.592Z", "modifiedAt": null, "url": null, "title": "Conversation as social grooming \u2013 a rationality problem?", "slug": "conversation-as-social-grooming-a-rationality-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.390Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "4mYMvt6SSZtZRbMMX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9meQRSnRbNic3PoSR/conversation-as-social-grooming-a-rationality-problem", "pageUrlRelative": "/posts/9meQRSnRbNic3PoSR/conversation-as-social-grooming-a-rationality-problem", "linkUrl": "https://www.lesswrong.com/posts/9meQRSnRbNic3PoSR/conversation-as-social-grooming-a-rationality-problem", "postedAtFormatted": "Thursday, October 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Conversation%20as%20social%20grooming%20%E2%80%93%20a%20rationality%20problem%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConversation%20as%20social%20grooming%20%E2%80%93%20a%20rationality%20problem%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9meQRSnRbNic3PoSR%2Fconversation-as-social-grooming-a-rationality-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Conversation%20as%20social%20grooming%20%E2%80%93%20a%20rationality%20problem%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9meQRSnRbNic3PoSR%2Fconversation-as-social-grooming-a-rationality-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9meQRSnRbNic3PoSR%2Fconversation-as-social-grooming-a-rationality-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 765, "htmlBody": "<p>Summary: the evolved social communication style of humans is not optimised for problem-solving. People of average intelligence generally fail to notice this, therefore they habitually fail to make full use of their faculties of precise thinking, and privilege conversation at the expense of less natural but effective means of problem-solving such as books, the internet and humans outside their social group.</p>\n<hr />\n<p><a href=\"http://en.wikipedia.org/wiki/Dunbar's_number\">Dunbar&rsquo;s number</a> is a theoretical upper limit to the number of other people with whom an average human can maintain stable social relationships, given the limitations of human brain power in facilitating these relationships. The number is extrapolated from a regression of mean group size in other primates and the neocortex volume of these primates; the human average neocortex volume is input, and out pops Dunbar&rsquo;s number which is given to be ~150 (although the error bars are rather wide).</p>\n<p>Other primates, with their relatively small social group sizes, maintain their social relationships by physically grooming one another. However, the large potential social group size of humans renders physical grooming impractical because it would be so time consuming.</p>\n<p>From the wikipedia article on Dunbar&rsquo;s number:</p>\n<blockquote>\n<p>Dunbar, in <em>Grooming, Gossip, and the Evolution of Language</em>, proposes furthermore that language may have arisen as a \"cheap\" means of social grooming, allowing early humans to efficiently maintain social cohesion. Without language, Dunbar speculates, humans would have to expend nearly half their time on social grooming, which would have made productive, cooperative effort nearly impossible. Language may have allowed societies to remain cohesive, while reducing the need for physical and social intimacy.</p>\n</blockquote>\n<p>This certainly seems to be the case &ndash; humans use conversation to maintain their social relationships, rather than picking insects and dead skin off each other (if only we could claim to be so much more advanced than our primate cousins in <a href=\"http://www.livescience.com/117-monkeys-pay-female-monkey-bottoms.html\">every respect</a>).</p>\n<p>The relevance of this to rationality, as I see it, is that to the extent that human conversation is not optimised for efficient exchange of information and problem solving, social conversation is a sub-optimal means of obtaining help from other people. Presumably, our natural mode of conversation with social companions is a compromise between conversation as instrumental means of solving problems or gaining information, and conversation as grooming &ndash; it seems to me that in the <a href=\"http://en.wikipedia.org/wiki/Environment_of_evolutionary_adaptedness\">EEA</a>, these criteria would not have led to entirely the same results if our approach to conversation were only optimised for one or the other.</p>\n<p>If there had been internet and books in the EEA, humans would have evolved to prefer these information sources to what they can extract from their social contacts, in comparison to their natural inclinations given our actual evolutionary history (in which conversation was usually the best information source available, compromise though it may be). Given this counterfactual I suppose conversation would be optimised more as a purely social grooming activity, too.</p>\n<p>Therefore when people are talking to friends, they may be unduly optimistic about how useful they expect these interactions to be in comparison to (for example) researching things themselves, or asking questions on an internet forum. Admittedly humans are generally well aware that ulterior motives can be at play in their conversations, but even if someone has good reason to believe that their interlocutor is not consciously trying to hinder them (as is generally the case with friends) they are likely to overestimate the quality of the information, analysis or advice they receive.</p>\n<p>To state the obvious, social companions may be unwilling to speak the truth, regardless of how important it is to the problem. More subtly, friends may fail to realise the degree of precision of thought that is necessary in solving certain problems and resolving dilemmas &ndash; they may think they are offering advice (and the person with the problem may think so too), when in fact they are still in the habitual mode of conversation optimised towards the standards of &ldquo;be interesting&rdquo;, &ldquo;don&rsquo;t make a status play by acting too smart or talking too long&rdquo; et cetera.</p>\n<p>I see this as a problem that relatively smart people are likely to circumvent, firstly because they are used to thinking precisely in their work or studies and know what that feels like, therefore they tend to recognise when their social interactions are ill suited to problem-solving; and secondly because &ldquo;acting too smart&rdquo; is not frowned upon as an attempt to claim undue status in their social groups. That&rsquo;s probably why I&rsquo;ve never seen this problem discussed on Less Wrong; nonetheless to the extent that anyone is interested in improving the practical rationality of the IQ&lt;115 crowd, it might be a useful concept to tackle with them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9meQRSnRbNic3PoSR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 21, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "10646", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T00:20:06.270Z", "modifiedAt": null, "url": null, "title": "5 Second Level: Substituting the Question", "slug": "5-second-level-substituting-the-question", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.384Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "malthrin", "createdAt": "2011-03-22T15:23:59.536Z", "isAdmin": false, "displayName": "malthrin"}, "userId": "5b5DcLkcYGD9YGRfF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x4DNd9xXEHEW7zJko/5-second-level-substituting-the-question", "pageUrlRelative": "/posts/x4DNd9xXEHEW7zJko/5-second-level-substituting-the-question", "linkUrl": "https://www.lesswrong.com/posts/x4DNd9xXEHEW7zJko/5-second-level-substituting-the-question", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%205%20Second%20Level%3A%20Substituting%20the%20Question&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A5%20Second%20Level%3A%20Substituting%20the%20Question%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx4DNd9xXEHEW7zJko%2F5-second-level-substituting-the-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=5%20Second%20Level%3A%20Substituting%20the%20Question%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx4DNd9xXEHEW7zJko%2F5-second-level-substituting-the-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx4DNd9xXEHEW7zJko%2F5-second-level-substituting-the-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 343, "htmlBody": "<p>I picked this up in the new Kahneman book, <a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637\">Thinking, Fast and Slow</a>. He describes a common characteristic of reasoning heuristics: rather than answer a difficult question, they substitute a simpler question with a more readily available answer. This is a common failure mode.</p>\n<p>Later that evening, my wife made a comment about an article she was reading on diagnosing depression. I <em>immediately</em> thought, \"I'm pretty sure I've never been depressed.\" The speed of my response was a red flag. Did I really just scan the past 10 years of my adult life for depression symptoms? Or did I answer an easier question: \"Am I depressed right now?\" With a mouth full of delicious toast, the available answer was, \"I feel great!\"</p>\n<p>I think this technique is a good fit for the 5 Second Level, though it may need a name that indicates what to do rather than what to avoid doing. Hug the Query is close, but taken. The cover blurb for the skill is: take notice when you easily and swiftly answer a question, and double-check that you actually answered it.</p>\n<p>Here are a some more examples from the book:</p>\n<ul>\n<li><em>Target question</em>: How much would I contribute to save an endangered species?<br /><em>Heuristic question</em>: How much emotion do I feel when I think of dying dolphins?</li>\n<li><em>Target question</em>: How happy are you with your life these days?<br /><em>Heuristic question</em>: What is my mood right now?</li>\n<li><em>Target question</em>: How popular will the President be six months from now?<br /><em>Heuristic question</em>: How popular is the President right now?</li>\n<li><em>Target question</em>: How should financial advisers who prey on the elderly be punished?<br /><em>Heuristic question</em>: How much anger do I feel when I think of financial predators?</li>\n<li><em>Target question</em>: This woman is running for the primary. How far will she go in politics?<br /><em>Heuristic question</em>: Does this woman look like a political winner?</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x4DNd9xXEHEW7zJko", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 29, "extendedScore": null, "score": 7.905535338606386e-07, "legacy": true, "legacyId": "10648", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T01:29:53.640Z", "modifiedAt": null, "url": null, "title": "Gerald Jay Sussman talk on new ideas about modeling computation", "slug": "gerald-jay-sussman-talk-on-new-ideas-about-modeling", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.558Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cata", "createdAt": "2010-06-02T18:13:22.408Z", "isAdmin": false, "displayName": "cata"}, "userId": "X9jdpCokhLjCMZEc3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fk5nqMrpvcTz9eLET/gerald-jay-sussman-talk-on-new-ideas-about-modeling", "pageUrlRelative": "/posts/fk5nqMrpvcTz9eLET/gerald-jay-sussman-talk-on-new-ideas-about-modeling", "linkUrl": "https://www.lesswrong.com/posts/fk5nqMrpvcTz9eLET/gerald-jay-sussman-talk-on-new-ideas-about-modeling", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Gerald%20Jay%20Sussman%20talk%20on%20new%20ideas%20about%20modeling%20computation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGerald%20Jay%20Sussman%20talk%20on%20new%20ideas%20about%20modeling%20computation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffk5nqMrpvcTz9eLET%2Fgerald-jay-sussman-talk-on-new-ideas-about-modeling%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Gerald%20Jay%20Sussman%20talk%20on%20new%20ideas%20about%20modeling%20computation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffk5nqMrpvcTz9eLET%2Fgerald-jay-sussman-talk-on-new-ideas-about-modeling", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffk5nqMrpvcTz9eLET%2Fgerald-jay-sussman-talk-on-new-ideas-about-modeling", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 980, "htmlBody": "<p>This is a bit-over-an-hour-long talk with slides that I found extremely interesting from this year's Strange Loop conference, and I thought I would share it with any programmers in the audience here that hadn't seen it.</p>\n<p>It's about Sussman's ideas about the potential of modeling computation with sophisticated constraint-propagation/dataflow-esque constructs that have some really interesting properties, and might be of interest to anyone thinking about how an AI might create and maintain Bayesian beliefs.</p>\n<p>It would be accessible to anyone who can read a little Lisp, and I strongly recommend it unless this is all old hat to you already.</p>\n<p><a href=\"http://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute\">http://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute</a></p>\n<p>Unfortunately, I don't see a transcript yet. &nbsp;But here's a brief timeline I of the video I jotted down, in case you want to skip early parts of it and get to a piece that interests you:</p>\n<p><em>0:00 - 10:40: </em>Preface discussing the extreme flexibility and low latency of biological systems as opposed to human-designed systems. Programmers naturally design systems with very rigid constraints, but few natural systems are like this. &nbsp;Sussman feels that flexibility, not efficiency or correctness, is the central problem holding back human programmers. &nbsp;Example of Kanizsa's \"triangle\" figure-ground illusion where humans immediately see the shape of a triangle between other shapes.</p>\n<p><em>10:40 - 23:45:</em> Recap of the existing capability for compile-time flexibility in static languages and Lisp; gives an example of doing symbolic algebra in Lisp and building Lisp system for solving problems in classical mechanics. &nbsp;Suggests that the most powerful flexibility we have is to define new operators at runtime and redefine operators to operate on data in new ways at runtime. &nbsp;There is a direct tradeoff between this kind of flexibility and the ability to prove programs correct.</p>\n<p><em>23:45 - 25:30: </em>Sussman says that future computers are inevitably going to have to operate on a hugely parallel architecture where individual processors are plentiful and cheap. &nbsp;A solution to the flexibility problem needs to be highly parallel.</p>\n<p><em>25:30 - 28:10: </em>Discusses his experience teaching EE to students at MIT. &nbsp;Explains how strong engineers do network analysis on electrical circuits: &nbsp;They take some assumptions about parts of the circuit and scientific models to gradually conclude more and more about the voltage in different parts of the circuit. &nbsp;If an assumption turns out to be wrong, they can back it out with minimal effort.</p>\n<p><em>28:10 - 32:50: </em>Sussman and RMS wrote a Lisp program to replicate the process of how engineers analyze a circuit. &nbsp;Discusses how Lisp syntax helped him write an exploratory program to model the different parts of a circuit and a process in code. &nbsp;Sussman's program could take the wiring diagram of the circuit and the various rules for current to answer similar questions, calculate the current at some point, and then recapitulate the assumptions and rules that led the program to its answer, like an expert engineer could.</p>\n<p><em>32:50 - 35:00: </em>Sussman summarizes this idea as a \"propagator\" that has stateless machines moving pieces of data between stateful cells. &nbsp;Each machine is monitoring its inputs and pushing out some outputs when the inputs change. &nbsp;This is a good parallel architecture.&nbsp;</p>\n<p><em>35:00 - 40:30:</em> Expression-oriented languages have a problem in the syntax. &nbsp;Nested expressions have many inputs but one output. &nbsp;The intermediate sub-expression outputs aren't named or retained. &nbsp;This is not like real-world systems. &nbsp;You can change this to a propagator model by taking each intermediate output and making a propagator cell out of it that a machine can watch and act on. &nbsp;Shows a simple Lisp implementation of Newton's method modeled as a propagator.</p>\n<p><em>40:30 - 42:45: </em>Propagators can work in such a way that they update information multi-directionally; shows how he encodes the rules for resistors as propagators in Lisp.</p>\n<p><em>42:45 - 46:45: </em>Presents the interview-esque problem of \"how do I measure building height given a barometer and a ruler and a stopwatch.\" &nbsp;You can make multiple measurements to solve the problem. &nbsp;Since propagators work multi-directionally, you can model the problem in a way where taking multiple measurements not only narrows your error margin for the building result, but the inputs feed back and narrow the error margin for the other inputs.</p>\n<p><em>46:45 - 50:15: </em>Describes monads as \"lambda-calculus plumbing\" to carry along metadata together with a value. &nbsp;Shows how information going into a propagator network can carry metadata about its premises, so that outputs can keep track of which premises they depend upon.</p>\n<p><em>50:15 - 55:00:</em> Humans don't give up if different belief subsystems come to a contradictory conclusion. &nbsp;Presents the idea and Lisp implementation of a \"truth maintenance system\" developed by him, RMS, and his students. Each cell in the propagator network can keep track of multiple pieces of data, each dependent upon different premises. Premises can be believed or disbelieved and the output can be produced according to the current \"worldview\" with minimal necessary recomputation.</p>\n<p><em>55:00 - 56:45:</em> Truth maintenance systems can maintain locally consistent worldviews in the presence of globally contradictory inputs. &nbsp;The propagator network can automatically identify which beliefs are inconsistent, and very efficiently do backtracking and find sets of beliefs which are internally consistent. &nbsp;All of this works well in parallel.</p>\n<p><em>56:45 - 60:00:</em> Presents a logic puzzle where 5 people live in 5 houses with different rules saying which person may be or may not be assigned to each house. &nbsp;With normal recursive backtracking, solving the problem would take 3,000 backtracks. &nbsp;Sussman's propagation network reasoned out the right assignment with <strong>63</strong>&nbsp;backtracks.</p>\n<p><em>58:00 - 1:04:20:</em> Closing remarks on the potential application of propagation-based ideas. &nbsp;Points out that the triangle illusion plausibly seems like the result of a propagation network; pieces of evidence in the figure all contribute as inputs to the perception of the triangle in the background. &nbsp;Sussman doesn't know if this is right but feels like we need some drastically different model of computation to ever approach the functionality of natural systems.</p>\n<p>Finally, here's the information which Sussman and his student have published about their propagator work so far, with code included:</p>\n<p><a href=\"http://groups.csail.mit.edu/mac/users/gjs/propagators/\">http://groups.csail.mit.edu/mac/users/gjs/propagators/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fk5nqMrpvcTz9eLET", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 25, "extendedScore": null, "score": 5.5e-05, "legacy": true, "legacyId": "10649", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T01:59:23.204Z", "modifiedAt": null, "url": null, "title": "Review of Kahneman, 'Thinking, Fast and Slow' (2011)", "slug": "review-of-kahneman-thinking-fast-and-slow-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:05.798Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PipGvHwA9ZxYNgTyW/review-of-kahneman-thinking-fast-and-slow-2011", "pageUrlRelative": "/posts/PipGvHwA9ZxYNgTyW/review-of-kahneman-thinking-fast-and-slow-2011", "linkUrl": "https://www.lesswrong.com/posts/PipGvHwA9ZxYNgTyW/review-of-kahneman-thinking-fast-and-slow-2011", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Review%20of%20Kahneman%2C%20'Thinking%2C%20Fast%20and%20Slow'%20(2011)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReview%20of%20Kahneman%2C%20'Thinking%2C%20Fast%20and%20Slow'%20(2011)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPipGvHwA9ZxYNgTyW%2Freview-of-kahneman-thinking-fast-and-slow-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Review%20of%20Kahneman%2C%20'Thinking%2C%20Fast%20and%20Slow'%20(2011)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPipGvHwA9ZxYNgTyW%2Freview-of-kahneman-thinking-fast-and-slow-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPipGvHwA9ZxYNgTyW%2Freview-of-kahneman-thinking-fast-and-slow-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 782, "htmlBody": "<p><em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>&nbsp;is Kahneman's first book for a general audience, and a summary of his far-reaching and important work. Over the course of about 400 pages (this does not include the appendices, notes, or index), Kahneman explains his current views on: System 1 vs. System 2 thinking, heuristics and biases, overconfidence, decision making under uncertainty, the differences between the experiencing self and remembering self, and the implications of combining all this knowledge.</p>\n<p>In short: If you care about improving your thinking and decision making, and thus you care about the <a href=\"/lw/7e5/the_cognitive_science_of_rationality/\">cognitive science of rationality</a>, then you are likely to enjoy &mdash; and benefit from &mdash; this book. And if you know people who won't read the <a href=\"http://wiki.lesswrong.com/wiki/Sequences#Core_Sequences\">Core Sequences</a>, getting them to read <em>Thinking, Fast and Slow</em>&nbsp;will take them 30% of the way.</p>\n<p>Kahneman leaps deftly between demonstration (\"try this word problem, notice what your brain does\"), theory, and research stories. He covers dozens of issues likely to familiar to veteran LWers, and perhaps a dozen more that have never been discussed on Less Wrong: availability cascades, causal stereotyping, illusion of validity, the stuff on expert intuition from chapter 22, duration neglect, the peak-end effect, affective forecasting and \"miswanting,\"&nbsp;</p>\n<p>Each chapter ends with snippets of fictional dialogue, showing what it would like to use the concepts introduced in that chapter in everyday speech. What is remarkable is how much these snippets sound like things I hear in daily conversations at <a href=\"http://intelligence.org/\">Singularity Institute</a>. For example:</p>\n<ul>\n<li>\"What came quickly to my mind was an intuition from System 1. I&rsquo;ll have to start over and search my memory deliberately.\"</li>\n<li>\"She knows nothing about this person&rsquo;s management skills. All she is going by is the halo effect from a good presentation.\"</li>\n<li>\"Do we still remember the question we are trying to answer? Or have we substituted an easier one?\"</li>\n<li>\"This start-up looks as if it could not fail, but the base rate of success in the industry is extremely low. How do we know this case is different?\"</li>\n<li>\"Let's&nbsp;reframe the problem by changing the reference point. Imagine we did not own it; how much would we think it is worth?\"</li>\n</ul>\n<p>Other dialogue snippets from Kahneman's book are considered so obvious within Singularity Institute that sentences similar to Kahneman's snippets are often half-spoken before somebody interrupts and moves on because everyone in the room already knows the rest of the sentence, and everybody <em>knows</em> that everybody else knows the rest of the sentence:</p>\n<ul>\n<li>\"They&nbsp;were primed to find flaws, and this is exactly what they found.\"</li>\n<li>\"He underestimates the risks of indoor pollution because there are few media stories on them. That&rsquo;s an availability effect. He should look at the statistics.\"</li>\n<li>\"The&nbsp;mistake appears obvious, but it is just hindsight. You could not have known in advance.\"</li>\n<li>\"He's&nbsp;taking an inside view. He should forget about his own case and look for what happened in other cases.\"</li>\n<li>\"He&nbsp;weighs losses about twice as much as gains, which is normal.\"</li>\n</ul>\n<p>Other dialogue snippets from the book are even <em>more</em> obvious within Singularity Institute, and they can be communicated merely by raising an eyebrow at what someone has said:</p>\n<ul>\n<li>\"This is your System 1 talking. Slow down and let your System 2 take control.\"</li>\n<li>\"The&nbsp;sample of observations is too small to make any inferences. Let&rsquo;s not follow the law of small numbers.\"</li>\n</ul>\n<p>In the final chapter, Kahneman reflects on the good news that his and his colleagues' work is having an effect at the policy level. As a result of a book he wrote with Richard Thaler, <em><a href=\"http://www.amazon.com/Nudge-Improving-Decisions-Health-Happiness/dp/014311526X/\">Nudge: Improving Decisions about Health, Wealth, and Happiness</a></em>, <a href=\"http://en.wikipedia.org/wiki/Cass_Sunstein\">Cass Sunstein</a> was invited by President Obama to be the&nbsp;administrator of the Office of Information and Regulatory Affairs. From that post Sunstein has successfully implemented many new policies that treat humans as humans instead of as members of <em>Homo economicus</em>:</p>\n<blockquote>...applications that have been implemented [by Sunstein] include automatic enrollment in health insurance, a new version of the dietary guidelines that replaces the incomprehensible Food Pyramid with the powerful image of a Food Plate loaded with a balanced diet, and a rule formulated by the USDA that permits the inclusion of messages such as &ldquo;90% fat-free&rdquo; on the label of meat products, provided that the statement &ldquo;10% fat&rdquo; is also displayed &ldquo;contiguous to, in lettering of the same color, size, and type as, and on the same color background as, the statement of lean percentage.&rdquo;</blockquote>\n<p>The British government has also responded by <a href=\"http://www.independent.co.uk/news/uk/politics/first-obama-now-cameron-embraces-nudge-theory-2050127.html\">forming a special unit</a> dedicated to applying decision science to successful policy-making. Officially it is called the Behavioural Insight Team, but internally people just call it the Nudge Unit.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4Kcm4etxAJjmeDkHP": 1, "4R8JYu4QF2FqzJxE5": 1, "DLskYNGdAGDFpxBF8": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PipGvHwA9ZxYNgTyW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 40, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "10642", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 40, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xLm9mgJRPvmPGpo7Q"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T02:14:59.904Z", "modifiedAt": null, "url": null, "title": "Meetup : Austin, TX", "slug": "meetup-austin-tx-2", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.814Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ugma544z4yGkcT8iv/meetup-austin-tx-2", "pageUrlRelative": "/posts/ugma544z4yGkcT8iv/meetup-austin-tx-2", "linkUrl": "https://www.lesswrong.com/posts/ugma544z4yGkcT8iv/meetup-austin-tx-2", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Austin%2C%20TX&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Austin%2C%20TX%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fugma544z4yGkcT8iv%2Fmeetup-austin-tx-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Austin%2C%20TX%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fugma544z4yGkcT8iv%2Fmeetup-austin-tx-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fugma544z4yGkcT8iv%2Fmeetup-austin-tx-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 78, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4j'>Austin, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 October 2011 01:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2222B Guadalupe St Austin, Texas 78705</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>While the Austin Bayesian Conspiracy now exists as a UT student organization, there's a $5 fee to reserve a room on the weekends. For this week, we'll still be at Caffe Medici.</p>\n\n<p>SilasBarta will be celebrating his birthday this Saturday, and so there will be extra rationalist fun after the meetup ends!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4j'>Austin, TX</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ugma544z4yGkcT8iv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.905933573905974e-07, "legacy": true, "legacyId": "10655", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Austin__TX\">Discussion article for the meetup : <a href=\"/meetups/4j\">Austin, TX</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 October 2011 01:30:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2222B Guadalupe St Austin, Texas 78705</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>While the Austin Bayesian Conspiracy now exists as a UT student organization, there's a $5 fee to reserve a room on the weekends. For this week, we'll still be at Caffe Medici.</p>\n\n<p>SilasBarta will be celebrating his birthday this Saturday, and so there will be extra rationalist fun after the meetup ends!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Austin__TX1\">Discussion article for the meetup : <a href=\"/meetups/4j\">Austin, TX</a></h2>", "sections": [{"title": "Discussion article for the meetup : Austin, TX", "anchor": "Discussion_article_for_the_meetup___Austin__TX", "level": 1}, {"title": "Discussion article for the meetup : Austin, TX", "anchor": "Discussion_article_for_the_meetup___Austin__TX1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T02:30:35.471Z", "modifiedAt": null, "url": null, "title": "Best Intro to LW article for transhumanists", "slug": "best-intro-to-lw-article-for-transhumanists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.361Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Larks", "createdAt": "2009-04-28T20:21:45.860Z", "isAdmin": false, "displayName": "Larks"}, "userId": "jQXwiWxFcfyYjytXa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nHBMyn5AnJMsQLGLr/best-intro-to-lw-article-for-transhumanists", "pageUrlRelative": "/posts/nHBMyn5AnJMsQLGLr/best-intro-to-lw-article-for-transhumanists", "linkUrl": "https://www.lesswrong.com/posts/nHBMyn5AnJMsQLGLr/best-intro-to-lw-article-for-transhumanists", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Best%20Intro%20to%20LW%20article%20for%20transhumanists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABest%20Intro%20to%20LW%20article%20for%20transhumanists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnHBMyn5AnJMsQLGLr%2Fbest-intro-to-lw-article-for-transhumanists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Best%20Intro%20to%20LW%20article%20for%20transhumanists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnHBMyn5AnJMsQLGLr%2Fbest-intro-to-lw-article-for-transhumanists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnHBMyn5AnJMsQLGLr%2Fbest-intro-to-lw-article-for-transhumanists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<p>Summary: if you could show a page of LW to a random student who was interested in science, but couldn't otherwise communicate with them, which page would you choose?</p>\n<p>&nbsp;</p>\n<p>The Oxford University Transhumanist Society is a student society who arrange speakers on transhumanist topics - ranging from cognitive enhancement to AI to longevity to high-impact careers to Xrisk to brain-machine interfaces. The audience is a mixture of undergraduate and graduate students, mostly scientists, who are interested in the future of science and technology, but by no means self-describe as transhumanists.</p>\n<p>This week we're finally getting organised and producing membership cards. We intend to put a URL in a QR code on them, because people expect cool techy stuff from the Transhumanist society. It'd be nice if the link was something slightly more imaginative than just H+ or the facebook page. Naturally, I thought it should point to LW; but where specifically? The <a href=\"/about/\">About pag</a><a href=\"/about/\">e</a>, a very good article from the Sequences, something from Eliezer's website, MoR...? A well chosen page, showcasing what LW has to offer, could well draw someone into LW.</p>\n<p>&nbsp;</p>\n<p>Suggestions welcome. One article (or very similar set of articles) per top-level comment please, so people can upvote suggestions in a targetted manner.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nHBMyn5AnJMsQLGLr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 7.905987623000353e-07, "legacy": true, "legacyId": "10656", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bJ2haLkcGeLtTWaD5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T02:35:50.395Z", "modifiedAt": null, "url": null, "title": "The Pleasures of Rationality", "slug": "the-pleasures-of-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:08.891Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vbrtiub8HCmH286hx/the-pleasures-of-rationality", "pageUrlRelative": "/posts/vbrtiub8HCmH286hx/the-pleasures-of-rationality", "linkUrl": "https://www.lesswrong.com/posts/vbrtiub8HCmH286hx/the-pleasures-of-rationality", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Pleasures%20of%20Rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Pleasures%20of%20Rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvbrtiub8HCmH286hx%2Fthe-pleasures-of-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Pleasures%20of%20Rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvbrtiub8HCmH286hx%2Fthe-pleasures-of-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fvbrtiub8HCmH286hx%2Fthe-pleasures-of-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 335, "htmlBody": "<p>There are many pleasant benefits of improved <a href=\"/lw/31/what_do_we_mean_by_rationality/\">rationality</a>:</p>\n<ul>\n<li><a href=\"/lw/7i/rationality_is_systematized_winning/\">Winning</a> more often.</li>\n<li>Better <a href=\"http://en.wikipedia.org/wiki/Affective_forecasting\">affective forecasting</a>.</li>\n<li>Better <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">self-help skills</a> (e.g., <a href=\"http://en.wikipedia.org/wiki/Cognitive_behavioral_therapy\">CBT</a> is applied rationality).</li>\n</ul>\n<p>I'd like to mention two other benefits of rationality that arise when working with <em>other</em>&nbsp;rationalists, which&nbsp;I've noticed since moving to Berkeley to work with <a href=\"http://intelligence.org/\">Singularity Institute</a>&nbsp;(first as an intern, then as a staff member).</p>\n<p>The first is the comfort of knowing that people you work with agree on literally <em>hundreds</em> of norms and values relevant to decision-making: the laws of logic and probability theory, the recommendations of cognitive science for judgment and decision-making, the values of broad consequentialism and x-risk reduction, etc. When I walk into a decision-making meeting with Eliezer Yudkowsky or Anna Salamon or Louie Helm, I notice I'm more relaxed than when I walk into a meeting with most people. I know that we're operating on <a href=\"http://wiki.lesswrong.com/wiki/Crocker's_rules\">Crocker's rules</a>, that we all want to make the decisions that will most reduce existential risk, and that we agree on how we should go about making such a decision.</p>\n<p>The second pleasure, related to the first, is the extremely common result of reaching <a href=\"/lw/881/the_pleasures_of_rationality/54bc\">Aumann agreement</a> after initially disagreeing. Having worked closely with Anna on both the <a href=\"http://intelligence.org/blog/2011/06/21/rationality-minicamp-a-success/\">rationality minicamp</a> and a forthcoming article on intelligence explosion, we've had many opportunities to Aumann on things.&nbsp;We start by disagreeing on X. Then we reduce knowledge asymmetry about X. Then we share additional arguments for multiple potential conclusions about X. Then we both update from our initial impressions, also taking into account the other's updated opinion. In the end, we almost always agree on a final judgment or decision about X. And it's not that we agree to disagree and just move forward with one of our judgments. We actually both agree on what the most probably correct judgment <em>is</em>.&nbsp;I've had this experience literally <em>hundreds</em> of times with Anna alone.</p>\n<p>Being more rational is a pleasure. Being rational in the company of other rationalists is even better. Forget not the <a href=\"/lw/52g/the_good_news_of_situationist_psychology/\">good news of situationist psychology</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vbrtiub8HCmH286hx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 21, "extendedScore": null, "score": 7.906005816582189e-07, "legacy": true, "legacyId": "10657", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv", "4ARtkT3EYox3THYjF", "33KewgYhNSxFpbpXg", "Q5CjE8pRiACqTvhRM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T07:28:53.535Z", "modifiedAt": null, "url": null, "title": "How to popularize LW ideas: a webcomic?", "slug": "how-to-popularize-lw-ideas-a-webcomic", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.139Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9bWfynJr369uabA6K/how-to-popularize-lw-ideas-a-webcomic", "pageUrlRelative": "/posts/9bWfynJr369uabA6K/how-to-popularize-lw-ideas-a-webcomic", "linkUrl": "https://www.lesswrong.com/posts/9bWfynJr369uabA6K/how-to-popularize-lw-ideas-a-webcomic", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20popularize%20LW%20ideas%3A%20a%20webcomic%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20popularize%20LW%20ideas%3A%20a%20webcomic%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9bWfynJr369uabA6K%2Fhow-to-popularize-lw-ideas-a-webcomic%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20popularize%20LW%20ideas%3A%20a%20webcomic%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9bWfynJr369uabA6K%2Fhow-to-popularize-lw-ideas-a-webcomic", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9bWfynJr369uabA6K%2Fhow-to-popularize-lw-ideas-a-webcomic", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 87, "htmlBody": "<p>People have been asking this question here a lot lately (not sure, why, but still). MoR has been by far the most effective ad for LW so far, but this is a one-man effort. I wonder if a web comic drawn by the regulars based on, say, recent posts and comments would be another way to get people interested. Just to set the bar really, really low, here is my quick impression of <a href=\"/r/discussion/lw/881/the_pleasures_of_rationality/\">this post</a>&nbsp;(the idea is stolen from #lesswrong, but the obvious bad pun is mine):</p>\n<p>&nbsp;</p>\n<p><img src=\"http://images.lesswrong.com/t3_886_0.png\" alt=\"\" width=\"772\" height=\"676\" /></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9bWfynJr369uabA6K", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": -4, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "10662", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vbrtiub8HCmH286hx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T16:45:02.110Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Evolving to Extinction", "slug": "seq-rerun-evolving-to-extinction", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zjWXBJrRnT7s2Btjj/seq-rerun-evolving-to-extinction", "pageUrlRelative": "/posts/zjWXBJrRnT7s2Btjj/seq-rerun-evolving-to-extinction", "linkUrl": "https://www.lesswrong.com/posts/zjWXBJrRnT7s2Btjj/seq-rerun-evolving-to-extinction", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Evolving%20to%20Extinction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Evolving%20to%20Extinction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzjWXBJrRnT7s2Btjj%2Fseq-rerun-evolving-to-extinction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Evolving%20to%20Extinction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzjWXBJrRnT7s2Btjj%2Fseq-rerun-evolving-to-extinction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzjWXBJrRnT7s2Btjj%2Fseq-rerun-evolving-to-extinction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 204, "htmlBody": "<p>Today's post, <a href=\"/lw/l5/evolving_to_extinction/\">Evolving to Extinction</a> was originally published on 16 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Contrary to a naive view that evolution works for the good of a species, evolution says that genes which outreproduce their alternative alleles increase in frequency within a gene pool. It is entirely possible for genes which \"harm\" the species to outcompete their alternatives in this way - indeed, it is entirely possible for a species to evolve to extinction.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/87h/seq_rerun_terminal_values_and_instrumental_values/\">Terminal Values and Instrumental Values</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zjWXBJrRnT7s2Btjj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 7.908950378051597e-07, "legacy": true, "legacyId": "10663", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gDNrpuwahdRrDJ9iY", "BanLjZHgGHrjQFvuP", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T17:28:23.075Z", "modifiedAt": null, "url": null, "title": "Sustainability of Human Progress", "slug": "sustainability-of-human-progress", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.515Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Anatoly_Vorobey", "createdAt": "2009-03-22T09:13:04.364Z", "isAdmin": false, "displayName": "Anatoly_Vorobey"}, "userId": "gEQxcSsKD5bqjna3M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fv2nepQzQ6LJc8Nyq/sustainability-of-human-progress", "pageUrlRelative": "/posts/fv2nepQzQ6LJc8Nyq/sustainability-of-human-progress", "linkUrl": "https://www.lesswrong.com/posts/fv2nepQzQ6LJc8Nyq/sustainability-of-human-progress", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sustainability%20of%20Human%20Progress&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASustainability%20of%20Human%20Progress%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffv2nepQzQ6LJc8Nyq%2Fsustainability-of-human-progress%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sustainability%20of%20Human%20Progress%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffv2nepQzQ6LJc8Nyq%2Fsustainability-of-human-progress", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffv2nepQzQ6LJc8Nyq%2Fsustainability-of-human-progress", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 137, "htmlBody": "<p>John McCarthy, the inventor of LISP and one of the founders of the study of AI, died earlier this week. McCarthy was actually the person who came up with the phrase \"Artificial Intelligence\", in 1955. I find it likely that one day, not very soon, the first thinking self-aware machines will study their history and honor McCarthy's memory.</p>\n<p><a href=\"http://www-formal.stanford.edu/jmc/progress/\">Sustainability of Human Progress</a> is a set of pages jmc worked on mainly in the late 90s and early 2000s, I think, though he continued to update them occasionally later. This work isn't as widely known as it ought to be. It may be of interest to the LW crowd, even though McCarthy's underlying assumptions of how the human progress will proceed differ from those popular here.</p>\n<p>\"<strong>He who refuses to do arithmetic is doomed to talk nonsense.</strong>\" - John McCarthy</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fv2nepQzQ6LJc8Nyq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.909100742887019e-07, "legacy": true, "legacyId": "10665", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T18:13:11.610Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Penn State, Madison WI, Pittsburgh, Melbourne, Canberra, and Cambridge", "slug": "weekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:04.820Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/n9Y3b7vdboxNbLsB3/weekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne", "pageUrlRelative": "/posts/n9Y3b7vdboxNbLsB3/weekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne", "linkUrl": "https://www.lesswrong.com/posts/n9Y3b7vdboxNbLsB3/weekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Penn%20State%2C%20Madison%20WI%2C%20Pittsburgh%2C%20Melbourne%2C%20Canberra%2C%20and%20Cambridge&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Penn%20State%2C%20Madison%20WI%2C%20Pittsburgh%2C%20Melbourne%2C%20Canberra%2C%20and%20Cambridge%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fn9Y3b7vdboxNbLsB3%2Fweekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Penn%20State%2C%20Madison%20WI%2C%20Pittsburgh%2C%20Melbourne%2C%20Canberra%2C%20and%20Cambridge%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fn9Y3b7vdboxNbLsB3%2Fweekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fn9Y3b7vdboxNbLsB3%2Fweekly-lw-meetups-penn-state-madison-wi-pittsburgh-melbourne", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 343, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/3i\">Penn State University: NEW Meetup starting!:&nbsp;<span class=\"date\">22 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/4c\">Madison Monday Meetup:&nbsp;<span class=\"date\">24 October 2011 06:30AM</span></a></li>\n<li><a href=\"/meetups/4d\">Pittsburgh Meetup: Big Gaming Fun!:&nbsp;<span class=\"date\">25 October 2011 06:00PM</span></a></li>\n<li><a href=\"/meetups/4e\">Melbourne practical rationality meetup:&nbsp;<span class=\"date\">04 November 2011 07:00PM</span></a></li>\n<li><a href=\"/meetups/4a\">Canberra Meetup Saturday November 5th:&nbsp;<span class=\"date\">05 November 2011 11:00AM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/4b\">Cambridge (MA) Saturday meetup:&nbsp;<span class=\"date\">22 October 2011 02:00PM</span></a></li>\n</ul>\n<p>Cities with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>,</strong><strong> <a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine\">Irvine</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin, CA</a> </strong>(uses the Bay Area List)<strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong></strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>Despite the handy sidebar of upcoming meetups, we've decided to continue posting an overview of upcoming meetups on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening:<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison, WI</a></strong>,<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "n9Y3b7vdboxNbLsB3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 7.909256175510949e-07, "legacy": true, "legacyId": "10553", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pAHo9zSFXygp5A5dL", "tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T19:02:32.583Z", "modifiedAt": null, "url": null, "title": "Disability Culture Meets the Transhumanist Condition", "slug": "disability-culture-meets-the-transhumanist-condition", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:38.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Rubix", "createdAt": "2011-09-18T03:27:30.977Z", "isAdmin": false, "displayName": "Rubix"}, "userId": "3HSB6NdZm49DvQRFh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yzMbHLNdzzmsS8EB4/disability-culture-meets-the-transhumanist-condition", "pageUrlRelative": "/posts/yzMbHLNdzzmsS8EB4/disability-culture-meets-the-transhumanist-condition", "linkUrl": "https://www.lesswrong.com/posts/yzMbHLNdzzmsS8EB4/disability-culture-meets-the-transhumanist-condition", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Disability%20Culture%20Meets%20the%20Transhumanist%20Condition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADisability%20Culture%20Meets%20the%20Transhumanist%20Condition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyzMbHLNdzzmsS8EB4%2Fdisability-culture-meets-the-transhumanist-condition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Disability%20Culture%20Meets%20the%20Transhumanist%20Condition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyzMbHLNdzzmsS8EB4%2Fdisability-culture-meets-the-transhumanist-condition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyzMbHLNdzzmsS8EB4%2Fdisability-culture-meets-the-transhumanist-condition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 943, "htmlBody": "<p>With apologies to Ed Regis.</p>\n<p>Modern science has caused humankind to develop better cures and patches for once-debilitating conditions; people often survive maladies which would have killed them not long ago. In the wake of this and of a&nbsp;recently changing attitude regarding how cognitively disabled people might&nbsp;see the world, a disability rights movement came into swing in the 1970s. Increasingly, the attitude of disabled people was that it wasn't<em> inherently</em> bad<em> </em>to be disabled; a disability could be an intrinsic part of a person's self-image. Some people in wheelchairs, for instance, want badly to be able to walk - but some do not, and the mainstream attitude has <a href=\"http://www.thekidsareallright.org/\">historically not validated</a>&nbsp;<a href=\"http://www.mainstream-mag.com/tinytim.html\">those people's experiences.</a> This is where disability culture intersects the transhumanist movement. If it is possible to identify so strongly with a physical disability as to not want any cure, how does that mesh with believing that it is desirable to improve one's mind and body? Is it possible to identify as a happily disabled transhumanist?</p>\n<p>This does not intend to suggest that transhumanism is a movement of eugenic warriors; it's hard to imagine anyone suggesting that folks who don't sign up for the \"Harmless and easy cure for senescence\" shot be sterilized. However, despite the fact that hardly anyone would identify emself as an eugenicist (a fine thing to call yourself once-upon-a-time in America, until the Nazis rendered the term unpopular,) literally eugenic attitudes in society prevail, e.g. the prevalent belief that people with Huntington's disease or schizophrenia who reproduce are cruel for hazarding the inheritance of their condition.</p>\n<p>One wonders what disability culture would look like if people who are today in wheelchairs had access to technology that could repair their legs and allow them to walk. I wonder if people with congenital disabilities which would today require a wheelchair would have a choice about being cured, or whether the cure would be implemented in infancy. In 2007, a girl named <a href=\"http://en.wikipedia.org/wiki/Ashley_Treatment\">Ashley</a> who has an unknown brain disorder and cannot communicate or move herself effectively was given a series of radical procedures - hysterectomy, mastectomy and high estrogen doses - intended to make her easier to take care of. Was the literally&nbsp;non-consensual&nbsp;hysterectomy an eugenicist procedure? An immoral one? Was it in the spirit of transhumanism? In a future where Down syndrome can be prevented with a prenatal vaccine, would such a vaccine be moral? How about vaccines for \"low-functioning\" autism? At that rate, surely it would be possible to vaccinate for Asperger syndrome, depression, and ADHD, conditions which many people dislike and/or dislike having. (As an aside, with all the medically-repudiated yet widespread&nbsp;fear about vaccines causing autism, one can only imagine the panic an autism vaccine would cause.)</p>\n<p>I don't have answers to these questions. I have feelings and impressions, but those are not very useful. The issue cannot be solved unilaterally by saying that only those who enthusiastically consent to certain medical procedures should be given them, because many people are incapable of giving clear consent, as in the Ashley treatment. Nor can it be clearly solved by suggesting only prophylactic measures against disabling conditions, because certainly some parents would forego those measures. In a transhuman future, is the birth of a nonverbal autistic a preventable tragedy? Is it less of a tragedy if the child is a savant? Nor can one say that only conditions without an accompanying culture should be eradicated. Even if the definition of 'culture' were not elusive, HIV/AIDS has a definite culture about it, and few people would suggest that HIV should not be eradicated.</p>\n<p>It is not useful to ignore the role of disabled people and disability culture in the transhumanist movement. I believe that the future has a lot to offer many people with disabilities, including those who do not want a 'cure.' Transhumanism can encompass interest in diverse <a href=\"http://en.wikipedia.org/wiki/Augmentative_and_alternative_communication\">AAC</a>&nbsp;methods, and I believe it should. Simple keyboard technology has made it possible for many otherwise nonverbal people to communicate eloquently, as have DynaVox devices and various iPad apps. It would delight me to see widespread discussion about more powerful AAC devices, which could enable us to perceive and act on the desires of those who cannot now communicate.</p>\n<p>Nor has technology reached its limits in helping those with physical disabilities; wheelchairs are generally clumsy and heavy, and<em>&nbsp;</em>expensive for people without insurance - nearly inaccessible to people who live without insurance in impoverished areas of the world (or of the United States.) People who, like Stephen Hawking, become paralyzed by motor neuron diseases, do not all possess Stephen Hawking's access to high-tech communications devices (for which prices begin at thousands of dollars.) And people with disabilities like epilepsy or cerebral palsy are still often abused for their \"demonic possession\" or inaccurately stereotyped as mentally disabled. The transhumanist movement tends to <a href=\"http://www.transhumanism.org/index.php/WTA/communities/physicallydisabled/\">advocate</a>&nbsp;augmentation<em> sans</em> cure as far as physical disabilities are concerned, but there are people with&nbsp;<a href=\"http://futurisms.thenewatlantis.com/2011/08/fixed-new-documentary-on-disability-and.html\">mixed feelings</a>&nbsp;about transhumanism as it applies to disability.</p>\n<p>Disability is a hot button topic surrounded by widely varying spectra of beliefs. It directly affects humankind and is not often discussed rationally because of the subjective experiences people have had with varying&nbsp;disabilities. (The mother of a nonverbal autistic says, \"There should be a cure for autism; I want my son to say he loves me.\" A nonverbal autistic communicating by AAC says \"There shouldn't be a cure for autism; I want people to learn how I communicate my affection.\" Their conflicting beliefs do not predict radically different anticipated experiences.) So a rational, clear dialogue about disability is vital - for disabled people, their friends and families, and the world at large - in order to integrate these identities and experiences into the future and present of humankind.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"x6evH6MyPK3nxsoff": 1, "jiuackr7B5JAetbF6": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yzMbHLNdzzmsS8EB4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 39, "baseScore": 39, "extendedScore": null, "score": 0.000108, "legacy": true, "legacyId": "10667", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 150, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-28T21:06:19.649Z", "modifiedAt": null, "url": null, "title": "Help needed: German translation of the Singularity FAQ", "slug": "help-needed-german-translation-of-the-singularity-faq", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:25.358Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cadac", "createdAt": "2011-09-25T11:17:15.655Z", "isAdmin": false, "displayName": "cadac"}, "userId": "hMHAdTtN5PL9KThqu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HseHQzpSPyc5Ar87H/help-needed-german-translation-of-the-singularity-faq", "pageUrlRelative": "/posts/HseHQzpSPyc5Ar87H/help-needed-german-translation-of-the-singularity-faq", "linkUrl": "https://www.lesswrong.com/posts/HseHQzpSPyc5Ar87H/help-needed-german-translation-of-the-singularity-faq", "postedAtFormatted": "Friday, October 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%20needed%3A%20German%20translation%20of%20the%20Singularity%20FAQ&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%20needed%3A%20German%20translation%20of%20the%20Singularity%20FAQ%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHseHQzpSPyc5Ar87H%2Fhelp-needed-german-translation-of-the-singularity-faq%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%20needed%3A%20German%20translation%20of%20the%20Singularity%20FAQ%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHseHQzpSPyc5Ar87H%2Fhelp-needed-german-translation-of-the-singularity-faq", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHseHQzpSPyc5Ar87H%2Fhelp-needed-german-translation-of-the-singularity-faq", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<p>At <a href=\"/lw/7s7/useful_things_volunteers_can_do_right_now/\">lukeprog's suggestion</a>, I translated the <a href=\"http://intelligence.org/singularityfaq\">Singularity FAQ</a> into German. Unfortunately, Tripitaka, who volunteered to proofread, doesn't seem to have read my messages. As the translation is far from perfect, I ask German-speaking users to help with finalizing the text. Also, I have no objections if you'd like to upvote this post (and the comments of anyone who participates) as a way of <a href=\"/lw/7td/how_to_incentivize_people_doing_useful_stuff_on/4wkq\">incentivizing this kind of work</a>.<br /><br />The whole text should be proofread at least once, but you could help a great deal just by going over the highlighted sections. It helps if you are knowledgeable on the subject. The document is on Google docs, editable by anyone. I have made a backup and I think you can revert changes Wikipedia-style, so edit away!<br /><br /><a href=\"https://docs.google.com/document/d/1Qs4tJV0ikNg__IxoP5CIshE-q1w6O51A-dWdTybTfNY/edit?hl=en_US\">Here it is</a>.<br /><br /><a href=\"https://docs.google.com/document/d/1r28X90tOpj-CjHVadFMUCw8TzX4RHu9xY67fAkqWZRQ/edit?hl=en_US\">Side-by-side version</a> (comment only, changes should be made in the other version).<br /><br /><a href=\"https://docs.google.com/document/d/1h8N5cej77piamKaV1bx1kJzrQU_SUiTCg1LHyzqkkxg/edit?authkey=CMWztfsL&amp;hl=en_US&amp;authkey=CMWztfsL\">To-do-list</a>.</p>\n<p>Edit: Fixed links.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HseHQzpSPyc5Ar87H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 22, "extendedScore": null, "score": 7.909856792124879e-07, "legacy": true, "legacyId": "10668", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7z9cTAp4CGgaF6qFx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-29T15:21:09.499Z", "modifiedAt": null, "url": null, "title": "Whole Brain Emulation: Looking At Progress On C. elgans", "slug": "whole-brain-emulation-looking-at-progress-on-c-elgans", "viewCount": null, "lastCommentedAt": "2021-10-19T09:48:54.902Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XhHetxjWxZ6b85HK9/whole-brain-emulation-looking-at-progress-on-c-elgans", "pageUrlRelative": "/posts/XhHetxjWxZ6b85HK9/whole-brain-emulation-looking-at-progress-on-c-elgans", "linkUrl": "https://www.lesswrong.com/posts/XhHetxjWxZ6b85HK9/whole-brain-emulation-looking-at-progress-on-c-elgans", "postedAtFormatted": "Saturday, October 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Whole%20Brain%20Emulation%3A%20Looking%20At%20Progress%20On%20C.%20elgans&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhole%20Brain%20Emulation%3A%20Looking%20At%20Progress%20On%20C.%20elgans%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXhHetxjWxZ6b85HK9%2Fwhole-brain-emulation-looking-at-progress-on-c-elgans%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Whole%20Brain%20Emulation%3A%20Looking%20At%20Progress%20On%20C.%20elgans%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXhHetxjWxZ6b85HK9%2Fwhole-brain-emulation-looking-at-progress-on-c-elgans", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXhHetxjWxZ6b85HK9%2Fwhole-brain-emulation-looking-at-progress-on-c-elgans", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 658, "htmlBody": "<p>Being able to treat the pattern of someone's brain as software to be run on a computer, perhaps in parallel or at a large speedup, would have a huge impact, both socially and economically.&nbsp; Robin Hanson thinks it is the <a href=\"http://www.overcomingbias.com/2008/10/fhi-emulation-r.html\">most likely route to artificial intelligence</a>.&nbsp; Anders Sandberg and Nick Bostrom of the Future Of Humanity Institute created out a <a href=\"http://www.fhi.ox.ac.uk/Reports/2008-3.pdf\">roadmap for whole brain emulation</a> in 2008, which covers a huge amount of research in this direction, combined with some scale analysis of the difficulty of various tasks.</p>\n<p>Because the human brain is so large, and we are so far from having the technical capacity to scan or emulate it, it's difficult to evaluate progress.&nbsp; Some other organisms, however, have much smaller brains: the nematode C. elegans has only 302 cells in its entire nervous system.&nbsp; It is extremely well studied and well understood, having gone through heavy use as a research animal for decades.&nbsp; Since at least <a href=\"http://rstb.royalsocietypublishing.org/content/314/1165/1.short\">1986</a> we've known the full neural connectivity of C. elegans, something that would take decades and a huge amount of work to get for humans.&nbsp; At 302 neurons, simulation has been within our computational capacity for at least that long.&nbsp; With 25 years to work on it, shouldn't we be able to 'upload' a nematode by now?</p>\n<p>Reading through the research, there's been some work on modeling subsystems and components, but I only find three projects that have tried to integrate this research into a complete simulation: the University of Oregon's <a href=\"http://www.csi.uoregon.edu/projects/celegans/\">NemaSys</a> (~1997), the Perfect C. elegans Project (~1998), and Hiroshima University's Virtual C. Elegans project (~2004).&nbsp; The second two don't have web pages, but they did put out papers: [1], [2], [3].</p>\n<p>Another way to look at this is to list the researchers who seem to have been involved with C. elegans emulation.&nbsp; I find:</p>\n<ul>\n<li>Hiroaki Kitano, Sony [1]</li>\n<li>Shugo Hamahashi, Keio University [1]</li>\n<li>Sean Luke, University of Maryland [1]</li>\n<li>Michiyo Suzuki, Hiroshima University&nbsp; [2][3]</li>\n<li>Takeshi Goto, Hiroshima Univeristy [2]</li>\n<li>Toshio Tsuji, Hiroshima Univeristy [2][3]</li>\n<li>Hisao Ohtake, Hiroshima Univeristy [2]</li>\n<li>Thomas Ferree, University of Oregon [4][5][6][7]</li>\n<li>Ben Marcotte, University of Oregon [5]</li>\n<li>Sean Lockery, University of Oregon [4][5][6][7]</li>\n<li>Thomas Morse, University of Oregon [4]</li>\n<li>Stephen Wicks, University of British Columbia [8]</li>\n<li>Chris Roehrig, University of British Columbia [8]</li>\n<li>Catharine Rankin, University of British Columbia [8]</li>\n<li>Angelo Cangelosi, Rome Instituite of Psychology [9] </li>\n<li>Domenico Parisi, Rome Instituite of Psychology [9] </li>\n</ul>\n<p>This seems like a research area where you have multiple groups working at different universities, trying for a while, and then moving on.&nbsp; None of the simulation projects have gotten very far: their emulations are not complete and have some pieces filled in by guesswork, genetic algorithms, or other artificial sources.&nbsp; I was optimistic about finding successful simulation projects before I started trying to find one, but now that I haven't, my estimate of how hard whole brain emulation would be has gone up significantly.&nbsp; While I wouldn't say whole brain emulation could never happen, this looks to me like it is a very long way out, probably hundreds of years.</p>\n<p><em>Note: I later reorganized this into a <a href=\"http://www.jefftk.com/news/2011-11-02.html\">blog post</a>, incorporating some feed back from these comments. </em></p>\n<p>Papers:</p>\n<p>[1] <a href=\"http://www.mitpressjournals.org/doi/abs/10.1162/106454698568495\">The Perfect C. elegans Project: An Initial Report</a> (1998)</p>\n<p>[2] <a href=\"http://www.bsys.hiroshima-u.ac.jp/pub/pdf/J/J_152.pdf\">A Dynamic Body Model of the Nematode C. elegans With Neural Oscillators</a> (2005)</p>\n<p>[3] <a href=\"/www.bsys.hiroshima-u.ac.jp/pub/pdf/J/J_153.pdf\">A model of motor control of the nematode C. elegans with neuronal circuits</a> (2005)</p>\n<p>[4] <a href=\"http://www.csi.uoregon.edu/projects/celegans/pubs/AB1998.pdf\">Robust spacial navigation in a robot inspired by C. elegans</a> (1998)</p>\n<p>[5] <a href=\"http://www.csi.uoregon.edu/projects/celegans/pubs/NIPS1997.pdf\">Neural network models of chemotaxis in the nematode C. elegans</a> (1997)</p>\n<p>[6] <a href=\"http://www.csi.uoregon.edu/projects/celegans/pubs/CNS1998.pdf\">Chemotaxis control by linear recurrent networks</a> (1998)</p>\n<p>[7] <a href=\"http://www.csi.uoregon.edu/projects/celegans/pubs/JCN1999.pdf\">Computational rules for chemotaxis in the nematode C. elegans</a> (1999)</p>\n<p>[8] <a href=\"http://www.jneurosci.org/content/16/12/4017.short\">A Dynamic Network Simulation of the Nematode Tap Withdrawl Circuit: Predictions Concerning Synaptic Function Using Behavioral Criteria</a> (1996)</p>\n<p>[9] <a href=\"http://www.springerlink.com/content/x624g11272335148/\">A Neural Network Model of Caenorhabditis Elegans: The Circuit of Touch Sensitivity</a> (1997)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jQytxyauJ7kPhhGj3": 2, "5f5c37ee1b5cdee568cfb2ac": 2, "5f5c37ee1b5cdee568cfb2b1": 2, "3uE2pXvbcnS9nnZRE": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XhHetxjWxZ6b85HK9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 45, "baseScore": 59, "extendedScore": null, "score": 0.000134, "legacy": true, "legacyId": "10672", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 85, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-29T18:22:06.774Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] No Evolutions for Corporations or Nanodevices", "slug": "seq-rerun-no-evolutions-for-corporations-or-nanodevices", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.356Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/885vThJJCuYaFDbkE/seq-rerun-no-evolutions-for-corporations-or-nanodevices", "pageUrlRelative": "/posts/885vThJJCuYaFDbkE/seq-rerun-no-evolutions-for-corporations-or-nanodevices", "linkUrl": "https://www.lesswrong.com/posts/885vThJJCuYaFDbkE/seq-rerun-no-evolutions-for-corporations-or-nanodevices", "postedAtFormatted": "Saturday, October 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20No%20Evolutions%20for%20Corporations%20or%20Nanodevices&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20No%20Evolutions%20for%20Corporations%20or%20Nanodevices%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F885vThJJCuYaFDbkE%2Fseq-rerun-no-evolutions-for-corporations-or-nanodevices%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20No%20Evolutions%20for%20Corporations%20or%20Nanodevices%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F885vThJJCuYaFDbkE%2Fseq-rerun-no-evolutions-for-corporations-or-nanodevices", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F885vThJJCuYaFDbkE%2Fseq-rerun-no-evolutions-for-corporations-or-nanodevices", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 253, "htmlBody": "<p>Today's post, <a href=\"/lw/l6/no_evolutions_for_corporations_or_nanodevices/\">No Evolutions for Corporations or Nanodevices</a> was originally published on 17 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Price's Equation describes quantitatively how the change in a average trait, in each generation, is equal to the covariance between that trait and fitness. Such covariance requires substantial variation in traits, substantial variation in fitness, and substantial correlation between the two - and then, to get large cumulative selection pressures, the correlation must have persisted over many generations with high-fidelity inheritance, continuing sources of new variation, and frequent birth of a significant fraction of the population. People think of \"evolution\" as something that automatically gets invoked where \"reproduction\" exists, but these other conditions may not be fulfilled - which is why corporations haven't evolved, and nanodevices probably won't.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/887/seq_rerun_evolving_to_extinction/\">Evolving to Extinction</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "885vThJJCuYaFDbkE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 11, "extendedScore": null, "score": 7.914285090422121e-07, "legacy": true, "legacyId": "10673", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XC7Kry5q6CD9TyG4K", "zjWXBJrRnT7s2Btjj", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-29T22:40:12.609Z", "modifiedAt": null, "url": null, "title": "[LINK] Being proven wrong is like winning the lottery ", "slug": "link-being-proven-wrong-is-like-winning-the-lottery", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:08.377Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wTrkshWNdDxjGjNvM/link-being-proven-wrong-is-like-winning-the-lottery", "pageUrlRelative": "/posts/wTrkshWNdDxjGjNvM/link-being-proven-wrong-is-like-winning-the-lottery", "linkUrl": "https://www.lesswrong.com/posts/wTrkshWNdDxjGjNvM/link-being-proven-wrong-is-like-winning-the-lottery", "postedAtFormatted": "Saturday, October 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Being%20proven%20wrong%20is%20like%20winning%20the%20lottery%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Being%20proven%20wrong%20is%20like%20winning%20the%20lottery%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwTrkshWNdDxjGjNvM%2Flink-being-proven-wrong-is-like-winning-the-lottery%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Being%20proven%20wrong%20is%20like%20winning%20the%20lottery%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwTrkshWNdDxjGjNvM%2Flink-being-proven-wrong-is-like-winning-the-lottery", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwTrkshWNdDxjGjNvM%2Flink-being-proven-wrong-is-like-winning-the-lottery", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 250, "htmlBody": "<p>Phil Birnbaum at <em>Sabermetric Research</em> <a href=\"http://sabermetricresearch.blogspot.com/2011/10/being-proven-wrong-is-like-winning.html\">writes</a> about how people have things backwards; it's great to find out that you're wrong:</p>\n<blockquote>\n<p><span style=\"font-family: verdana;\">Let's suppose you open a restaurant, and you're very successful, and people like your food. You're very proud of being a great chef. Then, someone tells you, correctly, that one of your appetizers, one that you think is one of your best, is actually pretty awful. Your customers hate it.</span><br /><br /><span style=\"font-family: verdana;\">Your first reaction might be to get defensive. But, again, you should be thrilled! Now you can fix that dish. Your food, your restaurant, your profit, and your reputation will all be better than before. It's almost the best thing that can happen to you. Being wrong is like winning the lottery!</span></p>\n</blockquote>\n<p>...</p>\n<blockquote>\n<p><span style=\"font-family: verdana;\">I guess my overall point is that any  online discussion, even between people who violently disagree with each  other, should be a co-operative venture.  One of you is wrong, and  you're working together to find out who.  And, we should keep in mind  that most of the benefit goes to the person who was actually wrong in  the first place.</span><br /><br /><span style=\"font-family: verdana;\">When  someone you respect, or someone who seems to be expert and  knowledgeable, starts disagreeing with you, it's like you've stumbled  upon a fistful of lottery tickets.  Argue your position, yes, but don't  get defensive, and keep an open mind.  Sure, it might be that other guy  who's wrong.  But if you're really, really lucky, it'll be you.</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mQbxDKHxPcKKRG4mb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wTrkshWNdDxjGjNvM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 40, "extendedScore": null, "score": 7.915178127388604e-07, "legacy": true, "legacyId": "10674", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-30T02:07:29.709Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] The Simple Math of Everything", "slug": "seq-rerun-the-simple-math-of-everything", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.382Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LHxDayznWK5ZDaa3Q/seq-rerun-the-simple-math-of-everything", "pageUrlRelative": "/posts/LHxDayznWK5ZDaa3Q/seq-rerun-the-simple-math-of-everything", "linkUrl": "https://www.lesswrong.com/posts/LHxDayznWK5ZDaa3Q/seq-rerun-the-simple-math-of-everything", "postedAtFormatted": "Sunday, October 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20The%20Simple%20Math%20of%20Everything&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20The%20Simple%20Math%20of%20Everything%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLHxDayznWK5ZDaa3Q%2Fseq-rerun-the-simple-math-of-everything%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20The%20Simple%20Math%20of%20Everything%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLHxDayznWK5ZDaa3Q%2Fseq-rerun-the-simple-math-of-everything", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLHxDayznWK5ZDaa3Q%2Fseq-rerun-the-simple-math-of-everything", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<p>Today's post, <a href=\"/lw/l7/the_simple_math_of_everything/\">The Simple Math of Everything</a> was originally published on 17 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#The_Simple_Math_of_Everything\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>It is enormously advantageous to know the basic mathematical equations at the base of a field. Understanding a few simple equations of evolutionary biology, knowing how to use Bayes' Rule, and understanding the wave equation for sound in air are not enormously difficult challenges. However, if you know them, your own capabilities are greatly enhanced.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/88h/seq_rerun_no_evolutions_for_corporations_or/\">No Evolutions for Corporations or Nanodevices</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LHxDayznWK5ZDaa3Q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 13, "extendedScore": null, "score": 7.915901541449613e-07, "legacy": true, "legacyId": "10675", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HnPEpu5eQWkbyAJCT", "885vThJJCuYaFDbkE", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-30T03:58:38.870Z", "modifiedAt": null, "url": null, "title": "[Request] Feedback on my Writing", "slug": "request-feedback-on-my-writing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.160Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Gs5wyYNggmuNtXENo/request-feedback-on-my-writing", "pageUrlRelative": "/posts/Gs5wyYNggmuNtXENo/request-feedback-on-my-writing", "linkUrl": "https://www.lesswrong.com/posts/Gs5wyYNggmuNtXENo/request-feedback-on-my-writing", "postedAtFormatted": "Sunday, October 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BRequest%5D%20Feedback%20on%20my%20Writing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BRequest%5D%20Feedback%20on%20my%20Writing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGs5wyYNggmuNtXENo%2Frequest-feedback-on-my-writing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BRequest%5D%20Feedback%20on%20my%20Writing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGs5wyYNggmuNtXENo%2Frequest-feedback-on-my-writing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGs5wyYNggmuNtXENo%2Frequest-feedback-on-my-writing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p>I've written some posts.</p>\n<p>I'd like to get better at writing posts.</p>\n<p>I still have some more material for posts.</p>\n<p>I'd like to write it well.</p>\n<p>&nbsp;</p>\n<p>So, would people be willing to critique my work so far?</p>\n<p>Particularly helpful-awesome would be pointing out things I did well somewhere that I didn't do well somewhere else.&nbsp;Also nice would be pointing out what I did badly and well.</p>\n<p>Crocker's Rules apply.</p>\n<p>&nbsp;</p>\n<p>Miscellaneous:</p>\n<p>\n<p><a href=\"http://lesswrong.com/lw/7ix/story_rejection/\">http://lesswrong.com/lw/7ix/story_rejection/</a></p>\n<p><a href=\"http://lesswrong.com/lw/80t/thinking_in_bayes_light/\">http://lesswrong.com/lw/80t/thinking_in_bayes_light/</a></p>\n<p><a href=\"http://lesswrong.com/lw/64t/foma_beliefs_that_cause_themselves_to_be_true/\">http://lesswrong.com/lw/64t/foma_beliefs_that_cause_themselves_to_be_true/</a></p>\n<p>Consciousness:</p>\n</p>\n<p><a title=\"Blindsight and Conscious Access\" href=\"/lw/7pm/blindsight_and_consciousness/\">http://lesswrong.com/lw/7pm/blindsight_and_consciousness/</a></p>\n<p><a href=\"http://lesswrong.com/lw/7yr/neural_correlates_of_conscious_access/\">http://lesswrong.com/lw/7yr/neural_correlates_of_conscious_access/</a></p>\n<p><a href=\"http://lesswrong.com/lw/7yr/neural_correlates_of_conscious_access/\"></a><a href=\"http://lesswrong.com/lw/81w/the_protagonist_problem/\">http://lesswrong.com/lw/81w/the_protagonist_problem/</a></p>\n<p>Just do it:</p>\n<p>\n<p><a href=\"http://lesswrong.com/lw/53e/just_try_it_quantity_trumps_quality/\">http://lesswrong.com/lw/53e/just_try_it_quantity_trumps_quality/</a></p>\n<p><a href=\"http://lesswrong.com/lw/4up/dont_fear_failure/\">http://lesswrong.com/lw/4up/dont_fear_failure/</a></p>\n<p><a href=\"http://lesswrong.com/lw/4ln/go_try_things/\">http://lesswrong.com/lw/4ln/go_try_things/</a></p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Gs5wyYNggmuNtXENo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "10676", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["v8awKCJC6xMLJtcmk", "AcznJPygrpSET4zLe", "ckYGaqaq5kXz4oMvY", "K82imMHxwbR5FikKP", "9BRuYmSbyCfNyB6JR", "KXsWN8i4W26qGCmRR", "hY86FhYysQ7dBg3d8", "83naYmTXYcupTRGRW", "ADaZaEsmJMnKKhRqS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-30T14:01:33.566Z", "modifiedAt": null, "url": null, "title": "Why would we think artists perform better on drugs ?", "slug": "why-would-we-think-artists-perform-better-on-drugs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:27.621Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "kilobug", "createdAt": "2011-09-02T14:37:51.213Z", "isAdmin": false, "displayName": "kilobug"}, "userId": "7BQMuDSmLE2XRq2ph", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/x2AgpCvmEaNbvMvfz/why-would-we-think-artists-perform-better-on-drugs", "pageUrlRelative": "/posts/x2AgpCvmEaNbvMvfz/why-would-we-think-artists-perform-better-on-drugs", "linkUrl": "https://www.lesswrong.com/posts/x2AgpCvmEaNbvMvfz/why-would-we-think-artists-perform-better-on-drugs", "postedAtFormatted": "Sunday, October 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20would%20we%20think%20artists%20perform%20better%20on%20drugs%20%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20would%20we%20think%20artists%20perform%20better%20on%20drugs%20%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx2AgpCvmEaNbvMvfz%2Fwhy-would-we-think-artists-perform-better-on-drugs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20would%20we%20think%20artists%20perform%20better%20on%20drugs%20%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx2AgpCvmEaNbvMvfz%2Fwhy-would-we-think-artists-perform-better-on-drugs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fx2AgpCvmEaNbvMvfz%2Fwhy-would-we-think-artists-perform-better-on-drugs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3254, "htmlBody": "<h2>Introduction</h2>\n<p>It is common knowledge that many artists have used drugs (alcohol, opiates, cannabis, LSD, ...) and that this account for part of their creativity. This common knowledge is usually opposed to people advocating rationality in sentences like \"but with only your rationality, we wouldn't have much art\", \"you need chaos to make art\" or even \"the best artists were that great because they were irrational\".</p>\n<p>Eliezer partly addressed the issue in the <a href=\"http://wiki.lesswrong.com/wiki/Lawful_intelligence\">lawful intelligence Sequence</a>. While this Sequence is very interesting, I feel it didn't completely address the issue (unlike most of the Sequences). My hypothesis is that it's mostly focused on what's important to building a Friendly AI (which is a worthy goal, this should not be taken as a criticism), not so much as explaining creativity in actual humans. So I'm writing an article with my current thoughts on the topic, and I would welcome any additional argument, hypothesis, research paper, ... that anyone from the LW community can point me to. This article is not supposed to come to any definitive conclusion, but to show my current state of thinking on that issue. I hope to both give and receive in writing it.</p>\n<h2>Reasons for which it could be an illusion</h2>\n<h3>Availability bias</h3>\n<p>The first question to ask about \"it is a common knowledge that many artists were using drugs\" is : is this common knowledge true, or not, and if not, why do so many people believe something which is false ?</p>\n<p><a href=\"/lw/j5/availability/\">Availability bias</a> comes will full power on this issue : when we hear that a given artist (musician, writer, painter, ...) was taking drugs, we add a \"drug addict\" tag to him. Or more accurately we create a link between the \"drug addict\" node and his node in our belief network. When asked about artists who did take drugs, we can easily state many names : for example Hemingway, Van Gogh, the Beatles. When asked about artists who didn't take drugs... well, we usually don't have \"did not take drug\" node in our belief networks, and no easy way to say that Asimov or Bach didn't take drugs.</p>\n<p>Even when doing specific research, we can know with almost absolute certainty that Hemingway was drinking a lot of alcohol, but not so confidently that Asimov didn't. It's easier to be sure of the existence of something, than to be sure of its non-existence.</p>\n<h3>Reverse causality</h3>\n<p>The second question, if even after considering the affect of availability bias, it still seems than artists take drugs more often than average, is to ask about which sens the causality flows. Statistical correlation points to a causality, but doesn't tell you which sense is the causality, nor if it's direct or indirect.</p>\n<p>There can be many reasons for which the causality works backwards : someone is not a good artist because he takes drug, but he takes drugs because he is an artist.</p>\n<p>The lifestyle of a professional artist is usually different from the lifestyle of most other people. They usually don't have to wake up at 7 to be at work at 8, since they can work at any time. They also tend to be either very poor (many artists were only praised and recognized after being dead) or very rich (for the few who reach success while they are still alive). And we know that very poor people tend to fall on alcohol more often, while very rich people tend to use more frequently some of the very expensive drugs like cocaine.</p>\n<p>Being an artist also usually induces a higher uncertainty about the future than with most regular jobs, which may trigger the use of drugs to make the angst easier to withstand.</p>\n<h3>Common cause</h3>\n<p>Apart from direct causality one way or another, a statistical correlation can also indicate that is a hidden common cause between the two phenomenas. If artists take drugs more often, it could be because there is a common reason that pushes people to both by a great artist and to take drugs.</p>\n<p>Many reasons can be invoked that way, due to <a href=\"/lw/o3/superexponential_conceptspace_and_simple_words/\">superexponential hypothesis space</a>. I'll risk to be <a href=\"/lw/19m/privileging_the_hypothesis/\">privileging the hypothesis</a> but I can name a few. For example someone with an overdevelop emotional sensitivity could be both great at writing art able to call to our emotions and be more tempted to use drugs as relief from over-experienced negative emotions. Or someone who happens to be an outcast can be more likely to perform art (since it is usually a solitary work, not a team work) and at the same time use more drugs to escape from the pain of being an outcast.</p>\n<h3>So, where do we stand now ?</h3>\n<p>When faced with a statement such as \"artists take drugs more often than average, so drugs help creativity\" we can emit 4 different classes of hypothesis :</p>\n<ol>\n<li>The initial statement is wrong, artists don't take more drugs than average.</li>\n<li>Artists take more drugs than average, but the causality is reverse (it's being an artist that make you take drugs, not the other way around).</li>\n<li>Artists take more drugs than average, but that's because of a common factor that increases likelihood of taking drugs and of making great art, not the drugs themselves increasing artistic creativity.</li>\n<li>This is true, for a reason or another, drugs help creativity.</li>\n</ol>\n<p>We saw some possible reasons for 1., 2. and 3. Some of them seem to be very real to me, especially the availability bias, but I do not think they totally account for the facts.</p>\n<p>As much as I would love to be able to stop here and say that drugs and chaos play no positive role in creativity, that creativity is purely lawful and rational, I fear that would be wishful thinking and refusing to attack my belief's weak points. To state it more lightly : my D&amp;D alignment could very well be lawful-good (as my friends tease me it is), but that shouldn't prevent me from admitting that chaos play a positive role somewhere if it actually does.</p>\n<h2>Reasons for which it could be real</h2>\n<h3>Chaos and optimization</h3>\n<p>Generating great art can be seen as an optimization process. The actual function that evaluate a piece of art may be very complex, partly depending of the recipient, and its formalization unknown, but it can still be considered an optimization process : generating a book, or a painting, or a song that scores very high in most people's evaluation function.</p>\n<p>In general, chaos is not an optimization process. Adding chaos to an optimization process usually makes it worse. But there are known counter-examples, where an imperfect optimization process will gain from a slight controlled increase of chaos.</p>\n<h3>Lawfully controlled chaotic optimization<br /></h3>\n<p>The first known example is the first optimization process ever : evolution. Evolution involves too part : mutations which are chaotic, done at random, and natural selection which is lawful and selects the few evolutions that happened to be positive. The Roger Zelazny picture of the universe being an equilibrium between Order and Chaos may come from that pattern. If you increase chaos too much in natural selection, the information will not be replicated enough from generation to generation, and not much optimization will occur. But if you don't have any mutation, if you remove all the chaos, the process will freeze too.</p>\n<p>I remember an experiment from biology lessons in high school : take two small boxes of glass, put cotton with water and sugar at the bottom. Take some bacteria, and but the bacteria on side of the box. Take an antibiotics pill, and put it on the other side of the box. Put box A in safe storage. Put box B in safe storage too, but every day, expose it to a small amount of UV light. The bacteria of box A will quickly spread on the cotton, but will not go anywhere close the antibiotics pill. The bacteria of box B will start doing the same, but after two or three weeks, they conquer even the antibiotics area. After a longer time period, box A bacteria will also overcome the antibiotics, but it'll take them much longer. The UV light increased the mutation rate, and sped up the optimization process of evolution. But only a very small dose of UV light does that, overdose it, and the bacteria B will all die.</p>\n<p>That's what I call \"lawfully controlled chaotic optimization\" : there is a lawful control process (here, natural selection) that selects randomly tried solutions. That's something that can directly apply to artists : the control process (be it the filter of editors/publishers, or the filter of public reaction) is, to a point, lawful, but the process that generate solutions could benefit from a slight increase in chaos. Or more exactly, the combined (generator + filter) algorithm could perform better with a slightly more chaotic generator. To retake Eliezer's definition of creativity, which was \"<a href=\"/lw/vm/lawful_creativity/\">the creative surprise is the idea that ranks high in your <em>preference ordering</em> but low in your </a><em><a href=\"/lw/vm/lawful_creativity/\">search ordering</a></em>\", adding chaos to preference ordering would be pointless, but adding chaos to the search ordering can allow more creative surprise to happen in a given finite time.</p>\n<p>There is still a major difference between the two processes described here (evolution and human creativity) : evolution uses a fully random generator, whereas the human brain has a great ability of generating non-random designs, allowing a much faster improvement rate. You'll never get a book of Hemingway or a painting of Van Gogh by randomly selecting letters or randomly putting paint on a canvas. The chance of that is too infinitesimally low. So the generator will have to stay mostly lawful. Hemingway used words and respected the rules of grammar. Van Gogh painted something which look very like real sunflowers. A fully chaotic process would never produce anything near their masterpieces even given billions of years. So artistic creativity must be mostly lawful, even for generating its hypothesis to select from.</p>\n<p>As spotted by <a id=\"author_t1_54no\" href=\"/user/Vaniver\">Vaniver</a> in the comments, Hemingway himself said something very similar to that thesis : \"Write drunk; edit sober.\"</p>\n<h3>Avoiding local minimal<br /></h3>\n<p>One big problem of optimization processes is local minimal. Most of the naive optimization process, like a gradient descent, will get trapped into local minima. Let's have a look at that curve (burrowed from Wikipedia) :</p>\n<p><img style=\"vertical-align: middle;\" src=\"http://upload.wikimedia.org/wikipedia/commons/6/68/Extrema_example_original.svg\" alt=\"Local and global maxima, from Wikipedia\" width=\"515\" height=\"412\" /></p>\n<p>If you start a naive optimization algorithm in the right part of the curve, you'll very likely end up in the <span style=\"color: #3366ff;\">local minimum</span>, while the <span style=\"color: #ff0000;\">global minimum</span> would rank much better in your preferences. Adding some form of controlled chaos to the algorithm is an easy way to increase the chance of reaching the <span style=\"color: #ff0000;\">global minimum<span style=\"color: #000000;\">, even in much more complex setups than this simple curve. </span></span></p>\n<p><span style=\"color: #ff0000;\"><span style=\"color: #000000;\">For a relatively broad class of problems, like selecting the best position of nodes to minimize the length of edges when doing a bitmap representation of a graph structure, an algorithm which works quite well and is simple to code is the <a href=\"https://en.wikipedia.org/wiki/Simulated_annealing\">simulated annealing</a> algorithm, which works by doing local optimizations, but having a global temperature which adds chaos (the higher the temperature, the more random is the process). The temperature itself decreases with the process, and ultimately reaches 0 (pure lawful optimization).</span></span></p>\n<p>Such methods are of course \"dirty hacks\", that are used only when the problem is too complicated and we don't have a purely lawful algorithm that gives the answer, or (most of the time) when we do have one, but with an exponential complexity, meaning we can't run it in real life.</p>\n<p>The same idea applies to human creativity : chaos wouldn't be needed, nor useful, if we had a fully working algorithm to write the best books or songs or make the best paintings. But since we don't, using a purely lawful process has a risk (but yes, only a risk) of getting us stuck into a local minimum - improving the methods of the previous generation of artists, but not inventing brand new styles of art. This is a similar concept to the \"jumping out of the system\" described by Douglas Hofstadter and <a href=\"/lw/vm/lawful_creativity/\">analyzed by Eliezer</a>. JOOTSing is escaping a local minimum. It's escaping the safe warmth of the valley, climbing the cold and dangerous mountain top, to find another, more fertile valley on the other side. That requires to violate the rules of \"staying into the safe and warm valley\".</p>\n<p>(Note : there is somehow an analogy between the use of drugs and the simulated annealing : drugs induce a state of high chaos, which then slowly goes down as the drug effects disappears. Or at least I was told so, since I never tried personally. But that seems a <a href=\"/lw/rj/surface_analogies_and_deep_causes/\">surface analogy</a> to me, so I won't give it much credit).</p>\n<h3>Inhibitions and art<br /></h3>\n<p>Or another way to consider it is to look at is inhibitions : the human mind contains a process that'll check your actions (painting and writing in that case, but applies more broadly) and sometimes say \"no, don't do that, you'll look as a fool\". Those inhibitions are usually here to protect us from botching in social situations. But they are (as most of the human brain) imperfectly calibrated, and will tend to repress anything that goes out of the current norm. Lowering those inhibitions increases the risk of botching - but also the chance of doing something awesome.</p>\n<p>This points to much more general pattern, which applies when what matters is not improving your average gain, but your chance of being one of the few best. Consider you've a task to do, and two ways to achieve it. <span style=\"color: #339966;\">Way A</span> is quite classical, and doesn't involve much risk. <span style=\"color: #ff0000;\">Way B</span> is much less proven, and involves much risk of doing both better and worse. Being a role player, I usually use dice rolls to model those kinds of process. Let's say process A is 20d10. That means, rolling 20 times a 10-sided die, and doing the sum. This will give an expected value of 110, with only 1% of the rolls above 140. Now process B is 2d100 (rolling 2 times a 100-sided die and doing the sum). This will give a lower expected value, of 101 instead of 110. But with 18% of the rolls above 140. Here is a picture of the two process (<span style=\"color: #339966;\">way A</span> in green, <span style=\"color: #ff0000;\">way B</span> in red) generated with a quick Python script :</p>\n<p><img src=\"http://kilobug.net/lw/dice.png\" alt=\"2d100 (red) vs 20d10 (green)\" width=\"600\" height=\"400\" /></p>\n<p>If what matters is doing your best in average (your score at the task will directly map to an amount of money between $2 and $200), then the best choice is to look only at the expected value of <span style=\"color: #339966;\">A</span> and <span style=\"color: #ff0000;\">B</span>, and select the one which has the best expected value, so <span style=\"color: #339966;\">A</span> in this case, as you can see, the green curve peaks at a higher value.</p>\n<p>But if what matters is not doing the best in average, but being the best : 100 people are performing the task, and the best will take the prize, the rest won't have anything. Then, you except one of the 100 to be above 140, even if they all use <span style=\"color: #339966;\">way A</span>. So for yourself, if you use <span style=\"color: #339966;\">way A</span>, you only have 1 chance in 100 to be above 140. If you use <span style=\"color: #ff0000;\">way B</span>, you've 18 chances in 100 of beating the 140 mark. Looking at the curve, there is much bigger blob of the red curve that goes to very high values.</p>\n<p>When looking at arts, we don't regard the average. Countless people write books or paint. Almost everyone at least tried once. What history remembers are the few best of their time. Not those who did better in average, but those who manage to do better than most of their peers. Those to the right of the picture, in which the amplitude of the green curve is nearly void, but the red curve still exists.</p>\n<h2>The complexity of testing certain hypothesis</h2>\n<p>I emitted many hypothesis in this article, to try to explain the common knowledge that \"so many great artists take drugs\", and more generally to look into the reasons for which chaos can, in some cases, improve a result.</p>\n<p>All those hypothesis seem totally plausible to me - and I would say that they all play a role in the process. But saying \"everything plays a role\" is not saying much, a graph with all possible edges contains as much informations as a graph with no edge. What would be require now is to consider how much each hypothesis contributes to the result - and then, probably one or two will account for most.</p>\n<p>But how can we setup such a test ? In physics, doing experiments is relatively easy. It can costs a lot like building the LHC or sending the Hubble space telescope in orbit, but still, devising experiments is relatively easy. In social sciences, it's often much harder. Most social science experiments are done on a panel of test subjects (with a control group, ...). But right now we are speaking of the <em>best artists</em>. How can we build such a panel ? Defining who are the best artists is a very hard task. And then, getting them to participate in studies...</p>\n<p>The simplest hypothesis to test, the availability bias, would require a procedure like (numbers can be adjusted) :</p>\n<ol>\n<li>Take 1000 people at random, from various ages, social classes and background.</li>\n<li>Ask for each of them to name the 10 artists they like the most (without of course mentioning the purpose of the experiment).</li>\n<li>For each artist nominated by at least 4 persons, look if that artist did take drugs.</li>\n<li>Compare with the average drug use.</li>\n</ol>\n<p>But even that is not without troubles : for 3., how can you be sure an artist didn't take drug secretly, especially in time/places where drug use is prohibited or frown upon ? For 4., how do you ponder for the variation in drug use depending of the place/time ?</p>\n<p>Does anyone know of such a study (I couldn't find any, but I'm not well versed in the art for looking for social science studies) ?</p>\n<p>For the other hypothesis, testing them becomes even harder.</p>\n<h2>Conclusion</h2>\n<p>As Eliezer explained, pure chaos cannot lead to anything but static on a TV screen. Any optimization process, and art is one, requires a lawful part. But as I showed, for several reasons, an imperfect optimization process may perform better with a limited amount of added chaos. Since the human brain is an imperfect optimization process, it would not be surprising that in the purpose of creating awesome pieces of art in a limited time, some added chaos can help. But on the other hand, there are other reasons for which there could be a common knowledge that \"artistic creativity requires some chaos\" even if it were not true. And it is very hard to tell apart the various reasons.</p>\n<p>But even if <em>some amount</em> of chaos can help in generating exceptionally awesome pieces of art, it should not shadow the fact that the lawful part of process is absolutely required, and even the most important one; nor that chaos can only be useful when the optimization is itself imperfect. Improving the quality of the optimization process (by, for example, raising the sanity waterline or understanding better the human brain) would lower the need of chaos to generate the same awesomeness.</p>\n<p><em>PS : I post that to \"Less Wrong discussion\", for initial review and because it's half-way between a \"real\" article and a call for discussion on the topic. Depending of feedback, I hope to repost it to \"main Less Wrong\", hopefully improved from the feedback.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FwM9CYSSXgjX6fJvG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "x2AgpCvmEaNbvMvfz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 14, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "10568", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Introduction\">Introduction</h2>\n<p>It is common knowledge that many artists have used drugs (alcohol, opiates, cannabis, LSD, ...) and that this account for part of their creativity. This common knowledge is usually opposed to people advocating rationality in sentences like \"but with only your rationality, we wouldn't have much art\", \"you need chaos to make art\" or even \"the best artists were that great because they were irrational\".</p>\n<p>Eliezer partly addressed the issue in the <a href=\"http://wiki.lesswrong.com/wiki/Lawful_intelligence\">lawful intelligence Sequence</a>. While this Sequence is very interesting, I feel it didn't completely address the issue (unlike most of the Sequences). My hypothesis is that it's mostly focused on what's important to building a Friendly AI (which is a worthy goal, this should not be taken as a criticism), not so much as explaining creativity in actual humans. So I'm writing an article with my current thoughts on the topic, and I would welcome any additional argument, hypothesis, research paper, ... that anyone from the LW community can point me to. This article is not supposed to come to any definitive conclusion, but to show my current state of thinking on that issue. I hope to both give and receive in writing it.</p>\n<h2 id=\"Reasons_for_which_it_could_be_an_illusion\">Reasons for which it could be an illusion</h2>\n<h3 id=\"Availability_bias\">Availability bias</h3>\n<p>The first question to ask about \"it is a common knowledge that many artists were using drugs\" is : is this common knowledge true, or not, and if not, why do so many people believe something which is false ?</p>\n<p><a href=\"/lw/j5/availability/\">Availability bias</a> comes will full power on this issue : when we hear that a given artist (musician, writer, painter, ...) was taking drugs, we add a \"drug addict\" tag to him. Or more accurately we create a link between the \"drug addict\" node and his node in our belief network. When asked about artists who did take drugs, we can easily state many names : for example Hemingway, Van Gogh, the Beatles. When asked about artists who didn't take drugs... well, we usually don't have \"did not take drug\" node in our belief networks, and no easy way to say that Asimov or Bach didn't take drugs.</p>\n<p>Even when doing specific research, we can know with almost absolute certainty that Hemingway was drinking a lot of alcohol, but not so confidently that Asimov didn't. It's easier to be sure of the existence of something, than to be sure of its non-existence.</p>\n<h3 id=\"Reverse_causality\">Reverse causality</h3>\n<p>The second question, if even after considering the affect of availability bias, it still seems than artists take drugs more often than average, is to ask about which sens the causality flows. Statistical correlation points to a causality, but doesn't tell you which sense is the causality, nor if it's direct or indirect.</p>\n<p>There can be many reasons for which the causality works backwards : someone is not a good artist because he takes drug, but he takes drugs because he is an artist.</p>\n<p>The lifestyle of a professional artist is usually different from the lifestyle of most other people. They usually don't have to wake up at 7 to be at work at 8, since they can work at any time. They also tend to be either very poor (many artists were only praised and recognized after being dead) or very rich (for the few who reach success while they are still alive). And we know that very poor people tend to fall on alcohol more often, while very rich people tend to use more frequently some of the very expensive drugs like cocaine.</p>\n<p>Being an artist also usually induces a higher uncertainty about the future than with most regular jobs, which may trigger the use of drugs to make the angst easier to withstand.</p>\n<h3 id=\"Common_cause\">Common cause</h3>\n<p>Apart from direct causality one way or another, a statistical correlation can also indicate that is a hidden common cause between the two phenomenas. If artists take drugs more often, it could be because there is a common reason that pushes people to both by a great artist and to take drugs.</p>\n<p>Many reasons can be invoked that way, due to <a href=\"/lw/o3/superexponential_conceptspace_and_simple_words/\">superexponential hypothesis space</a>. I'll risk to be <a href=\"/lw/19m/privileging_the_hypothesis/\">privileging the hypothesis</a> but I can name a few. For example someone with an overdevelop emotional sensitivity could be both great at writing art able to call to our emotions and be more tempted to use drugs as relief from over-experienced negative emotions. Or someone who happens to be an outcast can be more likely to perform art (since it is usually a solitary work, not a team work) and at the same time use more drugs to escape from the pain of being an outcast.</p>\n<h3 id=\"So__where_do_we_stand_now__\">So, where do we stand now ?</h3>\n<p>When faced with a statement such as \"artists take drugs more often than average, so drugs help creativity\" we can emit 4 different classes of hypothesis :</p>\n<ol>\n<li>The initial statement is wrong, artists don't take more drugs than average.</li>\n<li>Artists take more drugs than average, but the causality is reverse (it's being an artist that make you take drugs, not the other way around).</li>\n<li>Artists take more drugs than average, but that's because of a common factor that increases likelihood of taking drugs and of making great art, not the drugs themselves increasing artistic creativity.</li>\n<li>This is true, for a reason or another, drugs help creativity.</li>\n</ol>\n<p>We saw some possible reasons for 1., 2. and 3. Some of them seem to be very real to me, especially the availability bias, but I do not think they totally account for the facts.</p>\n<p>As much as I would love to be able to stop here and say that drugs and chaos play no positive role in creativity, that creativity is purely lawful and rational, I fear that would be wishful thinking and refusing to attack my belief's weak points. To state it more lightly : my D&amp;D alignment could very well be lawful-good (as my friends tease me it is), but that shouldn't prevent me from admitting that chaos play a positive role somewhere if it actually does.</p>\n<h2 id=\"Reasons_for_which_it_could_be_real\">Reasons for which it could be real</h2>\n<h3 id=\"Chaos_and_optimization\">Chaos and optimization</h3>\n<p>Generating great art can be seen as an optimization process. The actual function that evaluate a piece of art may be very complex, partly depending of the recipient, and its formalization unknown, but it can still be considered an optimization process : generating a book, or a painting, or a song that scores very high in most people's evaluation function.</p>\n<p>In general, chaos is not an optimization process. Adding chaos to an optimization process usually makes it worse. But there are known counter-examples, where an imperfect optimization process will gain from a slight controlled increase of chaos.</p>\n<h3 id=\"Lawfully_controlled_chaotic_optimization\">Lawfully controlled chaotic optimization<br></h3>\n<p>The first known example is the first optimization process ever : evolution. Evolution involves too part : mutations which are chaotic, done at random, and natural selection which is lawful and selects the few evolutions that happened to be positive. The Roger Zelazny picture of the universe being an equilibrium between Order and Chaos may come from that pattern. If you increase chaos too much in natural selection, the information will not be replicated enough from generation to generation, and not much optimization will occur. But if you don't have any mutation, if you remove all the chaos, the process will freeze too.</p>\n<p>I remember an experiment from biology lessons in high school : take two small boxes of glass, put cotton with water and sugar at the bottom. Take some bacteria, and but the bacteria on side of the box. Take an antibiotics pill, and put it on the other side of the box. Put box A in safe storage. Put box B in safe storage too, but every day, expose it to a small amount of UV light. The bacteria of box A will quickly spread on the cotton, but will not go anywhere close the antibiotics pill. The bacteria of box B will start doing the same, but after two or three weeks, they conquer even the antibiotics area. After a longer time period, box A bacteria will also overcome the antibiotics, but it'll take them much longer. The UV light increased the mutation rate, and sped up the optimization process of evolution. But only a very small dose of UV light does that, overdose it, and the bacteria B will all die.</p>\n<p>That's what I call \"lawfully controlled chaotic optimization\" : there is a lawful control process (here, natural selection) that selects randomly tried solutions. That's something that can directly apply to artists : the control process (be it the filter of editors/publishers, or the filter of public reaction) is, to a point, lawful, but the process that generate solutions could benefit from a slight increase in chaos. Or more exactly, the combined (generator + filter) algorithm could perform better with a slightly more chaotic generator. To retake Eliezer's definition of creativity, which was \"<a href=\"/lw/vm/lawful_creativity/\">the creative surprise is the idea that ranks high in your <em>preference ordering</em> but low in your </a><em><a href=\"/lw/vm/lawful_creativity/\">search ordering</a></em>\", adding chaos to preference ordering would be pointless, but adding chaos to the search ordering can allow more creative surprise to happen in a given finite time.</p>\n<p>There is still a major difference between the two processes described here (evolution and human creativity) : evolution uses a fully random generator, whereas the human brain has a great ability of generating non-random designs, allowing a much faster improvement rate. You'll never get a book of Hemingway or a painting of Van Gogh by randomly selecting letters or randomly putting paint on a canvas. The chance of that is too infinitesimally low. So the generator will have to stay mostly lawful. Hemingway used words and respected the rules of grammar. Van Gogh painted something which look very like real sunflowers. A fully chaotic process would never produce anything near their masterpieces even given billions of years. So artistic creativity must be mostly lawful, even for generating its hypothesis to select from.</p>\n<p>As spotted by <a id=\"author_t1_54no\" href=\"/user/Vaniver\">Vaniver</a> in the comments, Hemingway himself said something very similar to that thesis : \"Write drunk; edit sober.\"</p>\n<h3 id=\"Avoiding_local_minimal\">Avoiding local minimal<br></h3>\n<p>One big problem of optimization processes is local minimal. Most of the naive optimization process, like a gradient descent, will get trapped into local minima. Let's have a look at that curve (burrowed from Wikipedia) :</p>\n<p><img style=\"vertical-align: middle;\" src=\"http://upload.wikimedia.org/wikipedia/commons/6/68/Extrema_example_original.svg\" alt=\"Local and global maxima, from Wikipedia\" width=\"515\" height=\"412\"></p>\n<p>If you start a naive optimization algorithm in the right part of the curve, you'll very likely end up in the <span style=\"color: #3366ff;\">local minimum</span>, while the <span style=\"color: #ff0000;\">global minimum</span> would rank much better in your preferences. Adding some form of controlled chaos to the algorithm is an easy way to increase the chance of reaching the <span style=\"color: #ff0000;\">global minimum<span style=\"color: #000000;\">, even in much more complex setups than this simple curve. </span></span></p>\n<p><span style=\"color: #ff0000;\"><span style=\"color: #000000;\">For a relatively broad class of problems, like selecting the best position of nodes to minimize the length of edges when doing a bitmap representation of a graph structure, an algorithm which works quite well and is simple to code is the <a href=\"https://en.wikipedia.org/wiki/Simulated_annealing\">simulated annealing</a> algorithm, which works by doing local optimizations, but having a global temperature which adds chaos (the higher the temperature, the more random is the process). The temperature itself decreases with the process, and ultimately reaches 0 (pure lawful optimization).</span></span></p>\n<p>Such methods are of course \"dirty hacks\", that are used only when the problem is too complicated and we don't have a purely lawful algorithm that gives the answer, or (most of the time) when we do have one, but with an exponential complexity, meaning we can't run it in real life.</p>\n<p>The same idea applies to human creativity : chaos wouldn't be needed, nor useful, if we had a fully working algorithm to write the best books or songs or make the best paintings. But since we don't, using a purely lawful process has a risk (but yes, only a risk) of getting us stuck into a local minimum - improving the methods of the previous generation of artists, but not inventing brand new styles of art. This is a similar concept to the \"jumping out of the system\" described by Douglas Hofstadter and <a href=\"/lw/vm/lawful_creativity/\">analyzed by Eliezer</a>. JOOTSing is escaping a local minimum. It's escaping the safe warmth of the valley, climbing the cold and dangerous mountain top, to find another, more fertile valley on the other side. That requires to violate the rules of \"staying into the safe and warm valley\".</p>\n<p>(Note : there is somehow an analogy between the use of drugs and the simulated annealing : drugs induce a state of high chaos, which then slowly goes down as the drug effects disappears. Or at least I was told so, since I never tried personally. But that seems a <a href=\"/lw/rj/surface_analogies_and_deep_causes/\">surface analogy</a> to me, so I won't give it much credit).</p>\n<h3 id=\"Inhibitions_and_art\">Inhibitions and art<br></h3>\n<p>Or another way to consider it is to look at is inhibitions : the human mind contains a process that'll check your actions (painting and writing in that case, but applies more broadly) and sometimes say \"no, don't do that, you'll look as a fool\". Those inhibitions are usually here to protect us from botching in social situations. But they are (as most of the human brain) imperfectly calibrated, and will tend to repress anything that goes out of the current norm. Lowering those inhibitions increases the risk of botching - but also the chance of doing something awesome.</p>\n<p>This points to much more general pattern, which applies when what matters is not improving your average gain, but your chance of being one of the few best. Consider you've a task to do, and two ways to achieve it. <span style=\"color: #339966;\">Way A</span> is quite classical, and doesn't involve much risk. <span style=\"color: #ff0000;\">Way B</span> is much less proven, and involves much risk of doing both better and worse. Being a role player, I usually use dice rolls to model those kinds of process. Let's say process A is 20d10. That means, rolling 20 times a 10-sided die, and doing the sum. This will give an expected value of 110, with only 1% of the rolls above 140. Now process B is 2d100 (rolling 2 times a 100-sided die and doing the sum). This will give a lower expected value, of 101 instead of 110. But with 18% of the rolls above 140. Here is a picture of the two process (<span style=\"color: #339966;\">way A</span> in green, <span style=\"color: #ff0000;\">way B</span> in red) generated with a quick Python script :</p>\n<p><img src=\"http://kilobug.net/lw/dice.png\" alt=\"2d100 (red) vs 20d10 (green)\" width=\"600\" height=\"400\"></p>\n<p>If what matters is doing your best in average (your score at the task will directly map to an amount of money between $2 and $200), then the best choice is to look only at the expected value of <span style=\"color: #339966;\">A</span> and <span style=\"color: #ff0000;\">B</span>, and select the one which has the best expected value, so <span style=\"color: #339966;\">A</span> in this case, as you can see, the green curve peaks at a higher value.</p>\n<p>But if what matters is not doing the best in average, but being the best : 100 people are performing the task, and the best will take the prize, the rest won't have anything. Then, you except one of the 100 to be above 140, even if they all use <span style=\"color: #339966;\">way A</span>. So for yourself, if you use <span style=\"color: #339966;\">way A</span>, you only have 1 chance in 100 to be above 140. If you use <span style=\"color: #ff0000;\">way B</span>, you've 18 chances in 100 of beating the 140 mark. Looking at the curve, there is much bigger blob of the red curve that goes to very high values.</p>\n<p>When looking at arts, we don't regard the average. Countless people write books or paint. Almost everyone at least tried once. What history remembers are the few best of their time. Not those who did better in average, but those who manage to do better than most of their peers. Those to the right of the picture, in which the amplitude of the green curve is nearly void, but the red curve still exists.</p>\n<h2 id=\"The_complexity_of_testing_certain_hypothesis\">The complexity of testing certain hypothesis</h2>\n<p>I emitted many hypothesis in this article, to try to explain the common knowledge that \"so many great artists take drugs\", and more generally to look into the reasons for which chaos can, in some cases, improve a result.</p>\n<p>All those hypothesis seem totally plausible to me - and I would say that they all play a role in the process. But saying \"everything plays a role\" is not saying much, a graph with all possible edges contains as much informations as a graph with no edge. What would be require now is to consider how much each hypothesis contributes to the result - and then, probably one or two will account for most.</p>\n<p>But how can we setup such a test ? In physics, doing experiments is relatively easy. It can costs a lot like building the LHC or sending the Hubble space telescope in orbit, but still, devising experiments is relatively easy. In social sciences, it's often much harder. Most social science experiments are done on a panel of test subjects (with a control group, ...). But right now we are speaking of the <em>best artists</em>. How can we build such a panel ? Defining who are the best artists is a very hard task. And then, getting them to participate in studies...</p>\n<p>The simplest hypothesis to test, the availability bias, would require a procedure like (numbers can be adjusted) :</p>\n<ol>\n<li>Take 1000 people at random, from various ages, social classes and background.</li>\n<li>Ask for each of them to name the 10 artists they like the most (without of course mentioning the purpose of the experiment).</li>\n<li>For each artist nominated by at least 4 persons, look if that artist did take drugs.</li>\n<li>Compare with the average drug use.</li>\n</ol>\n<p>But even that is not without troubles : for 3., how can you be sure an artist didn't take drug secretly, especially in time/places where drug use is prohibited or frown upon ? For 4., how do you ponder for the variation in drug use depending of the place/time ?</p>\n<p>Does anyone know of such a study (I couldn't find any, but I'm not well versed in the art for looking for social science studies) ?</p>\n<p>For the other hypothesis, testing them becomes even harder.</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>As Eliezer explained, pure chaos cannot lead to anything but static on a TV screen. Any optimization process, and art is one, requires a lawful part. But as I showed, for several reasons, an imperfect optimization process may perform better with a limited amount of added chaos. Since the human brain is an imperfect optimization process, it would not be surprising that in the purpose of creating awesome pieces of art in a limited time, some added chaos can help. But on the other hand, there are other reasons for which there could be a common knowledge that \"artistic creativity requires some chaos\" even if it were not true. And it is very hard to tell apart the various reasons.</p>\n<p>But even if <em>some amount</em> of chaos can help in generating exceptionally awesome pieces of art, it should not shadow the fact that the lawful part of process is absolutely required, and even the most important one; nor that chaos can only be useful when the optimization is itself imperfect. Improving the quality of the optimization process (by, for example, raising the sanity waterline or understanding better the human brain) would lower the need of chaos to generate the same awesomeness.</p>\n<p><em>PS : I post that to \"Less Wrong discussion\", for initial review and because it's half-way between a \"real\" article and a call for discussion on the topic. Depending of feedback, I hope to repost it to \"main Less Wrong\", hopefully improved from the feedback.</em></p>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "Reasons for which it could be an illusion", "anchor": "Reasons_for_which_it_could_be_an_illusion", "level": 1}, {"title": "Availability bias", "anchor": "Availability_bias", "level": 2}, {"title": "Reverse causality", "anchor": "Reverse_causality", "level": 2}, {"title": "Common cause", "anchor": "Common_cause", "level": 2}, {"title": "So, where do we stand now ?", "anchor": "So__where_do_we_stand_now__", "level": 2}, {"title": "Reasons for which it could be real", "anchor": "Reasons_for_which_it_could_be_real", "level": 1}, {"title": "Chaos and optimization", "anchor": "Chaos_and_optimization", "level": 2}, {"title": "Lawfully controlled chaotic optimization", "anchor": "Lawfully_controlled_chaotic_optimization", "level": 2}, {"title": "Avoiding local minimal", "anchor": "Avoiding_local_minimal", "level": 2}, {"title": "Inhibitions and art", "anchor": "Inhibitions_and_art", "level": 2}, {"title": "The complexity of testing certain hypothesis", "anchor": "The_complexity_of_testing_certain_hypothesis", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "35 comments"}], "headingsCount": 15}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["R8cpqD3NA4rZxRdQ4", "82eMd5KLiJ5Z6rTrr", "X2AD2LgtKgkRNPj2a", "KKLQp934n77cfZpPn", "6ByPxcGDhmx74gPSm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T01:18:17.035Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Conjuring an Evolution to Serve You", "slug": "seq-rerun-conjuring-an-evolution-to-serve-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.412Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yCWWKw4FLKsQp9nmL/seq-rerun-conjuring-an-evolution-to-serve-you", "pageUrlRelative": "/posts/yCWWKw4FLKsQp9nmL/seq-rerun-conjuring-an-evolution-to-serve-you", "linkUrl": "https://www.lesswrong.com/posts/yCWWKw4FLKsQp9nmL/seq-rerun-conjuring-an-evolution-to-serve-you", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Conjuring%20an%20Evolution%20to%20Serve%20You&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Conjuring%20an%20Evolution%20to%20Serve%20You%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCWWKw4FLKsQp9nmL%2Fseq-rerun-conjuring-an-evolution-to-serve-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Conjuring%20an%20Evolution%20to%20Serve%20You%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCWWKw4FLKsQp9nmL%2Fseq-rerun-conjuring-an-evolution-to-serve-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyCWWKw4FLKsQp9nmL%2Fseq-rerun-conjuring-an-evolution-to-serve-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 272, "htmlBody": "<p>Today's post, <a href=\"/lw/l8/conjuring_an_evolution_to_serve_you/\">Conjuring An Evolution To Serve You</a> was originally published on 19 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If you take the hens who lay the most eggs in each generation, and breed from them, you should get hens who lay more and more eggs. Sounds logical, right? But this selection may actually favor the most dominant hen, that pecked its way to the top of the pecking order at the expense of other hens. Such breeding programs produce hens that must be housed in individual cages, or they will peck each other to death. Jeff Skilling of Enron fancied himself an evolution-conjurer - summoning <em>the awesome power of evolution</em> to work for him - and so, every year, every Enron employee's performance would be evaluated, and the bottom 10% would get fired, and the top performers would get huge raises and bonuses...</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/r/discussion/lw/88j/seq_rerun_the_simple_math_of_everything/#comments\">The Simple Math of Everything</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yCWWKw4FLKsQp9nmL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 7.920735766551309e-07, "legacy": true, "legacyId": "10682", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KE8wPzGiX5QPotyS8", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T01:27:46.552Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup 11-02-2011", "slug": "meetup-west-la-meetup-11-02-2011", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3y3qbkEAjupmBQWeB/meetup-west-la-meetup-11-02-2011", "pageUrlRelative": "/posts/3y3qbkEAjupmBQWeB/meetup-west-la-meetup-11-02-2011", "linkUrl": "https://www.lesswrong.com/posts/3y3qbkEAjupmBQWeB/meetup-west-la-meetup-11-02-2011", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%2011-02-2011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%2011-02-2011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3y3qbkEAjupmBQWeB%2Fmeetup-west-la-meetup-11-02-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%2011-02-2011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3y3qbkEAjupmBQWeB%2Fmeetup-west-la-meetup-11-02-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3y3qbkEAjupmBQWeB%2Fmeetup-west-la-meetup-11-02-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4k'>West LA Meetup 11-02-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">02 November 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7pm - 9pm Wednesday, November 2nd.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em>, located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Recommended Reading:</strong></p>\n\n<ul>\n<li>The theme this week is goals. To that end, I recommend people have a look at the posts in <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a>.</li>\n</ul>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4k'>West LA Meetup 11-02-2011</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3y3qbkEAjupmBQWeB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 7.920768777394679e-07, "legacy": true, "legacyId": "10683", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_11_02_2011\">Discussion article for the meetup : <a href=\"/meetups/4k\">West LA Meetup 11-02-2011</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">02 November 2011 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7pm - 9pm Wednesday, November 2nd.</p>\n\n<p><strong>Where:</strong> The <a href=\"http://www.westsidetavernla.com/\" rel=\"nofollow\">Westside Tavern</a> <em>in the upstairs Wine Bar</em>, located inside the <a href=\"http://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters.</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong id=\"Recommended_Reading_\">Recommended Reading:</strong></p>\n\n<ul>\n<li>The theme this week is goals. To that end, I recommend people have a look at the posts in <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a>.</li>\n</ul>\n\n<p>Whether you're a regular reader or totally new, here for the theoretical musings or the practical things, come by and say hello! The conversation is largely unstructured, and the people are awesome.</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup_11_02_20111\">Discussion article for the meetup : <a href=\"/meetups/4k\">West LA Meetup 11-02-2011</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup 11-02-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_11_02_2011", "level": 1}, {"title": "Recommended Reading:", "anchor": "Recommended_Reading_", "level": 2}, {"title": "Discussion article for the meetup : West LA Meetup 11-02-2011", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup_11_02_20111", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T02:46:50.656Z", "modifiedAt": null, "url": null, "title": "Less Wrong Couchsurfing Network", "slug": "less-wrong-couchsurfing-network", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:02.913Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "loxfordian", "createdAt": "2011-06-29T21:58:01.487Z", "isAdmin": false, "displayName": "loxfordian"}, "userId": "xS2YQg3M68zu5w6gC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DBeTqcPgS54Pr3Dan/less-wrong-couchsurfing-network", "pageUrlRelative": "/posts/DBeTqcPgS54Pr3Dan/less-wrong-couchsurfing-network", "linkUrl": "https://www.lesswrong.com/posts/DBeTqcPgS54Pr3Dan/less-wrong-couchsurfing-network", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20Couchsurfing%20Network&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20Couchsurfing%20Network%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDBeTqcPgS54Pr3Dan%2Fless-wrong-couchsurfing-network%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20Couchsurfing%20Network%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDBeTqcPgS54Pr3Dan%2Fless-wrong-couchsurfing-network", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDBeTqcPgS54Pr3Dan%2Fless-wrong-couchsurfing-network", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 556, "htmlBody": "<p>One of my favorite aspects of Less Wrong is that every time I go to a new city (Oxford, Boston, Philadelphia and New York soon!), I know there&rsquo;s a group of people who will be happy to discuss rationality and welcome me into their community.</p>\n<p>It would be really cool if more Less Wrongers could have these experiences by traveling cheaply from city to city, meeting up with other smart, interesting people to have fantastic conversations, go to meetups/conferences/summits in new cities, and make friends in real life!</p>\n<p>Unfortunately, while traveling to different meetups (and conferences/summits) is intellectually and emotionally rewarding, hotels can be prohibitively expensive. In order to make traveling more affordable, the Less Wrong community could implement a system where community members can stay at each others houses (in guest rooms, on sofas, or on floors) for free/extremely affordable rates.</p>\n<p>Benefits of this system:<br /> 1) The traveler gets a free/affordable place to stay.<br /> 2) The host gets guaranteed company and (hopefully) some great conversation.<br /> 3) Less Wrong community bonds will be strengthened through real life interactions between members.<br /> 4) The value of meetups, which largely derives from the chance to meet other LWers, will increase as the pool of people attending grows.<br /> 5) People can be friends in real life!<br /> 6) Implementing this system is super easy. We just add a google maps page to Less Wrong.</p>\n<p>Logistics:<br /> 1) LW could create a google map where people interested in hosting put down a place marker in their general location (no need to list their actual address) and tag it with their username. <br /> 2) In their LW profiles, hosts could write a short description of what kind of accommodations they'll be providing (room/sofa/floor), what kind of guest they want to host (eg., male vs. female, people who are willing to talk a lot, etc.), how they want to be compensated by their traveler (e.g., conversation, a meal, a chore, a small monetary gift, etc.) and usernames of at least two other Less Wrong members who would be willing to serve as \"references\" to the host's non-creepiness.<br /> 3) Likewise, travelers should have a section in their LW profile that list at least two other Less Wrong members who are willing to serve as references as well as how they're willing to compensate their hosts.<br /> 4) A potential traveler would look at the map, find a suitable location, and then send a potential host a message asking if they can come over.<br /> 5) The host could then look at the traveler's posts to see how long they've been a member and read their posts (a fantastic measure of how interesting or obnoxious the potential traveler may be).</p>\n<p>How to encourage people to host:<br /> While the benefits are obvious for the travelers, benefits for hosts are slightly less tangible. Here are some ways to incentivize hosting.<br /> 1) Traveling etiquette states that the traveler offers their host a gift. (E.g., buys or cooks the host a meal, does a house chore, goes to a museum with their host, etc.).<br /> 2) Much like how LW keeps track of number of posts, up votes and down votes, there will also be a scoreboard for how many travelers people have hosted. Hopefully, this will make being a popular host a badge of pride.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DBeTqcPgS54Pr3Dan", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 59, "extendedScore": null, "score": 0.00014032266843013117, "legacy": true, "legacyId": "10687", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T18:40:41.441Z", "modifiedAt": null, "url": null, "title": "Wiki Quote Attributions", "slug": "wiki-quote-attributions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.622Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ryNskuYsiKAqoXYua/wiki-quote-attributions", "pageUrlRelative": "/posts/ryNskuYsiKAqoXYua/wiki-quote-attributions", "linkUrl": "https://www.lesswrong.com/posts/ryNskuYsiKAqoXYua/wiki-quote-attributions", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Wiki%20Quote%20Attributions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWiki%20Quote%20Attributions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FryNskuYsiKAqoXYua%2Fwiki-quote-attributions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Wiki%20Quote%20Attributions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FryNskuYsiKAqoXYua%2Fwiki-quote-attributions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FryNskuYsiKAqoXYua%2Fwiki-quote-attributions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 252, "htmlBody": "<p>After an interesting discussion the <a style=\"text-indent: -24px;\" href=\"/lw/7wm/rationality_quotes_october_2011/4y5e\">last time this topic came up</a><span style=\"text-indent: -24px;\">, I wanted people's input on the best way to attribute a quote to the LessWrong Wiki. The passage is obviously based on Eliezer's work, but he himself didn't write the summary. From the </span><a style=\"text-indent: -24px;\" href=\"http://wiki.lesswrong.com/mediawiki/index.php?title=Rationalists_should_win&amp;action=history\">quote logs</a><span style=\"text-indent: -24px;\">, it was </span><a style=\"text-indent: -24px;\" href=\"http://wiki.lesswrong.com/wiki/User:Z._M._Davis\">Z. M. Davis</a><span style=\"text-indent: -24px;\"> who originally wrote the passage. Below is the attribution as I currently have it. The issues with this are fairly obvious: The wiki can change. There's a legitimate argument that Eliezer really deserves the intellectual credit for this, even though they're not exactly his words. And is it more appropriate for the link to go to the wiki, which doesn't justify the words as Davis's, or to the quote logs, which do?</span></p>\n<hr />\n<p>\"The point of all this discussion of rationality is to actually achieve truer beliefs and more effective actions. It's not some arbitrary social fashion; there are actual criteria of success. It is for this reason that it is written that <strong style=\"text-indent: -24px;\">rationalists should <em>win</em></strong><span style=\"text-indent: -24px;\">. If some particular ritual of cognition&mdash;even one that you have long cherished as \"rational\"&mdash;systematically gives poorer results relative to some alternative, it is </span><em style=\"text-indent: -24px;\">not</em><span style=\"text-indent: -24px;\"> rational to cling to it. The rational algorithm is to </span><em style=\"text-indent: -24px;\">do what works</em><span style=\"text-indent: -24px;\">, to get the actual </span><em style=\"text-indent: -24px;\">answer</em><span style=\"text-indent: -24px;\">&mdash;in short, to </span><em style=\"text-indent: -24px;\">win</em><span style=\"text-indent: -24px;\">, whatever the method, whatever the means. If you can </span><em style=\"text-indent: -24px;\">detect</em><span style=\"text-indent: -24px;\"> a systematic mistake in your thinking, then </span><em style=\"text-indent: -24px;\">fix it</em><span style=\"text-indent: -24px;\">; if you can </span><em style=\"text-indent: -24px;\">see</em><span style=\"text-indent: -24px;\"> a better method, then </span><em style=\"text-indent: -24px;\">adopt it</em><span style=\"text-indent: -24px;\">.&rdquo; &ndash; </span><a style=\"text-indent: -24px;\" href=\"http://wiki.lesswrong.com/wiki/User:Z._M._Davis\">Z. M. Davis</a><span style=\"text-indent: -24px;\">, </span><a style=\"text-indent: -24px;\" href=\"http://wiki.lesswrong.com/wiki/Rationalists_should_win\">&ldquo;Rationalists Should Win&rdquo;</a><span style=\"text-indent: -24px;\">, on the </span><a style=\"text-indent: -24px;\" href=\"http://wiki.lesswrong.com/wiki/LessWrong_Wiki\">LessWrong Wiki</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ryNskuYsiKAqoXYua", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 7.924362480296831e-07, "legacy": true, "legacyId": "10698", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T19:48:33.263Z", "modifiedAt": null, "url": null, "title": "Foundations of Inference", "slug": "foundations-of-inference", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:19.550Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "amcknight", "createdAt": "2010-12-27T09:32:36.170Z", "isAdmin": false, "displayName": "amcknight"}, "userId": "YuN6asu3NWKwpEEQz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S3drS9h9RHjnRdwEL/foundations-of-inference", "pageUrlRelative": "/posts/S3drS9h9RHjnRdwEL/foundations-of-inference", "linkUrl": "https://www.lesswrong.com/posts/S3drS9h9RHjnRdwEL/foundations-of-inference", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Foundations%20of%20Inference&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFoundations%20of%20Inference%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS3drS9h9RHjnRdwEL%2Ffoundations-of-inference%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Foundations%20of%20Inference%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS3drS9h9RHjnRdwEL%2Ffoundations-of-inference", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS3drS9h9RHjnRdwEL%2Ffoundations-of-inference", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 146, "htmlBody": "<p>I've recently been getting into all of this wonderful Information Theory stuff and have come across a paper (thanks to <a href=\"/user/jsalvatier\">John Salvatier</a>) that was written by <a title=\"Knuth's Lab's Papers\" href=\"http://knuthlab.rit.albany.edu/index.php/Products/Papers\">Kevin H. Knuth</a>:</p>\n<p><a href=\"http://arxiv.org/abs/1008.4831\">Foundations of Inference</a></p>\n<p>The paper sets up some intuitive minimal axioms for quantifying power sets and then (seems to) use them to <em>derive</em> Bayesian probability theory, information gain, and Shannon Entropy. The paper also claims to use less assumptions than both <a title=\"Cox's Theorem\" href=\"http://en.wikipedia.org/wiki/Cox%27s_theorem\">Cox</a> and <a title=\"Kolmogorov Complexity\" href=\"http://en.wikipedia.org/wiki/Kolmogorov_complexity\">Kolmogorov</a> when choosing axioms. This seems like a significant foundation/unification. I'd like to hear whether others agree and what parts of the paper you think are the significant contributions.</p>\n<p>If a 14 page paper is too long for you, I recommend skipping to the conclusion (starting at the bottom of page 12) where there is a nice picture representation of the axioms and a quick summary of what they imply.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S3drS9h9RHjnRdwEL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 16, "extendedScore": null, "score": 7.924598691635902e-07, "legacy": true, "legacyId": "10699", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T21:44:44.965Z", "modifiedAt": null, "url": null, "title": "Write about risk and decision-making, win money", "slug": "write-about-risk-and-decision-making-win-money", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.873Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BjLxPLsev54LFCS3A/write-about-risk-and-decision-making-win-money", "pageUrlRelative": "/posts/BjLxPLsev54LFCS3A/write-about-risk-and-decision-making-win-money", "linkUrl": "https://www.lesswrong.com/posts/BjLxPLsev54LFCS3A/write-about-risk-and-decision-making-win-money", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Write%20about%20risk%20and%20decision-making%2C%20win%20money&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWrite%20about%20risk%20and%20decision-making%2C%20win%20money%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBjLxPLsev54LFCS3A%2Fwrite-about-risk-and-decision-making-win-money%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Write%20about%20risk%20and%20decision-making%2C%20win%20money%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBjLxPLsev54LFCS3A%2Fwrite-about-risk-and-decision-making-win-money", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBjLxPLsev54LFCS3A%2Fwrite-about-risk-and-decision-making-win-money", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 52, "htmlBody": "<p>A company near me is running an \"outreach competition\" with a first prize of 200 euro (=$275) for essays on \"risk\" from high school and university students. I know the person running the competition and he's very interested in probability calibration and cognitive biases. You can read more about the competition <a href=\"http://blog.projectionpoint.com/?p=204\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BjLxPLsev54LFCS3A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 7.925003157642711e-07, "legacy": true, "legacyId": "10700", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-10-31T23:58:38.110Z", "modifiedAt": null, "url": null, "title": "Great Explanations", "slug": "great-explanations", "viewCount": null, "lastCommentedAt": "2021-11-24T13:07:20.609Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6t4EjTfNzC6jN69ad/great-explanations", "pageUrlRelative": "/posts/6t4EjTfNzC6jN69ad/great-explanations", "linkUrl": "https://www.lesswrong.com/posts/6t4EjTfNzC6jN69ad/great-explanations", "postedAtFormatted": "Monday, October 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Great%20Explanations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGreat%20Explanations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6t4EjTfNzC6jN69ad%2Fgreat-explanations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Great%20Explanations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6t4EjTfNzC6jN69ad%2Fgreat-explanations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6t4EjTfNzC6jN69ad%2Fgreat-explanations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 662, "htmlBody": "<blockquote>\n<p>Explaining is a difficult art. You can explain something so that your reader understands the words; [I try to] explain something so that the reader feels it in the marrow of his bones.</p>\n</blockquote>\n<p align=\"right\">Richard Dawkins</p>\n<p>&nbsp;</p>\n<p>My private school taught biology from the infamous creationist textbook <em><a href=\"http://en.wikipedia.org/wiki/Biology_for_Christian_Schools\">Biology for Christian Schools</a></em>, so my early understanding of evolution was a bit... <a href=\"http://scienceblogs.com/authority/2007/09/more_bob_jones_biology_for_chr.php\">confused</a>. Lacking the <a href=\"/lw/4ku/use_curiosity/\">curiosity</a> to, say, check <a href=\"http://en.wikipedia.org/wiki/Altavista\">Altavista</a> for a <em>biologist&rsquo;s</em> explanation (faith is a <em>virtue</em>, don&rsquo;t ya know), I remained confused about evolution for years.</p>\n<p>Eventually I stumbled across an eloquent explanation of the fact that natural selection follows <a href=\"http://en.wikipedia.org/wiki/Evolution#Natural_selection\">necessarily</a> from heritability, variation, and selection.</p>\n<p><em>Click</em>. I got it.</p>\n<p>Explaining is <a href=\"/lw/kh/explainers_shoot_high_aim_low/\">hard</a>. Explainers need to pierce shields of misinformation (creationism), bridge vast <a href=\"/lw/kg/expecting_short_inferential_distances\">inferential distances</a> (probability theory), and cause readers to feel the truth of foreign concepts (quantum entanglement) in their bones. That isn&rsquo;t easy. Those who do it well are rare and valuable.</p>\n<p>Textbook writers are often skilled at explaining complex fields. That&rsquo;s why I called on my fellow Less Wrongers to name their favorite textbooks (<em>if</em> they had read at least two other textbooks on those subjects). <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">The Best Textbooks on Every Subject</a> now gives 22 textbook recommendations, for fields as diverse as scientific self-help and representation theory.</p>\n<p>Now I want to jump down a few levels in <a href=\"/lw/5p6/how_and_why_to_granularize/\">granularity</a>. Let&rsquo;s pool our knowledge to find <strong>great explanations for each important idea</strong> (in math, science, philosophy, etc.), whether or not there is equal value in the <em>rest</em> of the book or article in which each explanation is found.</p>\n<p>Great explanations, in my meaning, have four traits:</p>\n<ol>\n<li>\n<p>A great explanation does more than report facts; it uses analogy and rhetoric and other tools to make readers feel the target idea in their bones.</p>\n</li>\n<li>\n<p>A great explanation is not a single analogy nor a giant book. It is, roughly, between 2 and 100 pages in length.</p>\n</li>\n<li>\n<p>A great explanation is comprehensible at best to a young teenager, or at least to a 75th percentile college graduate. (There may be no way to seriously explain string theory to an average 13-year-old.)</p>\n</li>\n<li>\n<p>A great explanation is <a href=\"/lw/86a/rhetoric_for_the_good/\">exciting to read</a>.</p>\n</li>\n</ol>\n<p>By sharing great explanations we can more often experience <a href=\"/lw/1mh/that_magical_click/\">that magical click</a>.</p>\n<p><a id=\"more\"></a></p>\n<h3><br /></h3>\n<h3>List of Great Explanations</h3>\n<p>I&rsquo;ve barely begun to assemble the list below. Please comment with your own additions!</p>\n<p>(The list below is exclusive to <em>written</em> explanations, but feel free to share your favorite explanations from other media. My favorite explanation of BASIC programming is a piece of software from Interplay called <em><a href=\"http://www.amazon.com/Learn-Program-Basic-Windows-Macintosh/dp/B000N3W2L4/\">Learn to Program BASIC</a></em>, and of course many people love <a href=\"http://www.khanacademy.org/\">Khan Academy&rsquo;s</a> videos and <a href=\"http://www.thegreatcourses.com/\">The Teaching Company&rsquo;s</a> audio courses.)</p>\n<p><strong>Epistemology</strong></p>\n<ul>\n<li>\n<p>Aumann&rsquo;s agreement theorem: Landsburg, <em>The Big Questions</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Landsburg-Diogenes-Nightmare.pdf\">chapter 8</a>.</p>\n</li>\n<li>\n<p>Occam&rsquo;s razor: Yudkowsky, <a href=\"/lw/jp/occams_razor/\">Occam&rsquo;s razor</a>.</p>\n</li>\n</ul>\n<p><strong>Math and Logic</strong></p>\n<ul>\n<li>Bayes&rsquo; Theorem: Yudkowsky, <a href=\"http://yudkowsky.net/rational/bayes\">An Intuitive Explanation of Bayes&rsquo; Theorem</a>.</li>\n</ul>\n<p><strong>Physics</strong></p>\n<ul>\n<li>\n<p>Special relativity: Wolfson, <em><a href=\"http://www.amazon.com/Simply-Einstein-Demystified-Richard-Wolfson/dp/0393325075/\">Simply Einstein</a></em>, chapters 2&ndash;12.</p>\n</li>\n<li>\n<p>General relativity: Hawking, <em><a href=\"http://www.amazon.com/Universe-Nutshell-Stephen-William-Hawking/dp/055380202X/\">The Universe in a Nutshell</a></em>, chapters 1&ndash;2.</p>\n</li>\n<li>\n<p>Infinite, flat universe: Greene, <em>The Hidden Reality</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Greene-Hidden-Reality-chs-1-3.pdf\">chapters 1&ndash;3</a>.</p>\n</li>\n<li>\n<p>Timeless reality / block universe: Greene, <em>The Fabric of Reality</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Greene-The-Frozen-River.pdf\">chapter 5</a>.</p>\n</li>\n<li>\n<p>Inflationary cosmology: Greene, <em>The Hidden Reality</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Greene-The-Hidden-Reality-ch-3.pdf\">chapter 3</a>.</p>\n</li>\n<li>\n<p>Rainbows: Dawkins, <em><a href=\"http://www.amazon.com/Magic-Reality-Know-Whats-Really/dp/1439192812/\">The Magic of Reality</a></em>, chapter 7.</p>\n</li>\n</ul>\n<p><strong>Biology</strong></p>\n<ul>\n<li>Tool use in animals: Zimmer, <a href=\"http://carlzimmer.com/articles/2010.php?subaction=showfull&amp;id=1294079768&amp;archive=&amp;start_from=&amp;ucat=13&amp;\">50 Years of Animal Technology</a>.</li>\n</ul>\n<p><strong>Psychology</strong></p>\n<ul>\n<li>\n<p>Anchoring: Kahneman, <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>, chapter 11.</p>\n</li>\n<li>\n<p>Availability heuristic: Kahneman, <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>, chapters 12&ndash;13.</p>\n</li>\n<li>\n<p>Prospect theory: Kahneman, <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>, chapters 25&ndash;26.</p>\n</li>\n<li>\n<p>Modularity of mind: Kurzban, <em><a href=\"http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748/\">Why Everyone (Else) is a Hypocrite</a></em>, chapters 1&ndash;4.</p>\n</li>\n</ul>\n<p><strong>Economics</strong></p>\n<ul>\n<li>The Pareto Principle: BetterExplained, <a href=\"http://betterexplained.com/articles/understanding-the-pareto-principle-the-8020-rule/\">Understanding the Pareto Principle</a>.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"WPkEd3et8f488w8LT": 1, "EdDGrAxYcrXnKkDca": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6t4EjTfNzC6jN69ad", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 34, "extendedScore": null, "score": 7e-05, "legacy": true, "legacyId": "10701", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p>Explaining is a difficult art. You can explain something so that your reader understands the words; [I try to] explain something so that the reader feels it in the marrow of his bones.</p>\n</blockquote>\n<p align=\"right\">Richard Dawkins</p>\n<p>&nbsp;</p>\n<p>My private school taught biology from the infamous creationist textbook <em><a href=\"http://en.wikipedia.org/wiki/Biology_for_Christian_Schools\">Biology for Christian Schools</a></em>, so my early understanding of evolution was a bit... <a href=\"http://scienceblogs.com/authority/2007/09/more_bob_jones_biology_for_chr.php\">confused</a>. Lacking the <a href=\"/lw/4ku/use_curiosity/\">curiosity</a> to, say, check <a href=\"http://en.wikipedia.org/wiki/Altavista\">Altavista</a> for a <em>biologist\u2019s</em> explanation (faith is a <em>virtue</em>, don\u2019t ya know), I remained confused about evolution for years.</p>\n<p>Eventually I stumbled across an eloquent explanation of the fact that natural selection follows <a href=\"http://en.wikipedia.org/wiki/Evolution#Natural_selection\">necessarily</a> from heritability, variation, and selection.</p>\n<p><em>Click</em>. I got it.</p>\n<p>Explaining is <a href=\"/lw/kh/explainers_shoot_high_aim_low/\">hard</a>. Explainers need to pierce shields of misinformation (creationism), bridge vast <a href=\"/lw/kg/expecting_short_inferential_distances\">inferential distances</a> (probability theory), and cause readers to feel the truth of foreign concepts (quantum entanglement) in their bones. That isn\u2019t easy. Those who do it well are rare and valuable.</p>\n<p>Textbook writers are often skilled at explaining complex fields. That\u2019s why I called on my fellow Less Wrongers to name their favorite textbooks (<em>if</em> they had read at least two other textbooks on those subjects). <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">The Best Textbooks on Every Subject</a> now gives 22 textbook recommendations, for fields as diverse as scientific self-help and representation theory.</p>\n<p>Now I want to jump down a few levels in <a href=\"/lw/5p6/how_and_why_to_granularize/\">granularity</a>. Let\u2019s pool our knowledge to find <strong>great explanations for each important idea</strong> (in math, science, philosophy, etc.), whether or not there is equal value in the <em>rest</em> of the book or article in which each explanation is found.</p>\n<p>Great explanations, in my meaning, have four traits:</p>\n<ol>\n<li>\n<p>A great explanation does more than report facts; it uses analogy and rhetoric and other tools to make readers feel the target idea in their bones.</p>\n</li>\n<li>\n<p>A great explanation is not a single analogy nor a giant book. It is, roughly, between 2 and 100 pages in length.</p>\n</li>\n<li>\n<p>A great explanation is comprehensible at best to a young teenager, or at least to a 75th percentile college graduate. (There may be no way to seriously explain string theory to an average 13-year-old.)</p>\n</li>\n<li>\n<p>A great explanation is <a href=\"/lw/86a/rhetoric_for_the_good/\">exciting to read</a>.</p>\n</li>\n</ol>\n<p>By sharing great explanations we can more often experience <a href=\"/lw/1mh/that_magical_click/\">that magical click</a>.</p>\n<p><a id=\"more\"></a></p>\n<h3><br></h3>\n<h3 id=\"List_of_Great_Explanations\">List of Great Explanations</h3>\n<p>I\u2019ve barely begun to assemble the list below. Please comment with your own additions!</p>\n<p>(The list below is exclusive to <em>written</em> explanations, but feel free to share your favorite explanations from other media. My favorite explanation of BASIC programming is a piece of software from Interplay called <em><a href=\"http://www.amazon.com/Learn-Program-Basic-Windows-Macintosh/dp/B000N3W2L4/\">Learn to Program BASIC</a></em>, and of course many people love <a href=\"http://www.khanacademy.org/\">Khan Academy\u2019s</a> videos and <a href=\"http://www.thegreatcourses.com/\">The Teaching Company\u2019s</a> audio courses.)</p>\n<p><strong id=\"Epistemology\">Epistemology</strong></p>\n<ul>\n<li>\n<p>Aumann\u2019s agreement theorem: Landsburg, <em>The Big Questions</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Landsburg-Diogenes-Nightmare.pdf\">chapter 8</a>.</p>\n</li>\n<li>\n<p>Occam\u2019s razor: Yudkowsky, <a href=\"/lw/jp/occams_razor/\">Occam\u2019s razor</a>.</p>\n</li>\n</ul>\n<p><strong id=\"Math_and_Logic\">Math and Logic</strong></p>\n<ul>\n<li>Bayes\u2019 Theorem: Yudkowsky, <a href=\"http://yudkowsky.net/rational/bayes\">An Intuitive Explanation of Bayes\u2019 Theorem</a>.</li>\n</ul>\n<p><strong id=\"Physics\">Physics</strong></p>\n<ul>\n<li>\n<p>Special relativity: Wolfson, <em><a href=\"http://www.amazon.com/Simply-Einstein-Demystified-Richard-Wolfson/dp/0393325075/\">Simply Einstein</a></em>, chapters 2\u201312.</p>\n</li>\n<li>\n<p>General relativity: Hawking, <em><a href=\"http://www.amazon.com/Universe-Nutshell-Stephen-William-Hawking/dp/055380202X/\">The Universe in a Nutshell</a></em>, chapters 1\u20132.</p>\n</li>\n<li>\n<p>Infinite, flat universe: Greene, <em>The Hidden Reality</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Greene-Hidden-Reality-chs-1-3.pdf\">chapters 1\u20133</a>.</p>\n</li>\n<li>\n<p>Timeless reality / block universe: Greene, <em>The Fabric of Reality</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Greene-The-Frozen-River.pdf\">chapter 5</a>.</p>\n</li>\n<li>\n<p>Inflationary cosmology: Greene, <em>The Hidden Reality</em>, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/10/Greene-The-Hidden-Reality-ch-3.pdf\">chapter 3</a>.</p>\n</li>\n<li>\n<p>Rainbows: Dawkins, <em><a href=\"http://www.amazon.com/Magic-Reality-Know-Whats-Really/dp/1439192812/\">The Magic of Reality</a></em>, chapter 7.</p>\n</li>\n</ul>\n<p><strong id=\"Biology\">Biology</strong></p>\n<ul>\n<li>Tool use in animals: Zimmer, <a href=\"http://carlzimmer.com/articles/2010.php?subaction=showfull&amp;id=1294079768&amp;archive=&amp;start_from=&amp;ucat=13&amp;\">50 Years of Animal Technology</a>.</li>\n</ul>\n<p><strong id=\"Psychology\">Psychology</strong></p>\n<ul>\n<li>\n<p>Anchoring: Kahneman, <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>, chapter 11.</p>\n</li>\n<li>\n<p>Availability heuristic: Kahneman, <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>, chapters 12\u201313.</p>\n</li>\n<li>\n<p>Prospect theory: Kahneman, <em><a href=\"http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374275637/\">Thinking, Fast and Slow</a></em>, chapters 25\u201326.</p>\n</li>\n<li>\n<p>Modularity of mind: Kurzban, <em><a href=\"http://www.amazon.com/Why-Everyone-Else-Hypocrite-Evolution/dp/0691146748/\">Why Everyone (Else) is a Hypocrite</a></em>, chapters 1\u20134.</p>\n</li>\n</ul>\n<p><strong id=\"Economics\">Economics</strong></p>\n<ul>\n<li>The Pareto Principle: BetterExplained, <a href=\"http://betterexplained.com/articles/understanding-the-pareto-principle-the-8020-rule/\">Understanding the Pareto Principle</a>.</li>\n</ul>", "sections": [{"title": "List of Great Explanations", "anchor": "List_of_Great_Explanations", "level": 1}, {"title": "Epistemology", "anchor": "Epistemology", "level": 2}, {"title": "Math and Logic", "anchor": "Math_and_Logic", "level": 2}, {"title": "Physics", "anchor": "Physics", "level": 2}, {"title": "Biology", "anchor": "Biology", "level": 2}, {"title": "Psychology", "anchor": "Psychology", "level": 2}, {"title": "Economics", "anchor": "Economics", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "115 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 116, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WrSe4aB8sWBy3Nphm", "2TPph4EGZ6trEbtku", "HLqWn5LASfhhArZ7w", "xg3hXCYQPJkwHyik2", "jTk9m75y2bpujwRfb", "SiGY7aah56HvGXxBJ", "R3ATEWWmBhMhbY2AL", "f4txACqDWithRi7hs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T02:51:16.252Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Artificial Addition", "slug": "seq-rerun-artificial-addition", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:05.757Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XwY5SXrLghsYJqHmB/seq-rerun-artificial-addition", "pageUrlRelative": "/posts/XwY5SXrLghsYJqHmB/seq-rerun-artificial-addition", "linkUrl": "https://www.lesswrong.com/posts/XwY5SXrLghsYJqHmB/seq-rerun-artificial-addition", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Artificial%20Addition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Artificial%20Addition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXwY5SXrLghsYJqHmB%2Fseq-rerun-artificial-addition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Artificial%20Addition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXwY5SXrLghsYJqHmB%2Fseq-rerun-artificial-addition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXwY5SXrLghsYJqHmB%2Fseq-rerun-artificial-addition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 265, "htmlBody": "<p>Today's post, <a href=\"/lw/l9/artificial_addition/\">Artificial Addition</a> was originally published on 20 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>If you imagine a world where people are stuck on the \"artifical addition\" (i.e. machine calculator) problem, the way people currently are stuck on artificial intelligence, and you saw them trying the same popular approaches taken today toward AI, it would become clear how silly they are. Contrary to popular wisdom (in that world or ours), the solution is not to \"evolve\" an artificial adder, or invoke the need for special physics, or build a huge database of solutions, etc. -- because all of these methods dodge the crucial task of <em>understanding </em>what addition involves, and instead try to dance around it. Moreover, the history of AI research shows the problems of believing assertions one cannot re-generate from one's own knowledge.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/88q/seq_rerun_conjuring_an_evolution_to_serve_you/\">Conjuring an Evolution to Serve You</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XwY5SXrLghsYJqHmB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.926070310265334e-07, "legacy": true, "legacyId": "10708", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YhgjmCxcQXixStWMC", "yCWWKw4FLKsQp9nmL", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T03:36:16.554Z", "modifiedAt": null, "url": null, "title": "Thinking Statistically [ebook]", "slug": "thinking-statistically-ebook", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:06.225Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Hj88eHfH6KGfsrajn/thinking-statistically-ebook", "pageUrlRelative": "/posts/Hj88eHfH6KGfsrajn/thinking-statistically-ebook", "linkUrl": "https://www.lesswrong.com/posts/Hj88eHfH6KGfsrajn/thinking-statistically-ebook", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Thinking%20Statistically%20%5Bebook%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThinking%20Statistically%20%5Bebook%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHj88eHfH6KGfsrajn%2Fthinking-statistically-ebook%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Thinking%20Statistically%20%5Bebook%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHj88eHfH6KGfsrajn%2Fthinking-statistically-ebook", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHj88eHfH6KGfsrajn%2Fthinking-statistically-ebook", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 177, "htmlBody": "<p>Uri Bram, a recent Princeton graduate, has just published an ebook called <a href=\"http://www.amazon.com/dp/B005YOL2Z4\" target=\"_blank\">Thinking Statistically</a>. The book is aimed at conveying a few important statistical concepts (selection bias, endogeneity and correlation vs. causation, Bayes theorem and base rate neglect) to a general audience. The official product description:</p>\n<blockquote>\n<p>This book will show you how to think like a statistician, without  worrying about formal statistical techniques. Along the way we'll see  why supposed Casanovas might actually be examples of the Base Rate  Fallacy; how to use Bayes' Theorem to assess whether your partner is  cheating on you; and why you should never use Mark Zuckerberg as an  example for anything. See the world in a whole new light, and make  better decisions and judgements without ever going near a t-test. Think.  Think Statistically.</p>\n</blockquote>\n<p>Less Wrong members will be familiar with these topics, but we should keep this book in mind as a convenient method of getting friends, relatives, acquaintances, and others interested in understanding rationality.</p>\n<p>Eliezer's <a href=\"http://yudkowsky.net/rational/bayes\" target=\"_blank\">An Intuitive Explanation of Bayes' Theorem</a> gets a shout-out in the Recommended Reading at the end.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Hj88eHfH6KGfsrajn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.926227016173969e-07, "legacy": true, "legacyId": "10711", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T11:41:32.962Z", "modifiedAt": "2021-07-08T15:17:09.308Z", "url": null, "title": "Anthropic decision theory I: Sleeping beauty and selflessness", "slug": "anthropic-decision-theory-i-sleeping-beauty-and-selflessness", "viewCount": null, "lastCommentedAt": "2017-09-06T09:00:21.068Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/svhbnSdxW3XmFXXTK/anthropic-decision-theory-i-sleeping-beauty-and-selflessness", "pageUrlRelative": "/posts/svhbnSdxW3XmFXXTK/anthropic-decision-theory-i-sleeping-beauty-and-selflessness", "linkUrl": "https://www.lesswrong.com/posts/svhbnSdxW3XmFXXTK/anthropic-decision-theory-i-sleeping-beauty-and-selflessness", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anthropic%20decision%20theory%20I%3A%20Sleeping%20beauty%20and%20selflessness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnthropic%20decision%20theory%20I%3A%20Sleeping%20beauty%20and%20selflessness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsvhbnSdxW3XmFXXTK%2Fanthropic-decision-theory-i-sleeping-beauty-and-selflessness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anthropic%20decision%20theory%20I%3A%20Sleeping%20beauty%20and%20selflessness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsvhbnSdxW3XmFXXTK%2Fanthropic-decision-theory-i-sleeping-beauty-and-selflessness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsvhbnSdxW3XmFXXTK%2Fanthropic-decision-theory-i-sleeping-beauty-and-selflessness", "socialPreviewImageUrl": "http://images.lesswrong.com/t3_891_0.png", "question": false, "authorIsUnreviewed": false, "wordCount": 469, "htmlBody": "<p>A near-final version of my Anthropic Decision Theory\u00a0<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>\u00a0is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this and subsequent posts\u00a0<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>\u00a0<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>\u00a0<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>\u00a0<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>\u00a0<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>\u00a0<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<p><em>Many thanks to Nick Bostrom, Wei Dai, Anders Sandberg, Katja Grace, Carl Shulman, Toby Ord, Anna Salamon, Owen Cotton-barratt, and Eliezer Yudkowsky.</em></p>\n<h2>The Sleeping Beauty problem, and the incubator variant</h2>\n<p>The Sleeping Beauty problem is a major one in anthropics, and my paper establishes anthropic decision theory (ADT) by a careful analysis it. Therefore we should start with an explanation of what it is.</p>\n<p>In the standard setup, Sleeping Beauty is put to sleep on Sunday, and awoken again Monday morning, without being told what day it is. She is put to sleep again at the end of the day. A fair coin was tossed before the experiment began. If that coin showed heads, she is never reawakened. If the coin showed tails, she is fed a one-day amnesia potion (so that she does not remember being awake on Monday) and is reawakened on Tuesday, again without being told what day it is. At the end of Tuesday, she is put to sleep for ever. This is illustrated in the next figure:<a></a></p>\n<p><img src=\"http://images.lesswrong.com/t3_891_0.png\" /></p>\n<p>\u00a0</p>\n<p>The incubator variant of the problem, due to Nick Bostrom, has no initial Sleeping Beauty, just one or two copies of her created (in different, identical rooms), depending on the result of the coin flip. The name `incubator' derived from the machine that was to do the birthing of these observers. This is illustrated in the next figure:</p>\n<p><img src=\"http://images.lesswrong.com/t3_891_1.png?v=1dd15dcc5a57e4f88c81243af84e2a5f\" /></p>\n<p>The question then is what probability a recently awoken or created Sleeping Beauty should give to the coin falling heads or tails and it being Monday or Tuesday when she is awakened (or whether she is in Room 1 or 2).</p>\n<h2>Selfishness, selflessness and altruism</h2>\n<p>I will be using these terms in precise ways in ADT, somewhat differently from how they are usually used. A selfish agent is one whose preferences are only about their own personal welfare; a pure hedonist would be a good example. A selfless agent, on the other hand is one that cares only about the state of the world, not about their own personal welfare - or anyone else's. They might not be nice (patriots are - arguably - selfless), but they do not care about their own welfare as a terminal goal.</p>\n<p>Altruistic agents, on the other hand, care about the welfare of everyone, not just themselves. These can be divided into total utilitarians, and average utilitarians (there are other altruistic motivations, but they aren't relevant to the paper). In summary:</p>\n<table>\n<tbody>\n<tr>\n<th>Selfish</th>\n<td>\"Give me that chocolate bar\"</td>\n</tr>\n<tr>\n<th>Selfless</th>\n<td>\"Save the rainforests\"</td>\n</tr>\n<tr>\n<th>Average Utilitarian</th>\n<td>\"We must increase per capita GDP\"</td>\n</tr>\n<tr>\n<th>Total Utilitarian</th>\n<td>\"Every happy child is a gift to the world\"</td>\n</tr>\n</tbody>\n</table>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2, "NZB24aR9uHmDc5GcT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "svhbnSdxW3XmFXXTK", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 22, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "10693", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "http://images.lesswrong.com/t3_891_0.png", "canonicalSequenceId": "kmryZRz5r9bjsug9e", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "anthropic-decision-theory-ii-self-indication-self-sampling", "canonicalPrevPostSlug": "", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this and subsequent posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<p><em>Many thanks to Nick Bostrom, Wei Dai, Anders Sandberg, Katja Grace, Carl Shulman, Toby Ord, Anna Salamon, Owen Cotton-barratt, and Eliezer Yudkowsky.</em></p>\n<h2 id=\"The_Sleeping_Beauty_problem__and_the_incubator_variant\">The Sleeping Beauty problem, and the incubator variant</h2>\n<p>The Sleeping Beauty problem is a major one in anthropics, and my paper establishes anthropic decision theory (ADT) by a careful analysis it. Therefore we should start with an explanation of what it is.</p>\n<p>In the standard setup, Sleeping Beauty is put to sleep on Sunday, and awoken again Monday morning, without being told what day it is. She is put to sleep again at the end of the day. A fair coin was tossed before the experiment began. If that coin showed heads, she is never reawakened. If the coin showed tails, she is fed a one-day amnesia potion (so that she does not remember being awake on Monday) and is reawakened on Tuesday, again without being told what day it is. At the end of Tuesday, she is put to sleep for ever. This is illustrated in the next figure:<a></a></p>\n<p><img src=\"http://images.lesswrong.com/t3_891_0.png\"></p>\n<p>&nbsp;</p>\n<p>The incubator variant of the problem, due to Nick Bostrom, has no initial Sleeping Beauty, just one or two copies of her created (in different, identical rooms), depending on the result of the coin flip. The name `incubator' derived from the machine that was to do the birthing of these observers. This is illustrated in the next figure:</p>\n<p><img src=\"http://images.lesswrong.com/t3_891_1.png?v=1dd15dcc5a57e4f88c81243af84e2a5f\"></p>\n<p>The question then is what probability a recently awoken or created Sleeping Beauty should give to the coin falling heads or tails and it being Monday or Tuesday when she is awakened (or whether she is in Room 1 or 2).</p>\n<h2 id=\"Selfishness__selflessness_and_altruism\">Selfishness, selflessness and altruism</h2>\n<p>I will be using these terms in precise ways in ADT, somewhat differently from how they are usually used. A selfish agent is one whose preferences are only about their own personal welfare; a pure hedonist would be a good example. A selfless agent, on the other hand is one that cares only about the state of the world, not about their own personal welfare - or anyone else's. They might not be nice (patriots are - arguably - selfless), but they do not care about their own welfare as a terminal goal.</p>\n<p>Altruistic agents, on the other hand, care about the welfare of everyone, not just themselves. These can be divided into total utilitarians, and average utilitarians (there are other altruistic motivations, but they aren't relevant to the paper). In summary:</p>\n<table>\n<tbody>\n<tr>\n<th>Selfish</th>\n<td>\"Give me that chocolate bar\"</td>\n</tr>\n<tr>\n<th>Selfless</th>\n<td>\"Save the rainforests\"</td>\n</tr>\n<tr>\n<th>Average Utilitarian</th>\n<td>\"We must increase per capita GDP\"</td>\n</tr>\n<tr>\n<th>Total Utilitarian</th>\n<td>\"Every happy child is a gift to the world\"</td>\n</tr>\n</tbody>\n</table>", "sections": [{"title": "The Sleeping Beauty problem, and the incubator variant", "anchor": "The_Sleeping_Beauty_problem__and_the_incubator_variant", "level": 1}, {"title": "Selfishness, selflessness and altruism", "anchor": "Selfishness__selflessness_and_altruism", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "34 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": true, "version": "1.1.0", "pingbacks": {"Posts": ["G9scbpNrCxfJZQmYu", "zqm2nTqjAKg6EyxE3", "LXHsiHahr2eFQ4Hsp", "wQd3rLLLNWYRgjaYg", "NpPEJT2CCKjeo59Ps"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T16:22:55.575Z", "modifiedAt": null, "url": null, "title": "[LINK] Cracked on PitMK, Fundamental Attribution Error, Confimation Bias and More", "slug": "link-cracked-on-pitmk-fundamental-attribution-error", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.644Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GcXAE3CnNuP4NTiDx/link-cracked-on-pitmk-fundamental-attribution-error", "pageUrlRelative": "/posts/GcXAE3CnNuP4NTiDx/link-cracked-on-pitmk-fundamental-attribution-error", "linkUrl": "https://www.lesswrong.com/posts/GcXAE3CnNuP4NTiDx/link-cracked-on-pitmk-fundamental-attribution-error", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Cracked%20on%20PitMK%2C%20Fundamental%20Attribution%20Error%2C%20Confimation%20Bias%20and%20More&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Cracked%20on%20PitMK%2C%20Fundamental%20Attribution%20Error%2C%20Confimation%20Bias%20and%20More%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGcXAE3CnNuP4NTiDx%2Flink-cracked-on-pitmk-fundamental-attribution-error%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Cracked%20on%20PitMK%2C%20Fundamental%20Attribution%20Error%2C%20Confimation%20Bias%20and%20More%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGcXAE3CnNuP4NTiDx%2Flink-cracked-on-pitmk-fundamental-attribution-error", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGcXAE3CnNuP4NTiDx%2Flink-cracked-on-pitmk-fundamental-attribution-error", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 18, "htmlBody": "<p>It's Cracked, so it's not exactly the highest scientific authority on the matter, but still <a href=\"http://www.cracked.com/article_19468_5-logical-fallacies-that-make-you-wrong-more-than-you-think.html?utm_source=facebook&amp;utm_medium=fanpage&amp;utm_campaign=new+article&amp;wa_ibsrc=fanpage\">a decent read</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GcXAE3CnNuP4NTiDx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 7.92889731233072e-07, "legacy": true, "legacyId": "10720", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T18:28:22.220Z", "modifiedAt": null, "url": null, "title": "2011 Less Wrong Census / Survey", "slug": "2011-less-wrong-census-survey", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:53.218Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/miHttwTgajY2sjY3L/2011-less-wrong-census-survey", "pageUrlRelative": "/posts/miHttwTgajY2sjY3L/2011-less-wrong-census-survey", "linkUrl": "https://www.lesswrong.com/posts/miHttwTgajY2sjY3L/2011-less-wrong-census-survey", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%202011%20Less%20Wrong%20Census%20%2F%20Survey&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A2011%20Less%20Wrong%20Census%20%2F%20Survey%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmiHttwTgajY2sjY3L%2F2011-less-wrong-census-survey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=2011%20Less%20Wrong%20Census%20%2F%20Survey%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmiHttwTgajY2sjY3L%2F2011-less-wrong-census-survey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmiHttwTgajY2sjY3L%2F2011-less-wrong-census-survey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 227, "htmlBody": "<p>The final straw was noticing <a href=\"/r/discussion/lw/88v/less_wrong_couchsurfing_network/54rg\">a comment</a> referring to \"the most recent survey I know of\" and realizing <a href=\"/lw/fk/survey_results/\">it was from May 2009</a>. I think it is <em>well</em> past time for another survey, so here is one now.</p>\n<p><strong><a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHlYUVBYU0Q5MjNpMzJ5TWJESWtPb1E6MQ\">Click here to take the survey</a></strong></p>\n<p>I've tried to keep the structure of the last survey intact so it will be easy to compare results and see changes over time, but there were a few problems with the last survey that required changes, and a few questions from the last survey that just didn't apply as much anymore (how many people have strong feelings on <em>Three Worlds Collide</em> these days?)</p>\n<p>Please try to give serious answers that are easy to process by computer (see the introduction). And please let me know <em>as soon as possible</em> if there are any security problems (people other than me who can access the data) or any absolutely awful questions.</p>\n<p>I will probably run the survey for about a month unless new people stop responding well before that. Like the last survey, I'll try to calculate some results myself and release the raw data (minus the people who want to keep theirs private) for anyone else who wants to examine it.</p>\n<p>Like the last survey, if you take it and post that you took it here, I will upvote you, and I hope other people will upvote you too.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"kJrjorSx3hXa7q7CJ": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "miHttwTgajY2sjY3L", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 80, "baseScore": 101, "extendedScore": null, "score": 7.929334394254727e-07, "legacy": true, "legacyId": "10702", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": "2019-05-04T02:33:59.710Z", "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": true, "hideFrontpageComments": false, "maxBaseScore": 77, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 699, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ZWC3n9c6v4s35rrZ3"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T18:28:38.290Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes November 2011", "slug": "rationality-quotes-november-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:03.372Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jayson_Virissimo", "createdAt": "2009-03-13T06:51:41.976Z", "isAdmin": false, "displayName": "Jayson_Virissimo"}, "userId": "zwzw5ALJYG47kDek8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kiC3bBJW2xddiMmmy/rationality-quotes-november-2011", "pageUrlRelative": "/posts/kiC3bBJW2xddiMmmy/rationality-quotes-november-2011", "linkUrl": "https://www.lesswrong.com/posts/kiC3bBJW2xddiMmmy/rationality-quotes-november-2011", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20November%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20November%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkiC3bBJW2xddiMmmy%2Frationality-quotes-november-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20November%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkiC3bBJW2xddiMmmy%2Frationality-quotes-november-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkiC3bBJW2xddiMmmy%2Frationality-quotes-november-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 71, "htmlBody": "<p style=\"margin: 0px 0px 1em;\">Here's the new thread for posting quotes, with the usual rules:</p>\n<ul style=\"padding: 0px;\">\n<li>Please post all quotes separately, so that they can be voted up/down separately.&nbsp;&nbsp;(If they are strongly related, reply to your own comments.&nbsp;&nbsp;If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kiC3bBJW2xddiMmmy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 7.929335327390058e-07, "legacy": true, "legacyId": "10692", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 395, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T19:42:37.243Z", "modifiedAt": null, "url": null, "title": "You Are Not So Smart (Pop-Rationality Book) ", "slug": "you-are-not-so-smart-pop-rationality-book", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:02.831Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "betterthanwell", "createdAt": "2009-02-28T00:39:39.875Z", "isAdmin": false, "displayName": "betterthanwell"}, "userId": "W9LCYGeCRvhd5aREo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mn5562DQtcHGFTkHt/you-are-not-so-smart-pop-rationality-book", "pageUrlRelative": "/posts/Mn5562DQtcHGFTkHt/you-are-not-so-smart-pop-rationality-book", "linkUrl": "https://www.lesswrong.com/posts/Mn5562DQtcHGFTkHt/you-are-not-so-smart-pop-rationality-book", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20You%20Are%20Not%20So%20Smart%20(Pop-Rationality%20Book)%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AYou%20Are%20Not%20So%20Smart%20(Pop-Rationality%20Book)%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMn5562DQtcHGFTkHt%2Fyou-are-not-so-smart-pop-rationality-book%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=You%20Are%20Not%20So%20Smart%20(Pop-Rationality%20Book)%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMn5562DQtcHGFTkHt%2Fyou-are-not-so-smart-pop-rationality-book", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMn5562DQtcHGFTkHt%2Fyou-are-not-so-smart-pop-rationality-book", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 403, "htmlBody": "<p>Journalist <a href=\"http://youarenotsosmart.com/who-writes-all-this/\">David McRaney</a> has <a href=\"http://youarenotsosmart.com/2011/10/27/launch-trailer-book-out-today/\">very recently</a> published a <a href=\"http://www.amazon.com/You-Are-Not-So-Smart/dp/1592406599/ref=sr_1_1?ie=UTF8&amp;qid=1320173552&amp;sr=8-1\">popular book</a> on human rationality. The book, <em>You Are Not So Smart,</em> is currently the 3rd best selling book in Nonfiction/Philosophy on Amazon.com after less than a week on the market. (Eighth best selling book in Nonfiction/Education)</p>\n<p>The tag-line of the project is: <em>\"A celebration of self-delusion.\"</em> As such the book seems less an attempt at giving advice on how to act and decide, than an attempt to reveal, chapter by chapter, the folly of common sense.</p>\n<p><strong>Topics include:</strong> Hindsight Bias, Confirmation bias, The Sunk Cost Fallacy, Anchoring Effect, The Illusion of Transparency, The Just World Fallacy, Representativeness Heuristic, The Perils of Introspection, The Dunning-Kruger Effect, The Monty Hall Problem, The Bystander Effect, Placebo Buttons, Groupthink, Conformity, Social Loafing, Helplessness, Cults, Change Blindness, Self-Fulfilling Prophecies, Self Handicapping, Availability Heuristic, Self-Serving Bias, The Ultimatum Game, Inattentional Blindness.</p>\n<p>&nbsp;</p>\n<p>\n<object width=\"560\" height=\"315\" data=\"http://www.youtube.com/v/DJ2T4-rUUcs?version=3&amp;hl=en_US\" type=\"application/x-shockwave-flash\">\n<param name=\"allowFullScreen\" value=\"true\" />\n<param name=\"allowscriptaccess\" value=\"always\" />\n<param name=\"src\" value=\"http://www.youtube.com/v/DJ2T4-rUUcs?version=3&amp;hl=en_US\" />\n<param name=\"allowfullscreen\" value=\"true\" />\n</object>\n&nbsp;</p>\n<p>&nbsp;</p>\n<p>These are topics we enjoy learning about, pride ourself in knowing a lot about, and, we profess, we would want more people to know about. A popular book on this subject is now out. This sounds like a good thing.</p>\n<p>I will note that the blog features at least one <a href=\"http://youarenotsosmart.com/2010/07/14/the-illusion-of-transparency/\">direct quote</a> from LessWrong.</p>\n<blockquote>\n<p>We always know what&nbsp;<em>we</em> mean by our words, and so we expect others to know it too.&nbsp; Reading our own writing, the intended interpretation falls easily into place, guided by our knowledge of what we really meant.&nbsp; It&rsquo;s hard to empathise with someone who must interpret blindly, guided only by the words.</p>\n<p>- Eliezer Yudowsky from Lesswrong.com</p>\n</blockquote>\n<p>One one hand, <em>You Are Not So Smart</em> could bee a boon to Eliezer's <a href=\"/lw/62i/more_info_about_the_book_eliezer_is_writing/#comments\">popular rationality book</a> by priming the market. His writings on a given topic have rarely been described as redundant. On the other hand, it seems to me that this book closely covers a number of topics, seemingly in a similar style to the treatments that were published on this site and Overcoming Bias. Intended to be published in book form at a later date. I will try to refrain from speculation here.</p>\n<p><strong>Sample blook chapters from <em>YouAreNotSoSmart</em>:</strong></p>\n<ul>\n<li><a href=\"http://youarenotsosmart.com/2010/10/27/procrastination/\">Procrastination</a><a href=\"http://youarenotsosmart.com/2010/10/27/procrastination/\"><br /></a></li>\n<li><a href=\"http://youarenotsosmart.com/2011/07/07/misattribution-of-arousal/\">Misattribution of Arousal<br /></a></li>\n<li><a href=\"http://youarenotsosmart.com/2010/09/11/the-texas-sharpshooter-fallacy\">Texas Sharpshooter Fallacy</a></li>\n</ul>\n<div id=\"body_t1_554s\" class=\"comment-content \">\n<div class=\"md\">\n<p>For more material, here's a list of <a rel=\"nofollow\" href=\"http://youarenotsosmart.com/all-posts/\">all posts</a> at youarenotsosmart.com</p>\n<p>&nbsp;</p>\n</div>\n</div>\n<p>I'll save the rest of my review until I have actually read the book.</p>\n<p>In the meantime I would like to know your thoughts on this project.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mn5562DQtcHGFTkHt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 9, "extendedScore": null, "score": 7.929593123105933e-07, "legacy": true, "legacyId": "10722", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-01T20:08:15.110Z", "modifiedAt": null, "url": null, "title": "Myers-Briggs / MLPTI personality-type conversion chart", "slug": "myers-briggs-mlpti-personality-type-conversion-chart", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:04.461Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P42ix2c6PLxDwftaS/myers-briggs-mlpti-personality-type-conversion-chart", "pageUrlRelative": "/posts/P42ix2c6PLxDwftaS/myers-briggs-mlpti-personality-type-conversion-chart", "linkUrl": "https://www.lesswrong.com/posts/P42ix2c6PLxDwftaS/myers-briggs-mlpti-personality-type-conversion-chart", "postedAtFormatted": "Tuesday, November 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Myers-Briggs%20%2F%20MLPTI%20personality-type%20conversion%20chart&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMyers-Briggs%20%2F%20MLPTI%20personality-type%20conversion%20chart%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP42ix2c6PLxDwftaS%2Fmyers-briggs-mlpti-personality-type-conversion-chart%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Myers-Briggs%20%2F%20MLPTI%20personality-type%20conversion%20chart%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP42ix2c6PLxDwftaS%2Fmyers-briggs-mlpti-personality-type-conversion-chart", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP42ix2c6PLxDwftaS%2Fmyers-briggs-mlpti-personality-type-conversion-chart", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<p>While psychology wonks have been going on for years about the statistical rigor and calibration of the Big Five, most people have just carried on using the Myers-Briggs type indicator (MBTI), which may not be statistical or scientific but <em>is</em> able to categorize people without insulting them.</p>\n<p>A serious critique of the MBTI is the Myers-Briggs entropy distribution paradox (or, \"Why are there 16 personality types when everyone I know is an INTJ?\")&nbsp; A new personality test which has been gaining ground recently, the MLPTI, does not break up the INTJ into multiple categories; but does reduce the number of bothersome non-INTJ personality types and thus ameliorates the entropy paradox.&nbsp; For those not yet familiar with it, here is a rough translation between MLPTI and MBTI types.</p>\n<table style=\"height: 214px;\" border=\"1\" width=\"427\">\n<tbody>\n<tr>\n<td><strong>MLP type<br /></strong></td>\n<td align=\"center\"><strong>Traits</strong></td>\n<td><strong>M-B types</strong></td>\n</tr>\n<tr>\n<td>TS</td>\n<td>conscientious, introverted, self-conscious<br /></td>\n<td>INTJ</td>\n</tr>\n<tr>\n<td>RD</td>\n<td>impulsive, activity-oriented, high stimulation threshold<br /></td>\n<td>ESFJ, ESFP<br /></td>\n</tr>\n<tr>\n<td>PP</td>\n<td>creative, un-self-conscious<br /></td>\n<td>ENFP</td>\n</tr>\n<tr>\n<td>AJ</td>\n<td>pragmatic, disciplined, outcome-oriented<br /></td>\n<td>ISTJ</td>\n</tr>\n<tr>\n<td>FS</td>\n<td>introverted, empathetic, anxious</td>\n<td>ISFJ, INFJ<br /></td>\n</tr>\n<tr>\n<td>R</td>\n<td>extroverted, creative, status-seeking<br /></td>\n<td>ENFJ</td>\n</tr>\n</tbody>\n</table>\n<p>&nbsp;</p>\n<p>The loss of half of the MBTI categories is not a serious problem, as demonstrated by the fact that you can't even name the ones that were left out without going back and looking.&nbsp; Seriously, when was the last time you met an ENTP?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P42ix2c6PLxDwftaS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 8, "extendedScore": null, "score": 1.6e-05, "legacy": true, "legacyId": "10723", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T01:53:01.625Z", "modifiedAt": null, "url": null, "title": "Do we have it too easy?", "slug": "do-we-have-it-too-easy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:21.477Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Klao", "createdAt": "2011-09-08T21:42:31.537Z", "isAdmin": false, "displayName": "Klao"}, "userId": "vw5ScQXYbwYAi5kNp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2C2nGLDSygZXYTw6P/do-we-have-it-too-easy", "pageUrlRelative": "/posts/2C2nGLDSygZXYTw6P/do-we-have-it-too-easy", "linkUrl": "https://www.lesswrong.com/posts/2C2nGLDSygZXYTw6P/do-we-have-it-too-easy", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20we%20have%20it%20too%20easy%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20we%20have%20it%20too%20easy%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2C2nGLDSygZXYTw6P%2Fdo-we-have-it-too-easy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20we%20have%20it%20too%20easy%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2C2nGLDSygZXYTw6P%2Fdo-we-have-it-too-easy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2C2nGLDSygZXYTw6P%2Fdo-we-have-it-too-easy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 777, "htmlBody": "<p>I am worried that I have it too easy. I recently discovered LessWrong for myself, and it feels very exciting and very important and I am learning a lot, but how do I know that I am really on a right way? I have some achievements to show, but there are some worrisome signs too.</p>\n<p>I need some background to explain what I mean. I was raised in an atheist/agnostic family, but some time in my early teens I gave a mysterious answer to a mysterious question, and... And long story short, influenced by everything I was reading at the time I became a theist. I wasn't religious in the sense that I never followed any established religion, but I had my own \"theological model\" (heavily influenced by theosophy and other western interpretations of eastern religions). I believed in god, and it was a very important part of my life (around the end of high school, beginning of college I started talking about it with my friends and was quite open and proud about it).</p>\n<p>Snip 15-20 years. This summer I started lurking on LessWrong, reading mostly Eliezer's sequences. One morning, walking to the train station, thinking about something I read, my thoughts wondered to how this all affects my faith. And I noticed myself flinching away, and thought&nbsp;<span style=\"font-family: 'Times New Roman'; font-size: medium;\">&ldquo;</span>Isn't this what Eliezer calls \"flinching away\"?<span style=\"font-family: 'Times New Roman'; font-size: medium;\">&rdquo;</span>&nbsp;I didn't resolve my doubts there and then, but there was no turning back and couple of days later I was an atheist. This is my first \"achievement\". The second is: when I got to the \"free will\" sequence, I stopped before reading any spoilers, gave myself a weekend and <em>I figured it out!</em> (Not perfectly, but at least one part I figured out very clearly, and got important insights into the other part.) Which I would have never thought I would be able to do, because as it happens, this was the original mysterious question on which I got so confused as a teenager. (Another, smaller \"achievement\" I documented <a href=\"/lw/80k/motivated_skepticism_its_harder_to_avoid_than_id/\">here</a>.)</p>\n<p>Maybe these are not too impressive, but they are not completely trivial either (actually, I am a bit proud of myself :)). But, I get a distinct feeling that something is off. Take the atheism: I think, one of the reasons I so easily let go of my precious belief, was that <em>I had something to replace it with.</em> And this is very-very scary, that I sometimes get the same feeling of amazing discovery reading Eliezer as when I was 13, and my mind just accepts it all unconditionally! I have to constantly remind myself that this is not what I should do with it!</p>\n<p>Do not misunderstand, I am not afraid of becoming a part of some cult. (I had some experience with less or more strongly cultish groups, and I didn't have hard time of seeing through and not falling for them. So, I am not afraid. Maybe foolishly.) &nbsp;What I am afraid of, is that I will do the same mistake on a different level: I won't actually change my mind, won't learn what's really matters. Because, even if everything I read here turns out to be 100% accurate, it would be a mistake \"believing in it\". Because, as soon as I get to a real-world problem I will just go astray again.</p>\n<p><a href=\"/lw/4e/cached_selves/3aq\">This comment</a> is the closest I saw here on LessWrong to my concerns. It also sheds some light on why is this happening. Eliezer describes the experience vividly enough, that afterwards my mind behaves as if I had the experience too. Which is, of course, the whole point, but also one source of this problem. Because I <em>didn't</em> have the experience, it wasn't <em>me</em> who thought it through, so I don't have it in my bones. I will need much more to make the technique/conclusion a part of myself (and a lot of critical thinking, or else I am worse off and not better.) &nbsp;And no, Eliezer, I don't know how to make it less dark either. &nbsp;Other than what is already quite clear: we have to be tested on our rationality. The skills have to be tested, or one won't be able to use them properly. &nbsp;The \"free will\" challenge is very good, but only if one takes it. (I took it, because it was a crucial question for me.) And not everything can be tested like this. And it's not enough.</p>\n<p>&nbsp;</p>\n<p>So, my question to more experienced LessWrongers: how did you cope with this (if you had such worries)? &nbsp;Or am I even right on this (do I \"worry\"&nbsp;in the right direction)?</p>\n<p>&nbsp;</p>\n<p>(Oh, and also, is this content appropriate for a \"Main\" post? Now that I have enough precious karma. :))</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "9YFoDPFwMoWthzgkY": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2C2nGLDSygZXYTw6P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 37, "extendedScore": null, "score": 8.8e-05, "legacy": true, "legacyId": "10729", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["aTYWYCxKCfLEovmTA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T03:30:20.580Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Truly Part of You", "slug": "seq-rerun-truly-part-of-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:08.012Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4Yvm4EwZkXCkPCKTy/seq-rerun-truly-part-of-you", "pageUrlRelative": "/posts/4Yvm4EwZkXCkPCKTy/seq-rerun-truly-part-of-you", "linkUrl": "https://www.lesswrong.com/posts/4Yvm4EwZkXCkPCKTy/seq-rerun-truly-part-of-you", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Truly%20Part%20of%20You&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Truly%20Part%20of%20You%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yvm4EwZkXCkPCKTy%2Fseq-rerun-truly-part-of-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Truly%20Part%20of%20You%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yvm4EwZkXCkPCKTy%2Fseq-rerun-truly-part-of-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yvm4EwZkXCkPCKTy%2Fseq-rerun-truly-part-of-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 250, "htmlBody": "<p>Today's post, <a href=\"/lw/la/truly_part_of_you/\">Truly Part Of You</a> was originally published on 21 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Any time you believe you've learned something, you should ask yourself, \"Could I re-generate this knowledge if it were somehow deleted from my mind, and how would I do so?\" If the supposed knowledge is just empty buzzwords, you will recognize that you can't, and therefore that you haven't learned anything. But if it's an actual model of reality, this method will reinforce how the knowledge is entangled with the rest of the world, enabling you to apply it to other domains, and know when you need to update those beliefs. It will have become \"truly part of you\", growing and changing with the rest of your knowledge.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/89g/seq_rerun_artificial_addition/\">Artificial Addition</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4Yvm4EwZkXCkPCKTy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 7.93122326626855e-07, "legacy": true, "legacyId": "10733", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fg9fXrHpeaDD6pEPL", "XwY5SXrLghsYJqHmB", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T06:52:24.623Z", "modifiedAt": null, "url": null, "title": "Review of Sharot & Dolan, 'Neuroscience of Preference and Choice' (2011)", "slug": "review-of-sharot-and-dolan-neuroscience-of-preference-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.870Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GpAHPC5MELJQfusfv/review-of-sharot-and-dolan-neuroscience-of-preference-and", "pageUrlRelative": "/posts/GpAHPC5MELJQfusfv/review-of-sharot-and-dolan-neuroscience-of-preference-and", "linkUrl": "https://www.lesswrong.com/posts/GpAHPC5MELJQfusfv/review-of-sharot-and-dolan-neuroscience-of-preference-and", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Review%20of%20Sharot%20%26%20Dolan%2C%20'Neuroscience%20of%20Preference%20and%20Choice'%20(2011)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReview%20of%20Sharot%20%26%20Dolan%2C%20'Neuroscience%20of%20Preference%20and%20Choice'%20(2011)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGpAHPC5MELJQfusfv%2Freview-of-sharot-and-dolan-neuroscience-of-preference-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Review%20of%20Sharot%20%26%20Dolan%2C%20'Neuroscience%20of%20Preference%20and%20Choice'%20(2011)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGpAHPC5MELJQfusfv%2Freview-of-sharot-and-dolan-neuroscience-of-preference-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGpAHPC5MELJQfusfv%2Freview-of-sharot-and-dolan-neuroscience-of-preference-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 577, "htmlBody": "<p>The new edited volume <a style=\"font-style: italic;\" href=\"http://www.amazon.com/Neuroscience-Preference-Choice-Cognitive-Mechanisms/dp/0123814316/\">Neuroscience of Preference and Choice</a>&nbsp;includes chapters&nbsp;from a good chunk of the leading researchers in neuroeconomics. If you read only two books on neuroeconomics, they should be <a href=\"http://www.amazon.com/Foundations-Neuroeconomic-Analysis-Paul-Glimcher/dp/0199744254/\">Glimcher (2010)</a> and <em>Neuroscience of Preference and Choice</em>.</p>\n<p>First, let me review the main conclusions from my <a href=\"/lw/71x/a_crash_course_in_the_neuroscience_of_human/\">Crash Course in the Neuroscience of Human Motivation</a>:</p>\n<ol>\n<li>Utilities [aka 'decision values'] are real numbers ranging from 0 to 1,000 that take action potentials per second as their natural units.</li>\n<li>Mean utilities are mean firing rates of specific populations of neurons in the final common path of human choice circuits.</li>\n<li>Mean utilities predict choice stochastically, similar to random utility models from economics.</li>\n<li>Utilities are encoded cardinally in firing rates relative to neuronal baseline firing rates. (This is opposed to post-Pareto, ordinal notions of utility.)</li>\n<li>The choice circuit takes as its input a firing rate that encodes relative (normalized) stochastic expected utility.</li>\n<li>As the choice set size grows, so does the error rate.</li>\n<li>Final choice is implemented by an argmax function or a reservation price mechanism.</li>\n</ol>\n<p>Much of <em>Neuroscience of Preference and Choice</em> repeats and reinforces these conclusions. In this review, I'll focus on the major results that are discussed in <em>Neuroscience of Preference and Choice</em> but not in my 'Crash Course'. The editors of <em>Neuroscience of Preference and Choice</em>&nbsp;see two major results from the work reviewed in the book:</p>\n<ol>\n<li>Contrary to traditional decision-making theories, which assume choices are based on relatively steady preferences, <strong>preferences are in fact highly volatile and susceptible to the context</strong> in which the alternatives are presented. Moreover, our preferences are modified by the mere act of choosing and altered by changing choice sets.</li>\n<li>Regardless of whether we are selecting a musical tune, a perfume, or a new car &ndash; <strong>the brain uses similar computational principles to compute the value of our options</strong>, which are tracked by common neural systems.</li>\n</ol>\n<p>I will highlight three additional important results:</p>\n<ol>\n<li>There are three&nbsp;<strong>competing valuation systems</strong>, and they respond to different stimuli.&nbsp;The first is \"model-based\" control, associated with goal-directed behavior. The second is \"model-free\" control, associated with reinforcement learning. The third is \"Pavlovian control,\" which imposes hard-wired motivation on the choice mechanism. We're not sure by which exact algorithm the inputs from these three competing valuation systems determine final choice, but several possible algorithms are being tested.</li>\n<li>Brain systems involved in valuation and choice acquire and use information about the environment and about utility in different ways.&nbsp;<strong>Values may not be consistent across systems</strong>, and <strong>choices emerging from some systems may not be consistent with their own underlying values</strong>.</li>\n<li>In goal-directed behavior, <strong>we simulate achieving the goal, during which a dopamine signal tracks the value we anticipate getting from the achievement of that goal</strong>. Unfortunately, a variety of biases limit our capacity for accurate affective forecasting.</li>\n</ol>\n<p>Many of the chapters do not report surprising results from the last 10 years of neuroeconomics; instead, they explain the neural mechanisms behind things we already knew about, for example common biases in decision-making, the social and emotional factors that contribute to value appraisal, the ways that context can affect preference, the ways that action can affect preference, and more.</p>\n<p>Caplin's chapter presents not a \"result\" but the interesting suggestion that choice sets can be modeled as percepts. This would be an interesting result, but we'll have to wait for the tests he proposes to be performed.</p>\n<p>The final chapter reviews the implications of the field's results for public policy.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GpAHPC5MELJQfusfv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 7.931927711425763e-07, "legacy": true, "legacyId": "10735", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hN2aRnu798yas5b2k"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T08:25:53.179Z", "modifiedAt": null, "url": null, "title": "AGI Quotes", "slug": "agi-quotes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:38.679Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FTvd9uCQMEMvpLRyS/agi-quotes", "pageUrlRelative": "/posts/FTvd9uCQMEMvpLRyS/agi-quotes", "linkUrl": "https://www.lesswrong.com/posts/FTvd9uCQMEMvpLRyS/agi-quotes", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AGI%20Quotes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAGI%20Quotes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTvd9uCQMEMvpLRyS%2Fagi-quotes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AGI%20Quotes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTvd9uCQMEMvpLRyS%2Fagi-quotes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFTvd9uCQMEMvpLRyS%2Fagi-quotes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p>Similar to the monthly <a href=\"/tag/quotes/\">Rationality Quotes</a> threads, this is a thread for memorable quotes about Artificial General Intelligence.</p>\n<p>\n<p>\n<ul>\n<li>Please post all quotes separately, so that they can be voted up/down separately. &nbsp;(If they are strongly related, reply to your own comments. &nbsp;If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n</ul>\n<div><br /></div>\n</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FTvd9uCQMEMvpLRyS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 6, "extendedScore": null, "score": 7.932253623695829e-07, "legacy": true, "legacyId": "10737", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 90, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T10:03:07.981Z", "modifiedAt": null, "url": null, "title": "Anthropic Decision Theory II: Self-Indication, Self-Sampling and decisions", "slug": "anthropic-decision-theory-ii-self-indication-self-sampling", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:09.250Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/G9scbpNrCxfJZQmYu/anthropic-decision-theory-ii-self-indication-self-sampling", "pageUrlRelative": "/posts/G9scbpNrCxfJZQmYu/anthropic-decision-theory-ii-self-indication-self-sampling", "linkUrl": "https://www.lesswrong.com/posts/G9scbpNrCxfJZQmYu/anthropic-decision-theory-ii-self-indication-self-sampling", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anthropic%20Decision%20Theory%20II%3A%20Self-Indication%2C%20Self-Sampling%20and%20decisions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnthropic%20Decision%20Theory%20II%3A%20Self-Indication%2C%20Self-Sampling%20and%20decisions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG9scbpNrCxfJZQmYu%2Fanthropic-decision-theory-ii-self-indication-self-sampling%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anthropic%20Decision%20Theory%20II%3A%20Self-Indication%2C%20Self-Sampling%20and%20decisions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG9scbpNrCxfJZQmYu%2Fanthropic-decision-theory-ii-self-indication-self-sampling", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG9scbpNrCxfJZQmYu%2Fanthropic-decision-theory-ii-self-indication-self-sampling", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 776, "htmlBody": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this, subsequent, and previous posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<p>In the last&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">post</a>, we saw the Sleeping Beauty problem, and the question was what probability a recently awoken or created Sleeping Beauty should give to the coin falling heads or tails and it being Monday or Tuesday when she is awakened (or whether she is in Room 1 or 2). There are two main schools of thought on this, the Self-Sampling Assumption and the Self-Indication Assumption, both of which give different probabilities for these events.</p>\n<h2>The Self-Sampling Assumption</h2>\n<p>The self-sampling assumption (<a href=\"http://en.wikipedia.org/wiki/Self-Sampling_Assumption\">SSA</a>) relies on the insight that Sleeping Beauty, before being put to sleep on Sunday, expects that she will be awakened in future. Thus her awakening grants her no extra information, and she should continue to give the same credence to the coin flip being heads as she did before, namely 1/2.</p>\n<p>In the case where the coin is tails, there will be two copies of Sleeping Beauty, one on Monday and one on Tuesday, and she will not be able to tell, upon awakening, which copy she is. She should assume that both are equally likely. This leads to SSA:<a id=\"more\"></a></p>\n<ul>\n<li>All other things being equal, an observer should reason as if they are randomly selected from the set of all actually existent observers (past, present and future) in their reference class.</li>\n</ul>\n<p>There are some issues with the concept of 'reference class', but here it is enough to set the reference class to be the set of all other Sleeping Beauties woken up in the experiment.</p>\n<p>Given this, the probability calculations become straightforward:</p>\n<ul>\n<li><strong>P<sub>SSA</sub>(Heads) = 1/2</strong></li>\n<li><strong>P<sub>SSA</sub>(Tails) = 1/2</strong></li>\n<li>P<sub>SSA</sub>(Monday|Heads) = 1</li>\n<li>P<sub>SSA</sub>(Tuesday|Head) = 0</li>\n<li>P<sub>SSA</sub>(Monday|Tails) = 1/2</li>\n<li>P<sub>SSA</sub>(Tuesday|Tails) = 1/2</li>\n</ul>\n<p>By Bayes' theorem, these imply that:</p>\n<ul>\n<li><strong>P<sub>SSA</sub>(Monday) = 3/4</strong></li>\n<li><strong>P<sub>SSA</sub>(Tuesday) = 1/4</strong></li>\n</ul>\n<p>&nbsp;</p>\n<h2>The Self-Indication Assumption</h2>\n<p>There is another common way of doing anthropic probability, namely to use the self-indication assumption (<a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">SIA</a>). This derives from the insight that being woken up on Monday after a heads, being woken up on Monday after a tails, and being woken up on Tuesday are all subjectively indistinguishable events, which each have a probability 1/2 of happening, therefore we should consider them equally probable. This is formalised as:</p>\n<ul>\n<li>All other things being equal, an observer should reason as if they are randomly selected from the set of all possible observers.</li>\n</ul>\n<p>Note that this definition of SIA is slightly different from that used by Bostrom; what we would call SIA he designated as the combined SIA+SSA. We shall stick with the definition above, however, as it is coming into general use. Note that there is no mention of reference classes, as one of the great advantages of SIA is that any reference class will do, as long as it contains the observers in question.</p>\n<p>Given SIA, the three following observer situations are equiprobable (each has an 'objective' probability 1/2 of happening), and hence SIA gives them equal probabilities of 1/3:</p>\n<ul>\n<li><span>P<sub>SIA</sub>(Monday</span>&nbsp;&cap;&nbsp;<span>Heads) = 1/3</span></li>\n<li><span>P<sub>SIA</sub>(Monday</span>&nbsp;&cap;&nbsp;<span>Tails) = 1/3</span></li>\n<li>P<sub>SIA</sub>(Tuesday &cap;&nbsp;Tails) = 1/3</li>\n</ul>\n<p>This allows us to compute the probabilities:</p>\n<ul>\n<li><strong>P<sub>SIA</sub>(Monday) = 2/3</strong></li>\n<li><strong>P<sub>SIA</sub>(Tuesday) = 1/3</strong></li>\n<li><strong>P<sub>SIA</sub>(Heads) = 1/3</strong></li>\n<li><strong>P<sub>SIA</sub>(Tails) = 2/3</strong></li>\n</ul>\n<p>SIA and SSA are sometimes referred to as the thirder and halfer positions respectively, referring to the probability they give for Heads.</p>\n<h2>Probabilities and decisions</h2>\n<div>SIA and SSA give probabilities in anthropic situations, but aren't enough to give decisions. Consider the case where Sleeping Beauty has to vote on some policy, that is only implemented if voted for by all existent copies. When there are multiple copies, being identical, they will vote the same way.</div>\n<div>Which poses the question as to how much impact each copy has on the final outcome. Do they have an individual impact, i.e. they are responsible for one n-th of the outcome if there are n copies voting? Or are they responsible for the total impact, since the result requires unanimity, and (since the copies are identical) if they voted the other way, so would the other copies?</div>\n<div>In that situation, SIA with individual impact gives the same decision as SSA with total impact (SIA prefers worlds with large number of people in them, which also magnify the size of total impact). So probabilities are not enough, on their own, to solve anthropic problems. Hence we will be focusing not on anthropic probabilities but on anthropic decisions. It is astonishing that one can solve the later, without making use of the former.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "G9scbpNrCxfJZQmYu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 13, "extendedScore": null, "score": 2.8e-05, "legacy": true, "legacyId": "10694", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "kmryZRz5r9bjsug9e", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "anthropic-decision-theory-iii-solving-selfless-and-total", "canonicalPrevPostSlug": "anthropic-decision-theory-i-sleeping-beauty-and-selflessness", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this, subsequent, and previous posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<p>In the last&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">post</a>, we saw the Sleeping Beauty problem, and the question was what probability a recently awoken or created Sleeping Beauty should give to the coin falling heads or tails and it being Monday or Tuesday when she is awakened (or whether she is in Room 1 or 2). There are two main schools of thought on this, the Self-Sampling Assumption and the Self-Indication Assumption, both of which give different probabilities for these events.</p>\n<h2 id=\"The_Self_Sampling_Assumption\">The Self-Sampling Assumption</h2>\n<p>The self-sampling assumption (<a href=\"http://en.wikipedia.org/wiki/Self-Sampling_Assumption\">SSA</a>) relies on the insight that Sleeping Beauty, before being put to sleep on Sunday, expects that she will be awakened in future. Thus her awakening grants her no extra information, and she should continue to give the same credence to the coin flip being heads as she did before, namely 1/2.</p>\n<p>In the case where the coin is tails, there will be two copies of Sleeping Beauty, one on Monday and one on Tuesday, and she will not be able to tell, upon awakening, which copy she is. She should assume that both are equally likely. This leads to SSA:<a id=\"more\"></a></p>\n<ul>\n<li>All other things being equal, an observer should reason as if they are randomly selected from the set of all actually existent observers (past, present and future) in their reference class.</li>\n</ul>\n<p>There are some issues with the concept of 'reference class', but here it is enough to set the reference class to be the set of all other Sleeping Beauties woken up in the experiment.</p>\n<p>Given this, the probability calculations become straightforward:</p>\n<ul>\n<li><strong>P<sub>SSA</sub>(Heads) = 1/2</strong></li>\n<li><strong>P<sub>SSA</sub>(Tails) = 1/2</strong></li>\n<li>P<sub>SSA</sub>(Monday|Heads) = 1</li>\n<li>P<sub>SSA</sub>(Tuesday|Head) = 0</li>\n<li>P<sub>SSA</sub>(Monday|Tails) = 1/2</li>\n<li>P<sub>SSA</sub>(Tuesday|Tails) = 1/2</li>\n</ul>\n<p>By Bayes' theorem, these imply that:</p>\n<ul>\n<li><strong>P<sub>SSA</sub>(Monday) = 3/4</strong></li>\n<li><strong>P<sub>SSA</sub>(Tuesday) = 1/4</strong></li>\n</ul>\n<p>&nbsp;</p>\n<h2 id=\"The_Self_Indication_Assumption\">The Self-Indication Assumption</h2>\n<p>There is another common way of doing anthropic probability, namely to use the self-indication assumption (<a href=\"http://en.wikipedia.org/wiki/Self-Indication_Assumption\">SIA</a>). This derives from the insight that being woken up on Monday after a heads, being woken up on Monday after a tails, and being woken up on Tuesday are all subjectively indistinguishable events, which each have a probability 1/2 of happening, therefore we should consider them equally probable. This is formalised as:</p>\n<ul>\n<li>All other things being equal, an observer should reason as if they are randomly selected from the set of all possible observers.</li>\n</ul>\n<p>Note that this definition of SIA is slightly different from that used by Bostrom; what we would call SIA he designated as the combined SIA+SSA. We shall stick with the definition above, however, as it is coming into general use. Note that there is no mention of reference classes, as one of the great advantages of SIA is that any reference class will do, as long as it contains the observers in question.</p>\n<p>Given SIA, the three following observer situations are equiprobable (each has an 'objective' probability 1/2 of happening), and hence SIA gives them equal probabilities of 1/3:</p>\n<ul>\n<li><span>P<sub>SIA</sub>(Monday</span>&nbsp;\u2229&nbsp;<span>Heads) = 1/3</span></li>\n<li><span>P<sub>SIA</sub>(Monday</span>&nbsp;\u2229&nbsp;<span>Tails) = 1/3</span></li>\n<li>P<sub>SIA</sub>(Tuesday \u2229&nbsp;Tails) = 1/3</li>\n</ul>\n<p>This allows us to compute the probabilities:</p>\n<ul>\n<li><strong>P<sub>SIA</sub>(Monday) = 2/3</strong></li>\n<li><strong>P<sub>SIA</sub>(Tuesday) = 1/3</strong></li>\n<li><strong>P<sub>SIA</sub>(Heads) = 1/3</strong></li>\n<li><strong>P<sub>SIA</sub>(Tails) = 2/3</strong></li>\n</ul>\n<p>SIA and SSA are sometimes referred to as the thirder and halfer positions respectively, referring to the probability they give for Heads.</p>\n<h2 id=\"Probabilities_and_decisions\">Probabilities and decisions</h2>\n<div>SIA and SSA give probabilities in anthropic situations, but aren't enough to give decisions. Consider the case where Sleeping Beauty has to vote on some policy, that is only implemented if voted for by all existent copies. When there are multiple copies, being identical, they will vote the same way.</div>\n<div>Which poses the question as to how much impact each copy has on the final outcome. Do they have an individual impact, i.e. they are responsible for one n-th of the outcome if there are n copies voting? Or are they responsible for the total impact, since the result requires unanimity, and (since the copies are identical) if they voted the other way, so would the other copies?</div>\n<div>In that situation, SIA with individual impact gives the same decision as SSA with total impact (SIA prefers worlds with large number of people in them, which also magnify the size of total impact). So probabilities are not enough, on their own, to solve anthropic problems. Hence we will be focusing not on anthropic probabilities but on anthropic decisions. It is astonishing that one can solve the later, without making use of the former.</div>", "sections": [{"title": "The Self-Sampling Assumption", "anchor": "The_Self_Sampling_Assumption", "level": 1}, {"title": "The Self-Indication Assumption", "anchor": "The_Self_Indication_Assumption", "level": 1}, {"title": "Probabilities and decisions", "anchor": "Probabilities_and_decisions", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "19 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["svhbnSdxW3XmFXXTK", "G9scbpNrCxfJZQmYu", "zqm2nTqjAKg6EyxE3", "LXHsiHahr2eFQ4Hsp", "wQd3rLLLNWYRgjaYg", "NpPEJT2CCKjeo59Ps"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T10:24:37.111Z", "modifiedAt": null, "url": null, "title": "Less Wrong link exchange", "slug": "less-wrong-link-exchange", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:35.144Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FiftyTwo", "createdAt": "2011-03-21T03:38:33.142Z", "isAdmin": false, "displayName": "FiftyTwo"}, "userId": "BZL3TWZXx2wyptxeJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XrTALCQNSuBDz5Lgh/less-wrong-link-exchange", "pageUrlRelative": "/posts/XrTALCQNSuBDz5Lgh/less-wrong-link-exchange", "linkUrl": "https://www.lesswrong.com/posts/XrTALCQNSuBDz5Lgh/less-wrong-link-exchange", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrong%20link%20exchange&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrong%20link%20exchange%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXrTALCQNSuBDz5Lgh%2Fless-wrong-link-exchange%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrong%20link%20exchange%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXrTALCQNSuBDz5Lgh%2Fless-wrong-link-exchange", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXrTALCQNSuBDz5Lgh%2Fless-wrong-link-exchange", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<p>We've had similar threads before, but not for a while so I thought I'd make one.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Basic rules, share links that are relevant to Less Wrong areas of interest, but aren't worthy of their own post. Please include a brief description with the link. (My own contributions are below.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XrTALCQNSuBDz5Lgh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.932667628350845e-07, "legacy": true, "legacyId": "10738", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T10:38:27.083Z", "modifiedAt": null, "url": null, "title": "[Link] Active tactile exploration using a brain\u2013machine\u2013brain interface", "slug": "link-active-tactile-exploration-using-a-brain-machine-brain", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Logos01", "createdAt": "2011-07-21T18:59:16.270Z", "isAdmin": false, "displayName": "Logos01"}, "userId": "WZxoXCWQviJp9dNc5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cSsiWiv3B2n2tfWLr/link-active-tactile-exploration-using-a-brain-machine-brain", "pageUrlRelative": "/posts/cSsiWiv3B2n2tfWLr/link-active-tactile-exploration-using-a-brain-machine-brain", "linkUrl": "https://www.lesswrong.com/posts/cSsiWiv3B2n2tfWLr/link-active-tactile-exploration-using-a-brain-machine-brain", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Active%20tactile%20exploration%20using%20a%20brain%E2%80%93machine%E2%80%93brain%20interface&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Active%20tactile%20exploration%20using%20a%20brain%E2%80%93machine%E2%80%93brain%20interface%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcSsiWiv3B2n2tfWLr%2Flink-active-tactile-exploration-using-a-brain-machine-brain%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Active%20tactile%20exploration%20using%20a%20brain%E2%80%93machine%E2%80%93brain%20interface%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcSsiWiv3B2n2tfWLr%2Flink-active-tactile-exploration-using-a-brain-machine-brain", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcSsiWiv3B2n2tfWLr%2Flink-active-tactile-exploration-using-a-brain-machine-brain", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>ICMS (intracortical microstimulation) was successfully demonstrated for inducing artificial sensory stimulation in rhesus monkeys. (This is a significant -- albeit miniscule -- step forward for data-in brain-computer interfaces.)</p>\n<p>&nbsp;</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<p>-- http://www.nature.com/nature/journal/vaop/ncurrent/full/nature10489.html --</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cSsiWiv3B2n2tfWLr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 7.932715864255008e-07, "legacy": true, "legacyId": "10739", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T12:49:26.074Z", "modifiedAt": null, "url": null, "title": "9/11 Survey", "slug": "9-11-survey", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:09.066Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "roland", "createdAt": "2009-02-27T23:03:47.279Z", "isAdmin": false, "displayName": "roland"}, "userId": "p2C9rpg32LHrGwer8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SLXKMADoGoHguKhAc/9-11-survey", "pageUrlRelative": "/posts/SLXKMADoGoHguKhAc/9-11-survey", "linkUrl": "https://www.lesswrong.com/posts/SLXKMADoGoHguKhAc/9-11-survey", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%209%2F11%20Survey&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A9%2F11%20Survey%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSLXKMADoGoHguKhAc%2F9-11-survey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=9%2F11%20Survey%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSLXKMADoGoHguKhAc%2F9-11-survey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSLXKMADoGoHguKhAc%2F9-11-survey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 98, "htmlBody": "<p>Hello,</p>\n<p>&nbsp;</p>\n<p>we had a number of posts on 9/11, for example there was this one</p>\n<p><a href=\"/lw/5ku/what_causes_people_to_believe_in_conspiracy/\">http://lesswrong.com/lw/5ku/what_causes_people_to_believe_in_conspiracy/</a></p>\n<p>that listed the opinions of people in several countries.&nbsp;But AFAIK there never has been a survey regarding the opinion of LWers on this subject. So here it is, I'm grateful for all answers:</p>\n<p>&nbsp;</p>\n<p><a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHZneGdtZjBiczhWVnlVUVB1eklEQWc6MQ\">Click here to take the survey. (Closed)<br /></a></p>\n<p>&nbsp;</p>\n<p>EDIT: Added a 3rd option(no opinion) to the survey.</p>\n<p>EDIT 2: Link to other opinion polls:</p>\n<p><a href=\"http://en.wikipedia.org/wiki/September_11_attacks_opinion_polls#United_States\">http://en.wikipedia.org/wiki/September_11_attacks_opinion_polls#United_States</a></p>\n<p>EDIT 3: The survey is closed now(2012-06-14), no further answers will be accepted.</p>\n<p>Answers:</p>\n<p>\n<table id=\"table#0\" style=\"border-collapse: collapse; empty-cells: show; font-size: 12px; width: 585px; color: #000000; font-family: arial,sans-serif; text-align: left; padding: 0px; margin: 0px;\" border=\"0\">\n<tbody style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">\n<tr style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">\n<td class=\"ss-table-label\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 0px; border-image: initial; vertical-align: top; white-space: nowrap; margin: 0px; border: 0px initial initial;\">Inside Job(The US Government did it)</td>\n<td style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">&nbsp;</td>\n<td class=\"ss-table-number\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 1.38em; border-image: initial; vertical-align: top; font-weight: bold; text-align: right; margin: 0px; border: 0px initial initial;\">3</td>\n<td class=\"ss-table-percentage\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 1.38em; border-image: initial; vertical-align: top; color: #666666; text-align: right; margin: 0px; border: 0px initial initial;\">3%</td>\n</tr>\n<tr style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">\n<td class=\"ss-table-label\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 0px; border-image: initial; vertical-align: top; white-space: nowrap; margin: 0px; border: 0px initial initial;\">Outside Job(Al Qaeda, Bin Laden or others did it)</td>\n<td style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">&nbsp;</td>\n<td class=\"ss-table-number\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 1.38em; border-image: initial; vertical-align: top; font-weight: bold; text-align: right; margin: 0px; border: 0px initial initial;\">102</td>\n<td class=\"ss-table-percentage\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 1.38em; border-image: initial; vertical-align: top; color: #666666; text-align: right; margin: 0px; border: 0px initial initial;\">92%</td>\n</tr>\n<tr style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">\n<td class=\"ss-table-label\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 0px; border-image: initial; vertical-align: top; white-space: nowrap; margin: 0px; border: 0px initial initial;\">I have no opinion on this.</td>\n<td style=\"border-image: initial; padding: 0px; margin: 0px; border: 0px initial initial;\">&nbsp;</td>\n<td class=\"ss-table-number\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 1.38em; border-image: initial; vertical-align: top; font-weight: bold; text-align: right; margin: 0px; border: 0px initial initial;\">5</td>\n<td class=\"ss-table-percentage\" style=\"padding-top: 0px; padding-right: 0px; padding-bottom: 0.5em; padding-left: 1.38em; border-image: initial; vertical-align: top; color: #666666; text-align: right; margin: 0px; border: 0px initial initial;\">5%</td>\n</tr>\n</tbody>\n</table>\n</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SLXKMADoGoHguKhAc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": -39, "extendedScore": null, "score": -8.3e-05, "legacy": true, "legacyId": "10740", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KG9xzRiQQm8tYXfkQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T18:19:16.423Z", "modifiedAt": null, "url": null, "title": "Open thread, November 2011", "slug": "open-thread-november-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.955Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oscar_Cunningham", "createdAt": "2009-09-18T13:28:22.764Z", "isAdmin": false, "displayName": "Oscar_Cunningham"}, "userId": "G2SZuAiaBaNPg9rBt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s9oafmAMQKwEWP4vb/open-thread-november-2011", "pageUrlRelative": "/posts/s9oafmAMQKwEWP4vb/open-thread-november-2011", "linkUrl": "https://www.lesswrong.com/posts/s9oafmAMQKwEWP4vb/open-thread-november-2011", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20thread%2C%20November%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20thread%2C%20November%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs9oafmAMQKwEWP4vb%2Fopen-thread-november-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20thread%2C%20November%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs9oafmAMQKwEWP4vb%2Fopen-thread-november-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs9oafmAMQKwEWP4vb%2Fopen-thread-november-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 27, "htmlBody": "<p>Discuss things here if they don't deserve a post in <a href=\"/promoted/\">Main</a> or <a href=\"/r/discussion/new/\">Discussion</a>.</p>\n<p>If a topic is worthy and receives much discussion, make a new thread for it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s9oafmAMQKwEWP4vb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 7.934323075215806e-07, "legacy": true, "legacyId": "10741", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 212, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T19:11:54.544Z", "modifiedAt": null, "url": null, "title": "[LINK] Nature Editorial Argues for More Bayes in Court", "slug": "link-nature-editorial-argues-for-more-bayes-in-court", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.815Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobertLumley", "createdAt": "2011-04-28T23:53:16.950Z", "isAdmin": false, "displayName": "RobertLumley"}, "userId": "KXJjaWHDF4HJ2DF7a", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8PR69oWkxCGJAPvyz/link-nature-editorial-argues-for-more-bayes-in-court", "pageUrlRelative": "/posts/8PR69oWkxCGJAPvyz/link-nature-editorial-argues-for-more-bayes-in-court", "linkUrl": "https://www.lesswrong.com/posts/8PR69oWkxCGJAPvyz/link-nature-editorial-argues-for-more-bayes-in-court", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Nature%20Editorial%20Argues%20for%20More%20Bayes%20in%20Court&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Nature%20Editorial%20Argues%20for%20More%20Bayes%20in%20Court%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8PR69oWkxCGJAPvyz%2Flink-nature-editorial-argues-for-more-bayes-in-court%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Nature%20Editorial%20Argues%20for%20More%20Bayes%20in%20Court%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8PR69oWkxCGJAPvyz%2Flink-nature-editorial-argues-for-more-bayes-in-court", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8PR69oWkxCGJAPvyz%2Flink-nature-editorial-argues-for-more-bayes-in-court", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 14, "htmlBody": "<p>Nothing new here, but a good graphic of likelihood ratios that was quite good.</p>\n<p>&nbsp;</p>\n<p>http://www.nature.com/nature/journal/v479/n7371/full/479036a.html</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8PR69oWkxCGJAPvyz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "10742", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T19:21:42.249Z", "modifiedAt": null, "url": null, "title": "What does your accuracy tell you about your confidence interval?", "slug": "what-does-your-accuracy-tell-you-about-your-confidence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:19.653Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HonoreDB", "createdAt": "2010-11-18T19:42:02.810Z", "isAdmin": false, "displayName": "HonoreDB"}, "userId": "7eyYSfGvgCur6pXmk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ajrfXoSoCQc3u9r2a/what-does-your-accuracy-tell-you-about-your-confidence", "pageUrlRelative": "/posts/ajrfXoSoCQc3u9r2a/what-does-your-accuracy-tell-you-about-your-confidence", "linkUrl": "https://www.lesswrong.com/posts/ajrfXoSoCQc3u9r2a/what-does-your-accuracy-tell-you-about-your-confidence", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20does%20your%20accuracy%20tell%20you%20about%20your%20confidence%20interval%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20does%20your%20accuracy%20tell%20you%20about%20your%20confidence%20interval%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FajrfXoSoCQc3u9r2a%2Fwhat-does-your-accuracy-tell-you-about-your-confidence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20does%20your%20accuracy%20tell%20you%20about%20your%20confidence%20interval%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FajrfXoSoCQc3u9r2a%2Fwhat-does-your-accuracy-tell-you-about-your-confidence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FajrfXoSoCQc3u9r2a%2Fwhat-does-your-accuracy-tell-you-about-your-confidence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 471, "htmlBody": "<p>Yvain's <a href=\"/lw/89a/2011_less_wrong_census_survey/\">2011 Less Wrong Census/Survey</a>&nbsp;is still ongoing throughout November, 2011. &nbsp;If you haven't taken it, please do before reading on, or at least write down your answers to the calibration questions so they won't get skewed by the following discussion.</p>\n<p><a id=\"more\"></a>The survey includes these questions:</p>\n<p><span style=\"font-family: Arial, sans-serif; font-size: 13px;\"> </span></p>\n<div class=\"errorbox-good\" style=\"padding: 0px; margin: 0px; border: 0px initial initial;\">\n<div class=\"ss-item ss-text\" style=\"padding: 0px; margin: 0px; border: 0px initial initial;\">\n<div class=\"ss-form-entry\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1.5em; margin-left: 0px; zoom: 1; padding: 0px; border: 0px initial initial;\"><label class=\"ss-q-title\" style=\"display: block; cursor: pointer; font-weight: bold;\" for=\"entry_38\">Calibration Year</label><label class=\"ss-q-help\" style=\"display: block; cursor: pointer; color: #666666; margin-top: 0.1em; margin-right: 0px; margin-bottom: 0.25em; margin-left: 0px;\" for=\"entry_38\">Without checking a source, in what year do you estimate [redacted event happened]?</label></div>\n</div>\n</div>\n<div class=\"errorbox-good\" style=\"padding: 0px; margin: 0px; border: 0px initial initial;\">\n<div class=\"ss-item ss-text\" style=\"padding: 0px; margin: 0px; border: 0px initial initial;\">\n<div class=\"ss-form-entry\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1.5em; margin-left: 0px; zoom: 1; padding: 0px; border: 0px initial initial;\"><label class=\"ss-q-title\" style=\"display: block; cursor: pointer; font-weight: bold;\" for=\"entry_39\">Calibration Answer</label><label class=\"ss-q-help\" style=\"display: block; cursor: pointer; color: #666666; margin-top: 0.1em; margin-right: 0px; margin-bottom: 0.25em; margin-left: 0px;\" for=\"entry_39\">Without checking a source, estimate the probability that the answer you just gave is within 15 years either way of the correct answer.</label></div>\n</div>\n<div class=\"ss-form-entry\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1.5em; margin-left: 0px; zoom: 1; padding: 0px; border: 0px initial initial;\">In the comments, several people including myself wondered what our level of accuracy in the first question said about the calibration of our answer to the second question. &nbsp;If your guess for the first question was really close to correct, but your probability for the second question was low, were you underconfident? &nbsp;If you were far off, but your probability was high, were you overconfident?</div>\n</div>\n<div class=\"ss-form-entry\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1.5em; margin-left: 0px; zoom: 1; padding: 0px; border: 0px initial initial;\">We could test our calibration by simply answering a lot of these pairs of questions, then applying a proper scoring rule. &nbsp;But that seems like throwing out information. &nbsp;Surely we could calibrate faster if we're allowed to use our accuracy as evidence?</div>\n<div class=\"ss-form-entry\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1.5em; margin-left: 0px; zoom: 1; padding: 0px; border: 0px initial initial;\">I suspect there are people on here with the tools to work this out trivially. &nbsp;Here's my try at it:</div>\n<div class=\"ss-form-entry\" style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1.5em; margin-left: 0px; zoom: 1; padding: 0px; border: 0px initial initial;\">\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">Suppose you state a p-confidence interval of &plusmn;a around your guess x of the true value X.&nbsp; Then you find that, actually, |X - x| = b.&nbsp; What does this say about your confidence interval?</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; min-height: 14.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">As a first approximation, we can represent your confidence interval as a claim that the answer is uniformly randomly placed within an interval of &plusmn;(a/p), and that you have guessed uniformly within the same interval.&nbsp; If this is the case, your guess should on average be &plusmn;(1/3 * a/p) off, following a triangular distribution.&nbsp; It should be in the range (1/3 &plusmn; 3/16)(a/p) half the time.&nbsp; It should be less than 1/3(3 - sqrt(6)), or about .18, 1/3 of the time, and greater than 1-1/(sqrt(3), or about .42, 1/3 of the time.</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; min-height: 14.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">So, here's a rule of thumb for evaluating your confidence intervals based on how close you're getting to the actual answer.&nbsp; Again, a is the radius of your interval, and p is the probability you assigned that the answer is in that interval.</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; min-height: 14.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">1.&nbsp; Determine how far you were off, divide by a, and multiply by p.</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">2.&nbsp; If your result is less than .18 more than a third of the time, you're being underconfident.&nbsp; If your result is greater than .42 more than a third of the time, you're being overconfident.</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">In my case, I was 2 years off, and estimated a probability of .85 that I was within 15 years. &nbsp;So my result is 2/15 * .85 = .11333... &nbsp;That's less than the lower threshold. &nbsp;If I find this happening more than 1/3 of the time, I'm being underconfident.</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">Can anybody suggest a better system?</p>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ajrfXoSoCQc3u9r2a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 7.934540858138348e-07, "legacy": true, "legacyId": "10743", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["miHttwTgajY2sjY3L"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-02T20:54:41.444Z", "modifiedAt": null, "url": null, "title": "[link]s Recent developments in life-extension", "slug": "link-s-recent-developments-in-life-extension", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:07.897Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaZ", "createdAt": "2010-04-05T04:07:01.214Z", "isAdmin": false, "displayName": "JoshuaZ"}, "userId": "fmTiLqp6mmXeLjwfN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EBgxWap8FBJ57DEe2/link-s-recent-developments-in-life-extension", "pageUrlRelative": "/posts/EBgxWap8FBJ57DEe2/link-s-recent-developments-in-life-extension", "linkUrl": "https://www.lesswrong.com/posts/EBgxWap8FBJ57DEe2/link-s-recent-developments-in-life-extension", "postedAtFormatted": "Wednesday, November 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5Ds%20Recent%20developments%20in%20life-extension&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5Ds%20Recent%20developments%20in%20life-extension%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEBgxWap8FBJ57DEe2%2Flink-s-recent-developments-in-life-extension%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5Ds%20Recent%20developments%20in%20life-extension%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEBgxWap8FBJ57DEe2%2Flink-s-recent-developments-in-life-extension", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEBgxWap8FBJ57DEe2%2Flink-s-recent-developments-in-life-extension", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 89, "htmlBody": "<p>Progeria is a very rare disease which causes children to undergo symptoms extremely similar to rapid aging, and generally dying before the age of 20. Recent results suggest that a fairly cheap drug may help reduce the aging systems, and it is possible it may have similar effects on normal humans. <a href=\"http://www.bbc.co.uk/news/health-15536744\">Lay summary by BBC</a> and <a href=\"http://hmg.oxfordjournals.org/content/20/20/3997.short\">actual article</a></p>\n<p><a href=\"http://hmg.oxfordjournals.org/content/20/20/3997.short\"> </a></p>\n<p>On a related note, in a strain of mice which age unusually quickly, there's been success delaying many symptoms of aging by removing senescent cells. Here is the relevant <a href=\"http://www.nature.com/nature/journal/vaop/ncurrent/full/nature10600.html\">article in Nature. </a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EBgxWap8FBJ57DEe2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 17, "extendedScore": null, "score": 7.93486525306287e-07, "legacy": true, "legacyId": "10745", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T02:02:42.281Z", "modifiedAt": null, "url": null, "title": "What are the best ways of absorbing, and maintaining, knowledge?", "slug": "what-are-the-best-ways-of-absorbing-and-maintaining", "viewCount": null, "lastCommentedAt": "2020-05-03T04:13:39.018Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Arkanj3l", "createdAt": "2011-04-23T03:48:47.569Z", "isAdmin": false, "displayName": "Arkanj3l"}, "userId": "nQmA4dnBdX99WyCt3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fX9cye9fdhpcK25Gm/what-are-the-best-ways-of-absorbing-and-maintaining", "pageUrlRelative": "/posts/fX9cye9fdhpcK25Gm/what-are-the-best-ways-of-absorbing-and-maintaining", "linkUrl": "https://www.lesswrong.com/posts/fX9cye9fdhpcK25Gm/what-are-the-best-ways-of-absorbing-and-maintaining", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20the%20best%20ways%20of%20absorbing%2C%20and%20maintaining%2C%20knowledge%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20the%20best%20ways%20of%20absorbing%2C%20and%20maintaining%2C%20knowledge%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfX9cye9fdhpcK25Gm%2Fwhat-are-the-best-ways-of-absorbing-and-maintaining%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20the%20best%20ways%20of%20absorbing%2C%20and%20maintaining%2C%20knowledge%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfX9cye9fdhpcK25Gm%2Fwhat-are-the-best-ways-of-absorbing-and-maintaining", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfX9cye9fdhpcK25Gm%2Fwhat-are-the-best-ways-of-absorbing-and-maintaining", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 657, "htmlBody": "<p>Recently, I've collapsed (ascended?) down/up a meta-learning death spiral -- doing a lot less of <em>reading</em> actual informative content, than figuring out how to <em>manage</em> and acquire such content (<a href=\"/lw/5a5/no_seriously_just_try_it/\">as well as completely ignoring the antidote</a>). In other words, I've been taking notes on taking notes. And now, I'm looking for your notes on notes for notes.</p>\n<p>What kind of scientific knowledge, techniques, and resources do we have right now in the way of information management? How would one efficiently extract useful information possible out of a single pass of the source? The second pass?&nbsp;</p>\n<p>The answers may depend on the media, and the media might not be readily apparent. Example: <a href=\"http://www.media.mit.edu/people/esb\">Edward Boyden</a>, Assistant Professor at the MIT Media Lab, recommends recording in a notebook every conversation you ever have with other people. And how do you prepare yourself for the serendipity of a walk downtown? I know I'm more likely to regret not having a notebook on hand than spending the time to bring one along.</p>\n<p>I'll conglomerate what I remember seeing on the <a href=\"/groups.google.com/group/brain-training\">N-Back Mailing List</a> and in general: I sincerely apologize for my lack of citation.</p>\n<p><strong>Notes</strong></p>\n<ul>\n<li>I'm on the fence about <a href=\"http://en.wikipedia.org/wiki/Shorthand\">Shorthand</a>&nbsp;as a note-taking technique, given the learning overhead, but I'm sure that the same has been said for touch-typing. It would involve a second stage of processing if you can't read as well as you write, but given the way I have taken notes (... \"non-linearly\"...), that stage would have to come about anyway. The act of translation may serve as a way of laying connective groundwork down.</li>\n<li><a href=\"http://www.livescribe.com/en-gb/\">Livescribe Pens</a>&nbsp;are nifty for those who write slowly, but they need to be combined with a written technique to be of any use (otherwise you're just recording the talk, and would have to live through it twice without any obvious annotation and tagging).</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Cornell_Notes\">Cornell Notes</a>&nbsp;or taking notes in a hierarchy may have been the method you were taught in high school; it was in mine. The issue I have had with this format is that I found it hard to generate a structure while listening to the teacher at the same time.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Mind_map\">Mind-Mapping</a>.</li>\n<li>Color-coding annotations of text has been remarked to be useful on Science Daily.</li>\n</ul>\n<div><strong>Reading</strong></div>\n<ul>\n<li><a href=\"http://www.fourhourworkweek.com/blog/2009/07/30/speed-reading-and-accelerated-learning/\">Speed Reading Techniques</a>&nbsp; or removing sub-vocalization would seem to have benefits.</li>\n<li>Once upon a time someone recommended me the book, \"<a href=\"http://www.amazon.com/How-Read-Book-Touchstone-book/dp/0671212095/ref=cm_cr_pr_product_top\">How to Read a Book</a>\". Nothing ground-breaking -- outline the author's intent, the structure of his argument, and its content. Then criticize. In short, book reverse-engineering.</li>\n</ul>\n<div><strong>Retention</strong></div>\n<ul>\n<li>Spaced Repetition. I'm currently flipping through the thoughts of &nbsp;<a href=\"http://www.supermemo.com/\">Peter Wozniak</a>, who seems to have made it his dire mission to make <em>every kind of media possible</em> Spaced Repetition'able. I'm wondering if anyone has any thoughts on&nbsp;<a href=\"http://www.supermemo.com/help/read.htm\">incremental reading</a>&nbsp;or &nbsp;<a href=\"http://www.supermemo.com/help/video.htm\">video</a>; also, how to possibly translate the benefits of SRS to dead-tree media, which seems a bit cumbersome.</li>\n</ul>\n<p><span style=\"white-space: pre;\"> </span>(I've also heard a handful of individuals claim that SRS has helped them \"internalize\" certain behaviors, or maybe patterns of <span style=\"white-space: pre;\"> </span>thought, like Non-Violent Comunication or Bayes Theorem... any takers on this?)</p>\n<ul>\n<li>Wikis, which seem like a good format for creating social accountability, and filing notes that aren't note-carded. &nbsp;<em>But what kind of information should that be?</em></li>\n<li>Emotionally charged stimuli, especially stressful, tends to be remembered to greater accuracy.</li>\n<li>Category Brainstorming.Take your bits of knowledge, and organize them into as many different groups as you can think of, mixing and matching if need be. Sources for such provocations could include Edward De Bono's \"<a href=\"http://books.google.ca/books?id=H-ROAAAAMAAJ&amp;redir_esc=y\">Lateral Thinking</a>\" and Seth Godin's \"<a href=\"http://www.amazon.com/Free-Prize-Inside-Next-Marketing/dp/1591840414\">Free Prize Inside</a>\", or George Polya's \"<a href=\"http://www.amazon.com/How-Solve-Aspect-Mathematical-Method/dp/0691023565\">How to Solve It</a>\". I'm a bit ambivalent of deliberately memorizing such provocations -- does it get in the way&nbsp;of seeing originally? -- but once again, it could lay down the connective framework needed for good recall.</li>\n<li>Mnemonics to encode related information seems useful.</li>\n</ul>\n<div>Any other information gathering, optimising and retaining techniques worthy of mention?</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fX9cye9fdhpcK25Gm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 22, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "10748", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Zmfo388RA9oky3KYe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T03:17:13.585Z", "modifiedAt": null, "url": null, "title": "Guardian coverage of the Summit [link]", "slug": "guardian-coverage-of-the-summit-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:09.150Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FPpA6tiQfMR3BG7uD/guardian-coverage-of-the-summit-link", "pageUrlRelative": "/posts/FPpA6tiQfMR3BG7uD/guardian-coverage-of-the-summit-link", "linkUrl": "https://www.lesswrong.com/posts/FPpA6tiQfMR3BG7uD/guardian-coverage-of-the-summit-link", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Guardian%20coverage%20of%20the%20Summit%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGuardian%20coverage%20of%20the%20Summit%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFPpA6tiQfMR3BG7uD%2Fguardian-coverage-of-the-summit-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Guardian%20coverage%20of%20the%20Summit%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFPpA6tiQfMR3BG7uD%2Fguardian-coverage-of-the-summit-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFPpA6tiQfMR3BG7uD%2Fguardian-coverage-of-the-summit-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>http://www.guardian.co.uk/commentisfree/belief/2011/nov/02/ai-gods-singularity-artificial-intelligence?newsfeed=true</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FPpA6tiQfMR3BG7uD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 7.936200022044014e-07, "legacy": true, "legacyId": "10753", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T04:29:45.039Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Not for the Sake of Happiness (Alone)", "slug": "seq-rerun-not-for-the-sake-of-happiness-alone", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:21.924Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/exnET8DmenJTH2ALC/seq-rerun-not-for-the-sake-of-happiness-alone", "pageUrlRelative": "/posts/exnET8DmenJTH2ALC/seq-rerun-not-for-the-sake-of-happiness-alone", "linkUrl": "https://www.lesswrong.com/posts/exnET8DmenJTH2ALC/seq-rerun-not-for-the-sake-of-happiness-alone", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Not%20for%20the%20Sake%20of%20Happiness%20(Alone)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Not%20for%20the%20Sake%20of%20Happiness%20(Alone)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexnET8DmenJTH2ALC%2Fseq-rerun-not-for-the-sake-of-happiness-alone%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Not%20for%20the%20Sake%20of%20Happiness%20(Alone)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexnET8DmenJTH2ALC%2Fseq-rerun-not-for-the-sake-of-happiness-alone", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FexnET8DmenJTH2ALC%2Fseq-rerun-not-for-the-sake-of-happiness-alone", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 192, "htmlBody": "<p>Today's post, <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">Not for the Sake of Happiness (Alone)</a> was originally published on 22 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>Tackles the Hollywood Rationality trope that \"rational\" preferences must reduce to selfish hedonism - caring strictly about personally experienced pleasure. An ideal Bayesian agent - implementing strict Bayesian decision theory - can have a utility function that ranges over anything, not just internal subjective experiences.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/8a5/seq_rerun_truly_part_of_you/\">Truly Part of You</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb186": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "exnET8DmenJTH2ALC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.936453122786576e-07, "legacy": true, "legacyId": "10757", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["synsRtBKDeAFuo7e3", "4Yvm4EwZkXCkPCKTy", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T10:04:34.447Z", "modifiedAt": null, "url": null, "title": "Anthropic Decision Theory III: Solving Selfless and Total Utilitarian Sleeping Beauty", "slug": "anthropic-decision-theory-iii-solving-selfless-and-total", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:38.601Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zqm2nTqjAKg6EyxE3/anthropic-decision-theory-iii-solving-selfless-and-total", "pageUrlRelative": "/posts/zqm2nTqjAKg6EyxE3/anthropic-decision-theory-iii-solving-selfless-and-total", "linkUrl": "https://www.lesswrong.com/posts/zqm2nTqjAKg6EyxE3/anthropic-decision-theory-iii-solving-selfless-and-total", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anthropic%20Decision%20Theory%20III%3A%20Solving%20Selfless%20and%20Total%20Utilitarian%20Sleeping%20Beauty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnthropic%20Decision%20Theory%20III%3A%20Solving%20Selfless%20and%20Total%20Utilitarian%20Sleeping%20Beauty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzqm2nTqjAKg6EyxE3%2Fanthropic-decision-theory-iii-solving-selfless-and-total%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anthropic%20Decision%20Theory%20III%3A%20Solving%20Selfless%20and%20Total%20Utilitarian%20Sleeping%20Beauty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzqm2nTqjAKg6EyxE3%2Fanthropic-decision-theory-iii-solving-selfless-and-total", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzqm2nTqjAKg6EyxE3%2Fanthropic-decision-theory-iii-solving-selfless-and-total", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 952, "htmlBody": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this, subsequent, and previous posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<h2><strong>Consistency</strong></h2>\n<p>In&nbsp;order to transform the Sleeping Beauty problem into a decision problem, assume that every time she is awoken, she is offered a coupon that pays out &pound;1 if the coin fell tails. She must then decide at what cost she is willing to buy that coupon.</p>\n<p>The very first axiom is that of temporal consistency. If your preferences are going to predictably change, then someone will be able to exploit this, by selling you something now that they will buy back for more later, or vice versa. This axiom is implicit in the independence axiom in the von Neumann-Morgenstern axioms of expected utility, where non-independent decisions show inconsistency after partially resolving one of the lotteries. For our purposes, we will define it as:</p>\n<p><a id=\"more\"></a></p>\n<ul>\n<li>Temporal Consistency: If an agent at two different times has the same knowledge and preferences, then the past version will never give up anything of value in order to change the decision of the future version.</li>\n</ul>\n<p>This is appropriate for the standard Sleeping Beauty problem, but not for the incubator variant, where the different copies are not future or past versions of each other. To deal with that, we extend the axiom to:</p>\n<ul>\n<li>Consistency: If two copies of an agent have the same knowledge and preferences, then the one version will never give up anything of value in order to change the decision of the other version.</li>\n</ul>\n<p>Note that while 'same preferences' is something we could expect to see for the same agent at different times, it is not something the case for copies, who are generally assumed to be selfish towards each other. Indeed, this whole issue of selflessness, altruism and selfishness will be of great import for the agent's behaviour, as we shall now see.</p>\n<h2><strong>Selfless Sleeping Beauty</strong></h2>\n<p>Assume that Sleeping Beauty has an entirely selfless utility function. To simplify matters, we will further assume her utility is linear in cash (though cash for her is simply a tool to accomplish her selfless goals).&nbsp;Before Sleeping Beauty is put to sleep the first time, she will follow the following reasoning:</p>\n<p style=\"padding-left: 30px;\">\"In the tails world, future copies of myself will be offered the same deal twice. Any profit they make will be dedicated to my selfless goal, so from my perspective, profits (and losses) will be doubled in the tails world. If my future copies will buy the coupon for &pound;x, there would be an expected &pound;0.5(2(-x + 1) + 1(-x + 0)) = &pound;(1-3/2x) going towards my goal. Hence I would want my copies to buy whenever x&lt;2/3.\"</p>\n<p>Then by the temporal consistency axiom, this is indeed what her future copies will do. Note that Sleeping Beauty is here showing a behaviour similar to the SIA probabilities -- she is betting on 2:1 odds that she is in the world with two copies.</p>\n<h2><strong>Selfless Incubator Sleeping Beauty</strong></h2>\n<p>In the incubator variant, there is no initial Sleeping Beauty to make decisions for her future copies. Thus consistency is not enough to resolve the decision problem, even for a selfless Sleeping Beauty. To do so, we will need to make use of our second axiom:</p>\n<ul>\n<li>Outside agent: If there exists a collection of identical agents (which may be the same agent at different times) with same knowledge and preferences, then another copy of them with the same information would never give up anything of value to make them change their decisions.</li>\n</ul>\n<p>With this axiom, the situation reduces to the above selfless Sleeping Beauty, by simply adding in the initial Sleeping Beauty again as 'another copy'.&nbsp;Some might feel that that axiom is too strong, that invariance under the creation or destruction of extra copies is something that cannot be simply assumed in anthropic reasoning. An equivalent axiom could be:</p>\n<ul>\n<li>Total agent: If there exists a collection of identical agents (which may be the same agent at different times) with same knowledge and preferences, then they will make their decisions as if they were a single agent simultaneously controlling all their (correlated) decisions.</li>\n</ul>\n<p>This axiom is equivalent to the other, with the total agent taking the role of the outside agent. Since all the agents are identical, going through exactly the same reasoning process to reach the same decision, the total agent formulation may be more intuitive. They are, from a certain perspective, literally the same agent. This is the decision that the agents would reach if they could all coordinate with each other, if there were a way of doing this without them figuring out how many of them there were.</p>\n<h2><strong>Altruistic total utilitarian Sleeping Beauty</strong></h2>\n<p>An altruistic total utilitarian will have the same preferences over the possible outcomes in a Sleeping Beauty situation: the outcomes in the tails world is doubled, as any gain/loss happens twice, and the altruist adds up the effect of each gain/loss. Hence the altruistic total utilitarian Sleeping Beauty will make the same decisions as the selfless one.</p>\n<h2><strong>Copy-altruistic total utilitarian Sleeping Beauty</strong></h2>\n<p>The above argument does not require that Sleeping Beauty be entirely altruistic, only that she be altruistic towards all her copies. Thus she may have selfish personal preferences (\"I prefer to have this chocolate bar, rather than letting Snow White get it\"), as long as these are not towards her copies (\"I'm indifferent as to whether I or Sleeping Beauty II gets the chocolate bar\"). And then she will make the same decision in this problem as if she was entirely altruistic.</p>\n<p>This post looked at situation implying SIA-like behaviour; tomorrow's post will look at cases where SSA-like behaviour is the right way to go.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2, "NZB24aR9uHmDc5GcT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zqm2nTqjAKg6EyxE3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "10718", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "kmryZRz5r9bjsug9e", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "anthropic-decision-theory-iv-solving-selfish-and-average", "canonicalPrevPostSlug": "anthropic-decision-theory-ii-self-indication-self-sampling", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this, subsequent, and previous posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<h2 id=\"Consistency\"><strong>Consistency</strong></h2>\n<p>In&nbsp;order to transform the Sleeping Beauty problem into a decision problem, assume that every time she is awoken, she is offered a coupon that pays out \u00a31 if the coin fell tails. She must then decide at what cost she is willing to buy that coupon.</p>\n<p>The very first axiom is that of temporal consistency. If your preferences are going to predictably change, then someone will be able to exploit this, by selling you something now that they will buy back for more later, or vice versa. This axiom is implicit in the independence axiom in the von Neumann-Morgenstern axioms of expected utility, where non-independent decisions show inconsistency after partially resolving one of the lotteries. For our purposes, we will define it as:</p>\n<p><a id=\"more\"></a></p>\n<ul>\n<li>Temporal Consistency: If an agent at two different times has the same knowledge and preferences, then the past version will never give up anything of value in order to change the decision of the future version.</li>\n</ul>\n<p>This is appropriate for the standard Sleeping Beauty problem, but not for the incubator variant, where the different copies are not future or past versions of each other. To deal with that, we extend the axiom to:</p>\n<ul>\n<li>Consistency: If two copies of an agent have the same knowledge and preferences, then the one version will never give up anything of value in order to change the decision of the other version.</li>\n</ul>\n<p>Note that while 'same preferences' is something we could expect to see for the same agent at different times, it is not something the case for copies, who are generally assumed to be selfish towards each other. Indeed, this whole issue of selflessness, altruism and selfishness will be of great import for the agent's behaviour, as we shall now see.</p>\n<h2 id=\"Selfless_Sleeping_Beauty\"><strong>Selfless Sleeping Beauty</strong></h2>\n<p>Assume that Sleeping Beauty has an entirely selfless utility function. To simplify matters, we will further assume her utility is linear in cash (though cash for her is simply a tool to accomplish her selfless goals).&nbsp;Before Sleeping Beauty is put to sleep the first time, she will follow the following reasoning:</p>\n<p style=\"padding-left: 30px;\">\"In the tails world, future copies of myself will be offered the same deal twice. Any profit they make will be dedicated to my selfless goal, so from my perspective, profits (and losses) will be doubled in the tails world. If my future copies will buy the coupon for \u00a3x, there would be an expected \u00a30.5(2(-x + 1) + 1(-x + 0)) = \u00a3(1-3/2x) going towards my goal. Hence I would want my copies to buy whenever x&lt;2/3.\"</p>\n<p>Then by the temporal consistency axiom, this is indeed what her future copies will do. Note that Sleeping Beauty is here showing a behaviour similar to the SIA probabilities -- she is betting on 2:1 odds that she is in the world with two copies.</p>\n<h2 id=\"Selfless_Incubator_Sleeping_Beauty\"><strong>Selfless Incubator Sleeping Beauty</strong></h2>\n<p>In the incubator variant, there is no initial Sleeping Beauty to make decisions for her future copies. Thus consistency is not enough to resolve the decision problem, even for a selfless Sleeping Beauty. To do so, we will need to make use of our second axiom:</p>\n<ul>\n<li>Outside agent: If there exists a collection of identical agents (which may be the same agent at different times) with same knowledge and preferences, then another copy of them with the same information would never give up anything of value to make them change their decisions.</li>\n</ul>\n<p>With this axiom, the situation reduces to the above selfless Sleeping Beauty, by simply adding in the initial Sleeping Beauty again as 'another copy'.&nbsp;Some might feel that that axiom is too strong, that invariance under the creation or destruction of extra copies is something that cannot be simply assumed in anthropic reasoning. An equivalent axiom could be:</p>\n<ul>\n<li>Total agent: If there exists a collection of identical agents (which may be the same agent at different times) with same knowledge and preferences, then they will make their decisions as if they were a single agent simultaneously controlling all their (correlated) decisions.</li>\n</ul>\n<p>This axiom is equivalent to the other, with the total agent taking the role of the outside agent. Since all the agents are identical, going through exactly the same reasoning process to reach the same decision, the total agent formulation may be more intuitive. They are, from a certain perspective, literally the same agent. This is the decision that the agents would reach if they could all coordinate with each other, if there were a way of doing this without them figuring out how many of them there were.</p>\n<h2 id=\"Altruistic_total_utilitarian_Sleeping_Beauty\"><strong>Altruistic total utilitarian Sleeping Beauty</strong></h2>\n<p>An altruistic total utilitarian will have the same preferences over the possible outcomes in a Sleeping Beauty situation: the outcomes in the tails world is doubled, as any gain/loss happens twice, and the altruist adds up the effect of each gain/loss. Hence the altruistic total utilitarian Sleeping Beauty will make the same decisions as the selfless one.</p>\n<h2 id=\"Copy_altruistic_total_utilitarian_Sleeping_Beauty\"><strong>Copy-altruistic total utilitarian Sleeping Beauty</strong></h2>\n<p>The above argument does not require that Sleeping Beauty be entirely altruistic, only that she be altruistic towards all her copies. Thus she may have selfish personal preferences (\"I prefer to have this chocolate bar, rather than letting Snow White get it\"), as long as these are not towards her copies (\"I'm indifferent as to whether I or Sleeping Beauty II gets the chocolate bar\"). And then she will make the same decision in this problem as if she was entirely altruistic.</p>\n<p>This post looked at situation implying SIA-like behaviour; tomorrow's post will look at cases where SSA-like behaviour is the right way to go.</p>", "sections": [{"title": "Consistency", "anchor": "Consistency", "level": 1}, {"title": "Selfless Sleeping Beauty", "anchor": "Selfless_Sleeping_Beauty", "level": 1}, {"title": "Selfless Incubator Sleeping Beauty", "anchor": "Selfless_Incubator_Sleeping_Beauty", "level": 1}, {"title": "Altruistic total utilitarian Sleeping Beauty", "anchor": "Altruistic_total_utilitarian_Sleeping_Beauty", "level": 1}, {"title": "Copy-altruistic total utilitarian Sleeping Beauty", "anchor": "Copy_altruistic_total_utilitarian_Sleeping_Beauty", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["svhbnSdxW3XmFXXTK", "G9scbpNrCxfJZQmYu", "zqm2nTqjAKg6EyxE3", "LXHsiHahr2eFQ4Hsp", "wQd3rLLLNWYRgjaYg", "NpPEJT2CCKjeo59Ps"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T15:31:42.635Z", "modifiedAt": null, "url": null, "title": "AI Challenge: Ants", "slug": "ai-challenge-ants", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.617Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lavalamp", "createdAt": "2009-04-16T17:40:52.495Z", "isAdmin": false, "displayName": "lavalamp"}, "userId": "eAtTnhxH9y8suzqrf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rrX37rZkf2o4XEfuT/ai-challenge-ants", "pageUrlRelative": "/posts/rrX37rZkf2o4XEfuT/ai-challenge-ants", "linkUrl": "https://www.lesswrong.com/posts/rrX37rZkf2o4XEfuT/ai-challenge-ants", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AI%20Challenge%3A%20Ants&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAI%20Challenge%3A%20Ants%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrrX37rZkf2o4XEfuT%2Fai-challenge-ants%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AI%20Challenge%3A%20Ants%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrrX37rZkf2o4XEfuT%2Fai-challenge-ants", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrrX37rZkf2o4XEfuT%2Fai-challenge-ants", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 206, "htmlBody": "<p>Aichallenge.org has started their third AI contest this year: <a href=\"http://aichallenge.org/index.php\">Ants</a>.</p>\n<blockquote>\n<p><span style=\"font-family: Ubuntu, arial, serif; font-size: 12px; line-height: 18px;\">The AI Challenge is all about creating artificial intelligence, whether you are a beginning programmer or an expert. ... [Y]ou will create a computer program (in any language) that controls a colony of ants which fight against other colonies for domination. ...&nbsp;</span><span style=\"font-family: Ubuntu, arial, serif; font-size: 12px; line-height: 18px;\">The current phase of the contest will end December 18th at 11:59pm EST. At that time submissions will be closed. Shortly thereafter the final tournament will be started. ... Upon completion the contest winner will be announced and all results will be publically available.</span></p>\n<p><span style=\"font-family: Ubuntu, arial, serif; font-size: 12px; line-height: 18px;\">Ants is a multi-player strategy game set on a plot of dirt with water for obstacles and food that randomly drops. Each player has one or more hills where ants will spawn. The objective is for players to seek and destroy the most enemy ant hills while defending their own hills. Players must also gather food to spawn more ants, however, if all of a player's hills are destroyed they can't spawn any more ants.</span></p>\n</blockquote>\n<p>I mentioned this in the <a href=\"/lw/8ad/open_thread_november_2011/55js\">open thread</a>, and there was a discussion about possibly making one or more \"official\" LessWrong teams. D_Alex has offered a <a href=\"/lw/8ad/open_thread_november_2011/55nc\">motivational prize</a>. If this interests you, please discuss in the comments!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rrX37rZkf2o4XEfuT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 22, "extendedScore": null, "score": 7.938763947399381e-07, "legacy": true, "legacyId": "10762", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T20:12:24.560Z", "modifiedAt": null, "url": null, "title": "[LINK] Fraud Case Seen as a Red Flag for Psychology Research", "slug": "link-fraud-case-seen-as-a-red-flag-for-psychology-research", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:20.168Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YNGEHggJfHdxTC3G4/link-fraud-case-seen-as-a-red-flag-for-psychology-research", "pageUrlRelative": "/posts/YNGEHggJfHdxTC3G4/link-fraud-case-seen-as-a-red-flag-for-psychology-research", "linkUrl": "https://www.lesswrong.com/posts/YNGEHggJfHdxTC3G4/link-fraud-case-seen-as-a-red-flag-for-psychology-research", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Fraud%20Case%20Seen%20as%20a%20Red%20Flag%20for%20Psychology%20Research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Fraud%20Case%20Seen%20as%20a%20Red%20Flag%20for%20Psychology%20Research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYNGEHggJfHdxTC3G4%2Flink-fraud-case-seen-as-a-red-flag-for-psychology-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Fraud%20Case%20Seen%20as%20a%20Red%20Flag%20for%20Psychology%20Research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYNGEHggJfHdxTC3G4%2Flink-fraud-case-seen-as-a-red-flag-for-psychology-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYNGEHggJfHdxTC3G4%2Flink-fraud-case-seen-as-a-red-flag-for-psychology-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 734, "htmlBody": "<p>An article in the <a href=\"http://www.nytimes.com/2011/11/03/health/research/noted-dutch-psychologist-stapel-accused-of-research-fraud.html?_r=1&amp;hp\">NYT</a>'s about everyone's favourite messy science, you know the one we sometimes rely on to provide a throwaway line as we pontificate wisely about biases? ;)</p>\n<blockquote>\n<p>A well-known psychologist in the Netherlands whose work has been published widely in professional journals falsified data and made up entire experiments, an investigating committee has found. Experts say the case exposes deep flaws in the way science is done in a field, psychology, that has only recently earned a fragile respectability.</p>\n<p>The psychologist, Diederik Stapel, of Tilburg University, committed academic fraud in &ldquo;several dozen&rdquo; published papers, many accepted in respected journals and reported in the news media, according to a report released on Monday by the three Dutch institutions where he has worked ...</p>\n<p><em><strong>In recent years, psychologists have reported a raft of findings on race biases, brain imaging and even extrasensory perception that have not stood up to scrutiny.</strong></em> Outright fraud may be rare, these experts say, but they contend that Dr. Stapel took advantage of a system that allows researchers to operate in near secrecy and massage data to find what they want to find, without much fear of being challenged. ...</p>\n<p>In a prolific career, Dr. Stapel published papers on the effect of power on hypocrisy, on racial stereotyping and on how advertisements affect how people view themselves. Many of his findings appeared in newspapers around the world, including The New York Times, which reported in December on his study about advertising and identity.</p>\n<p>In a statement posted Monday on Tilburg University&rsquo;s Web site, Dr. Stapel apologized to his colleagues. &ldquo;I have failed as a scientist and researcher,&rdquo; it read, in part. &ldquo;I feel ashamed for it and have great regret.&rdquo; ...</p>\n<p>Dr. Stapel has published about 150 papers, many of which, like the advertising study, seem devised to make a splash in the media. The study published in Science this year claimed that white people became more likely to &ldquo;stereotype and discriminate&rdquo; against black people when they were in a messy environment, versus an organized one. Another study, published in 2009, claimed that people judged job applicants as more competent if they had a male voice. The investigating committee did not post a list of papers that it had found fraudulent. ...</p>\n<p>In a survey of more than 2,000 American psychologists scheduled to be published this year, Leslie John of Harvard Business School and two colleagues found that 70 percent had acknowledged, anonymously, to cutting some corners in reporting data. About a third said they had reported an unexpected finding as predicted from the start, and about 1 percent admitted to falsifying data.</p>\n<p>Also common is a self-serving statistical sloppiness. In an analysis published this year, Dr. Wicherts and Marjan Bakker, also at the University of Amsterdam, searched a random sample of 281 psychology papers for statistical errors. They found that about half of the papers in high-end journals contained some statistical error, and that about 15 percent of all papers had at least one error that changed a reported finding &mdash; almost always in opposition to the authors&rsquo; hypothesis.</p>\n<p>...<em><strong></strong></em></p>\n<p><em><strong>found that the more reluctant that scientists were to share their data, the more likely that evidence contradicted their reported findings. </strong></em></p>\n<p><em><strong>...</strong></em></p>\n<em><strong>&ldquo;We know the general tendency of humans to draw the conclusions they want to draw &mdash; there&rsquo;s a different threshold,&rdquo;</strong></em> said Joseph P. Simmons, a psychologist at the University of Pennsylvania&rsquo;s Wharton School. &ldquo;With findings we want to see, we ask, &lsquo;Can I believe this?&rsquo; With those we don&rsquo;t, we ask, &lsquo;Must I believe this?&rsquo; <br />\n<p><em><strong>But reviewers working for psychology journals rarely take this into account in any rigorous way. Neither do they typically ask to see the original data. </strong></em>While many psychologists shade and spin, Dr. Stapel went ahead and drew any conclusion he wanted.</p>\n</blockquote>\n<p>In any case this brought to my attention by a recent blog entry on <a href=\"http://isteve.blogspot.com/2011/11/telling-people-what-they-want-to-hear.html\">iSteve</a>.</p>\n<blockquote>\n<p>Telling people what they want to hear</p>\n</blockquote>\n<p>Steve Sailer thinks that what gets distorted the most in such a way is a matter of supply and demand. Which is obviously good signalling for him, but is also eminently plausible. One can't help but wonder especially on the interesting connections that exist between <em>some</em> of the \"findings\" of psychology of a certain period and place the obsessions and neurosis (heh) specific to that society.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YNGEHggJfHdxTC3G4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 18, "extendedScore": null, "score": 3.6e-05, "legacy": true, "legacyId": "10763", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-03T22:10:36.312Z", "modifiedAt": null, "url": null, "title": "Any good visual images to explain complicated ideas?", "slug": "any-good-visual-images-to-explain-complicated-ideas", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:19.964Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TheatreAddict", "createdAt": "2011-05-01T17:03:11.634Z", "isAdmin": false, "displayName": "TheatreAddict"}, "userId": "xtL2cZS7kaFnSNLus", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ows6iMjjYH4uQNgR4/any-good-visual-images-to-explain-complicated-ideas", "pageUrlRelative": "/posts/ows6iMjjYH4uQNgR4/any-good-visual-images-to-explain-complicated-ideas", "linkUrl": "https://www.lesswrong.com/posts/ows6iMjjYH4uQNgR4/any-good-visual-images-to-explain-complicated-ideas", "postedAtFormatted": "Thursday, November 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Any%20good%20visual%20images%20to%20explain%20complicated%20ideas%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAny%20good%20visual%20images%20to%20explain%20complicated%20ideas%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fows6iMjjYH4uQNgR4%2Fany-good-visual-images-to-explain-complicated-ideas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Any%20good%20visual%20images%20to%20explain%20complicated%20ideas%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fows6iMjjYH4uQNgR4%2Fany-good-visual-images-to-explain-complicated-ideas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fows6iMjjYH4uQNgR4%2Fany-good-visual-images-to-explain-complicated-ideas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 126, "htmlBody": "<p><span style=\"white-space: pre;\"> </span>I'm not really looking for anything in particular, but I just recently took a look at&nbsp;<a href=\"/lw/fc/you_are_a_brain/\">http://lesswrong.com/lw/fc/you_are_a_brain/</a>&nbsp;at You Are a Brain presentation. It was really good, and helped things click for me. Does anyone else have any recommendations for extreme beginners? I'm interested in learning most anything really, I've read a few of the Sequences, like the Mysterious Answers to Mysterious Questions, How to Actually Change Your Mind, and half of Reductionism. The Quantum Physics section looks really cool, but unfortunately it's beyond me, as of now. I'm trying to get teachers to help me, but it appears to be beyond them as well. But anyway, if you don't have any videos, pictures, or presentations, do you at least have any good textbooks to recommend? For beginners?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ows6iMjjYH4uQNgR4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 1, "extendedScore": null, "score": 7.940157016652786e-07, "legacy": true, "legacyId": "10764", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["r5H6YCmnn8DMtBtxt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T04:24:54.483Z", "modifiedAt": null, "url": null, "title": "How to manipulate future self into being productive?", "slug": "how-to-manipulate-future-self-into-being-productive", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:19.068Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Baldcat", "createdAt": "2011-11-04T03:54:27.287Z", "isAdmin": false, "displayName": "Baldcat"}, "userId": "G2zkJjTt3SgBmsKbN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/edAXEmJEZQv3ADvnE/how-to-manipulate-future-self-into-being-productive", "pageUrlRelative": "/posts/edAXEmJEZQv3ADvnE/how-to-manipulate-future-self-into-being-productive", "linkUrl": "https://www.lesswrong.com/posts/edAXEmJEZQv3ADvnE/how-to-manipulate-future-self-into-being-productive", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20manipulate%20future%20self%20into%20being%20productive%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20manipulate%20future%20self%20into%20being%20productive%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FedAXEmJEZQv3ADvnE%2Fhow-to-manipulate-future-self-into-being-productive%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20manipulate%20future%20self%20into%20being%20productive%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FedAXEmJEZQv3ADvnE%2Fhow-to-manipulate-future-self-into-being-productive", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FedAXEmJEZQv3ADvnE%2Fhow-to-manipulate-future-self-into-being-productive", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p>I don't like doing much work. I would however, like my future self to do work so that my far future self will have better opportunities.</p>\n<p>To clarify, I want these things for each specified self:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Current self: immediate gratification</li>\n<li>Future self: work hard</li>\n<li>Far future self: benefit from future self's work</li>\n</ul>\n<p>&nbsp;</p>\n<p>The problem is, I expect that my future self will feel the same way and also want immediate gratification. What can I do now to achieve all 3 of those goals? How can I manipulate my future self into doing more work without having to do much work right now?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "edAXEmJEZQv3ADvnE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 0, "extendedScore": null, "score": 7.941464595848603e-07, "legacy": true, "legacyId": "10773", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T04:31:10.922Z", "modifiedAt": null, "url": null, "title": "[SEQ RERUN] Leaky Generalizations", "slug": "seq-rerun-leaky-generalizations", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2TAfmGBZeRjRDLiMc/seq-rerun-leaky-generalizations", "pageUrlRelative": "/posts/2TAfmGBZeRjRDLiMc/seq-rerun-leaky-generalizations", "linkUrl": "https://www.lesswrong.com/posts/2TAfmGBZeRjRDLiMc/seq-rerun-leaky-generalizations", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BSEQ%20RERUN%5D%20Leaky%20Generalizations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BSEQ%20RERUN%5D%20Leaky%20Generalizations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2TAfmGBZeRjRDLiMc%2Fseq-rerun-leaky-generalizations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BSEQ%20RERUN%5D%20Leaky%20Generalizations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2TAfmGBZeRjRDLiMc%2Fseq-rerun-leaky-generalizations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2TAfmGBZeRjRDLiMc%2Fseq-rerun-leaky-generalizations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 197, "htmlBody": "<p>Today's post, <a href=\"/lw/lc/leaky_generalizations/\">Leaky Generalizations</a> was originally published on 22 November 2007.  A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries#Leaky_Generalizations\">LW wiki</a>):</p>\n<p>&nbsp;</p>\n<blockquote>The words and statements that we use are inherently \"leaky\", they do not precisely convey absolute and perfect information. Most humans have ten fingers, but if you know that someone is a human, you cannot confirm (with probability 1) that they have ten fingers. The same holds with planning and ethical advice.</blockquote>\n<p><br />Discuss the post here (rather than in the comments to the original post).<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.  The previous post was <a href=\"/lw/8at/seq_rerun_not_for_the_sake_of_happiness_alone/\">Not for the Sake of Happiness (Alone)</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> or <a href=\"/r/discussion/tag/sequence_reruns/.rss\">rss feed</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.  You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go <a href=\"/r/discussion/lw/5as/introduction_to_the_sequence_reruns/\">here</a> for more details, or to have meta discussions about the Rerunning the Sequences series.</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2TAfmGBZeRjRDLiMc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 6, "extendedScore": null, "score": 7.941486516301122e-07, "legacy": true, "legacyId": "10774", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Tc2H9KbKRjuDJ3WSS", "exnET8DmenJTH2ALC", "m9PsRxu65FuL9c8xp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T09:14:43.364Z", "modifiedAt": null, "url": null, "title": "Selection Effects in estimates of Global Catastrophic Risk", "slug": "selection-effects-in-estimates-of-global-catastrophic-risk", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:34.069Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bentarm", "createdAt": "2009-03-05T17:59:17.163Z", "isAdmin": false, "displayName": "bentarm"}, "userId": "xdmTZWK4DzchxkyQC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oFgTAYLncbmvRvRrA/selection-effects-in-estimates-of-global-catastrophic-risk", "pageUrlRelative": "/posts/oFgTAYLncbmvRvRrA/selection-effects-in-estimates-of-global-catastrophic-risk", "linkUrl": "https://www.lesswrong.com/posts/oFgTAYLncbmvRvRrA/selection-effects-in-estimates-of-global-catastrophic-risk", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Selection%20Effects%20in%20estimates%20of%20Global%20Catastrophic%20Risk&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelection%20Effects%20in%20estimates%20of%20Global%20Catastrophic%20Risk%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFgTAYLncbmvRvRrA%2Fselection-effects-in-estimates-of-global-catastrophic-risk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Selection%20Effects%20in%20estimates%20of%20Global%20Catastrophic%20Risk%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFgTAYLncbmvRvRrA%2Fselection-effects-in-estimates-of-global-catastrophic-risk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoFgTAYLncbmvRvRrA%2Fselection-effects-in-estimates-of-global-catastrophic-risk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 223, "htmlBody": "<p>Here's a poser that occurred to us over the summer, and one that we couldn't really come up with any satisfactory solution to. The people who work at the Singularity Institute have a high estimate of the probability that an Unfriendly AI will destroy the world. People who work for&nbsp;<a href=\"http://nuclearrisk.org/\">http://nuclearrisk.org/</a>&nbsp;have a very high estimate of the probability that a nuclear war will destroy the world (by their estimates, if you are American and under 40, then nuclear war is the single most likely way in which you might die next year).&nbsp;</p>\n<p>It seems like there are good reasons to take these numbers seriously, because Eliezer is probably the world expert on AI risk, and Hellman is probably the world expert on nuclear risk. However, there's a problem - Eliezer is an expert on AI risk <em>because </em>he believes that AI risk is a bigger risk than nuclear war. Similarly, Hellman chose to study nuclear risks and not AI risk I <em>because </em>he had a higher than average estimate of the threat of nuclear war.&nbsp;</p>\n<p>It seems like it might be a good idea to know what the probability of each of these risks is. Is there a sensible way for these people to correct for the fact that the people studying these risks are those that have high estimate of them in the first place?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MAp6Ft8b3s7kJdrQ9": 1, "Rz5jb3cYHTSRmqNnN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oFgTAYLncbmvRvRrA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 32, "extendedScore": null, "score": 7.942477288488422e-07, "legacy": true, "legacyId": "9996", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 64, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T10:55:19.530Z", "modifiedAt": null, "url": null, "title": "Anthropic Decision Theory IV: Solving Selfish and Average-Utilitarian Sleeping Beauty", "slug": "anthropic-decision-theory-iv-solving-selfish-and-average", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:20.740Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LXHsiHahr2eFQ4Hsp/anthropic-decision-theory-iv-solving-selfish-and-average", "pageUrlRelative": "/posts/LXHsiHahr2eFQ4Hsp/anthropic-decision-theory-iv-solving-selfish-and-average", "linkUrl": "https://www.lesswrong.com/posts/LXHsiHahr2eFQ4Hsp/anthropic-decision-theory-iv-solving-selfish-and-average", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anthropic%20Decision%20Theory%20IV%3A%20Solving%20Selfish%20and%20Average-Utilitarian%20Sleeping%20Beauty&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnthropic%20Decision%20Theory%20IV%3A%20Solving%20Selfish%20and%20Average-Utilitarian%20Sleeping%20Beauty%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXHsiHahr2eFQ4Hsp%2Fanthropic-decision-theory-iv-solving-selfish-and-average%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anthropic%20Decision%20Theory%20IV%3A%20Solving%20Selfish%20and%20Average-Utilitarian%20Sleeping%20Beauty%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXHsiHahr2eFQ4Hsp%2Fanthropic-decision-theory-iv-solving-selfish-and-average", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLXHsiHahr2eFQ4Hsp%2Fanthropic-decision-theory-iv-solving-selfish-and-average", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1059, "htmlBody": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this, subsequent, and previous posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<p>In the previous <a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">post</a>, I looked at a decision problem when Sleeping Beauty was selfless or a (copy-)total utilitarian. Her behaviour was&nbsp;reminiscent&nbsp;of someone following SIA-type odds. Here I'll look at situations where her behaviour is SSA-like.</p>\n<h2><strong>Altruistic average utilitarian Sleeping Beauty</strong></h2>\n<p>In the incubator variant, consider the reasoning of an Outside/Total agent who is an average utilitarian (and there are no other agents in the universe apart from the Sleeping Beauties).</p>\n<p style=\"padding-left: 30px;\">\"If the various Sleeping Beauties decide to pay &pound;x for the coupon, they will make -&pound;x in the heads world. In the tails world, they will each make &pound;(1-x) each, so an average of &pound;(1-x). This give me an expected utility of &pound;0.5(-x+(1-x))= &pound;(0.5-x), so I would want them to buy the coupon for any price less than &pound;0.5.\"</p>\n<p>And this will then be the behaviour the agents will follow, by consistency. Thus they would be behaving as if they were following SSA odds, and putting equal probability on the heads versus tails world.<a id=\"more\"></a></p>\n<p>For a version of this that makes senses for the classical Sleeping Beauty problem, one could imagine that she to be awaknened a week after the experiment. Further imagine she would take her winnings and losses during the experiment in the form of chocolate, consumed immediatly. Then because of the amneia drug, she would only remember one instance of this in the tails world. Hence if she valued memory of pleasure, she would want to be average utilitarian towards the pleasures of her different versions, and would follow SSA odds.</p>\n<div><span style=\"font-size: 16px; font-weight: bold;\">Reference classes and copy-altruistic agents</span></div>\n<p>Standard SSA has a problem with reference classes. For instance, the larger the reference class becomes, the more the results of SSA in small situations become similar to SIA. The above setup mimics the effect: if there is a very large population of outsider individuals that Sleeping Beauty is altruistic towards, then the gains to two extra copies will tend to add, rather than average: if &Omega;&nbsp;is large, then 2x/(2+&Omega;) (averaged gain to two created agents each gaining x) is approximately twice x/(1+&Omega;) (averaged gain to one created agent gaining $x$), so she will behave more closely to SIA odds.</p>\n<p>This issue is not present for <em>copy-altruistic</em> average utilitarian Sleeping Beauties, as she doesn't care about any outsiders.</p>\n<h2>Selfish Sleeping Beauty</h2>\n<p>In all of the above example, the goals of one Sleeping Beauty were always in accordance with the goals of her copies or the past and future versions of herself. But what happens when this fails? What happens when the different versions are entirely selfish towards each other? Very easy to understand in the incubator variant (the different created copies feel no mutual loyalty), it can also be understood in the standard Sleeping Beauty problem if she is a hedonist with a high discount rates.</p>\n<p>Since the different copies do have different goals, the consistency axioms no longer apply. It seems that we cannot decide what the correct decision is in this case. There is, however, a tantalising similarity between this case and the altruistic average utilitarian Sleeping Beauty. The setups (including probabilities) are the same. By `setup' we mean the different worlds, their probabilities, the number of agents in each world, and the decisions faced by these agents. Similarly, the possible 'linked' decisions are the same. See <a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">future posts</a> for a proper definition of linked decisions; here it just means that all copies will have to make the same decision, being identical, so there is one universal 'buy coupon' or 'reject coupon'. And, given this linking, the utilities derived by the agents is the same for either outcome in the two cases.</p>\n<p>To see this, consider the selfish situation. Each Sleeping Beauty will make a single decision, whether to buy the coupon at the price offered. Not buying the coupon nets her &pound;0 in all worlds. Buying the coupon at price &pound;x nets her -&pound;x in the heads world, and &pound;(1-x) in the tails world. The linking is present but has no impact on these selfish agents: they don't care what the other copies decide.</p>\n<p>This is exactly the same for the altruistic average utilitarian Sleeping Beauties. In the heads world, buying the coupon at price &pound;x nets her -&pound;x worth of utility. In the tails world, it would net the current copy &pound;(1-x) worth of individual utility. Since the copies are identical (linked decision), this would happen twice in the tails world, but since she only cares about the average, this grants both copies only &pound;(1-x) worth of utility in total. The linking is present, and has an impact, but that impact is dissolved by the average utilitarianism of the copies.</p>\n<p>Thus the two situations have the same setup, the same possible linked decisions and the same utility outcomes for each possible linked decision. It would seem there is nothing relevant to decision theory that distinguishes these two cases. This gives us the last axiom:</p>\n<ul>\n<li>Isomorphic decisions:&nbsp;If two situations have the same setup, the same possible linked decisions and the same utility outcomes for each possible linked decision, and all agents are aware of these facts, then agents should make the same decisions in both situations.</li>\n</ul>\n<p>This axiom immediately solves the selfish Sleeping Beauty problem, implying that agents there must behave as they do in the altruistic average utilitarian Sleeping Beauty problem, namely paying up to &pound;0.50 for the coupon. In this way, the selfish agents also behave as if they were following SSA probabilities, and believed that heads and tails were equally likely.</p>\n<h2>Summary of results</h2>\n<p>We have broadly four categories of agents, and they follow two different types of decisions (SIA-like and SSA-like). In the Sleeping Beauty problem (and in more general problems), the categories decompose as:</p>\n<ol>\n<li>Selfless agents who will follow SIA-type odds.</li>\n<li>(Copy-)Altruistic total utilitarians who will follow SIA-type odds.</li>\n<li>(Copy-)Altruistic average utilitarians who will follow SSA-type odds.</li>\n<li>Selfish agents who will follow SSA-type odds.</li>\n</ol>\n<p>For the standard Sleeping Beauty problem, the first three decisions derived from consistency. The same result can be established for the incubator variants using the Outside/Total agent axioms. The selfish result, however, needs to make use of the Isomorphic decisions axiom.</p>\n<p><strong>EDIT</strong>: A good&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/564l\">question</a>&nbsp;from Wei Dai illustrates the issue of precommitment for selfish agents.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2, "NZB24aR9uHmDc5GcT": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LXHsiHahr2eFQ4Hsp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 7.942828875958784e-07, "legacy": true, "legacyId": "10760", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "kmryZRz5r9bjsug9e", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "anthropic-decision-theory-v-linking-and-adt", "canonicalPrevPostSlug": "anthropic-decision-theory-iii-solving-selfless-and-total", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>A near-final version of my Anthropic Decision Theory&nbsp;<a href=\"http://arxiv.org/abs/1110.6437\">paper</a>&nbsp;is available on the arXiv. Since anthropics problems have been discussed quite a bit on this list, I'll be presenting its arguments and results in this, subsequent, and previous posts&nbsp;<a href=\"/r/discussion/lw/891/anthropic_decision_theory_i_sleeping_beauty_and/\">1</a>&nbsp;<a href=\"/r/discussion/lw/892/anthropic_decision_theory_ii_selfindication/\">2</a>&nbsp;<a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">3</a>&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/\">4</a>&nbsp;<a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">5</a>&nbsp;<a href=\"/lw/8bw/anthropic_decision_theory_vi_applying_adt_to/\">6</a>.</p>\n<p>In the previous <a href=\"/r/discussion/lw/89q/anthropic_decision_theory_iii_solving_selfless/\">post</a>, I looked at a decision problem when Sleeping Beauty was selfless or a (copy-)total utilitarian. Her behaviour was&nbsp;reminiscent&nbsp;of someone following SIA-type odds. Here I'll look at situations where her behaviour is SSA-like.</p>\n<h2 id=\"Altruistic_average_utilitarian_Sleeping_Beauty\"><strong>Altruistic average utilitarian Sleeping Beauty</strong></h2>\n<p>In the incubator variant, consider the reasoning of an Outside/Total agent who is an average utilitarian (and there are no other agents in the universe apart from the Sleeping Beauties).</p>\n<p style=\"padding-left: 30px;\">\"If the various Sleeping Beauties decide to pay \u00a3x for the coupon, they will make -\u00a3x in the heads world. In the tails world, they will each make \u00a3(1-x) each, so an average of \u00a3(1-x). This give me an expected utility of \u00a30.5(-x+(1-x))= \u00a3(0.5-x), so I would want them to buy the coupon for any price less than \u00a30.5.\"</p>\n<p>And this will then be the behaviour the agents will follow, by consistency. Thus they would be behaving as if they were following SSA odds, and putting equal probability on the heads versus tails world.<a id=\"more\"></a></p>\n<p>For a version of this that makes senses for the classical Sleeping Beauty problem, one could imagine that she to be awaknened a week after the experiment. Further imagine she would take her winnings and losses during the experiment in the form of chocolate, consumed immediatly. Then because of the amneia drug, she would only remember one instance of this in the tails world. Hence if she valued memory of pleasure, she would want to be average utilitarian towards the pleasures of her different versions, and would follow SSA odds.</p>\n<div><span style=\"font-size: 16px; font-weight: bold;\">Reference classes and copy-altruistic agents</span></div>\n<p>Standard SSA has a problem with reference classes. For instance, the larger the reference class becomes, the more the results of SSA in small situations become similar to SIA. The above setup mimics the effect: if there is a very large population of outsider individuals that Sleeping Beauty is altruistic towards, then the gains to two extra copies will tend to add, rather than average: if \u03a9&nbsp;is large, then 2x/(2+\u03a9) (averaged gain to two created agents each gaining x) is approximately twice x/(1+\u03a9) (averaged gain to one created agent gaining $x$), so she will behave more closely to SIA odds.</p>\n<p>This issue is not present for <em>copy-altruistic</em> average utilitarian Sleeping Beauties, as she doesn't care about any outsiders.</p>\n<h2 id=\"Selfish_Sleeping_Beauty\">Selfish Sleeping Beauty</h2>\n<p>In all of the above example, the goals of one Sleeping Beauty were always in accordance with the goals of her copies or the past and future versions of herself. But what happens when this fails? What happens when the different versions are entirely selfish towards each other? Very easy to understand in the incubator variant (the different created copies feel no mutual loyalty), it can also be understood in the standard Sleeping Beauty problem if she is a hedonist with a high discount rates.</p>\n<p>Since the different copies do have different goals, the consistency axioms no longer apply. It seems that we cannot decide what the correct decision is in this case. There is, however, a tantalising similarity between this case and the altruistic average utilitarian Sleeping Beauty. The setups (including probabilities) are the same. By `setup' we mean the different worlds, their probabilities, the number of agents in each world, and the decisions faced by these agents. Similarly, the possible 'linked' decisions are the same. See <a href=\"/r/discussion/lw/8be/anthropic_decision_theory_v_linking_and_adt/\">future posts</a> for a proper definition of linked decisions; here it just means that all copies will have to make the same decision, being identical, so there is one universal 'buy coupon' or 'reject coupon'. And, given this linking, the utilities derived by the agents is the same for either outcome in the two cases.</p>\n<p>To see this, consider the selfish situation. Each Sleeping Beauty will make a single decision, whether to buy the coupon at the price offered. Not buying the coupon nets her \u00a30 in all worlds. Buying the coupon at price \u00a3x nets her -\u00a3x in the heads world, and \u00a3(1-x) in the tails world. The linking is present but has no impact on these selfish agents: they don't care what the other copies decide.</p>\n<p>This is exactly the same for the altruistic average utilitarian Sleeping Beauties. In the heads world, buying the coupon at price \u00a3x nets her -\u00a3x worth of utility. In the tails world, it would net the current copy \u00a3(1-x) worth of individual utility. Since the copies are identical (linked decision), this would happen twice in the tails world, but since she only cares about the average, this grants both copies only \u00a3(1-x) worth of utility in total. The linking is present, and has an impact, but that impact is dissolved by the average utilitarianism of the copies.</p>\n<p>Thus the two situations have the same setup, the same possible linked decisions and the same utility outcomes for each possible linked decision. It would seem there is nothing relevant to decision theory that distinguishes these two cases. This gives us the last axiom:</p>\n<ul>\n<li>Isomorphic decisions:&nbsp;If two situations have the same setup, the same possible linked decisions and the same utility outcomes for each possible linked decision, and all agents are aware of these facts, then agents should make the same decisions in both situations.</li>\n</ul>\n<p>This axiom immediately solves the selfish Sleeping Beauty problem, implying that agents there must behave as they do in the altruistic average utilitarian Sleeping Beauty problem, namely paying up to \u00a30.50 for the coupon. In this way, the selfish agents also behave as if they were following SSA probabilities, and believed that heads and tails were equally likely.</p>\n<h2 id=\"Summary_of_results\">Summary of results</h2>\n<p>We have broadly four categories of agents, and they follow two different types of decisions (SIA-like and SSA-like). In the Sleeping Beauty problem (and in more general problems), the categories decompose as:</p>\n<ol>\n<li>Selfless agents who will follow SIA-type odds.</li>\n<li>(Copy-)Altruistic total utilitarians who will follow SIA-type odds.</li>\n<li>(Copy-)Altruistic average utilitarians who will follow SSA-type odds.</li>\n<li>Selfish agents who will follow SSA-type odds.</li>\n</ol>\n<p>For the standard Sleeping Beauty problem, the first three decisions derived from consistency. The same result can be established for the incubator variants using the Outside/Total agent axioms. The selfish result, however, needs to make use of the Isomorphic decisions axiom.</p>\n<p><strong>EDIT</strong>: A good&nbsp;<a href=\"/r/discussion/lw/8aw/anthropic_decision_theory_iv_solving_selfish_and/564l\">question</a>&nbsp;from Wei Dai illustrates the issue of precommitment for selfish agents.</p>", "sections": [{"title": "Altruistic average utilitarian Sleeping Beauty", "anchor": "Altruistic_average_utilitarian_Sleeping_Beauty", "level": 1}, {"title": "Selfish Sleeping Beauty", "anchor": "Selfish_Sleeping_Beauty", "level": 1}, {"title": "Summary of results", "anchor": "Summary_of_results", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "24 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["svhbnSdxW3XmFXXTK", "G9scbpNrCxfJZQmYu", "zqm2nTqjAKg6EyxE3", "LXHsiHahr2eFQ4Hsp", "wQd3rLLLNWYRgjaYg", "NpPEJT2CCKjeo59Ps"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T13:18:15.749Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups: Austin, Houston, Fort Collins, Melbourne, Canberra, Zurich", "slug": "weekly-lw-meetups-austin-houston-fort-collins-melbourne", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:06.513Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i6a2m3LtsfWdegZ8s/weekly-lw-meetups-austin-houston-fort-collins-melbourne", "pageUrlRelative": "/posts/i6a2m3LtsfWdegZ8s/weekly-lw-meetups-austin-houston-fort-collins-melbourne", "linkUrl": "https://www.lesswrong.com/posts/i6a2m3LtsfWdegZ8s/weekly-lw-meetups-austin-houston-fort-collins-melbourne", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups%3A%20Austin%2C%20Houston%2C%20Fort%20Collins%2C%20Melbourne%2C%20Canberra%2C%20Zurich&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%3A%20Austin%2C%20Houston%2C%20Fort%20Collins%2C%20Melbourne%2C%20Canberra%2C%20Zurich%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi6a2m3LtsfWdegZ8s%2Fweekly-lw-meetups-austin-houston-fort-collins-melbourne%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%3A%20Austin%2C%20Houston%2C%20Fort%20Collins%2C%20Melbourne%2C%20Canberra%2C%20Zurich%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi6a2m3LtsfWdegZ8s%2Fweekly-lw-meetups-austin-houston-fort-collins-melbourne", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi6a2m3LtsfWdegZ8s%2Fweekly-lw-meetups-austin-houston-fort-collins-melbourne", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 340, "htmlBody": "<p>There are upcoming irregularly scheduled Less Wrong meetups in:</p>\n<ul>\n<li><a href=\"/meetups/4g\">Houston Meetup:&nbsp;<span class=\"date\">30 October 2011 02:00PM</span></a></li>\n<li><a href=\"/meetups/4i\">Fort Collins, Colorado Meetup Wednesday 7pm:&nbsp;<span class=\"date\">02 November 2011 07:00PM</span></a></li>\n<li><a href=\"/meetups/4e\">Melbourne practical rationality meetup:&nbsp;<span class=\"date\">04 November 2011 07:00PM</span></a></li>\n<li><a href=\"/meetups/4a\">Canberra Meetup Saturday November 5th:&nbsp;<span class=\"date\">05 November 2011 11:00AM</span></a></li>\n<li><a href=\"/meetups/4h\">First Zurich LW Meetup:&nbsp;<span class=\"date\">12 November 2011 03:00PM</span></a></li>\n</ul>\n<p>The following meetups take place in cities with regularly scheduled meetups, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/4j\">Austin, TX:&nbsp;<span class=\"date\">29 October 2011 01:30PM</span></a></li>\n</ul>\n<p>Cities with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>,</strong><strong> <a href=\"/r/discussion/lw/5pd/southern_california_meetup_may_21_weekly_irvine\">Irvine</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin, CA</a> </strong>(uses the Bay Area List)<strong>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Oxford.2C_UK\">Oxford</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#San_Francisco\">San Francisco</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>, and <strong><a href=\"/r/discussion/lw/6at/west_la_biweekly_meetups\">West Los Angeles</a></strong>.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>Despite the handy sidebar of upcoming meetups, we've decided to continue posting an overview of upcoming meetups on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening:<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison, WI</a></strong>,<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a></strong><strong>.</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i6a2m3LtsfWdegZ8s", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 7.943328460702006e-07, "legacy": true, "legacyId": "10666", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pAHo9zSFXygp5A5dL", "tHFu6kvy2HMvQBEhW", "d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T13:28:30.778Z", "modifiedAt": null, "url": null, "title": "FHI Essay Competition", "slug": "fhi-essay-competition", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:09.241Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Gedusa", "createdAt": "2011-05-15T18:08:02.729Z", "isAdmin": false, "displayName": "Gedusa"}, "userId": "668TNpjNJh2nwwMs7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bZJ9QcCMX7FW5GArb/fhi-essay-competition", "pageUrlRelative": "/posts/bZJ9QcCMX7FW5GArb/fhi-essay-competition", "linkUrl": "https://www.lesswrong.com/posts/bZJ9QcCMX7FW5GArb/fhi-essay-competition", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20FHI%20Essay%20Competition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFHI%20Essay%20Competition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbZJ9QcCMX7FW5GArb%2Ffhi-essay-competition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=FHI%20Essay%20Competition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbZJ9QcCMX7FW5GArb%2Ffhi-essay-competition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbZJ9QcCMX7FW5GArb%2Ffhi-essay-competition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 202, "htmlBody": "<p><a href=\"http://www.fhi.ox.ac.uk/prize\">This competition</a> is only open to philosophy students.</p>\n<blockquote>\n<p style=\"text-align: left;\">Can philosophical research contribute to securing a long and prosperous future for humanity and its descendants?</p>\n<p style=\"text-align: left;\">What would you think about if you really wanted to make a difference?</p>\n<p style=\"text-align: left;\">Crucial considerations are questions or ideas that could decisively change your entire approach to an issue. What are the crucial considerations for humanity&rsquo;s future? These could range from deep questions about population ethics to world government, the creation of greater than human intelligence, or the risks of human extinction.</p>\n<p>The Future of Humanity Institute at Oxford University wants to get young philosophers thinking about these big questions. We know that choosing a PhD thesis topic is one of the big choices affecting the direction of your career, and so deserves a great deal of thought. To encourage this, we are running a slightly unusual prize competition. The format is a two page &lsquo;thesis proposal&rsquo; consisting of a 300 word abstract and an outline plan of a thesis regarding a crucial consideration for humanity&rsquo;s future. We will publish the best abstracts on our website and give a prize of &pound;2,000 to the author of the proposal we deem the most promising or original.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb354": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bZJ9QcCMX7FW5GArb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 7.943364289665193e-07, "legacy": true, "legacyId": "10779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T14:39:59.939Z", "modifiedAt": null, "url": null, "title": "Meetup : Paris, Sunday November 13", "slug": "meetup-paris-sunday-november-13", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:26.308Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ddm8jA7qvxozF7KeL/meetup-paris-sunday-november-13", "pageUrlRelative": "/posts/Ddm8jA7qvxozF7KeL/meetup-paris-sunday-november-13", "linkUrl": "https://www.lesswrong.com/posts/Ddm8jA7qvxozF7KeL/meetup-paris-sunday-november-13", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Paris%2C%20Sunday%20November%2013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Paris%2C%20Sunday%20November%2013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDdm8jA7qvxozF7KeL%2Fmeetup-paris-sunday-november-13%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Paris%2C%20Sunday%20November%2013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDdm8jA7qvxozF7KeL%2Fmeetup-paris-sunday-november-13", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDdm8jA7qvxozF7KeL%2Fmeetup-paris-sunday-november-13", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 90, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4l'>Paris, Sunday November 13</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 November 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 des Arts et M\u00e9tiers\u200e, 51 Rue Turbigo, Paris</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Paris Meetup will be Sunday, November 13, at the Caf\u00e9 des Arts et M\u00e9tiers opposite the Museum (and not in the Caf\u00e9 that's <em>inside</em> the Museum, like last time, because on Sundays you can't get to it without a Museum ticket).</p>\n\n<p>There should be at least Morendil, kilobug and me - and maybe <em>you</em> too!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4l'>Paris, Sunday November 13</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ddm8jA7qvxozF7KeL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 7.943614166109116e-07, "legacy": true, "legacyId": "10781", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Paris__Sunday_November_13\">Discussion article for the meetup : <a href=\"/meetups/4l\">Paris, Sunday November 13</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 November 2011 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 des Arts et M\u00e9tiers\u200e, 51 Rue Turbigo, Paris</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Paris Meetup will be Sunday, November 13, at the Caf\u00e9 des Arts et M\u00e9tiers opposite the Museum (and not in the Caf\u00e9 that's <em>inside</em> the Museum, like last time, because on Sundays you can't get to it without a Museum ticket).</p>\n\n<p>There should be at least Morendil, kilobug and me - and maybe <em>you</em> too!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Paris__Sunday_November_131\">Discussion article for the meetup : <a href=\"/meetups/4l\">Paris, Sunday November 13</a></h2>", "sections": [{"title": "Discussion article for the meetup : Paris, Sunday November 13", "anchor": "Discussion_article_for_the_meetup___Paris__Sunday_November_13", "level": 1}, {"title": "Discussion article for the meetup : Paris, Sunday November 13", "anchor": "Discussion_article_for_the_meetup___Paris__Sunday_November_131", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-11-04T16:18:56.993Z", "modifiedAt": null, "url": null, "title": "Meetup : Madison Monday Meetup", "slug": "meetup-madison-monday-meetup-4", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fiddlemath", "createdAt": "2010-04-19T03:50:34.425Z", "isAdmin": false, "displayName": "fiddlemath"}, "userId": "5F5aTS6F8642KxHLK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vZB5N3kMf256awCu4/meetup-madison-monday-meetup-4", "pageUrlRelative": "/posts/vZB5N3kMf256awCu4/meetup-madison-monday-meetup-4", "linkUrl": "https://www.lesswrong.com/posts/vZB5N3kMf256awCu4/meetup-madison-monday-meetup-4", "postedAtFormatted": "Friday, November 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Madison%20Monday%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Madison%20Monday%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvZB5N3kMf256awCu4%2Fmeetup-madison-monday-meetup-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Madison%20Monday%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvZB5N3kMf256awCu4%2Fmeetup-madison-monday-meetup-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvZB5N3kMf256awCu4%2Fmeetup-madison-monday-meetup-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/4m'>Madison Monday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 November 2011 08:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">1831 Monroe St., Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Along with the usual likely discussions and likely games, I'll run some exercises on group estimation and <a href=\"http://en.wikipedia.org/wiki/Fermi_problem\" rel=\"nofollow\">Fermi calculations</a>, and then we'll play a few rounds of <a href=\"http://wiki.lesswrong.com/wiki/Paranoid_debating\">Paranoid Debating</a>.</p>\n\n<p>eta: And, if you're in Madison and haven't already, be sure to sign up for the Madison <a href=\"https://groups.google.com/forum/#!forum/lesswrong-madison\">mailing list</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/4m'>Madison Monday Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vZB5N3kMf256awCu4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.943960067863185e-07, "legacy": true, "legacyId": "10782", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Madison_Monday_Meetup\">Discussion article for the meetup : <a href=\"/meetups/4m\">Madison Monday Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 November 2011 08:00:00PM (-0500)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">1831 Monroe St., Madison, WI</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Along with the usual likely discussions and likely games, I'll run some exercises on group estimation and <a href=\"http://en.wikipedia.org/wiki/Fermi_problem\" rel=\"nofollow\">Fermi calculations</a>, and then we'll play a few rounds of <a href=\"http://wiki.lesswrong.com/wiki/Paranoid_debating\">Paranoid Debating</a>.</p>\n\n<p>eta: And, if you're in Madison and haven't already, be sure to sign up for the Madison <a href=\"https://groups.google.com/forum/#!forum/lesswrong-madison\">mailing list</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Madison_Monday_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/4m\">Madison Monday Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Madison Monday Meetup", "anchor": "Discussion_article_for_the_meetup___Madison_Monday_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Madison Monday Meetup", "anchor": "Discussion_article_for_the_meetup___Madison_Monday_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}