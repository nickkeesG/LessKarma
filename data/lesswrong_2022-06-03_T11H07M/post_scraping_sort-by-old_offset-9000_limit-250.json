{"results": [{"createdAt": null, "postedAt": "2013-05-25T04:12:37.939Z", "modifiedAt": null, "url": null, "title": "Mathematicians and the Prevention of Recessions", "slug": "mathematicians-and-the-prevention-of-recessions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:08.527Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CbsYTQS8YNEWTWdM3/mathematicians-and-the-prevention-of-recessions", "pageUrlRelative": "/posts/CbsYTQS8YNEWTWdM3/mathematicians-and-the-prevention-of-recessions", "linkUrl": "https://www.lesswrong.com/posts/CbsYTQS8YNEWTWdM3/mathematicians-and-the-prevention-of-recessions", "postedAtFormatted": "Saturday, May 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mathematicians%20and%20the%20Prevention%20of%20Recessions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMathematicians%20and%20the%20Prevention%20of%20Recessions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCbsYTQS8YNEWTWdM3%2Fmathematicians-and-the-prevention-of-recessions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mathematicians%20and%20the%20Prevention%20of%20Recessions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCbsYTQS8YNEWTWdM3%2Fmathematicians-and-the-prevention-of-recessions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCbsYTQS8YNEWTWdM3%2Fmathematicians-and-the-prevention-of-recessions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1490, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>86</o:Words> <o:Characters>492</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>4</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>577</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I completed a PhD in Mathematics from University of Illinois under the direction of Nathan Dunfield in 2011. I worked as a research analyst at GiveWell from April 2012 to May 2013. All views expressed here are my own.</p>\n<p class=\"MsoNormal\"><strong>About this post:</strong> I've long been interested in ways in which mathematicians can contribute high social value. In this post, I discuss a tentative idea along these lines. My thoughts are very preliminary in nature, and my intent in making this post is to provide a launching point for further exploration of the subject, rather than to persuade.</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>7</o:Words> <o:Characters>43</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>49</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Recessions as a serious threat to global welfare</span></strong></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>36</o:Words> <o:Characters>209</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>244</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">In 2008, the <a href=\"http://en.wikipedia.org/wiki/United_States_housing_bubble\">US housing bubble</a> popped, precipitating the <a href=\"http://en.wikipedia.org/wiki/Great_Recession\">Great Recession</a>. The costs of this were staggering:</p>\n<ul>\n<li>It&rsquo;s been claimed that the cost to US taxpayers in bank bailouts was&nbsp;<a href=\"http://money.cnn.com/2010/12/01/news/economy/fed_reserve_data_release/index.htm\">$9 trillion</a>.</li>\n<li>The Dow Jones Industrial Average&nbsp;<a href=\"http://www.macrotrends.net/1358/dow-jones-industrial-average-last-10-years\">dropped by almost 50%</a>&nbsp;and took over 4 years to recover.</li>\n<li>US unemployment&nbsp;<a href=\"https://www.google.com/publicdata/explore?ds=z1ebjpgk2654c1_&amp;ctype=l&amp;strail=false&amp;bcs=d&amp;nselm=h&amp;met_y=unemployment_rate&amp;fdim_y=seasonality:S&amp;scale_y=lin&amp;ind_y=false&amp;rdim=country&amp;idim=country:US&amp;ifdim=country&amp;tstart=937983600000&amp;tend=1366614000000&amp;hl=en&amp;dl=en&amp;ind=false\">jumped from ~5% to ~10%</a>, and has only gradually been declining.</li>\n<li>Budget cuts were especially great for government support of activities with unusually high humanitarian value to those without political constituency, such as investment in global health.</li>\n<li>\n<p class=\"MsoNormal\">It&rsquo;s been claimed that&nbsp;<a href=\"http://www.amazon.com/Moral-Consequences-Economic-Growth/dp/1400095719\">recessions cause a drop in prosocial behavior</a>.</p>\n</li>\n</ul>\n<div><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>263</o:Words> <o:Characters>1500</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>12</o:Lines> <o:Paragraphs>3</o:Paragraphs> <o:CharactersWithSpaces>1760</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\">All told, the Great Recession had massive negative humanitarian disvalue, and preventing another such recession would have massive humanitarian value.<br /> <!--[endif]--></p>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Transparent financial analysis as a possible solution</span></strong></p>\n<p class=\"MsoNormal\">There are actors in finance who accurately predicted that there was a housing bubble that was on the brink of popping, and who bet heavily against subprime mortgages, reaping enormous profits as a result. The most prominent example is <a href=\"http://en.wikipedia.org/wiki/John_Paulson\">John Paulson</a>, who made $3.7 billion in a 2007 alone, starting from a base of less than $1 billion. There are less extreme examples that are nevertheless very striking.&nbsp;</p>\n<p class=\"MsoNormal\">It&rsquo;s difficult to determine the relative roles that skill and luck played in these peoples&rsquo; success, and the situation is further obscured by <a href=\"http://en.wikipedia.org/wiki/Hindsight_bias\">hindsight bias</a>. Nevertheless, it seems possible that the financial success of Paulson and others was a consequence of careful analysis and shrewdness, and that other people of sufficiently high intellectual caliber and rationality would have been able to predict it as well.</p>\n<p class=\"MsoNormal\">As is always the case in finance, those who recognized the impending pop of the housing bubble kept their analysis secret, because sharing it would have allowed others to partially close the arbitrage opportunity, reducing the potential to profit. If these people had made their thinking public, <em>it could have resulted in <strong>other</strong> people betting against the housing bubble earlier on</em>, popped the housing bubble when it was smaller, possibly substantially lessening the severity of the ensuing recession. While there were people who publicly voiced concern, a large number of people would have had a bigger impact</p>\n<p class=\"MsoNormal\">This suggests that transparent financial analysis by intellectual elites could carry massive humanitarian value.&nbsp;</p>\n</div>\n<div>\n<p class=\"MsoNormal\"><strong><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Mathematicians as unusually well positioned to perform such analysis</span></strong></p>\n<p class=\"MsoNormal\">In the course of my graduate school days, I became familiar with mathematical community. There&rsquo;s a wide cultural gulf between pure math and finance. My experience was that mathematicians generally view finance as &ldquo;dirty business,&rdquo; on account of:</p>\n</div>\n<div>\n<ul>\n<li>Often having left-wing political beliefs</li>\n<li>Discomfort with the zero-sum and/or negative-sum nature of finance</li>\n<li>Not identifying with materialism</li>\n<li>Disliking messy problems that are less intrinsically interesting than problems in pure math.</li>\n</ul>\n<div><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>95</o:Words> <o:Characters>548</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>4</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>642</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\">I believe that this gulf has led to a potential opportunity being overlooked: <em>mathematicians may be ideally suited to perform transparent financial analysis that reduces damage from financial bubbles</em>.</p>\n<p class=\"MsoNormal\">This idea occurred to me a few weeks ago. Ideas for philanthropic interventions generally fall apart upon closer examination, and so I wasn&rsquo;t too optimistic about it holding up. So I was surprised when <a href=\"http://en.wikipedia.org/wiki/Neal_Koblitz\">Neal Koblitz</a> (co-creator of <a href=\"http://en.wikipedia.org/wiki/Elliptic_curve_cryptography\">elliptic curve cryptography</a>) raised the same idea in unrelated correspondence:</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>73</o:Words> <o:Characters>422</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>3</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>494</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">If mathematicians had been noticing the dubious ways that people in the financial world were claiming to be applying mathematics, and if they had publicly and loudly criticized the misuse of mathematics, then the world might have been spared the collapse of 2008 (or, rather, it wouldn't have been as bad). If mathematicians could have played a role stopping the credit-derivatives bubble before it got out of hand, the economic value of doing that would have been in the trillions of dollars.</p>\n<!--EndFragment--></div>\n</div>\n<!--[if !supportLineBreakNewLine]--> <!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>20</o:Words> <o:Characters>116</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>135</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} -->\n<p>When an idea occurs to two people independently, the case for it being a good idea is strengthened. Moreover, Koblitz has <a href=\"http://www.amazon.com/Random-Curves-Mathematician-Neal-Koblitz/dp/3540740775/ref=la_B000APHL8Y_1_4?ie=UTF8&amp;qid=1369329138&amp;sr=1-4\">a long history of involvement with humanitarian efforts</a> and so can be expected to have perspective on them.&nbsp;</p>\n<p class=\"MsoNormal\">Some reasons why mathematicians seem unusually well suited to the task are:</p>\n<p class=\"MsoNormal\"><strong>Transferable Skills</strong> &mdash;&nbsp;Most mathematicians are unfamiliar with some of most important tools used in finance: statistics, data analysis &amp; programming. But there&rsquo;s a historical track record of mathematicians being able to pick up these skills and use them to powerful effect. <a href=\"http://en.wikipedia.org/wiki/James_Harris_Simons\">James Simons</a> transitioned from differential geometry to quantitative finance, and became one of the most successful hedge fund managers ever. <a href=\"http://mathbabe.org/\">Cathy O&rsquo;Neil</a> did a PhD in algebraic number theory under Barry Mazur&rsquo;s direction, and got a job at <a href=\"http://en.wikipedia.org/wiki/D._E._Shaw_%26_Co.\">DE Shaw</a>, which is one of the most prestigious hedge funds. Mathematicians who are motivated to learn these skills are well positioned to do so.</p>\n<p class=\"MsoNormal\">There are other skills that are very important for successful financial analysis &ndash;&nbsp;in particular, one has to have a good eye for empirical data. This is a skill that&rsquo;s not directly transferable, but it still seems likely that a nontrivial fraction of mathematicians could develop high facility with it.</p>\n<!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\"><strong>Intellectual Caliber</strong> &mdash;&nbsp;The mathematics community has a very dense concentration of intellectual power. &nbsp;James Simons offers a direct point of comparison between math and finance:</p>\n<p class=\"MsoNormal\">Simons won the <a href=\"http://en.wikipedia.org/wiki/Oswald_Veblen_Prize_in_Geometry\">Oswald Veblan Prize in Geometry</a> before leaving academia to start <a href=\"http://en.wikipedia.org/wiki/Renaissance_Technologies\">Renaissance Technologies</a>. There are 25 living mathematicians who have won this prize. The prize is awarded exclusively for work in geometry/topology, and if one looks more broadly at all mathematical fields, one can generate a list of about 100 living mathematicians who were at least as accomplished as Simons at the same age.</p>\n<p class=\"MsoNormal\">&nbsp;After leaving academia, Simons made $10 billion in quantitative finance. What I find most interesting about this is that the situation is not that Simons succeeded where other mathematicians of the same caliber had failed&nbsp;&ndash;&nbsp;rather, <em>Simons is virtually the only pure mathematician of his caliber to have left academia</em>. This raises the possibility that there are a handful of elite mathematicians who could make much better financial predictions than most present day actors in finance. Less accomplished but capable mathematicians may also do very well.</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>64</o:Words> <o:Characters>370</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>3</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>433</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Cautiousness</strong> &mdash;&nbsp;Mathematicians are naturally intellectually conservative, as they spend much of their time rigorously examining arguments for flaws. Thus, they&rsquo;re unusually unlikely to succumb to <a href=\"http://en.wikipedia.org/wiki/Greed_and_fear\">greed and fear</a>, which are factors that are thought to play a large role in the behavior of financial markets, and which lead to speculative bubbles. This is corroborated by some of Cathy O&rsquo;Neil&rsquo;s remarks on finance.</p>\n<!--EndFragment-->\n<p><strong><span style=\"font-size: 14.0pt; mso-bidi-font-size: 12.0pt;\">Implications</span></strong></p>\n<p class=\"MsoNormal\">The above considerations suggest that mathematicians could contribute <em>enormous social value</em> by engaging in transparent financial analysis.&nbsp;</p>\n<p class=\"MsoNormal\">Many mathematicians who I know wish that they could contribute more social value. In the essay&nbsp;<a href=\"http://publications.ias.edu/sites/default/files/ND.pdf\">Is there beauty in mathematical theories?</a>, the great mathematician Robert Langlands wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">In a letter to A.-M.Legendre of 1830, which I came across while preparing this lecture, Jacobi famously wrote</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em>It is true that Mr. Fourier thought that the principal goal of mathematics was their public utility and their use in explaining natural phenomena. A philosopher like him should have known that the only goal of Science is the honor of the human spirit, and that as such, a question in number theory is worth a question concerning the system of the world.</em></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em></em>I am not sure it is so easy. I have given a great deal of my life to matters closely related to the theory of numbers, but the honor of the human spirit is, perhaps, too doubtful and too suspect a notion to serve as vindication. [&hellip;] Moreover, the appeal to the common welfare as a goal of mathematics is, if not then at least now, often abusive. So it is not easy to \ufb01nd an apology for a life in mathematics.</p>\n<!--EndFragment-->\n<p style=\"padding-left: 30px;\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>82</o:Words> <o:Characters>474</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>3</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>555</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">A fair number of mathematicians <em>don&rsquo;t have any choice but to do pure math</em>. Gromov wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">You become a mathematician, a slave of this insatiable hunger of your brain, of everybody's brain, for making structures of everything that goes into it.</p>\n<p class=\"MsoNormal\">I'm very sympathetic to Gromov's remark, and I think that for people who constituted in this way, it&rsquo;s probably best not to try to suppress these urges, as such attempts tend to be unsustainable and <a href=\"/lw/38u/best_career_models_for_doing_research/33et\">result in lower contributions to global welfare rather than higher ones</a>.</p>\n<!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\">But for mathematicians who are:</p>\n<ul>\n<li>Tenured professors who don&rsquo;t have to worry about career considerations&nbsp;</li>\n<li>Able to enjoy financial analysis</li>\n<li>Strongly motivated to do an excellent job</li>\n</ul>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>26</o:Words> <o:Characters>153</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>178</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">there may be a major opportunity to contribute enormous social value by conducting transparent high quality financial analysis.</p>\n<p class=\"MsoNormal\">This question warrants further investigation.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CbsYTQS8YNEWTWdM3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 15, "extendedScore": null, "score": 4.4e-05, "legacy": true, "legacyId": "22708", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>86</o:Words> <o:Characters>492</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>4</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>577</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I completed a PhD in Mathematics from University of Illinois under the direction of Nathan Dunfield in 2011. I worked as a research analyst at GiveWell from April 2012 to May 2013. All views expressed here are my own.</p>\n<p class=\"MsoNormal\"><strong>About this post:</strong> I've long been interested in ways in which mathematicians can contribute high social value. In this post, I discuss a tentative idea along these lines. My thoughts are very preliminary in nature, and my intent in making this post is to provide a launching point for further exploration of the subject, rather than to persuade.</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>7</o:Words> <o:Characters>43</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>49</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong id=\"Recessions_as_a_serious_threat_to_global_welfare\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Recessions as a serious threat to global welfare</span></strong></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>36</o:Words> <o:Characters>209</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>244</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">In 2008, the <a href=\"http://en.wikipedia.org/wiki/United_States_housing_bubble\">US housing bubble</a> popped, precipitating the <a href=\"http://en.wikipedia.org/wiki/Great_Recession\">Great Recession</a>. The costs of this were staggering:</p>\n<ul>\n<li>It\u2019s been claimed that the cost to US taxpayers in bank bailouts was&nbsp;<a href=\"http://money.cnn.com/2010/12/01/news/economy/fed_reserve_data_release/index.htm\">$9 trillion</a>.</li>\n<li>The Dow Jones Industrial Average&nbsp;<a href=\"http://www.macrotrends.net/1358/dow-jones-industrial-average-last-10-years\">dropped by almost 50%</a>&nbsp;and took over 4 years to recover.</li>\n<li>US unemployment&nbsp;<a href=\"https://www.google.com/publicdata/explore?ds=z1ebjpgk2654c1_&amp;ctype=l&amp;strail=false&amp;bcs=d&amp;nselm=h&amp;met_y=unemployment_rate&amp;fdim_y=seasonality:S&amp;scale_y=lin&amp;ind_y=false&amp;rdim=country&amp;idim=country:US&amp;ifdim=country&amp;tstart=937983600000&amp;tend=1366614000000&amp;hl=en&amp;dl=en&amp;ind=false\">jumped from ~5% to ~10%</a>, and has only gradually been declining.</li>\n<li>Budget cuts were especially great for government support of activities with unusually high humanitarian value to those without political constituency, such as investment in global health.</li>\n<li>\n<p class=\"MsoNormal\">It\u2019s been claimed that&nbsp;<a href=\"http://www.amazon.com/Moral-Consequences-Economic-Growth/dp/1400095719\">recessions cause a drop in prosocial behavior</a>.</p>\n</li>\n</ul>\n<div><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>263</o:Words> <o:Characters>1500</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>12</o:Lines> <o:Paragraphs>3</o:Paragraphs> <o:CharactersWithSpaces>1760</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\">All told, the Great Recession had massive negative humanitarian disvalue, and preventing another such recession would have massive humanitarian value.<br> <!--[endif]--></p>\n<p class=\"MsoNormal\"><strong id=\"Transparent_financial_analysis_as_a_possible_solution\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Transparent financial analysis as a possible solution</span></strong></p>\n<p class=\"MsoNormal\">There are actors in finance who accurately predicted that there was a housing bubble that was on the brink of popping, and who bet heavily against subprime mortgages, reaping enormous profits as a result. The most prominent example is <a href=\"http://en.wikipedia.org/wiki/John_Paulson\">John Paulson</a>, who made $3.7 billion in a 2007 alone, starting from a base of less than $1 billion. There are less extreme examples that are nevertheless very striking.&nbsp;</p>\n<p class=\"MsoNormal\">It\u2019s difficult to determine the relative roles that skill and luck played in these peoples\u2019 success, and the situation is further obscured by <a href=\"http://en.wikipedia.org/wiki/Hindsight_bias\">hindsight bias</a>. Nevertheless, it seems possible that the financial success of Paulson and others was a consequence of careful analysis and shrewdness, and that other people of sufficiently high intellectual caliber and rationality would have been able to predict it as well.</p>\n<p class=\"MsoNormal\">As is always the case in finance, those who recognized the impending pop of the housing bubble kept their analysis secret, because sharing it would have allowed others to partially close the arbitrage opportunity, reducing the potential to profit. If these people had made their thinking public, <em>it could have resulted in <strong>other</strong> people betting against the housing bubble earlier on</em>, popped the housing bubble when it was smaller, possibly substantially lessening the severity of the ensuing recession. While there were people who publicly voiced concern, a large number of people would have had a bigger impact</p>\n<p class=\"MsoNormal\">This suggests that transparent financial analysis by intellectual elites could carry massive humanitarian value.&nbsp;</p>\n</div>\n<div>\n<p class=\"MsoNormal\"><strong id=\"Mathematicians_as_unusually_well_positioned_to_perform_such_analysis\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Mathematicians as unusually well positioned to perform such analysis</span></strong></p>\n<p class=\"MsoNormal\">In the course of my graduate school days, I became familiar with mathematical community. There\u2019s a wide cultural gulf between pure math and finance. My experience was that mathematicians generally view finance as \u201cdirty business,\u201d on account of:</p>\n</div>\n<div>\n<ul>\n<li>Often having left-wing political beliefs</li>\n<li>Discomfort with the zero-sum and/or negative-sum nature of finance</li>\n<li>Not identifying with materialism</li>\n<li>Disliking messy problems that are less intrinsically interesting than problems in pure math.</li>\n</ul>\n<div><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>95</o:Words> <o:Characters>548</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>4</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>642</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\">I believe that this gulf has led to a potential opportunity being overlooked: <em>mathematicians may be ideally suited to perform transparent financial analysis that reduces damage from financial bubbles</em>.</p>\n<p class=\"MsoNormal\">This idea occurred to me a few weeks ago. Ideas for philanthropic interventions generally fall apart upon closer examination, and so I wasn\u2019t too optimistic about it holding up. So I was surprised when <a href=\"http://en.wikipedia.org/wiki/Neal_Koblitz\">Neal Koblitz</a> (co-creator of <a href=\"http://en.wikipedia.org/wiki/Elliptic_curve_cryptography\">elliptic curve cryptography</a>) raised the same idea in unrelated correspondence:</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>73</o:Words> <o:Characters>422</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>3</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>494</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">If mathematicians had been noticing the dubious ways that people in the financial world were claiming to be applying mathematics, and if they had publicly and loudly criticized the misuse of mathematics, then the world might have been spared the collapse of 2008 (or, rather, it wouldn't have been as bad). If mathematicians could have played a role stopping the credit-derivatives bubble before it got out of hand, the economic value of doing that would have been in the trillions of dollars.</p>\n<!--EndFragment--></div>\n</div>\n<!--[if !supportLineBreakNewLine]--> <!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>20</o:Words> <o:Characters>116</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>135</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} -->\n<p>When an idea occurs to two people independently, the case for it being a good idea is strengthened. Moreover, Koblitz has <a href=\"http://www.amazon.com/Random-Curves-Mathematician-Neal-Koblitz/dp/3540740775/ref=la_B000APHL8Y_1_4?ie=UTF8&amp;qid=1369329138&amp;sr=1-4\">a long history of involvement with humanitarian efforts</a> and so can be expected to have perspective on them.&nbsp;</p>\n<p class=\"MsoNormal\">Some reasons why mathematicians seem unusually well suited to the task are:</p>\n<p class=\"MsoNormal\"><strong>Transferable Skills</strong> \u2014&nbsp;Most mathematicians are unfamiliar with some of most important tools used in finance: statistics, data analysis &amp; programming. But there\u2019s a historical track record of mathematicians being able to pick up these skills and use them to powerful effect. <a href=\"http://en.wikipedia.org/wiki/James_Harris_Simons\">James Simons</a> transitioned from differential geometry to quantitative finance, and became one of the most successful hedge fund managers ever. <a href=\"http://mathbabe.org/\">Cathy O\u2019Neil</a> did a PhD in algebraic number theory under Barry Mazur\u2019s direction, and got a job at <a href=\"http://en.wikipedia.org/wiki/D._E._Shaw_%26_Co.\">DE Shaw</a>, which is one of the most prestigious hedge funds. Mathematicians who are motivated to learn these skills are well positioned to do so.</p>\n<p class=\"MsoNormal\">There are other skills that are very important for successful financial analysis \u2013&nbsp;in particular, one has to have a good eye for empirical data. This is a skill that\u2019s not directly transferable, but it still seems likely that a nontrivial fraction of mathematicians could develop high facility with it.</p>\n<!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\"><strong>Intellectual Caliber</strong> \u2014&nbsp;The mathematics community has a very dense concentration of intellectual power. &nbsp;James Simons offers a direct point of comparison between math and finance:</p>\n<p class=\"MsoNormal\">Simons won the <a href=\"http://en.wikipedia.org/wiki/Oswald_Veblen_Prize_in_Geometry\">Oswald Veblan Prize in Geometry</a> before leaving academia to start <a href=\"http://en.wikipedia.org/wiki/Renaissance_Technologies\">Renaissance Technologies</a>. There are 25 living mathematicians who have won this prize. The prize is awarded exclusively for work in geometry/topology, and if one looks more broadly at all mathematical fields, one can generate a list of about 100 living mathematicians who were at least as accomplished as Simons at the same age.</p>\n<p class=\"MsoNormal\">&nbsp;After leaving academia, Simons made $10 billion in quantitative finance. What I find most interesting about this is that the situation is not that Simons succeeded where other mathematicians of the same caliber had failed&nbsp;\u2013&nbsp;rather, <em>Simons is virtually the only pure mathematician of his caliber to have left academia</em>. This raises the possibility that there are a handful of elite mathematicians who could make much better financial predictions than most present day actors in finance. Less accomplished but capable mathematicians may also do very well.</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>64</o:Words> <o:Characters>370</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>3</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>433</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\"><strong>Cautiousness</strong> \u2014&nbsp;Mathematicians are naturally intellectually conservative, as they spend much of their time rigorously examining arguments for flaws. Thus, they\u2019re unusually unlikely to succumb to <a href=\"http://en.wikipedia.org/wiki/Greed_and_fear\">greed and fear</a>, which are factors that are thought to play a large role in the behavior of financial markets, and which lead to speculative bubbles. This is corroborated by some of Cathy O\u2019Neil\u2019s remarks on finance.</p>\n<!--EndFragment-->\n<p><strong id=\"Implications\"><span style=\"font-size: 14.0pt; mso-bidi-font-size: 12.0pt;\">Implications</span></strong></p>\n<p class=\"MsoNormal\">The above considerations suggest that mathematicians could contribute <em>enormous social value</em> by engaging in transparent financial analysis.&nbsp;</p>\n<p class=\"MsoNormal\">Many mathematicians who I know wish that they could contribute more social value. In the essay&nbsp;<a href=\"http://publications.ias.edu/sites/default/files/ND.pdf\">Is there beauty in mathematical theories?</a>, the great mathematician Robert Langlands wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">In a letter to A.-M.Legendre of 1830, which I came across while preparing this lecture, Jacobi famously wrote</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em>It is true that Mr. Fourier thought that the principal goal of mathematics was their public utility and their use in explaining natural phenomena. A philosopher like him should have known that the only goal of Science is the honor of the human spirit, and that as such, a question in number theory is worth a question concerning the system of the world.</em></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em></em>I am not sure it is so easy. I have given a great deal of my life to matters closely related to the theory of numbers, but the honor of the human spirit is, perhaps, too doubtful and too suspect a notion to serve as vindication. [\u2026] Moreover, the appeal to the common welfare as a goal of mathematics is, if not then at least now, often abusive. So it is not easy to \ufb01nd an apology for a life in mathematics.</p>\n<!--EndFragment-->\n<p style=\"padding-left: 30px;\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>82</o:Words> <o:Characters>474</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>3</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>555</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">A fair number of mathematicians <em>don\u2019t have any choice but to do pure math</em>. Gromov wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">You become a mathematician, a slave of this insatiable hunger of your brain, of everybody's brain, for making structures of everything that goes into it.</p>\n<p class=\"MsoNormal\">I'm very sympathetic to Gromov's remark, and I think that for people who constituted in this way, it\u2019s probably best not to try to suppress these urges, as such attempts tend to be unsustainable and <a href=\"/lw/38u/best_career_models_for_doing_research/33et\">result in lower contributions to global welfare rather than higher ones</a>.</p>\n<!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\">But for mathematicians who are:</p>\n<ul>\n<li>Tenured professors who don\u2019t have to worry about career considerations&nbsp;</li>\n<li>Able to enjoy financial analysis</li>\n<li>Strongly motivated to do an excellent job</li>\n</ul>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>26</o:Words> <o:Characters>153</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>178</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"0\" Name=\"Body Text\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--></p>\n<p class=\"MsoNormal\">there may be a major opportunity to contribute enormous social value by conducting transparent high quality financial analysis.</p>\n<p class=\"MsoNormal\">This question warrants further investigation.</p>", "sections": [{"title": "Recessions as a serious threat to global welfare", "anchor": "Recessions_as_a_serious_threat_to_global_welfare", "level": 1}, {"title": "Transparent financial analysis as a possible solution", "anchor": "Transparent_financial_analysis_as_a_possible_solution", "level": 1}, {"title": "Mathematicians as unusually well positioned to perform such analysis", "anchor": "Mathematicians_as_unusually_well_positioned_to_perform_such_analysis", "level": 1}, {"title": "Implications", "anchor": "Implications", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "132 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 132, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-25T10:31:51.169Z", "modifiedAt": null, "url": null, "title": "Be a little bit more trusting than most people think sensible", "slug": "be-a-little-bit-more-trusting-than-most-people-think", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.365Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "purplerabbits", "createdAt": "2009-04-17T13:03:09.540Z", "isAdmin": false, "displayName": "purplerabbits"}, "userId": "2MPCPgrqsghoJQ6SK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nutHTZKyzkHkxXT5A/be-a-little-bit-more-trusting-than-most-people-think", "pageUrlRelative": "/posts/nutHTZKyzkHkxXT5A/be-a-little-bit-more-trusting-than-most-people-think", "linkUrl": "https://www.lesswrong.com/posts/nutHTZKyzkHkxXT5A/be-a-little-bit-more-trusting-than-most-people-think", "postedAtFormatted": "Saturday, May 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Be%20a%20little%20bit%20more%20trusting%20than%20most%20people%20think%20sensible&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABe%20a%20little%20bit%20more%20trusting%20than%20most%20people%20think%20sensible%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnutHTZKyzkHkxXT5A%2Fbe-a-little-bit-more-trusting-than-most-people-think%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Be%20a%20little%20bit%20more%20trusting%20than%20most%20people%20think%20sensible%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnutHTZKyzkHkxXT5A%2Fbe-a-little-bit-more-trusting-than-most-people-think", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnutHTZKyzkHkxXT5A%2Fbe-a-little-bit-more-trusting-than-most-people-think", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 290, "htmlBody": "<p>I am just working on a list of rationalist rules I live by, and this is the one I have most confidence in, so it seems a good topic for my first ever post (which will be short as I have to be on a train in 15)</p>\n<p>Since people routinely exaggerate risk, and social norms pull us towards the <a href=\"http://en.m.wikipedia.org/wiki/Crab_mentality\">crabs in a bucket</a>&nbsp;effect&nbsp;(especially for women) I want to correct for that. (Preferably without ending up with a giant Rob Me sign over my head, but that's not the direction I err in.)</p>\n<p>For example, there was this rationalist walked into a bar. I had a lot of luggage - everything I need for a four day break, including over two thousand pounds worth of electronic devices and binoculars. I am insured, but it would be an especially annoying time to lose stuff. I had a coffee and then I needed the bathroom, which was far away through a lot of people.</p>\n<p>I knew logically how little risk there was in leaving all my stuff; a Highland bar in the middle of the afternoon is even safer than where I live in Edinburgh, and no-one was pinging any alarm bells, but I still spent more time than I'd like to admit convincing myself I didn't have to drag the huge bag with me to the ladies and back. Yes brain, even though I'm alone, and the customers are men, and I'm a middle aged woman, and my mother would freak if she saw me...&nbsp;</p>\n<p>Of course it was fine, like it was the last &nbsp;hundred times. One day I hope to not even have to persuade myself, but meanwhile I notice my prediction was correct and feel just a little bit pleased with myself.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nutHTZKyzkHkxXT5A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 15, "extendedScore": null, "score": 1.2105037639892499e-06, "legacy": true, "legacyId": "22632", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-25T10:58:40.175Z", "modifiedAt": null, "url": null, "title": "Collecting expressions of interest in a rationality conference in August", "slug": "collecting-expressions-of-interest-in-a-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.316Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "purplerabbits", "createdAt": "2009-04-17T13:03:09.540Z", "isAdmin": false, "displayName": "purplerabbits"}, "userId": "2MPCPgrqsghoJQ6SK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R4Fmiw3BuLeRkr4Y9/collecting-expressions-of-interest-in-a-rationality", "pageUrlRelative": "/posts/R4Fmiw3BuLeRkr4Y9/collecting-expressions-of-interest-in-a-rationality", "linkUrl": "https://www.lesswrong.com/posts/R4Fmiw3BuLeRkr4Y9/collecting-expressions-of-interest-in-a-rationality", "postedAtFormatted": "Saturday, May 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Collecting%20expressions%20of%20interest%20in%20a%20rationality%20conference%20in%20August&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACollecting%20expressions%20of%20interest%20in%20a%20rationality%20conference%20in%20August%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4Fmiw3BuLeRkr4Y9%2Fcollecting-expressions-of-interest-in-a-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Collecting%20expressions%20of%20interest%20in%20a%20rationality%20conference%20in%20August%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4Fmiw3BuLeRkr4Y9%2Fcollecting-expressions-of-interest-in-a-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR4Fmiw3BuLeRkr4Y9%2Fcollecting-expressions-of-interest-in-a-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 116, "htmlBody": "<p class=\"p1\">On the principle of organising events that I want to attend myself, I would very much like to organise a rationality conference/convention in the UK. I organise events for a living<span style=\"color: #262626; font-family: arial, sans-serif; font-size: 13px; line-height: 16px;\">; in addition, in my free time I've organised five ~200 person weekend conventions and several other events</span>.</p>\n<p class=\"p2\">At the moment I am thinking of a one day event on a weekend or a Friday in August, at Stamford Bridge or somewhere else easy to get to around London. There would probably also be a pre-conference dinner, or private bar night with music.</p>\n<p class=\"p2\">Costs would be in the region of &pound;50-&pound;100 a head including lunch.</p>\n<p class=\"p2\">Can I get a show of hands to see if the idea is viable?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R4Fmiw3BuLeRkr4Y9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 30, "extendedScore": null, "score": 1.2105235157653355e-06, "legacy": true, "legacyId": "22712", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-25T13:09:46.948Z", "modifiedAt": null, "url": null, "title": "...so did we now get cold fusion to work or what?", "slug": "so-did-we-now-get-cold-fusion-to-work-or-what", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:09.027Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Friendly-HI", "createdAt": "2011-04-18T18:19:01.357Z", "isAdmin": false, "displayName": "Friendly-HI"}, "userId": "nXA5fJiYcfJGaQkwG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QgqtGNSzFJ8F2giuZ/so-did-we-now-get-cold-fusion-to-work-or-what", "pageUrlRelative": "/posts/QgqtGNSzFJ8F2giuZ/so-did-we-now-get-cold-fusion-to-work-or-what", "linkUrl": "https://www.lesswrong.com/posts/QgqtGNSzFJ8F2giuZ/so-did-we-now-get-cold-fusion-to-work-or-what", "postedAtFormatted": "Saturday, May 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20...so%20did%20we%20now%20get%20cold%20fusion%20to%20work%20or%20what%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A...so%20did%20we%20now%20get%20cold%20fusion%20to%20work%20or%20what%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQgqtGNSzFJ8F2giuZ%2Fso-did-we-now-get-cold-fusion-to-work-or-what%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=...so%20did%20we%20now%20get%20cold%20fusion%20to%20work%20or%20what%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQgqtGNSzFJ8F2giuZ%2Fso-did-we-now-get-cold-fusion-to-work-or-what", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQgqtGNSzFJ8F2giuZ%2Fso-did-we-now-get-cold-fusion-to-work-or-what", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 107, "htmlBody": "<p>Some of you may have heard about the following paper already:<br /><br />http://arxiv.org/ftp/arxiv/papers/1305/1305.3913.pdf<br /><br />Here's a news article wrapping up the main points:<br /><br />http://atom-ecology.russgeorge.net/2013/05/20/an-italian-cold-fusion-tide-lifts-all-boats-arvix-independent-review-paper-confirms-rossi-fusion/<br /><br /><br />I'm way out of my depth here so I find it hard to judge, is this a pile of BS or are we finally getting somewhere for real?<br />Is burning coal (and using chemical reactions in general) for the purpose of producing energy coming to an end in the upcoming decades?<br /><br /><br /><br />EDIT: Here's a review of the article, it should be read. http://scienceblogs.com/startswithabang/2013/05/21/the-e-cat-is-back-and-people-are-still-falling-for-it/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QgqtGNSzFJ8F2giuZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": -18, "extendedScore": null, "score": 1.210620094650247e-06, "legacy": true, "legacyId": "22713", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-25T18:40:36.006Z", "modifiedAt": null, "url": null, "title": "Evidence and counterexample to positive relevance", "slug": "evidence-and-counterexample-to-positive-relevance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.636Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fsopho", "createdAt": "2011-12-07T12:31:31.940Z", "isAdmin": false, "displayName": "fsopho"}, "userId": "26wYfWx8uuMr7Hpc4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/59iLdwhht7a96XfWD/evidence-and-counterexample-to-positive-relevance", "pageUrlRelative": "/posts/59iLdwhht7a96XfWD/evidence-and-counterexample-to-positive-relevance", "linkUrl": "https://www.lesswrong.com/posts/59iLdwhht7a96XfWD/evidence-and-counterexample-to-positive-relevance", "postedAtFormatted": "Saturday, May 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Evidence%20and%20counterexample%20to%20positive%20relevance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEvidence%20and%20counterexample%20to%20positive%20relevance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F59iLdwhht7a96XfWD%2Fevidence-and-counterexample-to-positive-relevance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Evidence%20and%20counterexample%20to%20positive%20relevance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F59iLdwhht7a96XfWD%2Fevidence-and-counterexample-to-positive-relevance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F59iLdwhht7a96XfWD%2Fevidence-and-counterexample-to-positive-relevance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 531, "htmlBody": "<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">I would like to share a doubt with you. Peter Achinstein, in his&nbsp;<a style=\"color: #666666;\" href=\"http://books.google.com/books/about/The_Book_of_Evidence.html?id=cZHflkcvCEUC\" target=\"_blank\"><em>The Book of Evidence</em></a>&nbsp;considers two probabilistic views about the conditions that must be satisfied in order for&nbsp;<em>e</em>&nbsp;to be evidence that&nbsp;<em>h</em>. The first one says that&nbsp;<em>e</em>&nbsp;is evidence that&nbsp;<em>h</em>&nbsp;when&nbsp;<em>e</em>&nbsp;<em>increases the probability</em>&nbsp;of&nbsp;<em>h</em>&nbsp;when added to some background information&nbsp;<em>b</em>:</p>\n<blockquote style=\"margin: 0px 3em; font-family: Georgia, 'Bitstream Charter', serif !important; font-style: italic !important; color: #333333; font-size: 12px; line-height: 19px;\">\n<p style=\"margin: 0px 3em;\"><strong>(<em style=\"font-style: normal;\">Increase in Probability</em>)</strong>&nbsp;<em style=\"font-style: normal;\">e</em>&nbsp;is evidence that&nbsp;<em style=\"font-style: normal;\">h&nbsp;</em>iff&nbsp;<em style=\"font-style: normal;\">P</em>(<em style=\"font-style: normal;\">h</em>|<em style=\"font-style: normal;\">e</em>&amp;<em style=\"font-style: normal;\">b</em>) &gt;&nbsp;<em style=\"font-style: normal;\">P</em>(<em style=\"font-style: normal;\">h</em>|<em style=\"font-style: normal;\">b</em>).</p>\n</blockquote>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">The second one says that&nbsp;<em>e</em>&nbsp;is evidence that&nbsp;<em>h</em>&nbsp;when the probability of&nbsp;<em>h</em>&nbsp;conditional on&nbsp;<em>e</em>&nbsp;is higher than some threshold&nbsp;<em>k</em>:</p>\n<blockquote style=\"margin: 0px 3em; font-family: Georgia, 'Bitstream Charter', serif !important; font-style: italic !important; color: #333333; font-size: 12px; line-height: 19px;\">\n<p style=\"margin: 0px 3em;\"><strong>(<em style=\"font-style: normal;\">High Probability</em>)</strong>&nbsp;<em style=\"font-style: normal;\">e</em>&nbsp;is evidence that&nbsp;<em style=\"font-style: normal;\">h</em>&nbsp;iff&nbsp;<em style=\"font-style: normal;\">P</em>(<em style=\"font-style: normal;\">h</em>|<em style=\"font-style: normal;\">e</em>) &gt;&nbsp;<em style=\"font-style: normal;\">k</em>.</p>\n</blockquote>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">A plausible way of interpreting the second definition is by saying that&nbsp;<em>k</em>&nbsp;= 1/2. When one takes&nbsp;<em>k</em>&nbsp;to have such fixed value, it turns out that&nbsp;<em>P</em>(<em>h</em>|<em>e</em>) &gt;&nbsp;<em>k</em>&nbsp;has the same truth-conditions as&nbsp;<em>P</em>(<em>h</em>|<em>e</em>) &gt;&nbsp;<em>P</em>(~<em>h</em>|<em>e</em>) - at least if we are assuming that&nbsp;<em>P</em>&nbsp;is a function obeying Kolmogorov's axioms of the probability calculus. Now, Achinstein takes&nbsp;<em>P</em>(<em>h</em>|<em>e</em>) &gt;&nbsp;<em>k&nbsp;</em>to be a necessary but insufficient condition for&nbsp;<em>e</em>&nbsp;to be evidence that&nbsp;<em>h</em>&nbsp;- while he claims that&nbsp;<em>P</em>(<em>h</em>|<em>e</em>&amp;<em>b</em>) &gt;&nbsp;<em>P</em>(<em>h</em>|<em>b</em>) is neither necessary nor sufficient for&nbsp;<em>e</em>&nbsp;to be evidence that&nbsp;<em>h</em>. That may seem shocking for those that take the condition fleshed out in (<em>Increase in Probability</em>)&nbsp;<em>at least&nbsp;</em>as a necessary condition for evidential support (I take it that the claim that it is necessary&nbsp;<em>and</em>&nbsp;sufficient is far from accepted - presumably one also wants to qualify&nbsp;<em>e</em>&nbsp;as true, or as known, or as justifiably believed, etc). So I would like to check one of Achinstein's counter-examples to the claim that increase in probability is a necessary condition for evidential support.</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">The relevant example is as follows:</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<blockquote style=\"margin: 0px 3em; font-family: Georgia, 'Bitstream Charter', serif !important; font-style: italic !important; color: #333333; font-size: 12px; line-height: 19px;\">\n<p style=\"margin: 0px 3em;\"><strong><em style=\"font-style: normal;\">The lottery counterexample</em></strong></p>\n<p style=\"margin: 0px 3em;\">Suppose one has the following background&nbsp;<em style=\"font-style: normal;\">b</em>&nbsp;and piece of evidence&nbsp;<em style=\"font-style: normal;\">e1:</em></p>\n<p style=\"margin: 0px 3em;\"><em style=\"font-style: normal;\">b</em>: &nbsp;This is a fair lottery in which one ticket drawn at random will win.</p>\n<p style=\"margin: 0px 3em;\"><em style=\"font-style: normal;\">e1</em>:&nbsp;<em style=\"font-style: normal;\">The New York Times&nbsp;</em>reports that Bill Clinton owns all but one of the 1000 lottery&nbsp;tickets sold in a lottery.</p>\n<p style=\"margin: 0px 3em;\">Further, one also learns&nbsp;<em style=\"font-style: normal;\">e2</em>:</p>\n<p style=\"margin: 0px 3em;\"><em style=\"font-style: normal;\">e2</em>:&nbsp;<em style=\"font-style: normal;\">The Washington Post&nbsp;</em>reports that Bill Clinton owns all but one of the 1000 lottery&nbsp;tickets sold in a lottery.<em style=\"font-style: normal;\">&nbsp;</em></p>\n<p style=\"margin: 0px 3em;\">So, one has evidence in favor of</p>\n<p style=\"margin: 0px 3em;\"><em style=\"font-style: normal;\">h</em>: &nbsp;Bill Clinton will win the lottery.</p>\n</blockquote>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">The point now is that, although it seems right to regard&nbsp;<em>e2</em>&nbsp;as being evidence in favor of&nbsp;<em>h</em>, it fails to increase&nbsp;<em>h</em>'s probability conditional on (<em>b</em>&amp;<em>e1</em>) - at least so says Achinstein. According to his example, the following is true:</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<blockquote style=\"margin: 0px 3em; font-family: Georgia, 'Bitstream Charter', serif !important; font-style: italic !important; color: #333333; font-size: 12px; line-height: 19px;\">\n<p style=\"margin: 0px 3em;\"><em style=\"font-style: normal;\">P</em>(<em style=\"font-style: normal;\">h</em>|<em style=\"font-style: normal;\">b</em>&amp;<em style=\"font-style: normal;\">e1</em>&amp;<em style=\"font-style: normal;\">e2</em>) =&nbsp;<em style=\"font-style: normal;\">P</em>(<em style=\"font-style: normal;\">h</em>|<em style=\"font-style: normal;\">b</em>&amp;<em style=\"font-style: normal;\">e1</em>) = 999/1000.</p>\n</blockquote>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">Well, I have my doubts about this counterexample. The problem with it seems to me to be this: that&nbsp;<em>e1</em>&nbsp;and&nbsp;<em>e2</em>&nbsp;are taken to be the same piece of evidence. Let me explain. If&nbsp;<em>e1</em>&nbsp;and&nbsp;<em>e2</em>&nbsp;increase the probability of&nbsp;<em>h</em>, that is because they increase the probability of a further proposition:</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<blockquote style=\"margin: 0px 3em; font-family: Georgia, 'Bitstream Charter', serif !important; font-style: italic !important; color: #333333; font-size: 12px; line-height: 19px;\">\n<p style=\"margin: 0px 3em;\"><em style=\"font-style: normal;\">g</em>: Bill Clinton owns all but one of the 1000 lottery tickets sold in a lottery,</p>\n</blockquote>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">&nbsp;</p>\n<p style=\"margin-bottom: 1.5em; color: #333333; font-family: Helvetica, Arial, 'Nimbus Sans L', sans-serif; font-size: 12px; line-height: 19px;\">and, as it happens,&nbsp;<em>g</em>&nbsp;increases the probability of&nbsp;<em>h</em>. That&nbsp;<em>The New York Times</em>&nbsp;reports&nbsp;<em>g</em>, assuming that the&nbsp;<em>New York Times</em>&nbsp;is reliable, increases the probability of&nbsp;<em>g</em>&nbsp;- and the same can be said about&nbsp;<em>The Washington Post</em>&nbsp;reporting&nbsp;<em>g</em>. But the counterexample seems to assume that both&nbsp;<em>e1</em>&nbsp;and&nbsp;<em>e2</em>&nbsp;are equivalent with&nbsp;<em>g</em>, and they're not. Now, it is clear that&nbsp;<em>P</em>(<em>h</em>|<em>b</em>&amp;<em>g</em>) =&nbsp;<em>P</em>(<em>h</em>|<em>b</em>&amp;<em>g</em>&amp;<em>g</em>), but this does not show that&nbsp;<em>e2</em>&nbsp;fails to increase&nbsp;<em>h</em>'s probability on (<em>b</em>&amp;<em>e1</em>). So, if it is true that&nbsp;<em>e2</em>&nbsp;increases the probability of&nbsp;<em>g</em>&nbsp;conditional on<em>&nbsp;e1</em>, that is, if&nbsp;<em>P</em>(<em>g</em>|<em>e1</em>&amp;<em>e2</em>) &gt;&nbsp;<em>P</em>(<em>g</em>|<em>e1</em>), and if it is true that&nbsp;<em>g</em>&nbsp;increases the probability of&nbsp;<em>h</em>, then it is also true that&nbsp;<em>e2</em>&nbsp;increases the probability of&nbsp;<em>h</em>. I may be missing something, but this reasoning sounds right to me - the example wouldn't be a counterexample. What do you think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "59iLdwhht7a96XfWD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -3, "extendedScore": null, "score": 1.210863838422909e-06, "legacy": true, "legacyId": "22714", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-26T00:08:55.793Z", "modifiedAt": null, "url": null, "title": "[LINK] Sign up for DAGGRE to improve science and technology forecasting", "slug": "link-sign-up-for-daggre-to-improve-science-and-technology", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:43.665Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q3viwhp4ors53WWmv/link-sign-up-for-daggre-to-improve-science-and-technology", "pageUrlRelative": "/posts/q3viwhp4ors53WWmv/link-sign-up-for-daggre-to-improve-science-and-technology", "linkUrl": "https://www.lesswrong.com/posts/q3viwhp4ors53WWmv/link-sign-up-for-daggre-to-improve-science-and-technology", "postedAtFormatted": "Sunday, May 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Sign%20up%20for%20DAGGRE%20to%20improve%20science%20and%20technology%20forecasting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Sign%20up%20for%20DAGGRE%20to%20improve%20science%20and%20technology%20forecasting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3viwhp4ors53WWmv%2Flink-sign-up-for-daggre-to-improve-science-and-technology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Sign%20up%20for%20DAGGRE%20to%20improve%20science%20and%20technology%20forecasting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3viwhp4ors53WWmv%2Flink-sign-up-for-daggre-to-improve-science-and-technology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3viwhp4ors53WWmv%2Flink-sign-up-for-daggre-to-improve-science-and-technology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 200, "htmlBody": "<p><a href=\"http://intelligence.org/2013/05/24/sign-up-for-daggre-to-improve-science-technology-forecasting/\">Link</a>:</p>\n<blockquote>\n<p>In <a href=\"http://intelligence.org/2013/05/15/when-will-ai-be-created/\">When Will AI Be Created?</a>, I named four methods that might improve our forecasts of AI and other important technologies. Two of these methods were <em>explicit quantification</em> and <em>leveraging aggregation</em>, as exemplified by IARPA's <a href=\"http://www.iarpa.gov/Programs/ia/ACE/ace.html\">ACE program</a>, which aims to &ldquo;dramatically enhance the accuracy, precision, and timeliness of&hellip; forecasts for a broad range of event types, through the development of advanced techniques that elicit, weight, and combine the judgments of many analysts.</p>\n<p>GMU's <a href=\"http://www.daggre.org/info/\">DAGGRE program</a>, one of five teams participating in ACE, recently&nbsp;<a href=\"http://blog.daggre.org/2013/05/24/3054/\">announced</a>&nbsp;a transition from geopolitical forecasting to science &amp; technology forecasting:</p>\n<p style=\"padding-left: 30px;\">DAGGRE will continue, but it will transition from geo-political forecasting to science and technology (S&amp;T) forecasting to better use its combinatorial capabilities. We will have a brand new shiny, friendly and informative interface co-designed by Inkling Markets, opportunities for you to provide your own forecasting questions and more!</p>\n<p style=\"padding-left: 30px;\">Another exciting development is that our S&amp;T forecasting prediction market will be open to everyone in the world who is at least eighteen years of age. We&rsquo;re going global!</p>\n<p>If you want help improve humanity&rsquo;s ability to forecast important technological developments like AI, please&nbsp;register for DAGGRE&rsquo;s new S&amp;T prediction website&nbsp;<a href=\"http://signup.daggre.org/\">here</a>.</p>\n</blockquote>\n<p>Experienced PredictionBook veterans should do well.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q3viwhp4ors53WWmv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 8, "extendedScore": null, "score": 1.2111058350407872e-06, "legacy": true, "legacyId": "22715", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-26T19:07:11.861Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne, practical rationality", "slug": "meetup-melbourne-practical-rationality-13", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:43.853Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gKTzN95bmgrb32HXH/meetup-melbourne-practical-rationality-13", "pageUrlRelative": "/posts/gKTzN95bmgrb32HXH/meetup-melbourne-practical-rationality-13", "linkUrl": "https://www.lesswrong.com/posts/gKTzN95bmgrb32HXH/meetup-melbourne-practical-rationality-13", "postedAtFormatted": "Sunday, May 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%2C%20practical%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%2C%20practical%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgKTzN95bmgrb32HXH%2Fmeetup-melbourne-practical-rationality-13%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%2C%20practical%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgKTzN95bmgrb32HXH%2Fmeetup-melbourne-practical-rationality-13", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgKTzN95bmgrb32HXH%2Fmeetup-melbourne-practical-rationality-13", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 126, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n5'>Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 June 2013 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">491 King Street, West Melbourne VIC 3003, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>NOTE: We've moved a stone's throw from our old office. Note the new address (which is unchanged from May, but changed from April).</p>\n\n<p>Practical rationality. This meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Topic for June: Hypothetical Apostasies - bring a <em>written down</em> belief you think it likely that at least several other attendees will share but that just might be wrong\n<a href=\"http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3881488-small-groups-hypothetical-apostasies\" rel=\"nofollow\">http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3881488-small-groups-hypothetical-apostasies</a>\n(<a href=\"http://wiki.lesswrong.com/mediawiki/images/c/ca/How_to_Run_a_Successful_Less_Wrong_Meetup_Group.pdf\" rel=\"nofollow\">http://wiki.lesswrong.com/mediawiki/images/c/ca/How_to_Run_a_Successful_Less_Wrong_Meetup_Group.pdf</a> p23)</p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n5'>Melbourne, practical rationality</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gKTzN95bmgrb32HXH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.2119454622383576e-06, "legacy": true, "legacyId": "22719", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality\">Discussion article for the meetup : <a href=\"/meetups/n5\">Melbourne, practical rationality</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 June 2013 07:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">491 King Street, West Melbourne VIC 3003, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>NOTE: We've moved a stone's throw from our old office. Note the new address (which is unchanged from May, but changed from April).</p>\n\n<p>Practical rationality. This meetup repeats on the 1st Friday of each month and is distinct from our social meetup on the 3rd Friday of each month.</p>\n\n<p>Topic for June: Hypothetical Apostasies - bring a <em>written down</em> belief you think it likely that at least several other attendees will share but that just might be wrong\n<a href=\"http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3881488-small-groups-hypothetical-apostasies\" rel=\"nofollow\">http://lesswrongmelbourne.uservoice.com/forums/203428-general/suggestions/3881488-small-groups-hypothetical-apostasies</a>\n(<a href=\"http://wiki.lesswrong.com/mediawiki/images/c/ca/How_to_Run_a_Successful_Less_Wrong_Meetup_Group.pdf\" rel=\"nofollow\">http://wiki.lesswrong.com/mediawiki/images/c/ca/How_to_Run_a_Successful_Less_Wrong_Meetup_Group.pdf</a> p23)</p>\n\n<p>Discussion: <a href=\"http://groups.google.com/group/melbourne-less-wrong\" rel=\"nofollow\">http://groups.google.com/group/melbourne-less-wrong</a></p>\n\n<p>All welcome from 6:30pm. Call the phone number on the door and I'll let you in.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne__practical_rationality1\">Discussion article for the meetup : <a href=\"/meetups/n5\">Melbourne, practical rationality</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality", "level": 1}, {"title": "Discussion article for the meetup : Melbourne, practical rationality", "anchor": "Discussion_article_for_the_meetup___Melbourne__practical_rationality1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-26T22:29:39.239Z", "modifiedAt": null, "url": null, "title": "Research is polygamous! The importance of what you do needn't be proportional to your awesomeness ", "slug": "research-is-polygamous-the-importance-of-what-you-do-needn-t", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.406Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tvRYLsJXkmsD58ECr/research-is-polygamous-the-importance-of-what-you-do-needn-t", "pageUrlRelative": "/posts/tvRYLsJXkmsD58ECr/research-is-polygamous-the-importance-of-what-you-do-needn-t", "linkUrl": "https://www.lesswrong.com/posts/tvRYLsJXkmsD58ECr/research-is-polygamous-the-importance-of-what-you-do-needn-t", "postedAtFormatted": "Sunday, May 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Research%20is%20polygamous!%20The%20importance%20of%20what%20you%20do%20needn't%20be%20proportional%20to%20your%20awesomeness%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AResearch%20is%20polygamous!%20The%20importance%20of%20what%20you%20do%20needn't%20be%20proportional%20to%20your%20awesomeness%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtvRYLsJXkmsD58ECr%2Fresearch-is-polygamous-the-importance-of-what-you-do-needn-t%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Research%20is%20polygamous!%20The%20importance%20of%20what%20you%20do%20needn't%20be%20proportional%20to%20your%20awesomeness%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtvRYLsJXkmsD58ECr%2Fresearch-is-polygamous-the-importance-of-what-you-do-needn-t", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtvRYLsJXkmsD58ECr%2Fresearch-is-polygamous-the-importance-of-what-you-do-needn-t", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 501, "htmlBody": "<p>In a recent discussion a friend was telling me how he felt he was not as smart as the people he thinks are doing the best research on the most important topics. He said a few jaw-dropping names, which indeed are smarter than him, and mentioned their research agenda, say, A B and C. &nbsp;</p>\n<p>From that, a remarkable implication followed, in his cognitive algorithm:&nbsp;</p>\n<p>&nbsp;</p>\n<p>Therefore I should research thing D or thing E.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Which made me pause for a moment. Here is a<em> hypothetical schematic</em> of this conception of the world. Arrows stand for \"Ought to research\"</p>\n<p>Humans by Level of Awesome (HLA) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Research Agenda by Level of Importance. (RALI)</p>\n<p>HLA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; RALI</p>\n<p>Mrs 1<span style=\"white-space: pre;\"> </span>--------&gt;<span style=\"white-space: pre;\"> </span>X-risk #1</p>\n<p><span style=\"white-space: pre;\"> </span>2<span style=\"white-space: pre;\"> </span>--------&gt;<span style=\"white-space: pre;\"> </span>X-risk #2&nbsp;</p>\n<p><span style=\"white-space: pre;\"> </span>3<span style=\"white-space: pre;\"> </span>--------&gt;<span style=\"white-space: pre;\"> </span>Longevity</p>\n<p><span style=\"white-space: pre;\"> </span>4<span style=\"white-space: pre;\"> </span>--------&gt;<span style=\"white-space: pre;\"> </span>Malaria Reduction&nbsp;</p>\n<p><span style=\"white-space: pre;\"> </span>5<span style=\"white-space: pre;\"> </span>--------&gt;<span style=\"white-space: pre;\"> </span>Enhancement&nbsp;</p>\n<p><span style=\"white-space: pre;\"> </span>1344<span style=\"white-space: pre;\"> </span>--------&gt;<span style=\"white-space: pre;\"> </span>Increasing Puppies Cuteness</p>\n<p>Etc...&nbsp;</p>\n<p>&nbsp;</p>\n<p>It made me think of the problem of creating match making algorithms for websites where people want to pair to do stuff, such as playing tennis, chess or having a romantic relationship.</p>\n<p>This reasoning is profoundly mistaken, and I can look back into my mind, and remember dozens of times I have made the exact same mistake. So I thought it would be good to spell out 10 times <a href=\"http://st0rage.info/ttc-audio-prof-monisha-pasupathi-how-we-learn-24-mp3-everything-else/\">in different ways</a> for the unconscious bots in my mind that didn't get it yet:&nbsp;</p>\n<p>1) Research agenda topics are polygamous, they do not mind if there is someone else researching them, besides the very best people who could be doing such research.&nbsp;</p>\n<p>2) The function above should not be one-to-one (biunivocal), but many-to-one.&nbsp;</p>\n<p>3) There is no relation of overshadowing based on someone's awesomeness to everyone else who researches the same topic, unless they are researching the same narrow minimal sub-type of the same question coming from the same background.&nbsp;</p>\n<p>4) Overdetermination doesn't happen at the \"general topic level\".&nbsp;</p>\n<p>5) Awesome people do not obfuscate what less awesome people do in their area, they catapult it, by creating resources.&nbsp;</p>\n<p>6) Being in an area where the most awesome people are is not asking to \"lose the game\" it is being in an environment that <a href=\"/lw/52g/the_good_news_of_situationist_psychology/\">cultivates greatness</a>.&nbsp;</p>\n<p>7) The amount of awesomeness in a field does not supervene on the amount of awesomeness in it's best explorer.&nbsp;</p>\n<p>8) The Best person in each area would never be able to cause progress alone.&nbsp;</p>\n<p>9) To want to be the best in something has absolutely no precedence over doing something that matters.&nbsp;</p>\n<p>10) If you believe in monogamous research, you'd be in the akward situation where finding out that no one gives a flying fuck about X-risk should make you ecstatic, and that can't be right. That there are people doing something that matters so well that you currently estimate you can't beat them should be fantastic news!&nbsp;</p>\n<p>Well, I hope every last cortical column I have got it now, and the overall surrounding being may be a little less wrong.&nbsp;</p>\n<p>Also, <a href=\"http://edge.org/response-detail/23876\">this text</a> by Michael Vassar is magnificent, and makes a related set of points.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "Z38PqJbRyfwCxKvvL": 1, "qAvbtzdG2A2RBn7in": 1, "xexCWMyds6QLWognu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tvRYLsJXkmsD58ECr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 35, "extendedScore": null, "score": 0.000106, "legacy": true, "legacyId": "22721", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Q5CjE8pRiACqTvhRM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-27T02:04:19.778Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta LessWrong June Meetup: Effective Altruism", "slug": "meetup-atlanta-lesswrong-june-meetup-effective-altruism", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nova_Division", "createdAt": "2011-03-14T15:21:15.124Z", "isAdmin": false, "displayName": "Nova_Division"}, "userId": "eFXLR4aNaxDBCDatT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MLJ5kHrGkJLubXprq/meetup-atlanta-lesswrong-june-meetup-effective-altruism", "pageUrlRelative": "/posts/MLJ5kHrGkJLubXprq/meetup-atlanta-lesswrong-june-meetup-effective-altruism", "linkUrl": "https://www.lesswrong.com/posts/MLJ5kHrGkJLubXprq/meetup-atlanta-lesswrong-june-meetup-effective-altruism", "postedAtFormatted": "Monday, May 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%20LessWrong%20June%20Meetup%3A%20Effective%20Altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%20LessWrong%20June%20Meetup%3A%20Effective%20Altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLJ5kHrGkJLubXprq%2Fmeetup-atlanta-lesswrong-june-meetup-effective-altruism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%20LessWrong%20June%20Meetup%3A%20Effective%20Altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLJ5kHrGkJLubXprq%2Fmeetup-atlanta-lesswrong-june-meetup-effective-altruism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMLJ5kHrGkJLubXprq%2Fmeetup-atlanta-lesswrong-june-meetup-effective-altruism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n6'>Atlanta LessWrong June Meetup: Effective Altruism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 June 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Effective altruism - the application of rationality to helping other people and improving the world.</p>\n\n<ul>\n<li><p>Introductions, and meet and greet for new members.</p></li>\n<li><p>Mini-presentations. Anyone is invited to present on a topic of their choice related to this month\u2019s theme.</p></li>\n<li><p>Discussions. We\u2019ll start with a large group discussion and break into smaller groups as needed.</p></li>\n<li><p>Games!</p></li>\n</ul>\n\n<p>(Please contact me if you have allergies to cats, as our meeting space has two of the most adorable cats you\u2019ve ever seen.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n6'>Atlanta LessWrong June Meetup: Effective Altruism</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MLJ5kHrGkJLubXprq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.2122534115879066e-06, "legacy": true, "legacyId": "22723", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta_LessWrong_June_Meetup__Effective_Altruism\">Discussion article for the meetup : <a href=\"/meetups/n6\">Atlanta LessWrong June Meetup: Effective Altruism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 June 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Effective altruism - the application of rationality to helping other people and improving the world.</p>\n\n<ul>\n<li><p>Introductions, and meet and greet for new members.</p></li>\n<li><p>Mini-presentations. Anyone is invited to present on a topic of their choice related to this month\u2019s theme.</p></li>\n<li><p>Discussions. We\u2019ll start with a large group discussion and break into smaller groups as needed.</p></li>\n<li><p>Games!</p></li>\n</ul>\n\n<p>(Please contact me if you have allergies to cats, as our meeting space has two of the most adorable cats you\u2019ve ever seen.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta_LessWrong_June_Meetup__Effective_Altruism1\">Discussion article for the meetup : <a href=\"/meetups/n6\">Atlanta LessWrong June Meetup: Effective Altruism</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta LessWrong June Meetup: Effective Altruism", "anchor": "Discussion_article_for_the_meetup___Atlanta_LessWrong_June_Meetup__Effective_Altruism", "level": 1}, {"title": "Discussion article for the meetup : Atlanta LessWrong June Meetup: Effective Altruism", "anchor": "Discussion_article_for_the_meetup___Atlanta_LessWrong_June_Meetup__Effective_Altruism1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-27T03:39:01.559Z", "modifiedAt": null, "url": null, "title": "A Proposed Adjustment to the Astronomical Waste Argument", "slug": "a-proposed-adjustment-to-the-astronomical-waste-argument", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:59.422Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nick_Beckstead", "createdAt": "2011-08-19T23:58:47.870Z", "isAdmin": false, "displayName": "Nick_Beckstead"}, "userId": "Sjm96fPXwa2x4eHHv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5czcpvqZ4RH7orcAa/a-proposed-adjustment-to-the-astronomical-waste-argument", "pageUrlRelative": "/posts/5czcpvqZ4RH7orcAa/a-proposed-adjustment-to-the-astronomical-waste-argument", "linkUrl": "https://www.lesswrong.com/posts/5czcpvqZ4RH7orcAa/a-proposed-adjustment-to-the-astronomical-waste-argument", "postedAtFormatted": "Monday, May 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Proposed%20Adjustment%20to%20the%20Astronomical%20Waste%20Argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Proposed%20Adjustment%20to%20the%20Astronomical%20Waste%20Argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5czcpvqZ4RH7orcAa%2Fa-proposed-adjustment-to-the-astronomical-waste-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Proposed%20Adjustment%20to%20the%20Astronomical%20Waste%20Argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5czcpvqZ4RH7orcAa%2Fa-proposed-adjustment-to-the-astronomical-waste-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5czcpvqZ4RH7orcAa%2Fa-proposed-adjustment-to-the-astronomical-waste-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3600, "htmlBody": "<p class=\"MsoNormal\">This article has been <a href=\"http://effective-altruism.com/node/30\">cross-posted</a> at&nbsp;<a href=\"http://effective-altruism.com/\">http://effective-altruism.com/</a>.</p>\n<p class=\"MsoNormal\">An <em>existential risk</em> is a risk &ldquo;that threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development,&rdquo; (<a href=\"http://www.existential-risk.org/concept.html\">Bostrom</a>, 2013). <a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a> has <a href=\"http://www.existential-risk.org/concept.html\">argued that</a></p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">&ldquo;[T]he loss in expected value resulting from an existential catastrophe is so enormous that the objective of reducing existential risks should be a dominant consideration whenever we act out of an impersonal concern for humankind as a whole. It may be useful to adopt the following rule of thumb for such impersonal moral action:</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.0in;\">Maxipok: Maximize the probability of an &ldquo;OK outcome,&rdquo; where an OK outcome is any outcome that avoids existential catastrophe.&rdquo;</p>\n<p class=\"MsoNormal\">There are a number of people in the <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">effective altruism</a>&nbsp;community who accept this view and cite Bostrom&rsquo;s argument as their primary justification. Many of these people also believe that the best ways of minimizing existential risk involve making plans to prevent specific existential catastrophes from occurring, and believe that the best giving opportunities must be with charities that primarily focus on reducing existential risk. They also appeal to Bostrom&rsquo;s argument to support their views. (Edited to add: Note that Bostrom himself sees maxipok as neutral on the question of whether the best methods of reducing existential risk are very broad and general, or highly targeted and specific.) For one example of this, see Luke Muehlhauser&rsquo;s <a href=\"/lw/di4/reply_to_holden_on_the_singularity_institute/\">comment</a>:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">&ldquo;Many humans living today value both current and future people enough that&nbsp;<em>if</em>&nbsp;existential catastrophe is plausible this century, then upon reflection (e.g. after counteracting their unconscious, default&nbsp;<a href=\"/lw/hw/scope_insensitivity/\">scope insensitivity</a>) they would conclude that reducing the risk of existential catastrophe is the most valuable thing they can do &mdash; whether through direct work or by&nbsp;<a href=\"http://intelligence.org/donate/\">donating</a>&nbsp;to support direct work.&rdquo;</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">I now think these views require some significant adjustments and qualifications, and given these adjustments and qualifications, their practical implications become very uncertain. I still believe that what matters most about what we do is how our actions affect humanity&rsquo;s long-term future potential, and I still believe that targeted existential risk reduction and research is a promising cause, but it now seems unclear whether targeted existential risk reduction is the best area to look for ways of making the distant future go as well as possible. It may be and it may not be, and which is right probably depends on many messy details about specific opportunities, as well as general methodological considerations which are, at this point, highly uncertain. Various considerations played a role in my reasoning about this, and I intend to talk about more of them in greater detail in the future. I&rsquo;ll talk about just a couple of these considerations in this post.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">In this post, I argue that:</p>\n<ol>\n<li><strong style=\"text-indent: -0.25in;\">Though Bostrom&rsquo;s argument supports the conclusion that maximizing humanity&rsquo;s long term potential is extremely important, it does not provide strong evidence that reducing existential risk is the best way of maximizing humanity&rsquo;s future potential.</strong><span style=\"text-indent: -0.25in;\"> There is a much broader class of actions which may affect humanity&rsquo;s long-term potential, and Bostrom&rsquo;s argument does not uniquely favor existential risk over other members in this class.</span></li>\n<li><strong style=\"text-indent: -0.25in;\">A version of Bostrom&rsquo;s argument better supports a more general view: what matters most is that we make path-dependent aspects of the far future go as well as possible. </strong><span style=\"text-indent: -0.25in;\">There are important questions about whether we should accept this more general view and what its practical significance is, but this more general view seems to be a strict improvement on the view that minimizing existential risk is what matters most.</span></li>\n<li><strong style=\"text-indent: -0.25in;\">The above points favor very broad, general, and indirect approaches to shaping the far future for the better</strong><span style=\"text-indent: -0.25in;\">, rather than thinking about very specific risks and responses, though there are many relevant considerations and the issue is far from settled.</span></li>\n</ol>\n<p><span style=\"text-indent: 0.5in;\">I think some prominent advocates of existential risk reduction already agree with these general points, and believe that other arguments, or other arguments together with Bostrom&rsquo;s argument, establish that direct existential risk reduction is what matters most. This post is most relevant to people who currently think Bostrom&rsquo;s arguments may settle the issues discussed above.</span></p>\n<h1>Path-dependence and trajectory changes</h1>\n<p class=\"MsoNormal\">In thinking about how we might affect the far future, I've found it useful to use the concept of the world's <em>development trajectory</em>, or just trajectory for short. The world's development trajectory, as I use the term, is a rough summary way the future will unfold over time. The summary includes various facts about the world that matter from a macro perspective, such as how rich people are, what technologies are available, how happy people are, how developed our science and culture is along various dimensions, and how well things are going all-things-considered at different points of time. It may help to think of the trajectory as a collection of graphs, where each graph in the collection has time on the x-axis and one of these other variables on the y-axis.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">With that concept in place, consider three different types of benefits from doing good. First, doing something good might have <em>proximate benefits</em>&mdash;this is the name I give to the fairly short-run, fairly predictable benefits that we ordinarily think about when we cure some child's blindness, save a life, or help an old lady cross the street. Second, there are <em>benefits from speeding up development</em>. In many cases, <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">ripple effects</a>&nbsp;from good ordinary actions speed up development. For example, saving some child's life might cause his country's economy to develop very slightly more quickly, or make certain technological or cultural innovations arrive more quickly. Third, our actions may slightly or significantly alter the world's development trajectory. I call these shifts <em>trajectory changes</em>. If we ever prevent an existential catastrophe, that would be an extreme example of a trajectory change. There may also be smaller trajectory changes. For example, if some species of dolphins that we really loved were destroyed, that would be a much smaller trajectory change.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">The concept of a trajectory change is closely related to the concept of path dependence in the social sciences, though when I talk about trajectory changes I am interested in effects that persist much longer than standard examples of path dependence. A classic example of path dependence is our use of QWERTY keyboards. Our keyboards could have been arranged in any number of other possible ways. A large part of the explanation of why we use QWERTY keyboards is that it happened to be convenient for making typewriters, that a lot of people learned to use these keyboards, and there are advantages to having most people use the same kind of keyboard. In essence, there is path dependence whenever some aspect of the future could easily have been way X, but it is arranged in way Y due to something that happened in the past, and now it would be hard or impossible to switch to way X. Path dependence is especially interesting when way X would have been better than way Y. Some political scientists have argued that path dependence is very common in politics. For example, in an influential paper (with over 3000 citations) <a href=\"http://www.jstor.org/discover/10.2307/2586011?uid=3739576&amp;uid=2&amp;uid=4&amp;uid=3739256&amp;sid=21101564634081\">Pierson</a> (2000, p. 251) argues that:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">Specific patterns of timing and sequence matter; a wide range of social outcomes may be possible; large consequences may result from relatively small or contingent events; particular courses of action, once introduced, can be almost impossible to reverse; and consequently, political development is punctuated by critical moments or junctures that shape the basic contours of social life.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">The concept of a trajectory change is also closely related to the concept of a historical contingency. If Thomas Edison had not invented the light bulb, someone else would have done it later. In this sense, it is not historically contingent that we have light bulbs, and the most obvious benefits from Thomas Edison inventing the light bulb are proximate benefits and benefits from speeding up development. Something analogous is probably true of many other technological innovations such as computers, candles, wheelbarrows, object-oriented programming, and the printing press. Some important examples of historical contingencies: the rise of Christianity, the creation of the US Constitution, and the writings of Karl Marx. Various aspects of Christian morality influence the world today in significant ways, but the fact that those aspects of morality, in exactly those ways, were part of a dominant world religion was historically contingent. And therefore events like Jesus's death and Paul writing his epistles are examples of trajectory changes. Likewise, the US Constitution was the product of deliberation among a specific set of men, the document affects government policy today and will affect it for the foreseeable future, but it could easily have been a different document. And now that the document exists in its specific legal and historical context, it is challenging to make changes to it, so the change is somewhat self-reinforcing.</p>\n<h1>Some small trajectory changes could be suboptimal</h1>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; background-position: initial initial; background-repeat: initial initial;\">Persistent trajectory changes that do not involve existential catastrophes could have great significance for shaping the far future. It is unlikely that the far future will inherit many of our institutions exactly as they are, but <strong>various aspects of the far future&mdash;including social norms, values, political systems, and perhaps even some technologies&mdash;may be path dependent on what happens now, and sometimes in suboptimal ways.</strong> In general, it is reasonable to assume that if there is some problem that might exist in the future and we can do something to fix it now, future people would also be able to solve that problem. But if values or social norms change, they might not agree that some things we think are problems <em>really are</em> problems. Or, if people make the wrong decisions now, certain standards or conventions may get entrenched, and resulting problems may be too expensive to be worth fixing. For further categories of examples of path-dependent aspects of the far future, see <a href=\"http://www.overcomingbias.com/2009/12/long-legacies.html\">these</a>&nbsp;<a href=\"http://www.overcomingbias.com/2012/10/how-plastic-are-people.html\">posts</a>&nbsp;by <a href=\"http://hanson.gmu.edu/\">Robin Hanson</a>.</p>\n<h1>The astronomical waste argument and trajectory changes</h1>\n<p class=\"MsoNormal\">Bostrom&rsquo;s argument only works if reducing existential risk is the most effective way of maximizing humanity&rsquo;s future potential. But<strong> there is no robust argument that trying to reduce existential risk is a more effective way of shaping the far future than trying to create other positive trajectory changes. </strong>Bostrom&rsquo;s argument for the overwhelming importance of reducing existential risk can be summarized as follows:<strong></strong></p>\n<ol>\n<li><span style=\"text-indent: -0.25in;\">The expected size of humanity's future influence is astronomically great.</span></li>\n<li><span style=\"text-indent: -0.25in;\">If the expected size of humanity's future influence is astronomically great, then the expected value of the future is astronomically great.</span></li>\n<li><span style=\"text-indent: -0.25in;\">If&nbsp;the expected value of the future is astronomically great, then what matters most is that we maximize humanity&rsquo;s long-term potential.</span></li>\n<li><span style=\"text-indent: -0.25in;\">Some of our actions are expected to reduce existential risk in not-ridiculously-small ways.</span></li>\n<li><span style=\"text-indent: -0.25in;\">If what matters most is that we maximize humanity&rsquo;s future potential and some of our actions are expected to reduce existential risk in not-ridiculously-small ways, what it is best to do is primarily determined by how our actions are expected to reduce existential risk.</span></li>\n<li><span style=\"text-indent: -0.25in;\">Therefore, what it is best to do is primarily determined by how our actions are expected to reduce existential risk.</span></li>\n</ol>\n<p><span style=\"text-indent: -0.25in;\">Call that the &ldquo;astronomical waste&rdquo; argument.</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">It is unclear whether premise (5) is true because it is unclear whether trying to reduce existential risk is the most effective way of maximizing humanity&rsquo;s future potential. For all we know, it could be more effective to try to create other positive trajectory changes. Clearly, it would be better to prevent extinction than to improve our social norms in a way that indirectly makes the future go one millionth better, but, in general, &ldquo;X is a bigger problem than Y&rdquo; is only a <a href=\"http://blog.givewell.org/2009/04/20/the-most-important-problem-may-not-be-the-best-charitable-cause/\">weak argument</a> that &ldquo;trying to address X is more important than trying to address Y.&rdquo; To be strong, the argument must be supplemented by looking at many other considerations related to X and Y, such as how much effort is going into solving X and Y, how tractable X and Y are, how much X and Y could use additional resources, and whether there are subsets of X or Y that are especially strong in terms of these considerations.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">Bostrom <em>does</em> have arguments that speeding up development and providing proximate benefits are not as important, in themselves, as reducing existential risk. And these arguments, I believe, have some plausibility. <strong>Since we don&rsquo;t have an argument that reducing existential risk is better than trying to create other positive trajectory changes and an existential catastrophe is one type of trajectory change, it seems more reasonable for defenders of the astronomical waste argument to focus on trajectory changes in general.</strong> It would be better to replace the last two steps of the above argument with:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in; text-indent: -.25in;\">4&rsquo; &nbsp; Some of our actions are expected to change our development trajectory in not-ridiculously-small ways.</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in; text-indent: -.25in;\">5&rsquo;. &nbsp;If what matters most is that we maximize humanity&rsquo;s future potential and some of our actions are expected to change our development trajectory in not-ridiculously-small ways, what it is best to do is primarily determined by how our actions are expected to change our development trajectory.</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in; text-indent: -.25in;\">6&rsquo;. &nbsp;Therefore, what it is best to do is primarily determined by how our actions are expected to change our development trajectory.</p>\n<p class=\"MsoNormal\">This seems to be a strictly more plausible claim than the original one, though it is less focused.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; background-position: initial initial; background-repeat: initial initial;\">In response to the arguments in this post, which I e-mailed him in advance, Bostrom wrote a reply (see the end of the post). The key comment, from my perspective, is:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">&ldquo;Many trajectory changes are already encompassed within the notion of an existential catastrophe. &nbsp;Becoming permanently locked into some radically suboptimal state is an xrisk. &nbsp;The notion is more useful to the extent that likely scenarios fall relatively sharply into two distinct categories---very good ones and very bad ones. &nbsp;To the extent that there is a wide range of scenarios that are roughly equally plausible and that vary continuously in the degree to which the trajectory is good, the existential risk concept will be a less useful tool for thinking about our choices. &nbsp;One would then have to resort to a more complicated calculation. &nbsp;However, extinction is quite dichotomous, and there is also a thought that many sufficiently good future civilizations would over time asymptote to the optimal track.&rdquo;</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; background-position: initial initial; background-repeat: initial initial;\">I agree that a key question here is whether there is a very large range of plausible equilibria for advanced civilizations, or whether civilizations that manage to survive long enough naturally converge on something close to the best possible outcome. The more confidence one has in the second possibility, the more interesting existential risk is as a concept. The less confidence one has in the second possibility, the more interesting trajectory changes in general are. However, I would emphasize that unless we can be highly confident in the second possibility, it seems that we cannot be confident that reducing existential risk is more important than creating other positive trajectory changes because of the astronomical waste argument alone. This would turn on further considerations of the sort I described above.</p>\n<h1>Broad and narrow strategies for shaping the far future</h1>\n<p class=\"MsoNormal\">Both the astronomical waste argument and the fixed up version of that argument conclude that what matters most is how our actions affect the far future. I am very sympathetic to this viewpoint, abstractly considered, but I think its practical implications are highly uncertain. There is a spectrum of strategies for shaping the far future that ranges from the very targeted (e.g., stop that asteroid from hitting the Earth) to very broad (e.g., create economic growth, help the poor, provide education programs for talented youth), with options like &ldquo;tell powerful people about the importance of shaping the far future&rdquo; in between. The limiting case of breadth might be just optimizing for proximate benefits or for speeding up development. Defenders of the astronomical waste argument tend to be on the highly targeted end of this spectrum. I think it&rsquo;s a very interesting question where on this spectrum we should prefer to be, other things being equal, and it&rsquo;s a topic I plan to return to in the future.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">The arguments I&rsquo;ve offered above favor broader strategies for shaping the far future, though they don&rsquo;t settle the issue. The main reason I say this is that <strong>the best ways of creating positive trajectory changes may be very broad and general, whereas the best ways of reducing existential risk may be more narrow and specific.</strong> For example, it may be reasonable to try to assess, in detail, questions like, &ldquo;What are the largest specific existential risks?&rdquo; and, &ldquo;What are the most effective ways of reducing those specific risks?&rdquo; In contrast, it seems less promising to try to make specific guesses about how we might create smaller positive trajectory changes because there are so many possibilities and many trajectory changes do not have significance that is predictable in advance. No one could have predicted the persistent ripple effects that Jesus's life had, for example. In other cases&mdash;such as the framing of the US Constitution&mdash;it's clear that a decision has trajectory change potential, but it would be hard to specify, in advance, which concrete measures should be taken. In general, it seems that the worse you are at predicting some phenomenon that is critical to your plans, the less your plans should depend on specific predictions about that phenomenon. Because of this, promising ways to create positive trajectory changes in the world may be more broad than the most promising ways of trying to reduce existential risk specifically. Improving education, improving parenting, improving science, improving our political system, spreading humanitarian values, or otherwise improving our collective wisdom as stewards of the future could, I believe, create many small, unpredictable positive trajectory changes.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">I do not mean to suggest that broad approaches are necessarily best, only that people interested in shaping the far future should take them more seriously than they currently do. The way I see the trade-off between highly targeted strategies and highly broad strategies is as follows. Highly targeted strategies for shaping the far future often depend on highly speculative plans, often with many steps, which are hard to execute. We often have very little sense of whether we are making valuable progress on AI risk research or geo-engineering research. On the other hand, highly broad strategies must rely on implicit assumptions about the ripple effects of doing good in more ordinary ways. It is very subtle and speculative to say how ordinary actions are related to positive trajectory changes, and estimating magnitudes seems extremely challenging. Considering these trade-offs in specific cases seems like a promising area for additional research.<strong></strong></p>\n<h1>Summary</h1>\n<p class=\"MsoNormal\">In this post, I argued that:</p>\n<ol>\n<li><span style=\"text-indent: -0.25in;\">The astronomical waste argument becomes strictly more plausible if we replace the idea of minimizing existential risk with the idea of creating positive trajectory changes.</span></li>\n<li><span style=\"text-indent: -0.25in;\">There are many ways in which our actions could unpredictably affect our general development trajectory, and therefore many ways in which our actions could shape the far future for the better. This is one reason to favor broad strategies for shaping the far future.</span></li>\n</ol><!--[if !supportLists]-->\n<p>The trajectory change perspective may have other strategic implications for people who are concerned about maximizing humanity&rsquo;s long-term potential. I plan to write about these implications in the future.<a name=\"_ednref1\" href=\"file:///C:/Users/Nick%20Beckstead/Desktop/Dropbox/Blogposts/Trajectory%20changes%20blogpost%201.5.docx#_edn1\"><span class=\"MsoEndnoteReference\"><span class=\"MsoEndnoteReference\"><span style=\"font-size: 11pt; line-height: 17px; font-family: Calibri, sans-serif;\">[i]</span></span></span></a></p>\n<h1>Comment from Nick Bostrom on this post</h1>\n<p class=\"MsoNormal\">[What follows is an e-mail response from Nick Bostrom. He suggested that I share his comment along with the post. Note that I added a couple of small clarifications to this post (noted above) in response to Bostrom's comment.]</p>\n<p class=\"MsoNormal\">One can arrive at a more probably correct principle by weakening, eventually arriving at something like 'do what is best' or 'maximize expected good'. &nbsp;There the well-trained analytic philosopher could rest, having achieved perfect sterility. &nbsp;Of course, to get something fruitful, one has to look at the world not just at our concepts.</p>\n<p class=\"MsoNormal\">Many trajectory changes are already encompassed within the notion of an existential catastrophe. &nbsp;Becoming permanently locked into some radically suboptimal state is an xrisk. &nbsp;The notion is more useful to the extent that likely scenarios fall relatively sharply into two distinct categories---very good ones and very bad ones. &nbsp;To the extent that there is a wide range of scenarios that are roughly equally plausible and that vary continuously in the degree to which the trajectory is good, the existential risk concept will be a less useful tool for thinking about our choices. &nbsp;One would then have to resort to a more complicated calculation. &nbsp;However, extinction is quite dichotomous, and there is also a thought that many sufficiently good future civilizations would over time asymptote to the optimal track.</p>\n<p class=\"MsoNormal\">In a more extended and careful analysis there are good reasons to consider second-order effects that are not captured by the simple concept of existential risk. &nbsp;Reducing the probability of negative-value outcomes is obviously important, and some parameters such as global values and coordination may admit of more-or-less continuous variation in a certain class of scenarios and might affect the value of the long-term outcome in correspondingly continuous ways. &nbsp;(The degree to which these complications loom large also depends on some unsettled issues in axiology; so in an all-things-considered assessment, the proper handling of normative uncertainty becomes important. &nbsp;In fact, creating a future civilization that can be entrusted to resolve normative uncertainty well wherever an epistemic resolution is possible, and to find widely acceptable and mutually beneficial compromises to the extent such resolution is not possible---this seems to me like a promising convergence point for action.)</p>\n<p class=\"MsoNormal\">It is not part of the xrisk concept or the maxipok principle that we ought to adopt some maximally direct and concrete method of reducing existential risk (such as asteroid defense): whether one best reduces xrisk through direct or indirect means is an altogether separate question.</p>\n<p>&nbsp;</p>\n<div>\n<hr size=\"1\" />\n<!--[endif]-->\n<div id=\"edn1\">\n<p class=\"MsoEndnoteText\"><a name=\"_edn1\" href=\"file:///C:/Users/Nick%20Beckstead/Desktop/Dropbox/Blogposts/Trajectory%20changes%20blogpost%201.5.docx#_ednref1\"><span class=\"MsoEndnoteReference\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 10.0pt; line-height: 115%; font-family: &quot;Calibri&quot;,&quot;sans-serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">[i]</span></span><!--[endif]--></span></a> I am grateful to Nick Bostrom, Paul Christiano, Luke Muehlhauser, Vipul Naik, Carl Shulman, and Jonah Sinick for feedback on earlier drafts of this post.</p>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"pGqRLe9bFDX2G2kXY": 1, "Rz5jb3cYHTSRmqNnN": 1, "sPpZRaxpNNJjw55eu": 1, "5f5c37ee1b5cdee568cfb2a8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5czcpvqZ4RH7orcAa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 34, "extendedScore": null, "score": 9.7e-05, "legacy": true, "legacyId": "22727", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\">This article has been <a href=\"http://effective-altruism.com/node/30\">cross-posted</a> at&nbsp;<a href=\"http://effective-altruism.com/\">http://effective-altruism.com/</a>.</p>\n<p class=\"MsoNormal\">An <em>existential risk</em> is a risk \u201cthat threatens the premature extinction of Earth-originating intelligent life or the permanent and drastic destruction of its potential for desirable future development,\u201d (<a href=\"http://www.existential-risk.org/concept.html\">Bostrom</a>, 2013). <a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a> has <a href=\"http://www.existential-risk.org/concept.html\">argued that</a></p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">\u201c[T]he loss in expected value resulting from an existential catastrophe is so enormous that the objective of reducing existential risks should be a dominant consideration whenever we act out of an impersonal concern for humankind as a whole. It may be useful to adopt the following rule of thumb for such impersonal moral action:</p>\n<p class=\"MsoNormal\" style=\"margin-left: 1.0in;\">Maxipok: Maximize the probability of an \u201cOK outcome,\u201d where an OK outcome is any outcome that avoids existential catastrophe.\u201d</p>\n<p class=\"MsoNormal\">There are a number of people in the <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">effective altruism</a>&nbsp;community who accept this view and cite Bostrom\u2019s argument as their primary justification. Many of these people also believe that the best ways of minimizing existential risk involve making plans to prevent specific existential catastrophes from occurring, and believe that the best giving opportunities must be with charities that primarily focus on reducing existential risk. They also appeal to Bostrom\u2019s argument to support their views. (Edited to add: Note that Bostrom himself sees maxipok as neutral on the question of whether the best methods of reducing existential risk are very broad and general, or highly targeted and specific.) For one example of this, see Luke Muehlhauser\u2019s <a href=\"/lw/di4/reply_to_holden_on_the_singularity_institute/\">comment</a>:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">\u201cMany humans living today value both current and future people enough that&nbsp;<em>if</em>&nbsp;existential catastrophe is plausible this century, then upon reflection (e.g. after counteracting their unconscious, default&nbsp;<a href=\"/lw/hw/scope_insensitivity/\">scope insensitivity</a>) they would conclude that reducing the risk of existential catastrophe is the most valuable thing they can do \u2014 whether through direct work or by&nbsp;<a href=\"http://intelligence.org/donate/\">donating</a>&nbsp;to support direct work.\u201d</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">I now think these views require some significant adjustments and qualifications, and given these adjustments and qualifications, their practical implications become very uncertain. I still believe that what matters most about what we do is how our actions affect humanity\u2019s long-term future potential, and I still believe that targeted existential risk reduction and research is a promising cause, but it now seems unclear whether targeted existential risk reduction is the best area to look for ways of making the distant future go as well as possible. It may be and it may not be, and which is right probably depends on many messy details about specific opportunities, as well as general methodological considerations which are, at this point, highly uncertain. Various considerations played a role in my reasoning about this, and I intend to talk about more of them in greater detail in the future. I\u2019ll talk about just a couple of these considerations in this post.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">In this post, I argue that:</p>\n<ol>\n<li><strong style=\"text-indent: -0.25in;\">Though Bostrom\u2019s argument supports the conclusion that maximizing humanity\u2019s long term potential is extremely important, it does not provide strong evidence that reducing existential risk is the best way of maximizing humanity\u2019s future potential.</strong><span style=\"text-indent: -0.25in;\"> There is a much broader class of actions which may affect humanity\u2019s long-term potential, and Bostrom\u2019s argument does not uniquely favor existential risk over other members in this class.</span></li>\n<li><strong style=\"text-indent: -0.25in;\">A version of Bostrom\u2019s argument better supports a more general view: what matters most is that we make path-dependent aspects of the far future go as well as possible. </strong><span style=\"text-indent: -0.25in;\">There are important questions about whether we should accept this more general view and what its practical significance is, but this more general view seems to be a strict improvement on the view that minimizing existential risk is what matters most.</span></li>\n<li><strong style=\"text-indent: -0.25in;\">The above points favor very broad, general, and indirect approaches to shaping the far future for the better</strong><span style=\"text-indent: -0.25in;\">, rather than thinking about very specific risks and responses, though there are many relevant considerations and the issue is far from settled.</span></li>\n</ol>\n<p><span style=\"text-indent: 0.5in;\">I think some prominent advocates of existential risk reduction already agree with these general points, and believe that other arguments, or other arguments together with Bostrom\u2019s argument, establish that direct existential risk reduction is what matters most. This post is most relevant to people who currently think Bostrom\u2019s arguments may settle the issues discussed above.</span></p>\n<h1 id=\"Path_dependence_and_trajectory_changes\">Path-dependence and trajectory changes</h1>\n<p class=\"MsoNormal\">In thinking about how we might affect the far future, I've found it useful to use the concept of the world's <em>development trajectory</em>, or just trajectory for short. The world's development trajectory, as I use the term, is a rough summary way the future will unfold over time. The summary includes various facts about the world that matter from a macro perspective, such as how rich people are, what technologies are available, how happy people are, how developed our science and culture is along various dimensions, and how well things are going all-things-considered at different points of time. It may help to think of the trajectory as a collection of graphs, where each graph in the collection has time on the x-axis and one of these other variables on the y-axis.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">With that concept in place, consider three different types of benefits from doing good. First, doing something good might have <em>proximate benefits</em>\u2014this is the name I give to the fairly short-run, fairly predictable benefits that we ordinarily think about when we cure some child's blindness, save a life, or help an old lady cross the street. Second, there are <em>benefits from speeding up development</em>. In many cases, <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">ripple effects</a>&nbsp;from good ordinary actions speed up development. For example, saving some child's life might cause his country's economy to develop very slightly more quickly, or make certain technological or cultural innovations arrive more quickly. Third, our actions may slightly or significantly alter the world's development trajectory. I call these shifts <em>trajectory changes</em>. If we ever prevent an existential catastrophe, that would be an extreme example of a trajectory change. There may also be smaller trajectory changes. For example, if some species of dolphins that we really loved were destroyed, that would be a much smaller trajectory change.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">The concept of a trajectory change is closely related to the concept of path dependence in the social sciences, though when I talk about trajectory changes I am interested in effects that persist much longer than standard examples of path dependence. A classic example of path dependence is our use of QWERTY keyboards. Our keyboards could have been arranged in any number of other possible ways. A large part of the explanation of why we use QWERTY keyboards is that it happened to be convenient for making typewriters, that a lot of people learned to use these keyboards, and there are advantages to having most people use the same kind of keyboard. In essence, there is path dependence whenever some aspect of the future could easily have been way X, but it is arranged in way Y due to something that happened in the past, and now it would be hard or impossible to switch to way X. Path dependence is especially interesting when way X would have been better than way Y. Some political scientists have argued that path dependence is very common in politics. For example, in an influential paper (with over 3000 citations) <a href=\"http://www.jstor.org/discover/10.2307/2586011?uid=3739576&amp;uid=2&amp;uid=4&amp;uid=3739256&amp;sid=21101564634081\">Pierson</a> (2000, p. 251) argues that:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">Specific patterns of timing and sequence matter; a wide range of social outcomes may be possible; large consequences may result from relatively small or contingent events; particular courses of action, once introduced, can be almost impossible to reverse; and consequently, political development is punctuated by critical moments or junctures that shape the basic contours of social life.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">The concept of a trajectory change is also closely related to the concept of a historical contingency. If Thomas Edison had not invented the light bulb, someone else would have done it later. In this sense, it is not historically contingent that we have light bulbs, and the most obvious benefits from Thomas Edison inventing the light bulb are proximate benefits and benefits from speeding up development. Something analogous is probably true of many other technological innovations such as computers, candles, wheelbarrows, object-oriented programming, and the printing press. Some important examples of historical contingencies: the rise of Christianity, the creation of the US Constitution, and the writings of Karl Marx. Various aspects of Christian morality influence the world today in significant ways, but the fact that those aspects of morality, in exactly those ways, were part of a dominant world religion was historically contingent. And therefore events like Jesus's death and Paul writing his epistles are examples of trajectory changes. Likewise, the US Constitution was the product of deliberation among a specific set of men, the document affects government policy today and will affect it for the foreseeable future, but it could easily have been a different document. And now that the document exists in its specific legal and historical context, it is challenging to make changes to it, so the change is somewhat self-reinforcing.</p>\n<h1 id=\"Some_small_trajectory_changes_could_be_suboptimal\">Some small trajectory changes could be suboptimal</h1>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; background-position: initial initial; background-repeat: initial initial;\">Persistent trajectory changes that do not involve existential catastrophes could have great significance for shaping the far future. It is unlikely that the far future will inherit many of our institutions exactly as they are, but <strong>various aspects of the far future\u2014including social norms, values, political systems, and perhaps even some technologies\u2014may be path dependent on what happens now, and sometimes in suboptimal ways.</strong> In general, it is reasonable to assume that if there is some problem that might exist in the future and we can do something to fix it now, future people would also be able to solve that problem. But if values or social norms change, they might not agree that some things we think are problems <em>really are</em> problems. Or, if people make the wrong decisions now, certain standards or conventions may get entrenched, and resulting problems may be too expensive to be worth fixing. For further categories of examples of path-dependent aspects of the far future, see <a href=\"http://www.overcomingbias.com/2009/12/long-legacies.html\">these</a>&nbsp;<a href=\"http://www.overcomingbias.com/2012/10/how-plastic-are-people.html\">posts</a>&nbsp;by <a href=\"http://hanson.gmu.edu/\">Robin Hanson</a>.</p>\n<h1 id=\"The_astronomical_waste_argument_and_trajectory_changes\">The astronomical waste argument and trajectory changes</h1>\n<p class=\"MsoNormal\">Bostrom\u2019s argument only works if reducing existential risk is the most effective way of maximizing humanity\u2019s future potential. But<strong> there is no robust argument that trying to reduce existential risk is a more effective way of shaping the far future than trying to create other positive trajectory changes. </strong>Bostrom\u2019s argument for the overwhelming importance of reducing existential risk can be summarized as follows:<strong></strong></p>\n<ol>\n<li><span style=\"text-indent: -0.25in;\">The expected size of humanity's future influence is astronomically great.</span></li>\n<li><span style=\"text-indent: -0.25in;\">If the expected size of humanity's future influence is astronomically great, then the expected value of the future is astronomically great.</span></li>\n<li><span style=\"text-indent: -0.25in;\">If&nbsp;the expected value of the future is astronomically great, then what matters most is that we maximize humanity\u2019s long-term potential.</span></li>\n<li><span style=\"text-indent: -0.25in;\">Some of our actions are expected to reduce existential risk in not-ridiculously-small ways.</span></li>\n<li><span style=\"text-indent: -0.25in;\">If what matters most is that we maximize humanity\u2019s future potential and some of our actions are expected to reduce existential risk in not-ridiculously-small ways, what it is best to do is primarily determined by how our actions are expected to reduce existential risk.</span></li>\n<li><span style=\"text-indent: -0.25in;\">Therefore, what it is best to do is primarily determined by how our actions are expected to reduce existential risk.</span></li>\n</ol>\n<p><span style=\"text-indent: -0.25in;\">Call that the \u201castronomical waste\u201d argument.</span></p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">It is unclear whether premise (5) is true because it is unclear whether trying to reduce existential risk is the most effective way of maximizing humanity\u2019s future potential. For all we know, it could be more effective to try to create other positive trajectory changes. Clearly, it would be better to prevent extinction than to improve our social norms in a way that indirectly makes the future go one millionth better, but, in general, \u201cX is a bigger problem than Y\u201d is only a <a href=\"http://blog.givewell.org/2009/04/20/the-most-important-problem-may-not-be-the-best-charitable-cause/\">weak argument</a> that \u201ctrying to address X is more important than trying to address Y.\u201d To be strong, the argument must be supplemented by looking at many other considerations related to X and Y, such as how much effort is going into solving X and Y, how tractable X and Y are, how much X and Y could use additional resources, and whether there are subsets of X or Y that are especially strong in terms of these considerations.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">Bostrom <em>does</em> have arguments that speeding up development and providing proximate benefits are not as important, in themselves, as reducing existential risk. And these arguments, I believe, have some plausibility. <strong>Since we don\u2019t have an argument that reducing existential risk is better than trying to create other positive trajectory changes and an existential catastrophe is one type of trajectory change, it seems more reasonable for defenders of the astronomical waste argument to focus on trajectory changes in general.</strong> It would be better to replace the last two steps of the above argument with:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in; text-indent: -.25in;\">4\u2019 &nbsp; Some of our actions are expected to change our development trajectory in not-ridiculously-small ways.</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in; text-indent: -.25in;\">5\u2019. &nbsp;If what matters most is that we maximize humanity\u2019s future potential and some of our actions are expected to change our development trajectory in not-ridiculously-small ways, what it is best to do is primarily determined by how our actions are expected to change our development trajectory.</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in; text-indent: -.25in;\">6\u2019. &nbsp;Therefore, what it is best to do is primarily determined by how our actions are expected to change our development trajectory.</p>\n<p class=\"MsoNormal\">This seems to be a strictly more plausible claim than the original one, though it is less focused.</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; background-position: initial initial; background-repeat: initial initial;\">In response to the arguments in this post, which I e-mailed him in advance, Bostrom wrote a reply (see the end of the post). The key comment, from my perspective, is:</p>\n<p class=\"MsoNormal\" style=\"margin-left: .5in;\">\u201cMany trajectory changes are already encompassed within the notion of an existential catastrophe. &nbsp;Becoming permanently locked into some radically suboptimal state is an xrisk. &nbsp;The notion is more useful to the extent that likely scenarios fall relatively sharply into two distinct categories---very good ones and very bad ones. &nbsp;To the extent that there is a wide range of scenarios that are roughly equally plausible and that vary continuously in the degree to which the trajectory is good, the existential risk concept will be a less useful tool for thinking about our choices. &nbsp;One would then have to resort to a more complicated calculation. &nbsp;However, extinction is quite dichotomous, and there is also a thought that many sufficiently good future civilizations would over time asymptote to the optimal track.\u201d</p>\n<p class=\"MsoNormal\" style=\"margin-bottom: 0.0001pt; background-position: initial initial; background-repeat: initial initial;\">I agree that a key question here is whether there is a very large range of plausible equilibria for advanced civilizations, or whether civilizations that manage to survive long enough naturally converge on something close to the best possible outcome. The more confidence one has in the second possibility, the more interesting existential risk is as a concept. The less confidence one has in the second possibility, the more interesting trajectory changes in general are. However, I would emphasize that unless we can be highly confident in the second possibility, it seems that we cannot be confident that reducing existential risk is more important than creating other positive trajectory changes because of the astronomical waste argument alone. This would turn on further considerations of the sort I described above.</p>\n<h1 id=\"Broad_and_narrow_strategies_for_shaping_the_far_future\">Broad and narrow strategies for shaping the far future</h1>\n<p class=\"MsoNormal\">Both the astronomical waste argument and the fixed up version of that argument conclude that what matters most is how our actions affect the far future. I am very sympathetic to this viewpoint, abstractly considered, but I think its practical implications are highly uncertain. There is a spectrum of strategies for shaping the far future that ranges from the very targeted (e.g., stop that asteroid from hitting the Earth) to very broad (e.g., create economic growth, help the poor, provide education programs for talented youth), with options like \u201ctell powerful people about the importance of shaping the far future\u201d in between. The limiting case of breadth might be just optimizing for proximate benefits or for speeding up development. Defenders of the astronomical waste argument tend to be on the highly targeted end of this spectrum. I think it\u2019s a very interesting question where on this spectrum we should prefer to be, other things being equal, and it\u2019s a topic I plan to return to in the future.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">The arguments I\u2019ve offered above favor broader strategies for shaping the far future, though they don\u2019t settle the issue. The main reason I say this is that <strong>the best ways of creating positive trajectory changes may be very broad and general, whereas the best ways of reducing existential risk may be more narrow and specific.</strong> For example, it may be reasonable to try to assess, in detail, questions like, \u201cWhat are the largest specific existential risks?\u201d and, \u201cWhat are the most effective ways of reducing those specific risks?\u201d In contrast, it seems less promising to try to make specific guesses about how we might create smaller positive trajectory changes because there are so many possibilities and many trajectory changes do not have significance that is predictable in advance. No one could have predicted the persistent ripple effects that Jesus's life had, for example. In other cases\u2014such as the framing of the US Constitution\u2014it's clear that a decision has trajectory change potential, but it would be hard to specify, in advance, which concrete measures should be taken. In general, it seems that the worse you are at predicting some phenomenon that is critical to your plans, the less your plans should depend on specific predictions about that phenomenon. Because of this, promising ways to create positive trajectory changes in the world may be more broad than the most promising ways of trying to reduce existential risk specifically. Improving education, improving parenting, improving science, improving our political system, spreading humanitarian values, or otherwise improving our collective wisdom as stewards of the future could, I believe, create many small, unpredictable positive trajectory changes.</p>\n<p class=\"MsoNormal\" style=\"text-indent: .5in;\">I do not mean to suggest that broad approaches are necessarily best, only that people interested in shaping the far future should take them more seriously than they currently do. The way I see the trade-off between highly targeted strategies and highly broad strategies is as follows. Highly targeted strategies for shaping the far future often depend on highly speculative plans, often with many steps, which are hard to execute. We often have very little sense of whether we are making valuable progress on AI risk research or geo-engineering research. On the other hand, highly broad strategies must rely on implicit assumptions about the ripple effects of doing good in more ordinary ways. It is very subtle and speculative to say how ordinary actions are related to positive trajectory changes, and estimating magnitudes seems extremely challenging. Considering these trade-offs in specific cases seems like a promising area for additional research.<strong></strong></p>\n<h1 id=\"Summary\">Summary</h1>\n<p class=\"MsoNormal\">In this post, I argued that:</p>\n<ol>\n<li><span style=\"text-indent: -0.25in;\">The astronomical waste argument becomes strictly more plausible if we replace the idea of minimizing existential risk with the idea of creating positive trajectory changes.</span></li>\n<li><span style=\"text-indent: -0.25in;\">There are many ways in which our actions could unpredictably affect our general development trajectory, and therefore many ways in which our actions could shape the far future for the better. This is one reason to favor broad strategies for shaping the far future.</span></li>\n</ol><!--[if !supportLists]-->\n<p>The trajectory change perspective may have other strategic implications for people who are concerned about maximizing humanity\u2019s long-term potential. I plan to write about these implications in the future.<a name=\"_ednref1\" href=\"file:///C:/Users/Nick%20Beckstead/Desktop/Dropbox/Blogposts/Trajectory%20changes%20blogpost%201.5.docx#_edn1\"><span class=\"MsoEndnoteReference\"><span class=\"MsoEndnoteReference\"><span style=\"font-size: 11pt; line-height: 17px; font-family: Calibri, sans-serif;\">[i]</span></span></span></a></p>\n<h1 id=\"Comment_from_Nick_Bostrom_on_this_post\">Comment from Nick Bostrom on this post</h1>\n<p class=\"MsoNormal\">[What follows is an e-mail response from Nick Bostrom. He suggested that I share his comment along with the post. Note that I added a couple of small clarifications to this post (noted above) in response to Bostrom's comment.]</p>\n<p class=\"MsoNormal\">One can arrive at a more probably correct principle by weakening, eventually arriving at something like 'do what is best' or 'maximize expected good'. &nbsp;There the well-trained analytic philosopher could rest, having achieved perfect sterility. &nbsp;Of course, to get something fruitful, one has to look at the world not just at our concepts.</p>\n<p class=\"MsoNormal\">Many trajectory changes are already encompassed within the notion of an existential catastrophe. &nbsp;Becoming permanently locked into some radically suboptimal state is an xrisk. &nbsp;The notion is more useful to the extent that likely scenarios fall relatively sharply into two distinct categories---very good ones and very bad ones. &nbsp;To the extent that there is a wide range of scenarios that are roughly equally plausible and that vary continuously in the degree to which the trajectory is good, the existential risk concept will be a less useful tool for thinking about our choices. &nbsp;One would then have to resort to a more complicated calculation. &nbsp;However, extinction is quite dichotomous, and there is also a thought that many sufficiently good future civilizations would over time asymptote to the optimal track.</p>\n<p class=\"MsoNormal\">In a more extended and careful analysis there are good reasons to consider second-order effects that are not captured by the simple concept of existential risk. &nbsp;Reducing the probability of negative-value outcomes is obviously important, and some parameters such as global values and coordination may admit of more-or-less continuous variation in a certain class of scenarios and might affect the value of the long-term outcome in correspondingly continuous ways. &nbsp;(The degree to which these complications loom large also depends on some unsettled issues in axiology; so in an all-things-considered assessment, the proper handling of normative uncertainty becomes important. &nbsp;In fact, creating a future civilization that can be entrusted to resolve normative uncertainty well wherever an epistemic resolution is possible, and to find widely acceptable and mutually beneficial compromises to the extent such resolution is not possible---this seems to me like a promising convergence point for action.)</p>\n<p class=\"MsoNormal\">It is not part of the xrisk concept or the maxipok principle that we ought to adopt some maximally direct and concrete method of reducing existential risk (such as asteroid defense): whether one best reduces xrisk through direct or indirect means is an altogether separate question.</p>\n<p>&nbsp;</p>\n<div>\n<hr size=\"1\">\n<!--[endif]-->\n<div id=\"edn1\">\n<p class=\"MsoEndnoteText\"><a name=\"_edn1\" href=\"file:///C:/Users/Nick%20Beckstead/Desktop/Dropbox/Blogposts/Trajectory%20changes%20blogpost%201.5.docx#_ednref1\"><span class=\"MsoEndnoteReference\"><!--[if !supportFootnotes]--><span class=\"MsoEndnoteReference\"><span style=\"font-size: 10.0pt; line-height: 115%; font-family: &quot;Calibri&quot;,&quot;sans-serif&quot;; mso-ascii-theme-font: minor-latin; mso-fareast-font-family: Calibri; mso-fareast-theme-font: minor-latin; mso-hansi-theme-font: minor-latin; mso-bidi-font-family: &quot;Times New Roman&quot;; mso-bidi-theme-font: minor-bidi; mso-ansi-language: EN-US; mso-fareast-language: EN-US; mso-bidi-language: AR-SA;\">[i]</span></span><!--[endif]--></span></a> I am grateful to Nick Bostrom, Paul Christiano, Luke Muehlhauser, Vipul Naik, Carl Shulman, and Jonah Sinick for feedback on earlier drafts of this post.</p>\n</div>\n</div>", "sections": [{"title": "Path-dependence and trajectory changes", "anchor": "Path_dependence_and_trajectory_changes", "level": 1}, {"title": "Some small trajectory changes could be suboptimal", "anchor": "Some_small_trajectory_changes_could_be_suboptimal", "level": 1}, {"title": "The astronomical waste argument and trajectory changes", "anchor": "The_astronomical_waste_argument_and_trajectory_changes", "level": 1}, {"title": "Broad and narrow strategies for shaping the far future", "anchor": "Broad_and_narrow_strategies_for_shaping_the_far_future", "level": 1}, {"title": "Summary", "anchor": "Summary", "level": 1}, {"title": "Comment from Nick Bostrom on this post", "anchor": "Comment_from_Nick_Bostrom_on_this_post", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "38 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5GskScdvYXBpL78wL", "2ftJ38y9SRBCBsCzy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-27T11:10:23.014Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne, social meetup: 31 May 2013 07:00PM", "slug": "meetup-melbourne-social-meetup-31-may-2013-07-00pm", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.402Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RyanCarey", "createdAt": "2011-04-27T00:19:14.586Z", "isAdmin": false, "displayName": "RyanCarey"}, "userId": "CBkbKSCEzEK2kLQww", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PteQEPtPXgYoRg5Sg/meetup-melbourne-social-meetup-31-may-2013-07-00pm", "pageUrlRelative": "/posts/PteQEPtPXgYoRg5Sg/meetup-melbourne-social-meetup-31-may-2013-07-00pm", "linkUrl": "https://www.lesswrong.com/posts/PteQEPtPXgYoRg5Sg/meetup-melbourne-social-meetup-31-may-2013-07-00pm", "postedAtFormatted": "Monday, May 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%2C%20social%20meetup%3A%2031%20May%202013%2007%3A00PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%2C%20social%20meetup%3A%2031%20May%202013%2007%3A00PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPteQEPtPXgYoRg5Sg%2Fmeetup-melbourne-social-meetup-31-may-2013-07-00pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%2C%20social%20meetup%3A%2031%20May%202013%2007%3A00PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPteQEPtPXgYoRg5Sg%2Fmeetup-melbourne-social-meetup-31-may-2013-07-00pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPteQEPtPXgYoRg5Sg%2Fmeetup-melbourne-social-meetup-31-may-2013-07-00pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 142, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n7'>Melbourne, social meetup: 31 May 2013 07:00PM</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">31 May 2013 09:09:16PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Malvern East</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>You probably all think we're about due for a practical rationality meetup,\nbut not quite - it's the fifth Friday of the month,\nso come to my place instead!</p>\n\n<p>Brayden will share stories from his San Francisco trip. Also, Chris will come, you can meet a couple of my non LW rationalist friends; we'll likely get Thai.\nGood ways to get there by public transport are walking from Darling station (5mins) or getting a lift from Caulfield by calling me on 0413275523. The address is available via the Google Group.\nAs usual, those who commit to come are rewarded with an upvote.\nYou're welcome to come any time from 6.30</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n7'>Melbourne, social meetup: 31 May 2013 07:00PM</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PteQEPtPXgYoRg5Sg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2126567471853646e-06, "legacy": true, "legacyId": "22732", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne__social_meetup__31_May_2013_07_00PM\">Discussion article for the meetup : <a href=\"/meetups/n7\">Melbourne, social meetup: 31 May 2013 07:00PM</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">31 May 2013 09:09:16PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Malvern East</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>You probably all think we're about due for a practical rationality meetup,\nbut not quite - it's the fifth Friday of the month,\nso come to my place instead!</p>\n\n<p>Brayden will share stories from his San Francisco trip. Also, Chris will come, you can meet a couple of my non LW rationalist friends; we'll likely get Thai.\nGood ways to get there by public transport are walking from Darling station (5mins) or getting a lift from Caulfield by calling me on 0413275523. The address is available via the Google Group.\nAs usual, those who commit to come are rewarded with an upvote.\nYou're welcome to come any time from 6.30</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne__social_meetup__31_May_2013_07_00PM1\">Discussion article for the meetup : <a href=\"/meetups/n7\">Melbourne, social meetup: 31 May 2013 07:00PM</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne, social meetup: 31 May 2013 07:00PM", "anchor": "Discussion_article_for_the_meetup___Melbourne__social_meetup__31_May_2013_07_00PM", "level": 1}, {"title": "Discussion article for the meetup : Melbourne, social meetup: 31 May 2013 07:00PM", "anchor": "Discussion_article_for_the_meetup___Melbourne__social_meetup__31_May_2013_07_00PM1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-27T18:31:41.379Z", "modifiedAt": null, "url": null, "title": "The Centre for Applied Rationality: a year later from a (somewhat) outside perspective ", "slug": "the-centre-for-applied-rationality-a-year-later-from-a", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.433Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a", "pageUrlRelative": "/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a", "linkUrl": "https://www.lesswrong.com/posts/zqqQDtsWGpXN3wBLZ/the-centre-for-applied-rationality-a-year-later-from-a", "postedAtFormatted": "Monday, May 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Centre%20for%20Applied%20Rationality%3A%20a%20year%20later%20from%20a%20(somewhat)%20outside%20perspective%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Centre%20for%20Applied%20Rationality%3A%20a%20year%20later%20from%20a%20(somewhat)%20outside%20perspective%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzqqQDtsWGpXN3wBLZ%2Fthe-centre-for-applied-rationality-a-year-later-from-a%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Centre%20for%20Applied%20Rationality%3A%20a%20year%20later%20from%20a%20(somewhat)%20outside%20perspective%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzqqQDtsWGpXN3wBLZ%2Fthe-centre-for-applied-rationality-a-year-later-from-a", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzqqQDtsWGpXN3wBLZ%2Fthe-centre-for-applied-rationality-a-year-later-from-a", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1515, "htmlBody": "<p>I recently had the privilege of being a CFAR alumni volunteering at a later workshop, which is a fascinating thing to do, and put me in a position both to evaluate how much of a difference the first workshop actually made in my life, and to see how the workshops themselves have evolved.&nbsp;</p>\n<p>Exactly a year ago, I attended one of the first <a href=\"/lw/b98/minicamps_on_rationality_and_awesomeness_may_1113/\">workshops</a>, back when they were still inexplicably called &ldquo;minicamps&rdquo;. I wasn't sure what to expect, and I especially wasn't sure why I had been accepted. But I bravely bullied the nursing faculty staff until they reluctantly let me switch a day of clinical around, and later&nbsp;stumbled off my plane into the San Francisco airport in a haze of exhaustion. The workshop spat me out three days later, twice as exhausted, with teetering piles of ideas and very little time or energy to apply them. I left with a list of annual goals, which I had never bothered to have before, and a feeling that more was possible&ndash;this included the feeling that more would have been possible if the workshop had been longer and less chaotic, if I had slept more the week before, if I hadn't had to rush out on Sunday evening to catch a plane and miss the social.&nbsp;</p>\n<p>Like I frequently do on Less Wrong the website, I left the minicamp feeling a bit like an outsider, but also a bit like I had come home. As well as my written goals, I made an unwritten&nbsp;pre-commitment&nbsp;to come back to San Francisco later, for longer, and see whether I could make the \"more is possible\" in my head more specific. Of my thirteen written goals on my list, I fully accomplished only four and partially accomplished five, but I did make it back to San Francisco, at the opportunity cost of four weeks of sacrificed hospital shifts.&nbsp;</p>\n<p>A week or so into my stay, while I shifted around between different rationalist shared houses and attempted to max out interesting-conversations-for-day, I found out that CFAR was holding another May workshop. I offered to volunteer, proved my sincerity by spending 6 hours printing and sticking nametags, and lived on site for another 4-day weekend of delightful information overload and limited sleep.&nbsp;</p>\n<p>Before the May 2012 workshop, I had a low prior that any four-day workshop could be life-changing in a major way. A four-year nursing degree, okay&ndash;I've successfully retrained my social skills and my <a href=\"/lw/4fo/ability_to_react/\">ability to react under pressure</a> by putting myself in particular situations over and over and over and over again. Four days? Nah. Brains don't work that way.&nbsp;</p>\n<p>In my experience, it's exceedingly hard for the human brain to do&nbsp;<em>anything&nbsp;</em>deliberately. In Kahneman-speak, habits are System 1, effortless and automatic. Doing things on purpose involves System 2, effortful and a bit aversive. I could have had a&nbsp;<em>much&nbsp;</em>better experience in my <a href=\"/lw/gnv/learning_critical_thinking_a_personal_example/\">final intensive care clinical</a> if I'd though to open up my workshop notes and tried to address the causes of aversions, or use offline time to train habits, or, y'know, do&nbsp;<em>anything&nbsp;</em>on purpose instead of floundering around trying things at random until they worked.&nbsp;</p>\n<p>(The again, I didn't apply concepts like System 1 and System 2 to myself a year ago. I read 'Thinking Fast and Slow' by Kahneman and 'Rationality and the Reflective Mind' by Stanovich as part of my minicamp goal 'read 12 hard nonfiction books this year', most of which came from the <a href=\"http://rationality.org/recommended-reading-on-rationality/\">CFAR recommended reading list</a>. If my preceptor had had any idea what I was saying when I explained to her that she was running particular nursing skills on System 1, because they were engrained on the level of habit, and I was running the same tasks on System 2 in working memory because they were new and confusing to me, and that was why I appeared to have poor time management, because System 2 takes forever to do anything, this terminology might have helped. Oh, for the world where everyone knows all jargon!)</p>\n<p>...And here I am, setting aside a month of my life to think only about rationality. I can't imagine that my counterfactual self-who-didn't-attend-in-May-2012 would be here. I can't imagine that being here now will have <em>zero&nbsp;</em>effect on what I'm doing in a year, or ten years. Bingo. I did one thing deliberately!</p>\n<p><strong>So what was the May 2013 workshop actually like?</strong></p>\n<p>The curriculum has shifted around a lot in the past year, and I think with 95% probability that it's now more concretely useful. (Speaking of probabilities, the prediction markets during the workshop seemed to flow better and be more fun and interesting this time, although this may just show that I was more averse to games in general and betting in particular. In that case, yay for partly-cured aversions!)</p>\n<p>The classes are grouped in an order that allows them to build on each other usefully, and they've been honed by practice into forms that successfully teach skills, instead of just putting words in the air and on flipcharts. For example, having a personal productivity system like GTD came across as a culturally prestigious thing at the last workshop, but there wasn't a lot of useful curriculum on it. Of course, I left on this trip wanting to spend my offline month creating with a GTD system better than paper to-do lists taped to walls, so I have both motivation and a low threshold for improvement.&nbsp;</p>\n<p>There are also some completely new classes, including \"Againstness training\" by <a href=\"/user/Valentine/overview/\">Valentine</a>, which seem to relate to some of the 'reacting under pressure' stuff in interesting ways, and gave me vocabulary and techniques for something I've been doing inefficiently by trial and error for a good part of my life.</p>\n<p>In general, there are more classes about emotions, both how to deal with them when they're in the way and how to use them when they're the best tool available. Given that none of us are Spock, I think this is useful.&nbsp;</p>\n<p>Rejection therapy has morphed into a less terrifying and more helpful form with the awesome name of CoZE (Comfort Zone Expansion). I didn't personally find the original rejection therapy all that awful, but some people did, and that problem is largely solved.&nbsp;</p>\n<p>The workshops are vastly more orderly and organized. (I like to think I contributed to this slightly with my volunteer skills of keeping the fridge stocked with water bottles and calling restaurants to confirm orders and make sure food arrived on time.) Classes began and ended on time. The venue stayed tidy. The food was excellent. It was easier to get enough sleep. Etc. The May 2012 venue had a pool, and this one didn't, which made exercise harder for addicts like me. CFAR staff are talking about solving this.&nbsp;</p>\n<p>The workshops still aren't an easy environment for introverts. The negative parts of my experience in May 2012 were mostly because of this. It was easier this time, because as a volunteer I could skip classes if I started to feel socially overloaded, but periods of quiet alone time had to be effortfully carved out of the day, and at an opportunity cost of missing interesting conversations. I'm not sure if this problem is solvable without either making the workshops longer, in order to space the material out, and thus less accessible for people with jobs, or by cutting out curriculum. Either would impose a cost on the extroverts who don't want an hour at lunch to meditate or go running alone or read a sci-fi book, etc.&nbsp;</p>\n<p>In general, I found the May 2012 workshop too short and intense&ndash;we had material thrown at us at a rate far exceeding the usual human idea-digestion rate. Keeping in touch via Skype chats with other participants helped. CFAR now does official followups with participants for six weeks following the workshop.&nbsp;</p>\n<p>Meeting the other participants was, as usual, the best part of the weekend. The group was quite diverse, although I was still the only health care professional there. (Whyyy???? The health care system needs more rationality <em>so </em>badly!)&nbsp;The conversations were engaging. Many of the participants seem eager to stay in touch. The May 2012 workshop has a total of six people still on the Skype chats list, which is a 75% attrition rate. CFAR is now working on strategies to help people who want to stay in touch do it successfully.&nbsp;</p>\n<p><strong>Conclusions?</strong></p>\n<p>I thought the May 2012 workshop was awesome. I thought the May 2013 workshop was about an order of magnitude more awesome. I would say that now is a great time to attend a CFAR workshop...except that the organization is financially stable and likely to still be around in a year and producing even <em>better </em>workshops. So I'm not sure. Then again, rationality skills have compound interest&ndash;the value of learning some new skills now, even if they amount more to vocab words and mental labels than superpowers, compounds over the year that you spend seeing all the books you read and all the opportunities you have in that framework. I'm glad I went a year ago instead of this May. I'm even more glad I had the opportunity to see the new classes and meet the new participants a year later.&nbsp;</p>\n<p><strong><br /></strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"X7v7Fyp9cgBYaMe2e": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zqqQDtsWGpXN3wBLZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 46, "baseScore": 65, "extendedScore": null, "score": 0.00018, "legacy": true, "legacyId": "22711", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 65, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I recently had the privilege of being a CFAR alumni volunteering at a later workshop, which is a fascinating thing to do, and put me in a position both to evaluate how much of a difference the first workshop actually made in my life, and to see how the workshops themselves have evolved.&nbsp;</p>\n<p>Exactly a year ago, I attended one of the first <a href=\"/lw/b98/minicamps_on_rationality_and_awesomeness_may_1113/\">workshops</a>, back when they were still inexplicably called \u201cminicamps\u201d. I wasn't sure what to expect, and I especially wasn't sure why I had been accepted. But I bravely bullied the nursing faculty staff until they reluctantly let me switch a day of clinical around, and later&nbsp;stumbled off my plane into the San Francisco airport in a haze of exhaustion. The workshop spat me out three days later, twice as exhausted, with teetering piles of ideas and very little time or energy to apply them. I left with a list of annual goals, which I had never bothered to have before, and a feeling that more was possible\u2013this included the feeling that more would have been possible if the workshop had been longer and less chaotic, if I had slept more the week before, if I hadn't had to rush out on Sunday evening to catch a plane and miss the social.&nbsp;</p>\n<p>Like I frequently do on Less Wrong the website, I left the minicamp feeling a bit like an outsider, but also a bit like I had come home. As well as my written goals, I made an unwritten&nbsp;pre-commitment&nbsp;to come back to San Francisco later, for longer, and see whether I could make the \"more is possible\" in my head more specific. Of my thirteen written goals on my list, I fully accomplished only four and partially accomplished five, but I did make it back to San Francisco, at the opportunity cost of four weeks of sacrificed hospital shifts.&nbsp;</p>\n<p>A week or so into my stay, while I shifted around between different rationalist shared houses and attempted to max out interesting-conversations-for-day, I found out that CFAR was holding another May workshop. I offered to volunteer, proved my sincerity by spending 6 hours printing and sticking nametags, and lived on site for another 4-day weekend of delightful information overload and limited sleep.&nbsp;</p>\n<p>Before the May 2012 workshop, I had a low prior that any four-day workshop could be life-changing in a major way. A four-year nursing degree, okay\u2013I've successfully retrained my social skills and my <a href=\"/lw/4fo/ability_to_react/\">ability to react under pressure</a> by putting myself in particular situations over and over and over and over again. Four days? Nah. Brains don't work that way.&nbsp;</p>\n<p>In my experience, it's exceedingly hard for the human brain to do&nbsp;<em>anything&nbsp;</em>deliberately. In Kahneman-speak, habits are System 1, effortless and automatic. Doing things on purpose involves System 2, effortful and a bit aversive. I could have had a&nbsp;<em>much&nbsp;</em>better experience in my <a href=\"/lw/gnv/learning_critical_thinking_a_personal_example/\">final intensive care clinical</a> if I'd though to open up my workshop notes and tried to address the causes of aversions, or use offline time to train habits, or, y'know, do&nbsp;<em>anything&nbsp;</em>on purpose instead of floundering around trying things at random until they worked.&nbsp;</p>\n<p>(The again, I didn't apply concepts like System 1 and System 2 to myself a year ago. I read 'Thinking Fast and Slow' by Kahneman and 'Rationality and the Reflective Mind' by Stanovich as part of my minicamp goal 'read 12 hard nonfiction books this year', most of which came from the <a href=\"http://rationality.org/recommended-reading-on-rationality/\">CFAR recommended reading list</a>. If my preceptor had had any idea what I was saying when I explained to her that she was running particular nursing skills on System 1, because they were engrained on the level of habit, and I was running the same tasks on System 2 in working memory because they were new and confusing to me, and that was why I appeared to have poor time management, because System 2 takes forever to do anything, this terminology might have helped. Oh, for the world where everyone knows all jargon!)</p>\n<p>...And here I am, setting aside a month of my life to think only about rationality. I can't imagine that my counterfactual self-who-didn't-attend-in-May-2012 would be here. I can't imagine that being here now will have <em>zero&nbsp;</em>effect on what I'm doing in a year, or ten years. Bingo. I did one thing deliberately!</p>\n<p><strong id=\"So_what_was_the_May_2013_workshop_actually_like_\">So what was the May 2013 workshop actually like?</strong></p>\n<p>The curriculum has shifted around a lot in the past year, and I think with 95% probability that it's now more concretely useful. (Speaking of probabilities, the prediction markets during the workshop seemed to flow better and be more fun and interesting this time, although this may just show that I was more averse to games in general and betting in particular. In that case, yay for partly-cured aversions!)</p>\n<p>The classes are grouped in an order that allows them to build on each other usefully, and they've been honed by practice into forms that successfully teach skills, instead of just putting words in the air and on flipcharts. For example, having a personal productivity system like GTD came across as a culturally prestigious thing at the last workshop, but there wasn't a lot of useful curriculum on it. Of course, I left on this trip wanting to spend my offline month creating with a GTD system better than paper to-do lists taped to walls, so I have both motivation and a low threshold for improvement.&nbsp;</p>\n<p>There are also some completely new classes, including \"Againstness training\" by <a href=\"/user/Valentine/overview/\">Valentine</a>, which seem to relate to some of the 'reacting under pressure' stuff in interesting ways, and gave me vocabulary and techniques for something I've been doing inefficiently by trial and error for a good part of my life.</p>\n<p>In general, there are more classes about emotions, both how to deal with them when they're in the way and how to use them when they're the best tool available. Given that none of us are Spock, I think this is useful.&nbsp;</p>\n<p>Rejection therapy has morphed into a less terrifying and more helpful form with the awesome name of CoZE (Comfort Zone Expansion). I didn't personally find the original rejection therapy all that awful, but some people did, and that problem is largely solved.&nbsp;</p>\n<p>The workshops are vastly more orderly and organized. (I like to think I contributed to this slightly with my volunteer skills of keeping the fridge stocked with water bottles and calling restaurants to confirm orders and make sure food arrived on time.) Classes began and ended on time. The venue stayed tidy. The food was excellent. It was easier to get enough sleep. Etc. The May 2012 venue had a pool, and this one didn't, which made exercise harder for addicts like me. CFAR staff are talking about solving this.&nbsp;</p>\n<p>The workshops still aren't an easy environment for introverts. The negative parts of my experience in May 2012 were mostly because of this. It was easier this time, because as a volunteer I could skip classes if I started to feel socially overloaded, but periods of quiet alone time had to be effortfully carved out of the day, and at an opportunity cost of missing interesting conversations. I'm not sure if this problem is solvable without either making the workshops longer, in order to space the material out, and thus less accessible for people with jobs, or by cutting out curriculum. Either would impose a cost on the extroverts who don't want an hour at lunch to meditate or go running alone or read a sci-fi book, etc.&nbsp;</p>\n<p>In general, I found the May 2012 workshop too short and intense\u2013we had material thrown at us at a rate far exceeding the usual human idea-digestion rate. Keeping in touch via Skype chats with other participants helped. CFAR now does official followups with participants for six weeks following the workshop.&nbsp;</p>\n<p>Meeting the other participants was, as usual, the best part of the weekend. The group was quite diverse, although I was still the only health care professional there. (Whyyy???? The health care system needs more rationality <em>so </em>badly!)&nbsp;The conversations were engaging. Many of the participants seem eager to stay in touch. The May 2012 workshop has a total of six people still on the Skype chats list, which is a 75% attrition rate. CFAR is now working on strategies to help people who want to stay in touch do it successfully.&nbsp;</p>\n<p><strong id=\"Conclusions_\">Conclusions?</strong></p>\n<p>I thought the May 2012 workshop was awesome. I thought the May 2013 workshop was about an order of magnitude more awesome. I would say that now is a great time to attend a CFAR workshop...except that the organization is financially stable and likely to still be around in a year and producing even <em>better </em>workshops. So I'm not sure. Then again, rationality skills have compound interest\u2013the value of learning some new skills now, even if they amount more to vocab words and mental labels than superpowers, compounds over the year that you spend seeing all the books you read and all the opportunities you have in that framework. I'm glad I went a year ago instead of this May. I'm even more glad I had the opportunity to see the new classes and meet the new participants a year later.&nbsp;</p>\n<p><strong><br></strong></p>", "sections": [{"title": "So what was the May 2013 workshop actually like?", "anchor": "So_what_was_the_May_2013_workshop_actually_like_", "level": 1}, {"title": "Conclusions?", "anchor": "Conclusions_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "102 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 102, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["fkhbBE2ZTSytvsy9x", "p67vi8kk3LJCjL2v7", "pp62TwbtyFnTZe4Nb"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-27T20:13:15.166Z", "modifiedAt": null, "url": null, "title": "[LINK] Bets do not (necessarily) reveal beliefs", "slug": "link-bets-do-not-necessarily-reveal-beliefs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:31.540Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ts4KmAR8aJoGMawLb/link-bets-do-not-necessarily-reveal-beliefs", "pageUrlRelative": "/posts/ts4KmAR8aJoGMawLb/link-bets-do-not-necessarily-reveal-beliefs", "linkUrl": "https://www.lesswrong.com/posts/ts4KmAR8aJoGMawLb/link-bets-do-not-necessarily-reveal-beliefs", "postedAtFormatted": "Monday, May 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Bets%20do%20not%20(necessarily)%20reveal%20beliefs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Bets%20do%20not%20(necessarily)%20reveal%20beliefs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fts4KmAR8aJoGMawLb%2Flink-bets-do-not-necessarily-reveal-beliefs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Bets%20do%20not%20(necessarily)%20reveal%20beliefs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fts4KmAR8aJoGMawLb%2Flink-bets-do-not-necessarily-reveal-beliefs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fts4KmAR8aJoGMawLb%2Flink-bets-do-not-necessarily-reveal-beliefs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 138, "htmlBody": "<p>When does a bet fail to reveal your true beliefs? When it hedges a risk in your portfolio.</p>\n<p>If this claim does not immediately strike you as obviously true, you may benefit from reading <a href=\"http://noahpinionblog.blogspot.ca/2013/05/bets-do-not-necessarily-reveal-beliefs.html\">this post</a> by econblogger Noah Smith. Excerpt:</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"font-size: 13px; color: #222222; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; line-height: 18px;\">...Alex Tabarrok famously declared that \"</span><a style=\"font-size: 13px; text-decoration: none; color: #7c93a1; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; line-height: 18px;\" href=\"http://marginalrevolution.com/marginalrevolution/2012/11/a-bet-is-a-tax-on-bullshit.html\">a bet is a tax on bullshit</a><span style=\"font-size: 13px; color: #222222; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; line-height: 18px;\">\".</span></p>\n<p><span style=\"color: #222222; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; font-size: 13px; line-height: 18px;\">But this idea, attractive as it is, is not quite true. The reason is something that I've decided to call the Fundamental Error of Risk. It's a mistake that most people make (myself often included!), and that an intro finance class spends months correcting. The mistake is looking at the risk and return of single assets instead of total portfolios. Basically, the risk of an asset - which includes a bet! - is based mainly on how that asset relates to&nbsp;</span><em style=\"color: #222222; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; font-size: 13px; line-height: 18px;\">other assets in your portfolio</em><span style=\"color: #222222; font-family: Arial, Tahoma, Helvetica, FreeSans, sans-serif; font-size: 13px; line-height: 18px;\">.</span></p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ts4KmAR8aJoGMawLb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 20, "extendedScore": null, "score": 1.2130579661011189e-06, "legacy": true, "legacyId": "22733", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-28T01:55:20.000Z", "modifiedAt": null, "url": null, "title": "Transhumanist Fables", "slug": "transhumanist-fables", "viewCount": null, "lastCommentedAt": "2020-04-27T20:53:14.496Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AYbhqi65SWzHzy7Xx/transhumanist-fables", "pageUrlRelative": "/posts/AYbhqi65SWzHzy7Xx/transhumanist-fables", "linkUrl": "https://www.lesswrong.com/posts/AYbhqi65SWzHzy7Xx/transhumanist-fables", "postedAtFormatted": "Tuesday, May 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Transhumanist%20Fables&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATranshumanist%20Fables%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYbhqi65SWzHzy7Xx%2Ftranshumanist-fables%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Transhumanist%20Fables%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYbhqi65SWzHzy7Xx%2Ftranshumanist-fables", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAYbhqi65SWzHzy7Xx%2Ftranshumanist-fables", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 800, "htmlBody": "<p>Once upon a time there were three little pigs who went out into the world to build their houses. The first pig was very lazy and built his house out of straw. The second pig was a little harder-working and built his house out of sticks. The third pig was the hardest-working of all, and built his house out of bricks. Then came the Big Bad Wolf. When he saw the house of straw, he huffed and he puffed and he blew the house down, eating the first little pig. When he saw the house of sticks, he huffed and he puffed and he blew the house down, eating the second little pig. When he saw the house of bricks, he got out a bazooka and blew the house to pieces, eating the third little pig.</p>\n<p><b>Moral:</b> Reality doesn&#8217;t grade on a curve.</p>\n<hr>\n<p>Once upon a time there was a big strong troll who lived under a bridge. A little goat went across the bridge, and the troll reached out to grab and eat the goat. &#8220;Wait, Mr. Troll!&#8221;, the goat cried. &#8220;Soon my brother is coming, and he is even bigger than I am!&#8221; The troll let the goat pass, and soon came another goat, twice as big as the first. The troll reached out to grab and eat him, but the brother likewise objected, saying <i>his</i> brother was even bigger. Sure enough, a third goat arrived at the bridge, twice as big as the second, and the troll, now ready for a very hearty dinner, reached out to grab and eat him. &#8220;Wait!&#8221; said the third goat. &#8220;My brother is the biggest of us all!&#8221;. So the troll let the third goat pass. Then came the fourth goat, who was hundreds of miles tall and blotted out the sun, whose very steps caused earthquakes and made the rivers change course. Without even noticing, he stepped on bridge and troll, pulverizing both to bits.</p>\n<p><b>Moral:</b> Sometimes growth is superexponential.</p>\n<hr>\n<p>Once upon a time, Chicken Little ran to her friend Henny Penny. &#8220;The sky is falling!&#8221; she shouted. &#8220;We must tell the king!&#8221; Henny Penny joined her, and together they headed toward the capital. On their way they run into their friend Goosey Loosey. &#8220;The sky is falling!&#8221; they shouted. &#8220;We must tell the king!&#8221; Goosey Loosey joined them, and together they headed toward the capital. On their way, they ran into the cunning Foxy Loxy. &#8220;The sky is falling!&#8221; they shouted. &#8220;We must tell the king!&#8221; &#8220;Oh,&#8221; said Foxy Loxy. &#8220;I know a shortcut to the palace. Follow me into my den.&#8221; So the birds all followed Foxy Loxy into his den, where he ate them all, laughing all the while about how gullible they were. Then an asteroid hit Earth, killing everyone.</p>\n<p><b>Moral:</b> Beware <A HREF=\"http://wiki.lesswrong.com/wiki/Absurdity_heuristic\">the absurdity heuristic</A>.</p>\n<hr>\n<p>Once upon a time, a young boy named Jack lived with his mother. Their family was very poor and owned only a single cow. &#8220;Go sell this cow at the market,&#8221; Jack&#8217;s mother told him, &#8220;so we will have food to eat for the winter.&#8221; Jack went to the market and came back with three beans. &#8220;These are magic beans!&#8221; he told his mother. &#8220;A man told me that when we plant them, they will grow into a beanstalk leading to a land of infinite riches.&#8221; His mother pooh &#8211; poohed him and threw the beans in the ground angrily. That winter, they both died of hunger.</p>\n<p><b>Moral:</b> Good decision theories should <A HREF=\"http://wiki.lesswrong.com/wiki/Pascal%27s_mugging\">be able to resist Pascal&#8217;s Mugging</A>.</p>\n<hr>\n<p>Once upon a time, there was an old woodcutter who had no son. He made a little marionette out of pine wood and named it Pinocchio. Then he wished upon a star that it could become a real boy. The star turned out to be the evil Red Fairy, who brought Pinocchio to life, but told him that if he wanted to be a real boy he must murder everyone in the village. That night, Pinocchio took his father&#8217;s saw and killed Gepetto and everyone else in town.</p>\n<p><b>Moral:</b> Never create an intelligence unless you are certain it will share your values.</p>\n<hr>\n<p>Once upon a time, an evil witch transformed a prince into a frog, telling him that only the kiss of a princess could restore him to his proper form. But although he searched around the world, he could find no princess who was willing to kiss a hideous little frog. Finally, he went to the Wise Wizard. &#8220;Gender is a social construct,&#8221; said the Wise Wizard. &#8220;Just declare your gender identity to be female, then kiss yourself on the hand or something.&#8221; So the frog did that, returned to human form, and ruled the land for many years as a wise and benevolent queen.</p>\n<p><b>Moral:</b> Ability to self-modify is just <i>ridiculously</i> powerful.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jiuackr7B5JAetbF6": 2, "hNFdS3rRiYgqqD8aM": 3, "F2XfCTxXLQBGjbm8P": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AYbhqi65SWzHzy7Xx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 84, "baseScore": 85, "extendedScore": null, "score": 0.000201, "legacy": null, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "XsMTxdQ6fprAQMoKi", "canonicalCollectionSlug": "codex", "canonicalBookId": "jF58hKP9ZLzgy22Jr", "canonicalNextPostSlug": "and-i-show-you-how-deep-the-rabbit-hole-goes", "canonicalPrevPostSlug": "beware-isolated-demands-for-rigor", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 85, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-28T06:02:07.554Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley: The Motivation Hacker by Nick Winter", "slug": "meetup-berkeley-the-motivation-hacker-by-nick-winter", "viewCount": null, "lastCommentedAt": "2013-06-06T13:23:19.387Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pqpgrND6KJnuxnn98/meetup-berkeley-the-motivation-hacker-by-nick-winter", "pageUrlRelative": "/posts/pqpgrND6KJnuxnn98/meetup-berkeley-the-motivation-hacker-by-nick-winter", "linkUrl": "https://www.lesswrong.com/posts/pqpgrND6KJnuxnn98/meetup-berkeley-the-motivation-hacker-by-nick-winter", "postedAtFormatted": "Tuesday, May 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%3A%20The%20Motivation%20Hacker%20by%20Nick%20Winter&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%3A%20The%20Motivation%20Hacker%20by%20Nick%20Winter%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqpgrND6KJnuxnn98%2Fmeetup-berkeley-the-motivation-hacker-by-nick-winter%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%3A%20The%20Motivation%20Hacker%20by%20Nick%20Winter%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqpgrND6KJnuxnn98%2Fmeetup-berkeley-the-motivation-hacker-by-nick-winter", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqpgrND6KJnuxnn98%2Fmeetup-berkeley-the-motivation-hacker-by-nick-winter", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n8'>Berkeley: The Motivation Hacker by Nick Winter</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 May 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, this week Swimmer963 will give a presentation on Nick Winter's new book <em>The Motivation Hacker</em>:</p>\n\n<p><a href=\"http://www.nickwinter.net/the-motivation-hacker\" rel=\"nofollow\">http://www.nickwinter.net/the-motivation-hacker</a></p>\n\n<p>Nick Winter is a community member, startup founder, and CFAR workshop alumnus. Thanks to Swimmer963 for giving this presentation!</p>\n\n<p>Doors open at 7:30pm on Wednesday; the presentation will start at 8pm and take roughly half an hour. Stick around afterwards to chat. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n8'>Berkeley: The Motivation Hacker by Nick Winter</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pqpgrND6KJnuxnn98", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.213493450727397e-06, "legacy": true, "legacyId": "22740", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley__The_Motivation_Hacker_by_Nick_Winter\">Discussion article for the meetup : <a href=\"/meetups/n8\">Berkeley: The Motivation Hacker by Nick Winter</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 May 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, this week Swimmer963 will give a presentation on Nick Winter's new book <em>The Motivation Hacker</em>:</p>\n\n<p><a href=\"http://www.nickwinter.net/the-motivation-hacker\" rel=\"nofollow\">http://www.nickwinter.net/the-motivation-hacker</a></p>\n\n<p>Nick Winter is a community member, startup founder, and CFAR workshop alumnus. Thanks to Swimmer963 for giving this presentation!</p>\n\n<p>Doors open at 7:30pm on Wednesday; the presentation will start at 8pm and take roughly half an hour. Stick around afterwards to chat. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley__The_Motivation_Hacker_by_Nick_Winter1\">Discussion article for the meetup : <a href=\"/meetups/n8\">Berkeley: The Motivation Hacker by Nick Winter</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley: The Motivation Hacker by Nick Winter", "anchor": "Discussion_article_for_the_meetup___Berkeley__The_Motivation_Hacker_by_Nick_Winter", "level": 1}, {"title": "Discussion article for the meetup : Berkeley: The Motivation Hacker by Nick Winter", "anchor": "Discussion_article_for_the_meetup___Berkeley__The_Motivation_Hacker_by_Nick_Winter1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-28T13:03:51.269Z", "modifiedAt": null, "url": null, "title": "Requesting advice: Doing Epistemology Right (Warning: Abstract mainstream Philosophy herein)", "slug": "requesting-advice-doing-epistemology-right-warning-abstract", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:35.877Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Carinthium", "createdAt": "2010-11-10T22:28:58.091Z", "isAdmin": false, "displayName": "Carinthium"}, "userId": "DL8CRWfXPCHYqQsv4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mq6KNAngoQZJXbCXE/requesting-advice-doing-epistemology-right-warning-abstract", "pageUrlRelative": "/posts/Mq6KNAngoQZJXbCXE/requesting-advice-doing-epistemology-right-warning-abstract", "linkUrl": "https://www.lesswrong.com/posts/Mq6KNAngoQZJXbCXE/requesting-advice-doing-epistemology-right-warning-abstract", "postedAtFormatted": "Tuesday, May 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Requesting%20advice%3A%20Doing%20Epistemology%20Right%20(Warning%3A%20Abstract%20mainstream%20Philosophy%20herein)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARequesting%20advice%3A%20Doing%20Epistemology%20Right%20(Warning%3A%20Abstract%20mainstream%20Philosophy%20herein)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMq6KNAngoQZJXbCXE%2Frequesting-advice-doing-epistemology-right-warning-abstract%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Requesting%20advice%3A%20Doing%20Epistemology%20Right%20(Warning%3A%20Abstract%20mainstream%20Philosophy%20herein)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMq6KNAngoQZJXbCXE%2Frequesting-advice-doing-epistemology-right-warning-abstract", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMq6KNAngoQZJXbCXE%2Frequesting-advice-doing-epistemology-right-warning-abstract", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 420, "htmlBody": "<div id=\"entry_t3_hjt\" class=\"content clear\">\r\n<div class=\"md\">Amongst other things I am currently a First Year Arts student at Melbourne University, doing Philosophy amongst my subjects. At the moment, I'm in several discussions with other students and my lecturers about various matters.\r\n<div>\r\n<div>\r\n<p>I have naturally read the material here, but am still not sure how to act on two questions.</p>\r\n<p>1: I've been arguing out the question of Foundationalism v.s Coherentism v.s other similiarly basic methods of justifying knowledge (e.g. infinitism, pragmatism). The discussion left off with two problems for Foundationalism.</p>\r\n<p>a: The Evil Demon argument, particularly the problem of memory. When following any piece of reason, an Evil Demon could theoretically fool my reason into thinking that it had reasoned correctly when it hadn't, or fool my memory into thinking I'd reasoned properly before with reasoning I'd never done. Since a Foundationalist either is a weak Foundationalist (and runs into severe problems) or must discard all but self-evident and incorrigible assumptions (of which memory is not one), I'm stuffed.</p>\r\n<p>(Then again, it has been argued, if a Coherentist were decieved by an evil demon they could be decieved into thinking data coheres when it doesn't. Since their belief rests upon the assumption that their beliefs cohere, should they not discard if they can't know if it coheres or not? The <em>seems to cohere </em>formulation has it's own problem)</p>\r\n<p>b: Even if that's discarded,&nbsp;there is still the problem of how Strong Foundationalist beliefs are justified within a Strong Foundationalist system. Strong Foundationalism is neither self-evident nor incorrigible, after all.</p>\r\n<p>I know myself well enough to know I have an unusually strong (even for a non-rationalist)&nbsp;irrational emotive bias in favour of Foundationalism, and even I&nbsp;begin to suspect I've lost the argument (though some people arguing on my side would disagree). Just to confirm, though- have I lost? What should I do now, either way?</p>\r\n<p>2: What&nbsp;to say on the&nbsp;question of skepticism (on which so far I've technically&nbsp;said nothing)? If I remember correctly Elizier has spoken of philosophy as how to act in the world, but I'm arguing with somebody who maintains as an axiom that the purpose of Philosophy is to find truth, whether useful or useless, in whatever area is under discussion.</p>\r\n<p>3: Finally, how do I speak intelligently on the Contextualist v.s Invariantist problem? I can see in basic that it is an empirical problem and therefore not part of abstract philosophy, but that isn't the same thing as having an answer. It would be good to know where to look up enough neuroscience to at least make an intelligent contribution to the discussion.</p>\r\n</div>\r\n</div>\r\n</div>\r\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mq6KNAngoQZJXbCXE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 1, "extendedScore": null, "score": 1.2138054982707388e-06, "legacy": true, "legacyId": "22746", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-28T13:40:50.431Z", "modifiedAt": null, "url": null, "title": "Meetup : London - Inaugural Practical Session - June 9th", "slug": "meetup-london-inaugural-practical-session-june-9th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:08.387Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hJrs7g4nPkHoWd9Nm/meetup-london-inaugural-practical-session-june-9th", "pageUrlRelative": "/posts/hJrs7g4nPkHoWd9Nm/meetup-london-inaugural-practical-session-june-9th", "linkUrl": "https://www.lesswrong.com/posts/hJrs7g4nPkHoWd9Nm/meetup-london-inaugural-practical-session-june-9th", "postedAtFormatted": "Tuesday, May 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20-%20Inaugural%20Practical%20Session%20-%20June%209th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20-%20Inaugural%20Practical%20Session%20-%20June%209th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhJrs7g4nPkHoWd9Nm%2Fmeetup-london-inaugural-practical-session-june-9th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20-%20Inaugural%20Practical%20Session%20-%20June%209th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhJrs7g4nPkHoWd9Nm%2Fmeetup-london-inaugural-practical-session-june-9th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhJrs7g4nPkHoWd9Nm%2Fmeetup-london-inaugural-practical-session-june-9th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 331, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/n9'>London - Inaugural Practical Session - June 9th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 June 2013 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Shakespeare's Head, London WC2B 6BG</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Up until now the London Less Wrong meetups have mostly just been social gatherings. Quite a few of us have expressed a desire to get more out of the group. As such, we'll be alternating the fortnightly meetups between a \"social\" emphasis and a \"practical\" emphasis.\nAs the first of our practical-oriented meetups, this session will be more structured than previous gatherings. Attendees are encouraged to think of <em>specific examples</em> of what they would like to work on in advance. This could be:</p>\n\n<ul>\n<li><p>a specific goal they wish to achieve\n<em>(\"I would like to save 60% of my monthly income\")</em></p></li>\n<li><p>a specific habit or unreasonable psychological demand they would like to overcome\n<em>(\"I would like to be able to work for four-hour stretches without losing motivation or succumbing to akrasia\")</em></p></li>\n<li><p>a specific skill they would like to develop\n<em>(\"I would like to be able to competently present material to large groups of people\")</em></p></li>\n<li><p>any other <em>specific thing they want</em> which they currently don't have to their satisfaction</p></li>\n</ul>\n\n<p>As this is our first practical, we're still experimenting with the format. In this meetup, discussion will be structured to identify common goals and desires among attendees, and to foster support and collaboration towards achieving them. We are also working on developing group social norms to provide more pleasant, productive and personally-inclusive discussion.</p>\n\n<p>Please be there for 2pm if you can. We can accommodate later arrivals, but we will be starting promptly.</p>\n\n<p>The venue is the Shakespeare's Head by Holborn tube station. Turn left out of the station exit and it's &lt;100m on your left.\nWe also have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google Group</a>. Why not join it?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/n9'>London - Inaugural Practical Session - June 9th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hJrs7g4nPkHoWd9Nm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 4, "extendedScore": null, "score": 1.2138328719196957e-06, "legacy": true, "legacyId": "22748", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London___Inaugural_Practical_Session___June_9th\">Discussion article for the meetup : <a href=\"/meetups/n9\">London - Inaugural Practical Session - June 9th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 June 2013 02:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Shakespeare's Head, London WC2B 6BG</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Up until now the London Less Wrong meetups have mostly just been social gatherings. Quite a few of us have expressed a desire to get more out of the group. As such, we'll be alternating the fortnightly meetups between a \"social\" emphasis and a \"practical\" emphasis.\nAs the first of our practical-oriented meetups, this session will be more structured than previous gatherings. Attendees are encouraged to think of <em>specific examples</em> of what they would like to work on in advance. This could be:</p>\n\n<ul>\n<li><p>a specific goal they wish to achieve\n<em>(\"I would like to save 60% of my monthly income\")</em></p></li>\n<li><p>a specific habit or unreasonable psychological demand they would like to overcome\n<em>(\"I would like to be able to work for four-hour stretches without losing motivation or succumbing to akrasia\")</em></p></li>\n<li><p>a specific skill they would like to develop\n<em>(\"I would like to be able to competently present material to large groups of people\")</em></p></li>\n<li><p>any other <em>specific thing they want</em> which they currently don't have to their satisfaction</p></li>\n</ul>\n\n<p>As this is our first practical, we're still experimenting with the format. In this meetup, discussion will be structured to identify common goals and desires among attendees, and to foster support and collaboration towards achieving them. We are also working on developing group social norms to provide more pleasant, productive and personally-inclusive discussion.</p>\n\n<p>Please be there for 2pm if you can. We can accommodate later arrivals, but we will be starting promptly.</p>\n\n<p>The venue is the Shakespeare's Head by Holborn tube station. Turn left out of the station exit and it's &lt;100m on your left.\nWe also have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google Group</a>. Why not join it?</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___London___Inaugural_Practical_Session___June_9th1\">Discussion article for the meetup : <a href=\"/meetups/n9\">London - Inaugural Practical Session - June 9th</a></h2>", "sections": [{"title": "Discussion article for the meetup : London - Inaugural Practical Session - June 9th", "anchor": "Discussion_article_for_the_meetup___London___Inaugural_Practical_Session___June_9th", "level": 1}, {"title": "Discussion article for the meetup : London - Inaugural Practical Session - June 9th", "anchor": "Discussion_article_for_the_meetup___London___Inaugural_Practical_Session___June_9th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-28T22:07:46.617Z", "modifiedAt": null, "url": null, "title": "Is there any way to avoid Post Narcissism? [with Video link]", "slug": "is-there-any-way-to-avoid-post-narcissism-with-video-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:31:37.305Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8M4jbP66esGS3MCwS/is-there-any-way-to-avoid-post-narcissism-with-video-link", "pageUrlRelative": "/posts/8M4jbP66esGS3MCwS/is-there-any-way-to-avoid-post-narcissism-with-video-link", "linkUrl": "https://www.lesswrong.com/posts/8M4jbP66esGS3MCwS/is-there-any-way-to-avoid-post-narcissism-with-video-link", "postedAtFormatted": "Tuesday, May 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20there%20any%20way%20to%20avoid%20Post%20Narcissism%3F%20%5Bwith%20Video%20link%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20there%20any%20way%20to%20avoid%20Post%20Narcissism%3F%20%5Bwith%20Video%20link%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8M4jbP66esGS3MCwS%2Fis-there-any-way-to-avoid-post-narcissism-with-video-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20there%20any%20way%20to%20avoid%20Post%20Narcissism%3F%20%5Bwith%20Video%20link%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8M4jbP66esGS3MCwS%2Fis-there-any-way-to-avoid-post-narcissism-with-video-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8M4jbP66esGS3MCwS%2Fis-there-any-way-to-avoid-post-narcissism-with-video-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 358, "htmlBody": "<p>I tried to stop posting for a semester... that didn't work. If I have an idea, I just feel like putting it out somewhere in the world, and sometimes, that is Lesswrong.</p>\n<p>Which is totally fine and doesn't worry me at all.</p>\n<p>&nbsp;</p>\n<p>But......</p>\n<p>There is another problem also related to time constraints and posting.</p>\n<p>Here is the best TED Talker, Juan Enriquez, talking about Narcissus and other greeks at 4:30 of 6 minutes.</p>\n<p><a href=\"http://goo.gl/cMQk1\">http://goo.gl/cMQk1</a></p>\n<p>I'm a Post Narcissist. I don't know how frequent that is, and only one person at FHI told me they were an email Narcissus, but maybe there are others, and more importantly, maybe there is a solution. It may not be clear to you what post Narcissism is, if so, throw your arms up in the air, and scream \"Victory!\" because you just escaped a terrible thing...</p>\n<p><em>Post Narcissism</em>: An absolutely intense eagerness to read your own posts and comments after you wrote them, accompanied by a feeling of flow while doing so, even when you would do much better to just read someone else's post or do something else altogether. Sometimes, but now always, accompanied by a low anxiety that something may be wrong with your writing, and intermittent thoughts about whether it needs changes. Just to set an arbitrary definitional threshold, if you read it three times <em>after</em> posting, you definitely have it.&nbsp;</p>\n<p><img src=\"http://andrejkoymasky.com/liv/fam/bion1/narcis01/narc1f.jpg\" alt=\"\" width=\"550\" height=\"424\" /></p>\n<p>&nbsp;</p>\n<p>Don't care about actual mirrors. Don't care about <a href=\"http://edge.org/response-detail/23876\">making enemies while self-actualizing</a>, don't care wearing beautiful&nbsp; or awful clothing or showing off whatever physical ability I may have to show off... Don't care about mentioning what makes me shy, or things I'm absolutely terrible at, but oh, the fuzzy feeling inside when reading a <em>set of words that I know is open to public scrutiny</em>. Gets my attention more than Orangutangs, South Park or family members, more than latest Google scholar new publications updates on <a href=\"/lw/58d/how_not_to_be_a_na%C3%AFve_computationalist/\">Philosophy of Mind</a>. More than the weather, an impending deadline or a self imposed rule.</p>\n<p>I know that others must suffer from this condition as I do. And maybe there is a solution... If you don't know a solution, post suggestions, if you do know a solution that has worked, please post it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8M4jbP66esGS3MCwS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 8, "extendedScore": null, "score": 1.2142081699185266e-06, "legacy": true, "legacyId": "22749", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HLadQZ6FqTTjnYpoB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-28T22:59:57.039Z", "modifiedAt": null, "url": null, "title": "Who thinks quantum computing will be necessary for AI?", "slug": "who-thinks-quantum-computing-will-be-necessary-for-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.828Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ChrisHallquist", "createdAt": "2011-05-25T19:16:15.462Z", "isAdmin": false, "displayName": "ChrisHallquist"}, "userId": "wvT2xWQqHKxkp9NWN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zrkk9ypr9S8TYiSgc/who-thinks-quantum-computing-will-be-necessary-for-ai", "pageUrlRelative": "/posts/zrkk9ypr9S8TYiSgc/who-thinks-quantum-computing-will-be-necessary-for-ai", "linkUrl": "https://www.lesswrong.com/posts/zrkk9ypr9S8TYiSgc/who-thinks-quantum-computing-will-be-necessary-for-ai", "postedAtFormatted": "Tuesday, May 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Who%20thinks%20quantum%20computing%20will%20be%20necessary%20for%20AI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWho%20thinks%20quantum%20computing%20will%20be%20necessary%20for%20AI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzrkk9ypr9S8TYiSgc%2Fwho-thinks-quantum-computing-will-be-necessary-for-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Who%20thinks%20quantum%20computing%20will%20be%20necessary%20for%20AI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzrkk9ypr9S8TYiSgc%2Fwho-thinks-quantum-computing-will-be-necessary-for-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fzrkk9ypr9S8TYiSgc%2Fwho-thinks-quantum-computing-will-be-necessary-for-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 169, "htmlBody": "<p>While writing my article <a href=\"/lw/hit/could_robots_take_all_our_jobs_a_philosophical/\">\"Could Robots Take All Our Jobs?: A Philosophical Perspective\"</a>&nbsp;I came across a lot of people who claim (roughly) that human intelligence isn't Turing computable. At one point this led me to tweet something to the effect of, \"where are the sophisticated AI critics who claim the problem of AI is NP-complete?\" But that was just me being whimsical; I was mostly not-serious.</p>\n<p>A couple times, though, I've heard people suggest something to the effect that maybe we will need quantum computing to do human-level AI, though so far I've never heard this from an academic, only interested amateurs (though ones with some real computing knowledge). Who else here has encountered this? Does anyone know of any academics who adopt this point of view? Answers to the latter question especially could be valuable for doing article version 2.0.</p>\n<p><strong>Edit: </strong>This very brief query may have given the impression that I'm more sympathetic to the \"AI requires QC\" idea than I actually am; see my response to gwern below.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zrkk9ypr9S8TYiSgc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "22750", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 101, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["X7rWCw5fMRc2MetBD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-29T15:14:45.362Z", "modifiedAt": null, "url": null, "title": "[LINK] SMBC on human and alien values", "slug": "link-smbc-on-human-and-alien-values", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:39.704Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/foA7GZAbcLpLz87SX/link-smbc-on-human-and-alien-values", "pageUrlRelative": "/posts/foA7GZAbcLpLz87SX/link-smbc-on-human-and-alien-values", "linkUrl": "https://www.lesswrong.com/posts/foA7GZAbcLpLz87SX/link-smbc-on-human-and-alien-values", "postedAtFormatted": "Wednesday, May 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20SMBC%20on%20human%20and%20alien%20values&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20SMBC%20on%20human%20and%20alien%20values%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfoA7GZAbcLpLz87SX%2Flink-smbc-on-human-and-alien-values%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20SMBC%20on%20human%20and%20alien%20values%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfoA7GZAbcLpLz87SX%2Flink-smbc-on-human-and-alien-values", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfoA7GZAbcLpLz87SX%2Flink-smbc-on-human-and-alien-values", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 10, "htmlBody": "<p>Zach <a href=\"http://www.smbc-comics.com/index.php?db=comics&amp;id=2992\">nailed</a> it, as usual, especially with his red-button punchline.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "foA7GZAbcLpLz87SX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 5, "extendedScore": null, "score": 1.214969098102293e-06, "legacy": true, "legacyId": "22763", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-29T20:04:07.923Z", "modifiedAt": null, "url": null, "title": "Meetup : [Boston] The Science Of Happiness", "slug": "meetup-boston-the-science-of-happiness", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/i6BDXHoykEqBRPhRn/meetup-boston-the-science-of-happiness", "pageUrlRelative": "/posts/i6BDXHoykEqBRPhRn/meetup-boston-the-science-of-happiness", "linkUrl": "https://www.lesswrong.com/posts/i6BDXHoykEqBRPhRn/meetup-boston-the-science-of-happiness", "postedAtFormatted": "Wednesday, May 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BBoston%5D%20The%20Science%20Of%20Happiness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BBoston%5D%20The%20Science%20Of%20Happiness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi6BDXHoykEqBRPhRn%2Fmeetup-boston-the-science-of-happiness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BBoston%5D%20The%20Science%20Of%20Happiness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi6BDXHoykEqBRPhRn%2Fmeetup-boston-the-science-of-happiness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fi6BDXHoykEqBRPhRn%2Fmeetup-boston-the-science-of-happiness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 93, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/na\">[Boston] The Science Of Happiness</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">02 June 2013 02:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">25 Ames St, Cambridge, MA</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>We'll review the current research on what makes humans happy and discuss how to apply these lessons to our own lives.</p>\n<p>&nbsp;</p>\n<p><a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/\">Cambridge/Boston-area Less Wrong meetups</a> are on the first and third Sunday of every month at 2pm in MIT's <a href=\"http://whereis.mit.edu/?go=66\">building 66</a> at 25 Ames St, room 156. Room number subject to change based on availability; signs will be posted with the actual room number.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/na\">[Boston] The Science Of Happiness</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "i6BDXHoykEqBRPhRn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.215183660318809e-06, "legacy": true, "legacyId": "22765", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Boston__The_Science_Of_Happiness\">Discussion article for the meetup : <a href=\"/meetups/na\">[Boston] The Science Of Happiness</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">02 June 2013 02:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">25 Ames St, Cambridge, MA</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>We'll review the current research on what makes humans happy and discuss how to apply these lessons to our own lives.</p>\n<p>&nbsp;</p>\n<p><a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/\">Cambridge/Boston-area Less Wrong meetups</a> are on the first and third Sunday of every month at 2pm in MIT's <a href=\"http://whereis.mit.edu/?go=66\">building 66</a> at 25 Ames St, room 156. Room number subject to change based on availability; signs will be posted with the actual room number.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup____Boston__The_Science_Of_Happiness1\">Discussion article for the meetup : <a href=\"/meetups/na\">[Boston] The Science Of Happiness</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Boston] The Science Of Happiness", "anchor": "Discussion_article_for_the_meetup____Boston__The_Science_Of_Happiness", "level": 1}, {"title": "Discussion article for the meetup : [Boston] The Science Of Happiness", "anchor": "Discussion_article_for_the_meetup____Boston__The_Science_Of_Happiness1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-29T21:44:51.627Z", "modifiedAt": null, "url": null, "title": "Stats Advice on a New N-back Game", "slug": "stats-advice-on-a-new-n-back-game", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.858Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Antisuji", "createdAt": "2009-04-15T23:39:08.004Z", "isAdmin": false, "displayName": "Antisuji"}, "userId": "zRsg2BPDaXGTkXFMd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gQGXiGwECQ6vGAfAT/stats-advice-on-a-new-n-back-game", "pageUrlRelative": "/posts/gQGXiGwECQ6vGAfAT/stats-advice-on-a-new-n-back-game", "linkUrl": "https://www.lesswrong.com/posts/gQGXiGwECQ6vGAfAT/stats-advice-on-a-new-n-back-game", "postedAtFormatted": "Wednesday, May 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Stats%20Advice%20on%20a%20New%20N-back%20Game&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStats%20Advice%20on%20a%20New%20N-back%20Game%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgQGXiGwECQ6vGAfAT%2Fstats-advice-on-a-new-n-back-game%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Stats%20Advice%20on%20a%20New%20N-back%20Game%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgQGXiGwECQ6vGAfAT%2Fstats-advice-on-a-new-n-back-game", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgQGXiGwECQ6vGAfAT%2Fstats-advice-on-a-new-n-back-game", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1007, "htmlBody": "<p style=\"padding-left: 30px;\"><em>Cross-posted to my <a href=\"http://hyponymo.us/double-dynamo-flow-stats/\">blog</a>. I expect this will be of some interest to the LessWrong community both because of&nbsp;<a href=\"/lw/2u4/dual_nback_news/\">previous</a>&nbsp;<a href=\"/lw/68k/nback_news_jaeggi_2011_or_is_there_a/\">interest</a>&nbsp;<a href=\"/r/discussion/lw/6sj/experience_with_dual_nback/\">in</a>&nbsp;<a href=\"/lw/die/dual_nback_browserbased_game_in_public/\">N-back</a>&nbsp;and because of the opportunity to apply Bayesian statistics to a real-world problem. The main reason I'm writing this article is to get feedback on my approach and to ask for help in the areas where I'm stuck. For some background, I'm a software developer who's been working in games for 7+ years and recently left my corporate job to work on this project full-time.</em></p>\n<p>As I mentioned <a href=\"/lw/gkz/what_are_you_working_on_february_2013/8etz\">here</a>&nbsp;and <a href=\"/lw/goe/open_thread_february_1528_2013/8hpw\">here</a>, since early February I've been working on an&nbsp;<a href=\"http://www.gwern.net/DNB%20FAQ\">N-back</a>-like mobile <a href=\"https://www.facebook.com/DoubleDynamo\">game</a>. I plan to release for iOS this summer and for Android a few months later if all goes well. I have fully implemented the core gameplay and most of the visual styling and UI, and am currently working with a composer on the sound and music.</p>\n<p>I am just now starting on the final component of the game: an adaptive mode that assesses the player's skill and presents challenges that are tuned to induce a state of <a href=\"http://en.wikipedia.org/wiki/Flow_(psychology)\">flow</a>.</p>\n<h1>The Problem</h1>\n<p>The game is broken down into waves, each of which presents an N-back-like task with certain parameters, such as the number of attributes, the number of variants in each attribute, the tempo, and so on. I would like to find a way to collapse these parameters into a single difficulty parameter that I can compare against a player's skill level to predict their performance on a given wave.</p>\n<p>But I realize that some players will be better at some challenges than others (e.g. memory, matching multiple attributes, handling fast tempos, dealing with visual distractions like rotation, or recognizing letters). Skill and difficulty are multidimensional quantities, and this makes performance hard to predict. The question is, is there a single-parameter approximation that delivers an adequate experience? Additionally, the task is not pure N-back &mdash; I've made it more game-like &mdash; and as a result the relationship between the game parameters and the overall difficulty is not as straightforward as it would be in a cleaner environment (e.g. difficulty might be nearly linear in tempo for some set-ups but highly non-linear for others).</p>\n<p>I have the luxury of having access to fairly rich behavioral data. The game is partly a rhythm game, so not only do I know whether a match has been made correctly (or a non-match correctly skipped) but I also know the timing of a player's positive responses. A player with higher skill should have smaller timing errors, so a well-timed match is <a href=\"http://wiki.lesswrong.com/wiki/Evidence\">evidence</a> for higher skill. I am still unsure exactly how I can use this information optimally.</p>\n<p>I plan to display a plot of player skill over time, but this opens another set of questions. What exactly am I plotting? How do I model player skill over time (just a time-weighted average? as a series of slopes and plateaus? how should I expect skill to change over a period of time without any play?)? How much variation in performance is due to fatigue, attention, caffeine, etc.? Do I show error bars or box plots? What units do I use?</p>\n<p>And finally, how do I turn a difficulty and a skill level into a prediction of performance? What is the model of the player playing the game?</p>\n<h2>Main Questions</h2>\n<ul>\n<li>Is there an adequate difficulty parameter and if so how do I calculate it?</li>\n<li>Can I use timing data to improve predictions? How?</li>\n<li>What model do I use for player skill changing over time?</li>\n<li>How do I communicate performance stats to the user? Box and whiskers? Units?</li>\n<li>What is the model of the player and how do I turn that into a prediction?</li>\n</ul>\n<h1>My Approach</h1>\n<p>I've read <a href=\"http://www.amazon.com/Data-Analysis-Bayesian-Tutorial-Publications/dp/0198518897\">Sivia</a>, so I have some theoretical background on how to solve this kind of problem, but only limited real-world experience. These are my thoughts so far.</p>\n<p>Modeling gameplay performance as <a href=\"http://en.wikipedia.org/wiki/Bernoulli_trial\">Bernoulli trials</a> seems ok. That is, given a skill level S and a difficulty D, performance on a set of N matches should be closely matched by N Bernoulli trials with probability of success p(S, D) as follows:</p>\n<ul>\n<li>if S \u226a D, p = 0.5</li>\n<li>if S \u226b&nbsp;D, p is close to 1.0 (how close?)</li>\n<li>if S = D, p = 0.9 feels about right</li>\n<li>etc.</li>\n</ul>\n<p>Then I can update S (and maybe D? see next paragraph) on actual player performance. This will result in a new <a href=\"http://en.wikipedia.org/wiki/Probability_density_function\">probability density function</a> over the \"true\" value of S, which will hopefully be unimodal and narrow enough to report as a single best estimate (possibly with error bars). Which reminds me, what do I use as a prior for S? And what happens if the player just stops playing halfway through, or hands the game to their 5-year-old?</p>\n<p>Determining difficulty is another hard problem. I currently have a complicated ad-hoc formula that I cobbled together with logarithms, exponentials, and magic numbers, and lots of trial and error. It seems to work pretty well for the limited set of levels I've tested with a small group of playtesters, but I'm worried that it won't predict difficulty well outside of that domain. One possibility is to croud-source it: after release I'd collect performance data across all users and update the difficulty ratings on the fly. This seems risky and difficult, and the initial difficulty ratings might be way off, which would lead to poor initial user experiences with the adaptive mode. I would also have to worry about maintaining a server back-end to gather the data and report on updated difficulty levels.</p>\n<h1>Request For Feedback</h1>\n<p>So, any suggestions on how to tackle these problems? Or the first place to start looking?</p>\n<p>I'm pretty excited about the potential to collect real-world data on skill acquisition over time. If there is sufficient interest I'll consider making the raw data public, and even instrument the code to collect other data of interest, by request. I do have some concerns over data privacy, so I may allow users to opt out of sending their data up to the server.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gQGXiGwECQ6vGAfAT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.215258362621043e-06, "legacy": true, "legacyId": "22764", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p style=\"padding-left: 30px;\"><em>Cross-posted to my <a href=\"http://hyponymo.us/double-dynamo-flow-stats/\">blog</a>. I expect this will be of some interest to the LessWrong community both because of&nbsp;<a href=\"/lw/2u4/dual_nback_news/\">previous</a>&nbsp;<a href=\"/lw/68k/nback_news_jaeggi_2011_or_is_there_a/\">interest</a>&nbsp;<a href=\"/r/discussion/lw/6sj/experience_with_dual_nback/\">in</a>&nbsp;<a href=\"/lw/die/dual_nback_browserbased_game_in_public/\">N-back</a>&nbsp;and because of the opportunity to apply Bayesian statistics to a real-world problem. The main reason I'm writing this article is to get feedback on my approach and to ask for help in the areas where I'm stuck. For some background, I'm a software developer who's been working in games for 7+ years and recently left my corporate job to work on this project full-time.</em></p>\n<p>As I mentioned <a href=\"/lw/gkz/what_are_you_working_on_february_2013/8etz\">here</a>&nbsp;and <a href=\"/lw/goe/open_thread_february_1528_2013/8hpw\">here</a>, since early February I've been working on an&nbsp;<a href=\"http://www.gwern.net/DNB%20FAQ\">N-back</a>-like mobile <a href=\"https://www.facebook.com/DoubleDynamo\">game</a>. I plan to release for iOS this summer and for Android a few months later if all goes well. I have fully implemented the core gameplay and most of the visual styling and UI, and am currently working with a composer on the sound and music.</p>\n<p>I am just now starting on the final component of the game: an adaptive mode that assesses the player's skill and presents challenges that are tuned to induce a state of <a href=\"http://en.wikipedia.org/wiki/Flow_(psychology)\">flow</a>.</p>\n<h1 id=\"The_Problem\">The Problem</h1>\n<p>The game is broken down into waves, each of which presents an N-back-like task with certain parameters, such as the number of attributes, the number of variants in each attribute, the tempo, and so on. I would like to find a way to collapse these parameters into a single difficulty parameter that I can compare against a player's skill level to predict their performance on a given wave.</p>\n<p>But I realize that some players will be better at some challenges than others (e.g. memory, matching multiple attributes, handling fast tempos, dealing with visual distractions like rotation, or recognizing letters). Skill and difficulty are multidimensional quantities, and this makes performance hard to predict. The question is, is there a single-parameter approximation that delivers an adequate experience? Additionally, the task is not pure N-back \u2014 I've made it more game-like \u2014 and as a result the relationship between the game parameters and the overall difficulty is not as straightforward as it would be in a cleaner environment (e.g. difficulty might be nearly linear in tempo for some set-ups but highly non-linear for others).</p>\n<p>I have the luxury of having access to fairly rich behavioral data. The game is partly a rhythm game, so not only do I know whether a match has been made correctly (or a non-match correctly skipped) but I also know the timing of a player's positive responses. A player with higher skill should have smaller timing errors, so a well-timed match is <a href=\"http://wiki.lesswrong.com/wiki/Evidence\">evidence</a> for higher skill. I am still unsure exactly how I can use this information optimally.</p>\n<p>I plan to display a plot of player skill over time, but this opens another set of questions. What exactly am I plotting? How do I model player skill over time (just a time-weighted average? as a series of slopes and plateaus? how should I expect skill to change over a period of time without any play?)? How much variation in performance is due to fatigue, attention, caffeine, etc.? Do I show error bars or box plots? What units do I use?</p>\n<p>And finally, how do I turn a difficulty and a skill level into a prediction of performance? What is the model of the player playing the game?</p>\n<h2 id=\"Main_Questions\">Main Questions</h2>\n<ul>\n<li>Is there an adequate difficulty parameter and if so how do I calculate it?</li>\n<li>Can I use timing data to improve predictions? How?</li>\n<li>What model do I use for player skill changing over time?</li>\n<li>How do I communicate performance stats to the user? Box and whiskers? Units?</li>\n<li>What is the model of the player and how do I turn that into a prediction?</li>\n</ul>\n<h1 id=\"My_Approach\">My Approach</h1>\n<p>I've read <a href=\"http://www.amazon.com/Data-Analysis-Bayesian-Tutorial-Publications/dp/0198518897\">Sivia</a>, so I have some theoretical background on how to solve this kind of problem, but only limited real-world experience. These are my thoughts so far.</p>\n<p>Modeling gameplay performance as <a href=\"http://en.wikipedia.org/wiki/Bernoulli_trial\">Bernoulli trials</a> seems ok. That is, given a skill level S and a difficulty D, performance on a set of N matches should be closely matched by N Bernoulli trials with probability of success p(S, D) as follows:</p>\n<ul>\n<li>if S \u226a D, p = 0.5</li>\n<li>if S \u226b&nbsp;D, p is close to 1.0 (how close?)</li>\n<li>if S = D, p = 0.9 feels about right</li>\n<li>etc.</li>\n</ul>\n<p>Then I can update S (and maybe D? see next paragraph) on actual player performance. This will result in a new <a href=\"http://en.wikipedia.org/wiki/Probability_density_function\">probability density function</a> over the \"true\" value of S, which will hopefully be unimodal and narrow enough to report as a single best estimate (possibly with error bars). Which reminds me, what do I use as a prior for S? And what happens if the player just stops playing halfway through, or hands the game to their 5-year-old?</p>\n<p>Determining difficulty is another hard problem. I currently have a complicated ad-hoc formula that I cobbled together with logarithms, exponentials, and magic numbers, and lots of trial and error. It seems to work pretty well for the limited set of levels I've tested with a small group of playtesters, but I'm worried that it won't predict difficulty well outside of that domain. One possibility is to croud-source it: after release I'd collect performance data across all users and update the difficulty ratings on the fly. This seems risky and difficult, and the initial difficulty ratings might be way off, which would lead to poor initial user experiences with the adaptive mode. I would also have to worry about maintaining a server back-end to gather the data and report on updated difficulty levels.</p>\n<h1 id=\"Request_For_Feedback\">Request For Feedback</h1>\n<p>So, any suggestions on how to tackle these problems? Or the first place to start looking?</p>\n<p>I'm pretty excited about the potential to collect real-world data on skill acquisition over time. If there is sufficient interest I'll consider making the raw data public, and even instrument the code to collect other data of interest, by request. I do have some concerns over data privacy, so I may allow users to opt out of sending their data up to the server.</p>", "sections": [{"title": "The Problem", "anchor": "The_Problem", "level": 1}, {"title": "Main Questions", "anchor": "Main_Questions", "level": 2}, {"title": "My Approach", "anchor": "My_Approach", "level": 1}, {"title": "Request For Feedback", "anchor": "Request_For_Feedback", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Mr48vuoavJEGRtrtT", "WDcXoMdFxkSXPSrwR", "CC7fqY2Apu2YMHikA", "iChEzNBM6Y55Fr8kG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-29T23:32:47.545Z", "modifiedAt": null, "url": null, "title": "To become more rational, rinse your left ear with cold water", "slug": "to-become-more-rational-rinse-your-left-ear-with-cold-water", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:56.211Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dvasya", "createdAt": "2011-03-08T00:30:12.369Z", "isAdmin": false, "displayName": "dvasya"}, "userId": "2484AHxytrNyQXajh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iA2xt6ywvJTzKQmiz/to-become-more-rational-rinse-your-left-ear-with-cold-water", "pageUrlRelative": "/posts/iA2xt6ywvJTzKQmiz/to-become-more-rational-rinse-your-left-ear-with-cold-water", "linkUrl": "https://www.lesswrong.com/posts/iA2xt6ywvJTzKQmiz/to-become-more-rational-rinse-your-left-ear-with-cold-water", "postedAtFormatted": "Wednesday, May 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20To%20become%20more%20rational%2C%20rinse%20your%20left%20ear%20with%20cold%20water&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATo%20become%20more%20rational%2C%20rinse%20your%20left%20ear%20with%20cold%20water%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA2xt6ywvJTzKQmiz%2Fto-become-more-rational-rinse-your-left-ear-with-cold-water%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=To%20become%20more%20rational%2C%20rinse%20your%20left%20ear%20with%20cold%20water%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA2xt6ywvJTzKQmiz%2Fto-become-more-rational-rinse-your-left-ear-with-cold-water", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA2xt6ywvJTzKQmiz%2Fto-become-more-rational-rinse-your-left-ear-with-cold-water", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 366, "htmlBody": "<p>A recent paper in <em>Cortex</em>&nbsp;describes how caloric vestibular stimulation (CVS), i.e., rinsing of the ear canal with cold water, reduces unrealistic optimism. Here are some bits from the paper:</p>\n<blockquote><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">Participants were 31 healthy right-handed adults (15 men, 20&ndash;40 years)...</span>\n<p><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">Participants were oriented in a supine position with the head inclined 30&deg; from the horizontal and cold water (24&nbsp;&deg;C) was irrigated into the external auditory canal on one side (</span><span id=\"bbib9\" style=\"border: 0px; font-size: 13px; margin: 0px; padding: 0px; vertical-align: baseline; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\"><a id=\"ancbbib9\" class=\"intra_ref\" style=\"color: #316c9d; text-decoration: none; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\" href=\"http://www.sciencedirect.com/science/article/pii/S0010945213001123#bib9\">Fitzgerald and Hallpike, 1942</a></span><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">).</span><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">&nbsp;After both vestibular-evoked eye movements and vertigo had stopped, the procedure was repeated on the other side...</span></p>\n<p><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">Participants were asked to estimate their own risk, relative to that of their peers (same age, sex and education), of contracting a series of illnesses. The risk rating scale ranged from &minus;6 (lower risk) to +6 (higher risk). ... Each participant was tested in three conditions, with 5&nbsp;min rest between each: baseline with no CI (always first), left-ear CI and right-ear CI (order counterbalanced).&nbsp;</span><span style=\"font-size: 13px; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">In the latter conditions risk-estimation was initiated after 30&nbsp;sec of CI, when nystagmic response had built up. Ten illnesses were rated in each condition and the average risk estimate per condition (mean of 10 ratings) was calculated for each participant. The 30 illnesses used in this study (see&nbsp;</span><span id=\"btbl1\" style=\"font-size: 13px; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\"><a id=\"ancbtbl1\" class=\"intra_ref\" style=\"color: #316c9d; text-decoration: none; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline;\" href=\"http://www.sciencedirect.com/science/article/pii/S0010945213001123#tbl1\">Table 1</a></span><span style=\"font-size: 13px; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">) were selected from a larger pool of illnesses pre-rated by a separate group of 30 healthy participants.</span><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">Overall, our participants were unrealistically optimistic about their chances of contracting illnesses at baseline ...&nbsp;</span><span style=\"color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; font-size: 13px; line-height: 20px; text-align: justify; word-spacing: -1px;\">and during right-ear CI. ...</span><span style=\"font-size: 13px; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">Post-hoc tests using the Bonferroni correction revealed that, compared to baseline, average risk estimates were significantly higher during left-ear CI (</span><em style=\"font-size: 13px; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">p</em><span style=\"font-size: 13px; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">&nbsp;=&nbsp;.016), whereas they remained unchanged during right-ear CI (</span><em style=\"font-size: 13px; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">p</em><span style=\"font-size: 13px; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px; text-align: justify; word-spacing: -1px;\">&nbsp;=&nbsp;.476). Unrealistic optimism was thus reduced selectively during left-ear stimulation.</span></p>\n</blockquote>\n<p>(CI stands for caloric irrigation which is how CVS was performed.)</p>\n<p>It is not clear how close the participants came to being <em>realistic</em> in their estimates after CVS, but they definitely became more pessimistic, which is the right direction to go in the context of numerous biases such as the planning fallacy.</p>\n<p>The paper:</p>\n<h1 class=\"svTitle\" style=\"border: 0px; font-size: 1.4em; margin: 0px 0px 6px; padding: 0px; vertical-align: baseline; color: #5c5c5c; line-height: 1.5em; clear: both; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif;\">Vestibular stimulation attenuates unrealistic optimism</h1>\n<ul class=\"authorGroup noCollab\" style=\"border: 0px; font-size: 13px; margin: 0px 0px 6px; padding: 0px; vertical-align: baseline; list-style-type: none; list-style-position: initial; display: inline; color: #2e2e2e; font-family: 'Arial Unicode MS', 'Arial Unicode', Arial, 'URW Gothic L', Helvetica, Tahoma, sans-serif; line-height: 20px;\">\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Ryan McKay</span>,&nbsp;</li>\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Corinne Tamagni</span>,&nbsp;</li>\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Antonella Palla</span>,&nbsp;</li>\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Peter Krummenacher</span>,&nbsp;</li>\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Stefan C.A. Hegemann</span>,&nbsp;</li>\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Dominik Straumann</span>,&nbsp;</li>\n<li style=\"border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; display: inline;\"><span style=\"color: #316c9d;\">Peter Brugger</span></li>\n</ul>\n<div><a href=\"http://www.sciencedirect.com/science/article/pii/S0010945213001123\">http://www.sciencedirect.com/science/article/pii/S0010945213001123</a></div>\n<div><br /></div>\n<div>(paywalled, but a pre-publication version is available</div>\n<div>here:&nbsp;<a href=\"http://precedings.nature.com/documents/4519/version/1/files/npre20104519-1.pdf\">http://precedings.nature.com/documents/4519/version/1/files/npre20104519-1.pdf</a>)</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iA2xt6ywvJTzKQmiz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 3, "extendedScore": null, "score": 1.2153384162716727e-06, "legacy": true, "legacyId": "22766", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T00:32:05.691Z", "modifiedAt": null, "url": null, "title": "The Rational Investor, Part I", "slug": "the-rational-investor-part-i", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:59.498Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wubbles", "createdAt": "2013-05-29T00:24:22.534Z", "isAdmin": false, "displayName": "wubbles"}, "userId": "u9LLQXTBYhzPMjyAD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8y7rpySzNLJX9RD4a/the-rational-investor-part-i", "pageUrlRelative": "/posts/8y7rpySzNLJX9RD4a/the-rational-investor-part-i", "linkUrl": "https://www.lesswrong.com/posts/8y7rpySzNLJX9RD4a/the-rational-investor-part-i", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Rational%20Investor%2C%20Part%20I&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Rational%20Investor%2C%20Part%20I%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8y7rpySzNLJX9RD4a%2Fthe-rational-investor-part-i%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Rational%20Investor%2C%20Part%20I%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8y7rpySzNLJX9RD4a%2Fthe-rational-investor-part-i", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8y7rpySzNLJX9RD4a%2Fthe-rational-investor-part-i", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 855, "htmlBody": "<p>First off, note that I am not in possession of any of the licenses that entitle me to call myself a financial advisor. However, the approach to investing I will present in this article is endorsed by many economists, Warren Buffet, and Vanguard. I personally follow it, and you can too.</p>\n<p>What is the goal of investing? To turn money today into money tomorrow. There are several ways to do this, and people on Wall Street are constantly inventing new ones. What is more, you have professional competition in this activity: people who want to make money today into more money tomorrow then is otherwise possible. You are producing a commodity, and the better you understand this, the better investing decisions you will make.</p>\n<p>What are the ways to make money today into money tomorrow? There are many ways. But we want to make money today into money tomorrow in the most efficient way that involves the least amount of worry. &nbsp;After all, we have&nbsp;specialised&nbsp;in some other area of human activity, and are not good at this area. So we should pick an investment that requires no upkeep, no worry, and good returns. This rules out real estate entirely, and the last criterion rules out letting money sit there.</p>\n<p>So how does money today turn into money tomorrow? First you pay taxes on the money today, then give the money today as a loan (called \"buying a bond\") &nbsp;to someone who needs it to do something that will be profitable. Or you can purchase a bit of an enterprise that makes money (called \"buying stock\") and let it make money, and pay you in the form of dividends or appreciation of shares, as the company grows. Then you sell what you have or get payed back and get taxed again.</p>\n<p>But what if they don't pay me back or the company fails? Then you are screwed.</p>\n<p>So what if I put a little bit of money in each loan and each share? Then the failure of each one won't hurt you that much.</p>\n<p>Okay, I'll do that! Got a few million lying around?</p>\n<p>Nope. So I can't do that? Nope, you can't. Bonds come in units of $1000 face value, and stocks in lots of 100.</p>\n<p>Wait, what if I got a bunch of my friends together, and we pooled our money? That's called a mutual fund, and you can buy them. But the person who manages the fund charges you money, and that comes right out of the money tomorrow, and sometimes out of the money you put in.</p>\n<p>So I should try to minimize these charges? Exactly!</p>\n<p>Someone promises me higher returns for his fees! He's lying: academic research has shown no evidence of after-fee returns beating the market in general. After all, wouldn't you keep this secret for yourself if it really worked? He gets paid the same even if you lose all your money.</p>\n<p>So what is the fund with the lowest fees? Well, the Vanguard Admiral Shares S&amp;P 500 has fees of 0.05% of your money. Check out the prospectuses before you invest: they list out all the things that can go wrong.</p>\n<p>But I don't like the risk! Remember bonds? You are more likely to get paid back, but the price is lower returns.</p>\n<p>But I want diversification! So buy a bond mutual fund as well. And as usual there are fees you want to avoid.</p>\n<p>Do I need anything else? According to CAPM, no. (We can talk about international stocks, but the S&amp;P 500 do&nbsp;business&nbsp;worldwide, and there are lots of details about the costs of diversification etc.)</p>\n<p>But how much do I put in each? That's a research question. But there is plenty of advice on this one question, and it doesn't cost you anything.</p>\n<p>What about taxes? That's between you and the IRS. But sign up for a 401(k), maximize it, put as much into an IRA as you can, consider carefully the Roth IRA, think about which bonds you want to hold, and don't trade!</p>\n<p>Don't trade? Don't trade: remember, you have competition. Trading hurts retail investors: it is expensive and they aren't good at it.</p>\n<p>But I have a really good idea! Then work on Wall Street and risk someone else's money. Best part: you get paid either way.</p>\n<p>But I want to change which mutual fund I hold to one that got more returns! Don't do it: the high returns don't last. Reversion to the mean is a powerful force.</p>\n<p>I want to move to bonds as I get older! Still don't do it: you get taxed on the realized gains. It's easier to buy new then to sell old.</p>\n<p>So what should I do? Think of your portfolio as one thing, and think about how to minimize taxes and fees as you go from where you are now to where you want to be. Then do it. But think first! Buying doesn't destroy the basis the way selling does, and overbalancing in tax-deferred accounts cancels out imbalanced non tax-deferred accounts.</p>\n<p>------</p>\n<p>Sources:&nbsp;http://www.vanguard.com/bogle_site/sp20051015.htm,&nbsp;</p>\n<p>http://online.wsj.com/article/SB10001424053111904583204576544681577401622.html</p>\n<p>Buffet endorsing the index fund&nbsp;http://www.berkshirehathaway.com/letters/1996.html</p>\n<p>http://johncbogle.com/wordpress/wp-content/uploads/2011/09/The-Professor-The-Student-and-the-Index-Fund-9-4-11.pdf</p>\n<p>Similar sources exist everywhere. Ask your local economics professor what his investments are, and I will be willing to bet 10:1 odds that they are majority placed in an index fund.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jgcAJnksReZRuvgzp": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8y7rpySzNLJX9RD4a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -2, "extendedScore": null, "score": 1.2153824051208058e-06, "legacy": true, "legacyId": "22751", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T07:21:37.467Z", "modifiedAt": null, "url": null, "title": "Meetup : Helsinki meetup with CatM (CFAR instructor) as special guest star", "slug": "meetup-helsinki-meetup-with-catm-cfar-instructor-as-special", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:56.760Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iXSMzGTQiMXEPx2K5/meetup-helsinki-meetup-with-catm-cfar-instructor-as-special", "pageUrlRelative": "/posts/iXSMzGTQiMXEPx2K5/meetup-helsinki-meetup-with-catm-cfar-instructor-as-special", "linkUrl": "https://www.lesswrong.com/posts/iXSMzGTQiMXEPx2K5/meetup-helsinki-meetup-with-catm-cfar-instructor-as-special", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Helsinki%20meetup%20with%20CatM%20(CFAR%20instructor)%20as%20special%20guest%20star&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Helsinki%20meetup%20with%20CatM%20(CFAR%20instructor)%20as%20special%20guest%20star%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXSMzGTQiMXEPx2K5%2Fmeetup-helsinki-meetup-with-catm-cfar-instructor-as-special%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Helsinki%20meetup%20with%20CatM%20(CFAR%20instructor)%20as%20special%20guest%20star%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXSMzGTQiMXEPx2K5%2Fmeetup-helsinki-meetup-with-catm-cfar-instructor-as-special", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXSMzGTQiMXEPx2K5%2Fmeetup-helsinki-meetup-with-catm-cfar-instructor-as-special", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 91, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nb'>Helsinki meetup with CatM (CFAR instructor) as special guest star</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">08 June 2013 03:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 Vanha, Mannerheimintie 3, Helsinki, Finland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cat, who has volunteered extensively at CFAR (and taught at CFAR), will be visiting many cities in Europe. She will now also be visiting Helsinki, and has said that she would happily teach a CFAR class or lead a discussion on some rationality material.</p>\n\n<p>Apologies for the short notice.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nb'>Helsinki meetup with CatM (CFAR instructor) as special guest star</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iXSMzGTQiMXEPx2K5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.2156862593384327e-06, "legacy": true, "legacyId": "22776", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Helsinki_meetup_with_CatM__CFAR_instructor__as_special_guest_star\">Discussion article for the meetup : <a href=\"/meetups/nb\">Helsinki meetup with CatM (CFAR instructor) as special guest star</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">08 June 2013 03:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 Vanha, Mannerheimintie 3, Helsinki, Finland</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Cat, who has volunteered extensively at CFAR (and taught at CFAR), will be visiting many cities in Europe. She will now also be visiting Helsinki, and has said that she would happily teach a CFAR class or lead a discussion on some rationality material.</p>\n\n<p>Apologies for the short notice.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Helsinki_meetup_with_CatM__CFAR_instructor__as_special_guest_star1\">Discussion article for the meetup : <a href=\"/meetups/nb\">Helsinki meetup with CatM (CFAR instructor) as special guest star</a></h2>", "sections": [{"title": "Discussion article for the meetup : Helsinki meetup with CatM (CFAR instructor) as special guest star", "anchor": "Discussion_article_for_the_meetup___Helsinki_meetup_with_CatM__CFAR_instructor__as_special_guest_star", "level": 1}, {"title": "Discussion article for the meetup : Helsinki meetup with CatM (CFAR instructor) as special guest star", "anchor": "Discussion_article_for_the_meetup___Helsinki_meetup_with_CatM__CFAR_instructor__as_special_guest_star1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T08:10:17.822Z", "modifiedAt": null, "url": null, "title": "Meetup :  ", "slug": "meetup-4", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:56.051Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "A4YWnHwTjSbdqiGhj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vyLenrFt3mF8CHhcj/meetup-4", "pageUrlRelative": "/posts/vyLenrFt3mF8CHhcj/meetup-4", "linkUrl": "https://www.lesswrong.com/posts/vyLenrFt3mF8CHhcj/meetup-4", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvyLenrFt3mF8CHhcj%2Fmeetup-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvyLenrFt3mF8CHhcj%2Fmeetup-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvyLenrFt3mF8CHhcj%2Fmeetup-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nc'> </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">01 June 2013 04:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nc'> </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vyLenrFt3mF8CHhcj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "22778", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____\">Discussion article for the meetup : <a href=\"/meetups/nc\"> </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">01 June 2013 04:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____1\">Discussion article for the meetup : <a href=\"/meetups/nc\"> </a></h2>", "sections": [{"title": "Discussion article for the meetup :  ", "anchor": "Discussion_article_for_the_meetup____", "level": 1}, {"title": "Discussion article for the meetup :  ", "anchor": "Discussion_article_for_the_meetup____1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T15:31:15.773Z", "modifiedAt": null, "url": null, "title": "Finding interesting communities", "slug": "finding-interesting-communities", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:59.259Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Error", "createdAt": "2012-09-14T14:09:41.325Z", "isAdmin": false, "displayName": "Error"}, "userId": "uLxJE9XRTCBrzn8uL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/669f2a8MmPiAhNc8A/finding-interesting-communities", "pageUrlRelative": "/posts/669f2a8MmPiAhNc8A/finding-interesting-communities", "linkUrl": "https://www.lesswrong.com/posts/669f2a8MmPiAhNc8A/finding-interesting-communities", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Finding%20interesting%20communities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFinding%20interesting%20communities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F669f2a8MmPiAhNc8A%2Ffinding-interesting-communities%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Finding%20interesting%20communities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F669f2a8MmPiAhNc8A%2Ffinding-interesting-communities", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F669f2a8MmPiAhNc8A%2Ffinding-interesting-communities", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 430, "htmlBody": "<p><span class=\"votes\"> <span id=\"score_t3_hj5\" class=\"votes \"> </span></span><span class=\"author\">diegocaleiro said this in <a title=\"Research is Polygamous\" href=\"/r/discussion/lw/hj5/research_is_polygamous_the_importance_of_what_you/\">Research is Polygamous</a>:</span></p>\n<blockquote>\n<p>Being in an area where the most awesome people are is not asking to \"lose the game\" it is being in an environment that <a href=\"/lw/52g/the_good_news_of_situationist_psychology/\">cultivates greatness</a>.</p>\n</blockquote>\n<p>It made me think of the recent post in Main on <a title=\"How to Build a Community\" href=\"/lw/hfq/how_to_build_a_community/\">How to Build a Community</a>. And reflect a bit on how, while I've lived pretty much exclusively online for the last ten years, the lack of meatspace social contact is finally beginning to annoy me. So here's a question for the group: Not how does one build a community, but where and how does one <em>find</em> existing communities that are worth joining? And what are some examples? Not counting LW itself and its tributaries.</p>\n<p>A few things I've tried or will try, in no particular order:</p>\n<p>Mensa. Didn't work out terribly well, largely because I seemed to have very little in common with anyone else there. Apparently intelligence alone is an insufficient filter.</p>\n<p>Geek conventions. (e.g. Dragoncon) I'm a giant flaming unrepentant geek, so I get the feeling of being among my own kind, and selecting for passion seems to work better than selecting for intelligence insofar as finding interesting people goes. The sheer size of the crowd makes getting at the people who are actually doing awesome things difficult, though.&nbsp;</p>\n<p>Makerspaces. For those that haven't heard the term, these are a sort of shared lab for private individuals. I actually became aware of these through item 2. Seems promising and it's the next thing I intend to look into, within the next few weeks. Unfortunately the nearest established one, like the nearest LW meetup, is downtown through murdertraffic; a 2-3 hour round trip.</p>\n<p>I <em>suspect</em>, but have no significant evidence, that universities containing graduate schools would also be a good bet. But I'm long out of college (I dropped out, for irrelevant reasons) and have no wish (or money, or time) to go back. I occasionally apply for jobs at the closest such place to me, but haven't had a hit yet and I'm unsure I would want to move downtown anyway. I do get the impression that many here are undergrads or graduate students, so opinions on whether that route may be worth pursuing are welcome.</p>\n<p>Beyond that? I don't know. There don't seem to be many communities that both select for <em>being awesome</em> and are accessible to anyone who cares to be awesome. I've found that social reinforcement for doing cool stuff helps a lot. I don't <em>like </em>that fact very much, but I had better find a way to use it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "669f2a8MmPiAhNc8A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 19, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "22779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tvRYLsJXkmsD58ECr", "Q5CjE8pRiACqTvhRM", "87GCpuFr8ywGqqXkP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T16:51:10.177Z", "modifiedAt": null, "url": null, "title": "does imagining +singularity cause depression?", "slug": "does-imagining-singularity-cause-depression", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:55.941Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonathan_Graehl", "createdAt": "2009-02-27T23:21:15.671Z", "isAdmin": false, "displayName": "Jonathan_Graehl"}, "userId": "eKsWtKKceoRYwcc7s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7hDjKtKfdwJo8aWmv/does-imagining-singularity-cause-depression", "pageUrlRelative": "/posts/7hDjKtKfdwJo8aWmv/does-imagining-singularity-cause-depression", "linkUrl": "https://www.lesswrong.com/posts/7hDjKtKfdwJo8aWmv/does-imagining-singularity-cause-depression", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20does%20imagining%20%2Bsingularity%20cause%20depression%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Adoes%20imagining%20%2Bsingularity%20cause%20depression%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7hDjKtKfdwJo8aWmv%2Fdoes-imagining-singularity-cause-depression%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=does%20imagining%20%2Bsingularity%20cause%20depression%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7hDjKtKfdwJo8aWmv%2Fdoes-imagining-singularity-cause-depression", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7hDjKtKfdwJo8aWmv%2Fdoes-imagining-singularity-cause-depression", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 38, "htmlBody": "<p>How many people feel despair in imagining a heaven (positive singularity) that they'll miss out on if they don't survive long enough? I don't think about it, but I already have plenty of reasons to like being alive.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7hDjKtKfdwJo8aWmv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": -18, "extendedScore": null, "score": 1.2161090622754008e-06, "legacy": true, "legacyId": "22780", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T18:02:36.127Z", "modifiedAt": null, "url": null, "title": "Meetup : LW Vienna Meetup #3", "slug": "meetup-lw-vienna-meetup-3", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ratcourse", "createdAt": "2012-11-03T10:26:05.641Z", "isAdmin": false, "displayName": "Ratcourse"}, "userId": "qwnfbBpAcbxLT4JBr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Jjw9dZXvWY37aaaut/meetup-lw-vienna-meetup-3", "pageUrlRelative": "/posts/Jjw9dZXvWY37aaaut/meetup-lw-vienna-meetup-3", "linkUrl": "https://www.lesswrong.com/posts/Jjw9dZXvWY37aaaut/meetup-lw-vienna-meetup-3", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20LW%20Vienna%20Meetup%20%233&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20LW%20Vienna%20Meetup%20%233%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJjw9dZXvWY37aaaut%2Fmeetup-lw-vienna-meetup-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20LW%20Vienna%20Meetup%20%233%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJjw9dZXvWY37aaaut%2Fmeetup-lw-vienna-meetup-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJjw9dZXvWY37aaaut%2Fmeetup-lw-vienna-meetup-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nd'>LW Vienna Meetup #3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 June 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Universit\u00e4tsstra\u00dfe 7, 1010 Wien</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Rationality goes University!! - meetup at the NIG, room 2G on the second floor, Universit\u00e4tsstra\u00dfe 7, 1010 Wien\nViliam Bur will be talking on \"being specific\" and Gunther Greindl on what constitutes evidence.\nNewcomers welcome.\nFB event: https://www.facebook.com/events/483142041754571/</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nd'>LW Vienna Meetup #3</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Jjw9dZXvWY37aaaut", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2161621086854562e-06, "legacy": true, "legacyId": "22782", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___LW_Vienna_Meetup__3\">Discussion article for the meetup : <a href=\"/meetups/nd\">LW Vienna Meetup #3</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 June 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Universit\u00e4tsstra\u00dfe 7, 1010 Wien</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Rationality goes University!! - meetup at the NIG, room 2G on the second floor, Universit\u00e4tsstra\u00dfe 7, 1010 Wien\nViliam Bur will be talking on \"being specific\" and Gunther Greindl on what constitutes evidence.\nNewcomers welcome.\nFB event: https://www.facebook.com/events/483142041754571/</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___LW_Vienna_Meetup__31\">Discussion article for the meetup : <a href=\"/meetups/nd\">LW Vienna Meetup #3</a></h2>", "sections": [{"title": "Discussion article for the meetup : LW Vienna Meetup #3", "anchor": "Discussion_article_for_the_meetup___LW_Vienna_Meetup__3", "level": 1}, {"title": "Discussion article for the meetup : LW Vienna Meetup #3", "anchor": "Discussion_article_for_the_meetup___LW_Vienna_Meetup__31", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T20:25:03.167Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels meetup with Cat", "slug": "meetup-brussels-meetup-with-cat", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:00.793Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WZd28LirYyWotktHE/meetup-brussels-meetup-with-cat", "pageUrlRelative": "/posts/WZd28LirYyWotktHE/meetup-brussels-meetup-with-cat", "linkUrl": "https://www.lesswrong.com/posts/WZd28LirYyWotktHE/meetup-brussels-meetup-with-cat", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20meetup%20with%20Cat&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20meetup%20with%20Cat%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWZd28LirYyWotktHE%2Fmeetup-brussels-meetup-with-cat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20meetup%20with%20Cat%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWZd28LirYyWotktHE%2Fmeetup-brussels-meetup-with-cat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWZd28LirYyWotktHE%2Fmeetup-brussels-meetup-with-cat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ne'>Brussels meetup with Cat</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">03 June 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>we are lucky enough to be meeting Cat from the CfAR in \"la fleur en papier dorr\u00e9e\" on Monday the 3rd of June.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ne'>Brussels meetup with Cat</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WZd28LirYyWotktHE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.2162679059788686e-06, "legacy": true, "legacyId": "22783", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup_with_Cat\">Discussion article for the meetup : <a href=\"/meetups/ne\">Brussels meetup with Cat</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">03 June 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>we are lucky enough to be meeting Cat from the CfAR in \"la fleur en papier dorr\u00e9e\" on Monday the 3rd of June.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup_with_Cat1\">Discussion article for the meetup : <a href=\"/meetups/ne\">Brussels meetup with Cat</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels meetup with Cat", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup_with_Cat", "level": 1}, {"title": "Discussion article for the meetup : Brussels meetup with Cat", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup_with_Cat1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-30T21:33:12.398Z", "modifiedAt": null, "url": null, "title": "\"disfluency\" research", "slug": "disfluency-research", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.089Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonathan_Graehl", "createdAt": "2009-02-27T23:21:15.671Z", "isAdmin": false, "displayName": "Jonathan_Graehl"}, "userId": "eKsWtKKceoRYwcc7s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FQ3tWoZEf4jBq5GEq/disfluency-research", "pageUrlRelative": "/posts/FQ3tWoZEf4jBq5GEq/disfluency-research", "linkUrl": "https://www.lesswrong.com/posts/FQ3tWoZEf4jBq5GEq/disfluency-research", "postedAtFormatted": "Thursday, May 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22disfluency%22%20research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22disfluency%22%20research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFQ3tWoZEf4jBq5GEq%2Fdisfluency-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22disfluency%22%20research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFQ3tWoZEf4jBq5GEq%2Fdisfluency-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFQ3tWoZEf4jBq5GEq%2Fdisfluency-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1149, "htmlBody": "<p><a href=\"http://edge.org/conversation/disfluency\">Adam Alter lists some evidence</a>&nbsp;from people who study the effects of \"disfluency\" (unfamiliarity, or lack of clarity), which somewhat surprisingly leads to greater depth of thought (while you're expending the energy to understand something, you can't help but think about it), and also a willingness to depart further from immediate concrete reality (as in Robin Hanson's <a href=\"http://www.overcomingbias.com/2010/06/near-far-summary.html\">Near-Far</a>). Think of the effort given to studying vague, poetic, or just incomprehensible religious materials (sometimes in their original scripts) and the investment this can generate.</p>\n<p>Below are some of the linked claims of evidence:</p>\n<blockquote>\n<p><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">When you give the prompt ... \"Think about what it would be like to be fit and to have done a lot of exercise,\" if you give that prompt in a font that's very difficult to read, in a disfluent font, people tend to think longer about the task, they think more deeply about it, they depart more from reality, and then later on they actually say that they're going to be more willing to do this sort of exercise, and so they become more committed.</span></p>\n</blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">When you give them the bill that's been slightly altered [George Washington's portrait faces left], they think they can't purchase quite as much with it. If you say to them, \"How many M&amp;Ms can you purchase with this dollar bill,\" they'll give you a higher number when it's the real bill, and they'll also do that when it's a dollar bill versus a more obscure form of currency, like a dollar coin, or if you give them two $1bills, they think they can buy more with those two $1 bills than they can with a single $2 bill, the Jefferson $2 bill, which is much rarer. It's legal tender, but it's just more rare, and you find that people think they can purchase more with the two $1 bills than with the single $2 bill. That effect is also stronger to the extent that they are unfamiliar with the Jefferson bill. It goes away completely when they're very familiar with the Jefferson bill, but when they haven't seen it as many times, you get this very strong effect that they think that the Jefferson bill is less valuable, can purchase less than two $1 bills.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">[about some anonymous confessions website] In the middle of 2008 he decided to change the format, and now the background, instead of being this gray shade that was very similar to the black text, he changed the background to white, and all of a sudden it was much easier to read the information on the site. ...&nbsp;</span><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">The gravity of the confessions went up. They were much more revealing. Often they revealed crimes and major things that people might not otherwise reveal. A lot of the confessions that people were revealing when the site was disfluent were peccadilloes. They were minor issues. They were revealing really minor trivial things. We have some evidence that disfluency might mitigate some of those issues with over-sharing on the internet</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">if you ask people about how risky a ride is at an amusement park, if the ride has a very simple name, and it's easy to pronounce, people assume that it's not a very dangerous ride. It's not very risky. If you give them a ride that's much more disfluent, that's got a very complex name, they then think the ride is much more dangerous. They did the same thing with additives for food. They assume that the more complicated and convoluted the additive, and the harder it is to pronounce the additive's name, the more dangerous the additive will probably be.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">\"How likely do you think it is that this person knows that what you're clapping is Happy Birthday?\" People, as they're clapping Happy Birthday, in their heads, they're humming it to themselves, and so they imagine the other person has a lot of that information, that it's totally obvious, and it turns out not to be</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">When you feel disfluency, it makes you feel a distance from the target. We've shown this effect with lawyers, that lawyers are just judged more harshly. We've shown the effect with politicians as well. If you say to someone, \"Here are two politicians. How would you judge these two,\" you often find that you get more votes for having the simpler name.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">When you ask people how well they understand what distinguishes two candidates, this particularly happens when you're dealing at the primary level before the main election, you'll find that people say, \"I understand the difference between the candidates pretty well.\" They have this sense that they know the candidates, they know a little bit about them, and when you ask, \"Okay. Can you explain the differences between the candidates to me,\" that leads them to a point where they can't do that.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">If it feels more difficult to remember you'll assume that it happened longer ago, that it's further from where you are today. The same thing is true if you're looking at something, and you're trying to judge its physical distance. If it's fuzzy or difficult to perceive, you might assume that it's farther away.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">If you present the questions [</span><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">&ldquo;When you add the cost of a bat and a ball together the sum of those two is worth $1.10, and the bat costs a dollar more than the ball, how much does the ball cost?&rdquo; etc.]&nbsp;</span><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">in a font that's a little bit more difficult to read, we found that you can increase their accuracy pretty dramatically. They make fewer of those intuitive responses. They take the time to reconsider their initial responses. They assume that the task is more difficult. They have a bit less confidence in their initial response, and so they tend to do a little bit better at the task.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">If you look at the codes that are pronounceable, like BRI would be Bri, it's not an English word, but it's pronounceable, whereas BRK would be unpronounceable according to the rules of English grammar. The stocks that are pronounceable tend to do better when they first enter the market.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">&nbsp;If you present the same information in a format that's difficult to read, either because the font that you've chosen is complex, or because you put the font against a background that isn't very highly contrasting, or contrasted against that font, you find that people think that that moral transgression they're reading is worse. By struggling to read the transgression, they basically assume that the transgression is worse.</span></blockquote>\n<blockquote><span style=\"color: #4e4e4e; font-size: 12px; line-height: 18px;\">If you look at lawyers who join law firms they tend to ascend up the legal hierarchy much more quickly when their names are easy to pronounce or process. That's independent of a whole lot of other factors, like how foreign the name is.</span></blockquote>\n<p style=\"color: #000000; font-size: small; line-height: normal;\">(you may wish to skip over a long section speculating about the effects of 'kids these days don't remember phone numbers', since there's no new information in it).</p>\n<div><br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FQ3tWoZEf4jBq5GEq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 17, "extendedScore": null, "score": 1.2163185292159215e-06, "legacy": true, "legacyId": "22784", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T01:35:46.626Z", "modifiedAt": null, "url": null, "title": "The Paucity of Elites Online", "slug": "the-paucity-of-elites-online", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:39.441Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dugN5SjSvoCgXgmbh/the-paucity-of-elites-online", "pageUrlRelative": "/posts/dugN5SjSvoCgXgmbh/the-paucity-of-elites-online", "linkUrl": "https://www.lesswrong.com/posts/dugN5SjSvoCgXgmbh/the-paucity-of-elites-online", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Paucity%20of%20Elites%20Online&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Paucity%20of%20Elites%20Online%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdugN5SjSvoCgXgmbh%2Fthe-paucity-of-elites-online%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Paucity%20of%20Elites%20Online%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdugN5SjSvoCgXgmbh%2Fthe-paucity-of-elites-online", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdugN5SjSvoCgXgmbh%2Fthe-paucity-of-elites-online", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 788, "htmlBody": "<p>Something that's caught my attention over the past few months is that out of the strongest thinkers who I'm familiar with, a very low proportion record their informal ideas online, and discuss their thoughts in the public domain.&nbsp;</p>\n<p>The domain that I'm most familiar with is pure math, so I'll focus on that, but I imagine that my remarks apply more broadly.</p>\n<p>A very large fraction of pure mathematicians (including a large fraction of elite mathematicians) post their papers to <a href=\"http://arxiv.org/\">ArXiv</a>, a database which stores preprints of mathematical papers. The invention and widespread use of ArXiv has been very valuable, in that researchers can easily notice and access the new papers in their fields as soon as they become available.&nbsp;</p>\n<p>That not withstanding, the fraction of <em>mathematical thinking</em>&nbsp;that's in the public domain is vastly smaller. Math papers generally don't include explanations of&nbsp;<em>why the researchers are interested in the questions that they're writing about</em>&nbsp;or<em>&nbsp;how they came up with the proofs of the theorems</em>. Even when an author does attempt to explain his or her thinking, a reader will often find parts of it opaque, and want clarification. The need to write to the author for clarification poses a&nbsp;<a href=\"/lw/f1/beware_trivial_inconveniences/\">trivial inconvenience</a>&nbsp;which, in practice, discourages a large fraction of questions that people ask.</p>\n<p>Informal mathematical thoughts are extremely important for doing mathematical research, and it's generally difficult to learn it without in-person contact with authors of papers.</p>\n<p>A natural solution to these issues is for researchers to spend more time blogging about their informal thoughts, and for a commenting system to be enabled for readers to offer suggestions or request clarification.</p>\n<p>The mathematicians who have the most to offer in the way of ideas and insight are the elite mathematicians. The fraction of them who blog is tiny. <a href=\"http://terrytao.wordpress.com/\">Terence Tao</a> and <a href=\"http://gowers.wordpress.com/\">Timothy Gowers</a>&nbsp;do a considerable amount of blogging, but they're nearly alone in this.</p>\n<ul>\n<li>Of the 42 living <a href=\"http://en.wikipedia.org/wiki/Fields_Medal\">Fields Medalists</a>, Tao and Gowers are the only active bloggers who I know of, and <a href=\"https://en.wikipedia.org/wiki/Richard_Borcherds\">Borcherds</a> and <a href=\"http://en.wikipedia.org/wiki/Alain_Connes\">Connes</a>&nbsp;are the only others who I know of who have ever blogged.&nbsp;</li>\n<li>I don't know of any bloggers amongst the winners of the <a href=\"http://en.wikipedia.org/wiki/Cole_Prize\">Cole Prize</a> in algebra or in number theory.</li>\n<li>I don't know any bloggers amongst the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Leroy_P._Steele_Prize\">Steele Prize</a>&nbsp;winners.</li>\n<li><a href=\"http://en.wikipedia.org/wiki/Ian_Agol\">Ian Agol</a> is the only blogger amongst winners of the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Oswald_Veblen_Prize_in_Geometry\">Oswald Veblan Prize in Geometry</a>&nbsp;who I know of.</li>\n</ul>\n<div>The opportunity cost to mathematical research here seems to be enormous. Some explanations for the phenomenon are:</div>\n<div><ol>\n<li>Many of the prize winners who don't blog are elderly, and blogging is relatively uncommon among elderly people.</li>\n<li>There's adverse selection coming from the best people having the least to gain from public online discourse (in light of the fact that the fraction of participants who are of similar quality being tiny).</li>\n<li>Inertia.</li>\n</ol>\n<div>Point #1 is relevant, but the fraction of <em>young</em> mathematicians who blog is also very small (though larger than that of the older mathematicians).</div>\n</div>\n<div><br /></div>\n<div>To elaborate on #2 &mdash; when I first started using <a href=\"http://mathoverflow.net/\">MathOverflow</a>,&nbsp;I found it to be a very useful resource, and learned a lot from it. In the beginning, there was a substantial number of very high quality mathematicians who answered a lot of important questions. Since then, the number has dwindled (though I would emphasize that it remains true that some of the&nbsp;contributors&nbsp;are outstanding). In more recent times, I've had the experience of asking <a href=\"http://mathoverflow.net/questions/116244/the-natural-generalization-of-eulers-derivation-of-the-basel-sum\">very natural questions</a>&nbsp;that I'm sure that many mathematicians have thought about, without anyone answering (here too, I would emphasize that in recent times I've gotten <em>some </em>helpful answers: I'm thankful to the current MathOverflow community for this). I think that the drop off in participation by high quality mathematicians can be partially attributed to [the posters who were contributing the most getting relatively little helpful feedback on their own questions and answers]. In such a situation, corresponding with one's colleagues privately starts to look more attractive than posting publicly.</div>\n<div><br /></div>\n<div>It seems as though it might be possible to get around the issues #2 and #3 by simultaneously involving a substantial number of very high quality mathematicians, and having them write for and respond to each other, so that putting their thoughts into the public domain would become attractive. But doing so is beyond my pay grade :-)</div>\n<div><br /></div>\n<div>I suspect that the phenomenon that I describe extends well beyond pure math, and that across fields, there's a large opportunity cost associated with high quality thinkers not putting their thoughts into the public domain. Changing the status quo here could have enormous value. I think that there might be low hanging fruit in this area, insofar as what efforts there have been seem to be few and far between, relative to the landscape of people who think about ideas.&nbsp;</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"x3zyEPFaJANB2BHmP": 1, "MXcpQvaPGtXpB6vkM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dugN5SjSvoCgXgmbh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 40, "extendedScore": null, "score": 1.2164987357677001e-06, "legacy": true, "legacyId": "22786", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["reitXJgJXFzKpdKyd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T04:20:58.811Z", "modifiedAt": null, "url": null, "title": "Curriculum suggestions for someone looking to teach themselves contemporary philosophy", "slug": "curriculum-suggestions-for-someone-looking-to-teach", "viewCount": null, "lastCommentedAt": "2017-10-08T16:39:00.298Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "quanticle", "createdAt": "2009-12-02T01:39:50.714Z", "isAdmin": false, "displayName": "quanticle"}, "userId": "usztQFrTvM67pdcCq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Lr9v6fRbyvjELvRRu/curriculum-suggestions-for-someone-looking-to-teach", "pageUrlRelative": "/posts/Lr9v6fRbyvjELvRRu/curriculum-suggestions-for-someone-looking-to-teach", "linkUrl": "https://www.lesswrong.com/posts/Lr9v6fRbyvjELvRRu/curriculum-suggestions-for-someone-looking-to-teach", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Curriculum%20suggestions%20for%20someone%20looking%20to%20teach%20themselves%20contemporary%20philosophy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACurriculum%20suggestions%20for%20someone%20looking%20to%20teach%20themselves%20contemporary%20philosophy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLr9v6fRbyvjELvRRu%2Fcurriculum-suggestions-for-someone-looking-to-teach%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Curriculum%20suggestions%20for%20someone%20looking%20to%20teach%20themselves%20contemporary%20philosophy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLr9v6fRbyvjELvRRu%2Fcurriculum-suggestions-for-someone-looking-to-teach", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLr9v6fRbyvjELvRRu%2Fcurriculum-suggestions-for-someone-looking-to-teach", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 130, "htmlBody": "<p>Hello LessWrong,</p>\n<p>I just (finally) finished <em>Good and Real</em>, by Gary Drescher. It was a very stimulating read, and I'd like to continue learning philosophy on my own. However, I'm running into a bootstrapping problem. I don't know what I don't know, and therefore, I don't know where I should get started. I've tried searching the LessWrong archive to see if anyone has made a post outlining a curriculum for someone looking to teach themselves the fundamentals of modern philosophy and logic, but either my Google-fu is weak or no such post exists. So, what should someone who is looking to reduce the inferential distance between themselves and modern philosophical thought read, and in what order?</p>\n<p>Or, do you all think this is a quixotic quest that I should give up on?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Lr9v6fRbyvjELvRRu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 1.2218835773900422e-05, "legacy": true, "legacyId": "22790", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T06:08:00.097Z", "modifiedAt": null, "url": null, "title": "Meetup : [Moscow] Rational choice", "slug": "meetup-moscow-rational-choice", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FPTDkbsGrPqws2kae/meetup-moscow-rational-choice", "pageUrlRelative": "/posts/FPTDkbsGrPqws2kae/meetup-moscow-rational-choice", "linkUrl": "https://www.lesswrong.com/posts/FPTDkbsGrPqws2kae/meetup-moscow-rational-choice", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BMoscow%5D%20Rational%20choice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BMoscow%5D%20Rational%20choice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFPTDkbsGrPqws2kae%2Fmeetup-moscow-rational-choice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BMoscow%5D%20Rational%20choice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFPTDkbsGrPqws2kae%2Fmeetup-moscow-rational-choice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFPTDkbsGrPqws2kae%2Fmeetup-moscow-rational-choice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 185, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nf'>[Moscow] Rational choice</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 June 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Strategies how to make a rational choice.</p></li>\n<li><p>Prediction markets. We will have another round of predictions, you can find the discussion and bets table on the <a href=\"http://lesswrong.ru/forum/index.php/topic,103.0.html\">Russian forum</a>.</p></li>\n<li><p>Game session: the Liar's dice.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.\nReports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nf'>[Moscow] Rational choice</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FPTDkbsGrPqws2kae", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2167010285442767e-06, "legacy": true, "legacyId": "22793", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Moscow__Rational_choice\">Discussion article for the meetup : <a href=\"/meetups/nf\">[Moscow] Rational choice</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 June 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Strategies how to make a rational choice.</p></li>\n<li><p>Prediction markets. We will have another round of predictions, you can find the discussion and bets table on the <a href=\"http://lesswrong.ru/forum/index.php/topic,103.0.html\">Russian forum</a>.</p></li>\n<li><p>Game session: the Liar's dice.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.\nReports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Moscow__Rational_choice1\">Discussion article for the meetup : <a href=\"/meetups/nf\">[Moscow] Rational choice</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Moscow] Rational choice", "anchor": "Discussion_article_for_the_meetup____Moscow__Rational_choice", "level": 1}, {"title": "Discussion article for the meetup : [Moscow] Rational choice", "anchor": "Discussion_article_for_the_meetup____Moscow__Rational_choice1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T09:14:18.737Z", "modifiedAt": null, "url": null, "title": "Optimizing for attractiveness", "slug": "optimizing-for-attractiveness", "viewCount": null, "lastCommentedAt": "2020-06-20T03:04:04.033Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MrMind", "createdAt": "2011-04-19T08:43:22.388Z", "isAdmin": false, "displayName": "MrMind"}, "userId": "LJ4br8GWFXetsXkM8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zfzDnCqfDbqJEGK5A/optimizing-for-attractiveness", "pageUrlRelative": "/posts/zfzDnCqfDbqJEGK5A/optimizing-for-attractiveness", "linkUrl": "https://www.lesswrong.com/posts/zfzDnCqfDbqJEGK5A/optimizing-for-attractiveness", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Optimizing%20for%20attractiveness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOptimizing%20for%20attractiveness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzfzDnCqfDbqJEGK5A%2Foptimizing-for-attractiveness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Optimizing%20for%20attractiveness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzfzDnCqfDbqJEGK5A%2Foptimizing-for-attractiveness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzfzDnCqfDbqJEGK5A%2Foptimizing-for-attractiveness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 657, "htmlBody": "<p>I want to spend a substantial fraction of my time optimizing myself in the direction of being more attractive to females, and I'd really appreciate your suggestions on how to do so.</p>\n<p><strong>Why</strong></p>\n<p>It should be pretty self-explanatory, but in case you're wondering: relationships are a big part of personal happiness, and where I am now, I feel more inclined toward increasing the number and variability of short- or middle-term sexual relationships rather than just picking a girl who wants to be my wife and run with it. But at the moment women aren't exactly chasing me down the streets, so I want to offer them a more pleasant experience of my company than what it already is.</p>\n<p><strong>Mind-killing</strong></p>\n<p>I sincerely think this post should provoke none of the above. I'm not asking for ways to trick women into liking me, nor about gender differences about what males prefer over females, etc. <em>Please</em>&nbsp;try really hard to avoid mind-killing subjects into your comments. I'm 'just' asking for ways to change myself into being a more sexually attractive human being.</p>\n<p><strong>Caveat(s)</strong></p>\n<p>I'm aware of the dichotomy lying around: attraction can be created vs attraction can only be amplified. In both cases there should be at least <em>something</em>&nbsp;that can be done.<br />I'm also aware that some people strongly dislike posts full of personal details, so I will try to keep them at minimum, while at the same time trying to provide the necessary description of my situation.</p>\n<p><strong>I would like</strong></p>\n<p>Try to aim for advice on stable improvements, about aspects that are proven to be sexually attractive to straight females, in the age range of 20 to 40.<br />For example, I know that height or facial symmetry are proven to result universally attractive, but I cannot really change that, and sole-lifts or make-up are so short-term solutions to border on 'tricking women' (yes, I know that women use those tricks too, I simply would like to invest my time better).</p>\n<p><strong>My situation</strong></p>\n<p>This is the shortest possible description: I'm a straight male in my thirties, heavily overweight, living in Italy in a 20k people town, with a job paying me about $20k a year.<br />If you think you need more details ask for them in the comments or PM me.</p>\n<p><strong>What I'm already doing/planning to do</strong></p>\n<p>The first obvious choice is getting fit, although it's about two years I'm trying different diets with no results, so I'd really need pointers in that direction. I've also heard about training programs that tells you to concentrate on shoulders, because apparently shoulder-to-waist ratio of 1.5 or more is especially attractive.<br />I've also been told multiple times by multiple sources that women values confidence, competence and leadership. I understand the confidence part in being able to express without embarassment your interest (but still in a socially graceful manner), but I would really like pointers about what area of my life I could engage to become more competent or a leader. In what domains women like competence/leadership?<br />My only hobby at the moment are the game of Go and dabbing in math/logics/AI, which, as fascinating as they are, are seldom considered very attractive.</p>\n<p><strong>What I'm not sure about</strong></p>\n<p>Is fashion important? I understand that I need to dress well for my built, but I would like to know if a Versace button down shirt is more attractive than a plain brand one.</p>\n<p><strong>False beliefs</strong></p>\n<p>Do you think am I doing the right thing? Or am I wrong in my search for attractiveness? Should I concentrate on something totally unrelated? Dose the physical aspect matter or I should concentrate more on character? Am I completely off track?<br />If you think I'm grossly mistaken, in the name of Omega let me know!</p>\n<p><strong>Downvote</strong></p>\n<p>If you think this post doesn't belong in a community devoted rationality and self-improvement, feel free to downvote, but at least try to indicate a way to better phrase the problem or point me to another community I can ask the same question.</p>\n<p>Thank you very much!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zfzDnCqfDbqJEGK5A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 17, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "22795", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I want to spend a substantial fraction of my time optimizing myself in the direction of being more attractive to females, and I'd really appreciate your suggestions on how to do so.</p>\n<p><strong id=\"Why\">Why</strong></p>\n<p>It should be pretty self-explanatory, but in case you're wondering: relationships are a big part of personal happiness, and where I am now, I feel more inclined toward increasing the number and variability of short- or middle-term sexual relationships rather than just picking a girl who wants to be my wife and run with it. But at the moment women aren't exactly chasing me down the streets, so I want to offer them a more pleasant experience of my company than what it already is.</p>\n<p><strong id=\"Mind_killing\">Mind-killing</strong></p>\n<p>I sincerely think this post should provoke none of the above. I'm not asking for ways to trick women into liking me, nor about gender differences about what males prefer over females, etc. <em>Please</em>&nbsp;try really hard to avoid mind-killing subjects into your comments. I'm 'just' asking for ways to change myself into being a more sexually attractive human being.</p>\n<p><strong id=\"Caveat_s_\">Caveat(s)</strong></p>\n<p>I'm aware of the dichotomy lying around: attraction can be created vs attraction can only be amplified. In both cases there should be at least <em>something</em>&nbsp;that can be done.<br>I'm also aware that some people strongly dislike posts full of personal details, so I will try to keep them at minimum, while at the same time trying to provide the necessary description of my situation.</p>\n<p><strong id=\"I_would_like\">I would like</strong></p>\n<p>Try to aim for advice on stable improvements, about aspects that are proven to be sexually attractive to straight females, in the age range of 20 to 40.<br>For example, I know that height or facial symmetry are proven to result universally attractive, but I cannot really change that, and sole-lifts or make-up are so short-term solutions to border on 'tricking women' (yes, I know that women use those tricks too, I simply would like to invest my time better).</p>\n<p><strong id=\"My_situation\">My situation</strong></p>\n<p>This is the shortest possible description: I'm a straight male in my thirties, heavily overweight, living in Italy in a 20k people town, with a job paying me about $20k a year.<br>If you think you need more details ask for them in the comments or PM me.</p>\n<p><strong id=\"What_I_m_already_doing_planning_to_do\">What I'm already doing/planning to do</strong></p>\n<p>The first obvious choice is getting fit, although it's about two years I'm trying different diets with no results, so I'd really need pointers in that direction. I've also heard about training programs that tells you to concentrate on shoulders, because apparently shoulder-to-waist ratio of 1.5 or more is especially attractive.<br>I've also been told multiple times by multiple sources that women values confidence, competence and leadership. I understand the confidence part in being able to express without embarassment your interest (but still in a socially graceful manner), but I would really like pointers about what area of my life I could engage to become more competent or a leader. In what domains women like competence/leadership?<br>My only hobby at the moment are the game of Go and dabbing in math/logics/AI, which, as fascinating as they are, are seldom considered very attractive.</p>\n<p><strong id=\"What_I_m_not_sure_about\">What I'm not sure about</strong></p>\n<p>Is fashion important? I understand that I need to dress well for my built, but I would like to know if a Versace button down shirt is more attractive than a plain brand one.</p>\n<p><strong id=\"False_beliefs\">False beliefs</strong></p>\n<p>Do you think am I doing the right thing? Or am I wrong in my search for attractiveness? Should I concentrate on something totally unrelated? Dose the physical aspect matter or I should concentrate more on character? Am I completely off track?<br>If you think I'm grossly mistaken, in the name of Omega let me know!</p>\n<p><strong id=\"Downvote\">Downvote</strong></p>\n<p>If you think this post doesn't belong in a community devoted rationality and self-improvement, feel free to downvote, but at least try to indicate a way to better phrase the problem or point me to another community I can ask the same question.</p>\n<p>Thank you very much!</p>", "sections": [{"title": "Why", "anchor": "Why", "level": 1}, {"title": "Mind-killing", "anchor": "Mind_killing", "level": 1}, {"title": "Caveat(s)", "anchor": "Caveat_s_", "level": 1}, {"title": "I would like", "anchor": "I_would_like", "level": 1}, {"title": "My situation", "anchor": "My_situation", "level": 1}, {"title": "What I'm already doing/planning to do", "anchor": "What_I_m_already_doing_planning_to_do", "level": 1}, {"title": "What I'm not sure about", "anchor": "What_I_m_not_sure_about", "level": 1}, {"title": "False beliefs", "anchor": "False_beliefs", "level": 1}, {"title": "Downvote", "anchor": "Downvote", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "225 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 225, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T15:19:03.100Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-48", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CqdcQFXyLgicamscY/weekly-lw-meetups-48", "pageUrlRelative": "/posts/CqdcQFXyLgicamscY/weekly-lw-meetups-48", "linkUrl": "https://www.lesswrong.com/posts/CqdcQFXyLgicamscY/weekly-lw-meetups-48", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCqdcQFXyLgicamscY%2Fweekly-lw-meetups-48%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCqdcQFXyLgicamscY%2Fweekly-lw-meetups-48", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCqdcQFXyLgicamscY%2Fweekly-lw-meetups-48", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 485, "htmlBody": "<p><strong>This summary was posted to LW Main on May 24th. The following week's summary is <a href=\"/lw/hl9/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n<li><a href=\"/meetups/mx\">Bristol meetup:&nbsp;<span class=\"date\">25 May 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/n2\">[Chicago] Fermi Estimates in Chicago:&nbsp;<span class=\"date\">25 May 2013 03:00PM</span></a></li>\n<li><a style=\"color: #8a8a8b; font-family: Arial, Helvetica, sans-serif; font-size: 13px; line-height: 19px; text-align: justify;\" href=\"/meetups/m2\"></a><a href=\"/meetups/mv\">London Meetup: 26th May:&nbsp;<span class=\"date\">26 May 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/mt\">[Moscow] Belief cleaning:&nbsp;<span class=\"date\">26 May 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/n3\">Munich Meetup:&nbsp;<span class=\"date\">01 June 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/lo\"></a><a href=\"/meetups/mr\">Paris Meetup: Sunday, May 26.:&nbsp;<span class=\"date\">26 May 2013 02:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">25 May 2019 01:30PM</span></a><a href=\"/meetups/bx\"></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CqdcQFXyLgicamscY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2171107018918153e-06, "legacy": true, "legacyId": "22705", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["F42JLyeBd5dfhRDGu", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T16:46:48.168Z", "modifiedAt": null, "url": null, "title": "Great big ocean waves in an even bigger blank spot", "slug": "great-big-ocean-waves-in-an-even-bigger-blank-spot", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:02.393Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KiWd6qwnShvkvdg3r/great-big-ocean-waves-in-an-even-bigger-blank-spot", "pageUrlRelative": "/posts/KiWd6qwnShvkvdg3r/great-big-ocean-waves-in-an-even-bigger-blank-spot", "linkUrl": "https://www.lesswrong.com/posts/KiWd6qwnShvkvdg3r/great-big-ocean-waves-in-an-even-bigger-blank-spot", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Great%20big%20ocean%20waves%20in%20an%20even%20bigger%20blank%20spot&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGreat%20big%20ocean%20waves%20in%20an%20even%20bigger%20blank%20spot%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKiWd6qwnShvkvdg3r%2Fgreat-big-ocean-waves-in-an-even-bigger-blank-spot%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Great%20big%20ocean%20waves%20in%20an%20even%20bigger%20blank%20spot%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKiWd6qwnShvkvdg3r%2Fgreat-big-ocean-waves-in-an-even-bigger-blank-spot", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKiWd6qwnShvkvdg3r%2Fgreat-big-ocean-waves-in-an-even-bigger-blank-spot", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 187, "htmlBody": "<p><a href=\"http://www.amazon.com/The-Wave-Pursuit-Rogues-Freaks/dp/0767928857\">The Wave: In Pursuit of the Rogues, Freaks, and Giants of the Ocean</a> is a book about very big ocean waves-- the science, the danger (mostly to ships), and the surfers.</p>\n<p>Really big waves weren't scientifically verified until about ten years ago-- part of the problem was that even though sailors had been reporting huge waves, scientists had a theory that big waves (maybe over 80', though I don't have a sharp dividing line) required very rare conditions. Once satellite surveillance for waves was possible, it turned out that big waves were fairly common, and might explain why a ship or two per week disappears.</p>\n<p><a href=\"https://noc.ac.uk/people/rbw1\">Russell Wynn</a>: \"The way the radar system works, the very big ones are difficult to measure,\" he said. When behemoth waves appeared in the satellite data, the space agencies considered these readings to be errors, and they were automatically deleted. \"They give you missing value code instead, which is really annoying. We shout at them for that.\"</p>\n<p>The reason I'm posting this is that I've become very skeptical about any theory which claims that something which is well-attested and physically possible is actually not happening.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KiWd6qwnShvkvdg3r", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 16, "extendedScore": null, "score": 5.3e-05, "legacy": true, "legacyId": "22798", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T16:49:23.151Z", "modifiedAt": null, "url": null, "title": "[link] Join Wall Street. Save the World", "slug": "link-join-wall-street-save-the-world", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.353Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pablo_Stafforini", "createdAt": "2009-03-24T12:56:00.130Z", "isAdmin": false, "displayName": "Pablo"}, "userId": "W7ETRtvRMqYetyQE9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AmrhcWmLEn44nWYz5/link-join-wall-street-save-the-world", "pageUrlRelative": "/posts/AmrhcWmLEn44nWYz5/link-join-wall-street-save-the-world", "linkUrl": "https://www.lesswrong.com/posts/AmrhcWmLEn44nWYz5/link-join-wall-street-save-the-world", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Join%20Wall%20Street.%20Save%20the%20World&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Join%20Wall%20Street.%20Save%20the%20World%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAmrhcWmLEn44nWYz5%2Flink-join-wall-street-save-the-world%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Join%20Wall%20Street.%20Save%20the%20World%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAmrhcWmLEn44nWYz5%2Flink-join-wall-street-save-the-world", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAmrhcWmLEn44nWYz5%2Flink-join-wall-street-save-the-world", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 833, "htmlBody": "<p>A very interesting <a href=\"http://api.viglink.com/api/click?format=go&amp;key=9f37ca02a1e3cbd4f3d0a3618a39fbca&amp;loc=http%3A%2F%2Flesswrong.com%2Flw%2Fhlb%2Flink_join_wall_street_save_the_world%2F%23comments&amp;v=1&amp;libId=7d92491c-7032-4bbe-9ad0-bf75a00c7fe5&amp;out=http%3A%2F%2Fwww.washingtonpost.com%2Fblogs%2Fwonkblog%2Fwp%2F2013%2F05%2F31%2Fjoin-wall-street-save-the-world%2F&amp;ref=http%3A%2F%2Flesswrong.com%2Fuser%2Fbenthamite%2Foverview%2F&amp;title=%5Blink%5D%20Join%20Wall%20Street.%20Save%20the%20World%20-%20Less%20Wrong&amp;txt=original%20article&amp;jsonp=vglnk_jsonp_13700303661766\">article</a> on \"<a href=\"http://80000hours.org/earning-to-give\">earning to give</a>\", featuring &nbsp;LessWrong members&nbsp;<a href=\"/user/jkaufman/overview/\">Jeff Kaufman</a>, <a href=\"/user/juliawise/overview/\">Julia Wise</a>,&nbsp;<a href=\"/user/HoldenKarnofsky/overview/\">Holden Karnofsky</a>, <a href=\"/user/wdcrouch/overview/\">William MacAskill</a>&nbsp;and <a href=\"/user/Toby_Ord/overview/\">Toby Ord</a>. &nbsp;Some excerpts:</p>\n<blockquote>\n<p>Jason Trigg went into finance because he is after money &mdash; as much as he can earn.</p>\n<p>The 25-year-old certainly had other career options. An MIT computer science graduate, he could be writing software for the next tech giant. Or he might have gone into academia in computing or applied math or even biology. He could literally be working to cure cancer.</p>\n<p>Instead, he goes to work each morning for a high-frequency trading firm. It&rsquo;s a hedge fund on steroids. He writes software that turns a lot of money into even more money. For his labors, he reaps an uptown salary &mdash; and over time his earning potential is unbounded. It&rsquo;s all part of the plan.</p>\n<p>Why this compulsion? It&rsquo;s not for fast cars or fancy houses. Trigg makes money just to give it away. His logic is simple: The more he makes, the more good he can do. [...]</p>\n<p>Two former analysts at the mega-hedge fund Bridgewater and Associates have worked to change that. Holden Karnofsky and Elie Hassenfeld created GiveWell, a nonprofit that analyzes charities to help people decide where to give, rather than how much to give. They take into account, for instance, that a malaria donation can save a life, while a check sent to the New York City Ballet probably cannot. (Although it may produce a slightly better version of &ldquo;Swan Lake.&rdquo;) [...]</p>\n<p>Take Jeff Kaufman. A Cambridge, Mass.-based developer at Google, Kaufman and his wife, Julia Wise, managed to live on $10,000 in 2012, they say. Together, they give away at least 45 percent of their income each year (the rest goes to savings and taxes). Kaufman and Wise meticulously document their spending on their blogs. In 2010, for example, they spent a measly $164.44 on groceries each month and gave themselves $38 apiece to spend each week on nonessentials (including all non-grocery meals). In 2012, they moved in with Jeff&rsquo;s family, which saved even more money, they say. [...]</p>\n<p>If GiveWell makes the empirical argument to the public, Giving What We Can makes the moral one.</p>\n<p>Toby Ord, the founder, is an Australian philosopher teaching at Oxford. That&rsquo;s hardly an accident. Oxford&rsquo;s philosophy department is chock-full of consequentialists, or ethicists who think morality is about maximizing the good, however one defines &ldquo;good.&rdquo;</p>\n<p>The group conducts charity evaluations and is a grass-roots network for those trying to live the consequentialist lifestyle. At least in Britain, the idea took off fast, and not just with avowed consequentialists and utilitarians.</p>\n<p>The group has been profiled across Britain, in the Guardian, the Daily Mail and the BBC. The initial coverage focused on Ord&rsquo;s promise in 2010 to give &pound;1 million (or $1.5 million) to charity over his life, a tall order for an Oxford fellow making $50,000 a year. But somewhere along the line, Ord&rsquo;s colleague and charity co-founder Will MacAskill hit upon an even catchier pitch. At the height of the Occupy movement in late 2011, he gave a talk at Oxford titled: &ldquo;Want an ethical career? Become a banker.&rdquo;</p>\n<p>MacAskill, like Trigg, realized that percentages don&rsquo;t matter. Absolutes do. Ord may be able to give $1.5 million over the course of his life, but Goldman Sachs chief executive Lloyd Blankfein made more than $15 million in 2012 alone. Before the crisis, Blankfein was clearing $50 million annually. And investment bankers don&rsquo;t even get the biggest cut. Hedge fund manager John Paulson made $5 billion in 2010. Suppose Paulson were to keep his job, move to a studio in Hoboken, reduce his living expenses to $30,000 a year, and give the rest of the $5 billion away. He could save 3,000 times as many lives in a year as Ord could save in 80 years. So why not enter finance with the express goal of using earnings to save lives? [...]</p>\n<p>It&rsquo;s hard to imagine a 25-year-old Peter Singer envisioning that an article he published in Philosophy and Public Affairs would push people like Jason Trigg into the financial sector.</p>\n<p>But the 66-year-old Singer of today welcomes the result. In between fending off religious opponents and helping lead the animal rights movement, he&rsquo;s been doing a fair bit of giving advocacy himself. He has his own group, The Life You Can Save, spun off from his book of the same name, which also organizes at universities and works as an informal ally of Giving What We Can and 80,000 Hours.</p>\n<p>And he embraces earning-to-give as among the most ethical career choices one can make, more moral than his own, even. &ldquo;There is a relatively small group of philosophers who actually have a big influence,&rdquo; he says from his home in Australia. &ldquo;But otherwise, the marginal difference that you&rsquo;re going to make as a professor of philosophy compared to somebody else is not all that great.&rdquo;</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"qAvbtzdG2A2RBn7in": 1, "4kQXps8dYsKJgaayN": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AmrhcWmLEn44nWYz5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 36, "extendedScore": null, "score": 1.217177883324228e-06, "legacy": true, "legacyId": "22799", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-05-31T18:49:10.861Z", "modifiedAt": null, "url": null, "title": "Will the world's elites navigate the creation of AI just fine?", "slug": "will-the-world-s-elites-navigate-the-creation-of-ai-just", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:37.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ba8LNjWKDF5nrn9Q6/will-the-world-s-elites-navigate-the-creation-of-ai-just", "pageUrlRelative": "/posts/Ba8LNjWKDF5nrn9Q6/will-the-world-s-elites-navigate-the-creation-of-ai-just", "linkUrl": "https://www.lesswrong.com/posts/Ba8LNjWKDF5nrn9Q6/will-the-world-s-elites-navigate-the-creation-of-ai-just", "postedAtFormatted": "Friday, May 31st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Will%20the%20world's%20elites%20navigate%20the%20creation%20of%20AI%20just%20fine%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWill%20the%20world's%20elites%20navigate%20the%20creation%20of%20AI%20just%20fine%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa8LNjWKDF5nrn9Q6%2Fwill-the-world-s-elites-navigate-the-creation-of-ai-just%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Will%20the%20world's%20elites%20navigate%20the%20creation%20of%20AI%20just%20fine%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa8LNjWKDF5nrn9Q6%2Fwill-the-world-s-elites-navigate-the-creation-of-ai-just", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBa8LNjWKDF5nrn9Q6%2Fwill-the-world-s-elites-navigate-the-creation-of-ai-just", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 577, "htmlBody": "<p>One open question in AI risk strategy is: Can we trust the world's elite decision-makers (hereafter \"elites\") to navigate the creation of human-level AI (and beyond) just fine, without the kinds of special efforts that e.g. Bostrom and Yudkowsky think are needed?</p>\n<p>Some reasons for <em>concern</em> include:</p>\n<ul>\n<li>Otherwise smart people say unreasonable things about AI safety. </li>\n<li>Many people who believed AI was around the corner didn't take safety very seriously.</li>\n<li>Elites have failed to navigate many important issues wisely (2008 financial crisis, climate change, Iraq War, etc.), for a variety of reasons.</li>\n<li>AI may arrive rather suddenly, leaving little time for preparation.</li>\n</ul>\n<p>But if you were trying to argue for <em>hope</em>, you might argue along these lines (presented for the sake of argument; I don't actually endorse this argument):</p>\n<ul>\n<li><em>If AI is preceded by visible signals, elites are likely to take safety measures.</em> Effective measures were taken to address asteroid risk. Large resources are devoted to mitigating climate change risks. Personal and tribal selfishness align with AI risk-reduction in a way they may not align on climate change. Availability of information is increasing over time.</li>\n<li><em>AI is likely to be preceded by visible signals.</em> Conceptual insights often take years of incremental tweaking. In vision, speech, games, compression, robotics, and other fields, performance curves are mostly smooth. \"Human-level performance at X\" benchmarks influence perceptions and should be more exhaustive and come more rapidly as AI approaches. Recursive self-improvement capabilities could be charted, and are likely to be AI-complete. If AI succeeds, it will likely succeed for reasons comprehensible by the AI researchers of the time.</li>\n<li><em>Therefore, safety measures will likely be taken</em>.</li>\n<li><em>If safety measures are taken, then elites will navigate the creation of AI just fine.</em> Corporate and government leaders can use simple heuristics (e.g. Nobel prizes) to access the upper end of expert opinion. AI designs with easily tailored tendency to act may be the easiest to build. The use of early AIs to solve AI safety problems creates an attractor for \"safe, powerful AI.\" Arms races not insurmountable.</li>\n</ul>\n<p>The basic structure of this 'argument for hope' is due to Carl Shulman, though he doesn't necessarily endorse the details. (Also, it's just a rough argument, and as stated is not deductively valid.)</p>\n<p>Personally, I am not very comforted by this argument because:</p>\n<ul>\n<li>Elites often fail to take effective action despite plenty of warning.</li>\n<li>I think there's a &gt;10% chance AI will not be preceded by visible signals.</li>\n<li>I think the elites' safety measures will likely be insufficient.</li>\n</ul>\n<p>Obviously, there's a lot more for me to spell out here, and some of it may be unclear. The reason I'm posting these thoughts in such a rough state is so that <a href=\"http://intelligence.org/\">MIRI</a> can get some help on our research into this question.</p>\n<p>In particular, I'd like to know:</p>\n<ul>\n<li><em>Which historical events are analogous to AI risk in some important ways?</em> Possibilities include: nuclear weapons, climate change, recombinant DNA, nanotechnology, chloroflourocarbons, asteroids, cyberterrorism, Spanish flu, the 2008 financial crisis, and large wars. </li>\n<li><em>What are some good resources (e.g. books) for investigating the relevance of these analogies to AI risk</em> (for the purposes of illuminating elites' likely response to AI risk)? </li>\n<li><em>What are some good studies on elites' decision-making abilities in general?</em> </li>\n<li><em>Has the increasing availability of information in the past century noticeably improved elite decision-making?</em> </li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZFrgTgzwEfStg26JL": 1, "x3zyEPFaJANB2BHmP": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ba8LNjWKDF5nrn9Q6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 36, "extendedScore": null, "score": 8.5e-05, "legacy": true, "legacyId": "22800", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 266, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-01T00:00:51.680Z", "modifiedAt": null, "url": null, "title": "A World War I example showing the danger of deceiving your own side", "slug": "a-world-war-i-example-showing-the-danger-of-deceiving-your", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:10.654Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "James_Miller", "createdAt": "2009-03-05T17:14:38.674Z", "isAdmin": false, "displayName": "James_Miller"}, "userId": "LzF2X9eB9oS3q4BXG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8tPtuGGupaRydpk6i/a-world-war-i-example-showing-the-danger-of-deceiving-your", "pageUrlRelative": "/posts/8tPtuGGupaRydpk6i/a-world-war-i-example-showing-the-danger-of-deceiving-your", "linkUrl": "https://www.lesswrong.com/posts/8tPtuGGupaRydpk6i/a-world-war-i-example-showing-the-danger-of-deceiving-your", "postedAtFormatted": "Saturday, June 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20World%20War%20I%20example%20showing%20the%20danger%20of%20deceiving%20your%20own%20side&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20World%20War%20I%20example%20showing%20the%20danger%20of%20deceiving%20your%20own%20side%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8tPtuGGupaRydpk6i%2Fa-world-war-i-example-showing-the-danger-of-deceiving-your%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20World%20War%20I%20example%20showing%20the%20danger%20of%20deceiving%20your%20own%20side%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8tPtuGGupaRydpk6i%2Fa-world-war-i-example-showing-the-danger-of-deceiving-your", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8tPtuGGupaRydpk6i%2Fa-world-war-i-example-showing-the-danger-of-deceiving-your", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 326, "htmlBody": "<p>The following is a summary of the short article <em><a href=\"http://www.americahistorica.com/week%206/Avenger%20Ignored.pdf\">The Avenger Ignored</a></em> by <a href=\"http://www-personal.ksu.edu/~chassan/chuckcv.htm\">Charles Sanders</a>, published in <em>Military History Magazine</em>.</p>\n<p>&nbsp;</p>\n<p>French Intelligence bought what turned out to be partial German military plans for WWI around a decade before the outbreak of the war. &nbsp;The plans detailed a German invasion of Belgium for the obvious purpose of then attacking France from the North. &nbsp;French intelligence compared map to territory finding that the plans explained much German construction which until then had seemed &ldquo;random and unthreatening&rdquo;. &nbsp; Many in the French high command came to correctly believe in the plans&rsquo; authenticity and by 1907 French military strategy reflected this.</p>\n<p>&nbsp;</p>\n<p>In 1913 many in the French military wanted to take an offensive posture with respect to the German threat. &nbsp;This posture would be more justified if Germany intended to directly attack France rather than go via Belgium. &nbsp;Therefore, French military officer Lt. Col. Edmond Buat falsely claimed to have found a copy of a German military document &ldquo;under his seat during a train trip in Germany&rdquo; that showed this. &nbsp;This imaginary document purportedly outlined a direct German attack on France that would largely ignore Belgium.</p>\n<p>&nbsp;</p>\n<p>Buat described but never showed the document to anyone. &nbsp;His hoax was still believed and France based its military deployment on the imaginary document, to disastrous effects. &nbsp;When the French military command received reports of an actual gigantic German attack on Belgium (consistent with the real military plans French Intelligence bought a decade ago) an important French General telephoned French commanders to say &ldquo;reports on German forces in Belgium are greatly exaggerated. &nbsp;There is no cause for alarm.&rdquo; &nbsp;France went ahead and executed its existing military strategy &ldquo;as if the massive, deadly threat now clearly sweeping down from the north did not exist.&rdquo;</p>\n<p>&nbsp;</p>\n<p>In 1915 Buat admitted his deception, but this didn't stop him from going on to hold &ldquo;numerous important assignments in the postwar army.&rdquo;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>I found <em>The Avenger Ignored</em> article through a <a href=\"http://www.llamacomics.com/podcast/classicBob7.mp3\">History According to Bob Podcast</a>.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8tPtuGGupaRydpk6i", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 2, "extendedScore": null, "score": 9e-06, "legacy": true, "legacyId": "22801", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-01T00:52:57.304Z", "modifiedAt": null, "url": null, "title": "Jaan Tallinn: A Skype founder on biomonitors, existential risk and simulated realities", "slug": "jaan-tallinn-a-skype-founder-on-biomonitors-existential-risk", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:56.966Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JrsoPnKK5X3zwSgj7/jaan-tallinn-a-skype-founder-on-biomonitors-existential-risk", "pageUrlRelative": "/posts/JrsoPnKK5X3zwSgj7/jaan-tallinn-a-skype-founder-on-biomonitors-existential-risk", "linkUrl": "https://www.lesswrong.com/posts/JrsoPnKK5X3zwSgj7/jaan-tallinn-a-skype-founder-on-biomonitors-existential-risk", "postedAtFormatted": "Saturday, June 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Jaan%20Tallinn%3A%20A%20Skype%20founder%20on%20biomonitors%2C%20existential%20risk%20and%20simulated%20realities&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJaan%20Tallinn%3A%20A%20Skype%20founder%20on%20biomonitors%2C%20existential%20risk%20and%20simulated%20realities%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJrsoPnKK5X3zwSgj7%2Fjaan-tallinn-a-skype-founder-on-biomonitors-existential-risk%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Jaan%20Tallinn%3A%20A%20Skype%20founder%20on%20biomonitors%2C%20existential%20risk%20and%20simulated%20realities%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJrsoPnKK5X3zwSgj7%2Fjaan-tallinn-a-skype-founder-on-biomonitors-existential-risk", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJrsoPnKK5X3zwSgj7%2Fjaan-tallinn-a-skype-founder-on-biomonitors-existential-risk", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 940, "htmlBody": "<p><a href=\"http://online.wsj.com/article/SB10001424127887324412604578513472554236916.html\">http://online.wsj.com/article/SB10001424127887324412604578513472554236916.html</a></p>\n<h3>By ALEXANDRA WOLFE</h3>\n<p>As we try to talk by Skype, Jaan Tallinn is fading in and out on my computer screen. Sitting in his living room in Estonia, he is having trouble with his connection, which may seem ironic for a co-founder of Skype, the wildly successful video chat service. But these particular technical difficulties are not Mr. Tallinn's problem these days. Since Skype was sold for $2.6 billion in 2005, making him tens of millions of dollars, he has moved on to bigger issues&mdash;like extending the span of a healthy human life and saving the species. And those are just this spring's initiatives.</p>\n<p><img style=\"border-style: none; float: left; margin: 20px\" src=\"http://si.wsj.net/public/resources/images/RV-AK669B_WKCON_DV_20130531182702.jpg\" border=\"0\" alt=\"Jaan Tallinn, co-founder of Skype and now MetaMed. Photo illustration by Kaapo Kamu for the Wall street Journal, Grooming by Olga Zhgut\" hspace=\"0\" vspace=\"0\" width=\"262\" height=\"262\" /></p>\n<p>When the screen finally clears up, Mr. Tallinn comes into view. A youthful 41-years-old, with short blond bangs and fair skin, he could be a poster boy for his latest venture, MetaMed, which promises customers personalized health-care research and analysis of their medical conditions.</p>\n<p>Health care is a relatively new focus for Mr. Tallinn, who has been interested in computer science and technology since he was 10. Born in Estonia to an architect mother and a father who directs for film and TV, he didn't get access to a computer until he was 14, when the father of one of his schoolmates selected a group of them to work in his office. There he met the friends who would eventually join him in developing Kazaa, the file-sharing application turned music-subscription service, in 2000 and then Skype in 2002.</p>\n<p>He launched MetaMed last March after a $500,000 investment from PayPal co-founder Peter Thiel. So far, the New York-based company has about a dozen employees and 20 clients, half of them friends who are trying it pro bono. The idea emerged from another of Mr. Tallinn's goals: \"surviving as a species this century.\" He has also been developing a new nonprofit called the Cambridge Project for Existential Risk with two academics.</p>\n<p>What risks worry him? \"The first one is artificial intelligence,\" he says. \"The second is the things that technological progress might create that we're unaware of right now.\"</p>\n<p>He has just read an early draft of a book by his friend Max Tegmark, a physicist at the Massachusetts Institute of Technology, arguing that the only reason nuclear bombs can't be made from instructions downloaded from the Internet is that the laws of physics luckily make it hard to do. \"There's no guarantee that wouldn't be possible,\" he says, referring to homemade nuclear bombs.</p>\n<p>His third fear is biological risk. \"There could be synthetic viruses that evolution doesn't even know how to create,\" says Mr. Tallinn. For all practical purposes, he suggests, evolution stopped with the advent of gene technology. \"The future of the planet depends much more on technology than evolution,\" he adds.</p>\n<p>Having five children with his wife of 16 years has made many of these ideas more concrete for Mr. Tallinn. \"When somebody goes all abstract on me ... saying things like, 'Perhaps humanity doesn't deserve to survive,' I say, 'Look, do you have kids? Do you realize you're talking about the death of your kids or my kids?\" Mr. Tallinn says he's always glad to hear when technology developers have children because it makes them think in the long-term.</p>\n<p>Glancing away from the screen to the trees outside his house, Mr. Tallinn laments that most people don't take these longer-term risks seriously.</p>\n<p>\"In general, it seems to me that people in society are bad at dealing with things that have never happened and overreact to things that have happened and happened recently,\" he says. As he notes, more people die slipping in the shower than in plane crashes, train accidents and terrorist attacks combined. \"Since 9/11, more Americans have been killed by falling furniture than by terrorists,\" says Mr. Tallinn.</p>\n<p>And these, in his view, may not be humankind's only blind spots. Mr. Tallinn is open to the possibility that our lives and consciousness are all part of a computer simulation. \"As our computers and technology get better at making virtual worlds, it's reasonable to expect them to be able to create virtual worlds that are indistinguishable from the real one,\" he says. \"So if you're in a single-history universe, with one real one and many simulations, the chances of being in the simulation are higher than the real thing.\"</p>\n<p>If we are indeed living in a simulation, should we behave differently? \"What we should do depends on what kind of evidence we have that we are in a simulation ... and then the critical question is why the simulation is being run.\" Mr. Tallinn won't say whether or not he believes we are in the real world or a computerized fake. \"Once you're in a simulation you don't even know&mdash;it could be that it's not even you.\"</p>\n<p>At the moment, Mr. Tallinn's virtual presence is getting fuzzy again, and his image finally fades from my screen. Calling back with his video turned off, he assures me that he is no pessimist. He looks forward to self-driving cars, which \"might completely change the logistics of civilization.\" he says. With MetaMed, he's excited by the prospect of more advanced biomonitors. And then there's the possibility of cheap gene sequencing.</p>\n<p>As Mr. Tallinn sees it, his career, from Skype to MetaMed to the Cambridge Project for Existential Risk, has followed a progressive arc. He recalls how he introduced himself at a recent party: \"First I saved about one million human relationships,\" with Skype, but it \"doesn't make sense to save human relationships if you don't make sure [people] live longer, and then make sure they don't get destroyed.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JrsoPnKK5X3zwSgj7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "22802", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-01T02:00:48.801Z", "modifiedAt": null, "url": null, "title": "A disclaimer about my effective philanthropy posts (in connection with astronomical waste)", "slug": "a-disclaimer-about-my-effective-philanthropy-posts-in", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CNJvzT95djvHedXEh/a-disclaimer-about-my-effective-philanthropy-posts-in", "pageUrlRelative": "/posts/CNJvzT95djvHedXEh/a-disclaimer-about-my-effective-philanthropy-posts-in", "linkUrl": "https://www.lesswrong.com/posts/CNJvzT95djvHedXEh/a-disclaimer-about-my-effective-philanthropy-posts-in", "postedAtFormatted": "Saturday, June 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20disclaimer%20about%20my%20effective%20philanthropy%20posts%20(in%20connection%20with%20astronomical%20waste)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20disclaimer%20about%20my%20effective%20philanthropy%20posts%20(in%20connection%20with%20astronomical%20waste)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCNJvzT95djvHedXEh%2Fa-disclaimer-about-my-effective-philanthropy-posts-in%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20disclaimer%20about%20my%20effective%20philanthropy%20posts%20(in%20connection%20with%20astronomical%20waste)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCNJvzT95djvHedXEh%2Fa-disclaimer-about-my-effective-philanthropy-posts-in", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCNJvzT95djvHedXEh%2Fa-disclaimer-about-my-effective-philanthropy-posts-in", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 333, "htmlBody": "<p class=\"MsoNormal\">My recent posts <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness and Effective Philanthropy</a> and <a href=\"/lw/hjn/earning_to_give_vs_altruistic_career_choice/\">Earning to Give vs. Altruistic Career Choice Revisited</a> concern optimal philanthropy, and I&rsquo;ll be writing more posts about optimal philanthropy in the near future.</p>\n<p class=\"MsoNormal\">My use of examples from prosaic domains such as global health has given rise to some confusion, because some members of the Less Wrong community believe that existential risk reduction is by far the best target for optimal philanthropy, and also believe that effective philanthropy in the context of global health is very disanalogous to effective philanthropy in the context of x-risk reduction. For example, <a href=\"/lw/hjn/earning_to_give_vs_altruistic_career_choice/929n\">Eliezer wrote</a>&nbsp;</p>\n<blockquote>\n<p class=\"MsoNormal\">&hellip;talking about AMF [<a href=\"http://www.givewell.org/international/top-charities/AMF\">Against Malaria Foundation</a>] in the same breath as x-risk just seems really odd. The key issues are going to be very different when you're trying to do something so near-term, established, without scary ambiguity, etc. as AMF.</p>\n</blockquote>\n<p class=\"MsoNormal\">I believe that studying the issues surrounding philanthropic opportunities in areas such as global health is in fact helpful for better understanding how to assess x-risk reduction opportunities. My reasons for thinking this don&rsquo;t fit into a few sentences, and fully understanding them requires understanding some of my thoughts about more prosaic domains. So I&rsquo;ll respond to Eliezer&rsquo;s comment at a later date.</p>\n<p class=\"MsoNormal\">For now, I&rsquo;ll just remark:</p>\n<ol>\n<li>My discussion of prosaic philanthropic domains should not be interpreted as carrying the connotation that I think that they offer more promising philanthropic opportunities than x-risk reduction charities do (though in some cases I believe that they may be).<br /></li>\n<li>&nbsp;I believe that the points that I raise in connection with prosaic philanthropic domains will eventually offer input that's helpful for thinking about optimal philanthropy within the <a href=\"http://www.lesswrong.com/lw/hjb/a_proposed_adjustment_to_the_astronomical_waste/\">astronomical waste framework</a>.<br /></li>\n<li>My reason for restricting my discussion to prosaic philanthropic domains (in some posts) is to keep the discussion from become muddled by simultaneously considering of many orthogonal issues.</li>\n</ol>\n<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>431</o:Words> <o:Characters>2463</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>20</o:Lines> <o:Paragraphs>5</o:Paragraphs> <o:CharactersWithSpaces>2889</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Note:</strong> I formerly worked as a research analyst at <a href=\"http://www.givewell.org\">GiveWell</a>. All views expressed are my own.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CNJvzT95djvHedXEh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 19, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "22803", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rNuBzyWkigrf6BWg7", "3Ss29ihXsBb8tuoxK", "5czcpvqZ4RH7orcAa"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-01T09:58:26.343Z", "modifiedAt": null, "url": null, "title": "Two Weeks of Meditation can Reduce Mind Wandering and Improve Mental Performance. ", "slug": "two-weeks-of-meditation-can-reduce-mind-wandering-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.967Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ekziTH4Jko7Q6v4tk/two-weeks-of-meditation-can-reduce-mind-wandering-and", "pageUrlRelative": "/posts/ekziTH4Jko7Q6v4tk/two-weeks-of-meditation-can-reduce-mind-wandering-and", "linkUrl": "https://www.lesswrong.com/posts/ekziTH4Jko7Q6v4tk/two-weeks-of-meditation-can-reduce-mind-wandering-and", "postedAtFormatted": "Saturday, June 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Two%20Weeks%20of%20Meditation%20can%20Reduce%20Mind%20Wandering%20and%20Improve%20Mental%20Performance.%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATwo%20Weeks%20of%20Meditation%20can%20Reduce%20Mind%20Wandering%20and%20Improve%20Mental%20Performance.%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FekziTH4Jko7Q6v4tk%2Ftwo-weeks-of-meditation-can-reduce-mind-wandering-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Two%20Weeks%20of%20Meditation%20can%20Reduce%20Mind%20Wandering%20and%20Improve%20Mental%20Performance.%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FekziTH4Jko7Q6v4tk%2Ftwo-weeks-of-meditation-can-reduce-mind-wandering-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FekziTH4Jko7Q6v4tk%2Ftwo-weeks-of-meditation-can-reduce-mind-wandering-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 677, "htmlBody": "<p>There are any <a href=\"/lw/5h9/meditation_insight_and_rationality_part_1_of_3/\">number</a> of <a href=\"/lw/5jj/meditation_insight_and_rationality_part_2_of_3/\">reasons</a> why the Less Wrong crowd might be <a href=\"/lw/2w5/vipassana_meditation_developing_metafeeling_skills/\">interested</a> in mindfulness <a href=\"/lw/bzf/mindfulness_meditation_thread/\">meditation</a>. &nbsp;Cultivating an ability to observe thoughts without being swept away in them could help in <a href=\"/lw/if/your_strength_as_a_rationalist/\">noticing when you're confused</a>, <a href=\"/lw/iw/positive_bias_look_into_the_dark/\">looking into the dark</a>, and, if you are skilled enough, <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Noticing_Confusion\">actually changing your mind</a>. &nbsp;I've been on a couple of <a href=\"http://rulerstothesky.wordpress.com/2012/08/26/the-parable-of-an-atheist-at-a-temple/\">retreats</a> myself, and I value meditation because it's a useful technique with a lot of field testing that can be studied free of the religious context it generally comes packaged in. The results have been positive -- I've learned what a mess my mind really is and my metacognitive awareness has improved noticeably.</p>\n<p>Recent <a href=\"http://www.canyons.edu/faculty/rafterm/0%200LLI%20LOVEandLOSS/Day%208%20Files/2013%20-%20Mindfulness%20Training%20Improves%20Working%20Memory%20Capacity%20and%20GRE%20Performance%20While%20Reducing%20Mind%20Wandering.pdf\">research </a>suggests that we can add improved cognitive functioning to the list (Mrazek et al., 2013). &nbsp;</p>\n<p>There is no shortage of researchers and individuals interested in better thinking, and perhaps the most effective way of doing so is to \"target a cognitive process underlying performance in a variety of contexts\". &nbsp;A great example of such a process is \"the ability to attend to a task without distraction\", as unrelated thoughts compete with the job at hand for limited working memory. Based on this it makes sense to hypothesize that, if mindfulness training can reduce mind-wandering and distractedness, it ought to boost mental performance. &nbsp;</p>\n<p>Psychologists at the University of California Santa Barbara examined this hypothesis using a test of reading comprehension and a test of working memory capacity. &nbsp;Forty eight subjects, all undergraduates, were given two tasks: one, a modified version of the GRE verbal section and two, a test of working memory called the operation span task. &nbsp;The verbal section simply had all the vocabulary questions removed, while the operation span task alternates something that must be memorized (like a letter) with something irrelevant (like an equation which must be evaluated as true or false). &nbsp;If compared to someone else you can hold a longer string of memorized letters in your mind while also accurately evaluating equations, then you have a better working memory. &nbsp;</p>\n<p>Importantly, during these tasks a couple of different techniques were used to assess mind-wandering, including asking subjects to assess themselves after the fact and asking them semi-randomly during the task. &nbsp;</p>\n<p>Then the subjects were divided into a group which attended a two-week class on nutrition and a group which attended a two-week class on mindfulness meditation. &nbsp;Meditation instruction was pretty straightforward:&nbsp;</p>\n<blockquote>\n<p>\"Each class included 10 to 20 min of mindfulness exercises requiring focused attention to some aspect of sensory experience (e.g., sensations of breathing, tastes of a piece of fruit, or sounds of an audio recording)...Classes focused on (a) sitting in an upright posture with legs crossed and gaze lowered, (b) distinguishing between naturally arising thoughts and elaborated thinking, (c) minimizing the distracting quality of past and future concerns by reframing them as mental projections occurring in the present, (d) using the breath as an anchor for attention during meditation, (e) repeatedly counting up to 21 consecutive exhalations, and (f) allowing the mind to rest naturally rather than trying to suppress the occurrence of thoughts.</p>\n</blockquote>\n<p>Two-weeks later, the groups were tested again and it was found that:</p>\n<blockquote>\n<p>relative to nutrition training, which did not cause changes in performance or mind wandering, the mindfulness training led to an enhancement of performance that was mediated by reduced mind wandering among participants who had been prone to mind wandering at pretesting.&nbsp;</p>\n</blockquote>\n<p>I couldn't help but wonder about how much of a positive effect could be had by someone who didn't actually do the meditation. An interesting additional experiment to have done would've been explaining (b) and (c) (in the first block quote) to participants, asking them how much their minds wandered semi-randomly during a task and then after a task, and testing them again two weeks later. &nbsp;Is <em>noticing</em>&nbsp;the problem enough to get a partial solution, or does flexing your attention add something that you can't get any other way? &nbsp;</p>\n<p>This is good news for those of us who would like to get the most out of our brains in an age before really high-octane cognitive enhancements are available. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ekziTH4Jko7Q6v4tk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 21, "extendedScore": null, "score": 1.2179436524785124e-06, "legacy": true, "legacyId": "22781", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QqSNFcGSZdnARx56E", "QjoTFHzvrxQg9A6j3", "NTkBCFJSA4PFBxSM9", "Fy8rArz7PbJ9EKmg8", "5JDkW4MYXit2CquLs", "rmAbiEKQDpDnZzcRf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-01T23:37:31.970Z", "modifiedAt": null, "url": null, "title": "June 2013 Media Thread", "slug": "june-2013-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:19.812Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JBFLZFu5hiS6X7mMS/june-2013-media-thread", "pageUrlRelative": "/posts/JBFLZFu5hiS6X7mMS/june-2013-media-thread", "linkUrl": "https://www.lesswrong.com/posts/JBFLZFu5hiS6X7mMS/june-2013-media-thread", "postedAtFormatted": "Saturday, June 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20June%202013%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJune%202013%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBFLZFu5hiS6X7mMS%2Fjune-2013-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=June%202013%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBFLZFu5hiS6X7mMS%2Fjune-2013-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJBFLZFu5hiS6X7mMS%2Fjune-2013-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 185, "htmlBody": "<p>This is the monthly thread for posting media of various types that you've found that you enjoy. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the <a href=\"/r/discussion/tag/media_thread/\">older threads</a>.</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a <a href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees for genres. There is a meta thread for comments about future threads.</li>\n<li>If you think there should be a thread for a particular genre of media, please post it to the Other Media thread for now, and add a poll to the Meta thread asking if it should be a thread every month.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JBFLZFu5hiS6X7mMS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 8, "extendedScore": null, "score": 1.2185537900809524e-06, "legacy": true, "legacyId": "22810", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T01:46:53.931Z", "modifiedAt": null, "url": null, "title": "Karma as Money", "slug": "karma-as-money", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:31.994Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tnPidfPCYGLRtMhzz/karma-as-money", "pageUrlRelative": "/posts/tnPidfPCYGLRtMhzz/karma-as-money", "linkUrl": "https://www.lesswrong.com/posts/tnPidfPCYGLRtMhzz/karma-as-money", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Karma%20as%20Money&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKarma%20as%20Money%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtnPidfPCYGLRtMhzz%2Fkarma-as-money%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Karma%20as%20Money%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtnPidfPCYGLRtMhzz%2Fkarma-as-money", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtnPidfPCYGLRtMhzz%2Fkarma-as-money", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 434, "htmlBody": "<p>How do you gather a theory of Counterfactuals, Karma, and Economics, into a revised algorithm for thinking about Lesswrong?</p>\n<p>Thinking of Karma as money.&nbsp;</p>\n<p>There are a lot of things that one may consider worth saying on Lesswrong. Things that go against the agenda, things that may make people unconfortable, things that are different from what the high-ranking officials would prefer to read here. But we don't do it, because we don't want to \"loose\" precious Karma points. Each Karma point loss is felt as an insecurity, as a tiny arrow penetrating the chest. &nbsp;But should it be that way?&nbsp;</p>\n<p>Here is the alternative: Think of Karma as money. You work hard for getting a few karma points by writing interesting stuff on superintelligence and whatnot, society rewards you by paying some karma points. Then you go there and write something you think people need to hear, but will downvote for sure, at least initially. Some people by now will be very rich, which affords them the opportunity of saying a lot of things that they are not sure will get themselves upvoted, but are sure should be posted.</p>\n<p><em>Citizen: </em>Wait, you said counterfactuals...</p>\n<p>Yes, just like your State doesn't really care or like you going out in your hovercraft through the river and using equipment to climb a mountain, so the people here may not care about putting attention into that idea which <a href=\"/lw/a2f/on_what_selves_are_cev_sequence/\">you think they should hear</a>. Thus, they dowvote it. They make you <em>pay</em>&nbsp;for their attention. If you mentalize it as \"they are drawing my soul and life is worthless if karma is negative\", then you are much less likely to end up posting something <a href=\"/sex\">controversial</a> that <a href=\"/r/discussion/lw/af0/troubles_with_cev_part1_cev_sequence/\">may be counterfactually relevant</a>.&nbsp;</p>\n<p>Just like efficient charity donation works because the vast majority of people are not paying to effectively cause others into being happier, using karma as money works because the vast majority of people are afraid their soul is being sucked every time a downvote comes. But it isn't, this is just the price people charge for their attention, if you think the way I'm tentatively suggesting. &nbsp;It is just a test worth trying, not necessarily something that I fully endorse. I like the idea, and have been using it since forever. Every post linked here, or an earlier&nbsp;<a href=\"/lw/gkx/is_getting_more_utilons_your_true_acceptance/\">subpart</a> of <a href=\"/Calibrating Against Undetectable Utilons and Goal Changing Events (part2and1)\">it</a>, has been negative at some point, and from before posting, I knew it would be a \"costly one\". &nbsp;Try it, if you are rich, you may have nothing much to loose, and more <a href=\"/lw/fry/how_to_avoid_the_conflict_between_feminism_and/\">controversial</a> but <a href=\"/lw/hjx/is_there_any_way_to_avoid_post_narcissism_with/\">useful</a> stuff will show up with time. &nbsp;</p>\n<p>Let's see how much this costs.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tnPidfPCYGLRtMhzz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": -3, "extendedScore": null, "score": 1.2186502034079389e-06, "legacy": true, "legacyId": "22811", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DGfPyJbynXZF9NGv4", "pR5Wn7bJQWRPYNGsF", "bx5oaL2BDmWxrHyQb", "x6WkBHYEiqDYCpsnX", "8M4jbP66esGS3MCwS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T02:22:15.913Z", "modifiedAt": null, "url": null, "title": "Open Thread, June 2-15, 2013", "slug": "open-thread-june-2-15-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:31.542Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TimS", "createdAt": "2011-10-11T12:16:35.235Z", "isAdmin": false, "displayName": "TimS"}, "userId": "pewD8vNSS3LGCvE4t", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k4S7cZ8bjZeqbQqf9/open-thread-june-2-15-2013", "pageUrlRelative": "/posts/k4S7cZ8bjZeqbQqf9/open-thread-june-2-15-2013", "linkUrl": "https://www.lesswrong.com/posts/k4S7cZ8bjZeqbQqf9/open-thread-june-2-15-2013", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20June%202-15%2C%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20June%202-15%2C%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4S7cZ8bjZeqbQqf9%2Fopen-thread-june-2-15-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20June%202-15%2C%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4S7cZ8bjZeqbQqf9%2Fopen-thread-june-2-15-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk4S7cZ8bjZeqbQqf9%2Fopen-thread-june-2-15-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k4S7cZ8bjZeqbQqf9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 1.218676563426834e-06, "legacy": true, "legacyId": "22812", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 436, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T02:55:00.971Z", "modifiedAt": null, "url": null, "title": "Reductionism sequence now available in audio format", "slug": "reductionism-sequence-now-available-in-audio-format", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.516Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Rick_from_Castify", "createdAt": "2012-12-03T09:33:28.512Z", "isAdmin": false, "displayName": "Rick_from_Castify"}, "userId": "XyTqQupkZ9SW7nGCB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/maD47ddQfiBCuFxrr/reductionism-sequence-now-available-in-audio-format", "pageUrlRelative": "/posts/maD47ddQfiBCuFxrr/reductionism-sequence-now-available-in-audio-format", "linkUrl": "https://www.lesswrong.com/posts/maD47ddQfiBCuFxrr/reductionism-sequence-now-available-in-audio-format", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reductionism%20sequence%20now%20available%20in%20audio%20format&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReductionism%20sequence%20now%20available%20in%20audio%20format%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmaD47ddQfiBCuFxrr%2Freductionism-sequence-now-available-in-audio-format%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reductionism%20sequence%20now%20available%20in%20audio%20format%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmaD47ddQfiBCuFxrr%2Freductionism-sequence-now-available-in-audio-format", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmaD47ddQfiBCuFxrr%2Freductionism-sequence-now-available-in-audio-format", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p>The sequence \"<a href=\"http://wiki.lesswrong.com/wiki/Reductionism_(sequence)\">Reductionism</a>\", which includes the subsequences \"<a href=\"http://wiki.lesswrong.com/wiki/Joy_in_the_Merely_Real\">Joy in the Merely Real</a>\" and \"<a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">Zombies</a>\", is now available as a <a href=\"http://castify.co/channels/43-reductionism\">professionally read podcast</a>.</p>\n<p>Thanks to those who've been listening, let us know how your experience has been thus far and what you think of the service by dropping an email to support@castify.co. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "maD47ddQfiBCuFxrr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 31, "extendedScore": null, "score": 1.2187009749899467e-06, "legacy": true, "legacyId": "22678", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T02:55:23.414Z", "modifiedAt": null, "url": null, "title": "Earning to Give vs. Altruistic Career Choice Revisited", "slug": "earning-to-give-vs-altruistic-career-choice-revisited", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:34.899Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3Ss29ihXsBb8tuoxK/earning-to-give-vs-altruistic-career-choice-revisited", "pageUrlRelative": "/posts/3Ss29ihXsBb8tuoxK/earning-to-give-vs-altruistic-career-choice-revisited", "linkUrl": "https://www.lesswrong.com/posts/3Ss29ihXsBb8tuoxK/earning-to-give-vs-altruistic-career-choice-revisited", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Earning%20to%20Give%20vs.%20Altruistic%20Career%20Choice%20Revisited&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEarning%20to%20Give%20vs.%20Altruistic%20Career%20Choice%20Revisited%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Ss29ihXsBb8tuoxK%2Fearning-to-give-vs-altruistic-career-choice-revisited%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Earning%20to%20Give%20vs.%20Altruistic%20Career%20Choice%20Revisited%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Ss29ihXsBb8tuoxK%2Fearning-to-give-vs-altruistic-career-choice-revisited", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3Ss29ihXsBb8tuoxK%2Fearning-to-give-vs-altruistic-career-choice-revisited", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2337, "htmlBody": "<p class=\"MsoNormal\">A commonly voiced sentiment in the effective altruist community is that the best way to do the most good is generally to make as much money as possible, with a view toward donating to the most cost-effective charities. This is often referred to as &ldquo;earning to give.&rdquo; In the article <a href=\"http://qz.com/57254/to-save-the-world-dont-get-a-job-at-a-charity-go-work-on-wall-street/\">To save the world, don&rsquo;t get a job at a charity; go work on Wall Street</a> William MacAskill wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">Top undergraduates who want to &ldquo;make a difference&rdquo; are encouraged to forgo the allure of Wall Street and work in the charity sector ...&nbsp;</em><em style=\"mso-bidi-font-style:normal\">while researching ethical career choice, I concluded that it&rsquo;s in fact better to earn a lot of money and donate a good chunk of it to the most cost-effective charities, a path that I call &ldquo;earning to give.&rdquo; </em><span style=\"mso-bidi-font-style:normal\">...&nbsp;</span><em style=\"mso-bidi-font-style:normal\">In general, the charitable sector is people-rich but money-poor. Adding another person to the labor pool just isn&rsquo;t as valuable as providing more money, so that more workers can be hired.</em></p>\n<p class=\"MsoNormal\">In private correspondence, MacAskill clarified that he wasn&rsquo;t arguing that &ldquo;earning to give&rdquo; is the <em style=\"mso-bidi-font-style: normal\">best</em> way to do good, only that it&rsquo;s often better than working at a given nonprofit. <span style=\"mso-spacerun:yes\">&nbsp;</span>In <a href=\"https://www.facebook.com/jefftk/posts/613456690752?comment_id=713258\">a recent comment</a> MacAskill wrote</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">I think there's too much emphasis on &ldquo;earning to give&rdquo; as the *best* option rather than as the *baseline* option</em>&nbsp;</p>\n<p class=\"MsoNormal\">and raises a number of counter-considerations against&nbsp;&ldquo;earning to give.<em style=\"mso-bidi-font-style:normal\">&rdquo;</em>&nbsp;Despite this, the idea that &ldquo;earning to give&rdquo; is optimal has caught on in the effective altruist community, and so it&rsquo;s important to discuss it.</p>\n<p class=\"MsoNormal\">Over the past three years, I myself have shifted from the position that&nbsp;<em style=\"mso-bidi-font-style:normal\">&ldquo;</em>earning to give<em style=\"mso-bidi-font-style:normal\">&rdquo;</em>&nbsp;is philanthropically optimal, to the position that <strong style=\"mso-bidi-font-weight:normal\">it&rsquo;s generally the case that one can do more good by choosing a career with high direct social value than by choosing a lucrative career with a view toward donating as much as possible</strong>.&nbsp;</p>\n<p class=\"MsoNormal\">In this post I&rsquo;ll outline some arguments in favor of this view.<a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Responses to MacAskill&rsquo;s Considerations</span></strong></p>\n<p class=\"MsoNormal\">In the article <a href=\"http://qz.com/57254/to-save-the-world-dont-get-a-job-at-a-charity-go-work-on-wall-street/\">To save the world, don&rsquo;t get a job at a charity; go work on Wall Street</a>, MacAskill gives three considerations in favor of &ldquo;earning to give.&rdquo; I respond to these considerations below. What I write should be read as a response to the article, rather than to MacAskill&rsquo;s views.&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Variance in cost-effectiveness of charities</strong></p>\n<p class=\"MsoNormal\">MacAskill wrote</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">&hellip; charities vary tremendously in the amount of good they do with the money they receive. For example, it costs about $40,000 to train and provide a guide dog for one person, but it costs less than $25 to cure one person of sight-destroying trachoma. For the cost of improving the life of one person with blindness, you can cure 1,000 people of it&hellip;it&rsquo;s unlikely that you can work for only the very best charities. In contrast, if you earn to give, you can donate anywhere, preferably to the most cost-effective charities, and change your donations as often as you like.</em></p>\n<p class=\"MsoNormal\">GiveWell has spent about five years looking for the best giving opportunities in global health, and its current #1 ranked charity is <a href=\"http://www.givewell.org/international/top-charities/AMF\">Against Malaria Foundation</a> (AMF). GiveWell estimates that AMF <a href=\"http://www.givewell.org/international/top-charities/AMF#Costperlifesaved\">saves an infant&rsquo;s life for ~ $2,300</a>, not counting other benefits. These other benefits not withstanding, AMF&rsquo;s cost per <a href=\"http://www.givewell.org/international/technical/additional/DALY\">DALY saved</a> is much higher than the implied cost per DALY saved associated with the figure cited for curing sight-destroying trachoma.</p>\n<p class=\"MsoNormal\">GiveWell may have missed giving opportunities in global health that are much more cost-effective than AMF is, but given the amount of time, energy and attention that GiveWell spent on its search, one should have a strong prior against the possibility that one can easily find a better giving opportunity in global health. So a plausible estimate of the cost-effectiveness of donating to the best charity that delivers direct global health interventions is much lower than the above quotation suggests.</p>\n<p class=\"MsoNormal\">Furthermore, the phenomenon of the <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/91ia\">optimizer&rsquo;s curse</a> suggests that all charities with robust case for fairly high cost-effectiveness are closer in cost-effectiveness to AMF than explicit cost-effectiveness calculations indicate. This narrows the variance in cost-effectiveness amongst charities.&nbsp;</p>\n<p class=\"MsoNormal\">So the advantage of being able to choose a charity to support and change at any time is smaller than the above quotation suggests.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Discrepancy in earnings</strong></p>\n<p class=\"MsoNormal\">MacAskill wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">Annual salaries in banking or investment start at $80,000 and grow to over $500,000 if you do well. A lifetime salary of over $10 million is typical. Careers in nonprofits start at about $40,000, and don&rsquo;t typically exceed $100,000, even for executive directors </em><span style=\"mso-bidi-font-style:normal\"><em>... </em></span><em style=\"mso-bidi-font-style:normal\">By entering finance and donating 50% of your lifetime earnings, you could pay for two nonprofit workers in your place&mdash;while still living on double what you would have if you&rsquo;d chosen that route.</em>&nbsp;</p>\n<p class=\"MsoNormal\">The assumption &ldquo;if you do well&rdquo; is a very strong one. Only about 1% of Americans make ~$500k/year. There are some people who have a strong comparative advantage in finance, for whom &ldquo;earning to give&rdquo; to give may be especially compelling. But people who are able to make ~$500k/year in finance who <strong style=\"mso-bidi-font-weight:normal\">don&rsquo;t</strong> have a large comparative advantage in finance have <strong style=\"mso-bidi-font-weight:normal\">very strong transferable skills</strong>. Such people are significantly more capable than the average non-profit worker, and can plausibly have a bigger impact than 2 or 3 such workers by working directly on something with high social value.&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal\">Replaceability</strong></p>\n<p class=\"MsoNormal\">MacAskill wrote:</p>\n<!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">&hellip;&ldquo;making a difference&rdquo; requires<span>&nbsp;</span></span></em><em><a style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\" href=\"http://80000hours.org/blog/18-just-what-is-making-a-difference-counterfactuals-and-career-choice\"><span style=\"color: #168dd9; background-position: initial initial; background-repeat: initial initial;\">doing something that wouldn&rsquo;t have happened</span></a><span><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">&nbsp;</span><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">anyway&hellip;</span></span></em><em><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">The competition for not-for-profit jobs is fierce, and if someone else takes the job instead of you, he or she likely won&rsquo;t be much worse at it than you would have been. So the difference you make by taking the job is only the difference between the good you would do, and the good that the other person would have done.</span></em>&nbsp;</p>\n<p class=\"MsoNormal\">I would guess that there are some highly cost-effective humanitarian interventions that are sufficiently easy to implement that the implementers are easily replaceable. I could easily imagine that this is the case for vaccination efforts.&nbsp;</p>\n<p class=\"MsoNormal\">But funding opportunities for these interventions can be thought of as &ldquo;low hanging fruit.&rdquo; <a href=\"http://blog.givewell.org/2013/05/02/broad-market-efficiency/\">Broad market efficiency</a> suggests that such interventions will be funded. And indeed, GiveWell has found that straightforward immunization efforts <a href=\"http://blog.givewell.org/2013/03/21/trying-and-failing-to-find-more-funding-gaps-for-delivering-proven-cost-effective-interventions/\">are already largely funded</a>, to the point that GiveWell has been unable to find giving opportunities for individual donors in this area.&nbsp;</p>\n<p class=\"MsoNormal\">This suggests that at the margin, <strong style=\"mso-bidi-font-weight: normal\">very high value humanitarian efforts require highly skilled and highly motivated laborers</strong>.</p>\n<p class=\"MsoNormal\">High skilled laborers are a relatively small subset of laborers, so there are fewer people available to do these sorts of jobs than other jobs. Doing a hard, non-routine job well requires high motivation. <span style=\"mso-spacerun:yes\">&nbsp;</span>The collection of people who are sufficiently highly motivated to do a hard job with high social value that doesn&rsquo;t pay well, and who could otherwise be making much more money, largely consists of people who are trying to have a significant positive social impact.&nbsp;</p>\n<p class=\"MsoNormal\">So suppose that you&rsquo;re a highly skilled laborer deciding whether to &ldquo;earn to give&rdquo; or take a job with high social value that requires high skills and motivation. If you don&rsquo;t take the job with high social value, your counterfactual replacement is likely be one of the following:<br style=\"mso-special-character:line-break\" /> <!--[endif]--></p>\n<p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:38.7pt;mso-add-space: auto;text-indent:-.25in;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family:Cambria;mso-fareast-theme-font:minor-latin; mso-bidi-font-family:Cambria;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">1.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Substantially less capable than you on account of having low skills, or low altruistic motivation.</p>\n<p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left:38.7pt;mso-add-space: auto;text-indent:-.25in;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family:Cambria;mso-fareast-theme-font:minor-latin; mso-bidi-font-family:Cambria;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">2.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->A highly skilled person with high motivation, <em style=\"mso-bidi-font-style:normal\">who would be doing something else with high social value if you had taken the job, and who can&rsquo;t do this because they have to do the job that you would have done</em>.</p>\n<p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:38.7pt;mso-add-space:auto; text-indent:-.25in;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family:Cambria;mso-fareast-theme-font:minor-latin; mso-bidi-font-family:Cambria;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">3.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Nonexistent.</p>\n<p class=\"MsoNormal\">So the replaceability consideration carries less weight than it might seem.</p>\n<p class=\"MsoNormal\">Admittedly there&rsquo;s a counterconsideration &mdash;&nbsp;broad market efficiency cuts both ways, and one could imagine that the low hanging fruit in <em style=\"mso-bidi-font-style:normal\">working directly on projects with high social valu</em>e is also plucked, and this counter-consideration pushes in favor of &ldquo;earning to give.&rdquo; I have a fairly strong intuition that &ldquo;if you don&rsquo;t fund it, somebody else will&rdquo; is more true than &ldquo;if you don&rsquo;t do it, somebody else will&rdquo; so that this counter-consideration is outweighed. It&rsquo;s important to note that many projects of high social value are the first of their kind, and that finding somebody else to execute such a project is highly nontrivial. I think that it&rsquo;s also relevant that <a href=\"http://givingpledge.org/\">114 billionaires</a> have signed the Giving Pledge, committing to giving 50+% of their wealth away in their lifetimes.<span style=\"mso-spacerun:yes\">&nbsp;</span></p>\n<p class=\"MsoNormal\">In any case, there isn&rsquo;t a clear-cut, unconditional argument that favors &ldquo;earning to give&rdquo;: whether &ldquo;earning to give&rdquo; is the best option very much depends on nuanced empirical considerations rather than a general abstract argument.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Other important considerations that favor an altruistic career</span></strong></p>\n<p class=\"MsoNormal\">There are additional important considerations that favor pursuing a career with high social value over &ldquo;earning to give&rdquo;:</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Asymmetric implications of the existence of small probability failure modes</strong>&nbsp;</p>\n<p class=\"MsoNormal\">In <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>, I described how a large collection of small probability failure modes conspires to substantially reduce the expected value of a funding opportunity. The same issue applies to choosing a narrow career goal with a view toward directly having a high positive social impact. But <strong style=\"mso-bidi-font-weight:normal\">a worker has more capacity than a donor does to learn whether small probability failure modes prevail in practice, and can switch to a different job if he or she finds that such a failure mode prevails.</strong>&nbsp;</p>\n<p class=\"MsoNormal\">Here&rsquo;s an example. Suppose that you go to medical school with a view toward the possibility of performing cleft palate surgeries in the developing world. It&rsquo;s probably the case that the opportunity isn&rsquo;t as promising as it seems. But if you try it, then you&rsquo;ll be able to see how effective the intervention is firsthand. If it&rsquo;s highly effective, then you can keep doing it. If it&rsquo;s not highly effective, then you can explore other possibilities, such as&nbsp;</p>\n<ul>\n<li>Starting your own surgery organization.</li>\n<li>Switching to doing a different kind of surgery in the developing world, such as cataract removal.</li>\n<li>Working in a poor community in the developed world (which could have a bigger impact than working in the developing world owing to <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a>).</li>\n<li>Working for a biotech company.</li>\n<li>Getting involved in clinical medical research.</li>\n<li>Other things that haven't occurred to me.</li>\n</ul>\n<p class=\"MsoNormal\">By experimenting, one can hope to hone in on a job that has both high ostensible cost-effectiveness, and and a relatively small mass of small probability failure modes.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Altruistic careers extend beyond the nonprofit world</strong></p>\n<p class=\"MsoNormal\">Even on the assumption that &ldquo;earning to give&rdquo; is better than working at a nonprofit, it doesn&rsquo;t follow that &ldquo;earning to give&rdquo; optimizes social impact. There are ways to have a positive social impact in the for-profit world, in scientific research, and in the government.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Historical Precedent</strong></p>\n<p class=\"MsoNormal\">For the most part, the people who have had the biggest positive impact on the world haven&rsquo;t had their impact by &ldquo;earning to give.&rdquo;</p>\n<p class=\"MsoNormal\">There are a few possible exceptions, such as Bill Gates and Warren Buffett, whose philanthropic activities could be having a huge impact (though it&rsquo;s hard to tell from the outside) and could well outstrip the value that they contributed through their labor. But they appear to have an unusually high ratio of wealth to direct positive impact of their work, and so appear to be unrepresentative.</p>\n<p class=\"MsoNormal\">Steve Jobs&rsquo; highest net worth was on the order of $10 billion, whereas Bill Gates&rsquo; highest net worth was on the order of $100 billion. I don&rsquo;t think that Bill Gates contributed 10x as much as Steve Jobs to technology, and I don&rsquo;t think that Jobs could have had a bigger social impact by donating than through his work (which had massive positive <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a>). I acknowledge that Jobs is a cherry picked example, but I think that the general principle still holds.&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Mainstream consensus</strong></p>\n<p class=\"MsoNormal\">Few people think that &ldquo;earning to give&rdquo; is the best way to make the world a better place. This could be attributable to irrationality or to low altruism, but my experience is that there are many people who care about global welfare, or just welfare within a specific cause, and many people who are highly intelligent. In light of the existence of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Illusory_superiority\">illusory superiority</a>, one should be wary of holding an implicit view that one knows more about how to make the world a better place than the vast majority of the population.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Steelmanning wealth maximization</span></strong></p>\n<p class=\"MsoNormal\">It&rsquo;s worth highlighting some factors that <em style=\"mso-bidi-font-style:normal\">favor</em> choosing a career with a view toward maximizing wealth in some situations:</p>\n<ul>\n<li><strong style=\"mso-bidi-font-weight:normal\">Comparative advantage</strong> &mdash;&nbsp;Some people are unusually good at making money relative to doing other things. Such people may do better to &ldquo;earn to give&rdquo; than to try to choose a job that has a direct positive impact (which they&rsquo;re relatively bad at).<br /></li>\n<li><strong style=\"mso-bidi-font-weight:normal\">The market mechanism</strong>&nbsp;&mdash;&nbsp;In the for-profit world, maximizing wealth is often correlated with maximizing positive social impact, and so can be used as a proxy goal for maximizing positive social impact.<br /><strong style=\"mso-bidi-font-weight:normal\"><br /></strong></li>\n<li><span style=\"mso-bidi-font-weight:normal\"><strong>Connections and personal growth</strong></span>&nbsp;&mdash; People with high earnings are generally more capable and more knowledgeable than people in other contexts, and tend to be well connected, so positioning oneself among such people can increase one&rsquo;s prospects of soaring to greater heights. Jeff Bezos <a href=\"http://en.wikipedia.org/wiki/Jeff_Bezos#Business_career\">started his career</a> in finance, and later created Amazon, which has had massive positive social impact (both direct, and via <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a>).<br /><strong style=\"mso-bidi-font-weight:normal\"><br /></strong></li>\n<li><span style=\"mso-bidi-font-weight:normal\"><strong>Unusual values</strong></span> &mdash;&nbsp;If one cares about causes that very few people care about, then it could be difficult to find funding for work on them, so &ldquo;earning to give&rdquo; could be necessary. I don&rsquo;t believe this to be the case, but it&rsquo;s a consideration that's been raised by others, and so is worth mentioning.</li>\n</ul>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Closing summary</span></strong><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>2302</o:Words> <o:Characters>13127</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>109</o:Lines> <o:Paragraphs>30</o:Paragraphs> <o:CharactersWithSpaces>15399</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&shy;</span>There are many arguments against the claim that &ldquo;earning to give&rdquo; is generally the best way to maximize one&rsquo;s positive social impact, and I believe that choosing a job where one can do as much good as possible through one&rsquo;s work is generally the best way to maximize one&rsquo;s positive social impact. However, for some people in unusual situations, &ldquo;earning to give&rdquo; may be the best way to have a positive social impact.</p>\n<p class=\"MsoNormal\"><strong>Note:<em>&nbsp;</em></strong>I formerly worked as a research analyst at&nbsp;<a href=\"http://www.givewell.org/\">GiveWell</a>. All views expressed here are my own.</p>\n<p class=\"MsoNormal\"><strong>Acknowledgements:</strong><em style=\"font-weight: bold;\">&nbsp;</em>I thank Nick Beckstead, ModusPonies and Will Crouch for helpful feedback on an earlier version of this article.</p>\n<div style=\"mso-element:comment-list\">\n<div style=\"mso-element:comment\">\n<div id=\"_com_4\" class=\"msocomtxt\"><!--[if !supportAnnotations]--></div>\n<!--[endif]--></div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4kQXps8dYsKJgaayN": 1, "qAvbtzdG2A2RBn7in": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3Ss29ihXsBb8tuoxK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 48, "extendedScore": null, "score": 0.000195, "legacy": true, "legacyId": "22739", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\">A commonly voiced sentiment in the effective altruist community is that the best way to do the most good is generally to make as much money as possible, with a view toward donating to the most cost-effective charities. This is often referred to as \u201cearning to give.\u201d In the article <a href=\"http://qz.com/57254/to-save-the-world-dont-get-a-job-at-a-charity-go-work-on-wall-street/\">To save the world, don\u2019t get a job at a charity; go work on Wall Street</a> William MacAskill wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">Top undergraduates who want to \u201cmake a difference\u201d are encouraged to forgo the allure of Wall Street and work in the charity sector ...&nbsp;</em><em style=\"mso-bidi-font-style:normal\">while researching ethical career choice, I concluded that it\u2019s in fact better to earn a lot of money and donate a good chunk of it to the most cost-effective charities, a path that I call \u201cearning to give.\u201d </em><span style=\"mso-bidi-font-style:normal\">...&nbsp;</span><em style=\"mso-bidi-font-style:normal\">In general, the charitable sector is people-rich but money-poor. Adding another person to the labor pool just isn\u2019t as valuable as providing more money, so that more workers can be hired.</em></p>\n<p class=\"MsoNormal\">In private correspondence, MacAskill clarified that he wasn\u2019t arguing that \u201cearning to give\u201d is the <em style=\"mso-bidi-font-style: normal\">best</em> way to do good, only that it\u2019s often better than working at a given nonprofit. <span style=\"mso-spacerun:yes\">&nbsp;</span>In <a href=\"https://www.facebook.com/jefftk/posts/613456690752?comment_id=713258\">a recent comment</a> MacAskill wrote</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">I think there's too much emphasis on \u201cearning to give\u201d as the *best* option rather than as the *baseline* option</em>&nbsp;</p>\n<p class=\"MsoNormal\">and raises a number of counter-considerations against&nbsp;\u201cearning to give.<em style=\"mso-bidi-font-style:normal\">\u201d</em>&nbsp;Despite this, the idea that \u201cearning to give\u201d is optimal has caught on in the effective altruist community, and so it\u2019s important to discuss it.</p>\n<p class=\"MsoNormal\">Over the past three years, I myself have shifted from the position that&nbsp;<em style=\"mso-bidi-font-style:normal\">\u201c</em>earning to give<em style=\"mso-bidi-font-style:normal\">\u201d</em>&nbsp;is philanthropically optimal, to the position that <strong style=\"mso-bidi-font-weight:normal\">it\u2019s generally the case that one can do more good by choosing a career with high direct social value than by choosing a lucrative career with a view toward donating as much as possible</strong>.&nbsp;</p>\n<p class=\"MsoNormal\">In this post I\u2019ll outline some arguments in favor of this view.<a id=\"more\"></a></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Responses_to_MacAskill_s_Considerations\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Responses to MacAskill\u2019s Considerations</span></strong></p>\n<p class=\"MsoNormal\">In the article <a href=\"http://qz.com/57254/to-save-the-world-dont-get-a-job-at-a-charity-go-work-on-wall-street/\">To save the world, don\u2019t get a job at a charity; go work on Wall Street</a>, MacAskill gives three considerations in favor of \u201cearning to give.\u201d I respond to these considerations below. What I write should be read as a response to the article, rather than to MacAskill\u2019s views.&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Variance_in_cost_effectiveness_of_charities\">Variance in cost-effectiveness of charities</strong></p>\n<p class=\"MsoNormal\">MacAskill wrote</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">\u2026 charities vary tremendously in the amount of good they do with the money they receive. For example, it costs about $40,000 to train and provide a guide dog for one person, but it costs less than $25 to cure one person of sight-destroying trachoma. For the cost of improving the life of one person with blindness, you can cure 1,000 people of it\u2026it\u2019s unlikely that you can work for only the very best charities. In contrast, if you earn to give, you can donate anywhere, preferably to the most cost-effective charities, and change your donations as often as you like.</em></p>\n<p class=\"MsoNormal\">GiveWell has spent about five years looking for the best giving opportunities in global health, and its current #1 ranked charity is <a href=\"http://www.givewell.org/international/top-charities/AMF\">Against Malaria Foundation</a> (AMF). GiveWell estimates that AMF <a href=\"http://www.givewell.org/international/top-charities/AMF#Costperlifesaved\">saves an infant\u2019s life for ~ $2,300</a>, not counting other benefits. These other benefits not withstanding, AMF\u2019s cost per <a href=\"http://www.givewell.org/international/technical/additional/DALY\">DALY saved</a> is much higher than the implied cost per DALY saved associated with the figure cited for curing sight-destroying trachoma.</p>\n<p class=\"MsoNormal\">GiveWell may have missed giving opportunities in global health that are much more cost-effective than AMF is, but given the amount of time, energy and attention that GiveWell spent on its search, one should have a strong prior against the possibility that one can easily find a better giving opportunity in global health. So a plausible estimate of the cost-effectiveness of donating to the best charity that delivers direct global health interventions is much lower than the above quotation suggests.</p>\n<p class=\"MsoNormal\">Furthermore, the phenomenon of the <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/91ia\">optimizer\u2019s curse</a> suggests that all charities with robust case for fairly high cost-effectiveness are closer in cost-effectiveness to AMF than explicit cost-effectiveness calculations indicate. This narrows the variance in cost-effectiveness amongst charities.&nbsp;</p>\n<p class=\"MsoNormal\">So the advantage of being able to choose a charity to support and change at any time is smaller than the above quotation suggests.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Discrepancy_in_earnings\">Discrepancy in earnings</strong></p>\n<p class=\"MsoNormal\">MacAskill wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em style=\"mso-bidi-font-style:normal\">Annual salaries in banking or investment start at $80,000 and grow to over $500,000 if you do well. A lifetime salary of over $10 million is typical. Careers in nonprofits start at about $40,000, and don\u2019t typically exceed $100,000, even for executive directors </em><span style=\"mso-bidi-font-style:normal\"><em>... </em></span><em style=\"mso-bidi-font-style:normal\">By entering finance and donating 50% of your lifetime earnings, you could pay for two nonprofit workers in your place\u2014while still living on double what you would have if you\u2019d chosen that route.</em>&nbsp;</p>\n<p class=\"MsoNormal\">The assumption \u201cif you do well\u201d is a very strong one. Only about 1% of Americans make ~$500k/year. There are some people who have a strong comparative advantage in finance, for whom \u201cearning to give\u201d to give may be especially compelling. But people who are able to make ~$500k/year in finance who <strong style=\"mso-bidi-font-weight:normal\">don\u2019t</strong> have a large comparative advantage in finance have <strong style=\"mso-bidi-font-weight:normal\">very strong transferable skills</strong>. Such people are significantly more capable than the average non-profit worker, and can plausibly have a bigger impact than 2 or 3 such workers by working directly on something with high social value.&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal\" id=\"Replaceability\">Replaceability</strong></p>\n<p class=\"MsoNormal\">MacAskill wrote:</p>\n<!--[endif] --> <!--StartFragment-->\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><em><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">\u2026\u201cmaking a difference\u201d requires<span>&nbsp;</span></span></em><em><a style=\"-webkit-tap-highlight-color: rgba(0, 0, 0, 0);\" href=\"http://80000hours.org/blog/18-just-what-is-making-a-difference-counterfactuals-and-career-choice\"><span style=\"color: #168dd9; background-position: initial initial; background-repeat: initial initial;\">doing something that wouldn\u2019t have happened</span></a><span><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">&nbsp;</span><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">anyway\u2026</span></span></em><em><span style=\"color: #404040; background-position: initial initial; background-repeat: initial initial;\">The competition for not-for-profit jobs is fierce, and if someone else takes the job instead of you, he or she likely won\u2019t be much worse at it than you would have been. So the difference you make by taking the job is only the difference between the good you would do, and the good that the other person would have done.</span></em>&nbsp;</p>\n<p class=\"MsoNormal\">I would guess that there are some highly cost-effective humanitarian interventions that are sufficiently easy to implement that the implementers are easily replaceable. I could easily imagine that this is the case for vaccination efforts.&nbsp;</p>\n<p class=\"MsoNormal\">But funding opportunities for these interventions can be thought of as \u201clow hanging fruit.\u201d <a href=\"http://blog.givewell.org/2013/05/02/broad-market-efficiency/\">Broad market efficiency</a> suggests that such interventions will be funded. And indeed, GiveWell has found that straightforward immunization efforts <a href=\"http://blog.givewell.org/2013/03/21/trying-and-failing-to-find-more-funding-gaps-for-delivering-proven-cost-effective-interventions/\">are already largely funded</a>, to the point that GiveWell has been unable to find giving opportunities for individual donors in this area.&nbsp;</p>\n<p class=\"MsoNormal\">This suggests that at the margin, <strong style=\"mso-bidi-font-weight: normal\">very high value humanitarian efforts require highly skilled and highly motivated laborers</strong>.</p>\n<p class=\"MsoNormal\">High skilled laborers are a relatively small subset of laborers, so there are fewer people available to do these sorts of jobs than other jobs. Doing a hard, non-routine job well requires high motivation. <span style=\"mso-spacerun:yes\">&nbsp;</span>The collection of people who are sufficiently highly motivated to do a hard job with high social value that doesn\u2019t pay well, and who could otherwise be making much more money, largely consists of people who are trying to have a significant positive social impact.&nbsp;</p>\n<p class=\"MsoNormal\">So suppose that you\u2019re a highly skilled laborer deciding whether to \u201cearn to give\u201d or take a job with high social value that requires high skills and motivation. If you don\u2019t take the job with high social value, your counterfactual replacement is likely be one of the following:<br style=\"mso-special-character:line-break\"> <!--[endif]--></p>\n<p class=\"MsoListParagraphCxSpFirst\" style=\"margin-left:38.7pt;mso-add-space: auto;text-indent:-.25in;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family:Cambria;mso-fareast-theme-font:minor-latin; mso-bidi-font-family:Cambria;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">1.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Substantially less capable than you on account of having low skills, or low altruistic motivation.</p>\n<p class=\"MsoListParagraphCxSpMiddle\" style=\"margin-left:38.7pt;mso-add-space: auto;text-indent:-.25in;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family:Cambria;mso-fareast-theme-font:minor-latin; mso-bidi-font-family:Cambria;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">2.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->A highly skilled person with high motivation, <em style=\"mso-bidi-font-style:normal\">who would be doing something else with high social value if you had taken the job, and who can\u2019t do this because they have to do the job that you would have done</em>.</p>\n<p class=\"MsoListParagraphCxSpLast\" style=\"margin-left:38.7pt;mso-add-space:auto; text-indent:-.25in;mso-list:l0 level1 lfo1\"><!--[if !supportLists]--><span style=\"mso-fareast-font-family:Cambria;mso-fareast-theme-font:minor-latin; mso-bidi-font-family:Cambria;mso-bidi-theme-font:minor-latin\"><span style=\"mso-list:Ignore\">3.<span style=\"font:7.0pt &quot;Times New Roman&quot;\">&nbsp;&nbsp;&nbsp;&nbsp; </span></span></span><!--[endif]-->Nonexistent.</p>\n<p class=\"MsoNormal\">So the replaceability consideration carries less weight than it might seem.</p>\n<p class=\"MsoNormal\">Admittedly there\u2019s a counterconsideration \u2014&nbsp;broad market efficiency cuts both ways, and one could imagine that the low hanging fruit in <em style=\"mso-bidi-font-style:normal\">working directly on projects with high social valu</em>e is also plucked, and this counter-consideration pushes in favor of \u201cearning to give.\u201d I have a fairly strong intuition that \u201cif you don\u2019t fund it, somebody else will\u201d is more true than \u201cif you don\u2019t do it, somebody else will\u201d so that this counter-consideration is outweighed. It\u2019s important to note that many projects of high social value are the first of their kind, and that finding somebody else to execute such a project is highly nontrivial. I think that it\u2019s also relevant that <a href=\"http://givingpledge.org/\">114 billionaires</a> have signed the Giving Pledge, committing to giving 50+% of their wealth away in their lifetimes.<span style=\"mso-spacerun:yes\">&nbsp;</span></p>\n<p class=\"MsoNormal\">In any case, there isn\u2019t a clear-cut, unconditional argument that favors \u201cearning to give\u201d: whether \u201cearning to give\u201d is the best option very much depends on nuanced empirical considerations rather than a general abstract argument.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Other_important_considerations_that_favor_an_altruistic_career\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Other important considerations that favor an altruistic career</span></strong></p>\n<p class=\"MsoNormal\">There are additional important considerations that favor pursuing a career with high social value over \u201cearning to give\u201d:</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Asymmetric implications of the existence of small probability failure modes</strong>&nbsp;</p>\n<p class=\"MsoNormal\">In <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>, I described how a large collection of small probability failure modes conspires to substantially reduce the expected value of a funding opportunity. The same issue applies to choosing a narrow career goal with a view toward directly having a high positive social impact. But <strong style=\"mso-bidi-font-weight:normal\">a worker has more capacity than a donor does to learn whether small probability failure modes prevail in practice, and can switch to a different job if he or she finds that such a failure mode prevails.</strong>&nbsp;</p>\n<p class=\"MsoNormal\">Here\u2019s an example. Suppose that you go to medical school with a view toward the possibility of performing cleft palate surgeries in the developing world. It\u2019s probably the case that the opportunity isn\u2019t as promising as it seems. But if you try it, then you\u2019ll be able to see how effective the intervention is firsthand. If it\u2019s highly effective, then you can keep doing it. If it\u2019s not highly effective, then you can explore other possibilities, such as&nbsp;</p>\n<ul>\n<li>Starting your own surgery organization.</li>\n<li>Switching to doing a different kind of surgery in the developing world, such as cataract removal.</li>\n<li>Working in a poor community in the developed world (which could have a bigger impact than working in the developing world owing to <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a>).</li>\n<li>Working for a biotech company.</li>\n<li>Getting involved in clinical medical research.</li>\n<li>Other things that haven't occurred to me.</li>\n</ul>\n<p class=\"MsoNormal\">By experimenting, one can hope to hone in on a job that has both high ostensible cost-effectiveness, and and a relatively small mass of small probability failure modes.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Altruistic_careers_extend_beyond_the_nonprofit_world\">Altruistic careers extend beyond the nonprofit world</strong></p>\n<p class=\"MsoNormal\">Even on the assumption that \u201cearning to give\u201d is better than working at a nonprofit, it doesn\u2019t follow that \u201cearning to give\u201d optimizes social impact. There are ways to have a positive social impact in the for-profit world, in scientific research, and in the government.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Historical_Precedent\">Historical Precedent</strong></p>\n<p class=\"MsoNormal\">For the most part, the people who have had the biggest positive impact on the world haven\u2019t had their impact by \u201cearning to give.\u201d</p>\n<p class=\"MsoNormal\">There are a few possible exceptions, such as Bill Gates and Warren Buffett, whose philanthropic activities could be having a huge impact (though it\u2019s hard to tell from the outside) and could well outstrip the value that they contributed through their labor. But they appear to have an unusually high ratio of wealth to direct positive impact of their work, and so appear to be unrepresentative.</p>\n<p class=\"MsoNormal\">Steve Jobs\u2019 highest net worth was on the order of $10 billion, whereas Bill Gates\u2019 highest net worth was on the order of $100 billion. I don\u2019t think that Bill Gates contributed 10x as much as Steve Jobs to technology, and I don\u2019t think that Jobs could have had a bigger social impact by donating than through his work (which had massive positive <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a>). I acknowledge that Jobs is a cherry picked example, but I think that the general principle still holds.&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Mainstream_consensus\">Mainstream consensus</strong></p>\n<p class=\"MsoNormal\">Few people think that \u201cearning to give\u201d is the best way to make the world a better place. This could be attributable to irrationality or to low altruism, but my experience is that there are many people who care about global welfare, or just welfare within a specific cause, and many people who are highly intelligent. In light of the existence of&nbsp;<a href=\"https://en.wikipedia.org/wiki/Illusory_superiority\">illusory superiority</a>, one should be wary of holding an implicit view that one knows more about how to make the world a better place than the vast majority of the population.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"Steelmanning_wealth_maximization\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Steelmanning wealth maximization</span></strong></p>\n<p class=\"MsoNormal\">It\u2019s worth highlighting some factors that <em style=\"mso-bidi-font-style:normal\">favor</em> choosing a career with a view toward maximizing wealth in some situations:</p>\n<ul>\n<li><strong style=\"mso-bidi-font-weight:normal\">Comparative advantage</strong> \u2014&nbsp;Some people are unusually good at making money relative to doing other things. Such people may do better to \u201cearn to give\u201d than to try to choose a job that has a direct positive impact (which they\u2019re relatively bad at).<br></li>\n<li><strong style=\"mso-bidi-font-weight:normal\">The market mechanism</strong>&nbsp;\u2014&nbsp;In the for-profit world, maximizing wealth is often correlated with maximizing positive social impact, and so can be used as a proxy goal for maximizing positive social impact.<br><strong style=\"mso-bidi-font-weight:normal\"><br></strong></li>\n<li><span style=\"mso-bidi-font-weight:normal\"><strong>Connections and personal growth</strong></span>&nbsp;\u2014 People with high earnings are generally more capable and more knowledgeable than people in other contexts, and tend to be well connected, so positioning oneself among such people can increase one\u2019s prospects of soaring to greater heights. Jeff Bezos <a href=\"http://en.wikipedia.org/wiki/Jeff_Bezos#Business_career\">started his career</a> in finance, and later created Amazon, which has had massive positive social impact (both direct, and via <a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">flow-through effects</a>).<br><strong style=\"mso-bidi-font-weight:normal\"><br></strong></li>\n<li><span style=\"mso-bidi-font-weight:normal\"><strong>Unusual values</strong></span> \u2014&nbsp;If one cares about causes that very few people care about, then it could be difficult to find funding for work on them, so \u201cearning to give\u201d could be necessary. I don\u2019t believe this to be the case, but it\u2019s a consideration that's been raised by others, and so is worth mentioning.</li>\n</ul>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">Closing summary</span></strong><strong style=\"mso-bidi-font-weight:normal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">&nbsp;</span></strong></p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>2302</o:Words> <o:Characters>13127</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>109</o:Lines> <o:Paragraphs>30</o:Paragraphs> <o:CharactersWithSpaces>15399</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\"><span style=\"font-size:14.0pt;mso-bidi-font-size:12.0pt\">\u00ad</span>There are many arguments against the claim that \u201cearning to give\u201d is generally the best way to maximize one\u2019s positive social impact, and I believe that choosing a job where one can do as much good as possible through one\u2019s work is generally the best way to maximize one\u2019s positive social impact. However, for some people in unusual situations, \u201cearning to give\u201d may be the best way to have a positive social impact.</p>\n<p class=\"MsoNormal\"><strong>Note:<em>&nbsp;</em></strong>I formerly worked as a research analyst at&nbsp;<a href=\"http://www.givewell.org/\">GiveWell</a>. All views expressed here are my own.</p>\n<p class=\"MsoNormal\"><strong>Acknowledgements:</strong><em style=\"font-weight: bold;\">&nbsp;</em>I thank Nick Beckstead, ModusPonies and Will Crouch for helpful feedback on an earlier version of this article.</p>\n<div style=\"mso-element:comment-list\">\n<div style=\"mso-element:comment\">\n<div id=\"_com_4\" class=\"msocomtxt\"><!--[if !supportAnnotations]--></div>\n<!--[endif]--></div>\n</div>", "sections": [{"title": "Responses to MacAskill\u2019s Considerations", "anchor": "Responses_to_MacAskill_s_Considerations", "level": 1}, {"title": "Variance in cost-effectiveness of charities", "anchor": "Variance_in_cost_effectiveness_of_charities", "level": 1}, {"title": "Discrepancy in earnings", "anchor": "Discrepancy_in_earnings", "level": 1}, {"title": "Replaceability", "anchor": "Replaceability", "level": 1}, {"title": "Other important considerations that favor an altruistic career", "anchor": "Other_important_considerations_that_favor_an_altruistic_career", "level": 1}, {"title": "Altruistic careers extend beyond the nonprofit world", "anchor": "Altruistic_careers_extend_beyond_the_nonprofit_world", "level": 1}, {"title": "Historical Precedent", "anchor": "Historical_Precedent", "level": 1}, {"title": "Mainstream consensus", "anchor": "Mainstream_consensus", "level": 1}, {"title": "Steelmanning wealth maximization", "anchor": "Steelmanning_wealth_maximization", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "153 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 154, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rNuBzyWkigrf6BWg7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T04:56:20.548Z", "modifiedAt": null, "url": null, "title": "How much was creating Google worth? ", "slug": "how-much-was-creating-google-worth", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:35.718Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WpR4LkBCKx8bN6y6G/how-much-was-creating-google-worth", "pageUrlRelative": "/posts/WpR4LkBCKx8bN6y6G/how-much-was-creating-google-worth", "linkUrl": "https://www.lesswrong.com/posts/WpR4LkBCKx8bN6y6G/how-much-was-creating-google-worth", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20much%20was%20creating%20Google%20worth%3F%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20much%20was%20creating%20Google%20worth%3F%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWpR4LkBCKx8bN6y6G%2Fhow-much-was-creating-google-worth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20much%20was%20creating%20Google%20worth%3F%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWpR4LkBCKx8bN6y6G%2Fhow-much-was-creating-google-worth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWpR4LkBCKx8bN6y6G%2Fhow-much-was-creating-google-worth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 290, "htmlBody": "<p class=\"MsoNormal\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\"><em>I would greatly appreciate feedback on whether the assumptions in this post, as well as the conceptual framework, are reasonable. I recognize that I don't address <a href=\"http://www.guardian.co.uk/technology/2013/jan/08/why-charge-everything-kill-creativity\">positive externalities</a>&nbsp;explicitly. I think that they may be picked up implicitly, but am unsure about this.</em>&nbsp;</span></p>\n<p class=\"MsoNormal\"><a style=\"font-family: Verdana;\" href=\"https://en.wikipedia.org/wiki/Sergey_Brin\">Sergey Brin</a><span style=\"font-family: Verdana;\"> and </span><a style=\"font-family: Verdana;\" href=\"http://en.wikipedia.org/wiki/Larry_Page\">Larry Page</a><span style=\"font-family: Verdana;\"> made an outsized contribution to society by speeding the development of high quality online content filtering by creating Google.&nbsp;</span><span style=\"font-family: Verdana;\">They became </span><a style=\"font-family: Verdana;\" href=\"http://www.forbes.com/billionaires/list/#page:2_sort:0_direction:asc_search:_filter:All%20industries_filter:All%20countries_filter:All%20states\">spectacularly wealthy</a><span style=\"font-family: Verdana;\"> as a result, but plausibly produced far more value than they captured.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">One can estimate the value of creating Google by trying to place oneself in the shoes of somebody with average US earnings in 2000 (<a href=\"http://research.stlouisfed.org/fred2/series/USARGDPC\">~$45,000/yr</a>) and thinking about how much one would be willing to pay for Google to have been created, rather than its counterfactual replacement some years later.</span></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Assumption 1: </span></strong><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">The counterfactual replacement would have been created 3 years later (in expectation).</span></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Assumption 2: </span></strong><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Contingent on knowing assumption 1, the mean 2000 US citizen would be willing to pay at least $1/week (about 0.3% of his or her income).</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">The average person <a href=\"http://www.npr.org/blogs/money/2012/08/01/157664524/how-the-poor-the-middle-class-and-the-rich-spend-their-money\">spends about 15%</a> of his or her income on utilities and entertainment combined. In view of this, we&rsquo;ll assume</span></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Assumption 3: </span></strong><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">The mean American would not be willing to pay more 5% of his or her income for three years.</span></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Assumption 4: </span></strong><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">The percentage of income that one would be willing to pay for Google is approximately uniform over the entire population.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Putting these assumptions together, and using the fact that world GDP in 2000 was about $60 trillion, we get a ballpark estimate of the value of Google of<strong style=\"mso-bidi-font-weight: normal;\"> 0.6 trillion &mdash; 9 trillion</strong>.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Since Brin and Page have total net worth about $40 billion, the remarks above suggest that they produced between <strong style=\"mso-bidi-font-weight: normal;\">15x and 225x</strong> as much value as their aggregate earnings.</span></p>\n<p class=\"MsoNormal\"><span style=\"font-family: Verdana; mso-fareast-font-family: &quot;Times New Roman&quot;; mso-bidi-font-family: &quot;Times New Roman&quot;; color: black; background: white;\">Thoughts?</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WpR4LkBCKx8bN6y6G", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 1, "extendedScore": null, "score": 1.2187914154050632e-06, "legacy": true, "legacyId": "22813", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T17:19:57.957Z", "modifiedAt": null, "url": null, "title": "Risques existentiels en Fran\u00e7ais", "slug": "risques-existentiels-en-francais", "viewCount": null, "lastCommentedAt": "2020-03-20T12:08:22.893Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/to3CL6z6NPTGNty8T/risques-existentiels-en-francais", "pageUrlRelative": "/posts/to3CL6z6NPTGNty8T/risques-existentiels-en-francais", "linkUrl": "https://www.lesswrong.com/posts/to3CL6z6NPTGNty8T/risques-existentiels-en-francais", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Risques%20existentiels%20en%20Fran%C3%A7ais&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARisques%20existentiels%20en%20Fran%C3%A7ais%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fto3CL6z6NPTGNty8T%2Frisques-existentiels-en-francais%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Risques%20existentiels%20en%20Fran%C3%A7ais%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fto3CL6z6NPTGNty8T%2Frisques-existentiels-en-francais", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fto3CL6z6NPTGNty8T%2Frisques-existentiels-en-francais", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 52, "htmlBody": "<p>I've just been interviewed by Radio-Canada (in French) for their program \"<a href=\"http://www.radio-canada.ca/emissions/dessine_moi_un_dimanche/2012-2013/\">Dessine moi un Dimanche</a>\". There really wasn't enough time (the interview apparently lasted nine minutes; it felt like two), but I managed to touch upon some of the technology risks of the coming century (including AI).</p>\n<p>The segment can be found here:&nbsp;<a href=\"http://www.radio-canada.ca/emissions/dessine_moi_un_dimanche/2012-2013/chronique.asp?idChronique=295886\">http://www.radio-canada.ca/emissions/dessine_moi_un_dimanche/2012-2013/chronique.asp?idChronique=295886</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "to3CL6z6NPTGNty8T", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 1.219345995455587e-06, "legacy": true, "legacyId": "22815", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-02T20:11:18.085Z", "modifiedAt": null, "url": null, "title": "Meetup : Bratislava Meetup IV.", "slug": "meetup-bratislava-meetup-iv", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Viliam_Bur", "createdAt": "2011-08-23T08:46:37.137Z", "isAdmin": false, "displayName": "Viliam_Bur"}, "userId": "yaaPhHzrvrPf7je22", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Qn73iT8m8tMTZhQF4/meetup-bratislava-meetup-iv", "pageUrlRelative": "/posts/Qn73iT8m8tMTZhQF4/meetup-bratislava-meetup-iv", "linkUrl": "https://www.lesswrong.com/posts/Qn73iT8m8tMTZhQF4/meetup-bratislava-meetup-iv", "postedAtFormatted": "Sunday, June 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Bratislava%20Meetup%20IV.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Bratislava%20Meetup%20IV.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQn73iT8m8tMTZhQF4%2Fmeetup-bratislava-meetup-iv%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Bratislava%20Meetup%20IV.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQn73iT8m8tMTZhQF4%2Fmeetup-bratislava-meetup-iv", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQn73iT8m8tMTZhQF4%2Fmeetup-bratislava-meetup-iv", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ng'>Bratislava Meetup IV.</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">24 June 2013 06:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Malewill Cafe, Ur\u0161ul\u00ednska 9, Bratislava</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will see each other at Malewill caf\u00e9.</p>\n\n<p>Because of many new members, this time the meetup will be unstructured -- the goal is to meet each other, and talk about us, our goals and expectations from our community.</p>\n\n<p>Any questions? Call: +421-908-158110 (Viliam)</p>\n\n<p>Stretneme sa v pondelok o \u0161iestej v Malewill caf\u00e9 na rohu Primaci\u00e1lneho n\u00e1mestia, v zadnej nefaj\u010diarskej miestnosti. Ke\u010f\u017ee minule pri\u0161lo ve\u013ea nov\u00fdch \u013eud\u00ed a mali sme nabit\u00fd program, tentokr\u00e1t nie je form\u00e1lny program \u017eiaden, cie\u013eom je zozn\u00e1mi\u0165 sa, porozpr\u00e1va\u0165 sa o svojich pl\u00e1noch, a pouva\u017eova\u0165, \u010do m\u00f4\u017eeme spolu dosiahnu\u0165.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ng'>Bratislava Meetup IV.</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Qn73iT8m8tMTZhQF4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.2194738374132964e-06, "legacy": true, "legacyId": "22816", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Bratislava_Meetup_IV_\">Discussion article for the meetup : <a href=\"/meetups/ng\">Bratislava Meetup IV.</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">24 June 2013 06:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Malewill Cafe, Ur\u0161ul\u00ednska 9, Bratislava</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will see each other at Malewill caf\u00e9.</p>\n\n<p>Because of many new members, this time the meetup will be unstructured -- the goal is to meet each other, and talk about us, our goals and expectations from our community.</p>\n\n<p>Any questions? Call: +421-908-158110 (Viliam)</p>\n\n<p>Stretneme sa v pondelok o \u0161iestej v Malewill caf\u00e9 na rohu Primaci\u00e1lneho n\u00e1mestia, v zadnej nefaj\u010diarskej miestnosti. Ke\u010f\u017ee minule pri\u0161lo ve\u013ea nov\u00fdch \u013eud\u00ed a mali sme nabit\u00fd program, tentokr\u00e1t nie je form\u00e1lny program \u017eiaden, cie\u013eom je zozn\u00e1mi\u0165 sa, porozpr\u00e1va\u0165 sa o svojich pl\u00e1noch, a pouva\u017eova\u0165, \u010do m\u00f4\u017eeme spolu dosiahnu\u0165.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Bratislava_Meetup_IV_1\">Discussion article for the meetup : <a href=\"/meetups/ng\">Bratislava Meetup IV.</a></h2>", "sections": [{"title": "Discussion article for the meetup : Bratislava Meetup IV.", "anchor": "Discussion_article_for_the_meetup___Bratislava_Meetup_IV_", "level": 1}, {"title": "Discussion article for the meetup : Bratislava Meetup IV.", "anchor": "Discussion_article_for_the_meetup___Bratislava_Meetup_IV_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-03T03:08:50.803Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes June 2013", "slug": "rationality-quotes-june-2013", "viewCount": null, "lastCommentedAt": "2021-12-21T22:33:09.415Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Thomas", "createdAt": "2009-03-02T17:47:09.607Z", "isAdmin": false, "displayName": "Thomas"}, "userId": "GrAKeuxT4e9AKyHdE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kEfFzfsHpAFamwZ9B/rationality-quotes-june-2013", "pageUrlRelative": "/posts/kEfFzfsHpAFamwZ9B/rationality-quotes-june-2013", "linkUrl": "https://www.lesswrong.com/posts/kEfFzfsHpAFamwZ9B/rationality-quotes-june-2013", "postedAtFormatted": "Monday, June 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20June%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20June%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEfFzfsHpAFamwZ9B%2Frationality-quotes-june-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20June%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEfFzfsHpAFamwZ9B%2Frationality-quotes-june-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEfFzfsHpAFamwZ9B%2Frationality-quotes-june-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 84, "htmlBody": "<p>Another month has passed and here is a new rationality quotes thread. The usual rules are:</p>\n<ul>\n<li>Please post all quotes separately, so that they can be upvoted or downvoted separately. (If they are strongly related, reply to your own comments. If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote from Less Wrong itself, Overcoming Bias, or HPMoR.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kEfFzfsHpAFamwZ9B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 1.219785488157813e-06, "legacy": true, "legacyId": "22808", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 792, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-06-03T03:08:50.803Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-03T03:11:39.898Z", "modifiedAt": null, "url": null, "title": "Does model theory [psychology] predict anything? (book: \"How We Reason\" (2009)) ", "slug": "does-model-theory-psychology-predict-anything-book-how-we", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.100Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonathan_Graehl", "createdAt": "2009-02-27T23:21:15.671Z", "isAdmin": false, "displayName": "Jonathan_Graehl"}, "userId": "eKsWtKKceoRYwcc7s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3RGrT5kimCmRo2rfv/does-model-theory-psychology-predict-anything-book-how-we", "pageUrlRelative": "/posts/3RGrT5kimCmRo2rfv/does-model-theory-psychology-predict-anything-book-how-we", "linkUrl": "https://www.lesswrong.com/posts/3RGrT5kimCmRo2rfv/does-model-theory-psychology-predict-anything-book-how-we", "postedAtFormatted": "Monday, June 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Does%20model%20theory%20%5Bpsychology%5D%20predict%20anything%3F%20(book%3A%20%22How%20We%20Reason%22%20(2009))%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADoes%20model%20theory%20%5Bpsychology%5D%20predict%20anything%3F%20(book%3A%20%22How%20We%20Reason%22%20(2009))%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3RGrT5kimCmRo2rfv%2Fdoes-model-theory-psychology-predict-anything-book-how-we%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Does%20model%20theory%20%5Bpsychology%5D%20predict%20anything%3F%20(book%3A%20%22How%20We%20Reason%22%20(2009))%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3RGrT5kimCmRo2rfv%2Fdoes-model-theory-psychology-predict-anything-book-how-we", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3RGrT5kimCmRo2rfv%2Fdoes-model-theory-psychology-predict-anything-book-how-we", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 942, "htmlBody": "<p>Has anyone read <a href=\"http://books.google.com/books?id=UjYsJN0krNYC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false\">\"How We Reason\"</a>&nbsp;by&nbsp;<a style=\"color: #003399; font-family: verdana, arial, helvetica, sans-serif; font-size: 11px;\" href=\"http://www.amazon.com/s/ref=ntt_athr_dp_sr_1?_encoding=UTF8&amp;field-author=Philip%20Johnson-Laird&amp;search-alias=books&amp;sort=relevancerank\">Philip Johnson-Laird</a>? He and others in his field (the \"model theory\" of psychology/cognitive science) claim that their studies refute the naive claim that human brains often operate in terms of logic or Bayesian reasoning (probablistic logic). I gather they'd say that we are not Jaynes' perfect Bayesian reasoning robot or even something resembling a computationally bounded approximation to it.</p>\n<p>I'm intrigued by this recommendation:</p>\n<blockquote>\n<p><span style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\">&nbsp;... formal logic cannot be the basis for human reason. Johnson-Laird reviews evidence to this effect. For example, there are many valid conclusions that we never bother to draw because they are of no practical use to us. We also make systematic errors in reasoning that we would not make using logic. The content of logic problems used in research studies greatly affects their difficulty; it would not if logic were the primary process. We use knowledge to help us imagine possibilities and then evaluate the possibilities for consistency with other evidence.</span><br style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\" /><br style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\" /><span style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\">Constrained by the span of short term memory, the strength of our general intellectual abilities, and our level of expertise, we construct and manipulate mental models of the problems we reason about. \"...[F]rom the meanings of sentences in connected discourse, the listener implicitly sets up a much abbreviated and not especially linguistic model of the narrative ... Where the model is incomplete, material may even be unwittingly invented to render the memory more meaningful or more plausible.\" We can manipulate these models in a number of ways, including updating them with new information, combining two models when appropriate, searching for confirming evidence or information, and using counterexamples to challenge a model's validity.</span><br style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\" /><br style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\" /><span style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\">Mental model theory explains a number of systematic errors human beings make when reasoning. For example, the difficulty of reasoning problems is related to the number of models that must be held simultaneously in memory to work through them. And we exhibit a recurring bias to use a single model to reason about situations that have more possibilities than we can keep track of. We oversimplify. Consistent with model theory, we have difficulty reasoning with information about what is false about a situation.</span></p>\n<p><span style=\"color: #333333; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-size: 14px; line-height: 20px;\">The real key to human rationality is our ability to recognize and grasp the implications of counterexamples</span></p>\n</blockquote>\n<p><span style=\"font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; color: #333333;\"><span style=\"font-size: 14px; line-height: 20px;\">It seems like an interesting read, but I'd like to know if the research field is a scientific one, i.e. that their stories aren't just pleasing, but can predict, or at least explain real phenomena.</span></span></p>\n<p>In the Google books preview, I see the author spends some time claiming that we build iconic visual/spatial representations and that a lot of our thinking isn't verbal or available to verbal introspection (fairly uncontroversial to me).</p>\n<p>I liked the two related imagination-puzzles:</p>\n<p>1. I have thousands and thousands of very thin needles, which I hold in a bundle in my hands. I throw them up into the air, imparting a random force to each of them. They fall to the ground, but, before any of them hits the ground, I stop them by magic in mid-air. Many of the needles are horizontal or nearly so, and many of them are vertical or nearly so. Are there likely to be more needles in the first category, more needles in the second category, or do the two categories have roughly equal numbers?</p>\n<p>&nbsp;[and the same thing but for very thin circular disks - let's assume they're also dense, so the air isn't a factor]</p>\n<p>2. &nbsp;I have thousands and thousands of very thin circular disks, which I hold in a bundle in my hands. I throw them up into the air, imparting a random force to each of them. They fall to the ground, but, before any of them hits the ground, I stop them by magic in mid-air. Many of the disks are horizontal or nearly so, and many of them are vertical or nearly so. Are there likely to be more disks in the first category, more disks in the second category, or do the two categories have roughly equal numbers?</p>\n<p>He claims that for spatial propositions where we can imagine a picture that's more or less equivalent (\"the cabinet is behind the piano\" [as we face the keys]), the negation of that proposition can't be so pictured (in direct correspondence) because ... where would you put the cabinet? You could imagine all the alternative places it could be (presupposing that there is a specific piano and specific cabinet). You could imagine something \"not cabinet\" behind the piano (a cabinet with a red x, a cabinet repelling field?). He suggests an or(p1,p2,....pn) of images where we imagine the cabinet to be (that aren't behind the piano). I'm not sure what we can conclude from this. We already know that negation is tricky - linguistically, and mentally. Maybe I like to imagine someone telling me \"no, you're wrong to say X\" - to use a non-visual system.</p>\n<p>He explains that inferences about (written) non-spatial visual relations (light/dark clean/dirty) take longer to process than spatial ones, that the spatial and visual word inference word problems had different fMRI hot spots, that congenitally blind people weren't faster on spatial queries (i.e. were slower on average than non-blind, but didn't suffer any additional penalty on the visual ones). I suppose this could be taken as weak evidence that we can perform \"logical\" inferences with some sort of spatial-relationship processing, and that perhaps non-spatial attributes take longer to translate (even though they refer to visual qualities like light/dark).</p>\n<p>I'm leaning toward buying the book, since the writing is pleasant. But I thought first I'd ask if anyone could recommend for the quality of research in this field.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3RGrT5kimCmRo2rfv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.219787592119778e-06, "legacy": true, "legacyId": "22820", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-03T04:42:02.380Z", "modifiedAt": null, "url": null, "title": "The Use of Many Independent Lines of Evidence: The Basel Problem", "slug": "the-use-of-many-independent-lines-of-evidence-the-basel", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:03.535Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WsmnfWTP28dXCKEy8/the-use-of-many-independent-lines-of-evidence-the-basel", "pageUrlRelative": "/posts/WsmnfWTP28dXCKEy8/the-use-of-many-independent-lines-of-evidence-the-basel", "linkUrl": "https://www.lesswrong.com/posts/WsmnfWTP28dXCKEy8/the-use-of-many-independent-lines-of-evidence-the-basel", "postedAtFormatted": "Monday, June 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Use%20of%20Many%20Independent%20Lines%20of%20Evidence%3A%20The%20Basel%20Problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Use%20of%20Many%20Independent%20Lines%20of%20Evidence%3A%20The%20Basel%20Problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWsmnfWTP28dXCKEy8%2Fthe-use-of-many-independent-lines-of-evidence-the-basel%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Use%20of%20Many%20Independent%20Lines%20of%20Evidence%3A%20The%20Basel%20Problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWsmnfWTP28dXCKEy8%2Fthe-use-of-many-independent-lines-of-evidence-the-basel", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWsmnfWTP28dXCKEy8%2Fthe-use-of-many-independent-lines-of-evidence-the-basel", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1486, "htmlBody": "<p class=\"MsoNormal\">This post describes how one can use many independent arguments to justifiably develop very high confidence in the truth of a statement. It ends with a case study: Euler&rsquo;s use of several independent lines of evidence to develop confidence in the validity of his unrigorous solution to the <a href=\"http://en.wikipedia.org/wiki/Basel_problem\">Basel Problem</a>.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><a id=\"more\"></a></strong></p>\n<h2><strong>Justifiably high confidence</strong></h2>\n<p class=\"MsoNormal\">In <a href=\"/lw/jo/einsteins_arrogance/\">Einstein&rsquo;s Arrogance</a>, Eliezer described how Einstein could have been justifiably confident in the correctness of the theory of general relativity, <em>even if it were to fail an empirical test</em>:</p>\n<blockquote>\n<p class=\"MsoNormal\">In 1919, Sir Arthur Eddington led expeditions to Brazil and to the island of Principe, aiming to observe solar eclipses and thereby test an experimental prediction of Einstein's novel theory of General Relativity. A journalist asked Einstein what he would do if Eddington's observations failed to match his theory. Einstein famously replied: \"Then I would feel sorry for the good Lord. The theory is correct.\"</p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\">If Einstein had enough observational evidence to single out the correct equations of General Relativity in the first place, then he probably had enough evidence to be damn sure that General Relativity was true.</p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\">\"Then I would feel sorry for the good Lord; the theory is correct,\" doesn't sound nearly as appalling when you look at it from that perspective. And remember that General Relativity was correct, from all the vast space of possibilities.</p>\n</blockquote>\n<h2><strong style=\"mso-bidi-font-weight:normal\">Limits on the confidence conferred by a single argument</strong></h2>\n<p class=\"MsoNormal\">In <a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">Confidence levels inside and outside an argument</a>&nbsp;Yvain described how one can't develop very high confidence in a statement based on a single good argument that makes the prediction with very high confidence, because there&rsquo;s a&nbsp;sizable&nbsp;(even if small) chance that the apparently good argument is actually wrong.</p>\n<p class=\"MsoNormal\">How can this be reconciled with Einstein's justifiably high confidence in the truth of general relativity?</p>\n<h2><strong style=\"mso-bidi-font-weight:normal\">The use of many independent lines of evidence to develop high confidence</strong></h2>\n<p class=\"MsoNormal\">Something that I&rsquo;ve always admired about <a href=\"/user/CarlShulman/overview/\">Carl Shulman</a> is that he often presents many different arguments in favor of a position, rather than a single argument. In <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">Maximizing Cost-effectiveness via Critical Inquiry</a> Holden Karnofsky wrote about how one can improve one&rsquo;s confidence in a true statement by examining the statement from many different angles. Even though one can&rsquo;t gain very high confidence in a statement via a <em>single argument</em>, one can gain very high confidence in the truth of a statement if <em>many independent lines of evidence </em>support it.</p>\n<p class=\"MsoNormal\">Epistemology in the human world is murky:</p>\n<ul>\n<li>Most statements are inherently ill-defined</li>\n<li>There's a fair amount of ambiguity as to which statements can rationally be assigned truth value with very high confidence.</li>\n<li>There's ambiguity as to what constitutes good evidence.&nbsp;</li>\n</ul>\n<p class=\"MsoNormal\">To illustrate the principle mentioned above, it's instructive to consider an example in the domain of mathematics, which is a much simpler domain.</p>\n<h2><strong style=\"mso-bidi-font-weight:normal\">Euler&rsquo;s solution of the Basel Problem</strong><strong style=\"mso-bidi-font-weight:normal\">&nbsp;</strong></h2>\n<p class=\"MsoNormal\">In 1735, Euler solved <a href=\"http://en.wikipedia.org/wiki/Basel_problem\">the famous problem</a> of finding the value of the &ldquo;Basel Sum,&rdquo; which is defined to be the sum of reciprocals of squares of positive integers. He found that the value is equal to &lsquo;pi squared divided by 6.&rsquo;</p>\n<p class=\"MsoNormal\">Euler's initial method of solution is striking in that it relies on an assumption which was unproven at the time, and which is not true in full generality. Euler assumed the <strong style=\"mso-bidi-font-weight:normal\">product formula for the <a href=\"https://en.wikipedia.org/wiki/Sine\">sine function</a></strong>, which expresses the sine function as an infinite product of linear polynomials, each corresponding to a real root of the sine function. In hindsight, there are a number of reasons why Euler should have been concerned that the product formula sine might not be valid:</p>\n<ul>\n<li><span style=\"text-indent: -0.25in;\">Its truth hinges on the sine function being differentiable as a </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Complex_analysis\">function of a complex variable</a><span style=\"text-indent: -0.25in;\">, and on the sine function having no non-real complex roots. A reading of Chapter 5 of </span><a style=\"text-indent: -0.25in;\" href=\"http://www.amazon.com/Euler-Master-Dolciani-Mathematical-Expositions/dp/0883853280\">Euler: The Master of Us All</a><span style=\"text-indent: -0.25in;\"> suggests that Euler was unfamiliar with these facts in 1735 (though he seems to have discovered them later).<br /></span><span style=\"text-indent: -0.25in;\"><br /></span></li>\n<li><span style=\"text-indent: -0.25in;\">Not every function of a complex variable can be written as an infinite product in this way: the fact that the sine function in particular can be depends on the fact that the sine function is an </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Even_and_odd_functions\">odd function</a>,&nbsp;<span style=\"text-indent: -0.25in;\">as well as the fact that the sine function has no worse than </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Exponential_growth\">exponential growth rate</a><span style=\"text-indent: -0.25in;\"> in magnitude. It seems unlikely that Euler was aware that these conditions were necessary.</span><span style=\"mso-spacerun:yes\">&nbsp;</span></li>\n</ul>\n<p class=\"MsoNormal\">The general theorem of which the product formula for sine is a special case is the <a href=\"http://en.wikipedia.org/wiki/Weierstrass_factorization_theorem\">Weierstrass factorization theorem</a>, which wasn&rsquo;t proved until the mid/late 1800&rsquo;s.</p>\n<p class=\"MsoNormal\">And indeed, Euler&nbsp;<em>was</em>&nbsp;initially&nbsp;concerned that the product formula&nbsp;for sine might not be valid. So in view of the&nbsp;(at the time)&nbsp;dubious nature of the product formula for sine, how could Euler have known that he had correctly determined the value of the Basel sum?</p>\n<p class=\"MsoNormal\"><a href=\"http://www.amazon.com/Euler-Master-Dolciani-Mathematical-Expositions/dp/0883853280\">Euler: The Master of Us All</a> describes some of Euler's reasons:</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">The analogy with polynomial functions </strong></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"></strong>A polynomial function with all roots real can be written as products of linear polynomials corresponding to the roots of the function. Isaac Newton had shown that the sine function can be written as an infinite polynomial. So one might guess that the sine function can be written as a product of linear polynomials, in analogy with polynomial functions.</p>\n<p class=\"MsoNormal\">This evidence is weak, because not all polynomials have all roots real, and because statements that are true of finite objects often break down when one passes to infinite objects.</p>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-weight:normal\"><strong>Numerical evidence from the Basel sum and its analogs</strong></span></p>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-weight:normal\"><strong></strong></span>If a statement implies a nontrivial true statement, that&rsquo;s evidence that the original statement is true. (This is just Bayes&rsquo; Theorem, and the converse of the fact that&nbsp;<a href=\"/lw/ih/absence_of_evidence_is_evidence_of_absence/\">Absence of Evidence Is Evidence of Absence</a>.)</p>\n<p class=\"MsoNormal\">In 1731, Euler found that the Basel Sum is equal to 1.644934, up to six places past the decimal point. This decimal approximation agrees with that of &lsquo;pi squared over 6.&rsquo; So the assumption that the product formula for sine is true implies something that&rsquo;s both true and nontrivial.</p>\n<p class=\"MsoNormal\">The above numerical confirmation leaves open the possibility that the Basel Sum and &lsquo;pi squared over 6&rsquo; differ by a very small amount. It can happen that two apparently unrelated and simple mathematical quantities <a href=\"http://en.wikipedia.org/wiki/Complex_multiplication#Sample_consequence\">differ by less than a trillionth</a>, so this is a legitimate concern. &nbsp;</p>\n<p class=\"MsoNormal\">To assuage this concern, one can consider the fact that Euler&rsquo;s method yields the values of the sum of reciprocals of k<sup>th&nbsp;</sup>powers of positive integers <a href=\"http://en.wikipedia.org/wiki/Zeta_constant#Even_positive_integers\">for every even integer k</a>, and check these formulas for numerical accuracy, finding that they hold with high precision. It&rsquo;s less likely that <em style=\"mso-bidi-font-style:normal\">all</em> of them are just barely wrong than it is that a <em style=\"mso-bidi-font-style:normal\">single</em> one is just barely wrong. So this a nontrivial amount of further evidence that the product formula for sine is true.</p>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-weight:normal\"><strong>An independent derivation of the Wallis product formula and of the Leibniz series</strong></span></p>\n<p class=\"MsoNormal\">As stated above, if a statement implies a nontrivial true statement, this is evidence that the original statement is true. Euler used the product formula for sine to deduce the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Wallis_product\">Wallis product formula for pi</a>, which had been known since 1655. By assuming the existence of a formula analogous to the product formula for sine, this time for '1 minus sine,' Euler deduced the <a href=\"http://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80\">Leibniz formula for pi</a>.&nbsp;</p>\n<p class=\"MsoNormal\">Upon doing so, Euler wrote \"For our method, which may appear to some as not reliable enough, a great confirmation comes here to light. Therefore, we should not doubt at all of the other things which are derived by the same method.\"</p>\n<p class=\"MsoNormal\"><strong>Remark: </strong><em>After writing this post, I learned that George Polya gave an overlapping discussion of Euler's work on the Basel Problem on pages 17-21 of&nbsp;<a href=\"http://www.amazon.com/Mathematics-Plausible-Reasoning-Induction-Analogy/dp/0691025096\">Mathematics and Plausible Reasoning, Volume 1: Induction and Analogy in Mathematics</a>. I found Euler's deduction of the Leibniz formula for pi in Polya's book. Polya's book contains more case studies of the same type.</em></p>\n<h2><strong>Conclusion</strong></h2>\n<p class=\"MsoNormal\">Euler had good reason to believe that his derivation of the value of the Basel sum was valid, even though a rigorous proof that his derivation was valid was years or decades away.&nbsp;</p>\n<p class=\"MsoNormal\"><em>How </em>much confidence is rational based on the evidence available at the time depends on the degree to which the different lines of evidence are independent. The lines of evidence <em>appear</em> to be independent, but could have subtle interdependencies.</p>\n<p class=\"MsoNormal\">Nevertheless, I've never heard of an example of mathematical statement so robustly supported that turned out to be false. In the context of the fact that there's been a huge amount of mathematical research since then, it may be reasonable to conclude that the appropriate confidence level would have been 99.9999+%. [Edit: I lightly edited this paragraph &mdash; see <a href=\"/lw/hlx/the_use_of_many_independent_lines_of_evidence_the/93bs\">this comment thread</a>.]</p>\n<p class=\"MsoNormal\">It may be appropriate to hedge, with&nbsp;<a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">Confidence levels inside and outside an argument</a>&nbsp;in mind, because&nbsp;the arguments that I make in this post may themselves be wrong :-).</p>\n<p class=\"MsoNormal\">The example of Euler's work on the Basel Problem highlights the use of many independent lines of evidence to develop very high&nbsp;confidence&nbsp;in a statement: something which occurs and which can occur in many domains.</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at <a href=\"http://www.givewell.org/\">GiveWell</a>. All views here are my own.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1, "xgpBASEThXPuKRhbS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WsmnfWTP28dXCKEy8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 38, "extendedScore": null, "score": 8.9e-05, "legacy": true, "legacyId": "22821", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\">This post describes how one can use many independent arguments to justifiably develop very high confidence in the truth of a statement. It ends with a case study: Euler\u2019s use of several independent lines of evidence to develop confidence in the validity of his unrigorous solution to the <a href=\"http://en.wikipedia.org/wiki/Basel_problem\">Basel Problem</a>.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"><a id=\"more\"></a></strong></p>\n<h2 id=\"Justifiably_high_confidence\"><strong>Justifiably high confidence</strong></h2>\n<p class=\"MsoNormal\">In <a href=\"/lw/jo/einsteins_arrogance/\">Einstein\u2019s Arrogance</a>, Eliezer described how Einstein could have been justifiably confident in the correctness of the theory of general relativity, <em>even if it were to fail an empirical test</em>:</p>\n<blockquote>\n<p class=\"MsoNormal\">In 1919, Sir Arthur Eddington led expeditions to Brazil and to the island of Principe, aiming to observe solar eclipses and thereby test an experimental prediction of Einstein's novel theory of General Relativity. A journalist asked Einstein what he would do if Eddington's observations failed to match his theory. Einstein famously replied: \"Then I would feel sorry for the good Lord. The theory is correct.\"</p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\">If Einstein had enough observational evidence to single out the correct equations of General Relativity in the first place, then he probably had enough evidence to be damn sure that General Relativity was true.</p>\n<p class=\"MsoNormal\">[\u2026]</p>\n<p class=\"MsoNormal\">\"Then I would feel sorry for the good Lord; the theory is correct,\" doesn't sound nearly as appalling when you look at it from that perspective. And remember that General Relativity was correct, from all the vast space of possibilities.</p>\n</blockquote>\n<h2 id=\"Limits_on_the_confidence_conferred_by_a_single_argument\"><strong style=\"mso-bidi-font-weight:normal\">Limits on the confidence conferred by a single argument</strong></h2>\n<p class=\"MsoNormal\">In <a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">Confidence levels inside and outside an argument</a>&nbsp;Yvain described how one can't develop very high confidence in a statement based on a single good argument that makes the prediction with very high confidence, because there\u2019s a&nbsp;sizable&nbsp;(even if small) chance that the apparently good argument is actually wrong.</p>\n<p class=\"MsoNormal\">How can this be reconciled with Einstein's justifiably high confidence in the truth of general relativity?</p>\n<h2 id=\"The_use_of_many_independent_lines_of_evidence_to_develop_high_confidence\"><strong style=\"mso-bidi-font-weight:normal\">The use of many independent lines of evidence to develop high confidence</strong></h2>\n<p class=\"MsoNormal\">Something that I\u2019ve always admired about <a href=\"/user/CarlShulman/overview/\">Carl Shulman</a> is that he often presents many different arguments in favor of a position, rather than a single argument. In <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">Maximizing Cost-effectiveness via Critical Inquiry</a> Holden Karnofsky wrote about how one can improve one\u2019s confidence in a true statement by examining the statement from many different angles. Even though one can\u2019t gain very high confidence in a statement via a <em>single argument</em>, one can gain very high confidence in the truth of a statement if <em>many independent lines of evidence </em>support it.</p>\n<p class=\"MsoNormal\">Epistemology in the human world is murky:</p>\n<ul>\n<li>Most statements are inherently ill-defined</li>\n<li>There's a fair amount of ambiguity as to which statements can rationally be assigned truth value with very high confidence.</li>\n<li>There's ambiguity as to what constitutes good evidence.&nbsp;</li>\n</ul>\n<p class=\"MsoNormal\">To illustrate the principle mentioned above, it's instructive to consider an example in the domain of mathematics, which is a much simpler domain.</p>\n<h2 id=\"Euler_s_solution_of_the_Basel_Problem_\"><strong style=\"mso-bidi-font-weight:normal\">Euler\u2019s solution of the Basel Problem</strong><strong style=\"mso-bidi-font-weight:normal\">&nbsp;</strong></h2>\n<p class=\"MsoNormal\">In 1735, Euler solved <a href=\"http://en.wikipedia.org/wiki/Basel_problem\">the famous problem</a> of finding the value of the \u201cBasel Sum,\u201d which is defined to be the sum of reciprocals of squares of positive integers. He found that the value is equal to \u2018pi squared divided by 6.\u2019</p>\n<p class=\"MsoNormal\">Euler's initial method of solution is striking in that it relies on an assumption which was unproven at the time, and which is not true in full generality. Euler assumed the <strong style=\"mso-bidi-font-weight:normal\">product formula for the <a href=\"https://en.wikipedia.org/wiki/Sine\">sine function</a></strong>, which expresses the sine function as an infinite product of linear polynomials, each corresponding to a real root of the sine function. In hindsight, there are a number of reasons why Euler should have been concerned that the product formula sine might not be valid:</p>\n<ul>\n<li><span style=\"text-indent: -0.25in;\">Its truth hinges on the sine function being differentiable as a </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Complex_analysis\">function of a complex variable</a><span style=\"text-indent: -0.25in;\">, and on the sine function having no non-real complex roots. A reading of Chapter 5 of </span><a style=\"text-indent: -0.25in;\" href=\"http://www.amazon.com/Euler-Master-Dolciani-Mathematical-Expositions/dp/0883853280\">Euler: The Master of Us All</a><span style=\"text-indent: -0.25in;\"> suggests that Euler was unfamiliar with these facts in 1735 (though he seems to have discovered them later).<br></span><span style=\"text-indent: -0.25in;\"><br></span></li>\n<li><span style=\"text-indent: -0.25in;\">Not every function of a complex variable can be written as an infinite product in this way: the fact that the sine function in particular can be depends on the fact that the sine function is an </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Even_and_odd_functions\">odd function</a>,&nbsp;<span style=\"text-indent: -0.25in;\">as well as the fact that the sine function has no worse than </span><a style=\"text-indent: -0.25in;\" href=\"http://en.wikipedia.org/wiki/Exponential_growth\">exponential growth rate</a><span style=\"text-indent: -0.25in;\"> in magnitude. It seems unlikely that Euler was aware that these conditions were necessary.</span><span style=\"mso-spacerun:yes\">&nbsp;</span></li>\n</ul>\n<p class=\"MsoNormal\">The general theorem of which the product formula for sine is a special case is the <a href=\"http://en.wikipedia.org/wiki/Weierstrass_factorization_theorem\">Weierstrass factorization theorem</a>, which wasn\u2019t proved until the mid/late 1800\u2019s.</p>\n<p class=\"MsoNormal\">And indeed, Euler&nbsp;<em>was</em>&nbsp;initially&nbsp;concerned that the product formula&nbsp;for sine might not be valid. So in view of the&nbsp;(at the time)&nbsp;dubious nature of the product formula for sine, how could Euler have known that he had correctly determined the value of the Basel sum?</p>\n<p class=\"MsoNormal\"><a href=\"http://www.amazon.com/Euler-Master-Dolciani-Mathematical-Expositions/dp/0883853280\">Euler: The Master of Us All</a> describes some of Euler's reasons:</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\" id=\"The_analogy_with_polynomial_functions_\">The analogy with polynomial functions </strong></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\"></strong>A polynomial function with all roots real can be written as products of linear polynomials corresponding to the roots of the function. Isaac Newton had shown that the sine function can be written as an infinite polynomial. So one might guess that the sine function can be written as a product of linear polynomials, in analogy with polynomial functions.</p>\n<p class=\"MsoNormal\">This evidence is weak, because not all polynomials have all roots real, and because statements that are true of finite objects often break down when one passes to infinite objects.</p>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-weight:normal\"><strong>Numerical evidence from the Basel sum and its analogs</strong></span></p>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-weight:normal\"><strong></strong></span>If a statement implies a nontrivial true statement, that\u2019s evidence that the original statement is true. (This is just Bayes\u2019 Theorem, and the converse of the fact that&nbsp;<a href=\"/lw/ih/absence_of_evidence_is_evidence_of_absence/\">Absence of Evidence Is Evidence of Absence</a>.)</p>\n<p class=\"MsoNormal\">In 1731, Euler found that the Basel Sum is equal to 1.644934, up to six places past the decimal point. This decimal approximation agrees with that of \u2018pi squared over 6.\u2019 So the assumption that the product formula for sine is true implies something that\u2019s both true and nontrivial.</p>\n<p class=\"MsoNormal\">The above numerical confirmation leaves open the possibility that the Basel Sum and \u2018pi squared over 6\u2019 differ by a very small amount. It can happen that two apparently unrelated and simple mathematical quantities <a href=\"http://en.wikipedia.org/wiki/Complex_multiplication#Sample_consequence\">differ by less than a trillionth</a>, so this is a legitimate concern. &nbsp;</p>\n<p class=\"MsoNormal\">To assuage this concern, one can consider the fact that Euler\u2019s method yields the values of the sum of reciprocals of k<sup>th&nbsp;</sup>powers of positive integers <a href=\"http://en.wikipedia.org/wiki/Zeta_constant#Even_positive_integers\">for every even integer k</a>, and check these formulas for numerical accuracy, finding that they hold with high precision. It\u2019s less likely that <em style=\"mso-bidi-font-style:normal\">all</em> of them are just barely wrong than it is that a <em style=\"mso-bidi-font-style:normal\">single</em> one is just barely wrong. So this a nontrivial amount of further evidence that the product formula for sine is true.</p>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-weight:normal\"><strong>An independent derivation of the Wallis product formula and of the Leibniz series</strong></span></p>\n<p class=\"MsoNormal\">As stated above, if a statement implies a nontrivial true statement, this is evidence that the original statement is true. Euler used the product formula for sine to deduce the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Wallis_product\">Wallis product formula for pi</a>, which had been known since 1655. By assuming the existence of a formula analogous to the product formula for sine, this time for '1 minus sine,' Euler deduced the <a href=\"http://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80\">Leibniz formula for pi</a>.&nbsp;</p>\n<p class=\"MsoNormal\">Upon doing so, Euler wrote \"For our method, which may appear to some as not reliable enough, a great confirmation comes here to light. Therefore, we should not doubt at all of the other things which are derived by the same method.\"</p>\n<p class=\"MsoNormal\"><strong>Remark: </strong><em>After writing this post, I learned that George Polya gave an overlapping discussion of Euler's work on the Basel Problem on pages 17-21 of&nbsp;<a href=\"http://www.amazon.com/Mathematics-Plausible-Reasoning-Induction-Analogy/dp/0691025096\">Mathematics and Plausible Reasoning, Volume 1: Induction and Analogy in Mathematics</a>. I found Euler's deduction of the Leibniz formula for pi in Polya's book. Polya's book contains more case studies of the same type.</em></p>\n<h2 id=\"Conclusion\"><strong>Conclusion</strong></h2>\n<p class=\"MsoNormal\">Euler had good reason to believe that his derivation of the value of the Basel sum was valid, even though a rigorous proof that his derivation was valid was years or decades away.&nbsp;</p>\n<p class=\"MsoNormal\"><em>How </em>much confidence is rational based on the evidence available at the time depends on the degree to which the different lines of evidence are independent. The lines of evidence <em>appear</em> to be independent, but could have subtle interdependencies.</p>\n<p class=\"MsoNormal\">Nevertheless, I've never heard of an example of mathematical statement so robustly supported that turned out to be false. In the context of the fact that there's been a huge amount of mathematical research since then, it may be reasonable to conclude that the appropriate confidence level would have been 99.9999+%. [Edit: I lightly edited this paragraph \u2014 see <a href=\"/lw/hlx/the_use_of_many_independent_lines_of_evidence_the/93bs\">this comment thread</a>.]</p>\n<p class=\"MsoNormal\">It may be appropriate to hedge, with&nbsp;<a href=\"/lw/3be/confidence_levels_inside_and_outside_an_argument/\">Confidence levels inside and outside an argument</a>&nbsp;in mind, because&nbsp;the arguments that I make in this post may themselves be wrong :-).</p>\n<p class=\"MsoNormal\">The example of Euler's work on the Basel Problem highlights the use of many independent lines of evidence to develop very high&nbsp;confidence&nbsp;in a statement: something which occurs and which can occur in many domains.</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at <a href=\"http://www.givewell.org/\">GiveWell</a>. All views here are my own.</p>", "sections": [{"title": "Justifiably high confidence", "anchor": "Justifiably_high_confidence", "level": 1}, {"title": "Limits on the confidence conferred by a single argument", "anchor": "Limits_on_the_confidence_conferred_by_a_single_argument", "level": 1}, {"title": "The use of many independent lines of evidence to develop high confidence", "anchor": "The_use_of_many_independent_lines_of_evidence_to_develop_high_confidence", "level": 1}, {"title": "Euler\u2019s solution of the Basel Problem\u00a0", "anchor": "Euler_s_solution_of_the_Basel_Problem_", "level": 1}, {"title": "The analogy with polynomial functions ", "anchor": "The_analogy_with_polynomial_functions_", "level": 2}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "44 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MwQRucYo6BZZwjKE7", "GrtbTAPfkJa4D6jjH", "mnS2WYLCGJP2kQkRn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-03T06:05:22.275Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Quantifying and Measuring for Self-Experimentation", "slug": "meetup-west-la-meetup-quantifying-and-measuring-for-self", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "xgPZ27s4G27JhcA7n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jiiEaiWwaqkTLdYEc/meetup-west-la-meetup-quantifying-and-measuring-for-self", "pageUrlRelative": "/posts/jiiEaiWwaqkTLdYEc/meetup-west-la-meetup-quantifying-and-measuring-for-self", "linkUrl": "https://www.lesswrong.com/posts/jiiEaiWwaqkTLdYEc/meetup-west-la-meetup-quantifying-and-measuring-for-self", "postedAtFormatted": "Monday, June 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Quantifying%20and%20Measuring%20for%20Self-Experimentation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Quantifying%20and%20Measuring%20for%20Self-Experimentation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjiiEaiWwaqkTLdYEc%2Fmeetup-west-la-meetup-quantifying-and-measuring-for-self%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Quantifying%20and%20Measuring%20for%20Self-Experimentation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjiiEaiWwaqkTLdYEc%2Fmeetup-west-la-meetup-quantifying-and-measuring-for-self", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjiiEaiWwaqkTLdYEc%2Fmeetup-west-la-meetup-quantifying-and-measuring-for-self", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nh'>West LA Meetup - Quantifying and Measuring for Self-Experimentation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 June 2013 11:00:53PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm Wednesday, June 5th.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion:</strong> We will review and brainstorm methods for measuring the effects of changes when doing self-experimentation (trying a new medication, work environment, life policy, etc.), and consider what failure modes might exist for different sorts of self-experiments. Very abstract, but we will start off with a few useful working examples!</p>\n\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nh'>West LA Meetup - Quantifying and Measuring for Self-Experimentation</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jiiEaiWwaqkTLdYEc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.219917286241503e-06, "legacy": true, "legacyId": "22823", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Quantifying_and_Measuring_for_Self_Experimentation\">Discussion article for the meetup : <a href=\"/meetups/nh\">West LA Meetup - Quantifying and Measuring for Self-Experimentation</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 June 2013 11:00:53PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm Wednesday, June 5th.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion:</strong> We will review and brainstorm methods for measuring the effects of changes when doing self-experimentation (trying a new medication, work environment, life policy, etc.), and consider what failure modes might exist for different sorts of self-experiments. Very abstract, but we will start off with a few useful working examples!</p>\n\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n\n<p>I will bring a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Quantifying_and_Measuring_for_Self_Experimentation1\">Discussion article for the meetup : <a href=\"/meetups/nh\">West LA Meetup - Quantifying and Measuring for Self-Experimentation</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Quantifying and Measuring for Self-Experimentation", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Quantifying_and_Measuring_for_Self_Experimentation", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Quantifying and Measuring for Self-Experimentation", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Quantifying_and_Measuring_for_Self_Experimentation1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T03:32:04.987Z", "modifiedAt": "2021-10-24T21:39:09.967Z", "url": null, "title": "Many Weak Arguments vs. One Relatively Strong Argument", "slug": "many-weak-arguments-vs-one-relatively-strong-argument", "viewCount": null, "lastCommentedAt": "2019-06-14T06:27:21.151Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "JonahS", "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9W9P2snxu5Px746LD/many-weak-arguments-vs-one-relatively-strong-argument", "pageUrlRelative": "/posts/9W9P2snxu5Px746LD/many-weak-arguments-vs-one-relatively-strong-argument", "linkUrl": "https://www.lesswrong.com/posts/9W9P2snxu5Px746LD/many-weak-arguments-vs-one-relatively-strong-argument", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Many%20Weak%20Arguments%20vs.%20One%20Relatively%20Strong%20Argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMany%20Weak%20Arguments%20vs.%20One%20Relatively%20Strong%20Argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9W9P2snxu5Px746LD%2Fmany-weak-arguments-vs-one-relatively-strong-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Many%20Weak%20Arguments%20vs.%20One%20Relatively%20Strong%20Argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9W9P2snxu5Px746LD%2Fmany-weak-arguments-vs-one-relatively-strong-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9W9P2snxu5Px746LD%2Fmany-weak-arguments-vs-one-relatively-strong-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3446, "htmlBody": "<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">My epistemic framework has recently undergone some major shifts, and I believe that my current epistemic framework is better than my previous one. In the past, I tended to try to discover and rely on a&nbsp;<strong style=\"mso-bidi-font-weight: normal\">single relatively strong argument</strong>&nbsp;in favor or against a position. Since then, I\u2019ve come to the conclusion that I should shift my focus toward discovering and relying on&nbsp;<strong style=\"mso-bidi-font-weight:normal\">many independent weak arguments</strong>. In this post, I attempt to explain why. After I posted this article, I got lots of comments in response, and responded to them in <a href=\"/r/discussion/lw/hnq/some_clarifications_concerning_my_many_weak/\">this discussion post</a>.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\"><a id=\"more\"></a></span></p>\n<h2><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">My previous reliance on an individual relatively strong argument</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">I\u2019m a mathematician by training, and by inclination. In the past, I tried to achieve as much certainty as possible when I'd evaluate an important question.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">An example: Something that I\u2019ve thought a lot about is AI risk reduction effort as a target for effective philanthropy. In the past, I attempted to discover a single relatively strong argument for, or against, focus on AI risk reduction. Such an argument requires a number of inputs. An example of an input is an argument as to what kind of AI one should expect to be built by default. I spent a lot of time thinking about this and talking with people about it. What I found was that my views on the question were quite unstable, altering frequently and substantially in response to incoming evidence.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The phenomenon of [my position altering frequently and substantially in response to incoming evidence] was not limited to AI risk. It was characteristic of much of my thinking about important questions that could not be answered with clear-cut evidence. I recognized this as bad, but felt that I had no choice in the matter \u2014 I didn\u2019t see another way to think about such questions, and I thought that some such questions are sufficiently important so as to warrant focus. My hope was that my views on these questions would gradually stabilize, but this didn\u2019t happen with the passage of time.</span></p>\n<h2><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">An alternative \u2014 reliance on many weak independent arguments</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">While my views on various questions were bouncing around, I started to notice that some people seemed to be systematically better at answering questions that could not be answered with clear-cut evidence, in the sense that new data supported their prior views more often than new data supported my own prior views.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">This puzzled me, as I hadn\u2019t thought that it was possible to form such reliable views on these sorts of questions with the evidence that was available. I noticed that these people didn\u2019t seem to be using my epistemic framework, and I was unclear on what epistemic framework they were using.</span><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">They didn't seem to be trying to discover a relatively strong argument.&nbsp;</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">They sometimes gave weak arguments that seemed to me to be a product of the fundamental cognitive bias&nbsp;</span>described in Eliezer's article&nbsp;<a href=\"/lw/lj/the_halo_effect/\">The Halo Effect</a>&nbsp;and Yvain's articles&nbsp;<a href=\"/lw/bk/the_trouble_with_good/\">The Trouble with \"Good\"</a>&nbsp;and&nbsp;<a href=\"http://www.lesswrong.com/lw/13k/missing_the_trees_for_the_forest/\">Missing the Trees for the Forest</a>. When a member of a reference class has a given feature, by default, we tend to assume that all members of the reference class have the same feature. Some of the arguments seemed to me sufficiently weak so that they should be ignored, and I didn't understand why they were being mentioned at all.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">What I gradually came to realize is that these people were relying on&nbsp;<em>many independent</em>&nbsp;weak arguments. If the weak arguments&nbsp;<em style=\"mso-bidi-font-style:normal\">collectively</em>&nbsp;supported a position, that\u2019s the position that they would take.</span><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">&nbsp;</span>They were using the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Consilience\">principle of consilience</a>&nbsp;to good effect, obtaining a better predictive model than my own.</p>\n<h2>Many independent weak arguments: a case study</h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">For concreteness, I\u2019ll give an example of a claim that I believe to be true with high probability, despite the fact each individual argument that supports it is weak.</span>&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Claim:&nbsp;</strong><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family:Cambria\">At the current margin, on average, majoring in a quantitative subject increases people\u2019s expected earnings relative to majoring in other subjects.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The following weak arguments support this claim:</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 1:&nbsp;</strong>Historically, there\u2019s been a correlation between majoring in a quantitative subject and making more money. Examining the table in&nbsp;<a href=\"http://econlog.econlib.org/archives/2013/04/major_premium.html\">a blog post by Bryan Caplan</a>&nbsp;reveals that the common majors that are most strongly associated with high earnings are electrical engineering, computer science, mechanical engineering, finance, economics, accounting, and mathematics, each of which is a quantitative major.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 2:&nbsp;</strong>Outside of medicine, law, and management, the most salient jobs that offer the high earnings are finance and software engineering, both of which require quantitative skills. Majoring in a quantitative major builds quantitative skills, and so qualifies one for these jobs.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 3:&nbsp;</strong>Majoring in a subject with an abundance of intelligent people signals to employers that one is intelligent.&nbsp;<a href=\"http://www.statisticbrain.com/iq-estimates-by-intended-college-major/\">IQ estimates by college major</a>&nbsp;suggest that the majors with highest average IQ are physics, philosophy, math, economics, and engineering, most of which are quantitative majors. So majoring in a quantitative field signals intelligence. And employers want intelligent employees, so majoring in a quantitative subject increases earnings.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 4:&nbsp;</strong>Studying a quantitative subject offers better opportunities to test one\u2019s beliefs against the world than studying the humanities and social sciences does, because the measures of performance in quantitative subjects are more objective than those in humanities and social sciences. Thus, studying a quantitative subject raises one\u2019s general human capital relative to what it would have been if one studied a softer subject.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 5:&nbsp;</strong>Conventional wisdom is that majoring in a quantitative subject increases one\u2019s expected earnings. If there were strong arguments against the claim, one might expect them to percolate into conventional wisdom, which they haven't. In absence of evidence to the contrary, one should default to conventional wisdom.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 6:&nbsp;</strong>I know many smart people who enjoy thinking, and who themselves know other many smart people who enjoy thinking. As Yvain discussed in&nbsp;<a href=\"/lw/2pv/intellectual_hipsters_and_metacontrarianism/\">Intellectual Hipsters and Meta-Contrarianism</a>, smart people who enjoy thinking are often motivated to adopt and argue for positions opposed to conventional wisdom, in order to counter-signal intelligence. If the conventional wisdom concerning the subject at hand were wrong, one might expect some of the people who I know to have argued against it, and I\u2019ve never heard them do so.</p>\n<p class=\"MsoNormal\">To verify that these arguments are in fact weak, I\u2019ll give counterarguments against them:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 1:&nbsp;</strong>Correlation is not causation. The people who major in quantitative subjects may make more money later on because they have higher innate ability, or because they have better connections on account of having grown up in households with higher socio-economic status, or for some other nonobvious reason.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 2:&nbsp;</strong>It could be that one only needs to have high school level quantitative knowledge in order to succeed in these jobs.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Majoring in a quantitative field could reduce one\u2019s ability to go to medical school or law school later on (e.g. on account of grading being more strict in quantitative subjects, and medical and law schools selecting students by GPA).</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 3</strong>: Potential employees may have other ways of signaling intelligence, so that college major is not so important. As above, majoring in a quantitative subject may lower GPA, resulting in sending a signal of low quality.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 4:&nbsp;</strong>It could be that earnings don\u2019t depend very much on one\u2019s intellectual caliber. For example, maybe social connections matter more than intellectual caliber, so that one should focus on developing social connections. The heavy workload of a quantitative major could hinder this.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 5:&nbsp;</strong>Conventional wisdom is often wrong. Conventional wisdom on this subject is likely rooted in the correlation between majoring in a quantitative subject and having higher earnings, and as discussed in the counterarguments to 1, correlational evidence is weak.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 6:&nbsp;</strong>There are many, many issues on which one can adopt a meta-contrarian position, and meta-contrarians only discuss a few of these, because there are so many of them. Also, \u201cSmart people who like to think\u201d could, for some unknown reason, collectively be motivated to believe the claim.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">In view of these counterarguments, how can one be confident in the claim?</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">First off, I\u2019ll remark that the counterarguments don\u2019t suffice to refute the individual arguments, because the counterarguments aren\u2019t strong, and there are counterarguments against them.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">But there are counterarguments to the counterarguments as well. In view of this, one might resign oneself to a position of the type \u201cit may or may not be the case that the claim is true, and it\u2019s hopeless to decide whether or not it is.\u201d&nbsp;</span>Eight years ago, this was how I viewed most claims concerning the human world. In Yvain's words, I was experiencing&nbsp;<a href=\"http://squid314.livejournal.com/350090.html\">epistemic learned helplessness.</a></p>\n<p class=\"MsoNormal\">It\u2019s not uncommon for mathematicians to hold this position on claims concerning the human world. Of course there are&nbsp;<a href=\"/lw/hlx/the_use_of_many_independent_lines_of_evidence_the/\">instances</a>&nbsp;of mathematicians using several lines of evidence to arrive at a conclusion in absence of a rigorous proof. But the human world is much messier and more ambiguous than the mathematical world. The great mathematician&nbsp;<a href=\"http://en.wikipedia.org/wiki/Carl_Friedrich_Gauss\">Carl Friedrich Gauss</a>&nbsp;wrote</p>\n<blockquote>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-style:normal\">There are problems to whose solution I would attach infinitely greater importance than to those of mathematics, for example touching ethics, or our relation to God, or concerning our destiny and our future; but their solution lies wholly beyond us and completely outside the province of science.</span></p>\n</blockquote>\n<p class=\"MsoNormal\">Gauss's quotation doesn't directly refer to prosaic&nbsp;epistemic questions about the human world, but one could imagine him having such a view toward these questions, and even if not, I've heard a number of mathematicians express such a view on questions that cannot be answered with clear-cut evidence.</p>\n<p class=\"MsoNormal\">This not withstanding, my current position is that one&nbsp;<em>can</em>&nbsp;be confident in the claim, not with&nbsp;<em>extremely</em>&nbsp;high confidence (say, the&nbsp;<a href=\"https://www.lesswrong.com/lw/hlx/the_use_of_many_independent_lines_of_evidence_the\">level of confidence that Euler had</a>&nbsp;in the truth of the product formula for the sine function), but with confidence at the ~90% level, which is high enough to be actionable.</p>\n<p class=\"MsoNormal\">Why? The point is that the arguments in favor of the claim are, like&nbsp;<a href=\"/lesswrong.com/lw/hlx/the_use_of_many_independent_lines_of_evidence_the\">Euler\u2019s arguments</a>,&nbsp;<em style=\"mso-bidi-font-style: normal;\">largely independent of one another</em>. This corresponds to the fact that the counterarguments are&nbsp;<em style=\"mso-bidi-font-style: normal;\">ad hoc</em>&nbsp;and un-unified. The situation is analogous to Carl Sagan\u2019s \u201c<a href=\"http://www.godlessgeeks.com/LINKS/Dragon.htm\">Dragon in My Garage</a>\u201d parable. In order to refute&nbsp;<em style=\"mso-bidi-font-style: normal;\">all</em>&nbsp;of the arguments via the counterarguments, one needs to assume that all the counterarguments succeed (or other counterarguments succeed), and the counterarguments are pretty independent. If one assumes that for each argument, the counterarguments overpower the argument with probability 50%, and the counterarguments\u2019 successes are independent, the probability that they all succeed is ~1.5%.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">The counterarguments are&nbsp;<em style=\"mso-bidi-font-style: normal;\">not</em>&nbsp;independent \u2014&nbsp;for example, the point about majoring in a quantitative subject lowering GPA appears twice. So I don\u2019t think that one can be&nbsp;<em style=\"mso-bidi-font-style: normal;\">too</em>&nbsp;confident in the conclusion. But the existence of many independent weak arguments suffices to rescue us from epistemic paralysis, and yield an actionable conclusion.</span></p>\n<h2><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">The \u201csingle relatively strong argument\u201d approach to the claim in the case study above</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">The \u201csingle relatively strong argument\u201d approach to assessing the above claim is to try to synthesize as many of the above weak arguments and counterarguments as possible, into a single relatively strong argument. </span></p>\n<p class=\"MsoNormal\">[<strong>Added:</strong> <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93im?context=3\">Kawoomba's comment</a> realize that the above sentence wasn't clear. The point is that in focusing on a single strong argument to the exclusion of other arguments, one is implicitly rejecting the weak arguments, and so doing so constitutes an implicit attempt to synthesize the evidence. The sort of thing that I have in mind here is to say \"Correlation is not causation. Conventional wisdom is probably rooted in mistaking correlation for causation. Therefore we should ignore conventional wisdom in formulating our relatively strong argument.\"]</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">If I were to try to do this, it would look something like this:</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">Based on what people and employers say, it appears that many of the high paying jobs in our society require some quantitative skills. It\u2019s unclear how much quantitative skill one needs to do these jobs. But presumably one needs some.</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">People who are&nbsp;<em>below</em>&nbsp;this threshold may be able to surpass it by majoring in a quantitative subject, and thereby get higher earnings.&nbsp;</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">Even if one does surpass this threshold, majoring in a quantitative subject may not suffice to signal to employers that one is above that threshold, if the noise to signal ratio is high. But it may not be necessary to get a job that requires quantitative skills right out of college, in order to get high earnings from building quantitative skills in college \u2014&nbsp;it might be possible for an employee to \u201cwork his or her way up\u201d to a position that uses quantitative skills, and profit as a result.</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">It might appear as though people who are already&nbsp;<em>above</em>&nbsp;this threshold wouldn\u2019t get higher earnings from majoring in a quantitative subject. But employers may not be able to tell that potential employees have quantitative skills unless they major a quantitative subject. (Note that if this is true, it suggests that the concern in the previous paragraph is less of an issue. However, it could still be an issue, because different levels of quantitative skills are required to get different jobs, so that the level that employees need to signal is not homogenous). This pushes in favor of majoring in a quantitative subject. People above the threshold may also benefit in majoring in a quantitative subject because it signals intelligence, which is considered to be desirable, independently of the specific quantitative skills that a potential employee has acquired.&nbsp;</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">It\u2019s necessary to weigh these considerations against the fact that quantitative majors tend to be demanding, leaving less time for other activities, and are harder to get good grades in. Thus, majoring in a quantitative subject involves a tradeoff, the value of which will vary from individual to individual, depending on his or her skills, potential areas of work, and the criteria that graduate schools and employers use to select employees.</span></p>\n<h2>Major weaknesses of the \u201csingle relatively strong argument\u201d approach</h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The above argument has&nbsp;<em style=\"mso-bidi-font-style:normal\">some</em>&nbsp;value, and I imagine that a college freshman would find it&nbsp;<em style=\"mso-bidi-font-style: normal\">somewhat</em>&nbsp;useful. But it seems less helpful than the list of weak arguments, together with the most important counterarguments, given earlier in this post. The argument in the previous section doesn\u2019t clearly demarcate the different lines of evidence, and inadvertently leaves out some of the lines of evidence (because some of the lines of evidence don\u2019t easily fit into a single framework).</span></p>\n<p class=\"MsoNormal\">These problems with using the \u201csingle relatively strong argument\u201d approach are closely related to my past unstable epistemology. Because the \u201csingle relatively strong argument\u201d approach doesn\u2019t clearly demarcate the different lines of evidence, when a user of the approach gets new counter-evidence that\u2019s orthogonal to the argument, he or she has to rethink the entire argument. Because the \u201csingle relatively strong argument\u201d approach leaves out some lines of evidence, it\u2019s less robust than it could be.</p>\n<p class=\"MsoNormal\"><em>A priori,&nbsp;</em>one could imagine that these things wouldn\u2019t be a problem in practice: if the relatively strong argument were true with sufficiently high probability, then it would be unlikely that one would have to completely rethink things in the face of incoming evidence, and it wouldn\u2019t be so important that the argument doesn't incorporate all of the evidence.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">My experience is that this situation does not prevail in practice. One theoretical explanation for this is analogous to a point that I made in my post&nbsp;<a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>:</span></p>\n<blockquote>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">A key point that I had missed when I thought about these things earlier in my life is that&nbsp;<strong style=\"mso-bidi-font-weight:normal\">there are many small probability failure modes, which are not significant individually, but which collectively</strong>&nbsp;<strong style=\"mso-bidi-font-weight:normal\">substantially reduce [the probability that the argument is correct]</strong>. When I encountered such a potential failure mode, my reaction was to think \u201cthis is very unlikely to be an issue\u201d and then to forget about it. I didn\u2019t notice that I was doing this many times in a row.</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"tab-stops:261.1pt\"><span style=\"mso-ascii-font-family: Cambria;mso-hansi-font-family:Cambria\">This applies not only to cost-effectiveness, but also to the accuracy of individual relatively strong arguments. Relatively strong arguments in domains outside of math and the hard scientists are often much weaker than they appear. The phenomenon of&nbsp;<a href=\"http://ljsavage.wharton.upenn.edu/~edgeorge/Research_papers/CG-StatSci04.pdf\">model uncertainty</a>&nbsp;is pronounced.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The points in this section of the post are in consonance with a claim of&nbsp;</span>Philip Tetlock\u2019s in&nbsp;<a href=\"http://www.amazon.com/Expert-Political-Judgment-Good-Know/dp/0691128715\">Expert Political Judgment: How Good Is It? How Can We Know?</a>:</p>\n<blockquote>\n<p class=\"MsoNormal\">Tetlock contends that the fox \u2014 the thinker who knows many little things, draws from an eclectic array of traditions, and is better able to improvise in response to changing events \u2014 is more successful in predicting the future than the hedgehog, who knows one big thing, toils devotedly within one tradition, and imposes formulaic solutions on ill-defined problems.</p>\n</blockquote>\n<h2><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">A sample implication: a change in my attitude toward Penrose's beliefs about consciousness</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">An example that highlights my shift in epistemology is the shift in my attitude concerning Roger Penrose\u2019s beliefs about consciousness. </span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">[<strong>Edit: </strong><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93mf\">Eliezer's comment</a> and <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93oo?context=3\">Vaniver's comment</a>&nbsp;made me realize that the connection between this example and the rest of my post is unclear. The shift in my attitude toward Penrose's beliefs about consciousness isn't coming from my shift toward using the principle of consilience. I agree that the arrow of consilience points against Penrose's beliefs. The shift in my attitude is coming from the shift from \"give weight to arguments that stand up to scrutiny\" to \"give weight to all arguments with a nontrivial chance of being right, even the ones that don't seem to hold up to scrutiny.\"]</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">&nbsp;<a href=\"http://en.wikipedia.org/wiki/Roger_Penrose\">According to Wikipedia</a></span></p>\n<blockquote>\n<p class=\"MsoNormal\">In The Emperor's New Mind (1989), he argues that known laws of physics are inadequate to explain the phenomenon of consciousness. Penrose proposes the characteristics this new physics may have and specifies the requirements for a bridge between classical and quantum mechanics (what he calls correct quantum gravity). [\u2026] Penrose believes that such deterministic yet non-algorithmic processes may come into play in the quantum mechanical wave function reduction, and may be harnessed by the brain. He argues that the present computer is unable to have intelligence because it is an algorithmically deterministic system. He argues against the viewpoint that the rational processes of the mind are completely algorithmic and can thus be duplicated by a sufficiently complex computer. This contrasts with supporters of strong artificial intelligence, who contend that thought can be simulated algorithmically. He bases this on claims that consciousness transcends formal logic because things such as the insolubility of the halting problem and G\u00f6del's incompleteness theorem prevent an algorithmically based system of logic from reproducing such traits of human intelligence as mathematical insight.</p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"tab-stops:261.1pt\"><span style=\"mso-ascii-font-family: Cambria;mso-hansi-font-family:Cambria\">I believe that Penrose\u2019s views about consciousness are very unlikely to be true:</span></p>\n<ul>\n<li><span style=\"text-indent: -0.25in;\">I subscribe to reductionism, and I don't think that a present computer is unable to have intelligence, according to any reasonable definition of intelligence.<br></span><span style=\"text-indent: -0.25in; font-family: Symbol;\"><span style=\"font-size: 7pt; font-family: 'Times New Roman';\"><br></span></span></li>\n<li><span style=\"text-indent: -0.25in;\">This invocation of Godel\u2019s incompleteness theorem seems to be a non-sequitur, and has been criticized by many mathematicians.<span style=\"font-family: Symbol;\"><br></span></span><span style=\"text-indent: -0.25in;\"><br></span></li>\n<li><span style=\"text-indent: -0.25in;\">Max Tegmark&nbsp;<a href=\"http://arxiv.org/pdf/quant-ph/9907009.pdf\">did a calculation</a>&nbsp;calling into question the physics part of Penrose\u2019s argument.<br></span><span style=\"text-indent: -0.25in;\"><br></span></li>\n<li><span style=\"text-indent: -0.25in;\">I don\u2019t know anybody who shares Penrose\u2019s view on consciousness, and the fraction of all scientists who agree with Penrose\u2019s view appears to be tiny.</span></li>\n</ul>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">But Penrose isn\u2019t a random crank. Penrose is one of the greatest physicists of the second half of the 20<sup>th</sup>&nbsp;century. He\u2019s a far deeper thinker than me, and for that matter, a far deeper thinker than anybody who I\u2019ve ever met.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">I have several relatively strong arguments against Penrose's views on consciousness. Collectively, they\u2019re significantly stronger than the moderately strong argument \u201cgreat physicists are often right.\u201d In the past, I would have concluded \u201c\u2026therefore Penrose is wrong.\u201d</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">But it\u2019s not rational to ignore the moderately strong argument that supports Penrose\u2019s views. The chance of the argument being right is non-negligible. I should give nontrivial credence to Penrose\u2019s views on consciousness having substance. Maybe at least&nbsp;<em style=\"mso-bidi-font-style:normal\">some&nbsp;</em>of Penrose\u2019s ideas about consciousness are sound, and that the reason that they seem tenuous is that he\u2019s expressed his ideas poorly, or they've been misquoted. Maybe there's some other way to reconcile the hypothesis that his views are sound, with the evidence against this, that I haven't thought of.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">If I were using my previous epistemic framework, my world view could be turned upside down by a single conversation with Penrose. If I were using my previous epistemological framework, I would be subject to confirmation bias, using my conclusion \u201c\u2026therefore Penrose is wrong\u201d as overly strong evidence against the claim \u201cgreat physicists are often right,\u201d which I was unwarrantedly ignoring from the outset.<span style=\"mso-spacerun:yes\">&nbsp;</span></span></p>\n<h2><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\"><span style=\"mso-spacerun:yes\">End notes</span></span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">Retrospectively, it makes sense that there are people who are substantially better than I had been at reasoning about questions that I thought inherently near-impossible to think about.</span></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Acknowledgements:&nbsp;</strong><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">I thank&nbsp;</span>Luke Muehlhauser, Vipul Naik, Nick Beckstead, and Laurens Gunnarsen for useful suggestions for what to include in the post, as well as helpful comments on an earlier draft. I'm indebted to and grateful to Holden Karnofsky at&nbsp;<a href=\"http://www.givewell.org\">GiveWell</a>&nbsp;for his insights, as well as GiveWell, which offered me the opportunity to think about hard epistemic questions that can't be answered with clear-cut evidence. Both of these helped me recognize the core thesis of this post.</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at&nbsp;<a href=\"http://www.givewell.org\">GiveWell</a>. All views expressed here are my own.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xgpBASEThXPuKRhbS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9W9P2snxu5Px746LD", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 32, "extendedScore": null, "score": 8e-05, "legacy": true, "legacyId": "22835", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">My epistemic framework has recently undergone some major shifts, and I believe that my current epistemic framework is better than my previous one. In the past, I tended to try to discover and rely on a&nbsp;<strong style=\"mso-bidi-font-weight: normal\">single relatively strong argument</strong>&nbsp;in favor or against a position. Since then, I\u2019ve come to the conclusion that I should shift my focus toward discovering and relying on&nbsp;<strong style=\"mso-bidi-font-weight:normal\">many independent weak arguments</strong>. In this post, I attempt to explain why. After I posted this article, I got lots of comments in response, and responded to them in <a href=\"/r/discussion/lw/hnq/some_clarifications_concerning_my_many_weak/\">this discussion post</a>.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\"><a id=\"more\"></a></span></p>\n<h2 id=\"My_previous_reliance_on_an_individual_relatively_strong_argument\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">My previous reliance on an individual relatively strong argument</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">I\u2019m a mathematician by training, and by inclination. In the past, I tried to achieve as much certainty as possible when I'd evaluate an important question.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">An example: Something that I\u2019ve thought a lot about is AI risk reduction effort as a target for effective philanthropy. In the past, I attempted to discover a single relatively strong argument for, or against, focus on AI risk reduction. Such an argument requires a number of inputs. An example of an input is an argument as to what kind of AI one should expect to be built by default. I spent a lot of time thinking about this and talking with people about it. What I found was that my views on the question were quite unstable, altering frequently and substantially in response to incoming evidence.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The phenomenon of [my position altering frequently and substantially in response to incoming evidence] was not limited to AI risk. It was characteristic of much of my thinking about important questions that could not be answered with clear-cut evidence. I recognized this as bad, but felt that I had no choice in the matter \u2014 I didn\u2019t see another way to think about such questions, and I thought that some such questions are sufficiently important so as to warrant focus. My hope was that my views on these questions would gradually stabilize, but this didn\u2019t happen with the passage of time.</span></p>\n<h2 id=\"An_alternative___reliance_on_many_weak_independent_arguments\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">An alternative \u2014 reliance on many weak independent arguments</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">While my views on various questions were bouncing around, I started to notice that some people seemed to be systematically better at answering questions that could not be answered with clear-cut evidence, in the sense that new data supported their prior views more often than new data supported my own prior views.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">This puzzled me, as I hadn\u2019t thought that it was possible to form such reliable views on these sorts of questions with the evidence that was available. I noticed that these people didn\u2019t seem to be using my epistemic framework, and I was unclear on what epistemic framework they were using.</span><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">They didn't seem to be trying to discover a relatively strong argument.&nbsp;</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">They sometimes gave weak arguments that seemed to me to be a product of the fundamental cognitive bias&nbsp;</span>described in Eliezer's article&nbsp;<a href=\"/lw/lj/the_halo_effect/\">The Halo Effect</a>&nbsp;and Yvain's articles&nbsp;<a href=\"/lw/bk/the_trouble_with_good/\">The Trouble with \"Good\"</a>&nbsp;and&nbsp;<a href=\"http://www.lesswrong.com/lw/13k/missing_the_trees_for_the_forest/\">Missing the Trees for the Forest</a>. When a member of a reference class has a given feature, by default, we tend to assume that all members of the reference class have the same feature. Some of the arguments seemed to me sufficiently weak so that they should be ignored, and I didn't understand why they were being mentioned at all.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">What I gradually came to realize is that these people were relying on&nbsp;<em>many independent</em>&nbsp;weak arguments. If the weak arguments&nbsp;<em style=\"mso-bidi-font-style:normal\">collectively</em>&nbsp;supported a position, that\u2019s the position that they would take.</span><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">&nbsp;</span>They were using the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Consilience\">principle of consilience</a>&nbsp;to good effect, obtaining a better predictive model than my own.</p>\n<h2 id=\"Many_independent_weak_arguments__a_case_study\">Many independent weak arguments: a case study</h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">For concreteness, I\u2019ll give an example of a claim that I believe to be true with high probability, despite the fact each individual argument that supports it is weak.</span>&nbsp;</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Claim:&nbsp;</strong><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family:Cambria\">At the current margin, on average, majoring in a quantitative subject increases people\u2019s expected earnings relative to majoring in other subjects.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The following weak arguments support this claim:</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 1:&nbsp;</strong>Historically, there\u2019s been a correlation between majoring in a quantitative subject and making more money. Examining the table in&nbsp;<a href=\"http://econlog.econlib.org/archives/2013/04/major_premium.html\">a blog post by Bryan Caplan</a>&nbsp;reveals that the common majors that are most strongly associated with high earnings are electrical engineering, computer science, mechanical engineering, finance, economics, accounting, and mathematics, each of which is a quantitative major.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 2:&nbsp;</strong>Outside of medicine, law, and management, the most salient jobs that offer the high earnings are finance and software engineering, both of which require quantitative skills. Majoring in a quantitative major builds quantitative skills, and so qualifies one for these jobs.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 3:&nbsp;</strong>Majoring in a subject with an abundance of intelligent people signals to employers that one is intelligent.&nbsp;<a href=\"http://www.statisticbrain.com/iq-estimates-by-intended-college-major/\">IQ estimates by college major</a>&nbsp;suggest that the majors with highest average IQ are physics, philosophy, math, economics, and engineering, most of which are quantitative majors. So majoring in a quantitative field signals intelligence. And employers want intelligent employees, so majoring in a quantitative subject increases earnings.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 4:&nbsp;</strong>Studying a quantitative subject offers better opportunities to test one\u2019s beliefs against the world than studying the humanities and social sciences does, because the measures of performance in quantitative subjects are more objective than those in humanities and social sciences. Thus, studying a quantitative subject raises one\u2019s general human capital relative to what it would have been if one studied a softer subject.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 5:&nbsp;</strong>Conventional wisdom is that majoring in a quantitative subject increases one\u2019s expected earnings. If there were strong arguments against the claim, one might expect them to percolate into conventional wisdom, which they haven't. In absence of evidence to the contrary, one should default to conventional wisdom.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Weak argument 6:&nbsp;</strong>I know many smart people who enjoy thinking, and who themselves know other many smart people who enjoy thinking. As Yvain discussed in&nbsp;<a href=\"/lw/2pv/intellectual_hipsters_and_metacontrarianism/\">Intellectual Hipsters and Meta-Contrarianism</a>, smart people who enjoy thinking are often motivated to adopt and argue for positions opposed to conventional wisdom, in order to counter-signal intelligence. If the conventional wisdom concerning the subject at hand were wrong, one might expect some of the people who I know to have argued against it, and I\u2019ve never heard them do so.</p>\n<p class=\"MsoNormal\">To verify that these arguments are in fact weak, I\u2019ll give counterarguments against them:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 1:&nbsp;</strong>Correlation is not causation. The people who major in quantitative subjects may make more money later on because they have higher innate ability, or because they have better connections on account of having grown up in households with higher socio-economic status, or for some other nonobvious reason.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 2:&nbsp;</strong>It could be that one only needs to have high school level quantitative knowledge in order to succeed in these jobs.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Majoring in a quantitative field could reduce one\u2019s ability to go to medical school or law school later on (e.g. on account of grading being more strict in quantitative subjects, and medical and law schools selecting students by GPA).</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 3</strong>: Potential employees may have other ways of signaling intelligence, so that college major is not so important. As above, majoring in a quantitative subject may lower GPA, resulting in sending a signal of low quality.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 4:&nbsp;</strong>It could be that earnings don\u2019t depend very much on one\u2019s intellectual caliber. For example, maybe social connections matter more than intellectual caliber, so that one should focus on developing social connections. The heavy workload of a quantitative major could hinder this.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 5:&nbsp;</strong>Conventional wisdom is often wrong. Conventional wisdom on this subject is likely rooted in the correlation between majoring in a quantitative subject and having higher earnings, and as discussed in the counterarguments to 1, correlational evidence is weak.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><strong>Counterarguments to 6:&nbsp;</strong>There are many, many issues on which one can adopt a meta-contrarian position, and meta-contrarians only discuss a few of these, because there are so many of them. Also, \u201cSmart people who like to think\u201d could, for some unknown reason, collectively be motivated to believe the claim.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">In view of these counterarguments, how can one be confident in the claim?</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">First off, I\u2019ll remark that the counterarguments don\u2019t suffice to refute the individual arguments, because the counterarguments aren\u2019t strong, and there are counterarguments against them.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">But there are counterarguments to the counterarguments as well. In view of this, one might resign oneself to a position of the type \u201cit may or may not be the case that the claim is true, and it\u2019s hopeless to decide whether or not it is.\u201d&nbsp;</span>Eight years ago, this was how I viewed most claims concerning the human world. In Yvain's words, I was experiencing&nbsp;<a href=\"http://squid314.livejournal.com/350090.html\">epistemic learned helplessness.</a></p>\n<p class=\"MsoNormal\">It\u2019s not uncommon for mathematicians to hold this position on claims concerning the human world. Of course there are&nbsp;<a href=\"/lw/hlx/the_use_of_many_independent_lines_of_evidence_the/\">instances</a>&nbsp;of mathematicians using several lines of evidence to arrive at a conclusion in absence of a rigorous proof. But the human world is much messier and more ambiguous than the mathematical world. The great mathematician&nbsp;<a href=\"http://en.wikipedia.org/wiki/Carl_Friedrich_Gauss\">Carl Friedrich Gauss</a>&nbsp;wrote</p>\n<blockquote>\n<p class=\"MsoNormal\"><span style=\"mso-bidi-font-style:normal\">There are problems to whose solution I would attach infinitely greater importance than to those of mathematics, for example touching ethics, or our relation to God, or concerning our destiny and our future; but their solution lies wholly beyond us and completely outside the province of science.</span></p>\n</blockquote>\n<p class=\"MsoNormal\">Gauss's quotation doesn't directly refer to prosaic&nbsp;epistemic questions about the human world, but one could imagine him having such a view toward these questions, and even if not, I've heard a number of mathematicians express such a view on questions that cannot be answered with clear-cut evidence.</p>\n<p class=\"MsoNormal\">This not withstanding, my current position is that one&nbsp;<em>can</em>&nbsp;be confident in the claim, not with&nbsp;<em>extremely</em>&nbsp;high confidence (say, the&nbsp;<a href=\"https://www.lesswrong.com/lw/hlx/the_use_of_many_independent_lines_of_evidence_the\">level of confidence that Euler had</a>&nbsp;in the truth of the product formula for the sine function), but with confidence at the ~90% level, which is high enough to be actionable.</p>\n<p class=\"MsoNormal\">Why? The point is that the arguments in favor of the claim are, like&nbsp;<a href=\"/lesswrong.com/lw/hlx/the_use_of_many_independent_lines_of_evidence_the\">Euler\u2019s arguments</a>,&nbsp;<em style=\"mso-bidi-font-style: normal;\">largely independent of one another</em>. This corresponds to the fact that the counterarguments are&nbsp;<em style=\"mso-bidi-font-style: normal;\">ad hoc</em>&nbsp;and un-unified. The situation is analogous to Carl Sagan\u2019s \u201c<a href=\"http://www.godlessgeeks.com/LINKS/Dragon.htm\">Dragon in My Garage</a>\u201d parable. In order to refute&nbsp;<em style=\"mso-bidi-font-style: normal;\">all</em>&nbsp;of the arguments via the counterarguments, one needs to assume that all the counterarguments succeed (or other counterarguments succeed), and the counterarguments are pretty independent. If one assumes that for each argument, the counterarguments overpower the argument with probability 50%, and the counterarguments\u2019 successes are independent, the probability that they all succeed is ~1.5%.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">The counterarguments are&nbsp;<em style=\"mso-bidi-font-style: normal;\">not</em>&nbsp;independent \u2014&nbsp;for example, the point about majoring in a quantitative subject lowering GPA appears twice. So I don\u2019t think that one can be&nbsp;<em style=\"mso-bidi-font-style: normal;\">too</em>&nbsp;confident in the conclusion. But the existence of many independent weak arguments suffices to rescue us from epistemic paralysis, and yield an actionable conclusion.</span></p>\n<h2 id=\"The__single_relatively_strong_argument__approach_to_the_claim_in_the_case_study_above\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">The \u201csingle relatively strong argument\u201d approach to the claim in the case study above</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">The \u201csingle relatively strong argument\u201d approach to assessing the above claim is to try to synthesize as many of the above weak arguments and counterarguments as possible, into a single relatively strong argument. </span></p>\n<p class=\"MsoNormal\">[<strong>Added:</strong> <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93im?context=3\">Kawoomba's comment</a> realize that the above sentence wasn't clear. The point is that in focusing on a single strong argument to the exclusion of other arguments, one is implicitly rejecting the weak arguments, and so doing so constitutes an implicit attempt to synthesize the evidence. The sort of thing that I have in mind here is to say \"Correlation is not causation. Conventional wisdom is probably rooted in mistaking correlation for causation. Therefore we should ignore conventional wisdom in formulating our relatively strong argument.\"]</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">If I were to try to do this, it would look something like this:</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">Based on what people and employers say, it appears that many of the high paying jobs in our society require some quantitative skills. It\u2019s unclear how much quantitative skill one needs to do these jobs. But presumably one needs some.</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">People who are&nbsp;<em>below</em>&nbsp;this threshold may be able to surpass it by majoring in a quantitative subject, and thereby get higher earnings.&nbsp;</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">Even if one does surpass this threshold, majoring in a quantitative subject may not suffice to signal to employers that one is above that threshold, if the noise to signal ratio is high. But it may not be necessary to get a job that requires quantitative skills right out of college, in order to get high earnings from building quantitative skills in college \u2014&nbsp;it might be possible for an employee to \u201cwork his or her way up\u201d to a position that uses quantitative skills, and profit as a result.</span></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">It might appear as though people who are already&nbsp;<em>above</em>&nbsp;this threshold wouldn\u2019t get higher earnings from majoring in a quantitative subject. But employers may not be able to tell that potential employees have quantitative skills unless they major a quantitative subject. (Note that if this is true, it suggests that the concern in the previous paragraph is less of an issue. However, it could still be an issue, because different levels of quantitative skills are required to get different jobs, so that the level that employees need to signal is not homogenous). This pushes in favor of majoring in a quantitative subject. People above the threshold may also benefit in majoring in a quantitative subject because it signals intelligence, which is considered to be desirable, independently of the specific quantitative skills that a potential employee has acquired.&nbsp;</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\"><span style=\"mso-ascii-font-family: Cambria; mso-hansi-font-family: Cambria;\">It\u2019s necessary to weigh these considerations against the fact that quantitative majors tend to be demanding, leaving less time for other activities, and are harder to get good grades in. Thus, majoring in a quantitative subject involves a tradeoff, the value of which will vary from individual to individual, depending on his or her skills, potential areas of work, and the criteria that graduate schools and employers use to select employees.</span></p>\n<h2 id=\"Major_weaknesses_of_the__single_relatively_strong_argument__approach\">Major weaknesses of the \u201csingle relatively strong argument\u201d approach</h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The above argument has&nbsp;<em style=\"mso-bidi-font-style:normal\">some</em>&nbsp;value, and I imagine that a college freshman would find it&nbsp;<em style=\"mso-bidi-font-style: normal\">somewhat</em>&nbsp;useful. But it seems less helpful than the list of weak arguments, together with the most important counterarguments, given earlier in this post. The argument in the previous section doesn\u2019t clearly demarcate the different lines of evidence, and inadvertently leaves out some of the lines of evidence (because some of the lines of evidence don\u2019t easily fit into a single framework).</span></p>\n<p class=\"MsoNormal\">These problems with using the \u201csingle relatively strong argument\u201d approach are closely related to my past unstable epistemology. Because the \u201csingle relatively strong argument\u201d approach doesn\u2019t clearly demarcate the different lines of evidence, when a user of the approach gets new counter-evidence that\u2019s orthogonal to the argument, he or she has to rethink the entire argument. Because the \u201csingle relatively strong argument\u201d approach leaves out some lines of evidence, it\u2019s less robust than it could be.</p>\n<p class=\"MsoNormal\"><em>A priori,&nbsp;</em>one could imagine that these things wouldn\u2019t be a problem in practice: if the relatively strong argument were true with sufficiently high probability, then it would be unlikely that one would have to completely rethink things in the face of incoming evidence, and it wouldn\u2019t be so important that the argument doesn't incorporate all of the evidence.</p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">My experience is that this situation does not prevail in practice. One theoretical explanation for this is analogous to a point that I made in my post&nbsp;<a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>:</span></p>\n<blockquote>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">A key point that I had missed when I thought about these things earlier in my life is that&nbsp;<strong style=\"mso-bidi-font-weight:normal\">there are many small probability failure modes, which are not significant individually, but which collectively</strong>&nbsp;<strong style=\"mso-bidi-font-weight:normal\">substantially reduce [the probability that the argument is correct]</strong>. When I encountered such a potential failure mode, my reaction was to think \u201cthis is very unlikely to be an issue\u201d and then to forget about it. I didn\u2019t notice that I was doing this many times in a row.</span></p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"tab-stops:261.1pt\"><span style=\"mso-ascii-font-family: Cambria;mso-hansi-font-family:Cambria\">This applies not only to cost-effectiveness, but also to the accuracy of individual relatively strong arguments. Relatively strong arguments in domains outside of math and the hard scientists are often much weaker than they appear. The phenomenon of&nbsp;<a href=\"http://ljsavage.wharton.upenn.edu/~edgeorge/Research_papers/CG-StatSci04.pdf\">model uncertainty</a>&nbsp;is pronounced.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">The points in this section of the post are in consonance with a claim of&nbsp;</span>Philip Tetlock\u2019s in&nbsp;<a href=\"http://www.amazon.com/Expert-Political-Judgment-Good-Know/dp/0691128715\">Expert Political Judgment: How Good Is It? How Can We Know?</a>:</p>\n<blockquote>\n<p class=\"MsoNormal\">Tetlock contends that the fox \u2014 the thinker who knows many little things, draws from an eclectic array of traditions, and is better able to improvise in response to changing events \u2014 is more successful in predicting the future than the hedgehog, who knows one big thing, toils devotedly within one tradition, and imposes formulaic solutions on ill-defined problems.</p>\n</blockquote>\n<h2 id=\"A_sample_implication__a_change_in_my_attitude_toward_Penrose_s_beliefs_about_consciousness\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">A sample implication: a change in my attitude toward Penrose's beliefs about consciousness</span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">An example that highlights my shift in epistemology is the shift in my attitude concerning Roger Penrose\u2019s beliefs about consciousness. </span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">[<strong>Edit: </strong><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93mf\">Eliezer's comment</a> and <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93oo?context=3\">Vaniver's comment</a>&nbsp;made me realize that the connection between this example and the rest of my post is unclear. The shift in my attitude toward Penrose's beliefs about consciousness isn't coming from my shift toward using the principle of consilience. I agree that the arrow of consilience points against Penrose's beliefs. The shift in my attitude is coming from the shift from \"give weight to arguments that stand up to scrutiny\" to \"give weight to all arguments with a nontrivial chance of being right, even the ones that don't seem to hold up to scrutiny.\"]</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">&nbsp;<a href=\"http://en.wikipedia.org/wiki/Roger_Penrose\">According to Wikipedia</a></span></p>\n<blockquote>\n<p class=\"MsoNormal\">In The Emperor's New Mind (1989), he argues that known laws of physics are inadequate to explain the phenomenon of consciousness. Penrose proposes the characteristics this new physics may have and specifies the requirements for a bridge between classical and quantum mechanics (what he calls correct quantum gravity). [\u2026] Penrose believes that such deterministic yet non-algorithmic processes may come into play in the quantum mechanical wave function reduction, and may be harnessed by the brain. He argues that the present computer is unable to have intelligence because it is an algorithmically deterministic system. He argues against the viewpoint that the rational processes of the mind are completely algorithmic and can thus be duplicated by a sufficiently complex computer. This contrasts with supporters of strong artificial intelligence, who contend that thought can be simulated algorithmically. He bases this on claims that consciousness transcends formal logic because things such as the insolubility of the halting problem and G\u00f6del's incompleteness theorem prevent an algorithmically based system of logic from reproducing such traits of human intelligence as mathematical insight.</p>\n</blockquote>\n<p class=\"MsoNormal\" style=\"tab-stops:261.1pt\"><span style=\"mso-ascii-font-family: Cambria;mso-hansi-font-family:Cambria\">I believe that Penrose\u2019s views about consciousness are very unlikely to be true:</span></p>\n<ul>\n<li><span style=\"text-indent: -0.25in;\">I subscribe to reductionism, and I don't think that a present computer is unable to have intelligence, according to any reasonable definition of intelligence.<br></span><span style=\"text-indent: -0.25in; font-family: Symbol;\"><span style=\"font-size: 7pt; font-family: 'Times New Roman';\"><br></span></span></li>\n<li><span style=\"text-indent: -0.25in;\">This invocation of Godel\u2019s incompleteness theorem seems to be a non-sequitur, and has been criticized by many mathematicians.<span style=\"font-family: Symbol;\"><br></span></span><span style=\"text-indent: -0.25in;\"><br></span></li>\n<li><span style=\"text-indent: -0.25in;\">Max Tegmark&nbsp;<a href=\"http://arxiv.org/pdf/quant-ph/9907009.pdf\">did a calculation</a>&nbsp;calling into question the physics part of Penrose\u2019s argument.<br></span><span style=\"text-indent: -0.25in;\"><br></span></li>\n<li><span style=\"text-indent: -0.25in;\">I don\u2019t know anybody who shares Penrose\u2019s view on consciousness, and the fraction of all scientists who agree with Penrose\u2019s view appears to be tiny.</span></li>\n</ul>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">But Penrose isn\u2019t a random crank. Penrose is one of the greatest physicists of the second half of the 20<sup>th</sup>&nbsp;century. He\u2019s a far deeper thinker than me, and for that matter, a far deeper thinker than anybody who I\u2019ve ever met.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">I have several relatively strong arguments against Penrose's views on consciousness. Collectively, they\u2019re significantly stronger than the moderately strong argument \u201cgreat physicists are often right.\u201d In the past, I would have concluded \u201c\u2026therefore Penrose is wrong.\u201d</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">But it\u2019s not rational to ignore the moderately strong argument that supports Penrose\u2019s views. The chance of the argument being right is non-negligible. I should give nontrivial credence to Penrose\u2019s views on consciousness having substance. Maybe at least&nbsp;<em style=\"mso-bidi-font-style:normal\">some&nbsp;</em>of Penrose\u2019s ideas about consciousness are sound, and that the reason that they seem tenuous is that he\u2019s expressed his ideas poorly, or they've been misquoted. Maybe there's some other way to reconcile the hypothesis that his views are sound, with the evidence against this, that I haven't thought of.</span></p>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">If I were using my previous epistemic framework, my world view could be turned upside down by a single conversation with Penrose. If I were using my previous epistemological framework, I would be subject to confirmation bias, using my conclusion \u201c\u2026therefore Penrose is wrong\u201d as overly strong evidence against the claim \u201cgreat physicists are often right,\u201d which I was unwarrantedly ignoring from the outset.<span style=\"mso-spacerun:yes\">&nbsp;</span></span></p>\n<h2 id=\"End_notes\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\"><span style=\"mso-spacerun:yes\">End notes</span></span></h2>\n<p class=\"MsoNormal\"><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">Retrospectively, it makes sense that there are people who are substantially better than I had been at reasoning about questions that I thought inherently near-impossible to think about.</span></p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">Acknowledgements:&nbsp;</strong><span style=\"mso-ascii-font-family:Cambria;mso-hansi-font-family: Cambria\">I thank&nbsp;</span>Luke Muehlhauser, Vipul Naik, Nick Beckstead, and Laurens Gunnarsen for useful suggestions for what to include in the post, as well as helpful comments on an earlier draft. I'm indebted to and grateful to Holden Karnofsky at&nbsp;<a href=\"http://www.givewell.org\">GiveWell</a>&nbsp;for his insights, as well as GiveWell, which offered me the opportunity to think about hard epistemic questions that can't be answered with clear-cut evidence. Both of these helped me recognize the core thesis of this post.</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at&nbsp;<a href=\"http://www.givewell.org\">GiveWell</a>. All views expressed here are my own.</p>", "sections": [{"title": "My previous reliance on an individual relatively strong argument", "anchor": "My_previous_reliance_on_an_individual_relatively_strong_argument", "level": 1}, {"title": "An alternative \u2014 reliance on many weak independent arguments", "anchor": "An_alternative___reliance_on_many_weak_independent_arguments", "level": 1}, {"title": "Many independent weak arguments: a case study", "anchor": "Many_independent_weak_arguments__a_case_study", "level": 1}, {"title": "The \u201csingle relatively strong argument\u201d approach to the claim in the case study above", "anchor": "The__single_relatively_strong_argument__approach_to_the_claim_in_the_case_study_above", "level": 1}, {"title": "Major weaknesses of the \u201csingle relatively strong argument\u201d approach", "anchor": "Major_weaknesses_of_the__single_relatively_strong_argument__approach", "level": 1}, {"title": "A sample implication: a change in my attitude toward Penrose's beliefs about consciousness", "anchor": "A_sample_implication__a_change_in_my_attitude_toward_Penrose_s_beliefs_about_consciousness", "level": 1}, {"title": "End notes", "anchor": "End_notes", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "87 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 87, "af": false, "version": "1.1.0", "pingbacks": {"Posts": ["8462akth6EtRnpYAH", "ACGeaAk6KButv2xwQ", "M2LWXsJxKS626QNEA", "MtNnFg4uN32YPoKNa", "9kcTNWopvXFncXgPy", "WsmnfWTP28dXCKEy8", "rNuBzyWkigrf6BWg7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T14:29:27.435Z", "modifiedAt": null, "url": null, "title": "2013 June-August Life Hacks Thread ", "slug": "2013-june-august-life-hacks-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:25.312Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tnizp87tWPLoPXzcA/2013-june-august-life-hacks-thread", "pageUrlRelative": "/posts/tnizp87tWPLoPXzcA/2013-june-august-life-hacks-thread", "linkUrl": "https://www.lesswrong.com/posts/tnizp87tWPLoPXzcA/2013-june-august-life-hacks-thread", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%202013%20June-August%20Life%20Hacks%20Thread%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A2013%20June-August%20Life%20Hacks%20Thread%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftnizp87tWPLoPXzcA%2F2013-june-august-life-hacks-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=2013%20June-August%20Life%20Hacks%20Thread%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftnizp87tWPLoPXzcA%2F2013-june-august-life-hacks-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ftnizp87tWPLoPXzcA%2F2013-june-august-life-hacks-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 304, "htmlBody": "<p>Why don't we have Life Hack thread like we do have <a href=\"/lw/gjn/february_2013_media_thread/\">Media Threads</a> and <a href=\"/lw/g68/rationality_quotes_january_2013/\">Rationality Quote</a> Threads?</p>\n<p>Well, now we do.</p>\n<p>I'm copying in the comments some hacks previously written about by others for your convenience, also check out <a href=\"/lw/h9b/post_ridiculous_munchkin_ideas/\">the Munchkin post</a> if you haven't, there are many interesting hacks there. Timewise, I've made it <em>quarterly </em>because it is harder to face a life hack than it is to face o quote, so less frequency may improve average quality. Below is a suggested description for them with structure taken from media threads. Any further ideas on how to improve the thread are welcome and should be made at the Metathread tree.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">This is the quarterly thread for posting Life Hacks of various types that you've found that you enjoy. Four main thread-trees will be in the comment section. &nbsp;</span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">1) There is substantial evidence for it&nbsp; (please post pointers to it) <br /></span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">2) I tried/ Friends tried/ There is some small evidence for it<br /></span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">3) Seems like a cool idea</span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">4) Metathread<br /></span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Rules:</p>\n<ul style=\"padding: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees for level of certainty regarding effectiveness.&nbsp; There is a Metathread for comments about future threads.</li>\n<li><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\">Please post all Hacks separately, so that they can be voted up/down separately. &nbsp;(If they are strongly related, reply to your own comments. &nbsp;If strongly ordered, then go ahead and post them together.)</span></li>\n</ul>\n<p>&nbsp;</p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: 12px; line-height: 11px; text-align: justify;\"> </span></p>\n<hr />\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tnizp87tWPLoPXzcA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 1.2213704628731439e-06, "legacy": true, "legacyId": "22842", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3ehdgiPtXKffYsjh7", "DZQpoExSRwpmeFgjF", "3RJ3xFupXJKB8vE4q", "eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T15:15:26.992Z", "modifiedAt": null, "url": null, "title": "David Brooks from the NY Times writes on earning-to-give", "slug": "david-brooks-from-the-ny-times-writes-on-earning-to-give", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.436Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnthonyC", "createdAt": "2011-03-27T21:10:52.616Z", "isAdmin": false, "displayName": "AnthonyC"}, "userId": "E7Y53DiubddWFRLwE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jeoFsYYkpmWrHJwfs/david-brooks-from-the-ny-times-writes-on-earning-to-give", "pageUrlRelative": "/posts/jeoFsYYkpmWrHJwfs/david-brooks-from-the-ny-times-writes-on-earning-to-give", "linkUrl": "https://www.lesswrong.com/posts/jeoFsYYkpmWrHJwfs/david-brooks-from-the-ny-times-writes-on-earning-to-give", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20David%20Brooks%20from%20the%20NY%20Times%20writes%20on%20earning-to-give&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADavid%20Brooks%20from%20the%20NY%20Times%20writes%20on%20earning-to-give%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjeoFsYYkpmWrHJwfs%2Fdavid-brooks-from-the-ny-times-writes-on-earning-to-give%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=David%20Brooks%20from%20the%20NY%20Times%20writes%20on%20earning-to-give%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjeoFsYYkpmWrHJwfs%2Fdavid-brooks-from-the-ny-times-writes-on-earning-to-give", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjeoFsYYkpmWrHJwfs%2Fdavid-brooks-from-the-ny-times-writes-on-earning-to-give", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<p>Just wanted to highlight an article. David Brooks from the NY Times writes on earning-to-give by working at a hedge fund:</p>\n<p><a href=\"http://www.nytimes.com/2013/06/04/opinion/brooks-the-way-to-produce-a-person.html?ref=opinion\">http://www.nytimes.com/2013/06/04/opinion/brooks-the-way-to-produce-a-person.html?ref=opinion</a></p>\n<p>Basically, he claims that working in an amoral environment will eventually turn you into a worse person than you would otherwise be, and weaken your resolve and desire to fulfill your original goal. Psychologically he may be right, and today's me may not like the me I would become after a decade on Wall Street, but at first glance it seems like even if I could only maintain my resolve for a few years, the payoff far outweighs my own well being. He is also opposed to valuing the far - life in general - over the near - people in your own home or community. Or even valuing them equally, AFAICT.</p>\n<p>&nbsp;</p>\n<p>As a matter of history, though, I did not in fact choose such a career. Suboptimal or not, given what I did choose (consulting firm that helps companies invest and grow effectively in clean tech, nanotech, and biotech) I do not think I chose wrongly.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jeoFsYYkpmWrHJwfs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 14, "extendedScore": null, "score": 1.2214048787810696e-06, "legacy": true, "legacyId": "22843", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T15:20:46.927Z", "modifiedAt": null, "url": null, "title": "Why economics is not a morality tale", "slug": "why-economics-is-not-a-morality-tale", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:00.905Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vYiH2GaD9jCd7bgTx/why-economics-is-not-a-morality-tale", "pageUrlRelative": "/posts/vYiH2GaD9jCd7bgTx/why-economics-is-not-a-morality-tale", "linkUrl": "https://www.lesswrong.com/posts/vYiH2GaD9jCd7bgTx/why-economics-is-not-a-morality-tale", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20economics%20is%20not%20a%20morality%20tale&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20economics%20is%20not%20a%20morality%20tale%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvYiH2GaD9jCd7bgTx%2Fwhy-economics-is-not-a-morality-tale%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20economics%20is%20not%20a%20morality%20tale%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvYiH2GaD9jCd7bgTx%2Fwhy-economics-is-not-a-morality-tale", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvYiH2GaD9jCd7bgTx%2Fwhy-economics-is-not-a-morality-tale", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p><em>Example nicked from <a href=\"http://www.youtube.com/watch?v=h68BQjMJNNA\">this</a> online Berkeley lecture.</em></p>\n<p>&nbsp;</p>\n<p>Monopolies are <a href=\"http://en.wikipedia.org/wiki/Monopoly#Monopoly_and_efficiency\">bad</a>&nbsp;(morality and economics agree here).</p>\n<p>Firms that pollute are <a href=\"http://en.wikipedia.org/wiki/Externality#External_costs\">bad</a>&nbsp;(morality and economics agree here).</p>\n<p>What about monopolies that pollute?</p>\n<p>What about strong monopolies that pollute and receive government subsidies?</p>\n<p>&nbsp;</p>\n<p>Well...</p>\n<p>Pollution, and other negative externalities, cause firms to produce <strong>too much</strong> of their product. That's because they don't pay the full cost of the product, including the impact of pollution.</p>\n<p>The equilibrium behaviour for monopolies is to <a href=\"http://en.wikipedia.org/wiki/Monopoly#Monopoly_and_efficiency\">produce</a>&nbsp;<strong>too little</strong> of their product, to keep prices and profits high.</p>\n<p>So a monopoly that pollutes is subject to two opposite tendencies: the unpriced-pollution tendency to produce too much, and the monopolistic tendency to produce too little. If the effects are of comparable magnitude, then the monopoly might be much closer to social optimum than a free market would be (the social optimum, incidentally, will generally involve <em>some</em> pollution: we need to accept some pollution in the production of fertiliser, for instance, in order to have enough food to stop people starving).</p>\n<p>In fact, if the monopolistic effect is too strong, then the firm may under-produce, even taken the pollution effect into account. In that case, we can approach closer to the social optimum by... subsidising the polluting monopoly to produce more!!</p>\n<p>And that, my friends, is why economics is not a morality tale.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vYiH2GaD9jCd7bgTx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 11, "extendedScore": null, "score": 1.2214088689251762e-06, "legacy": true, "legacyId": "22844", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T16:13:50.225Z", "modifiedAt": null, "url": null, "title": "Other prespective on resolving the Prisoner's dilemma", "slug": "other-prespective-on-resolving-the-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:29.926Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pB9KZH7zvtQwjgJXa/other-prespective-on-resolving-the-prisoner-s-dilemma", "pageUrlRelative": "/posts/pB9KZH7zvtQwjgJXa/other-prespective-on-resolving-the-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/pB9KZH7zvtQwjgJXa/other-prespective-on-resolving-the-prisoner-s-dilemma", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Other%20prespective%20on%20resolving%20the%20Prisoner's%20dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOther%20prespective%20on%20resolving%20the%20Prisoner's%20dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpB9KZH7zvtQwjgJXa%2Fother-prespective-on-resolving-the-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Other%20prespective%20on%20resolving%20the%20Prisoner's%20dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpB9KZH7zvtQwjgJXa%2Fother-prespective-on-resolving-the-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpB9KZH7zvtQwjgJXa%2Fother-prespective-on-resolving-the-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 272, "htmlBody": "<p>Sometimes I see new ideas that, without offering any new information, offers a new perspective on old information, and a new way of thinking about an old problem. So it is with <a href=\"http://www.youtube.com/watch?v=ZFqmmzYVVJM\">this lecture</a> and the <a href=\"https://en.wikipedia.org/wiki/Prisoner's_dilemma\">prisoner's dilemma</a>.</p>\n<p>Now, I worked a lot with the prisoners dilemma, with superrationality, negotiations, fairness, retaliation, Rawlsian veils of ignorance, etc. I've studied the problem, and its possible resolutions, extensively. But the perspective of that lecture was refreshing and new to me:</p>\n<p style=\"padding-left: 30px;\"><em>The prisoner's dilemma is resolved only when the off-diagonal outcomes of the dilemma are known to be impossible.</em></p>\n<p><span style=\"line-height: 19px; text-align: justify;\">The \"off-diagonal outcomes\" are the \"(Defect, Cooperate)\" and the \"(Cooperate, Defect)\" squares where one person walks away with all the benefit and the other has none:</span></p>\n<table style=\"color: #000000; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<th>(Baron, Countess)<br /></th><th>Cooperate<br /></th><th>Defect<br /></th>\n</tr>\n<tr>\n<th>Cooperate<br /></th>\n<td style=\"font-size: 15px;\" align=\"center\">(3,3)</td>\n<td style=\"font-size: 15px;\" align=\"center\">(0,5)</td>\n</tr>\n<tr>\n<th>Defect<br /></th>\n<td style=\"font-size: 15px;\" align=\"center\">(5,0)</td>\n<td style=\"font-size: 15px;\" align=\"center\">(1,1)<br /></td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\">Facing an identical (or near identical) copy of yourself? Then the off-diagonal outcomes are impossible, because you're going to choose the same thing. Facing <a href=\"http://en.wikipedia.org/wiki/Tit_for_tat\">Tit-for-tat</a> in an <a href=\"http://en.wikipedia.org/wiki/Iterated_prisoner%27s_dilemma#The_iterated_prisoners.27_dilemma\">iterated prisoner's dilemma</a>? Well, the off-diagonal squares cannot be reached <em>consistently</em>. Is the other prisoner a Mafia don? Then the off-diagonal&nbsp;outcomes&nbsp;don't exist <em>as written</em>: there's a hidden negative term (you being horribly murdered) that isn't taken into account in that matrix. Various <a href=\"/lw/2ip/ai_cooperation_in_practice/\">agents with open code</a> are essentially publicly declaring the conditions under which they will not reach for the off-diagonal.&nbsp;</span><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\">The point of many contracts and agreements is to make the off-diagonal outcome impossible or expensive.</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\">As I said, nothing fundamentally new, but I find the perspective interesting. To my mind, it suggests that when resolving the prisoner's dilemma with probabilistic outcomes allowed, I should be thinking \"blocking off possible outcomes\", rather than \"reaching agreement\".</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pB9KZH7zvtQwjgJXa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 17, "extendedScore": null, "score": 1.2214485718977706e-06, "legacy": true, "legacyId": "22796", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TNfx89dh5KkcKrvho"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T16:21:17.574Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley: Board games", "slug": "meetup-berkeley-board-games-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/R6HcbtRFwcDPc87rh/meetup-berkeley-board-games-0", "pageUrlRelative": "/posts/R6HcbtRFwcDPc87rh/meetup-berkeley-board-games-0", "linkUrl": "https://www.lesswrong.com/posts/R6HcbtRFwcDPc87rh/meetup-berkeley-board-games-0", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%3A%20Board%20games&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%3A%20Board%20games%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6HcbtRFwcDPc87rh%2Fmeetup-berkeley-board-games-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%3A%20Board%20games%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6HcbtRFwcDPc87rh%2Fmeetup-berkeley-board-games-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FR6HcbtRFwcDPc87rh%2Fmeetup-berkeley-board-games-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ni'>Berkeley: Board games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 June 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, this week's Berkeley meetup will be a board games night. Zendo's games library includes:</p>\n\n<ul>\n<li>Dominion (two basic sets, Prosperity, Intrigue, Seaside)</li>\n<li>Scotland Yard</li>\n<li>Puerto Rico</li>\n<li>Thrun and Taxis</li>\n<li>Settlers of Catan (6 players)</li>\n<li>Ticket to Ride Europe</li>\n<li>Smallworld</li>\n<li>Robo Rally</li>\n<li>San Juan</li>\n<li>Zendo</li>\n<li>Two Go sets</li>\n<li>1 Chess set</li>\n<li>Poker</li>\n<li>Citadels</li>\n<li>Pandemic</li>\n<li>Race for the Galaxy</li>\n<li>Set</li>\n<li>Illuminati</li>\n<li>Carcasonne</li>\n</ul>\n\n<p>And many things besides. Feel free to bring your favorite game if we don't have it! The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ni'>Berkeley: Board games</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "R6HcbtRFwcDPc87rh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.2214541515197018e-06, "legacy": true, "legacyId": "22846", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Board_games\">Discussion article for the meetup : <a href=\"/meetups/ni\">Berkeley: Board games</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 June 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, this week's Berkeley meetup will be a board games night. Zendo's games library includes:</p>\n\n<ul>\n<li>Dominion (two basic sets, Prosperity, Intrigue, Seaside)</li>\n<li>Scotland Yard</li>\n<li>Puerto Rico</li>\n<li>Thrun and Taxis</li>\n<li>Settlers of Catan (6 players)</li>\n<li>Ticket to Ride Europe</li>\n<li>Smallworld</li>\n<li>Robo Rally</li>\n<li>San Juan</li>\n<li>Zendo</li>\n<li>Two Go sets</li>\n<li>1 Chess set</li>\n<li>Poker</li>\n<li>Citadels</li>\n<li>Pandemic</li>\n<li>Race for the Galaxy</li>\n<li>Set</li>\n<li>Illuminati</li>\n<li>Carcasonne</li>\n</ul>\n\n<p>And many things besides. Feel free to bring your favorite game if we don't have it! The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Board_games1\">Discussion article for the meetup : <a href=\"/meetups/ni\">Berkeley: Board games</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley: Board games", "anchor": "Discussion_article_for_the_meetup___Berkeley__Board_games", "level": 1}, {"title": "Discussion article for the meetup : Berkeley: Board games", "anchor": "Discussion_article_for_the_meetup___Berkeley__Board_games1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-04T17:31:24.675Z", "modifiedAt": "2020-05-05T19:16:40.724Z", "url": null, "title": "Applied art of rationality: Richard Feynman steelmanning his mother's concerns", "slug": "applied-art-of-rationality-richard-feynman-steelmanning-his", "viewCount": null, "lastCommentedAt": "2013-06-10T21:15:01.488Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/grszrDa6JZSZwyGLG/applied-art-of-rationality-richard-feynman-steelmanning-his", "pageUrlRelative": "/posts/grszrDa6JZSZwyGLG/applied-art-of-rationality-richard-feynman-steelmanning-his", "linkUrl": "https://www.lesswrong.com/posts/grszrDa6JZSZwyGLG/applied-art-of-rationality-richard-feynman-steelmanning-his", "postedAtFormatted": "Tuesday, June 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Applied%20art%20of%20rationality%3A%20Richard%20Feynman%20steelmanning%20his%20mother's%20concerns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApplied%20art%20of%20rationality%3A%20Richard%20Feynman%20steelmanning%20his%20mother's%20concerns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgrszrDa6JZSZwyGLG%2Fapplied-art-of-rationality-richard-feynman-steelmanning-his%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Applied%20art%20of%20rationality%3A%20Richard%20Feynman%20steelmanning%20his%20mother's%20concerns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgrszrDa6JZSZwyGLG%2Fapplied-art-of-rationality-richard-feynman-steelmanning-his", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgrszrDa6JZSZwyGLG%2Fapplied-art-of-rationality-richard-feynman-steelmanning-his", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1279, "htmlBody": "<p>First, imagine your parents disapproving of your first love. Imagine your mother inventing a whole whack of reasons why you shouldn't marry him/her. Now imagine being rational enough to acknowledge and address all her concerns while remaining a loving and caring son/daughter. If you can imagine, let alone do all that, you are better person than I am. But then I am not Feynman, who did just that in the following excerpt from the book&nbsp;<a href=\"http://www.amazon.com/Perfectly-Reasonable-Deviations-Beaten-Track/dp/0465023711\">Perfectly Reasonable Deviations from the Beaten Track</a>. It is also a great example of <a href=\"http://wiki.lesswrong.com/wiki/Luminosity\">Luminosity</a>. Now, if you think that you can be that good, look through your replies on LW to people whose comment irk you in the worst way. How charitable were you? Granted, you probably don't care about anonymous online posters nearly as much as Feynman cared about his mother, but I suspect that caring about someone makes you more emotional, not less in your reply.</p>\n<p>Comments by the book's author:</p>\n<p style=\"padding-left: 30px;\">The following letter is in response to one from Lucille, Richard&rsquo;s mother, in which she lovingly but forcefully outlined her concerns about Richard&rsquo;s intent to marry Arline. Arline&rsquo;s illness, she feared, would compromise not only his own health but his career. She was also concerned about the high cost of treatment (for oxygen, specialists, hospitalization, and so on).</p>\n<p style=\"padding-left: 30px;\">Lucille suggested that his desire to marry stemmed from his desire to please someone he loved (&ldquo;just as you used to occasionally eat spinach to please me&rdquo;) and recommended that they stay &ldquo;engaged.&rdquo;</p>\n<p>The letter itself:</p>\n<p style=\"padding-left: 30px;\">With regard to (1) and (2) I went to see Prof. Smyth at Pop&rsquo;s suggestion and the doctor here at the university.The doctor said I have less chance of getting T.B. in the sanatorium when visiting her than when I am walking around in the street. I think he was exaggerating (all this is in detail in a letter to Pop, so I won&rsquo;t repeat it all here). He said T.B. is infectious but not contagious&mdash;I didn&rsquo;t understand the distinction he made, however. Ask Dr. Sarrow. He said in sanatoriums the patients take care of their sputum by cups or Kleenex for the purpose, but on the streets people are careless and just spit all around and when it dries the germs float into the air. He said the germs are not floating around in the air in a sanatorium. He said a lot has been found out about this in the last 25, and in particular the last 10, years. I would be no danger to my students. Prof. Smyth didn&rsquo;t see any objection from his point of view to hiring me if my wife is sick.</p>\n<p style=\"padding-left: 30px;\">(3) If no one can make a budget for illness, how can I ever make enough to pay for it? How much is enough? Some guesses must be made and I guess I have enough. How much would you guess would be necessary?</p>\n<p style=\"padding-left: 30px;\">(4) I wouldn&rsquo;t be satisfied being engaged any longer. I want the burden and responsibility of being married.</p>\n<p style=\"padding-left: 30px;\">(5) It really wasn&rsquo;t hard at all.While I was out to lunch while waiting for somebody to come back to the courthouse in Trenton, I found myself singing&mdash;and I realized then that I really was very happy arranging things. It was, I suppose, the pleasure of arranging things for our life together&mdash;before she was sick we used to talk of the fun it would be going around ringing doorbells looking for a place to live&mdash;I guess it was similar to that idea.</p>\n<p style=\"padding-left: 30px;\">I am not afraid of her parents&mdash;and if they don&rsquo;t trust me with their daughter let them say so now. If they get sore at my mistakes later, it&rsquo;s too late and it won&rsquo;t bother me.You are right about my lack (4) of experience&mdash;I have no answer to that.</p>\n<p style=\"padding-left: 30px;\">(6) The cost here again is a guess. I want to take the chance, however, that it will be sufficient. If it isn&rsquo;t I&rsquo;ll be in difficulty as you suggest.</p>\n<p style=\"padding-left: 30px;\">(7) I&rsquo;ve already been employed at Princeton for the next year. If I must go elsewhere, I&rsquo;ll go where I&rsquo;m needed most.</p>\n<p style=\"padding-left: 30px;\">(8) I do want to get married. I also want to give someone I love what she wants&mdash;especially because at the same time I will be doing something I want. It is not at all like eating spinach&mdash;(also you misunderstood my motives as a small boy&mdash;I didn&rsquo;t want you angry at me)&mdash;I didn&rsquo;t like spinach.</p>\n<p style=\"padding-left: 30px;\">(9) This is the problem we are discussing&mdash;I mean whether marriage is worse than engagement.</p>\n<p style=\"padding-left: 30px;\">(10) I&rsquo;m honestly sorry it makes you feel so bad. I bet it won&rsquo;t be too heavy.</p>\n<p style=\"padding-left: 30px;\">Why I want go get married;</p>\n<p style=\"padding-left: 30px;\">It is not that I want to be noble. It is not that I think it&rsquo;s the only right, honest and decent thing to do, under the circumstances. It is not that I made a promise five years ago&mdash;(under entirely different circumstances)&mdash;and that I don&rsquo;t want to &ldquo;back out&rdquo; of the promise. That stuff is baloney. If anytime during the five years I thought I&rsquo;d rather not go thru with it&mdash;promise or no promise I&rsquo;d &ldquo;back out&rdquo; so fast it would make your head spin. I&rsquo;m not dopey enough to tie up my whole life in the future because of some promise I made in the past&mdash;under different circumstances.</p>\n<p style=\"padding-left: 30px;\">This decision to marry is a decision now and not one made five years ago.</p>\n<p style=\"padding-left: 30px;\">I want to marry Arline because I love her&mdash;which means I want to take care of her.That is all there is to it. I want to take care of her.</p>\n<p style=\"padding-left: 30px;\">I am anxious for the responsibilities and uncertainties of taking care of the girl I love.</p>\n<p style=\"padding-left: 30px;\">I have, however, other desires and aims in the world. One of them is to contribute as much as to physics as I can.This is, in my mind, of even more importance than my love for Arline.</p>\n<p style=\"padding-left: 30px;\">It is therefore especially fortunate that, as I can see (guess) my getting married will interfere very slightly, if at all with my main job in life. I am quite sure I can do both at once. (There is even the possibility that the consequent happiness of being married&mdash;and the constant encouragement and sympathy of my wife will aid in my endeavor&mdash;but actually in the past my love hasn&rsquo;t affected my physics much, and I don&rsquo;t really suppose it will be too great an assistance in the future.</p>\n<p style=\"padding-left: 30px;\">Since I feel I can carry on my main job, and still enjoy the luxury of taking care of someone I love&mdash;I intend to be married shortly.</p>\n<p style=\"padding-left: 30px;\">Does that explain anything?</p>\n<p style=\"padding-left: 30px;\">Your Son.</p>\n<p style=\"padding-left: 30px;\">R.P.F. PH.D.</p>\n<p style=\"padding-left: 30px;\">&nbsp;</p>\n<p style=\"padding-left: 30px;\">P.S. I should have pointed out that I know I am taking chances getting married and may get into all kinds of pickles. I think the chances of major disasters are sufficiently small, and the gain to me and Putzie great enough, that the risk is well worth taking. Of course, this is just the point we are discussing&mdash;the magnitude of the risk&mdash;so I am saying nothing but simply asserting I think it is small. You think it is large, and therefore I was particularly anxious to have you tell me where you thought the pitfalls were&mdash;and you have pointed out a few new ones to me. I still feel the risk is worth taking&mdash;and the fact that we differ is due to our difference in background, experience and viewpoint. Please don&rsquo;t worry that, by explaining your viewpoint, you have in any way pushed us further apart&mdash;you haven&rsquo;t. I only hope that my marrying directly in the face of your disapproval and your better judgment won&rsquo;t alienate you from me&mdash;because honestly, our judgments differ and I think you&rsquo;re wrong. I honestly believe we (Putzie and I) will be better off married and nobody will be hurt by it.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "grszrDa6JZSZwyGLG", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 13, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "22847", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2013-06-04T17:31:24.675Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-05T00:35:23.107Z", "modifiedAt": null, "url": null, "title": "Meetup : Zendo and discussion", "slug": "meetup-zendo-and-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:58.256Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "evand", "createdAt": "2012-05-14T16:45:50.150Z", "isAdmin": false, "displayName": "evand"}, "userId": "QSBopDfW3DLzeMG7L", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P3KzKfzDd3WzDW9FM/meetup-zendo-and-discussion", "pageUrlRelative": "/posts/P3KzKfzDd3WzDW9FM/meetup-zendo-and-discussion", "linkUrl": "https://www.lesswrong.com/posts/P3KzKfzDd3WzDW9FM/meetup-zendo-and-discussion", "postedAtFormatted": "Wednesday, June 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Zendo%20and%20discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Zendo%20and%20discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP3KzKfzDd3WzDW9FM%2Fmeetup-zendo-and-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Zendo%20and%20discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP3KzKfzDd3WzDW9FM%2Fmeetup-zendo-and-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP3KzKfzDd3WzDW9FM%2Fmeetup-zendo-and-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nj'>Zendo and discussion</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">06 June 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Cocoa Cinnamon, 420 W Geer St, Durham, NC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will talk about assorted things of interest over Zendo!</p>\n\n<p>If you have not played the game before, it is a fun game of inductive logic. It is good for critical thinking, demonstrating some common cognitive biases, and is generally good for prompting rationality related discussion.</p>\n\n<p>It's also very friendly to newcomers.</p>\n\n<p>Suggested things to think about before coming:</p>\n\n<p>What is your favorite recent LW article, and why?\nWhat changes have you made in your life recently, and what role did rationality play in them?\nWhat would you like to see more of in future meetups, and why?</p>\n\n<p>Meetup runs until 9, but there will probably be people having beers at Fullsteam after.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nj'>Zendo and discussion</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P3KzKfzDd3WzDW9FM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 3, "extendedScore": null, "score": 1.221824011624592e-06, "legacy": true, "legacyId": "22848", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Zendo_and_discussion\">Discussion article for the meetup : <a href=\"/meetups/nj\">Zendo and discussion</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">06 June 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Cocoa Cinnamon, 420 W Geer St, Durham, NC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We will talk about assorted things of interest over Zendo!</p>\n\n<p>If you have not played the game before, it is a fun game of inductive logic. It is good for critical thinking, demonstrating some common cognitive biases, and is generally good for prompting rationality related discussion.</p>\n\n<p>It's also very friendly to newcomers.</p>\n\n<p>Suggested things to think about before coming:</p>\n\n<p>What is your favorite recent LW article, and why?\nWhat changes have you made in your life recently, and what role did rationality play in them?\nWhat would you like to see more of in future meetups, and why?</p>\n\n<p>Meetup runs until 9, but there will probably be people having beers at Fullsteam after.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Zendo_and_discussion1\">Discussion article for the meetup : <a href=\"/meetups/nj\">Zendo and discussion</a></h2>", "sections": [{"title": "Discussion article for the meetup : Zendo and discussion", "anchor": "Discussion_article_for_the_meetup___Zendo_and_discussion", "level": 1}, {"title": "Discussion article for the meetup : Zendo and discussion", "anchor": "Discussion_article_for_the_meetup___Zendo_and_discussion1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T05:38:17.885Z", "modifiedAt": null, "url": null, "title": "A Viable Alternative to Typing", "slug": "a-viable-alternative-to-typing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.782Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LNGsDoFmyBkTMHFoX/a-viable-alternative-to-typing", "pageUrlRelative": "/posts/LNGsDoFmyBkTMHFoX/a-viable-alternative-to-typing", "linkUrl": "https://www.lesswrong.com/posts/LNGsDoFmyBkTMHFoX/a-viable-alternative-to-typing", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Viable%20Alternative%20to%20Typing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Viable%20Alternative%20to%20Typing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLNGsDoFmyBkTMHFoX%2Fa-viable-alternative-to-typing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Viable%20Alternative%20to%20Typing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLNGsDoFmyBkTMHFoX%2Fa-viable-alternative-to-typing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLNGsDoFmyBkTMHFoX%2Fa-viable-alternative-to-typing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 218, "htmlBody": "<p class=\"MsoNormal\"><span lang=\"EN-US\">I'm thinking about writing a more substantive post about how humans work and how we can work better, a little like <a href=\"/lw/5r6/spend_money_on_ergonomics/\">this</a> one.&nbsp; As is common with these sorts of things, once I started to do research and pull on various threads, it turned out that the field was pretty deep and would require time to understand.&nbsp; But in the meantime, I just thought I would link to <a href=\"https://www.youtube.com/watch?v=8SkdfdXWYaI\">this</a> video of someone programming using only their voice.&nbsp; </span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-US\">As I suffer with symptoms of carpal tunnel syndrome, this is of particular interest to me.&nbsp; Once I watched it I decided to start looking at different voice recognition software so that I could still get some work done while typing less.&nbsp; I'm happy to say that even the default software for speech recognition which came with windows is actually very able and accurate.&nbsp; I dictated almost this entire post using that software.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-US\">As far as I can tell, <a href=\"http://www.nuance.com/dragon/index.htm\">Dragon Naturally Speaking</a> is the gold standard in voice recognition software.&nbsp; It does come with a pretty hefty price tag, but it may be worth it if you have serious repetitive stress injuries, or as a preventative measure if you're someone who spends a lot of time at their computer. &nbsp;And if that doesn't work, chances are good your computer has adequate software pre-installed. &nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LNGsDoFmyBkTMHFoX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 1, "extendedScore": null, "score": 1.223130278705533e-06, "legacy": true, "legacyId": "22864", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Gy8fy7rTgTocNLKfT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T08:38:52.536Z", "modifiedAt": null, "url": null, "title": "[link] The Economics of Social Status", "slug": "link-the-economics-of-social-status", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.019Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kaj_Sotala", "createdAt": "2009-02-27T19:11:58.811Z", "isAdmin": false, "displayName": "Kaj_Sotala"}, "userId": "qxJ28GN72aiJu96iF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jXoiEkNKpBMP82RRA/link-the-economics-of-social-status", "pageUrlRelative": "/posts/jXoiEkNKpBMP82RRA/link-the-economics-of-social-status", "linkUrl": "https://www.lesswrong.com/posts/jXoiEkNKpBMP82RRA/link-the-economics-of-social-status", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20The%20Economics%20of%20Social%20Status&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20The%20Economics%20of%20Social%20Status%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjXoiEkNKpBMP82RRA%2Flink-the-economics-of-social-status%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20The%20Economics%20of%20Social%20Status%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjXoiEkNKpBMP82RRA%2Flink-the-economics-of-social-status", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjXoiEkNKpBMP82RRA%2Flink-the-economics-of-social-status", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 635, "htmlBody": "<p><a href=\"http://www.meltingasphalt.com/the-economics-of-social-status/\">http://www.meltingasphalt.com/the-economics-of-social-status/</a></p>\n<p>Discusses a number of aspects of social status, including the \"social status as currency\" concept that Morendil and I <a href=\"/lw/2g6/the_red_paperclip_theory_of_status/\">previously wrote about</a>.</p>\n<blockquote>\n<p>Now we get to the really interesting stuff: the&nbsp;<em>economic properties</em>&nbsp;of social status.</p>\n<p>Let&rsquo;s start with transactions, since they form the basis of an  economy.&nbsp;Status is part of our system for competing over scarce  resources, so it should be no surprise that it participates in so many  of our daily transactions. Some examples:</p>\n<ul>\n<li>We trade status for favors (and vice versa). This is so common you  might not even realize it, but even the simple act of saying &ldquo;please&rdquo;  and &ldquo;thank you&rdquo; accords a nominal amount of status to the person doing  the favor. The fact that status is at stake in these transactions  becomes clear when the pleasantries are withheld, which we often  interpret as an insult (i.e., a threat to our status).</li>\n<li>An apology is a ritual lowering of one&rsquo;s status to compensate for a  (real or perceived) affront. As with gratitude, withholding an apology  is perceived as an insult.</li>\n<li>We trade status for information (and vice versa). This is one component of &ldquo;powertalk,&rdquo; as illustrated in the&nbsp;<a href=\"http://www.ribbonfarm.com/2009/11/11/the-gervais-principle-ii-posturetalk-powertalk-babytalk-and-gametalk/\">Gervais Principle series</a>.</li>\n<li>We trade status for sex (and vice versa), which often goes by the  name &ldquo;seduction.&rdquo;&nbsp;Sometimes even the institution of marriage functions  as a sex-for-status transaction. Dowries illustrate this principle by  working against it &mdash; they reinforce class/caste systems by making it  harder for high-status men to marry low-status women.</li>\n<li>We reward employees in the form of institutionalized status (titles,  promotions, parking spots),&nbsp;which trade off against salary as a form of  compensation.</li>\n<li>We can turn money into status by means of conspicuous consumption,  or status into money by means of endorsement (i.e., being paid to lend  status to an endeavor).</li>\n</ul>\n</blockquote>\n<p>But the part that I found the most interesting was the idea of defining communities via their status standards:</p>\n<blockquote>\n<p>Previously we defined status with respect to a community, but we could also flip it around:</p>\n<blockquote>\n<p>A community is&nbsp;a group of people who agree on how to measure status among their members.</p>\n</blockquote>\n<p>In other words, it&rsquo;s a group of people who&nbsp;<em>share a common status currency</em>.&nbsp;Silicon  Valley, for example, is a community oriented around a particular way of  measuring status &mdash; the ability to influence the growth of engineering  companies. But Silicon-Valley status won&rsquo;t buy you anything in Hollywood  &mdash; unless you convert it to something that makes sense in the Hollywood  economy. (Financial wealth usually does the trick).</p>\n<p>This definition allows us not only to draw boundaries between  communities (porous and fuzzy though they may be), but also allows us to  discuss the&nbsp;<em>strength</em>&nbsp;of a community, i.e., the&nbsp;<em>level of agreement</em>&nbsp;about  how to measure status.&nbsp;Google, for example, is a fairly strong  community insofar as Googlers agree on how to measure status among  themselves, but&nbsp;<em>Google engineering</em>&nbsp;might be an even stronger community.</p>\n<p>Treating communities as &ldquo;status-currency blocs&rdquo; helps explain how  there&rsquo;s relatively&nbsp;free trade (at low transaction costs) within the  community &mdash; and also how trade is distorted across community boundaries.  The fluctuating &lsquo;exchange rates&rsquo; and asymmetric information make  cross-community interaction more difficult. When a Google VP walks into a  meeting with some employees from Facebook, say, everyone will be unsure  about their relative statuses, and the group will have to spend time  and effort (and a lot of posturing) in order to figure it out.</p>\n<p>The &ldquo;currency bloc&rdquo; metaphor also helps explain both the benefits and  the costs of institutional re-orgs. Merging two organizations, for  example, can increase economic efficiency (by standardizing on a single  status currency and thereby facilitating more interaction/trade), but  the integration will also require some &lsquo;repricing&rsquo; &mdash; with resistance  from everyone who loses out.</p>\n</blockquote>\n<p>The article has a lot more.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2EFq8dJbxKNzforjM": 8}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jXoiEkNKpBMP82RRA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 37, "extendedScore": null, "score": 8.2e-05, "legacy": true, "legacyId": "22869", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 27, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7ZkHyrBFaDwZ3XgLi"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T12:50:11.711Z", "modifiedAt": null, "url": null, "title": "Mahatma Armstrong: CEVed to death.", "slug": "mahatma-armstrong-ceved-to-death", "viewCount": null, "lastCommentedAt": "2020-05-11T11:58:44.677Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vgFvnr7FefZ3s3tHp/mahatma-armstrong-ceved-to-death", "pageUrlRelative": "/posts/vgFvnr7FefZ3s3tHp/mahatma-armstrong-ceved-to-death", "linkUrl": "https://www.lesswrong.com/posts/vgFvnr7FefZ3s3tHp/mahatma-armstrong-ceved-to-death", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mahatma%20Armstrong%3A%20CEVed%20to%20death.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMahatma%20Armstrong%3A%20CEVed%20to%20death.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgFvnr7FefZ3s3tHp%2Fmahatma-armstrong-ceved-to-death%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mahatma%20Armstrong%3A%20CEVed%20to%20death.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgFvnr7FefZ3s3tHp%2Fmahatma-armstrong-ceved-to-death", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvgFvnr7FefZ3s3tHp%2Fmahatma-armstrong-ceved-to-death", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 558, "htmlBody": "<p>My main objection to <a href=\"http://intelligence.org/files/CEV.pdf\">Coherent Extrapolated Volition</a> (CEV) is the \"Extrapolated\" part. I don't see any reason to trust the extrapolated volition of humanity - but this isn't just for self centred reasons. I don't see any reason to trust my own extrapolated volition. I think it's perfectly possible that my extrapolated volition would follow some scenario like this:</p>\n<ol>\n<li>It starts with me, Armstrong 1. &nbsp;I want to be more altruistic at the next level, valuing other humans more.</li>\n<li>The altruistic Armstrong 2 wants to be even more altruistic. He makes himself into a perfectly altruistic utilitarian towards humans, and increases his altruism towards animals.</li>\n<li>Armstrong 3 wonders about the difference between animals and humans, and why he should value one of them more. He decided to increase his altruism equally towards all sentient creatures.</li>\n<li>Armstrong 4 is worried about the fact that sentience isn't clearly defined, and seems arbitrary anyway. He increase his altruism towards all living things.</li>\n<li>Armstrong 5's problem is that the barrier between living and non-living things isn't clear either (e.g. viruses). He decides that he should solve this by valuing all worthwhile things - is not art and beauty worth something as well?</li>\n<li>But what makes a thing worthwhile? Is there not art in everything, beauty in the eye of the right beholder? Armstrong 6 will make himself value everything.</li>\n<li>Armstrong 7 is in turmoil: so many animals prey upon other animals, or destroy valuable rocks! To avoid this, he decides the most moral thing he can do is to try and destroy all life, and then create a world of stasis for the objects that remain.</li>\n</ol>\n<p>There are many other ways this could go, maybe ending up as a negative utilitarian or completely indifferent, but that's enough to give the flavour. You might trust the person you want to be, to do the right things. But you can't trust them to want to be the right person - especially several levels in (compare with the argument in&nbsp;<a href=\"/lw/ase/schelling_fences_on_slippery_slopes/\">this post</a>, and my very old <a href=\"http://www.neweuropeancentury.org/GodAI.pdf&lrm;\">chaining god</a> idea). I'm not claiming that such a value drift is inevitable, just that it's possible - and so I'd want my initial values to dominate when there is a large conflict.</p>\n<p>Nor do I give Armstrong 7's values any credit for having originated from mine. Under torture, I'm pretty sure I could be made to accept any system of values whatsoever; there are other ways that would provably alter my values, so I don't see any reason to privilege Armstrong 7's values in this way.</p>\n<p>\"But,\" says the objecting <a href=\"http://www.queen-of-theme-party-games.com/images/scarecrow-wizard-of-oz.jpg\">strawman</a>, \"this is completely different! Armstrong 7's values are the ones that you would reach by following the path you would want to follow anyway! That's where you would get to, if you started out wanting to be more altruistic, had control over you own motivational structure, and grew and learnt and knew more!\"</p>\n<p>\"Thanks for pointing that out,\" I respond, \"now that I know where that ends up, I must make sure to change the path I would want to follow! I'm not sure whether I shouldn't be more altruistic, or avoid touching my motivational structure, or not want to grow or learn or know more. Those all sound pretty good, but if they end up at Armstrong 7, <a href=\"http://www.overcomingbias.com/2008/01/knowing-your-ar.html\">something's going to have to give</a>.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NLwTnsH9RSotqXYLw": 1, "W6QZYSNt5FgWgvbdT": 1, "qQMEMrXioExa4uhTB": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vgFvnr7FefZ3s3tHp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 43, "baseScore": 32, "extendedScore": null, "score": 8.6e-05, "legacy": true, "legacyId": "22841", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 62, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Kbm6QnJv9dgWsPHQP"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T14:05:01.730Z", "modifiedAt": null, "url": null, "title": "Ideas wanted: democracy in an Em world", "slug": "ideas-wanted-democracy-in-an-em-world", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:04.911Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8ddgsXmcqw3PLABvm/ideas-wanted-democracy-in-an-em-world", "pageUrlRelative": "/posts/8ddgsXmcqw3PLABvm/ideas-wanted-democracy-in-an-em-world", "linkUrl": "https://www.lesswrong.com/posts/8ddgsXmcqw3PLABvm/ideas-wanted-democracy-in-an-em-world", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ideas%20wanted%3A%20democracy%20in%20an%20Em%20world&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIdeas%20wanted%3A%20democracy%20in%20an%20Em%20world%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ddgsXmcqw3PLABvm%2Fideas-wanted-democracy-in-an-em-world%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ideas%20wanted%3A%20democracy%20in%20an%20Em%20world%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ddgsXmcqw3PLABvm%2Fideas-wanted-democracy-in-an-em-world", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8ddgsXmcqw3PLABvm%2Fideas-wanted-democracy-in-an-em-world", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 318, "htmlBody": "<p>One person, one vote - a fundamental principle of our democratic government. But what happens in a world where one person can be copied, again and again?</p>\n<p>That is the world described by Robin Hanson's \"<a href=\"http://www.youtube.com/watch?v=s2GIirg43sU\">Em economics</a>\". Ems, or uploads, are human minds instantiated inside software, and hence can be copied as needed. But what is the fate of democratic government in such a world of copies? Can it be preserved? Should it be preserved? How much of it should be preserved? Those are the questions we'll be analysing at the FHI, but we first wanted to turn to Less Wrong to see the ideas and comments you might have on this. Original thoughts especially welcome!</p>\n<p>To start the conversation, here are some of the features of idealised democracy (the list isn't meant to be exhaustive or restrictive, or necessarily true about real world democracies). Which of these could exist in an Em world, and which should?</p>\n<ul>\n<li>Democracy grants legitimacy to the government.</li>\n<li>Democracy is fair and egalitarian - each person has a single vote.</li>\n<li>Democracy aligns the interests of the rulers with that of the ruled.</li>\n<li>Democracy is stable - powerful groups can generally seize power within the structure, rather than overthrowing it.</li>\n<li>Democracy allows the competition of governing ideas.</li>\n<li>Democracy often leads to market economies, which generate large wealth.</li>\n<li>Democracy often lead to welfare states, which increase happiness.</li>\n<li>Democracy doesn't need to use certain coercive methods, such as restrictions on free speech, that other systems require to remain stable.</li>\n<li>Democracy stops a particular group from hanging on to power indefinitely, which <em>can</em> reduce corruption, inefficiency and excessive use of state power for private purposes.</li>\n</ul>\n<p><strong>EDIT</strong>: For clarification purposes, I am not claiming that democracies achieve these goals, or that these are all desirable. They are just ideas to start thinking about.</p>\n<ul>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8ddgsXmcqw3PLABvm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 3, "extendedScore": null, "score": 1.2235105235571916e-06, "legacy": true, "legacyId": "22870", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 64, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T16:47:07.377Z", "modifiedAt": null, "url": null, "title": "Meetup : Second Bristol meetup & mailing list for future meetups", "slug": "meetup-second-bristol-meetup-and-mailing-list-for-future", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:00.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Benja", "createdAt": "2009-02-27T04:37:47.476Z", "isAdmin": false, "displayName": "Benya"}, "userId": "3vZZP8TBXvozbe5Cv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KkdNGptaYwRMfebBG/meetup-second-bristol-meetup-and-mailing-list-for-future", "pageUrlRelative": "/posts/KkdNGptaYwRMfebBG/meetup-second-bristol-meetup-and-mailing-list-for-future", "linkUrl": "https://www.lesswrong.com/posts/KkdNGptaYwRMfebBG/meetup-second-bristol-meetup-and-mailing-list-for-future", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Second%20Bristol%20meetup%20%26%20mailing%20list%20for%20future%20meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Second%20Bristol%20meetup%20%26%20mailing%20list%20for%20future%20meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKkdNGptaYwRMfebBG%2Fmeetup-second-bristol-meetup-and-mailing-list-for-future%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Second%20Bristol%20meetup%20%26%20mailing%20list%20for%20future%20meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKkdNGptaYwRMfebBG%2Fmeetup-second-bristol-meetup-and-mailing-list-for-future", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKkdNGptaYwRMfebBG%2Fmeetup-second-bristol-meetup-and-mailing-list-for-future", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 247, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nk'>Second Bristol meetup &amp; mailing list for future meetups</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 June 2013 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Hodgkin House, 3 Meridian Place, Bristol BS8 1JG</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>At our lovely <a href=\"http://lesswrong.com/meetups/mx\">first meetup</a> (four people came, if I count myself), I unfortunately forgot to take the opportunity to sort out when a good time for the next meetup would be. Sorry!</p>\n\n<p>Since I'm about to be away for a while and I think others are leaving for the summer as well, I decided to just be bold once more and announce a time and hope that somebody else is free as well. But to make it easier to find good times in the future, <strong>please <a href=\"https://groups.google.com/forum/?fromgroups#!forum/lesswrong-bristol\">join the Google Group I&#39;ve just created</a>!</strong></p>\n\n<p>Last time, we ended up sitting in the cafe for hours without consuming much, so for this meetup I've booked the dining room at <a href=\"http://goo.gl/maps/f11Uv\" rel=\"nofollow\">the student house where I live</a>, which should be a quiet and comfortable place to talk. I'll also put up a LessWrong sign outside saying this, but please ring the buzzer marked \"Basement\", or you can call me at +43-660-1461996 (unfortunately I don't have a UK mobile yet, but if you ring just once, I'll come up and meet you).</p>\n\n<p>Time &amp; date is <strong>Sunday</strong>, the <strong>16th</strong> of June, starting at 3pm. Hope that I didn't pick a terrible time and someone will be able to join me! :-)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nk'>Second Bristol meetup &amp; mailing list for future meetups</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KkdNGptaYwRMfebBG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.2236322012649744e-06, "legacy": true, "legacyId": "22872", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Second_Bristol_meetup___mailing_list_for_future_meetups\">Discussion article for the meetup : <a href=\"/meetups/nk\">Second Bristol meetup &amp; mailing list for future meetups</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 June 2013 03:00:00PM (+0100)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Hodgkin House, 3 Meridian Place, Bristol BS8 1JG</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>At our lovely <a href=\"http://lesswrong.com/meetups/mx\">first meetup</a> (four people came, if I count myself), I unfortunately forgot to take the opportunity to sort out when a good time for the next meetup would be. Sorry!</p>\n\n<p>Since I'm about to be away for a while and I think others are leaving for the summer as well, I decided to just be bold once more and announce a time and hope that somebody else is free as well. But to make it easier to find good times in the future, <strong>please <a href=\"https://groups.google.com/forum/?fromgroups#!forum/lesswrong-bristol\">join the Google Group I've just created</a>!</strong></p>\n\n<p>Last time, we ended up sitting in the cafe for hours without consuming much, so for this meetup I've booked the dining room at <a href=\"http://goo.gl/maps/f11Uv\" rel=\"nofollow\">the student house where I live</a>, which should be a quiet and comfortable place to talk. I'll also put up a LessWrong sign outside saying this, but please ring the buzzer marked \"Basement\", or you can call me at +43-660-1461996 (unfortunately I don't have a UK mobile yet, but if you ring just once, I'll come up and meet you).</p>\n\n<p>Time &amp; date is <strong>Sunday</strong>, the <strong>16th</strong> of June, starting at 3pm. Hope that I didn't pick a terrible time and someone will be able to join me! :-)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Second_Bristol_meetup___mailing_list_for_future_meetups1\">Discussion article for the meetup : <a href=\"/meetups/nk\">Second Bristol meetup &amp; mailing list for future meetups</a></h2>", "sections": [{"title": "Discussion article for the meetup : Second Bristol meetup & mailing list for future meetups", "anchor": "Discussion_article_for_the_meetup___Second_Bristol_meetup___mailing_list_for_future_meetups", "level": 1}, {"title": "Discussion article for the meetup : Second Bristol meetup & mailing list for future meetups", "anchor": "Discussion_article_for_the_meetup___Second_Bristol_meetup___mailing_list_for_future_meetups1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T16:47:42.749Z", "modifiedAt": null, "url": null, "title": "CFAR workshop, June 15th, Salt Lake City UT", "slug": "cfar-workshop-june-15th-salt-lake-city-ut", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.164Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Julia_Galef", "createdAt": "2009-12-20T01:44:38.850Z", "isAdmin": false, "displayName": "Julia_Galef"}, "userId": "qkDSxJnyKhPCJyKdD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rKX5f6EWcENhiuttG/cfar-workshop-june-15th-salt-lake-city-ut", "pageUrlRelative": "/posts/rKX5f6EWcENhiuttG/cfar-workshop-june-15th-salt-lake-city-ut", "linkUrl": "https://www.lesswrong.com/posts/rKX5f6EWcENhiuttG/cfar-workshop-june-15th-salt-lake-city-ut", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20CFAR%20workshop%2C%20June%2015th%2C%20Salt%20Lake%20City%20UT&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACFAR%20workshop%2C%20June%2015th%2C%20Salt%20Lake%20City%20UT%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKX5f6EWcENhiuttG%2Fcfar-workshop-june-15th-salt-lake-city-ut%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=CFAR%20workshop%2C%20June%2015th%2C%20Salt%20Lake%20City%20UT%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKX5f6EWcENhiuttG%2Fcfar-workshop-june-15th-salt-lake-city-ut", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrKX5f6EWcENhiuttG%2Fcfar-workshop-june-15th-salt-lake-city-ut", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 385, "htmlBody": "<p style=\"color: #222222; font-size: 13px;\">CFAR is experimenting with a mobile workshop, so we can bring our material to people who can't make it to Berkeley. &nbsp;So, next week, we're running a one-and-a-half day workshop in Salt Lake City, Utah!</p>\n<p style=\"color: #222222; font-size: 13px;\">&nbsp;</p>\n<p style=\"color: #222222; font-size: 13px;\"><strong>Workshop Details</strong></p>\n<p style=\"color: #222222; font-size: 13px;\">On&nbsp;<span class=\"aBn\" style=\"border-bottom-width: 1px; border-bottom-style: dashed; border-bottom-color: #cccccc; position: relative; top: -2px; z-index: 0;\"><span class=\"aQJ\" style=\"position: relative; top: 2px; z-index: -1;\">Saturday June 15th</span></span>, CFAR will be running a workshop in the Salt Lake City area. We&rsquo;ll be presenting selected material from&nbsp;<a style=\"color: #1155cc;\" href=\"http://rationality.org/workshops/\" target=\"_blank\">our four-day workshop</a>&nbsp;and giving you the chance to consult with our instructors on how you can put these skills to work.</p>\n<p style=\"color: #222222; font-size: 13px;\">You&rsquo;ll arrive for class at&nbsp;<span class=\"aBn\" style=\"border-bottom-width: 1px; border-bottom-style: dashed; border-bottom-color: #cccccc; position: relative; top: -2px; z-index: 0;\"><span class=\"aQJ\" style=\"position: relative; top: 2px; z-index: -1;\">10am on Saturday</span></span>, and you and eleven other participants will spend the day learning highlights from our applied rationality curriculum: how to recognize and defuse a fight-or-flight response when it doesn't do you any good (you can&rsquo;t outrun data you don&rsquo;t like!), how to make sure your desire to complete a long-term project (say, writing a book) trickles down to motivate all the picayune steps along the way (doing a read-through to pick off unnecessary adjectives), and how to make the most of your intuitive judgments. Classes wrap up at&nbsp;<span class=\"aBn\" style=\"border-bottom-width: 1px; border-bottom-style: dashed; border-bottom-color: #cccccc; position: relative; top: -2px; z-index: 0;\"><span class=\"aQJ\" style=\"position: relative; top: 2px; z-index: -1;\">7pm</span></span>, and then we&rsquo;ll all go out for dinner, where you&rsquo;ll have a chance to decompress and digest the day (along with your meal).</p>\n<p style=\"color: #222222; font-size: 13px;\">After dinner, if you&rsquo;ve registered for the optional half-day, you&rsquo;ll sleep over on site with the CFAR staff and play some fun, brain-teasing games. The evening is a time for unstructured conversation and collaboration. What are your pet projects and ambitions? Get feedback from classmates and instructors and start figuring out ways to make the most of your newfound skills.</p>\n<p style=\"color: #222222; font-size: 13px;\">The next morning, you&rsquo;ll choose which of the previous day&rsquo;s skills you really want to practice intensively. Catch any misunderstandings or sticking points while you&rsquo;re still around to troubleshoot them with a CFAR instructor. At our four-day workshops, many participants report that our final-day review sessions are the point where they were finally able to internalize the material and start to use it instinctively.</p>\n<p style=\"color: #222222; font-size: 13px;\">After a half-day of review and reinforcement, we send you back out into the world, better prepared to make the most of your brain.</p>\n<p style=\"color: #222222; font-size: 13px;\">&nbsp;</p>\n<p style=\"color: #222222; font-size: 13px;\"><strong>Application Details</strong></p>\n<p style=\"color: #222222; font-size: 13px;\">The cost of the workshop will be $90 for the first day of instruction + $50 if you plan to stick around for the overnight and the second day of practice.</p>\n<p style=\"color: #222222; font-size: 13px;\">Registration is first come, first serve. Space is limited to 12. To sign-up,&nbsp;<a style=\"color: #1155cc;\" href=\"https://docs.google.com/forms/d/1YESfkKL_5r4uHuV2A4eKCdEO0-mWs9gJTtCwfPimwUo/viewform\" target=\"_blank\">fill out this two minute form</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DQHWBcKeiLnyh9za9": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rKX5f6EWcENhiuttG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 30, "extendedScore": null, "score": 1.2236326438313122e-06, "legacy": true, "legacyId": "22871", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p style=\"color: #222222; font-size: 13px;\">CFAR is experimenting with a mobile workshop, so we can bring our material to people who can't make it to Berkeley. &nbsp;So, next week, we're running a one-and-a-half day workshop in Salt Lake City, Utah!</p>\n<p style=\"color: #222222; font-size: 13px;\">&nbsp;</p>\n<p style=\"color: #222222; font-size: 13px;\"><strong id=\"Workshop_Details\">Workshop Details</strong></p>\n<p style=\"color: #222222; font-size: 13px;\">On&nbsp;<span class=\"aBn\" style=\"border-bottom-width: 1px; border-bottom-style: dashed; border-bottom-color: #cccccc; position: relative; top: -2px; z-index: 0;\"><span class=\"aQJ\" style=\"position: relative; top: 2px; z-index: -1;\">Saturday June 15th</span></span>, CFAR will be running a workshop in the Salt Lake City area. We\u2019ll be presenting selected material from&nbsp;<a style=\"color: #1155cc;\" href=\"http://rationality.org/workshops/\" target=\"_blank\">our four-day workshop</a>&nbsp;and giving you the chance to consult with our instructors on how you can put these skills to work.</p>\n<p style=\"color: #222222; font-size: 13px;\">You\u2019ll arrive for class at&nbsp;<span class=\"aBn\" style=\"border-bottom-width: 1px; border-bottom-style: dashed; border-bottom-color: #cccccc; position: relative; top: -2px; z-index: 0;\"><span class=\"aQJ\" style=\"position: relative; top: 2px; z-index: -1;\">10am on Saturday</span></span>, and you and eleven other participants will spend the day learning highlights from our applied rationality curriculum: how to recognize and defuse a fight-or-flight response when it doesn't do you any good (you can\u2019t outrun data you don\u2019t like!), how to make sure your desire to complete a long-term project (say, writing a book) trickles down to motivate all the picayune steps along the way (doing a read-through to pick off unnecessary adjectives), and how to make the most of your intuitive judgments. Classes wrap up at&nbsp;<span class=\"aBn\" style=\"border-bottom-width: 1px; border-bottom-style: dashed; border-bottom-color: #cccccc; position: relative; top: -2px; z-index: 0;\"><span class=\"aQJ\" style=\"position: relative; top: 2px; z-index: -1;\">7pm</span></span>, and then we\u2019ll all go out for dinner, where you\u2019ll have a chance to decompress and digest the day (along with your meal).</p>\n<p style=\"color: #222222; font-size: 13px;\">After dinner, if you\u2019ve registered for the optional half-day, you\u2019ll sleep over on site with the CFAR staff and play some fun, brain-teasing games. The evening is a time for unstructured conversation and collaboration. What are your pet projects and ambitions? Get feedback from classmates and instructors and start figuring out ways to make the most of your newfound skills.</p>\n<p style=\"color: #222222; font-size: 13px;\">The next morning, you\u2019ll choose which of the previous day\u2019s skills you really want to practice intensively. Catch any misunderstandings or sticking points while you\u2019re still around to troubleshoot them with a CFAR instructor. At our four-day workshops, many participants report that our final-day review sessions are the point where they were finally able to internalize the material and start to use it instinctively.</p>\n<p style=\"color: #222222; font-size: 13px;\">After a half-day of review and reinforcement, we send you back out into the world, better prepared to make the most of your brain.</p>\n<p style=\"color: #222222; font-size: 13px;\">&nbsp;</p>\n<p style=\"color: #222222; font-size: 13px;\"><strong id=\"Application_Details\">Application Details</strong></p>\n<p style=\"color: #222222; font-size: 13px;\">The cost of the workshop will be $90 for the first day of instruction + $50 if you plan to stick around for the overnight and the second day of practice.</p>\n<p style=\"color: #222222; font-size: 13px;\">Registration is first come, first serve. Space is limited to 12. To sign-up,&nbsp;<a style=\"color: #1155cc;\" href=\"https://docs.google.com/forms/d/1YESfkKL_5r4uHuV2A4eKCdEO0-mWs9gJTtCwfPimwUo/viewform\" target=\"_blank\">fill out this two minute form</a>.</p>", "sections": [{"title": "Workshop Details", "anchor": "Workshop_Details", "level": 1}, {"title": "Application Details", "anchor": "Application_Details", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T18:28:28.946Z", "modifiedAt": null, "url": null, "title": "Meetup : [NYC] Self Improvement - Productivity Apps", "slug": "meetup-nyc-self-improvement-productivity-apps", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JZiGkvF47tiJTNKQK/meetup-nyc-self-improvement-productivity-apps", "pageUrlRelative": "/posts/JZiGkvF47tiJTNKQK/meetup-nyc-self-improvement-productivity-apps", "linkUrl": "https://www.lesswrong.com/posts/JZiGkvF47tiJTNKQK/meetup-nyc-self-improvement-productivity-apps", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BNYC%5D%20Self%20Improvement%20-%20Productivity%20Apps&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BNYC%5D%20Self%20Improvement%20-%20Productivity%20Apps%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJZiGkvF47tiJTNKQK%2Fmeetup-nyc-self-improvement-productivity-apps%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BNYC%5D%20Self%20Improvement%20-%20Productivity%20Apps%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJZiGkvF47tiJTNKQK%2Fmeetup-nyc-self-improvement-productivity-apps", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJZiGkvF47tiJTNKQK%2Fmeetup-nyc-self-improvement-productivity-apps", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nl'>[NYC] Self Improvement - Productivity Apps</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">09 June 2013 03:30:59PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Winterfell House, 316 W 138th Street, New York NY 10030</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>There's a growing wealth of productivity apps, each designed to help solve some particular obstacle on one's path to productive power and glory. Many similar apps have slight differences, catering to different people who are motivated in different ways. Many apps doing something novel and interesting but people may not know about them at all, or have realized they have the problem the app is intended to solve.</p>\n\n<p>This Sunday, those of us who have made use of productivity apps will report what we find useful (and what we found not useful).</p>\n\n<hr />\n\n<p>NOTICE: We are rotating our schedule one week forward, because the current string of Fortnights was producing a lot of conflict for members. This is this upcoming Sunday.</p>\n\n<p>The Less Wrong Self Improvement Group is a fortnightly meetup group for people looking to become more effective, at whatever it is they're trying to do, using modern rationality techniques.</p>\n\n<p>Meetups are held every other Sunday, at Winterfell House (316 West 138th Street) at 3:30 PM. Goals are set on the public google doc.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nl'>[NYC] Self Improvement - Productivity Apps</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JZiGkvF47tiJTNKQK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "22873", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____NYC__Self_Improvement___Productivity_Apps\">Discussion article for the meetup : <a href=\"/meetups/nl\">[NYC] Self Improvement - Productivity Apps</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">09 June 2013 03:30:59PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Winterfell House, 316 W 138th Street, New York NY 10030</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>There's a growing wealth of productivity apps, each designed to help solve some particular obstacle on one's path to productive power and glory. Many similar apps have slight differences, catering to different people who are motivated in different ways. Many apps doing something novel and interesting but people may not know about them at all, or have realized they have the problem the app is intended to solve.</p>\n\n<p>This Sunday, those of us who have made use of productivity apps will report what we find useful (and what we found not useful).</p>\n\n<hr>\n\n<p>NOTICE: We are rotating our schedule one week forward, because the current string of Fortnights was producing a lot of conflict for members. This is this upcoming Sunday.</p>\n\n<p>The Less Wrong Self Improvement Group is a fortnightly meetup group for people looking to become more effective, at whatever it is they're trying to do, using modern rationality techniques.</p>\n\n<p>Meetups are held every other Sunday, at Winterfell House (316 West 138th Street) at 3:30 PM. Goals are set on the public google doc.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____NYC__Self_Improvement___Productivity_Apps1\">Discussion article for the meetup : <a href=\"/meetups/nl\">[NYC] Self Improvement - Productivity Apps</a></h2>", "sections": [{"title": "Discussion article for the meetup : [NYC] Self Improvement - Productivity Apps", "anchor": "Discussion_article_for_the_meetup____NYC__Self_Improvement___Productivity_Apps", "level": 1}, {"title": "Discussion article for the meetup : [NYC] Self Improvement - Productivity Apps", "anchor": "Discussion_article_for_the_meetup____NYC__Self_Improvement___Productivity_Apps1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T18:52:32.590Z", "modifiedAt": null, "url": null, "title": "Many Weak Arguments and the Typical Mind", "slug": "many-weak-arguments-and-the-typical-mind", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:02.462Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8DHqN85vab54LjLrM/many-weak-arguments-and-the-typical-mind", "pageUrlRelative": "/posts/8DHqN85vab54LjLrM/many-weak-arguments-and-the-typical-mind", "linkUrl": "https://www.lesswrong.com/posts/8DHqN85vab54LjLrM/many-weak-arguments-and-the-typical-mind", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Many%20Weak%20Arguments%20and%20the%20Typical%20Mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMany%20Weak%20Arguments%20and%20the%20Typical%20Mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8DHqN85vab54LjLrM%2Fmany-weak-arguments-and-the-typical-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Many%20Weak%20Arguments%20and%20the%20Typical%20Mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8DHqN85vab54LjLrM%2Fmany-weak-arguments-and-the-typical-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8DHqN85vab54LjLrM%2Fmany-weak-arguments-and-the-typical-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2318, "htmlBody": "<p class=\"MsoNormal\">In my <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">previous post</a>, I advanced the view that discovering and using many weak arguments generally produces better predictive models for answering questions about the human world than discovering and using a single relatively strong argument does.</p>\n<p class=\"MsoNormal\">My impression is that most high functioning people use the &ldquo;many weak arguments&rdquo; epistemic framework, and that this contrasts with people like my (past) self. I believe that people like me have misunderstood parts of the reasoning of most high functioning people due to <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">typical mind fallacy</a>, and that<span style=\"mso-spacerun:yes\">&nbsp;</span>by extension, people like me have misunderstood parts of how society works.</p>\n<p class=\"MsoNormal\">I flesh out my thinking on this point below.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<h2>&nbsp;Simplistic generalizations and the typical mind</h2>\n<p class=\"MsoNormal\">When we recognize that a member of a reference class has a given feature, we tend to generalize this feature to all members of the reference class. For example, when we encounter an immigrant from a given country, we reflexively assume that other people from the country have the same personality as this immigrant.&nbsp;</p>\n<p class=\"MsoNormal\">Because most people don&rsquo;t have the resources or inclination to focus on improving their epistemic rationality, their beliefs are in part derived from uncritical simplistic generalizations of this type.</p>\n<p class=\"MsoNormal\">The reason that this sort of works in practice is that information about one member of a reference class <em>is</em> in fact evidence about other members of the reference class. This is a special case of Bayes&rsquo; theorem. But such simplistic generalization often yields bad epistemology, and the functionality of most people&rsquo;s epistemology is often highly contingent on their use of the beliefs of those around them, which are functional by virtue of having survived natural selection.</p>\n<h2>The dangers of uncritical generalization&nbsp;</h2>\n<p class=\"MsoNormal\">People responded to the <a href=\"http://en.wikipedia.org/wiki/September_11_attacks\">Islamic terrorist attacks on September 11, 2001</a> by developing xenophobia toward Muslims in general, even though the terrorists represented a tiny fraction of Muslims. The xenophobia toward Muslims that followed the September 11th attacks did a great deal of harm, and if people had not been thinking in such sweeping terms, the harm may have been averted.</p>\n<p class=\"MsoNormal\">With such examples in mind, much of my past effort to improve my epistemic rationality has focused on refining the reflexive simplistic generalizations that I make. I&rsquo;ve put a great deal of effort into appreciating and understanding the nuances present in a given reference class, and to figure out the appropriate subcategory of a reference class to which to extrapolate a feature of a given member of the reference class.</p>\n<p class=\"MsoNormal\">This style is characteristic of many of my friends.&nbsp;</p>\n<h2>Adroit use of simplistic generalizations<span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">My previous efforts to refine my reflexive simplistic generalizations have largely consisted of working to discover <em>a single relatively strong argument</em> for or against a proposition. As I discussed in <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">my previous post</a>, I now believe using many weak arguments generally yields better predictions about the human world.</p>\n<p class=\"MsoNormal\">Weak arguments often arise from simple generalizations. This is exemplified by the arguments that I gave for majoring in a quantitative subject increasing earnings. The statements &ldquo;The people who are wealthier majored in quantitative subjects,&rdquo; &ldquo;high paying jobs use quantitative skills,&rdquo; &ldquo;if you major in a quantitative subject, that shows that you&rsquo;re smart,&rdquo; &ldquo;math teaches you to think,&rdquo; &ldquo;people say that majoring in a quantitative subject increases earnings&rdquo; and &ldquo;my friends think that majoring in a quantitative subject increases earnings&rdquo; are each examples of placing something in a reference class that has a substantial probability of being inappropriate.</p>\n<p class=\"MsoNormal\">In my previous post, I used reference classes that have a substantial probability of being inappropriate, in order to derive a confident conclusion. I didn&rsquo;t do substantive object level investigation of whether or not the reference classes are appropriate. You don&rsquo;t <em>need</em> to do such an investigation to come to a fairly confident conclusion. All that you need is a sufficiently large number of unrelated reference classes.</p>\n<p class=\"MsoNormal\">In pages 27-28 of <a href=\"http://intelligence.org/files/IEM.pdf\">Intelligence Explosion Microeconomics</a>, Eliezer wrote</p>\n<p class=\"MsoNormal\"><em>Aside from the Lucas critique, the other major problem I have with the &ldquo;outside view&rdquo; is that everyone who uses it seems to come up with a di\ufb00erent reference class and a di\ufb00erent answer [&hellip;] I don&rsquo;t know what to do after two people take di\ufb00erent reference classes and come up with di\ufb00erent outside views, both of which we ought to just accept. My experience is that people end up doing the equivalent of saying, &ldquo;I&rsquo;m taking my reference class and going home.&rdquo;</em>&nbsp;</p>\n<p class=\"MsoNormal\">I&rsquo;m sympathetic to Eliezer&rsquo;s concerns with the use of the outside view: one can always find a reference class that supports one&rsquo;s conclusion, and it&rsquo;s unclear what the &ldquo;correct&rdquo; reference class is. Eliezer has argued that the <a href=\"/lw/vz/the_weak_inside_view/\">weak inside view</a> is a better alternative.&nbsp;</p>\n<p class=\"MsoNormal\">There&rsquo;s not a dichotomy between &ldquo;the outside view&rdquo; and &ldquo;the weak inside view&rdquo; &mdash; one can instead use <em>many independent</em> outside views. This is the &ldquo;many weak arguments&rdquo; approach. I believe that this alternative is largely free of the problems with &ldquo;reference class tennis&rdquo; that Eliezer highlights, and is generally superior to the use of the weak inside view.&nbsp;</p>\n<p class=\"MsoNormal\">One can mitigate the problems with using individual simplistic generalizations<span style=\"mso-spacerun:yes\">&nbsp;</span>by using simplistic generalizations from different reference classes and considering the composite picture.</p>\n<h2>Comparing the two approaches</h2>\n<p class=\"MsoNormal\">In epistemology, one observes a member of a given reference class, and wants to determine whether another member of the reference class shares a given feature of the first member. We start our lives by naively extrapolating from the features of the first example to features of the second example. There are two basic ways of improving this aspect of one&rsquo;s epistemology.</p>\n<p class=\"MsoNormal\">One way is to scrutinize the reference class that the first example falls into, and attempt to alter the reference class until one finds the largest reference class such that all members of the reference class share the feature of the sample member, and see whether the second member of interest falls into this reference class. This is the &ldquo;one relatively strong argument&rdquo; approach, and was previously my dominant mode of operation.&nbsp;</p>\n<p class=\"MsoNormal\">The other way is to attempt to consider many unrelated reference classes that both examples may or may not fit into, keep track of how many reference classes both examples fit into, and use the <a href=\"http://en.wikipedia.org/wiki/Consilience\">principle of consilience</a> to assess whether the feature of the first example can reliably be extrapolated to the second example. This is the &ldquo;many weak arguments&rdquo; approach. I&rsquo;ve been striving to make this my dominant mode of operation.</p>\n<h2>The use of many weak arguments as the default mode of operation for most high functioning people<span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">I believe that most high functioning people rely primarily on many weak arguments and the principle of consilience. Some reasons that I believe this are:</p>\n<ul>\n<li>Given that simplistic generalizations are a large input into people&rsquo;s initial epistemology, it seems more likely that people would improve their epistemology by such simplistic generalizations in conjunction with each other than by adopting some other epistemological principle.</li>\n<li>With the exception of people on Less Wrong and people in the mathematical community, I&rsquo;ve almost never seen high functioning people use the &ldquo;relatively one strong argument&rdquo; approach.</li>\n<li>I&rsquo;ve been told that successful venture capitalists use the &ldquo;many weak arguments&rdquo; approach, and have been referred to <a href=\"http://blakemasters.com/peter-thiels-cs183-startup\">notes on Peter Thiel&rsquo;s class about startups</a> as providing evidence for this claim. I haven&rsquo;t investigated further, and intend to do so. </li>\n<li>I&rsquo;ve been very impressed by the epistemic standard at GiveWell, where I worked for a year. My assessment is based on the content on <a href=\"http://www.givewell.org/\">GiveWell&rsquo;s website</a>, and on my experience working there.<br /><br />In <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">Maximizing Cost-Effectiveness via Critical Inquiry</a>, Co-Executive Director Holden Karnofsky expressed the position that rather than focusing on explicit cost-effectiveness estimates (a particular example of the use of one relatively strong argument), one should instead give explicit cost-effectiveness estimates a small amount of weight, and examine a philanthropic opportunity from many different angles.</li>\n</ul>\n<h2>How could we have missed this?<span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">If I&rsquo;m right about all of this, the question arises: Why have people like myself been oblivious to other people&rsquo;s epistemological framework, and the strengths of this framework relative to our own epistemological framework? The claim that I&rsquo;m making is a strong one, in light of people like me having previously been unaware of evidence for it. So I think it&rsquo;s important to address this question. Here I&rsquo;ll give some hypotheses:&nbsp;</p>\n<ul>\n<li><strong>More communication of single relatively strong arguments</strong> &mdash; A single relatively strong argument generally involves many steps, and so working it out often requires writing it down. By way of contrast, the &ldquo;many weak arguments&rdquo; approach doesn&rsquo;t involve as long inferential chains, and so there&rsquo;s less of a need to verbalize the analysis.<br /><br />A single relatively strong argument lends itself to &ldquo;story-telling&rdquo; to a greater extent than a collection of many weak arguments lends itself to &ldquo;story-telling.&rdquo; As cognitive scientist Daniel Willingham discussed in <a href=\"http://www.aft.org/newspubs/periodicals/ae/summer2004/willingham.cfm\">The Privileged Status of Story</a>, stories carry special significance for humans, and are more enjoyable to read and to write, than are lists of individual facts.<br /><br />So the &ldquo;many weak arguments&rdquo; approach is less salient in verbal discourse than the &ldquo;one relatively strong argument&rdquo; approach. <a href=\"http://wiki.lesswrong.com/wiki/Carl_Shulman\">Carl Shulman</a> is the one of the only people who I&rsquo;ve encountered who explicitly lists many weak arguments in favor or against a position. (For more on Carl&rsquo;s style, see Luke&rsquo;s post <a href=\"/lw/8sb/just_the_facts_maam/\">Just the facts, ma'am!</a>)<br /><br /><strong>Compensatory behavior</strong> &mdash; When somebody is very strong in one area and weak in another area, he or she can often use his or her strength in the first area to compensate for the weakness in the second area, and this can mask over the existence of the weakness in the second area, making it hard to recognize. Some examples of this are as follows:<br /><br />(i) My verbal comprehension ability is 1.5 standard deviations above my working memory. This is quite unusual. I only fully realized this very recently, because I had been able to use my relatively high verbal comprehension to partially compensate for my relatively low working memory.<br /><br />(ii) I have a friend who&rsquo;s extraordinarily productive and who&rsquo;s involved in many different activities in a substantive way. It&rsquo;s only recently that he realized that his productivity is as high as it is, and that he hadn&rsquo;t been triaging. My impression is because his productivity was so high, he never needed to learn to triage, in contrast with most people, who were forced to learn to triage by necessity. <br /><br />(iii) Isaac Newton missed the easy proof of the power series expansion for the sine function (using Taylor&rsquo;s theorem), because he was so powerful a mathematician that he was able to derive the series expansion without trouble in a very roundabout and difficult way.<br /><br />The &ldquo;one relatively strong argument&rdquo; epistemological framework is genuinely better than most people&rsquo;s epistemological framework, which tends to be of the &ldquo;few weak arguments&rdquo; type. So being unaware of the virtues of the use of multiple weak arguments doesn&rsquo;t cripple the epistemology of those who use &ldquo;one relatively strong argument&rdquo; to such a degree as to pull their epistemology to below average. People who use the &ldquo;one relatively strong argument&rdquo; approach are generally better at recognizing selection effects than people who use the &ldquo;many weak arguments&rdquo; approach, and so on that front have the edge over the people who use the&nbsp;&ldquo;many weak arguments&rdquo;&nbsp;approach.<br /><br /><strong>Typical mind fallacy</strong> &mdash; Humans <a href=\"http://wiki.lesswrong.com/wiki/Typical_mind_fallacy\">naturally model other people&rsquo;s minds based on their own minds</a>. This conspires with the above factors so that people who use the &ldquo;one relatively strong argument&rdquo; approach are apt to misread the &ldquo;many weak arguments&rdquo; approach as the &ldquo;few weak arguments&rdquo; approach, which can be viewed as an inferior version of the &ldquo;one relatively strong argument&rdquo; approach. This misreading is understandable. The fact that people <em>are using weak arguments</em> is more salient than the <em>number and independence</em> of the weak arguments that they make.</li>\n</ul>\n<h2>Implications</h2>\n<p class=\"MsoNormal\">The phenomena discussed above have important implications:</p>\n<ul>\n<li><strong>Developing facility with the use of many weak arguments is low hanging fruit</strong> &mdash; If people like myself have been neglecting the virtues of using many weak arguments, that suggests that we can improve our epistemology a lot by working to improve in this area, because marginal diminishing returns haven&rsquo;t set in, in contrast with the areas of epistemology that we&rsquo;ve been working on for a long time.</li>\n<li><strong>People like me should update in the direction of other people being more rational</strong> &mdash; Because we&rsquo;ve misread the &ldquo;many weak arguments&rdquo; style as the &ldquo;few weak arguments&rdquo; style, we&rsquo;ve probably underestimated the rationality of most high functioning people. With this in mind, we should update in the direction such people being more rational than we had thought.</li>\n<li><strong>We should pay more attention to people&rsquo;s bottom line than to their stated reasons</strong> &mdash; If most high functioning people aren&rsquo;t relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type &ldquo;Why do you think X?&rdquo; by saying &ldquo;I believe X because of argument Y&rdquo; we shouldn&rsquo;t conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they&rsquo;re not expressing, and we should focus on their belief in X instead of argument Y.</li>\n</ul>\n<p class=\"MsoNormal\"><strong>Acknowledgements: </strong>Thanks to Vipul Naik, Luke Muehlhauser and Nick Beckstead for very helpful comments on an earlier draft of this post.&nbsp;</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at GiveWell. All views expressed here are my own.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8DHqN85vab54LjLrM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 12, "extendedScore": null, "score": 1.223726363967553e-06, "legacy": true, "legacyId": "22874", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\">In my <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">previous post</a>, I advanced the view that discovering and using many weak arguments generally produces better predictive models for answering questions about the human world than discovering and using a single relatively strong argument does.</p>\n<p class=\"MsoNormal\">My impression is that most high functioning people use the \u201cmany weak arguments\u201d epistemic framework, and that this contrasts with people like my (past) self. I believe that people like me have misunderstood parts of the reasoning of most high functioning people due to <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">typical mind fallacy</a>, and that<span style=\"mso-spacerun:yes\">&nbsp;</span>by extension, people like me have misunderstood parts of how society works.</p>\n<p class=\"MsoNormal\">I flesh out my thinking on this point below.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<h2 id=\"_Simplistic_generalizations_and_the_typical_mind\">&nbsp;Simplistic generalizations and the typical mind</h2>\n<p class=\"MsoNormal\">When we recognize that a member of a reference class has a given feature, we tend to generalize this feature to all members of the reference class. For example, when we encounter an immigrant from a given country, we reflexively assume that other people from the country have the same personality as this immigrant.&nbsp;</p>\n<p class=\"MsoNormal\">Because most people don\u2019t have the resources or inclination to focus on improving their epistemic rationality, their beliefs are in part derived from uncritical simplistic generalizations of this type.</p>\n<p class=\"MsoNormal\">The reason that this sort of works in practice is that information about one member of a reference class <em>is</em> in fact evidence about other members of the reference class. This is a special case of Bayes\u2019 theorem. But such simplistic generalization often yields bad epistemology, and the functionality of most people\u2019s epistemology is often highly contingent on their use of the beliefs of those around them, which are functional by virtue of having survived natural selection.</p>\n<h2 id=\"The_dangers_of_uncritical_generalization_\">The dangers of uncritical generalization&nbsp;</h2>\n<p class=\"MsoNormal\">People responded to the <a href=\"http://en.wikipedia.org/wiki/September_11_attacks\">Islamic terrorist attacks on September 11, 2001</a> by developing xenophobia toward Muslims in general, even though the terrorists represented a tiny fraction of Muslims. The xenophobia toward Muslims that followed the September 11th attacks did a great deal of harm, and if people had not been thinking in such sweeping terms, the harm may have been averted.</p>\n<p class=\"MsoNormal\">With such examples in mind, much of my past effort to improve my epistemic rationality has focused on refining the reflexive simplistic generalizations that I make. I\u2019ve put a great deal of effort into appreciating and understanding the nuances present in a given reference class, and to figure out the appropriate subcategory of a reference class to which to extrapolate a feature of a given member of the reference class.</p>\n<p class=\"MsoNormal\">This style is characteristic of many of my friends.&nbsp;</p>\n<h2 id=\"Adroit_use_of_simplistic_generalizations_\">Adroit use of simplistic generalizations<span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">My previous efforts to refine my reflexive simplistic generalizations have largely consisted of working to discover <em>a single relatively strong argument</em> for or against a proposition. As I discussed in <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">my previous post</a>, I now believe using many weak arguments generally yields better predictions about the human world.</p>\n<p class=\"MsoNormal\">Weak arguments often arise from simple generalizations. This is exemplified by the arguments that I gave for majoring in a quantitative subject increasing earnings. The statements \u201cThe people who are wealthier majored in quantitative subjects,\u201d \u201chigh paying jobs use quantitative skills,\u201d \u201cif you major in a quantitative subject, that shows that you\u2019re smart,\u201d \u201cmath teaches you to think,\u201d \u201cpeople say that majoring in a quantitative subject increases earnings\u201d and \u201cmy friends think that majoring in a quantitative subject increases earnings\u201d are each examples of placing something in a reference class that has a substantial probability of being inappropriate.</p>\n<p class=\"MsoNormal\">In my previous post, I used reference classes that have a substantial probability of being inappropriate, in order to derive a confident conclusion. I didn\u2019t do substantive object level investigation of whether or not the reference classes are appropriate. You don\u2019t <em>need</em> to do such an investigation to come to a fairly confident conclusion. All that you need is a sufficiently large number of unrelated reference classes.</p>\n<p class=\"MsoNormal\">In pages 27-28 of <a href=\"http://intelligence.org/files/IEM.pdf\">Intelligence Explosion Microeconomics</a>, Eliezer wrote</p>\n<p class=\"MsoNormal\"><em>Aside from the Lucas critique, the other major problem I have with the \u201coutside view\u201d is that everyone who uses it seems to come up with a di\ufb00erent reference class and a di\ufb00erent answer [\u2026] I don\u2019t know what to do after two people take di\ufb00erent reference classes and come up with di\ufb00erent outside views, both of which we ought to just accept. My experience is that people end up doing the equivalent of saying, \u201cI\u2019m taking my reference class and going home.\u201d</em>&nbsp;</p>\n<p class=\"MsoNormal\">I\u2019m sympathetic to Eliezer\u2019s concerns with the use of the outside view: one can always find a reference class that supports one\u2019s conclusion, and it\u2019s unclear what the \u201ccorrect\u201d reference class is. Eliezer has argued that the <a href=\"/lw/vz/the_weak_inside_view/\">weak inside view</a> is a better alternative.&nbsp;</p>\n<p class=\"MsoNormal\">There\u2019s not a dichotomy between \u201cthe outside view\u201d and \u201cthe weak inside view\u201d \u2014 one can instead use <em>many independent</em> outside views. This is the \u201cmany weak arguments\u201d approach. I believe that this alternative is largely free of the problems with \u201creference class tennis\u201d that Eliezer highlights, and is generally superior to the use of the weak inside view.&nbsp;</p>\n<p class=\"MsoNormal\">One can mitigate the problems with using individual simplistic generalizations<span style=\"mso-spacerun:yes\">&nbsp;</span>by using simplistic generalizations from different reference classes and considering the composite picture.</p>\n<h2 id=\"Comparing_the_two_approaches\">Comparing the two approaches</h2>\n<p class=\"MsoNormal\">In epistemology, one observes a member of a given reference class, and wants to determine whether another member of the reference class shares a given feature of the first member. We start our lives by naively extrapolating from the features of the first example to features of the second example. There are two basic ways of improving this aspect of one\u2019s epistemology.</p>\n<p class=\"MsoNormal\">One way is to scrutinize the reference class that the first example falls into, and attempt to alter the reference class until one finds the largest reference class such that all members of the reference class share the feature of the sample member, and see whether the second member of interest falls into this reference class. This is the \u201cone relatively strong argument\u201d approach, and was previously my dominant mode of operation.&nbsp;</p>\n<p class=\"MsoNormal\">The other way is to attempt to consider many unrelated reference classes that both examples may or may not fit into, keep track of how many reference classes both examples fit into, and use the <a href=\"http://en.wikipedia.org/wiki/Consilience\">principle of consilience</a> to assess whether the feature of the first example can reliably be extrapolated to the second example. This is the \u201cmany weak arguments\u201d approach. I\u2019ve been striving to make this my dominant mode of operation.</p>\n<h2 id=\"The_use_of_many_weak_arguments_as_the_default_mode_of_operation_for_most_high_functioning_people_\">The use of many weak arguments as the default mode of operation for most high functioning people<span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">I believe that most high functioning people rely primarily on many weak arguments and the principle of consilience. Some reasons that I believe this are:</p>\n<ul>\n<li>Given that simplistic generalizations are a large input into people\u2019s initial epistemology, it seems more likely that people would improve their epistemology by such simplistic generalizations in conjunction with each other than by adopting some other epistemological principle.</li>\n<li>With the exception of people on Less Wrong and people in the mathematical community, I\u2019ve almost never seen high functioning people use the \u201crelatively one strong argument\u201d approach.</li>\n<li>I\u2019ve been told that successful venture capitalists use the \u201cmany weak arguments\u201d approach, and have been referred to <a href=\"http://blakemasters.com/peter-thiels-cs183-startup\">notes on Peter Thiel\u2019s class about startups</a> as providing evidence for this claim. I haven\u2019t investigated further, and intend to do so. </li>\n<li>I\u2019ve been very impressed by the epistemic standard at GiveWell, where I worked for a year. My assessment is based on the content on <a href=\"http://www.givewell.org/\">GiveWell\u2019s website</a>, and on my experience working there.<br><br>In <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">Maximizing Cost-Effectiveness via Critical Inquiry</a>, Co-Executive Director Holden Karnofsky expressed the position that rather than focusing on explicit cost-effectiveness estimates (a particular example of the use of one relatively strong argument), one should instead give explicit cost-effectiveness estimates a small amount of weight, and examine a philanthropic opportunity from many different angles.</li>\n</ul>\n<h2 id=\"How_could_we_have_missed_this__\">How could we have missed this?<span style=\"font-size: small;\">&nbsp;</span></h2>\n<p class=\"MsoNormal\">If I\u2019m right about all of this, the question arises: Why have people like myself been oblivious to other people\u2019s epistemological framework, and the strengths of this framework relative to our own epistemological framework? The claim that I\u2019m making is a strong one, in light of people like me having previously been unaware of evidence for it. So I think it\u2019s important to address this question. Here I\u2019ll give some hypotheses:&nbsp;</p>\n<ul>\n<li><strong>More communication of single relatively strong arguments</strong> \u2014 A single relatively strong argument generally involves many steps, and so working it out often requires writing it down. By way of contrast, the \u201cmany weak arguments\u201d approach doesn\u2019t involve as long inferential chains, and so there\u2019s less of a need to verbalize the analysis.<br><br>A single relatively strong argument lends itself to \u201cstory-telling\u201d to a greater extent than a collection of many weak arguments lends itself to \u201cstory-telling.\u201d As cognitive scientist Daniel Willingham discussed in <a href=\"http://www.aft.org/newspubs/periodicals/ae/summer2004/willingham.cfm\">The Privileged Status of Story</a>, stories carry special significance for humans, and are more enjoyable to read and to write, than are lists of individual facts.<br><br>So the \u201cmany weak arguments\u201d approach is less salient in verbal discourse than the \u201cone relatively strong argument\u201d approach. <a href=\"http://wiki.lesswrong.com/wiki/Carl_Shulman\">Carl Shulman</a> is the one of the only people who I\u2019ve encountered who explicitly lists many weak arguments in favor or against a position. (For more on Carl\u2019s style, see Luke\u2019s post <a href=\"/lw/8sb/just_the_facts_maam/\">Just the facts, ma'am!</a>)<br><br><strong>Compensatory behavior</strong> \u2014 When somebody is very strong in one area and weak in another area, he or she can often use his or her strength in the first area to compensate for the weakness in the second area, and this can mask over the existence of the weakness in the second area, making it hard to recognize. Some examples of this are as follows:<br><br>(i) My verbal comprehension ability is 1.5 standard deviations above my working memory. This is quite unusual. I only fully realized this very recently, because I had been able to use my relatively high verbal comprehension to partially compensate for my relatively low working memory.<br><br>(ii) I have a friend who\u2019s extraordinarily productive and who\u2019s involved in many different activities in a substantive way. It\u2019s only recently that he realized that his productivity is as high as it is, and that he hadn\u2019t been triaging. My impression is because his productivity was so high, he never needed to learn to triage, in contrast with most people, who were forced to learn to triage by necessity. <br><br>(iii) Isaac Newton missed the easy proof of the power series expansion for the sine function (using Taylor\u2019s theorem), because he was so powerful a mathematician that he was able to derive the series expansion without trouble in a very roundabout and difficult way.<br><br>The \u201cone relatively strong argument\u201d epistemological framework is genuinely better than most people\u2019s epistemological framework, which tends to be of the \u201cfew weak arguments\u201d type. So being unaware of the virtues of the use of multiple weak arguments doesn\u2019t cripple the epistemology of those who use \u201cone relatively strong argument\u201d to such a degree as to pull their epistemology to below average. People who use the \u201cone relatively strong argument\u201d approach are generally better at recognizing selection effects than people who use the \u201cmany weak arguments\u201d approach, and so on that front have the edge over the people who use the&nbsp;\u201cmany weak arguments\u201d&nbsp;approach.<br><br><strong>Typical mind fallacy</strong> \u2014 Humans <a href=\"http://wiki.lesswrong.com/wiki/Typical_mind_fallacy\">naturally model other people\u2019s minds based on their own minds</a>. This conspires with the above factors so that people who use the \u201cone relatively strong argument\u201d approach are apt to misread the \u201cmany weak arguments\u201d approach as the \u201cfew weak arguments\u201d approach, which can be viewed as an inferior version of the \u201cone relatively strong argument\u201d approach. This misreading is understandable. The fact that people <em>are using weak arguments</em> is more salient than the <em>number and independence</em> of the weak arguments that they make.</li>\n</ul>\n<h2 id=\"Implications\">Implications</h2>\n<p class=\"MsoNormal\">The phenomena discussed above have important implications:</p>\n<ul>\n<li><strong>Developing facility with the use of many weak arguments is low hanging fruit</strong> \u2014 If people like myself have been neglecting the virtues of using many weak arguments, that suggests that we can improve our epistemology a lot by working to improve in this area, because marginal diminishing returns haven\u2019t set in, in contrast with the areas of epistemology that we\u2019ve been working on for a long time.</li>\n<li><strong>People like me should update in the direction of other people being more rational</strong> \u2014 Because we\u2019ve misread the \u201cmany weak arguments\u201d style as the \u201cfew weak arguments\u201d style, we\u2019ve probably underestimated the rationality of most high functioning people. With this in mind, we should update in the direction such people being more rational than we had thought.</li>\n<li><strong>We should pay more attention to people\u2019s bottom line than to their stated reasons</strong> \u2014 If most high functioning people aren\u2019t relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \u201cWhy do you think X?\u201d by saying \u201cI believe X because of argument Y\u201d we shouldn\u2019t conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they\u2019re not expressing, and we should focus on their belief in X instead of argument Y.</li>\n</ul>\n<p class=\"MsoNormal\"><strong>Acknowledgements: </strong>Thanks to Vipul Naik, Luke Muehlhauser and Nick Beckstead for very helpful comments on an earlier draft of this post.&nbsp;</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at GiveWell. All views expressed here are my own.</p>\n<p>&nbsp;</p>", "sections": [{"title": "\u00a0Simplistic generalizations and the typical mind", "anchor": "_Simplistic_generalizations_and_the_typical_mind", "level": 1}, {"title": "The dangers of uncritical generalization\u00a0", "anchor": "The_dangers_of_uncritical_generalization_", "level": 1}, {"title": "Adroit use of simplistic generalizations\u00a0", "anchor": "Adroit_use_of_simplistic_generalizations_", "level": 1}, {"title": "Comparing the two approaches", "anchor": "Comparing_the_two_approaches", "level": 1}, {"title": "The use of many weak arguments as the default mode of operation for most high functioning people\u00a0", "anchor": "The_use_of_many_weak_arguments_as_the_default_mode_of_operation_for_most_high_functioning_people_", "level": 1}, {"title": "How could we have missed this?\u00a0", "anchor": "How_could_we_have_missed_this__", "level": 1}, {"title": "Implications", "anchor": "Implications", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9W9P2snxu5Px746LD", "w9KWNWFTXivjJ7rjF", "7YLuXtKqWiybJAmeo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T20:24:25.936Z", "modifiedAt": null, "url": null, "title": "Tiling Agents for Self-Modifying AI (OPFAI #2)", "slug": "tiling-agents-for-self-modifying-ai-opfai-2", "viewCount": null, "lastCommentedAt": "2014-08-30T04:06:46.225Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gnxDNEtkEo3sfeyPn/tiling-agents-for-self-modifying-ai-opfai-2", "pageUrlRelative": "/posts/gnxDNEtkEo3sfeyPn/tiling-agents-for-self-modifying-ai-opfai-2", "linkUrl": "https://www.lesswrong.com/posts/gnxDNEtkEo3sfeyPn/tiling-agents-for-self-modifying-ai-opfai-2", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tiling%20Agents%20for%20Self-Modifying%20AI%20(OPFAI%20%232)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATiling%20Agents%20for%20Self-Modifying%20AI%20(OPFAI%20%232)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgnxDNEtkEo3sfeyPn%2Ftiling-agents-for-self-modifying-ai-opfai-2%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tiling%20Agents%20for%20Self-Modifying%20AI%20(OPFAI%20%232)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgnxDNEtkEo3sfeyPn%2Ftiling-agents-for-self-modifying-ai-opfai-2", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgnxDNEtkEo3sfeyPn%2Ftiling-agents-for-self-modifying-ai-opfai-2", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 793, "htmlBody": "<p>An early draft of publication #2 in the Open Problems in Friendly AI series is now available: &nbsp;<a href=\"http://intelligence.org/files/TilingAgents.pdf\">Tiling Agents for Self-Modifying AI, and the Lobian Obstacle</a>.&nbsp; ~20,000 words, aimed at mathematicians or the highly mathematically literate.&nbsp; The research reported on was conducted by Yudkowsky and Herreshoff, substantially refined at the November 2012 MIRI Workshop with Mihaly Barasz and Paul Christiano, and refined further at the April 2013 MIRI Workshop.</p>\n<p style=\"padding-left: 60px;\"><strong>Abstract:</strong></p>\n<p style=\"padding-left: 30px;\">We model self-modi\fcation in AI by introducing 'tiling' agents whose decision systems will approve the construction of highly similar agents, creating a repeating pattern (including similarity of the off\u000bspring's goals). &nbsp;Constructing a formalism in the most straightforward way produces a G\u007fodelian difficulty, the Lobian obstacle. &nbsp;By technical methods we demonstrate the possibility of avoiding this obstacle, but the underlying puzzles of rational coherence are thus only partially addressed. &nbsp;We extend the formalism to partially unknown deterministic environments, and show a very crude extension to probabilistic environments and expected utility; but the problem of finding a fundamental decision criterion for self-modifying probabilistic agents remains open.</p>\n<p>Commenting here is the preferred venue for discussion of the paper. &nbsp;This is an early draft and has not been reviewed, so it may contain mathematical errors, and reporting of these will be much appreciated.</p>\n<p>The overall agenda of the paper is introduce the conceptual notion of a self-reproducing decision pattern which includes reproduction of the goal or utility function, by exposing a particular possible problem with a tiling logical decision pattern and coming up with some partial technical solutions. &nbsp;This then makes it conceptually much clearer to point out the even deeper problems with \"We can't yet describe a probabilistic way to do this because of non-monotonicity\" and \"We don't have a good bounded way to do this because maximization is impossible, satisficing is too weak and Schmidhuber's swapping criterion is underspecified.\" &nbsp;The paper uses first-order logic (FOL) because FOL has a lot of useful standard machinery for reflection which we can then invoke; in real life, FOL is of course a poor representational fit to most real-world environments outside a human-constructed computer chip with thermodynamically expensive crisp variable states.</p>\n<p>As further background, the idea that something-like-proof might be relevant to Friendly AI is not about achieving some chimera of absolute safety-feeling, but rather about the idea that the total probability of catastrophic failure should not have a significant conditionally independent component on each self-modification, and that self-modification will (at least in initial stages) take place within the highly deterministic environment of a computer chip. &nbsp;This means that statistical testing methods (e.g. an evolutionary algorithm's evaluation of average fitness on a set of test problems) are not suitable for self-modifications which can potentially induce catastrophic failure (e.g. of parts of code that can affect the representation or interpretation of the goals). &nbsp;Mathematical proofs have the property that they are as strong as their axioms and have no significant conditionally independent per-step failure probability if their axioms are semantically true, which suggests that something like mathematical reasoning may be appropriate for certain particular types of self-modification during some developmental stages.</p>\n<p>Thus the content of the paper is very far off from how a realistic AI would work, but conversely, if you can't even answer the kinds of simple problems posed within the paper (both those we partially solve and those we only pose) then you must be very far off from being able to build a stable self-modifying AI. &nbsp;Being able to say how to build a theoretical device that would play perfect chess given infinite computing power, is very far off from the ability to build Deep Blue. &nbsp;However, if you can't even say how to play perfect chess given infinite computing power, you are confused about the rules of the chess or the structure of chess-playing computation in a way that would make it entirely&nbsp;hopeless for you to figure out how to build a bounded chess-player. &nbsp;Thus \"In real life we're always bounded\" is no excuse for not being able to solve the much simpler unbounded form of the problem, and being able to describe the infinite chess-player would be substantial and useful conceptual progress compared to <em>not </em>being able to do that. &nbsp;We can't be absolutely certain that an analogous situation holds between solving the challenges posed in the paper, and realistic self-modifying AIs with stable goal systems, but every line of investigation has to start somewhere.</p>\n<p>Parts of the paper will be easier to understand if you've read <a href=\"http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners\">Highly Advanced Epistemology 101 For Beginners</a> including the parts on correspondence theories of truth (relevant to section 6) and model-theoretic semantics of logic (relevant to 3, 4, and 6), and there are footnotes intended to make the paper somewhat more accessible than usual, but the paper is still essentially aimed at mathematically sophisticated readers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Pa2SdZsLFmqhs42Do": 1, "ksdiAMKfgSyEeKMo6": 1, "wBoHTJs9iQzczNtW3": 1, "6nS8oYmSMuFMaiowF": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gnxDNEtkEo3sfeyPn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 57, "baseScore": 84, "extendedScore": null, "score": 0.00021656827549262344, "legacy": true, "legacyId": "22853", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 58, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 259, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-06-06T20:24:25.936Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-06T23:24:24.981Z", "modifiedAt": null, "url": null, "title": "Model Stability in Intervention Assessment", "slug": "model-stability-in-intervention-assessment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:02.727Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonathan_Lee", "createdAt": "2009-09-10T00:05:08.577Z", "isAdmin": false, "displayName": "Jonathan_Lee"}, "userId": "8qL3Hsw2TzaLPu3Bh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RsKWqKju54NHhXw5B/model-stability-in-intervention-assessment", "pageUrlRelative": "/posts/RsKWqKju54NHhXw5B/model-stability-in-intervention-assessment", "linkUrl": "https://www.lesswrong.com/posts/RsKWqKju54NHhXw5B/model-stability-in-intervention-assessment", "postedAtFormatted": "Thursday, June 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Model%20Stability%20in%20Intervention%20Assessment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModel%20Stability%20in%20Intervention%20Assessment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRsKWqKju54NHhXw5B%2Fmodel-stability-in-intervention-assessment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Model%20Stability%20in%20Intervention%20Assessment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRsKWqKju54NHhXw5B%2Fmodel-stability-in-intervention-assessment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRsKWqKju54NHhXw5B%2Fmodel-stability-in-intervention-assessment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2311, "htmlBody": "<p>In this post, I hope to examine the Bayesian Adjustment paradigm presented by <a href=\"/lw/745/why_we_cant_take_expected_value_estimates/\">Holden</a> <a href=\"/lw/8di/maximizing_costeffectiveness_via_critical_inquiry/\">Karnofsky</a> of Givewell from a mathematical viewpoint, in particular looking at how we can rigorously manage the notion of uncertainty in our models and the stability of an estimate. Several recent posts <a href=\"/lw/hlx/the_use_of_many_independent_lines_of_evidence_the/\">have</a> <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">touched</a> <a href=\"/lw/hne/many_weak_arguments_and_the_typical_mind/\">on</a> <a href=\"/lw/h78/estimate_stability/\">related</a> <a href=\"/lw/gzq/bayesian_adjustment_does_not_defeat_existential/\">issues</a>.</p>\n<p>In practise, we will need to have some substantive prior on the likely range of impacts that interventions can achieve, and I will look briefly at what kinds of log-ranges are supported in the literature, and the extent to which these can preclude extreme impact scenarios. I will then briefly look at less formal notions of confidence in a model, which may be more tractable either computationally or for heuristic purposes than a formal bayesian approach.</p>\n<h2><a id=\"more\"></a>Bayesian Adjustment, and the A<sub>p</sub> distribution</h2>\n<p>In the setting originally proposed, the BA framework takes a background prior on impacts and a noisy measurement of fixed variance of a fixed impact parameter. In this setting, the BA approach is provably <a href=\"http://blog.givewell.org/attachments/worms.pdf\">correct</a>. Unfortunately, the real world is not so accommodating; for general evidence about an intervention, the BA approach is not fully Bayesian. In this sense it unavoidably miscounts evidence. The general problem can be illustrated by working through the process formally. Consider propositions:</p>\n<p style=\"padding-left: 30px;\">x := Has Impact x,<br />E := Background data,<br />C := there exists a given computation or argument to a given impact y.</p>\n<p>We suppose for the framework that we have P(x|E), P(x|C) for each x. Since the set of propositions {x} are disjoint and exhaustive, these form distributions. For inference, what we actually want is P(x|EC). In the BA framework, we compute P(x|E)P(x|C) for each x, and normalise to get a distribution. Computing a bayesian update, we have:</p>\n<p style=\"padding-left: 30px;\">P(x|EC) = P(xEC)/P(EC) = P(C|xE)P(x|E)/P(C|E).</p>\n<p>So if the BA framework is to give the correct answer, we need to have P(x|EC) &prop; P(x|E)P(x|C), so that the normalisation in the BA framework fixes everything correctly. Since P(C|E) is also just a normalising factor, this proportionality occurs if and only if P(C|xE) &prop; P(x|C), which does not hold in general. In the precise setting that was originally proposed for the BA framework, there are two special features. Firstly, the estimate is a noisy measurement of x, and so P(C|x) = P(C|xE) because all dependence on the world factors through x. Secondly P(C|x) &prop; P(x|C), and so the bayesian and BA results coincide.</p>\n<p>However, when we investigate an indirect intervention we are typically looking at estimates derived non-trivially from the world; as a result, P(C|xE) &ne; P(C|x), and the BA framework breaks down. Put another way, when we look for estimates and find one, we have learned something about the world. If we don't account for this properly, we will make incorrect conclusions.</p>\n<p>In particular, it is reasonable to expect that the existence of estimates implying unusual values for an intervention should positively correlate with background states of the world which permit unusual values for the intervention. The BA framework does not account for this, and so heuristically it will overly penalise estimates of interventions which yield results far from the prior distribution. Of course, we can reasonably ask whether it is feasible to compute P(x|EC) explicitly; in general fully bayesian work is hard.</p>\n<p>Jaynes (<a href=\"http://omega.albany.edu:8008/ETJ-PS/cc18f.ps\">Probability Theory: The Logic of Science, Chapter 18</a>) deals with a simpler example of the same basic problem, where we are asked to ascribe credence to a proposition like</p>\n<p style=\"padding-left: 30px;\">A := &ldquo;when I flip this coin it will come up heads&rdquo;.</p>\n<p>Instead of merely having a belief about the distribution over outcomes (analogous to P(x|E) in the BA case), it turns out to be necessary to keep track of a distribution over propositions of form:</p>\n<p style=\"padding-left: 30px;\">A<sub>p</sub> := &ldquo;the subjective probability of Heads <em>is</em> p, regardless of any other evidence&rdquo;;</p>\n<p>or more formally we define P(A|A<sub>p</sub>E) = p. Hence the events A<sub>p</sub> are disjoint, and exactly one is true. Hence we have an object which behaves like a probability distribution over A<sub>p</sub>; we can abuse terminology and use probability directly. Jaynes then shows that:</p>\n<p style=\"padding-left: 30px;\">P(A) = &int;p P(A<sub>p</sub>) dp</p>\n<p>And so we can recover P(A) from the P(A<sub>p</sub>). The full A<sub>p</sub> distribution is needed to formalise confidence in one&rsquo;s estimate. For example, if one is sure from background data E that the coin is completely biased, then one trial flip will tell you which way the coin is biased, and so P(A|E,F) will be almost 0 or 1, whilst P(A|E) = &frac12;. On the other hand, if you have background information E&rsquo; that of 10000 trial flips 5000 were heads, then one additional trial flip F leaves P(A|E&rsquo;F) ~ P(A|E) = &frac12;. Jaynes shows that the A<sub>p</sub> distribution screens off E, and can be updated in light of new data F; the posterior P(A|EF) is then the mean of the new A<sub>p</sub> distribution. In this framework, and starting from a uniform prior over A<sub>p</sub>, Laplace&rsquo;s law of succession is derived.</p>\n<p>To generalise this framework to estimating a real value x rather than a binary outcome A, we can shift from a distribution A<sub>p</sub> over probabilities of A to a distribution P(X<sub>d</sub>) over distributions for x, with X<sub>d</sub> := \"x ~ d regardless of other evidence\"<sup>1</sup>. In this setting, there will still be a &ldquo;point estimate&rdquo; distribution X, the mean of X<sub>d</sub>, which summarises your current beliefs about x. Other information about X<sub>d</sub> is needed to allow you to update coherently in response to arbitrary new information. In such a case, new information may cause one to substantially change the distribution X<sub>d</sub>, and thus one&rsquo;s beliefs about the world, if this new information causes a great deal of surprise conditional on X.</p>\n<p>&nbsp;</p>\n<h2>Examples and Priors in the BA framework</h2>\n<p>The mathematics can also reveal when an intuition pump is bringing extra information in a non-obvious way. For example, some of the <a href=\"/lw/745/why_we_cant_take_expected_value_estimates/\">examples</a> given for how the BA framework should run had the apparently unintuitive feature that successively larger claims of impact eventually lead to decreasing posterior means to the estimates. This turns out to be because the standard deviation of the estimates was presumed to be roughly equal to their mean.</p>\n<p>De facto this means that the new evidence was prohibited a prior from suggesting that an intervention was better than the prior mean with high probability. In general, this need not hold, if we are able to find data which is reasonably constrained and not present in the background model. If we intend to also account for the possibilities of errors in cognition, then this kind of treatment of new evidence seems more reasonable, but then we should see similar broadening in our background prior.</p>\n<p>Similarly, as the stated BA priors are normal or log-normal, they assert that the event E := &ldquo;the range of intervention impact ratios is large&rdquo; has very low probability. Some decay is necessary to prevent arbitrarily large impacts dominating, which would make expected value computations fail to converge. Practically, this implies that a stated prior for impacts drops off faster than 1/impact&sup3; above some impact<sup>2</sup>, but this does not in and of itself mandate a specific form of prior, not specify the point above which the prior should drop rapidly, nor the absolute rate of the drop off. In particular, the log-normal or normal prior drop off much faster, and so are implicitly very confident that the range of impacts is bounded by what we've already seen.</p>\n<p>&nbsp;</p>\n<h2>What is the range of impacts for interventions?</h2>\n<p>It is not trivial to find out what kinds of ratios we should expect to see; for these purposes it is unfortunate that Givewell does not publicly emit $/DALY or $/life estimates of impact for the majority of the charities it assesses. It would be very useful to see what kinds of impacts are being sampled at the low end. Other studies (eg. DCP2) have assessed some hundreds of high and low impact interventions in public health, and assert 10000:1 ratios in impact, with their best $/DALY numbers consistent with Givewell&rsquo;s assessment that AMF is likely to be one of the better public health interventions available.</p>\n<p>Of course, we also strongly suspect that there exist interventions with better impacts than AMF, if we are willing to look outside public health. Givewell raison d&rsquo;etre is that one can gain leverage in moving funds from ineffective causes to effective ones, and so a dollar spent on Givewell should move much more than a dollar to effective interventions. In principle this demonstrates that the range of possible intervention impacts may be much larger than the range available in specific fields, such as developing world health interventions.</p>\n<p>By the lights of the BA prior, we are uncharitable about an estimate of impact if we assert it is large, in that this makes the estimate incredulous and thus heavily discounted. In this sense, existential risk reduction has been sketchily and optimistically estimated at around $0.125/life, which we can take as an uncharitable estimate for the BA framework. Assuming that this was a correct estimate, it being true would only require the existence of an intervention which is to AMF as AMF is to the least effective health interventions. It does not seem easy to confidently assert that the tail thickness and variance of the distribution of intervention impacts is such that the apparently observed ratios in public health interventions and Givewell are common enough that they can be searched for whilst ruling out a priori the credibility of estimates at the &lt;$1/life level.</p>\n<p>Now, it might be possible that these very high impact interventions are not easy to scale up, &nbsp;or are rare enough that it is not worth searching for them. On the other hand, we can free-ride on other people recommending interventions, if we are willing to accept internal or inside view assessments as substantively credible.</p>\n<p>&nbsp;</p>\n<h2>Confidence and Probability</h2>\n<p>It seems clear that the probability of a proposition and one&rsquo;s confidence in the quality of your assessment are distinct, although it is easy to confuse language by referring to confidence in a proposition, rather than in a probability or estimate. Fully rigorously, this is encompassed in the distribution over X<sub>d</sub>, but in practise we may wish to track only a single posterior distribution<sup>3</sup>.</p>\n<p>Other commenters have <a href=\"/lw/745/why_we_cant_take_expected_value_estimates/4nzy\">suggested</a> a similar distinction between confidence and probability; observing that having observed the computations exist the correct response is to say &ldquo;I notice that I am confused&rdquo;. More formally, in practise we have neither P(x|C) nor P(x|E). We have to also condition on some event like:</p>\n<p style=\"padding-left: 30px;\">N := \"My modelling and computations are correct\".</p>\n<p>Ideally one would have extensive tests of all of the pieces of a methodology, so that one could say something about which classes of interventions are well modelled, but practically this may excessively complicate the issue. A priori, it seems unreasonable to attach &gt;&gt; 1-1/1000 probability to propositions like N for a new method or model which has merely been output by human cognition. Assessing high confidence would be expected to wait on assessing the reliability and calibration of the methodology, or showing that the model is a stable output of cognition.</p>\n<p>In the event of a computation and a point prior belief about interventions disagreeing, a Bayesian update will reduce confidence in N, and also come to believe that the processes leading to the estimate C are less reliable. This is separate to the process which causes you to extract beliefs about this particular intervention. Whether the background model is substantively changed or the estimation procedure is discounted is a matter for your relative confidence in these processes, and the sensitivity of the outputs of the processes.</p>\n<p>&nbsp;</p>\n<h2>Conclusions</h2>\n<p>Disagreements over how to estimate the impact of an intervention on the world have existed for some time, and it seems that the grounds for these disagreements are not being well addressed. In general, it would be a good thing for our grounds for confidence in arguments and background priors to be made very explicit and open. In principle we can then reduce these disagreements to matters of fact and differences in prior beliefs.</p>\n<p>In the particular case of Givewell, it is clear that they have assessed a great many interventions systematically, and seem to possess a great deal of confidence in their modelled backgrounds. I do not know if there has been a formal process of checking the calibration of these estimates; if there has been, and so Givewell can assess in high confidence (say &raquo; 10 bits) in propositions of form &ldquo;our model is emitting a suitable background correct for this class of interventions&rdquo;, then the methods are highly likely to be highly valuable to the wider EA community for other purposes, and ideally would be distributed.</p>\n<p>&nbsp;</p>\n<h2>Notes</h2>\n<p>I wrote this post whilst a visiting fellow at MIRI; Lukeprog asked that I take a further look at LW's debates on cost effectiveness stability in effective altruism, and try to clarify the situation if possible.</p>\n<p>I am grateful to Carl Shulman, Luke Muehlhauser and Adam Casey for their substantive feedback and comments on early drafts of this post.</p>\n<p>&nbsp;</p>\n<p>1 To follow the modified mathematics of Jaynes' derivation closely, we amend 18-1 to read P(X = x|X<sub>d</sub>E) = d(x) for any distribution d, and then follow Jaynes&rsquo; derivation formally. It is reasonable to be worried that the space of distributions is not measurable; this can be fixed by restricting to a sigma-algebra of functions which are piecewise constant (or alternatively running Jaynes' original approach on the set of binary propositions A<sub>yz</sub> := \"y &le; x &le; z\" for all y and z)</p>\n<p>2 We could also assert strong cancellation properties, but it is unclear whether these effects can be substantial in practise. Technically, we also could get convergence with drop offs like 1/(n&sup2; log&sup2; n) or&nbsp; 1/(n&sup2; log n log&sup2; log n), but the distinction is slight for the purposes of discussion; they are<em><strong> </strong>much</em> slower than a normal.</p>\n<p>3 If we work with the set of A<sub>xy</sub> propositions instead, then Jaynes implies we have to hold a set of distributions (A<sub>xy</sub>)<sub>p</sub>, which is rather more tractable than X<sub>d</sub>, although harder to visualise concretely.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RsKWqKju54NHhXw5B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 1.2239305244140194e-06, "legacy": true, "legacyId": "22875", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In this post, I hope to examine the Bayesian Adjustment paradigm presented by <a href=\"/lw/745/why_we_cant_take_expected_value_estimates/\">Holden</a> <a href=\"/lw/8di/maximizing_costeffectiveness_via_critical_inquiry/\">Karnofsky</a> of Givewell from a mathematical viewpoint, in particular looking at how we can rigorously manage the notion of uncertainty in our models and the stability of an estimate. Several recent posts <a href=\"/lw/hlx/the_use_of_many_independent_lines_of_evidence_the/\">have</a> <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">touched</a> <a href=\"/lw/hne/many_weak_arguments_and_the_typical_mind/\">on</a> <a href=\"/lw/h78/estimate_stability/\">related</a> <a href=\"/lw/gzq/bayesian_adjustment_does_not_defeat_existential/\">issues</a>.</p>\n<p>In practise, we will need to have some substantive prior on the likely range of impacts that interventions can achieve, and I will look briefly at what kinds of log-ranges are supported in the literature, and the extent to which these can preclude extreme impact scenarios. I will then briefly look at less formal notions of confidence in a model, which may be more tractable either computationally or for heuristic purposes than a formal bayesian approach.</p>\n<h2 id=\"Bayesian_Adjustment__and_the_Ap_distribution\"><a id=\"more\"></a>Bayesian Adjustment, and the A<sub>p</sub> distribution</h2>\n<p>In the setting originally proposed, the BA framework takes a background prior on impacts and a noisy measurement of fixed variance of a fixed impact parameter. In this setting, the BA approach is provably <a href=\"http://blog.givewell.org/attachments/worms.pdf\">correct</a>. Unfortunately, the real world is not so accommodating; for general evidence about an intervention, the BA approach is not fully Bayesian. In this sense it unavoidably miscounts evidence. The general problem can be illustrated by working through the process formally. Consider propositions:</p>\n<p style=\"padding-left: 30px;\">x := Has Impact x,<br>E := Background data,<br>C := there exists a given computation or argument to a given impact y.</p>\n<p>We suppose for the framework that we have P(x|E), P(x|C) for each x. Since the set of propositions {x} are disjoint and exhaustive, these form distributions. For inference, what we actually want is P(x|EC). In the BA framework, we compute P(x|E)P(x|C) for each x, and normalise to get a distribution. Computing a bayesian update, we have:</p>\n<p style=\"padding-left: 30px;\">P(x|EC) = P(xEC)/P(EC) = P(C|xE)P(x|E)/P(C|E).</p>\n<p>So if the BA framework is to give the correct answer, we need to have P(x|EC) \u221d P(x|E)P(x|C), so that the normalisation in the BA framework fixes everything correctly. Since P(C|E) is also just a normalising factor, this proportionality occurs if and only if P(C|xE) \u221d P(x|C), which does not hold in general. In the precise setting that was originally proposed for the BA framework, there are two special features. Firstly, the estimate is a noisy measurement of x, and so P(C|x) = P(C|xE) because all dependence on the world factors through x. Secondly P(C|x) \u221d P(x|C), and so the bayesian and BA results coincide.</p>\n<p>However, when we investigate an indirect intervention we are typically looking at estimates derived non-trivially from the world; as a result, P(C|xE) \u2260 P(C|x), and the BA framework breaks down. Put another way, when we look for estimates and find one, we have learned something about the world. If we don't account for this properly, we will make incorrect conclusions.</p>\n<p>In particular, it is reasonable to expect that the existence of estimates implying unusual values for an intervention should positively correlate with background states of the world which permit unusual values for the intervention. The BA framework does not account for this, and so heuristically it will overly penalise estimates of interventions which yield results far from the prior distribution. Of course, we can reasonably ask whether it is feasible to compute P(x|EC) explicitly; in general fully bayesian work is hard.</p>\n<p>Jaynes (<a href=\"http://omega.albany.edu:8008/ETJ-PS/cc18f.ps\">Probability Theory: The Logic of Science, Chapter 18</a>) deals with a simpler example of the same basic problem, where we are asked to ascribe credence to a proposition like</p>\n<p style=\"padding-left: 30px;\">A := \u201cwhen I flip this coin it will come up heads\u201d.</p>\n<p>Instead of merely having a belief about the distribution over outcomes (analogous to P(x|E) in the BA case), it turns out to be necessary to keep track of a distribution over propositions of form:</p>\n<p style=\"padding-left: 30px;\">A<sub>p</sub> := \u201cthe subjective probability of Heads <em>is</em> p, regardless of any other evidence\u201d;</p>\n<p>or more formally we define P(A|A<sub>p</sub>E) = p. Hence the events A<sub>p</sub> are disjoint, and exactly one is true. Hence we have an object which behaves like a probability distribution over A<sub>p</sub>; we can abuse terminology and use probability directly. Jaynes then shows that:</p>\n<p style=\"padding-left: 30px;\">P(A) = \u222bp P(A<sub>p</sub>) dp</p>\n<p>And so we can recover P(A) from the P(A<sub>p</sub>). The full A<sub>p</sub> distribution is needed to formalise confidence in one\u2019s estimate. For example, if one is sure from background data E that the coin is completely biased, then one trial flip will tell you which way the coin is biased, and so P(A|E,F) will be almost 0 or 1, whilst P(A|E) = \u00bd. On the other hand, if you have background information E\u2019 that of 10000 trial flips 5000 were heads, then one additional trial flip F leaves P(A|E\u2019F) ~ P(A|E) = \u00bd. Jaynes shows that the A<sub>p</sub> distribution screens off E, and can be updated in light of new data F; the posterior P(A|EF) is then the mean of the new A<sub>p</sub> distribution. In this framework, and starting from a uniform prior over A<sub>p</sub>, Laplace\u2019s law of succession is derived.</p>\n<p>To generalise this framework to estimating a real value x rather than a binary outcome A, we can shift from a distribution A<sub>p</sub> over probabilities of A to a distribution P(X<sub>d</sub>) over distributions for x, with X<sub>d</sub> := \"x ~ d regardless of other evidence\"<sup>1</sup>. In this setting, there will still be a \u201cpoint estimate\u201d distribution X, the mean of X<sub>d</sub>, which summarises your current beliefs about x. Other information about X<sub>d</sub> is needed to allow you to update coherently in response to arbitrary new information. In such a case, new information may cause one to substantially change the distribution X<sub>d</sub>, and thus one\u2019s beliefs about the world, if this new information causes a great deal of surprise conditional on X.</p>\n<p>&nbsp;</p>\n<h2 id=\"Examples_and_Priors_in_the_BA_framework\">Examples and Priors in the BA framework</h2>\n<p>The mathematics can also reveal when an intuition pump is bringing extra information in a non-obvious way. For example, some of the <a href=\"/lw/745/why_we_cant_take_expected_value_estimates/\">examples</a> given for how the BA framework should run had the apparently unintuitive feature that successively larger claims of impact eventually lead to decreasing posterior means to the estimates. This turns out to be because the standard deviation of the estimates was presumed to be roughly equal to their mean.</p>\n<p>De facto this means that the new evidence was prohibited a prior from suggesting that an intervention was better than the prior mean with high probability. In general, this need not hold, if we are able to find data which is reasonably constrained and not present in the background model. If we intend to also account for the possibilities of errors in cognition, then this kind of treatment of new evidence seems more reasonable, but then we should see similar broadening in our background prior.</p>\n<p>Similarly, as the stated BA priors are normal or log-normal, they assert that the event E := \u201cthe range of intervention impact ratios is large\u201d has very low probability. Some decay is necessary to prevent arbitrarily large impacts dominating, which would make expected value computations fail to converge. Practically, this implies that a stated prior for impacts drops off faster than 1/impact\u00b3 above some impact<sup>2</sup>, but this does not in and of itself mandate a specific form of prior, not specify the point above which the prior should drop rapidly, nor the absolute rate of the drop off. In particular, the log-normal or normal prior drop off much faster, and so are implicitly very confident that the range of impacts is bounded by what we've already seen.</p>\n<p>&nbsp;</p>\n<h2 id=\"What_is_the_range_of_impacts_for_interventions_\">What is the range of impacts for interventions?</h2>\n<p>It is not trivial to find out what kinds of ratios we should expect to see; for these purposes it is unfortunate that Givewell does not publicly emit $/DALY or $/life estimates of impact for the majority of the charities it assesses. It would be very useful to see what kinds of impacts are being sampled at the low end. Other studies (eg. DCP2) have assessed some hundreds of high and low impact interventions in public health, and assert 10000:1 ratios in impact, with their best $/DALY numbers consistent with Givewell\u2019s assessment that AMF is likely to be one of the better public health interventions available.</p>\n<p>Of course, we also strongly suspect that there exist interventions with better impacts than AMF, if we are willing to look outside public health. Givewell raison d\u2019etre is that one can gain leverage in moving funds from ineffective causes to effective ones, and so a dollar spent on Givewell should move much more than a dollar to effective interventions. In principle this demonstrates that the range of possible intervention impacts may be much larger than the range available in specific fields, such as developing world health interventions.</p>\n<p>By the lights of the BA prior, we are uncharitable about an estimate of impact if we assert it is large, in that this makes the estimate incredulous and thus heavily discounted. In this sense, existential risk reduction has been sketchily and optimistically estimated at around $0.125/life, which we can take as an uncharitable estimate for the BA framework. Assuming that this was a correct estimate, it being true would only require the existence of an intervention which is to AMF as AMF is to the least effective health interventions. It does not seem easy to confidently assert that the tail thickness and variance of the distribution of intervention impacts is such that the apparently observed ratios in public health interventions and Givewell are common enough that they can be searched for whilst ruling out a priori the credibility of estimates at the &lt;$1/life level.</p>\n<p>Now, it might be possible that these very high impact interventions are not easy to scale up, &nbsp;or are rare enough that it is not worth searching for them. On the other hand, we can free-ride on other people recommending interventions, if we are willing to accept internal or inside view assessments as substantively credible.</p>\n<p>&nbsp;</p>\n<h2 id=\"Confidence_and_Probability\">Confidence and Probability</h2>\n<p>It seems clear that the probability of a proposition and one\u2019s confidence in the quality of your assessment are distinct, although it is easy to confuse language by referring to confidence in a proposition, rather than in a probability or estimate. Fully rigorously, this is encompassed in the distribution over X<sub>d</sub>, but in practise we may wish to track only a single posterior distribution<sup>3</sup>.</p>\n<p>Other commenters have <a href=\"/lw/745/why_we_cant_take_expected_value_estimates/4nzy\">suggested</a> a similar distinction between confidence and probability; observing that having observed the computations exist the correct response is to say \u201cI notice that I am confused\u201d. More formally, in practise we have neither P(x|C) nor P(x|E). We have to also condition on some event like:</p>\n<p style=\"padding-left: 30px;\">N := \"My modelling and computations are correct\".</p>\n<p>Ideally one would have extensive tests of all of the pieces of a methodology, so that one could say something about which classes of interventions are well modelled, but practically this may excessively complicate the issue. A priori, it seems unreasonable to attach &gt;&gt; 1-1/1000 probability to propositions like N for a new method or model which has merely been output by human cognition. Assessing high confidence would be expected to wait on assessing the reliability and calibration of the methodology, or showing that the model is a stable output of cognition.</p>\n<p>In the event of a computation and a point prior belief about interventions disagreeing, a Bayesian update will reduce confidence in N, and also come to believe that the processes leading to the estimate C are less reliable. This is separate to the process which causes you to extract beliefs about this particular intervention. Whether the background model is substantively changed or the estimation procedure is discounted is a matter for your relative confidence in these processes, and the sensitivity of the outputs of the processes.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conclusions\">Conclusions</h2>\n<p>Disagreements over how to estimate the impact of an intervention on the world have existed for some time, and it seems that the grounds for these disagreements are not being well addressed. In general, it would be a good thing for our grounds for confidence in arguments and background priors to be made very explicit and open. In principle we can then reduce these disagreements to matters of fact and differences in prior beliefs.</p>\n<p>In the particular case of Givewell, it is clear that they have assessed a great many interventions systematically, and seem to possess a great deal of confidence in their modelled backgrounds. I do not know if there has been a formal process of checking the calibration of these estimates; if there has been, and so Givewell can assess in high confidence (say \u00bb 10 bits) in propositions of form \u201cour model is emitting a suitable background correct for this class of interventions\u201d, then the methods are highly likely to be highly valuable to the wider EA community for other purposes, and ideally would be distributed.</p>\n<p>&nbsp;</p>\n<h2 id=\"Notes\">Notes</h2>\n<p>I wrote this post whilst a visiting fellow at MIRI; Lukeprog asked that I take a further look at LW's debates on cost effectiveness stability in effective altruism, and try to clarify the situation if possible.</p>\n<p>I am grateful to Carl Shulman, Luke Muehlhauser and Adam Casey for their substantive feedback and comments on early drafts of this post.</p>\n<p>&nbsp;</p>\n<p>1 To follow the modified mathematics of Jaynes' derivation closely, we amend 18-1 to read P(X = x|X<sub>d</sub>E) = d(x) for any distribution d, and then follow Jaynes\u2019 derivation formally. It is reasonable to be worried that the space of distributions is not measurable; this can be fixed by restricting to a sigma-algebra of functions which are piecewise constant (or alternatively running Jaynes' original approach on the set of binary propositions A<sub>yz</sub> := \"y \u2264 x \u2264 z\" for all y and z)</p>\n<p>2 We could also assert strong cancellation properties, but it is unclear whether these effects can be substantial in practise. Technically, we also could get convergence with drop offs like 1/(n\u00b2 log\u00b2 n) or&nbsp; 1/(n\u00b2 log n log\u00b2 log n), but the distinction is slight for the purposes of discussion; they are<em><strong> </strong>much</em> slower than a normal.</p>\n<p>3 If we work with the set of A<sub>xy</sub> propositions instead, then Jaynes implies we have to hold a set of distributions (A<sub>xy</sub>)<sub>p</sub>, which is rather more tractable than X<sub>d</sub>, although harder to visualise concretely.</p>", "sections": [{"title": "Bayesian Adjustment, and the Ap distribution", "anchor": "Bayesian_Adjustment__and_the_Ap_distribution", "level": 1}, {"title": "Examples and Priors in the BA framework", "anchor": "Examples_and_Priors_in_the_BA_framework", "level": 1}, {"title": "What is the range of impacts for interventions?", "anchor": "What_is_the_range_of_impacts_for_interventions_", "level": 1}, {"title": "Confidence and Probability", "anchor": "Confidence_and_Probability", "level": 1}, {"title": "Conclusions", "anchor": "Conclusions", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RdpqsQ6xbHzyckW9m", "QQo9N3WhZpL3ewii6", "WsmnfWTP28dXCKEy8", "9W9P2snxu5Px746LD", "8DHqN85vab54LjLrM", "K33mYmEk9LoTbN92L", "JyH7ezruQbC2iWcSg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-07T08:30:20.271Z", "modifiedAt": null, "url": null, "title": "Prisoner's Dilemma (with visible source code) Tournament", "slug": "prisoner-s-dilemma-with-visible-source-code-tournament", "viewCount": null, "lastCommentedAt": "2021-05-13T21:26:54.300Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BY8kvyuLzMZJkwTHL/prisoner-s-dilemma-with-visible-source-code-tournament", "pageUrlRelative": "/posts/BY8kvyuLzMZJkwTHL/prisoner-s-dilemma-with-visible-source-code-tournament", "linkUrl": "https://www.lesswrong.com/posts/BY8kvyuLzMZJkwTHL/prisoner-s-dilemma-with-visible-source-code-tournament", "postedAtFormatted": "Friday, June 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Prisoner's%20Dilemma%20(with%20visible%20source%20code)%20Tournament&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrisoner's%20Dilemma%20(with%20visible%20source%20code)%20Tournament%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBY8kvyuLzMZJkwTHL%2Fprisoner-s-dilemma-with-visible-source-code-tournament%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Prisoner's%20Dilemma%20(with%20visible%20source%20code)%20Tournament%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBY8kvyuLzMZJkwTHL%2Fprisoner-s-dilemma-with-visible-source-code-tournament", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBY8kvyuLzMZJkwTHL%2Fprisoner-s-dilemma-with-visible-source-code-tournament", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 647, "htmlBody": "<p style=\"margin-bottom: 0in\">After the <a href=\"/lw/7f2/prisoners_dilemma_tournament_results/\">iterated prisoner's dilemma tournament</a>&nbsp;organized by prase two years ago, there was discussion of running tournaments for several variants, including one in which two players submit programs, each of which are given the source code of the other player's program, and outputs either &ldquo;cooperate&rdquo; or &ldquo;defect&rdquo;. However, as far as I know, no such tournament has been run until now.</p>\n<p style=\"margin-bottom: 0in\">Here's how it's going to work: Each player will submit a file containing a single Scheme lambda-function. The function should take one input. Your program will play exactly one round against each other program submitted (not including itself). In each round, two programs will be run, each given the source code of the other as input, and will be expected to return either of the symbols &ldquo;C&rdquo; or &ldquo;D&rdquo; (for \"cooperate\" and \"defect\", respectively). The programs will receive points based on the following payoff matrix:</p>\n<p style=\"margin-bottom: 0in\"><img src=\"http://www.codecogs.com/png.latex?\\begin{array}{cccc}%20&amp;%20C%20&amp;%20D%20&amp;%20other\\\\%20C%20&amp;%20(2,\\,2)%20&amp;%20(0,\\,3)%20&amp;%20(0,\\,2)\\\\%20D%20&amp;%20(3,\\,0)%20&amp;%20(1,\\,1)%20&amp;%20(1,\\,0)\\\\%20other%20&amp;%20(2,\\,0)%20&amp;%20(0,\\,1)%20&amp;%20(0,\\,0)%20\\end{array}\" alt=\"\" width=\"215\" height=\"84\" /></p>\n<p style=\"margin-bottom: 0in\">&ldquo;Other&rdquo; includes any result other than returning &ldquo;C&rdquo; or &ldquo;D&rdquo;, including failing to terminate, throwing an exception, and even returning the string &ldquo;Cooperate&rdquo;. Notice that &ldquo;Other&rdquo; results in a worst-of-both-worlds scenario where you get the same payoff as you would have if you cooperated, but the other player gets the same payoff as if you had defected. This is an attempt to ensure that no one ever has incentive for their program to fail to run properly, or to trick another program into doing so.</p>\n<p style=\"margin-bottom: 0in\">Your score is the sum of the number of points you earn in each round. The player with the highest score wins the tournament. <strong>Edit: There is a <a href=\"/lw/hmx/prisoners_dilemma_with_visible_source_code/94no\">0.5 bitcoin prize</a> being offered for the winner. Thanks, VincentYu!</strong></p>\n<p style=\"margin-bottom: 0in\">Details:<br />All submissions must be emailed to <a href=\"mailto:wardenPD@gmail.com\">wardenPD@gmail.com</a> by July 5, at noon PDT (Edit: that's 19:00 UTC). Your email should also say how you would like to be identified when I announce the tournament results.<br />Each program will be allowed to run for 10 seconds. If it has not returned either &ldquo;C&rdquo; or &ldquo;D&rdquo; by then, it will be stopped, and treated as returning &ldquo;Other&rdquo;. For consistency, I will have Scheme collect garbage right before each run.<br />One submission per person or team. No person may contribute to more than one entry. <strong>Edit: This also means no copying from each others' source code. Describing the behavior of your program to others is okay.</strong><br />I will be running the submissions in Racket. You may be interested in how Racket handles <a href=\"http://docs.racket-lang.org/reference/time.html\">time</a>&nbsp;(especially the (current-milliseconds) function), <a href=\"http://docs.racket-lang.org/reference/threads.html\">threads</a>&nbsp;(in particular, &ldquo;thread&rdquo;, &ldquo;kill-thread&rdquo;, &ldquo;sleep&rdquo;, and &ldquo;thread-dead?&rdquo;), and possibly <a href=\"http://docs.racket-lang.org/reference/generic-numbers.html#%28def._%28%28quote._~23~25kernel%29._random%29%29\">randomness</a>.<br />Don't try to open the file you wrote your program in (or any other file, for that matter). I'll add code to the file before running it, so if you want your program to use a copy of your source code, you will need to use a quine. <strong>Edit: No I/O of any sort.</strong><br />Unless you tell me otherwise, I assume I have permission to publish your code after the contest.<br />You are encouraged to discuss strategies for achieving mutual cooperation in the comments thread.<br />I'm hoping to get as many entries as possible. If you know someone who might be interested in this, please tell them.<br />It's possible that I've said something stupid that I'll have to change or clarify, so you might want to come back to this page again occasionally to look for changes to the rules. Any edits will be bolded, and I'll try not to change anything too drastically, or make any edits late in the contest.</p>\n<p style=\"margin-bottom: 0in\">Here is an example of a correct entry, which cooperates with you if and only if you would cooperate with a program that always cooperates (actually, if and only if you would cooperate with one particular program that always cooperates):</p>\n<blockquote>\n<p style=\"margin-bottom: 0in;\">(lambda (x)<br />&nbsp; &nbsp; (if (eq? ((eval x) '(lambda (y) 'C)) 'C)<br />&nbsp; &nbsp; &nbsp; &nbsp; 'C<br />&nbsp; &nbsp; &nbsp; &nbsp; 'D))</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BY8kvyuLzMZJkwTHL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 50, "baseScore": 68, "extendedScore": null, "score": 0.000192, "legacy": true, "legacyId": "22857", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 69, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 236, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hamma4XgeNrsvAJv5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-07T08:30:25.557Z", "modifiedAt": null, "url": null, "title": "Robust Cooperation in the Prisoner's Dilemma", "slug": "robust-cooperation-in-the-prisoner-s-dilemma", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:07.061Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "orthonormal", "createdAt": "2009-03-22T16:06:51.665Z", "isAdmin": false, "displayName": "orthonormal"}, "userId": "4fh2AAe3n7oBviyxx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iQWk5jYeDg5ACCmpx/robust-cooperation-in-the-prisoner-s-dilemma", "pageUrlRelative": "/posts/iQWk5jYeDg5ACCmpx/robust-cooperation-in-the-prisoner-s-dilemma", "linkUrl": "https://www.lesswrong.com/posts/iQWk5jYeDg5ACCmpx/robust-cooperation-in-the-prisoner-s-dilemma", "postedAtFormatted": "Friday, June 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Robust%20Cooperation%20in%20the%20Prisoner's%20Dilemma&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARobust%20Cooperation%20in%20the%20Prisoner's%20Dilemma%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQWk5jYeDg5ACCmpx%2Frobust-cooperation-in-the-prisoner-s-dilemma%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Robust%20Cooperation%20in%20the%20Prisoner's%20Dilemma%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQWk5jYeDg5ACCmpx%2Frobust-cooperation-in-the-prisoner-s-dilemma", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiQWk5jYeDg5ACCmpx%2Frobust-cooperation-in-the-prisoner-s-dilemma", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2103, "htmlBody": "<p>I'm proud to announce the preprint of <a href=\"http://arxiv.org/abs/1401.5577\" target=\"_blank\">Robust Cooperation in the Prisoner's Dilemma: Program Equilibrium via Provability Logic</a>, a joint paper with Mihaly Barasz, Paul Christiano, Benja Fallenstein, Marcello Herreshoff, Patrick LaVictoire (me), and Eliezer Yudkowsky.</p>\n<p>This paper was one of three projects to come out of the <a href=\"http://intelligence.org/2013/03/07/upcoming-miri-research-workshops/\">2nd MIRI Workshop on Probability and Reflection</a> in April 2013, and had its genesis in ideas about formalizations of decision theory that have appeared on LessWrong. (At the end of this post, I'll include links for further reading.)</p>\n<p>Below, I'll briefly outline the problem we considered, the results we proved, and the (many) open questions that remain. Thanks in advance for your thoughts and suggestions!</p>\n<h2>Background: Writing programs to play the PD with source code swap</h2>\n<p>(If you're not familiar with the Prisoner's Dilemma, <a href=\"http://wiki.lesswrong.com/wiki/Prisoner's_dilemma\">see here.</a>)</p>\n<p>The paper concerns the following setup, <a href=\"/r/all/lw/duv/ai_cooperation_is_already_studied_in_academia_as/\">which has come up in academic research on game theory</a>: say that you have the chance to write a computer program <strong>X</strong>, which takes in one input and returns either <em>Cooperate</em> or <em>Defect</em>. This program will face off against some other computer program <strong>Y</strong>, but with a twist: <strong>X</strong> will receive the source code of <strong>Y</strong> as input, and <strong>Y</strong> will receive the source code of <strong>X</strong> as input. And you will be given your program's winnings, so you should think carefully about what sort of program you'd write!</p>\n<p>Of course, you could simply write a program that defects regardless of its input; we call this program <strong>DefectBot</strong>, and call the program that cooperates on all inputs <strong>CooperateBot</strong>. But with the wealth of information afforded by the setup, you might wonder if there's some program that might be able to achieve mutual cooperation in situations where <strong>DefectBot</strong> achieves mutual defection, without thereby risking a sucker's payoff. (Douglas Hofstadter would call this a perfect opportunity for <a href=\"http://www.gwern.net/docs/1985-hofstadter\">superrationality</a>...)</p>\n<h2>Previously known: CliqueBot and FairBot</h2>\n<p>And indeed, there's a way to do this that's been known since at least the 1980s. You can write <a href=\"http://en.wikipedia.org/wiki/Quine_(computing)\">a computer program that knows its own source code</a>, compares it to the input, and returns <em>C</em> if and only if the two are identical (and <em>D</em> otherwise). Thus it achieves mutual cooperation in one important case where it intuitively ought to: when playing against itself! We call this program <strong>CliqueBot</strong>, since it cooperates only with the \"clique\" of agents identical to itself.</p>\n<p>There's one particularly irksome issue with <strong>CliqueBot</strong>, and that's the fragility of its cooperation. If two people write functionally analogous but syntactically different versions of it, those programs will defect against one another! This problem can be patched somewhat, but not fully fixed. Moreover, mutual cooperation might be the best strategy against some agents that are not even functionally identical, and extending this approach requires you to explicitly delineate the list of programs that you're willing to cooperate with. Is there a more flexible and robust kind of program you could write instead?</p>\n<p>As it turns out, there is: <a href=\"/lw/2ip/ai_cooperation_in_practice/\">in a 2010 post on LessWrong</a>, cousin_it introduced an algorithm that we now call <strong>FairBot</strong>. Given the source code of <strong>Y</strong>, <strong>FairBot</strong> searches for a proof (of less than some large fixed length) that <strong>Y</strong> returns <em>C</em> when given the source code of <strong>FairBot</strong>, and then returns <em>C</em> if and only if it discovers such a proof (otherwise it returns <em>D</em>). Clearly, if our proof system is consistent, <strong>FairBot</strong> only cooperates when that cooperation will be mutual. But the really fascinating thing is what happens when you play two versions of <strong>FairBot</strong> against each other. Intuitively, it seems that <em>either</em> mutual cooperation or mutual defection would be stable outcomes, but it turns out that if their limits on proof lengths are sufficiently high, they will achieve mutual cooperation!</p>\n<p>The proof that they mutually cooperate follows from a bounded version of <a href=\"http://en.wikipedia.org/wiki/L%C3%B6b's_theorem\">L&ouml;b's Theorem</a>&nbsp;from mathematical logic. (If you're not familiar with this result, you might enjoy <a href=\"/lw/t6/the_cartoon_guide_to_l%C3%B6bs_theorem/\">Eliezer's Cartoon Guide to L&ouml;b's Theorem</a>, which is a correct formal proof written in much more intuitive notation.) Essentially, the asymmetry comes from the fact that both programs are searching for the same outcome, so that a short proof that one of them cooperates leads to a short proof that the other cooperates, and vice versa. (The opposite is not true, because <a href=\"/lw/t8/you_provably_cant_trust_yourself/\">the formal system can't know it won't find a contradiction</a>. This is a subtle but essential feature of mathematical logic!)</p>\n<h2>Generalization: Modal Agents</h2>\n<p>Unfortunately, <strong>FairBot</strong> isn't what I'd consider an ideal program to write: it happily cooperates with <strong>CooperateBot</strong>, when it could do better by defecting. This&nbsp;is problematic because in real life, the world isn't separated into agents and non-agents, and any natural phenomenon that doesn't predict your actions can be thought of as a&nbsp;<strong>CooperateBot</strong>&nbsp;(or a&nbsp;<strong>DefectBot</strong>). You don't want your agent to be making concessions to rocks that happened not to fall on them. (There's an important caveat: some things have utility functions that you care about, but don't have sufficient ability to predicate their actions on yours. In that case, though, it&nbsp;<a href=\"/lw/tn/the_true_prisoners_dilemma/\">wouldn't be a true Prisoner's Dilemma</a>&nbsp;if your values actually prefer the outcome (<em>C</em>,<em>C</em>) to (<em>D</em>,<em>C</em>).)</p>\n<p>However, <strong>FairBot</strong> belongs to a promising class of algorithms: those that decide on their action by looking for short proofs of logical statements that concern their opponent's actions. In fact, there's a really convenient mathematical structure that's analogous to the class of such algorithms: the <a href=\"http://plato.stanford.edu/entries/logic-provability/\">modal logic of provability</a> (known as GL, for G&ouml;del-L&ouml;b).</p>\n<p>So that's the subject of this preprint: <strong>what can we achieve in decision theory by considering agents defined by formulas of provability logic?</strong><a id=\"more\"></a></p>\n<p>More formally <em>(skip the next two paragraphs if you're willing to trust me)</em>, we inductively define the class of \"modal agents\" as formulas using propositional variables and <a href=\"http://en.wikipedia.org/wiki/Logical_connective\">logical connectives</a> and the modal operator&nbsp;<img src=\"http://www.codecogs.com/png.latex?\\Box\" alt=\"\" />&nbsp;<span style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px;\">(which represents provability in some base-level formal system like Peano Arithmetic), of the form&nbsp;<img src=\"http://www.codecogs.com/png.latex?P\\leftrightarrow \\varphi(P,Q,R_1,\\dots,R_N)\" alt=\"\" />, where&nbsp;<img src=\"http://www.codecogs.com/png.latex?\\varphi\" alt=\"\" width=\"12\" height=\"15\" />&nbsp;is fully modalized (i.e. all instances of variables are contained in an expression&nbsp;<img src=\"http://www.codecogs.com/png.latex?\\Box\\psi\" alt=\"\" />), and with each&nbsp;<img src=\"http://www.codecogs.com/png.latex?R_i\" alt=\"\" width=\"18\" height=\"16\" />&nbsp;corresponding to a fixed modal agent of lower rank. For example, <strong>FairBot</strong> is represented by the modal formula&nbsp;<img src=\"http://www.codecogs.com/png.latex?P\\leftrightarrow \\Box Q\" alt=\"\" />.</span></p>\n<p><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px;\">When two modal agents play against each other, the outcome is given by the unique fixed point of the system of modal statements, where the variables are identified with each other so that&nbsp;<img src=\"http://www.codecogs.com/png.latex?P\" alt=\"\" width=\"14\" height=\"13\" />&nbsp;represents the expression&nbsp;<img src=\"http://www.codecogs.com/png.latex?X(Y)=C\" alt=\"\" width=\"83\" height=\"19\" />,&nbsp;<img src=\"http://www.codecogs.com/png.latex?Q\" alt=\"\" width=\"15\" height=\"18\" />&nbsp;represents&nbsp;<img src=\"http://www.codecogs.com/png.latex?Y(X)=C\" alt=\"\" width=\"83\" height=\"19\" />, and the&nbsp;<img src=\"http://www.codecogs.com/png.latex?R_i\" alt=\"\" width=\"18\" height=\"16\" />&nbsp;represent the actions of lower-rank modal agents against&nbsp;<img src=\"http://www.codecogs.com/png.latex?Y\" alt=\"\" width=\"14\" height=\"13\" />&nbsp;and vice-versa. (Modal rank is defined as a natural number, so this always bottoms out in a finite number of modal statements; also, we interpret outcomes as statements of provability in Peano Arithmetic, evaluated in the model where PA is consistent, PA+Con(PA) is consistent, and so on. See the paper for the actual details.)</span></p>\n<p><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px;\">The nice part about modal agents is that there are <a href=\"http://en.wikipedia.org/wiki/Kripke_semantics\">simple tools</a> for finding the fixed points without having to search through proofs; in fact, Mihaly and Marcello wrote up a computer program to deduce the outcome of the source-code-swap Prisoner's Dilemma between any two (reasonably simple) modal agents. These tools also made it much easier to prove general theorems about such agents.</span></p>\n<h2>PrudentBot: The best of both worlds?</h2>\n<p>Can we find a modal agent that seems to improve on <strong>FairBot</strong>? In particular, we should want at least the following properties:</p>\n<ul>\n<li>It should be un-exploitable: if our axioms are consistent in the first place, then it had better only end up cooperating when it's mutual.</li>\n<li>It should cooperate with itself, and also mutually cooperate with <strong>FairBot</strong> (both are, common-sensically, the best actions in those cases).</li>\n<li>It should defect, however, against <strong>CooperateBot</strong> and lots of similarly exploitable modal agents.</li>\n</ul>\n<p>It's nontrivial that such an agent exists: you may remember the post I wrote about&nbsp;<a href=\"/lw/ebx/decision_theories_part_375_hang_on_i_think_this/\">the Masquerade agent</a>, which is a modal agent that does <em>almost</em> all of those things (it doesn't cooperate with the original <strong>FairBot</strong>, though it does cooperate with some more complicated variants), and indeed we didn't find anything better until after we had Mihaly and Marcello's modal-agent-evaluator to help us.</p>\n<p>But as it turns out, there is such an agent, and it's pretty elegant: we call it <strong>PrudentBot</strong>, and its modal version cooperates with another agent <strong>Y</strong> if and only if (there's a proof in Peano Arithmetic that <strong>Y</strong> cooperates with <strong>PrudentBot</strong> and there's a proof in PA+Con(PA) that <strong>Y</strong> defects against <strong>DefectBot</strong>). This agent can be seen to satisfy all of our criteria. But is it <em>optimal</em> among modal agents, by any reasonable criterion?</p>\n<h2>Results: Obstacles to Optimality</h2>\n<p>It turns out that, even within the class of modal agents, it's hard to formulate a definition of optimality that's actually true of something, and which meaningfully corresponds to our intuitions about the \"right\" decisions on decision-theoretic problems. (This intuition is not formally defined, so I'm using scare quotes.)</p>\n<p>There are agents that give preferential treatment to <strong>DefectBot</strong>, <strong>FairBot</strong>, or even <strong>CooperateBot</strong>, compared to <strong>PrudentBot</strong>, though these agents are not ones you'd program in an attempt to win at the Prisoner's Dilemma. (For instance, one agent that rewards <strong>CooperateBot&nbsp;</strong>over <strong>PrudentBot</strong> is the agent that cooperates with <strong>Y</strong> iff PA proves that <strong>Y</strong> cooperates against <strong>DefectBot</strong>; we've taken to jokingly calling that agent <strong>TrollBot</strong>.) One might well suppose that a modal agent could still be optimal in the sense of making the \"right\" decision in every case, regardless of whether it's being punished for some other decision. However, this is not the only obstacle to a useful concept of optimality.</p>\n<p>The second obstacle is that any modal agent only checks proofs at some finite number of levels on the hierarchy of formal systems, and agents that appear indistinguishable at all those levels may have obviously different \"right\" decisions. And thirdly, an agent might mimic another agent in such a way that the \"right\" decision is to treat the mimic differently from the agent it imitates, but in some cases one can prove that no modal agent can treat the two differently.</p>\n<p>These three strikes appear to indicate that if we're looking to formalize <a href=\"http://wiki.lesswrong.com/wiki/Decision_theory\">more advanced decision theories</a>, modal agents are too restrictive of a class to work with. We might instead allow things like quantifiers over agents, which would invalidate these specific obstacles, but may well introduce new ones (and certainly would make for more complicated proofs). But for a \"good enough\" algorithm on the original problem (assuming that the computer will have lots of computational resources), one could definitely do worse than submit a finite version of <strong>PrudentBot</strong>.</p>\n<h2>Why is this awesome, and what's next?</h2>\n<p>In my opinion, the result of L&ouml;bian cooperation deserves to be published for its illustration of Hofstadterian superrationality in action, apart from anything else! It's <em>really cool</em> that two agents reasoning about each other can in theory come to mutual cooperation for genuine reasons that don't have to involve being clones of each other (or other anthropic dodges). It's a far cry from a practical approach, of course, but it's a start: mathematicians always begin with a simplified and artificial model to see what happens, then add complications one at a time.</p>\n<p>As for what's next: First, we don't <em>actually</em> know that there's no meaningful non-vacuous concept of optimality for modal agents; it would be nice to know that one way or another. Secondly, we'd like to see if some other class of agents contains a simple example with really nice properties (the way that classical game theory doesn't always have a pure Nash equilibrium, but always has a mixed one). Thirdly, we might hope that there's an actual implementation of a decision theory (<a href=\"http://wiki.lesswrong.com/wiki/Timeless_decision_theory\">TDT</a>, <a href=\"http://wiki.lesswrong.com/wiki/Updateless_decision_theory\">UDT</a>, etc) in the context of program equilibrium.</p>\n<p>If we succeed in the positive direction on any of those, we'd next want to extend them in several important ways: using probabilistic information rather than certainty, considering more general games than the Prisoner's Dilemma (bargaining games have many further challenges, and games of more than two players could be more convoluted still), etc. I personally hope to work on such topics in future MIRI workshops.</p>\n<h2>Further Reading on LessWrong</h2>\n<p>Here are some LessWrong posts that have tackled similar material to the preprint:</p>\n<ul>\n<li><a href=\"/lw/2ip/ai_cooperation_in_practice/\">AI cooperation in practice</a>, cousin_it, 2010</li>\n<li><a href=\"/lw/2tq/notion_of_preference_in_ambient_control/\">Notion of Preference in Ambient Control</a>, Vladimir_Nesov, 2010</li>\n<li><a href=\"/lw/8wc/a_model_of_udt_with_a_halting_oracle/\">A model of UDT with a halting oracle</a>, cousin_it, 2011</li>\n<li><a href=\"/lw/9o7/formulas_of_arithmetic_that_behave_like_decision/\">Formulas of arithmetic that behave like decision agents</a>, Nisan, 2012</li>\n<li><a href=\"/lw/b0e/a_model_of_udt_without_proof_limits/\">A model of UDT without proof limits</a>, <a href=\"/lw/b5t/an_example_of_selffulfilling_spurious_proofs_in/\">An example of self-fulfilling spurious proofs in UDT</a>, <a href=\"/lw/crx/loebian_cooperation_version_2/\">L&ouml;bian cooperation, version 2</a>, <a href=\"/lw/dba/bounded_versions_of_g%C3%B6dels_and_l%C3%B6bs_theorems/\">Bounded versions of G&ouml;del's and L&ouml;b's theorems</a>, cousin_it, 2012</li>\n<li><a href=\"/lw/ap3/predictability_of_decisions_and_the_diagonal/\">Predictability of decisions and the diagonal method</a>, <a href=\"/lw/ca5/consequentialist_formal_systems/\">Consequentialist formal systems</a>, Vladimir_Nesov, 2012</li>\n<li>Decision Theories: A Semi-Formal Analysis: <a href=\"/lw/aq9/decision_theories_a_less_wrong_primer/\">Part 0 (A LessWrong Primer)</a>, <a href=\"/lw/axl/decision_theories_a_semiformal_analysis_part_i\">Part 1 (The Problem with Naive Decision Theory)</a>, <a href=\"/lw/az6/decision_theories_a_semiformal_analysis_part_ii/\">Part 2 (Causal Decision Theory and Substitution)</a>, <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">Part 3 (Formalizing Timeless Decision Theory)</a>, <a href=\"/lw/e94/decision_theories_part_35_halt_melt_and_catch_fire/\">Part 3.5 (Halt, Melt, and Catch Fire)</a>, <a href=\"/lw/ebx/decision_theories_part_375_hang_on_i_think_this/\">Part 3.75 (Hang On, I Think This Works After All)</a>, orthonormal, 2012</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 4, "chuP2QqQycjD8qakL": 2, "be2Mh2bddQ6ZaBcti": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iQWk5jYeDg5ACCmpx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 77, "baseScore": 115, "extendedScore": null, "score": 0.000273, "legacy": true, "legacyId": "22856", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 116, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I'm proud to announce the preprint of <a href=\"http://arxiv.org/abs/1401.5577\" target=\"_blank\">Robust Cooperation in the Prisoner's Dilemma: Program Equilibrium via Provability Logic</a>, a joint paper with Mihaly Barasz, Paul Christiano, Benja Fallenstein, Marcello Herreshoff, Patrick LaVictoire (me), and Eliezer Yudkowsky.</p>\n<p>This paper was one of three projects to come out of the <a href=\"http://intelligence.org/2013/03/07/upcoming-miri-research-workshops/\">2nd MIRI Workshop on Probability and Reflection</a> in April 2013, and had its genesis in ideas about formalizations of decision theory that have appeared on LessWrong. (At the end of this post, I'll include links for further reading.)</p>\n<p>Below, I'll briefly outline the problem we considered, the results we proved, and the (many) open questions that remain. Thanks in advance for your thoughts and suggestions!</p>\n<h2 id=\"Background__Writing_programs_to_play_the_PD_with_source_code_swap\">Background: Writing programs to play the PD with source code swap</h2>\n<p>(If you're not familiar with the Prisoner's Dilemma, <a href=\"http://wiki.lesswrong.com/wiki/Prisoner's_dilemma\">see here.</a>)</p>\n<p>The paper concerns the following setup, <a href=\"/r/all/lw/duv/ai_cooperation_is_already_studied_in_academia_as/\">which has come up in academic research on game theory</a>: say that you have the chance to write a computer program <strong>X</strong>, which takes in one input and returns either <em>Cooperate</em> or <em>Defect</em>. This program will face off against some other computer program <strong>Y</strong>, but with a twist: <strong>X</strong> will receive the source code of <strong>Y</strong> as input, and <strong>Y</strong> will receive the source code of <strong>X</strong> as input. And you will be given your program's winnings, so you should think carefully about what sort of program you'd write!</p>\n<p>Of course, you could simply write a program that defects regardless of its input; we call this program <strong>DefectBot</strong>, and call the program that cooperates on all inputs <strong>CooperateBot</strong>. But with the wealth of information afforded by the setup, you might wonder if there's some program that might be able to achieve mutual cooperation in situations where <strong>DefectBot</strong> achieves mutual defection, without thereby risking a sucker's payoff. (Douglas Hofstadter would call this a perfect opportunity for <a href=\"http://www.gwern.net/docs/1985-hofstadter\">superrationality</a>...)</p>\n<h2 id=\"Previously_known__CliqueBot_and_FairBot\">Previously known: CliqueBot and FairBot</h2>\n<p>And indeed, there's a way to do this that's been known since at least the 1980s. You can write <a href=\"http://en.wikipedia.org/wiki/Quine_(computing)\">a computer program that knows its own source code</a>, compares it to the input, and returns <em>C</em> if and only if the two are identical (and <em>D</em> otherwise). Thus it achieves mutual cooperation in one important case where it intuitively ought to: when playing against itself! We call this program <strong>CliqueBot</strong>, since it cooperates only with the \"clique\" of agents identical to itself.</p>\n<p>There's one particularly irksome issue with <strong>CliqueBot</strong>, and that's the fragility of its cooperation. If two people write functionally analogous but syntactically different versions of it, those programs will defect against one another! This problem can be patched somewhat, but not fully fixed. Moreover, mutual cooperation might be the best strategy against some agents that are not even functionally identical, and extending this approach requires you to explicitly delineate the list of programs that you're willing to cooperate with. Is there a more flexible and robust kind of program you could write instead?</p>\n<p>As it turns out, there is: <a href=\"/lw/2ip/ai_cooperation_in_practice/\">in a 2010 post on LessWrong</a>, cousin_it introduced an algorithm that we now call <strong>FairBot</strong>. Given the source code of <strong>Y</strong>, <strong>FairBot</strong> searches for a proof (of less than some large fixed length) that <strong>Y</strong> returns <em>C</em> when given the source code of <strong>FairBot</strong>, and then returns <em>C</em> if and only if it discovers such a proof (otherwise it returns <em>D</em>). Clearly, if our proof system is consistent, <strong>FairBot</strong> only cooperates when that cooperation will be mutual. But the really fascinating thing is what happens when you play two versions of <strong>FairBot</strong> against each other. Intuitively, it seems that <em>either</em> mutual cooperation or mutual defection would be stable outcomes, but it turns out that if their limits on proof lengths are sufficiently high, they will achieve mutual cooperation!</p>\n<p>The proof that they mutually cooperate follows from a bounded version of <a href=\"http://en.wikipedia.org/wiki/L%C3%B6b's_theorem\">L\u00f6b's Theorem</a>&nbsp;from mathematical logic. (If you're not familiar with this result, you might enjoy <a href=\"/lw/t6/the_cartoon_guide_to_l%C3%B6bs_theorem/\">Eliezer's Cartoon Guide to L\u00f6b's Theorem</a>, which is a correct formal proof written in much more intuitive notation.) Essentially, the asymmetry comes from the fact that both programs are searching for the same outcome, so that a short proof that one of them cooperates leads to a short proof that the other cooperates, and vice versa. (The opposite is not true, because <a href=\"/lw/t8/you_provably_cant_trust_yourself/\">the formal system can't know it won't find a contradiction</a>. This is a subtle but essential feature of mathematical logic!)</p>\n<h2 id=\"Generalization__Modal_Agents\">Generalization: Modal Agents</h2>\n<p>Unfortunately, <strong>FairBot</strong> isn't what I'd consider an ideal program to write: it happily cooperates with <strong>CooperateBot</strong>, when it could do better by defecting. This&nbsp;is problematic because in real life, the world isn't separated into agents and non-agents, and any natural phenomenon that doesn't predict your actions can be thought of as a&nbsp;<strong>CooperateBot</strong>&nbsp;(or a&nbsp;<strong>DefectBot</strong>). You don't want your agent to be making concessions to rocks that happened not to fall on them. (There's an important caveat: some things have utility functions that you care about, but don't have sufficient ability to predicate their actions on yours. In that case, though, it&nbsp;<a href=\"/lw/tn/the_true_prisoners_dilemma/\">wouldn't be a true Prisoner's Dilemma</a>&nbsp;if your values actually prefer the outcome (<em>C</em>,<em>C</em>) to (<em>D</em>,<em>C</em>).)</p>\n<p>However, <strong>FairBot</strong> belongs to a promising class of algorithms: those that decide on their action by looking for short proofs of logical statements that concern their opponent's actions. In fact, there's a really convenient mathematical structure that's analogous to the class of such algorithms: the <a href=\"http://plato.stanford.edu/entries/logic-provability/\">modal logic of provability</a> (known as GL, for G\u00f6del-L\u00f6b).</p>\n<p>So that's the subject of this preprint: <strong>what can we achieve in decision theory by considering agents defined by formulas of provability logic?</strong><a id=\"more\"></a></p>\n<p>More formally <em>(skip the next two paragraphs if you're willing to trust me)</em>, we inductively define the class of \"modal agents\" as formulas using propositional variables and <a href=\"http://en.wikipedia.org/wiki/Logical_connective\">logical connectives</a> and the modal operator&nbsp;<img src=\"http://www.codecogs.com/png.latex?\\Box\" alt=\"\">&nbsp;<span style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px;\">(which represents provability in some base-level formal system like Peano Arithmetic), of the form&nbsp;<img src=\"http://www.codecogs.com/png.latex?P\\leftrightarrow \\varphi(P,Q,R_1,\\dots,R_N)\" alt=\"\">, where&nbsp;<img src=\"http://www.codecogs.com/png.latex?\\varphi\" alt=\"\" width=\"12\" height=\"15\">&nbsp;is fully modalized (i.e. all instances of variables are contained in an expression&nbsp;<img src=\"http://www.codecogs.com/png.latex?\\Box\\psi\" alt=\"\">), and with each&nbsp;<img src=\"http://www.codecogs.com/png.latex?R_i\" alt=\"\" width=\"18\" height=\"16\">&nbsp;corresponding to a fixed modal agent of lower rank. For example, <strong>FairBot</strong> is represented by the modal formula&nbsp;<img src=\"http://www.codecogs.com/png.latex?P\\leftrightarrow \\Box Q\" alt=\"\">.</span></p>\n<p><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px;\">When two modal agents play against each other, the outcome is given by the unique fixed point of the system of modal statements, where the variables are identified with each other so that&nbsp;<img src=\"http://www.codecogs.com/png.latex?P\" alt=\"\" width=\"14\" height=\"13\">&nbsp;represents the expression&nbsp;<img src=\"http://www.codecogs.com/png.latex?X(Y)=C\" alt=\"\" width=\"83\" height=\"19\">,&nbsp;<img src=\"http://www.codecogs.com/png.latex?Q\" alt=\"\" width=\"15\" height=\"18\">&nbsp;represents&nbsp;<img src=\"http://www.codecogs.com/png.latex?Y(X)=C\" alt=\"\" width=\"83\" height=\"19\">, and the&nbsp;<img src=\"http://www.codecogs.com/png.latex?R_i\" alt=\"\" width=\"18\" height=\"16\">&nbsp;represent the actions of lower-rank modal agents against&nbsp;<img src=\"http://www.codecogs.com/png.latex?Y\" alt=\"\" width=\"14\" height=\"13\">&nbsp;and vice-versa. (Modal rank is defined as a natural number, so this always bottoms out in a finite number of modal statements; also, we interpret outcomes as statements of provability in Peano Arithmetic, evaluated in the model where PA is consistent, PA+Con(PA) is consistent, and so on. See the paper for the actual details.)</span></p>\n<p><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px;\">The nice part about modal agents is that there are <a href=\"http://en.wikipedia.org/wiki/Kripke_semantics\">simple tools</a> for finding the fixed points without having to search through proofs; in fact, Mihaly and Marcello wrote up a computer program to deduce the outcome of the source-code-swap Prisoner's Dilemma between any two (reasonably simple) modal agents. These tools also made it much easier to prove general theorems about such agents.</span></p>\n<h2 id=\"PrudentBot__The_best_of_both_worlds_\">PrudentBot: The best of both worlds?</h2>\n<p>Can we find a modal agent that seems to improve on <strong>FairBot</strong>? In particular, we should want at least the following properties:</p>\n<ul>\n<li>It should be un-exploitable: if our axioms are consistent in the first place, then it had better only end up cooperating when it's mutual.</li>\n<li>It should cooperate with itself, and also mutually cooperate with <strong>FairBot</strong> (both are, common-sensically, the best actions in those cases).</li>\n<li>It should defect, however, against <strong>CooperateBot</strong> and lots of similarly exploitable modal agents.</li>\n</ul>\n<p>It's nontrivial that such an agent exists: you may remember the post I wrote about&nbsp;<a href=\"/lw/ebx/decision_theories_part_375_hang_on_i_think_this/\">the Masquerade agent</a>, which is a modal agent that does <em>almost</em> all of those things (it doesn't cooperate with the original <strong>FairBot</strong>, though it does cooperate with some more complicated variants), and indeed we didn't find anything better until after we had Mihaly and Marcello's modal-agent-evaluator to help us.</p>\n<p>But as it turns out, there is such an agent, and it's pretty elegant: we call it <strong>PrudentBot</strong>, and its modal version cooperates with another agent <strong>Y</strong> if and only if (there's a proof in Peano Arithmetic that <strong>Y</strong> cooperates with <strong>PrudentBot</strong> and there's a proof in PA+Con(PA) that <strong>Y</strong> defects against <strong>DefectBot</strong>). This agent can be seen to satisfy all of our criteria. But is it <em>optimal</em> among modal agents, by any reasonable criterion?</p>\n<h2 id=\"Results__Obstacles_to_Optimality\">Results: Obstacles to Optimality</h2>\n<p>It turns out that, even within the class of modal agents, it's hard to formulate a definition of optimality that's actually true of something, and which meaningfully corresponds to our intuitions about the \"right\" decisions on decision-theoretic problems. (This intuition is not formally defined, so I'm using scare quotes.)</p>\n<p>There are agents that give preferential treatment to <strong>DefectBot</strong>, <strong>FairBot</strong>, or even <strong>CooperateBot</strong>, compared to <strong>PrudentBot</strong>, though these agents are not ones you'd program in an attempt to win at the Prisoner's Dilemma. (For instance, one agent that rewards <strong>CooperateBot&nbsp;</strong>over <strong>PrudentBot</strong> is the agent that cooperates with <strong>Y</strong> iff PA proves that <strong>Y</strong> cooperates against <strong>DefectBot</strong>; we've taken to jokingly calling that agent <strong>TrollBot</strong>.) One might well suppose that a modal agent could still be optimal in the sense of making the \"right\" decision in every case, regardless of whether it's being punished for some other decision. However, this is not the only obstacle to a useful concept of optimality.</p>\n<p>The second obstacle is that any modal agent only checks proofs at some finite number of levels on the hierarchy of formal systems, and agents that appear indistinguishable at all those levels may have obviously different \"right\" decisions. And thirdly, an agent might mimic another agent in such a way that the \"right\" decision is to treat the mimic differently from the agent it imitates, but in some cases one can prove that no modal agent can treat the two differently.</p>\n<p>These three strikes appear to indicate that if we're looking to formalize <a href=\"http://wiki.lesswrong.com/wiki/Decision_theory\">more advanced decision theories</a>, modal agents are too restrictive of a class to work with. We might instead allow things like quantifiers over agents, which would invalidate these specific obstacles, but may well introduce new ones (and certainly would make for more complicated proofs). But for a \"good enough\" algorithm on the original problem (assuming that the computer will have lots of computational resources), one could definitely do worse than submit a finite version of <strong>PrudentBot</strong>.</p>\n<h2 id=\"Why_is_this_awesome__and_what_s_next_\">Why is this awesome, and what's next?</h2>\n<p>In my opinion, the result of L\u00f6bian cooperation deserves to be published for its illustration of Hofstadterian superrationality in action, apart from anything else! It's <em>really cool</em> that two agents reasoning about each other can in theory come to mutual cooperation for genuine reasons that don't have to involve being clones of each other (or other anthropic dodges). It's a far cry from a practical approach, of course, but it's a start: mathematicians always begin with a simplified and artificial model to see what happens, then add complications one at a time.</p>\n<p>As for what's next: First, we don't <em>actually</em> know that there's no meaningful non-vacuous concept of optimality for modal agents; it would be nice to know that one way or another. Secondly, we'd like to see if some other class of agents contains a simple example with really nice properties (the way that classical game theory doesn't always have a pure Nash equilibrium, but always has a mixed one). Thirdly, we might hope that there's an actual implementation of a decision theory (<a href=\"http://wiki.lesswrong.com/wiki/Timeless_decision_theory\">TDT</a>, <a href=\"http://wiki.lesswrong.com/wiki/Updateless_decision_theory\">UDT</a>, etc) in the context of program equilibrium.</p>\n<p>If we succeed in the positive direction on any of those, we'd next want to extend them in several important ways: using probabilistic information rather than certainty, considering more general games than the Prisoner's Dilemma (bargaining games have many further challenges, and games of more than two players could be more convoluted still), etc. I personally hope to work on such topics in future MIRI workshops.</p>\n<h2 id=\"Further_Reading_on_LessWrong\">Further Reading on LessWrong</h2>\n<p>Here are some LessWrong posts that have tackled similar material to the preprint:</p>\n<ul>\n<li><a href=\"/lw/2ip/ai_cooperation_in_practice/\">AI cooperation in practice</a>, cousin_it, 2010</li>\n<li><a href=\"/lw/2tq/notion_of_preference_in_ambient_control/\">Notion of Preference in Ambient Control</a>, Vladimir_Nesov, 2010</li>\n<li><a href=\"/lw/8wc/a_model_of_udt_with_a_halting_oracle/\">A model of UDT with a halting oracle</a>, cousin_it, 2011</li>\n<li><a href=\"/lw/9o7/formulas_of_arithmetic_that_behave_like_decision/\">Formulas of arithmetic that behave like decision agents</a>, Nisan, 2012</li>\n<li><a href=\"/lw/b0e/a_model_of_udt_without_proof_limits/\">A model of UDT without proof limits</a>, <a href=\"/lw/b5t/an_example_of_selffulfilling_spurious_proofs_in/\">An example of self-fulfilling spurious proofs in UDT</a>, <a href=\"/lw/crx/loebian_cooperation_version_2/\">L\u00f6bian cooperation, version 2</a>, <a href=\"/lw/dba/bounded_versions_of_g%C3%B6dels_and_l%C3%B6bs_theorems/\">Bounded versions of G\u00f6del's and L\u00f6b's theorems</a>, cousin_it, 2012</li>\n<li><a href=\"/lw/ap3/predictability_of_decisions_and_the_diagonal/\">Predictability of decisions and the diagonal method</a>, <a href=\"/lw/ca5/consequentialist_formal_systems/\">Consequentialist formal systems</a>, Vladimir_Nesov, 2012</li>\n<li>Decision Theories: A Semi-Formal Analysis: <a href=\"/lw/aq9/decision_theories_a_less_wrong_primer/\">Part 0 (A LessWrong Primer)</a>, <a href=\"/lw/axl/decision_theories_a_semiformal_analysis_part_i\">Part 1 (The Problem with Naive Decision Theory)</a>, <a href=\"/lw/az6/decision_theories_a_semiformal_analysis_part_ii/\">Part 2 (Causal Decision Theory and Substitution)</a>, <a href=\"/lw/b7w/decision_theories_a_semiformal_analysis_part_iii/\">Part 3 (Formalizing Timeless Decision Theory)</a>, <a href=\"/lw/e94/decision_theories_part_35_halt_melt_and_catch_fire/\">Part 3.5 (Halt, Melt, and Catch Fire)</a>, <a href=\"/lw/ebx/decision_theories_part_375_hang_on_i_think_this/\">Part 3.75 (Hang On, I Think This Works After All)</a>, orthonormal, 2012</li>\n</ul>", "sections": [{"title": "Background: Writing programs to play the PD with source code swap", "anchor": "Background__Writing_programs_to_play_the_PD_with_source_code_swap", "level": 1}, {"title": "Previously known: CliqueBot and FairBot", "anchor": "Previously_known__CliqueBot_and_FairBot", "level": 1}, {"title": "Generalization: Modal Agents", "anchor": "Generalization__Modal_Agents", "level": 1}, {"title": "PrudentBot: The best of both worlds?", "anchor": "PrudentBot__The_best_of_both_worlds_", "level": 1}, {"title": "Results: Obstacles to Optimality", "anchor": "Results__Obstacles_to_Optimality", "level": 1}, {"title": "Why is this awesome, and what's next?", "anchor": "Why_is_this_awesome__and_what_s_next_", "level": 1}, {"title": "Further Reading on LessWrong", "anchor": "Further_Reading_on_LessWrong", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "146 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 146, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XkNXsi6bsxxFaL5FL", "TNfx89dh5KkcKrvho", "ALCnqX6Xx8bpFMZq3", "rm8tv9qZ9nwQxhshx", "HFyWNBnDNEDsDNLrZ", "X9vT3o3MmtWoRRKkm", "ZpATmvAyqajiA5XNC", "Bj244uWzDBXvE2N2S", "yX9pMZik7r38da7Fc", "m39dkp73YhN9QKYb9", "2GebvAXXfRMTjY2g7", "B64CZks9sb3PmgxXK", "z7SuGwxTBnQm8uFq4", "W6T93dSSm2xvHn9X6", "JGwD6zkhtXjCHjNn9", "af9MjBqF2hgu3EN6r", "2JdvZw3CXzafxQugN", "TxDcvtn2teAMobG2Z", "AMwzjjvFxEgxvL7xe", "ShD7EHb4HmPgfveim"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 14, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-07T15:26:09.241Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-50", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F42JLyeBd5dfhRDGu/weekly-lw-meetups-50", "pageUrlRelative": "/posts/F42JLyeBd5dfhRDGu/weekly-lw-meetups-50", "linkUrl": "https://www.lesswrong.com/posts/F42JLyeBd5dfhRDGu/weekly-lw-meetups-50", "postedAtFormatted": "Friday, June 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF42JLyeBd5dfhRDGu%2Fweekly-lw-meetups-50%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF42JLyeBd5dfhRDGu%2Fweekly-lw-meetups-50", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF42JLyeBd5dfhRDGu%2Fweekly-lw-meetups-50", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 536, "htmlBody": "<p><strong>This summary was posted to LW Main on May 31st. The following week's summary is <a href=\"/lw/hnp/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a href=\"/meetups/n6\">Atlanta LessWrong June Meetup: Effective Altruism:&nbsp;<span class=\"date\">15 June 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n<li><a href=\"/meetups/na\">[Boston] The Science Of Happiness:&nbsp;<span class=\"date\">02 June 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/ne\">Brussels meetup with Cat:&nbsp;<span class=\"date\">03 June 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/nc\">Frankfurt meetup with special guest CatM (CFAR instructor):&nbsp;<span class=\"date\">01 June 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/nb\">Helsinki meetup with CatM (CFAR instructor) as special guest star:&nbsp;<span class=\"date\">08 June 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/n9\">London - Inaugural Practical Session - June 9th:&nbsp;<span class=\"date\">09 June 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/nf\">[Moscow] Rational choice:&nbsp;<span class=\"date\">09 June 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/n3\">Munich Meetup:&nbsp;<span class=\"date\">01 June 2013 03:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">01 June 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/n5\">Melbourne, practical rationality:&nbsp;<span class=\"date\">07 June 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/nd\">Vienna Meetup #3:&nbsp;<span class=\"date\">15 June 2013 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F42JLyeBd5dfhRDGu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.2246532154296267e-06, "legacy": true, "legacyId": "22797", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XMEYJwdHw3mRGpz9d", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-07T19:34:50.350Z", "modifiedAt": null, "url": null, "title": "Some clarifications concerning my \"many weak arguments\" post", "slug": "some-clarifications-concerning-my-many-weak-arguments-post", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.636Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8462akth6EtRnpYAH/some-clarifications-concerning-my-many-weak-arguments-post", "pageUrlRelative": "/posts/8462akth6EtRnpYAH/some-clarifications-concerning-my-many-weak-arguments-post", "linkUrl": "https://www.lesswrong.com/posts/8462akth6EtRnpYAH/some-clarifications-concerning-my-many-weak-arguments-post", "postedAtFormatted": "Friday, June 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20clarifications%20concerning%20my%20%22many%20weak%20arguments%22%20post&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20clarifications%20concerning%20my%20%22many%20weak%20arguments%22%20post%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8462akth6EtRnpYAH%2Fsome-clarifications-concerning-my-many-weak-arguments-post%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20clarifications%20concerning%20my%20%22many%20weak%20arguments%22%20post%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8462akth6EtRnpYAH%2Fsome-clarifications-concerning-my-many-weak-arguments-post", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8462akth6EtRnpYAH%2Fsome-clarifications-concerning-my-many-weak-arguments-post", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1265, "htmlBody": "<p>I put substantial of effort into making my post&nbsp;<a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">Many Weak Arguments vs. One Relatively Strong Argument</a>&nbsp;as clear as possible, but as Luke said:</p>\n<blockquote>\n<p>This is a messy subject, and one that's difficult write about, and I appreciate you tackling the topic. I think there are some important qualifications to make about this post, as others have noted. But I know that when writing about messy subjects, it's hard to avoid \"death by a thousand qualifications.\"</p>\n</blockquote>\n<p>So a lot of aspects of my thinking didn't percolate into my post. With this in mind, I decided to address some of the questions and concerns that people raised in the comments on my post. The discussion below is intended for people who read the aforementioned article, and who have nagging concerns and questions.</p>\n<p>I'll address various questions and comments in turn.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>Motivated cognition:</strong>&nbsp;<a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>Motivated reasoning is a bigger risk when dealing with weak arguments, since it is relatively easy to come up with weak arguments on the side that you favor, but it is hard to make an argument rigorous just because you want it to be true. It also seems easier to ignore various weak arguments on the other side (or dismiss them as not even worth considering) than to dismiss a strong argument on the other side.</p>\n</blockquote>\n<p>I think that Unnamed raises a genuine weakness of the \"many weak arguments\" approach, but I think that the issue is smaller than it initially appears.</p>\n<p>I didn't mean to suggest that one could consider question, choose a position, come up with a bunch of weak arguments in favor of the postion, note that they're largely independent, and conclude that the position is true. \"Weak argument\" is relative, and in general, the weak arguments on one side of the argument will be weaker than those on the other side.</p>\n<p>My suggestion is that one should make a list of many weak arguments for a position and against a position, consider them all in juxtaposition, and then make an assessment of the direction in which the <a href=\"http://en.wikipedia.org/wiki/Consilience\">principle of consilience</a> points, and how strongly it points in that direction. My reason for highlighting the argument that \"Penrose is a great physicist and so is unusually likely to be right in his views about consciousness\" was to give an example of a weak argument on \"the other side\" that one should pay (a small amount of) attention to.&nbsp;</p>\n<p>If a question is a high stakes question, one should solicit weak arguments from people who support the position opposite to one's own, and consider them in juxtaposition with the weak argument that one has generated oneself.</p>\n<p><strong>The ostensible unbalanced quality of my discussion of the sample claim</strong></p>\n<p>The \"majoring in a quantitative subject increases earnings (on average, for those on the fence)\" example may have come across as unbalanced, on account of my not giving arguments against the claim (beyond the counterarguments). However, note however that if a position is in fact <strong>true</strong>, one would expect \"many weak arguments\" to systematically support the position more than its negation</p>\n<p>I started under the presumption that it's more likely than not that majoring in a quantitative subject increases earnings (on average, for those on the fence), which I believed with low confidence, and then I investigated further. Considering weak arguments raised my confidence in its truth.</p>\n<p>This is exactly what one would expect if the statement is in fact true. If the statement was false, then I would have come across more arguments against its truth, and stronger arguments against its truth. I'm fully open to considering arguments against its truth (beyond the counterarguments that I gave), but nobody offered any such arguments. This suggests that the fact that I&nbsp;asymmetrically&nbsp;found arguments favoring it rather than arguments opposing it was not driven by me having of a predetermined bottom line, but rather, by there genuinely being a lot more reasons for believing the claim than for disbelieving the claim.</p>\n<p><strong>Selection effects and non-independence: </strong><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>Selection effects will tend to expose you to more weak arguments on one side of an issue; e.g. if you are surrounded by Blues then you will be exposed to lots of weak arguments in favor of Blue positions, and few arguments in favor of Green positions. A person in this Blue-slanted situation has a better chance of finding their way into the pro-Green camp on an issue if they ignore the argument count and instead only compare the strongest pro-Blue argument that they have seen with the strongest pro-Green argument that they have seen (or, even better, the steel-manned version).</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p>Nonindependence: a set of arguments on a given issue are rarely independent; arguments which share a conclusion often have strong (and perhaps hidden) dependencies and interrelationships. For example, a large fraction of the set of arguments may all rely on the same methodology, or come from the same group of people, or be (perhaps indirect) consequences of a single piece of evidence, or share a single auxiliary assumption. So a set of seemingly independent arguments often provides less evidence than it appears.</p>\n</blockquote>\n<p>I acknowledge these as serious weaknesses of the \"many weak arguments\" approach. See my \"bubble\" example <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93vw\">in this comment</a>. I believe that using both approaches in conjunction yields better results than using the \"many weak arguments\" approach exclusively.</p>\n<p><strong>Argument structure:</strong></p>\n<p><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>Argument structure: the structure of a complex argument is often important but neglected, and it is not accounted for by listing simple points in favor of each side. To take one example, the claim IF (A or B or C or D or E) THEN Z has a very different structure from the claim IFF (A &amp; B &amp; C &amp; D &amp; E) THEN Z, but moderate evidence against D would appear similarly as \"a weak argument against the claim\" in both cases. Making a strong argument requires engaging with the structure of the argument.</p>\n</blockquote>\n<p><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\"></a>As above, I acknowledge this as a weakness \"many week models approach,\" and think that using both approaches in conjunction is better than using the \"many weak arguments\" approach exclusively.</p>\n<p>At the same time, I think that the degree to which argument is conjunctive vs. disjunctive is often highly nonobvious, so that the advantage that the \"one relatively strong argument\" approach has over the \"many weak arguments\" approach on this front is smaller than it might initially seem. See for example, <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">Holden Karnofsky's Objection 3 in his post about the former version of MIRI</a>.</p>\n<p><strong>Computational feasibility:</strong></p>\n<p><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>The 80/20 rule: in many domains, a small fraction of the things carry a large portion of the weight, and a useful heuristic is to focus on that small fraction (e.g., the 20% of effort that produces 80% of the results). Which suggests that, in this domain, the strongest few arguments will carry most of the evidential weight on an issue, and the long tail of weak arguments will not matter much.</p>\n</blockquote>\n<p>and <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93wu\">Utilitarian wrote</a>:</p>\n<blockquote>\n<p>My main comment on your post is that it's hard to keep track of all of these things computationally. Probably you should try, but it can get messy. It's also possible that in keeping track of too many details, you introduce more errors than if you had kept the analysis simple.</p>\n</blockquote>\n<p>I believe that it's possible to keep track of ~ four to eight weak arguments without too much difficulty, and that this number of weak arguments often suffices to beat the \"one relatively strong argument\" approach. I also believe that <a href=\"/lw/h6b/explicit_and_tacit_rationality/\">tacit</a>&nbsp;rationality&nbsp;implicitly picks up on still more weak arguments, so that using one's gut feeling as an input makes the it possible to use even more weak lines of evidence than one would be able to otherwise.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xgpBASEThXPuKRhbS": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8462akth6EtRnpYAH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 5, "extendedScore": null, "score": 1.2248402110530344e-06, "legacy": true, "legacyId": "22886", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I put substantial of effort into making my post&nbsp;<a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">Many Weak Arguments vs. One Relatively Strong Argument</a>&nbsp;as clear as possible, but as Luke said:</p>\n<blockquote>\n<p>This is a messy subject, and one that's difficult write about, and I appreciate you tackling the topic. I think there are some important qualifications to make about this post, as others have noted. But I know that when writing about messy subjects, it's hard to avoid \"death by a thousand qualifications.\"</p>\n</blockquote>\n<p>So a lot of aspects of my thinking didn't percolate into my post. With this in mind, I decided to address some of the questions and concerns that people raised in the comments on my post. The discussion below is intended for people who read the aforementioned article, and who have nagging concerns and questions.</p>\n<p>I'll address various questions and comments in turn.</p>\n<p><a id=\"more\"></a></p>\n<p><strong>Motivated cognition:</strong>&nbsp;<a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>Motivated reasoning is a bigger risk when dealing with weak arguments, since it is relatively easy to come up with weak arguments on the side that you favor, but it is hard to make an argument rigorous just because you want it to be true. It also seems easier to ignore various weak arguments on the other side (or dismiss them as not even worth considering) than to dismiss a strong argument on the other side.</p>\n</blockquote>\n<p>I think that Unnamed raises a genuine weakness of the \"many weak arguments\" approach, but I think that the issue is smaller than it initially appears.</p>\n<p>I didn't mean to suggest that one could consider question, choose a position, come up with a bunch of weak arguments in favor of the postion, note that they're largely independent, and conclude that the position is true. \"Weak argument\" is relative, and in general, the weak arguments on one side of the argument will be weaker than those on the other side.</p>\n<p>My suggestion is that one should make a list of many weak arguments for a position and against a position, consider them all in juxtaposition, and then make an assessment of the direction in which the <a href=\"http://en.wikipedia.org/wiki/Consilience\">principle of consilience</a> points, and how strongly it points in that direction. My reason for highlighting the argument that \"Penrose is a great physicist and so is unusually likely to be right in his views about consciousness\" was to give an example of a weak argument on \"the other side\" that one should pay (a small amount of) attention to.&nbsp;</p>\n<p>If a question is a high stakes question, one should solicit weak arguments from people who support the position opposite to one's own, and consider them in juxtaposition with the weak argument that one has generated oneself.</p>\n<p><strong id=\"The_ostensible_unbalanced_quality_of_my_discussion_of_the_sample_claim\">The ostensible unbalanced quality of my discussion of the sample claim</strong></p>\n<p>The \"majoring in a quantitative subject increases earnings (on average, for those on the fence)\" example may have come across as unbalanced, on account of my not giving arguments against the claim (beyond the counterarguments). However, note however that if a position is in fact <strong>true</strong>, one would expect \"many weak arguments\" to systematically support the position more than its negation</p>\n<p>I started under the presumption that it's more likely than not that majoring in a quantitative subject increases earnings (on average, for those on the fence), which I believed with low confidence, and then I investigated further. Considering weak arguments raised my confidence in its truth.</p>\n<p>This is exactly what one would expect if the statement is in fact true. If the statement was false, then I would have come across more arguments against its truth, and stronger arguments against its truth. I'm fully open to considering arguments against its truth (beyond the counterarguments that I gave), but nobody offered any such arguments. This suggests that the fact that I&nbsp;asymmetrically&nbsp;found arguments favoring it rather than arguments opposing it was not driven by me having of a predetermined bottom line, but rather, by there genuinely being a lot more reasons for believing the claim than for disbelieving the claim.</p>\n<p><strong>Selection effects and non-independence: </strong><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>Selection effects will tend to expose you to more weak arguments on one side of an issue; e.g. if you are surrounded by Blues then you will be exposed to lots of weak arguments in favor of Blue positions, and few arguments in favor of Green positions. A person in this Blue-slanted situation has a better chance of finding their way into the pro-Green camp on an issue if they ignore the argument count and instead only compare the strongest pro-Blue argument that they have seen with the strongest pro-Green argument that they have seen (or, even better, the steel-manned version).</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p>Nonindependence: a set of arguments on a given issue are rarely independent; arguments which share a conclusion often have strong (and perhaps hidden) dependencies and interrelationships. For example, a large fraction of the set of arguments may all rely on the same methodology, or come from the same group of people, or be (perhaps indirect) consequences of a single piece of evidence, or share a single auxiliary assumption. So a set of seemingly independent arguments often provides less evidence than it appears.</p>\n</blockquote>\n<p>I acknowledge these as serious weaknesses of the \"many weak arguments\" approach. See my \"bubble\" example <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93vw\">in this comment</a>. I believe that using both approaches in conjunction yields better results than using the \"many weak arguments\" approach exclusively.</p>\n<p><strong id=\"Argument_structure_\">Argument structure:</strong></p>\n<p><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>Argument structure: the structure of a complex argument is often important but neglected, and it is not accounted for by listing simple points in favor of each side. To take one example, the claim IF (A or B or C or D or E) THEN Z has a very different structure from the claim IFF (A &amp; B &amp; C &amp; D &amp; E) THEN Z, but moderate evidence against D would appear similarly as \"a weak argument against the claim\" in both cases. Making a strong argument requires engaging with the structure of the argument.</p>\n</blockquote>\n<p><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\"></a>As above, I acknowledge this as a weakness \"many week models approach,\" and think that using both approaches in conjunction is better than using the \"many weak arguments\" approach exclusively.</p>\n<p>At the same time, I think that the degree to which argument is conjunctive vs. disjunctive is often highly nonobvious, so that the advantage that the \"one relatively strong argument\" approach has over the \"many weak arguments\" approach on this front is smaller than it might initially seem. See for example, <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">Holden Karnofsky's Objection 3 in his post about the former version of MIRI</a>.</p>\n<p><strong id=\"Computational_feasibility_\">Computational feasibility:</strong></p>\n<p><a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93j1\">Unnamed wrote</a>:</p>\n<blockquote>\n<p>The 80/20 rule: in many domains, a small fraction of the things carry a large portion of the weight, and a useful heuristic is to focus on that small fraction (e.g., the 20% of effort that produces 80% of the results). Which suggests that, in this domain, the strongest few arguments will carry most of the evidential weight on an issue, and the long tail of weak arguments will not matter much.</p>\n</blockquote>\n<p>and <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/93wu\">Utilitarian wrote</a>:</p>\n<blockquote>\n<p>My main comment on your post is that it's hard to keep track of all of these things computationally. Probably you should try, but it can get messy. It's also possible that in keeping track of too many details, you introduce more errors than if you had kept the analysis simple.</p>\n</blockquote>\n<p>I believe that it's possible to keep track of ~ four to eight weak arguments without too much difficulty, and that this number of weak arguments often suffices to beat the \"one relatively strong argument\" approach. I also believe that <a href=\"/lw/h6b/explicit_and_tacit_rationality/\">tacit</a>&nbsp;rationality&nbsp;implicitly picks up on still more weak arguments, so that using one's gut feeling as an input makes the it possible to use even more weak lines of evidence than one would be able to otherwise.</p>", "sections": [{"title": "The ostensible unbalanced quality of my discussion of the sample claim", "anchor": "The_ostensible_unbalanced_quality_of_my_discussion_of_the_sample_claim", "level": 1}, {"title": "Argument structure:", "anchor": "Argument_structure_", "level": 1}, {"title": "Computational feasibility:", "anchor": "Computational_feasibility_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9W9P2snxu5Px746LD", "6SGqkCgHuNr7d4yJm", "NLJ6NyHFZPJ2oNSZ8"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-08T02:31:37.659Z", "modifiedAt": null, "url": null, "title": "Social Impact, Effective Altruism, and Motivated Cognition", "slug": "social-impact-effective-altruism-and-motivated-cognition", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:01.367Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dbyWERjyF5epdvjcL/social-impact-effective-altruism-and-motivated-cognition", "pageUrlRelative": "/posts/dbyWERjyF5epdvjcL/social-impact-effective-altruism-and-motivated-cognition", "linkUrl": "https://www.lesswrong.com/posts/dbyWERjyF5epdvjcL/social-impact-effective-altruism-and-motivated-cognition", "postedAtFormatted": "Saturday, June 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Social%20Impact%2C%20Effective%20Altruism%2C%20and%20Motivated%20Cognition&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASocial%20Impact%2C%20Effective%20Altruism%2C%20and%20Motivated%20Cognition%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdbyWERjyF5epdvjcL%2Fsocial-impact-effective-altruism-and-motivated-cognition%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Social%20Impact%2C%20Effective%20Altruism%2C%20and%20Motivated%20Cognition%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdbyWERjyF5epdvjcL%2Fsocial-impact-effective-altruism-and-motivated-cognition", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdbyWERjyF5epdvjcL%2Fsocial-impact-effective-altruism-and-motivated-cognition", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 605, "htmlBody": "<p class=\"MsoNormal\">Money is one measure of social status. People compare themselves favorably or unfavorably to others in their social circles based on their wealth and their earning power, and signals thereof, and compare their social circles favorably or unfavorably with other social circles based on the average wealth of people in the social circles. Humans crave social status, and this is one of people&rsquo;s motivations for making money.&nbsp;</p>\n<p class=\"MsoNormal\">Effective altruists attempt to quantify &ldquo;amount of good done&rdquo; and maximize it. Once this framing is adopted, &ldquo;amount of good done&rdquo; becomes a measure of social status in the same way that money is. Most people who aspire to be effective altruists will be partially motivated by a desire to matter more than other people, in the sense of doing more good. People who join the effective altruism movement may do so partially out of a desire to matter more than people who are not in the movement.&nbsp;</p>\n<p class=\"MsoNormal\">Harnessing status motivations for the sake of doing the most good can have profound positive impacts. But under this paradigm, <em style=\"mso-bidi-font-style:normal\">effective altruists will generally be motivated to believe that they&rsquo;re doing more good than other people are</em>. This motivation is not necessarily dominant in any given case, but it&rsquo;s sufficiently strong to be worth highlighting.</p>\n<p class=\"MsoNormal\">With this in mind, note that <em style=\"mso-bidi-font-style: normal\">effective altruists will be motivated to believe that the activities that they themselves are capable of engaging in have higher value than they actually do, and that activities that others are engaged in have lower value than they actually do. Without effort to counterbalance this motivation, effective altruists&rsquo; views of the philanthropic landscape will be distorted, and they&rsquo;ll be apt to bias others in favor of the areas that use their own core competencies.</em></p>\n<p class=\"MsoNormal\">I worry that the effective altruist community hasn&rsquo;t taken sufficient measures to guard against this issue. In particular, I&rsquo;m not aware of any overt public discussion of it. Independently of whether or not there are examples of public discussion that I&rsquo;m unaware of, the fact that I&rsquo;m not aware of any suggests that any discussion that has occurred hasn&rsquo;t percolated enough.</p>\n<p class=\"MsoNormal\">I&rsquo;ll refrain from giving specific examples that I see as causes for concern, on account of political sensitivity. The effective altruist community is divided into factions, and <a href=\"/lw/gw/politics_is_the_mindkiller/\">Politics is the Mind-Killer</a>. I believe that there are examples of each faction irrationally overestimating the value of their activities, and/or irrationally undervaluing the value of other faction's activities, and I believe that in each case, motivated reasoning of the above type may play a role.</p>\n<p class=\"MsoNormal\"><strong style=\"mso-bidi-font-weight:normal\">I request that commenters not discuss particular instances in which they believe that this has occurred, or is occurring, as I think that such discussion would reduce collaboration between different factions of the effective altruist community.</strong>&nbsp;</p>\n<p class=\"MsoNormal\">The effective altruist movement is in early stages, and it&rsquo;s important to arrive at accurate conclusions about effective philanthropy <a href=\"http://80000hours.org/blog/43-the-haste-consideration\">as fast as possible</a>. At this stage in time, it may be that the biggest contribution that members of the community can make is to engender and engage in an honest and unbiased discussion of how best to make the world a better place.</p>\n<p class=\"MsoNormal\">I don't have a very definite proposal for how this can be accomplished. I welcome any suggestions. For now, I would encourage effective altruist types to take pride in being <a href=\"/lw/dyk/selfskepticism_the_first_principle_of_rationality/\">self-skeptical</a>&nbsp;when it comes to favorable assessments of their potential impact relative to other effective altruist types, or relative to people outside of the effective altruist community.</p>\n<p class=\"MsoNormal\"><strong>Acknowledgements:&nbsp;</strong>Thanks to Vipul Naik and Nick Beckstead for feedback on an earlier draft of this post.</p>\n<p class=\"MsoNormal\"><strong>Note: </strong>I formerly worked as a research analyst at GiveWell. All views here are my own.</p>\n<p class=\"MsoNormal\">I <a href=\"http://www.effective-altruism.com/node/34\">cross-posted</a> this article to&nbsp;http://www.effective-altruism.com/</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xexCWMyds6QLWognu": 2, "Ng8Gice9KNkncxqcj": 2, "iP2X4jQNHMWHRNPne": 2, "LDTSbmXtokYAsEq8e": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dbyWERjyF5epdvjcL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 16, "extendedScore": null, "score": 1.2251537230594093e-06, "legacy": true, "legacyId": "22891", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9weLK2AJ9JEt2Tt8f", "NoYYBAaMRp9Y5Jnpo"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-08T14:32:04.276Z", "modifiedAt": null, "url": null, "title": "Exercise isn't necessarily good for people", "slug": "exercise-isn-t-necessarily-good-for-people", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:09.053Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/88iemwHCoAb4fEDvf/exercise-isn-t-necessarily-good-for-people", "pageUrlRelative": "/posts/88iemwHCoAb4fEDvf/exercise-isn-t-necessarily-good-for-people", "linkUrl": "https://www.lesswrong.com/posts/88iemwHCoAb4fEDvf/exercise-isn-t-necessarily-good-for-people", "postedAtFormatted": "Saturday, June 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Exercise%20isn't%20necessarily%20good%20for%20people&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExercise%20isn't%20necessarily%20good%20for%20people%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F88iemwHCoAb4fEDvf%2Fexercise-isn-t-necessarily-good-for-people%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Exercise%20isn't%20necessarily%20good%20for%20people%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F88iemwHCoAb4fEDvf%2Fexercise-isn-t-necessarily-good-for-people", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F88iemwHCoAb4fEDvf%2Fexercise-isn-t-necessarily-good-for-people", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1247, "htmlBody": "<p>I would appreciate it very much if anyone would take a close look at this-- it looks sound to me, but it also appeals to my prejudices.</p>\n<p>http://www.youtube.com/watch?feature=player_embedded&amp;v=E42TQNWhW3w#!</p>\n<p>My comments are in square brackets. Everything else is my notes on the Jamie Timmons lecture from the video.</p>\n<p>Short version: 12% of people become less healthy from exercise. 20% of people get nothing from exercise. This is a matter of genetics, not doing exercise wrong.</p>\n<p>****</p>\n<p>Ask a hundred people about exercise, you'll get a wide range of answers about what exercise is and what good it might do for health, and the same for health professionals.</p>\n<p>You need to focus on the evidence that exercise affects particular health outcomes. Weight and health are not strongly correlated. BMI is problematic.</p>\n<p>There's a recommendation for 150 minutes of exercise/week, but this isn't sound. People who *report* being active have better health. People who are fitter have better health. These are not evidence that having a person with low activity take up exercise will make them healthier.</p>\n<p>Nothing but a supervised intervention study is good enough.</p>\n<p>Improved lifestyle is better than Metformin for preventing diabetes. (Studies) Exercise + diet modification has a powerful effect of preventing and slowing the progression of Type II diabetes. People with Type II have more cardiovascular disease (heart attacks and strokes). However, it doesn't follow that the lifestyle changes which help with Type II will also help with CVD. [I'm surprised]</p>\n<p>Diabetes doesn't kill, CVD does, and a major motivation for the NHS to care is that CVD is expensive.</p>\n<p>[9:45] Two studies which find that lifestyle intervention has no effect on CVD in diabetics. [11:00] One study which found that lifestyle intervention prevents Type II but doesn't affect microvascular disease (blindness and ulcers). [I'm not sure what this means. Maybe people can have the ill effects of Type II without the disease showing up in their blood sugar levels?] There are no supervised exercise-only intervention studies which show that exercise prevents long term disease progression.</p>\n<p>[13:00] The usual advice on exercise from the NHS (pretty similar in the US): Aerobic exerise must raise your heart rate and make you sweat to be benefiscial. The more exercise you do, the better. Do a minimum of 150 minutes/week of aerobic exercise + strength training. If you do more than 150 minutes/week, you'll gain even more health benefits. Using a skipping rope is an example of vigorous intensity exercise. People aren't following this advice, and a major factor is the amount of time required. The advice is based on best guesses.</p>\n<p>[15:55] Exercise will increase aerobic capacity in 80% of people (lowers all-cause mortality), improve insulin action in 65% of people (lowers type II diabetes by 50%), reduce blood pressure in &gt;55% of people (lowers strokes 25%), increase good cholesterol in 70% of people (less vascular disease), promote muscle and bone mass (? less fractures and 'aging')</p>\n<p>[17:40] Exercise response graphs. The average person gets a 15% increase in aerobic capacity, but a few get less capacity if they exercise. Insulin response-- average of 20% improvement. Some people get better, some get worse. A high proportion, maybe the majority, have little or no change. The people in this chart were doing 150 minutes/week of supervised exercise.</p>\n<p>[20:00] High-intensity exercise is exercise which depends on stored energy, there's no way to take in enough oxygen to contribute. An athlete might be able to continue for 10 minutes. The average person can continue for more like 30 seconds to one minute.</p>\n<p>[22:00] Experiments with high-intensity/rest intervals: 3 x 20 seconds of high intensity. [25:00] Charts showing flattened glucose spike (there probably was a peak, but the test missed the moment) and less isulin in the blood after only two weeks of 6 x 30 seconds interval training (total 7 minutes).</p>\n<p>[30:54] \"Advice has been based on what epidemiology methods can detect, not what is actually important or required.\" Health questionaires don't include things like 20 seconds of running for the bus.</p>\n<p>[33:00] Ten days of bed rest will make healthy people insulin resistant.</p>\n<p>[35:00] It looks as though modern hunter gatherers expend about as much energy/mass as Americans on the east coast do. [I found I could make sense out of the graphs by using full screen.] This evidence suggests that people are eating more rather than moving less. The evidence for 7 minutes of HIIT three times a week isn't completely solid, but it's at least as good as the evidence for 150 minutes/week.</p>\n<p>[38:36] ..... Epidemiology of a sort-- evidence that eating chocolate makes it more likely to get a Nobel prize. Beautiful corelation! The Swiss eat the most chocolate and get the most prizes. The Swedes are an outlier-- they don't eat as much chocolate as they should to get so many prizes. That the prize is given in Sweden might have something to do with this. Cocoa has flavenols which slow age-related cognitive decline, but the corelation is probably just a coincidence.</p>\n<p>[40:00] 12% of healthy people make their blood pressure **higher** by exercising 150 minutes a week. 20% get little or no improvement. [42:00] Graphs of low responders for aerobic capacity, muscle mass, and insulin sensitivity. Exercise does slow progression of diabetes on the average, but that doesn't apply to all individuals.</p>\n<p>[44:47] There's no obvious indicator to tell high responders from low responders in advance. You have to either check the genes or track the results of exercise. [45:00] Finding non- or adverse responders: change in aerobic fitness is 60% genetic, insulin sensitivity is 40% genetic, strength is 50% genetic. These are estimates from family studies, including twin studies. There are 10 million genes variants which might have at least a 5% effect.</p>\n<p>[47:35] There's a group of 27 genes which together can 'predict' gains in VO2max. It isn't necessary to understand how the genes work to create their effect as long as that effect is predictable, and it's possible that we will never understand something so complex. There may be drug combinations which can make exercise safe and effective for non-adaptors. There's research happening. It's possible to breed rats which are better at responding to training.</p>\n<p>[53:52] A life-style program will *on average* reduce the risk of developing type II diabetes. We *don't know* whether exercise-training on its own will reduce heart-disease, angina, etc. It does improve risk factors and symptoms. If *you* have a risk-factor for ill-health, we *can not* be sure that exercise will help. (12% *adverse* responders, 20% no effect)</p>\n<p>[57:00]Public health (what advice should the government give?): 1 minute a day of high-intensity sprint cycling reduces major risk factors. [For what proportion of people?] People tend to like brief high intensity exercise better than longer low intensity exercise. North American study: 150 minutes/week of exercise increase one's carbon footprint by 15% (food, laundry, showers).</p>\n<p>Safety: 2 million marathoners have been studied. Very low fatalities. HIIT isn't likely to be more dangerous. [Ack! Ack! Ack! What happened to all the care about evidence? Marathoning isn't sprinting. Fatalities during the race aren't the only thing that can go wrong. People who do marathons aren't randomly selected.]</p>\n<p>HIIT has be done safely by medically supervised diabetes and heart failure patients. It would take a billion dollars to do a thorough supervised intervention study. Some pieces of it have been done. This is much less than big drug companies spend, without much results. The current hope is finding the gene markers and then useful drugs for non and adverse responders. There are no average people!</p>\n<p>**** http://www.medicalnewstoday.com/articles/242498.php</p>\n<p>Summary of a TV show which has more details about High Intensity Interval Training.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "88iemwHCoAb4fEDvf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 17, "extendedScore": null, "score": 1.2256959819649957e-06, "legacy": true, "legacyId": "22900", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-09T16:28:51.006Z", "modifiedAt": null, "url": null, "title": "Anticipating critical transitions", "slug": "anticipating-critical-transitions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:29.476Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pBd9ZsdfKBBN8qdR5/anticipating-critical-transitions", "pageUrlRelative": "/posts/pBd9ZsdfKBBN8qdR5/anticipating-critical-transitions", "linkUrl": "https://www.lesswrong.com/posts/pBd9ZsdfKBBN8qdR5/anticipating-critical-transitions", "postedAtFormatted": "Sunday, June 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anticipating%20critical%20transitions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnticipating%20critical%20transitions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpBd9ZsdfKBBN8qdR5%2Fanticipating-critical-transitions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anticipating%20critical%20transitions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpBd9ZsdfKBBN8qdR5%2Fanticipating-critical-transitions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpBd9ZsdfKBBN8qdR5%2Fanticipating-critical-transitions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 968, "htmlBody": "<p>(Mathematicians may find this post painfully obvious.)</p>\n<p>I read an interesting <a href=\"http://www.thebigquestions.com/2010/12/21/are-you-smarter-than-google/\">puzzle</a>&nbsp;on Stephen Landsburg's blog that generated a lot of disagreement. Stephen offered to bet anyone $15,000 that the average results of a computer simulation, run 1 million times, would be close to his solution's prediction of the expected value.</p>\n<p>Landsburg's solution is in fact correct. But the problem involves a probabilistic infinite series, a kind used often on less wrong in a context where one is offered some utility every time one flips a coin and it comes up heads, but loses everything if it ever comes up tails. Landsburg didn't justify the claim that a simulation could indicate the true expected outcome of this particular problem. Can we find similar-looking problems for which simulations give the wrong answer? &nbsp;Yes.</p>\n<p><a id=\"more\"></a>Here's Perl code to estimate by simulation the expected value of the series of terms 2^k / k from k = 1 to infinity, with a 50% chance of stopping after each term.</p>\n<pre><code>my $bigsum = 0;\nfor (my $trial = 0; $trial &lt; 1000000; $trial++) {\n&amp;nbsp; &amp;nbsp; my $sum = 0;\n</code><code><code>&amp;nbsp; &amp;nbsp; </code>my $top = 2;\n</code><code><code>&amp;nbsp; &amp;nbsp; </code>my $denom = 1;\n</code><code><code>&amp;nbsp; &amp;nbsp; </code>do {\n</code><code><code>&amp;nbsp; &amp;nbsp; </code></code><code><code><code>&amp;nbsp; &amp;nbsp; </code></code>$sum += $top / $denom;\n</code><code><code>&amp;nbsp; &amp;nbsp; </code></code><code><code><code>&amp;nbsp; &amp;nbsp; </code></code>$top *= 2;\n</code><code><code>&amp;nbsp; &amp;nbsp; </code></code><code><code><code>&amp;nbsp; &amp;nbsp; </code></code>$denom += 1;\n</code><code><code>&amp;nbsp; &amp;nbsp; </code>}\n</code><code><code>&amp;nbsp; &amp;nbsp; </code>while (rand(1) &lt; .5);\n</code><code><code>&amp;nbsp; &amp;nbsp; </code>$bigsum += $sum;\n}\nmy $ave = $bigsum / $runs;\nprint \"ave sum=$ave\\n\";\n</code></pre>\n<p>(If anyone knows how to enter a code block on this site, let me know. I used the \"pre\" tag, but the site stripped out my spaces anyway.)</p>\n<p>Running it 5 times, we get the answers</p>\n<p>ave sum=7.6035709716983</p>\n<p>ave sum=8.47543819631431</p>\n<p>ave sum=7.2618950097739</p>\n<p>ave sum=8.26159741956747</p>\n<p>ave sum=7.75774577340324</p>\n<p>&nbsp;</p>\n<p>So the expected value is somewhere around 8?</p>\n<p>No; the expected value is given by the sum of the harmonic series, which diverges, so it's infinite. Later terms in the series are exponentially larger, but exponentially less likely to appear.</p>\n<p>Some of you are saying, \"Of course the expected value of a divergent series can't be computed by simulation! Give me back my minute!\" But many things we might simulate with computers, like the weather, the economy, or existential risk, are full of power law distributions that might not have a convergent expected value. People have observed before that this can cause problems for simulations (see <em><a href=\"http://amzn.to/111n0QV\">The Black Swan</a></em>). What I find interesting is that the output of the program above doesn't look like something inside it diverges. It looks almost normal. So you could run your simulation many times and believe that you had a grip on its expected outcome, yet be completely mistaken.</p>\n<p>In real-life simulations (that sounds wrong, doesn't it?), there's often some system property that drifts slowly, and some critical value of that system property above which some distribution within the simulation diverges. Moving above that critical value doesn't suddenly change the output of the simulation in a way that gives an obvious warning. But the expected value of keeping that property below that critical value in the real-life system being simulated can be very high (or even infinite), with very little cost.</p>\n<p>Is there a way to look at a simulation's outputs, and guess whether a particular property is near some such critical threshold? &nbsp;Better yet, is there a way to guess whether there exists some property in the system nearing some such threshold, even if you don't know what it is?</p>\n<p>The October 19, 2012 issue of Science contains an article on just that question: \"Anticipating critical transitions\", Marten Scheffer et al., p. 344. It reviews 28 papers on systems and simulations, and lists about a dozen mathematical approaches used to estimate nearness to a critical point. These include:</p>\n<ul>\n<li>Critical slowing down: When the system is near a critical threshold, it recovers slowly from small perturbations. One measure of this is autocorrelation at lag 1, meaning the correlation between the system's output at times T and T-1. Counterintuitively, a higher autocorrelation at lag one by itself suggests that the system is more predictable than before, but may actually indicate it is less predictable. The more predictable system reverts to its mean; the unpredictable system has no mean.</li>\n<li>Flicker: Instead of having a single stable state that the system reverts to after perturbation, an additional stable state appears, and the system flickers back and forth between the two states.</li>\n<li>Dominant eigenvalue: I haven't read the paper that explains what this paper means when it cites this, but I do know that you can predict when a helicopter engine is going to malfunction by putting many sensors on it,&nbsp;running PCA on time-series data for those sensors to get a matrix that projects their output into just a few dimensions,&nbsp;then reading their output continuously and predicting failure anytime the PCA-projected output vector moves a lot. That probably is what they mean.</li>\n</ul>\n<p>So if you're modeling global warming, running your simulation a dozen times and averaging the results may be misleading. [1] Global temperature has sudden [2] dramatic transitions, and an exceptionally large and sudden one (15C in one million years) neatly spans the Earth's greatest extinction event so far on the Permian-Triassic boundary [3]. It's more important to figure out what the critical parameter is and where its critical point is than to try and estimate how many years it will be before Manhattan is underwater. The \"expected rise in water level per year\" may not be easily-answerable by simulation [4].</p>\n<p>And if you're thinking about betting Stephen Landsburg $15,000 on the outcome of a simulation, make sure his series converges first. [5]</p>\n<p>&nbsp;</p>\n<p>[1] Not that I'm particularly worried about global warming.</p>\n<p>[2] Geologically sudden.</p>\n<p>[3] Sun et al., \"Lethally hot temperatures during the early Triassic greenhouse\", Science 338 (Oct. 19 2012) p.366, see p. 368.&nbsp;Having just pointed out that an increase of .000015C/yr counts as a \"sudden\" global warming event, I feel obligated to also point out that the current increase is about .02C/yr.</p>\n<p>[4] It will be answerable by simulation, since rise in water level can't be infinite. But you may need a lot more simulations than you think.</p>\n<p>[5] Better yet, don't bet against Stephen Landsburg.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pBd9ZsdfKBBN8qdR5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 29, "extendedScore": null, "score": 8.4e-05, "legacy": true, "legacyId": "22908", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-09T19:00:57.196Z", "modifiedAt": "2020-10-21T23:38:35.887Z", "url": null, "title": "All Debates Are Bravery Debates", "slug": "all-debates-are-bravery-debates", "viewCount": null, "lastCommentedAt": "2020-07-20T04:34:03.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Scott Alexander", "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PQ3nutgxfTgvq69Xt/all-debates-are-bravery-debates", "pageUrlRelative": "/posts/PQ3nutgxfTgvq69Xt/all-debates-are-bravery-debates", "linkUrl": "https://www.lesswrong.com/posts/PQ3nutgxfTgvq69Xt/all-debates-are-bravery-debates", "postedAtFormatted": "Sunday, June 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20All%20Debates%20Are%20Bravery%20Debates&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAll%20Debates%20Are%20Bravery%20Debates%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPQ3nutgxfTgvq69Xt%2Fall-debates-are-bravery-debates%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=All%20Debates%20Are%20Bravery%20Debates%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPQ3nutgxfTgvq69Xt%2Fall-debates-are-bravery-debates", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPQ3nutgxfTgvq69Xt%2Fall-debates-are-bravery-debates", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1858, "htmlBody": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>\u201c<em>I don\u2019t practice what I preach because I\u2019m not the kind of person I\u2019m preaching to.</em>\u201d </p><p>\u2014 Bob Dobbs</p><p></p><p><strong>I.</strong></p><p>I read Atlas Shrugged probably about a decade ago, and felt turned off by its promotion of selfishness as a moral ideal. I thought that was basically just being a jerk. After all, if there\u2019s one thing the world doesn\u2019t need (I thought) it\u2019s more selfishness.</p><p>Then I talked to a friend who told me Atlas Shrugged had changed his life. That he\u2019d been raised in a really strict family that had told him that ever enjoying himself was selfish and made him a bad person, that he had to be working at every moment to make his family and other people happy or else let them shame him to pieces. And the revelation that it was sometimes okay to consider your own happiness gave him the strength to stand up to them and turn his life around, while still keeping the basic human instinct of helping others when he wanted to and he felt they deserved it (as, indeed, do Rand characters).</p><p><strong>II.</strong></p><p>The religious and the irreligious alike enjoy making fun of Reddit\u2019s r/atheism, which combines an extreme strawmanning of religious positions with childish insults and distasteful triumphalism. Recently the moderators themselves have become a bit embarrassed by it and instituted some rules intended to tone things down, leading to <a href=\"http://www.reddit.com/r/atheism/comments/1fzaai/65_of_responding_users_now_reject_banning_image/\">some</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzd0r/at_the_moment_15_of_the_top_25_posts_on_ratheism/\">of</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzn3n/i_for_one_am_eternally_grateful_that_there_is/\">the</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzhtl/fixed_approach_thread_to_remove_ujij_and_utuber/\">most</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzl0h/jij_if_you_want_a_different_ratheism_go_start/\">impressive</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzlmn/this_sub_is_now_useless_to_mobile_users_thanks_a/\">Internet</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzow2/remove_jij_give_the_sub_back_to_its_creator_skeen/\">drama</a> I have ever seen. In its midst, some people started talking about what the old strawmanning triumphalist r/atheism meant to them (see for example <a href=\"http://www.reddit.com/r/atheism/comments/1fraqe/why_i_dont_like_the_changes/\">here</a>).</p><p>A lot of them were raised in religious families where they would have been disowned if they had admitted to their atheism. Some of them were disowned for admitting to atheism, or lost boyfriends/girlfriends, or were terrified they might go to Hell. And then they found r/atheism, and saw people making fun of religion, and insulting it, in really REALLY offensive ways. And no one was striking them down with lightning. No one was shouting them down. No one was doing much of anything at all. And to see this taboo violated in the most shocking possible way with no repercussions sort of broke the spell for them, like as long as people were behaving respectfully to religion, even respectfully disagreeing, it still had this aura of invincibility about it, but if some perfectly normal person can post a a stupid comic where Jesus has gay sex with Mohammed, then there\u2019s this whole other world out there where religion holds no power.</p><p><a href=\"http://last-conformer.net/\">Gilbert</a> tells the story of how when, as a young Christian struggling with doubt, he would read r/atheism to remind himself that atheists could be pretty awful. r/atheism is doing a bad job at being the sort of people who can convert Gilbert, and the new mods\u2019 policy of \u201cyou should have more civil and intellectual discussions\u201d might work better on him. I think it would work better on me too.</p><p>But there is \u2013 previously unappreciated by me \u2013 a large population of people for whom really dumb offensive strawmannish memes are exactly what they need.</p><p><strong>III.</strong></p><p>A friend described his experiences in the Landmark Forum\u2019s self-improvement workshop. He said their modus operandi was to get people to take responsibility for the outcome of their actions. His example was an office worker who always did substandard work, and was always making excuses like \u201cMy boss doesn\u2019t s support me\u201d or \u201cMy computer system isn\u2019t good enough\u201d or \u201cMy coworkers aren\u2019t pulling their fair share.\u201d Landmark says those kinds of excuses are what\u2019s keeping you back. And they taught (again, according to this one person) that the solution was to treat everything that happens in your life as your responsiblity \u2013 no excuses, just \u201cit was my fault\u201d or \u201cit\u2019s to my credit\u201d.</p><p>Then a few days later, I was reading a book on therapy which contained the phrase (I copied it down to make sure I got it right) \u201cDon\u2019t be so hard on yourself. No one else is as hard on yourself as you are. You are your own worst critic.\u201d</p><p>Notice that this encodes the exact opposite assumption. Landmark claims its members are biased against ever thinking ill of themselves, even when they deserve it. The therapy book claims that patients are biased towards always thinking ill of themselves, even when they don\u2019t deserve it.</p><p>And you know, both claims are probably spot on. There are definitely people who are too hard on themselves. Ozy Frantz has done an amazing job of getting me and many other people inclined towards skepticism about feminist and transgender issues, engaging with us, and gradually convincing us to be more respectful and aware through sheer kindness and willingness to engage people reasonably on every part of the political spectrum. Two days ago some people on Twitter \u2013 who were angry Ozy said one need not boycott everything Orson Scott Card has ever written just because he\u2019s against gay marriage \u2013 told Ozy they weren\u2019t a real transgender person and suggested lots of people secretly disliked them. And instead of doing what I would do and telling the trolls to go to hell, Ozy freaked out and worried they was doing everything wrong and <a href=\"http://pervocracy.tumblr.com/post/52503212252/okay-a-whole-bunch-of-people-are-asking-me-what\">decided to delete</a> everything they had ever written online. I know Ozy is their own worst critic and if that therapy book was aimed at people like them, it was entirely correct to say what it said.</p><p>On the other hand, I look at people like <a href=\"http://en.wikipedia.org/wiki/Amy%27s_Baking_Company_%28Kitchen_Nightmares%29\">Amy\u2019s Baking Company</a>, who are obviously terrible people, who get a high-status professional chef as well as thousands of random joes informing them of exactly what they are doing wrong, who are so clearly in the wrong that it seems impossible not to realize it \u2013 and who then go on to attribute the negativity to a \u201cconspiracy\u201d against them and deny any wrongdoing. They could probably use some Landmark.</p><p><strong>IV.</strong></p><p>In a recent essay I complained about <a href=\"http://slatestarcodex.com/2013/05/18/against-bravery-debates/\">bravery debates</a>, arguments where people boast about how brave they are to take an unorthodox and persecuted position, and their opponents counter that they\u2019re not persecuted heretics, they\u2019re a vast leviathan persecuting everyone else. But I think I underestimated an important reason why some debates have to be bravery debates.</p><p>Suppose there are two sides to an issue. Be more or less selfish. Post more or less offensive atheist memes. Be more or less willing to blame and criticize yourself.</p><p>There are some people who need to hear each side of the issue. Some people really need to hear the advice \u201cIt\u2019s okay to be selfish sometimes!\u201d Other people really need to hear the advice \u201cYou are being way too selfish and it\u2019s not okay.\u201d</p><p>It\u2019s really hard to target advice at exactly the people who need it. You can\u2019t go around giving everyone surveys to see how selfish they are, and give half of them Atlas Shrugged and half of them <a href=\"http://en.wikipedia.org/wiki/Peter_Singer#World_poverty\">the collected works of Peter Singer</a>. You can\u2019t even write really complicated books on how to tell whether you need more or less selfishness in your life \u2013 they\u2019re not going to be as buyable, as readable, or as memorable as Atlas Shrugged. To a first approximation, all you can do is saturate society with pro-selfishness or anti-selfishness messages, and realize you\u2019ll be hurting a select few people while helping the majority.</p><p>But in this case, it makes a really big deal what the majority actually is.</p><p>Suppose an Objectivist argues \u201cOur culture has become too self-sacrificing! Everyone is told their entire life that the only purpose of living is to work for other people. As a result, people are miserable and no one is allowed to enjoy themselves at all.\u201d If they\u2019re right, then helping spread Objectivism is probably a good idea \u2013 it will help these legions of poor insufficiently-selfish people, but there will be very few too-selfish-already people who will be screwed up by the advice.</p><p>But suppose Peter Singer argues \u201cWe live in a culture of selfishness! Everyone is always told to look out for number one, and the poor are completely neglected!\u201d Well, then we want to give everyone the collected works of Peter Singer so we can solve this problem, and we don\u2019t have to worry about accidentally traumatizing the poor self-sacrificing people more, because we\u2019ve already agreed there aren\u2019t very many of these at all.</p><p>It\u2019s much easier to be charitable in political debates when you view the two participants as coming from two different cultures that err on opposite sides, each trying to propose advice that would help their own culture, each being tragically unaware that the other culture exists.</p><p>A lot of the time this happens when one person is from a dysfunctional community and suggesting very strong measures against some problem the community faces, and the other person is from a functional community and thinks the first person is being extreme, fanatical or persecutory.</p><p>This happens a lot among, once again, atheists. One guy is like \u201cWE NEED TO DESTROY RELIGION IT CORRUPTS EVERYTHING IT TOUCHES ANYONE WHO MAKES ANY COMPROMISES WITH IT IS A TRAITOR KILL KILL KILL.\u201d And the other guy is like \u201cHello? Religion may not be literally true, but it usually just makes people feel more comfortable and inspires them to do nice things and we don\u2019t want to look like huge jerks here.\u201d Usually the first guy was raised Jehovah\u2019s Witness and the second guy was raised <a href=\"http://en.wikipedia.org/wiki/Moralistic_therapeutic_deism\">Moralistic Therapeutic Deist</a>.</p><p>But I\u2019ve also sometimes had this issue when I talk to feminists. They\u2019re like \u201cGuys need to be more concerned about women\u2019s boundaries, and women need to be willing to shame and embarrass guys who hit on them inappropriately.\u201d And maybe they spent high school hanging out with bros on the football team who thought asking women\u2019s consent was a boring technicality, and I spent high school hanging out entirely with extremely considerate but very shy geeks who spent their teenage years in a state of nightmarish loneliness and depression because they were <a href=\"http://squid314.livejournal.com/328267.html\">too scared</a> to ask out women because the woman might try to shame and embarrass them for it.</p><p>And the big one is trust. There are so many people from extremely functional communities saying that people need to be more trusting and kind and take people at their word more often, and so many people from dysfunctional communities saying that\u2019s not how it works. Both are no doubt backed by ample advice from their own lives.</p><p>A blog like this one probably should promote the opinions and advice most likely to be underrepresented in the blog-reading populace (which is totally different from the populace at large). But this might convince \u201cthought leaders\u201d, who then use it to inspire change in the populace at large, which will probably be in the wrong direction. I think most of my friends are too leftist but society as a whole is too rightist \u2013 should I spread leftist or rightist memes among my friends?</p><p>I feel pretty okay about both being sort of a libertarian and writing <a href=\"https://slatestarcodex.com/2017/02/22/repost-the-non-libertarian-faq/\">an essay arguing against libertarianism</a>, because the world generally isn\u2019t libertarian enough but the sorts of people who read long online political essays generally are way more libertarian than can possibly be healthy.</p></div></div></div></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"gHCNhqxuJq2bZ2akb": 2, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PQ3nutgxfTgvq69Xt", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 76, "baseScore": 83, "extendedScore": null, "score": 0.000194, "legacy": true, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "XsMTxdQ6fprAQMoKi", "canonicalCollectionSlug": "codex", "canonicalBookId": "jF58hKP9ZLzgy22Jr", "canonicalNextPostSlug": "the-virtue-of-silence", "canonicalPrevPostSlug": "cardiologists-and-chinese-robbers", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 83, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<div class=\"ory-row\"><div class=\"ory-cell ory-cell-sm-12 ory-cell-xs-12\"><div class=\"ory-cell-inner ory-cell-leaf\"><div><p>\u201c<em>I don\u2019t practice what I preach because I\u2019m not the kind of person I\u2019m preaching to.</em>\u201d </p><p>\u2014 Bob Dobbs</p><p></p><p><strong id=\"I_\">I.</strong></p><p>I read Atlas Shrugged probably about a decade ago, and felt turned off by its promotion of selfishness as a moral ideal. I thought that was basically just being a jerk. After all, if there\u2019s one thing the world doesn\u2019t need (I thought) it\u2019s more selfishness.</p><p>Then I talked to a friend who told me Atlas Shrugged had changed his life. That he\u2019d been raised in a really strict family that had told him that ever enjoying himself was selfish and made him a bad person, that he had to be working at every moment to make his family and other people happy or else let them shame him to pieces. And the revelation that it was sometimes okay to consider your own happiness gave him the strength to stand up to them and turn his life around, while still keeping the basic human instinct of helping others when he wanted to and he felt they deserved it (as, indeed, do Rand characters).</p><p><strong id=\"II_\">II.</strong></p><p>The religious and the irreligious alike enjoy making fun of Reddit\u2019s r/atheism, which combines an extreme strawmanning of religious positions with childish insults and distasteful triumphalism. Recently the moderators themselves have become a bit embarrassed by it and instituted some rules intended to tone things down, leading to <a href=\"http://www.reddit.com/r/atheism/comments/1fzaai/65_of_responding_users_now_reject_banning_image/\">some</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzd0r/at_the_moment_15_of_the_top_25_posts_on_ratheism/\">of</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzn3n/i_for_one_am_eternally_grateful_that_there_is/\">the</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzhtl/fixed_approach_thread_to_remove_ujij_and_utuber/\">most</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzl0h/jij_if_you_want_a_different_ratheism_go_start/\">impressive</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzlmn/this_sub_is_now_useless_to_mobile_users_thanks_a/\">Internet</a> <a href=\"http://www.reddit.com/r/atheism/comments/1fzow2/remove_jij_give_the_sub_back_to_its_creator_skeen/\">drama</a> I have ever seen. In its midst, some people started talking about what the old strawmanning triumphalist r/atheism meant to them (see for example <a href=\"http://www.reddit.com/r/atheism/comments/1fraqe/why_i_dont_like_the_changes/\">here</a>).</p><p>A lot of them were raised in religious families where they would have been disowned if they had admitted to their atheism. Some of them were disowned for admitting to atheism, or lost boyfriends/girlfriends, or were terrified they might go to Hell. And then they found r/atheism, and saw people making fun of religion, and insulting it, in really REALLY offensive ways. And no one was striking them down with lightning. No one was shouting them down. No one was doing much of anything at all. And to see this taboo violated in the most shocking possible way with no repercussions sort of broke the spell for them, like as long as people were behaving respectfully to religion, even respectfully disagreeing, it still had this aura of invincibility about it, but if some perfectly normal person can post a a stupid comic where Jesus has gay sex with Mohammed, then there\u2019s this whole other world out there where religion holds no power.</p><p><a href=\"http://last-conformer.net/\">Gilbert</a> tells the story of how when, as a young Christian struggling with doubt, he would read r/atheism to remind himself that atheists could be pretty awful. r/atheism is doing a bad job at being the sort of people who can convert Gilbert, and the new mods\u2019 policy of \u201cyou should have more civil and intellectual discussions\u201d might work better on him. I think it would work better on me too.</p><p>But there is \u2013 previously unappreciated by me \u2013 a large population of people for whom really dumb offensive strawmannish memes are exactly what they need.</p><p><strong id=\"III_\">III.</strong></p><p>A friend described his experiences in the Landmark Forum\u2019s self-improvement workshop. He said their modus operandi was to get people to take responsibility for the outcome of their actions. His example was an office worker who always did substandard work, and was always making excuses like \u201cMy boss doesn\u2019t s support me\u201d or \u201cMy computer system isn\u2019t good enough\u201d or \u201cMy coworkers aren\u2019t pulling their fair share.\u201d Landmark says those kinds of excuses are what\u2019s keeping you back. And they taught (again, according to this one person) that the solution was to treat everything that happens in your life as your responsiblity \u2013 no excuses, just \u201cit was my fault\u201d or \u201cit\u2019s to my credit\u201d.</p><p>Then a few days later, I was reading a book on therapy which contained the phrase (I copied it down to make sure I got it right) \u201cDon\u2019t be so hard on yourself. No one else is as hard on yourself as you are. You are your own worst critic.\u201d</p><p>Notice that this encodes the exact opposite assumption. Landmark claims its members are biased against ever thinking ill of themselves, even when they deserve it. The therapy book claims that patients are biased towards always thinking ill of themselves, even when they don\u2019t deserve it.</p><p>And you know, both claims are probably spot on. There are definitely people who are too hard on themselves. Ozy Frantz has done an amazing job of getting me and many other people inclined towards skepticism about feminist and transgender issues, engaging with us, and gradually convincing us to be more respectful and aware through sheer kindness and willingness to engage people reasonably on every part of the political spectrum. Two days ago some people on Twitter \u2013 who were angry Ozy said one need not boycott everything Orson Scott Card has ever written just because he\u2019s against gay marriage \u2013 told Ozy they weren\u2019t a real transgender person and suggested lots of people secretly disliked them. And instead of doing what I would do and telling the trolls to go to hell, Ozy freaked out and worried they was doing everything wrong and <a href=\"http://pervocracy.tumblr.com/post/52503212252/okay-a-whole-bunch-of-people-are-asking-me-what\">decided to delete</a> everything they had ever written online. I know Ozy is their own worst critic and if that therapy book was aimed at people like them, it was entirely correct to say what it said.</p><p>On the other hand, I look at people like <a href=\"http://en.wikipedia.org/wiki/Amy%27s_Baking_Company_%28Kitchen_Nightmares%29\">Amy\u2019s Baking Company</a>, who are obviously terrible people, who get a high-status professional chef as well as thousands of random joes informing them of exactly what they are doing wrong, who are so clearly in the wrong that it seems impossible not to realize it \u2013 and who then go on to attribute the negativity to a \u201cconspiracy\u201d against them and deny any wrongdoing. They could probably use some Landmark.</p><p><strong id=\"IV_\">IV.</strong></p><p>In a recent essay I complained about <a href=\"http://slatestarcodex.com/2013/05/18/against-bravery-debates/\">bravery debates</a>, arguments where people boast about how brave they are to take an unorthodox and persecuted position, and their opponents counter that they\u2019re not persecuted heretics, they\u2019re a vast leviathan persecuting everyone else. But I think I underestimated an important reason why some debates have to be bravery debates.</p><p>Suppose there are two sides to an issue. Be more or less selfish. Post more or less offensive atheist memes. Be more or less willing to blame and criticize yourself.</p><p>There are some people who need to hear each side of the issue. Some people really need to hear the advice \u201cIt\u2019s okay to be selfish sometimes!\u201d Other people really need to hear the advice \u201cYou are being way too selfish and it\u2019s not okay.\u201d</p><p>It\u2019s really hard to target advice at exactly the people who need it. You can\u2019t go around giving everyone surveys to see how selfish they are, and give half of them Atlas Shrugged and half of them <a href=\"http://en.wikipedia.org/wiki/Peter_Singer#World_poverty\">the collected works of Peter Singer</a>. You can\u2019t even write really complicated books on how to tell whether you need more or less selfishness in your life \u2013 they\u2019re not going to be as buyable, as readable, or as memorable as Atlas Shrugged. To a first approximation, all you can do is saturate society with pro-selfishness or anti-selfishness messages, and realize you\u2019ll be hurting a select few people while helping the majority.</p><p>But in this case, it makes a really big deal what the majority actually is.</p><p>Suppose an Objectivist argues \u201cOur culture has become too self-sacrificing! Everyone is told their entire life that the only purpose of living is to work for other people. As a result, people are miserable and no one is allowed to enjoy themselves at all.\u201d If they\u2019re right, then helping spread Objectivism is probably a good idea \u2013 it will help these legions of poor insufficiently-selfish people, but there will be very few too-selfish-already people who will be screwed up by the advice.</p><p>But suppose Peter Singer argues \u201cWe live in a culture of selfishness! Everyone is always told to look out for number one, and the poor are completely neglected!\u201d Well, then we want to give everyone the collected works of Peter Singer so we can solve this problem, and we don\u2019t have to worry about accidentally traumatizing the poor self-sacrificing people more, because we\u2019ve already agreed there aren\u2019t very many of these at all.</p><p>It\u2019s much easier to be charitable in political debates when you view the two participants as coming from two different cultures that err on opposite sides, each trying to propose advice that would help their own culture, each being tragically unaware that the other culture exists.</p><p>A lot of the time this happens when one person is from a dysfunctional community and suggesting very strong measures against some problem the community faces, and the other person is from a functional community and thinks the first person is being extreme, fanatical or persecutory.</p><p>This happens a lot among, once again, atheists. One guy is like \u201cWE NEED TO DESTROY RELIGION IT CORRUPTS EVERYTHING IT TOUCHES ANYONE WHO MAKES ANY COMPROMISES WITH IT IS A TRAITOR KILL KILL KILL.\u201d And the other guy is like \u201cHello? Religion may not be literally true, but it usually just makes people feel more comfortable and inspires them to do nice things and we don\u2019t want to look like huge jerks here.\u201d Usually the first guy was raised Jehovah\u2019s Witness and the second guy was raised <a href=\"http://en.wikipedia.org/wiki/Moralistic_therapeutic_deism\">Moralistic Therapeutic Deist</a>.</p><p>But I\u2019ve also sometimes had this issue when I talk to feminists. They\u2019re like \u201cGuys need to be more concerned about women\u2019s boundaries, and women need to be willing to shame and embarrass guys who hit on them inappropriately.\u201d And maybe they spent high school hanging out with bros on the football team who thought asking women\u2019s consent was a boring technicality, and I spent high school hanging out entirely with extremely considerate but very shy geeks who spent their teenage years in a state of nightmarish loneliness and depression because they were <a href=\"http://squid314.livejournal.com/328267.html\">too scared</a> to ask out women because the woman might try to shame and embarrass them for it.</p><p>And the big one is trust. There are so many people from extremely functional communities saying that people need to be more trusting and kind and take people at their word more often, and so many people from dysfunctional communities saying that\u2019s not how it works. Both are no doubt backed by ample advice from their own lives.</p><p>A blog like this one probably should promote the opinions and advice most likely to be underrepresented in the blog-reading populace (which is totally different from the populace at large). But this might convince \u201cthought leaders\u201d, who then use it to inspire change in the populace at large, which will probably be in the wrong direction. I think most of my friends are too leftist but society as a whole is too rightist \u2013 should I spread leftist or rightist memes among my friends?</p><p>I feel pretty okay about both being sort of a libertarian and writing <a href=\"https://slatestarcodex.com/2017/02/22/repost-the-non-libertarian-faq/\">an essay arguing against libertarianism</a>, because the world generally isn\u2019t libertarian enough but the sorts of people who read long online political essays generally are way more libertarian than can possibly be healthy.</p></div></div></div></div>", "sections": [{"title": "I.", "anchor": "I_", "level": 1}, {"title": "II.", "anchor": "II_", "level": 1}, {"title": "III.", "anchor": "III_", "level": 1}, {"title": "IV.", "anchor": "IV_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-10T06:12:49.639Z", "modifiedAt": null, "url": null, "title": "Useful Concepts Repository", "slug": "useful-concepts-repository", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:39.114Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/umzNiYpHLypdcXuEf/useful-concepts-repository", "pageUrlRelative": "/posts/umzNiYpHLypdcXuEf/useful-concepts-repository", "linkUrl": "https://www.lesswrong.com/posts/umzNiYpHLypdcXuEf/useful-concepts-repository", "postedAtFormatted": "Monday, June 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Useful%20Concepts%20Repository&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AUseful%20Concepts%20Repository%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FumzNiYpHLypdcXuEf%2Fuseful-concepts-repository%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Useful%20Concepts%20Repository%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FumzNiYpHLypdcXuEf%2Fuseful-concepts-repository", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FumzNiYpHLypdcXuEf%2Fuseful-concepts-repository", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 193, "htmlBody": "<p><strong>See also:</strong>&nbsp;<a href=\"/lw/gx5/boring_advice_repository/\">Boring Advice Repository</a>, <a href=\"/lw/h2m/solved_problems_repository/\">Solved Problems Repository</a>, <a href=\"/lw/h7d/grad_student_advice_repository/\">Grad Student Advice Repository</a></p>\n<p>I often find that my understanding of the world is strongly informed by a few key concepts. For example, I've repeatedly found the concept of <a href=\"https://en.wikipedia.org/wiki/Opportunity_cost\">opportunity cost</a> to be a useful frame. My previous post on <a href=\"/lw/hba/privileging_the_question/\">privileging the question</a> is in some sense about the opportunity cost of paying attention to certain kinds of questions (namely that you don't get to use that attention on other kinds of questions). <a href=\"/lw/3gj/efficient_charity_do_unto_others/\">Efficient charity</a> can also be thought of in terms of the opportunity cost of donating inefficiently to charity. I've also found the concept of <a href=\"http://en.wikipedia.org/wiki/Incentive\">incentive structure</a>&nbsp;very useful for thinking about the behavior of groups of people in aggregate (see <a href=\"http://en.wikipedia.org/wiki/Perverse_incentive\">perverse incentive</a>).&nbsp;</p>\n<p>I'd like people to use this thread to post examples of concepts they've found particularly useful for understanding the world. I'm personally more interested in concepts that don't come from the <a href=\"http://wiki.lesswrong.com/wiki/Sequences\">Sequences</a>, but comments describing a concept from the Sequences and explaining why you've found it useful may help people new to the Sequences. (\"Useful\" should be interpreted broadly: a concept specific to a particular field might be useful more generally as a metaphor.)&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "ABG8vt87eW4FFA6gD": 1, "Eha62RrqBtEbpcEza": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "umzNiYpHLypdcXuEf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 45, "extendedScore": null, "score": 1.2274909389515175e-06, "legacy": true, "legacyId": "22665", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 105, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HEn2qiMxk5BggN83J", "iTzvJ7kKK2TYJhYHB", "9iofKNvYKZe3T7MpS", "6vcxuRHzeM99jYcYd", "pC47ZTsPNAkjavkXs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-10T12:07:21.442Z", "modifiedAt": null, "url": null, "title": "Meetup : Rationalist Housewarming at Isengard (Melbourne)", "slug": "meetup-rationalist-housewarming-at-isengard-melbourne", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:03.256Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BraydenM", "createdAt": "2013-06-10T09:17:31.294Z", "isAdmin": false, "displayName": "BraydenM"}, "userId": "KBZHqcMC6z2rPZkZK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Y48WAxNXgs3CmFNfs/meetup-rationalist-housewarming-at-isengard-melbourne", "pageUrlRelative": "/posts/Y48WAxNXgs3CmFNfs/meetup-rationalist-housewarming-at-isengard-melbourne", "linkUrl": "https://www.lesswrong.com/posts/Y48WAxNXgs3CmFNfs/meetup-rationalist-housewarming-at-isengard-melbourne", "postedAtFormatted": "Monday, June 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Rationalist%20Housewarming%20at%20Isengard%20(Melbourne)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Rationalist%20Housewarming%20at%20Isengard%20(Melbourne)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY48WAxNXgs3CmFNfs%2Fmeetup-rationalist-housewarming-at-isengard-melbourne%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Rationalist%20Housewarming%20at%20Isengard%20(Melbourne)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY48WAxNXgs3CmFNfs%2Fmeetup-rationalist-housewarming-at-isengard-melbourne", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY48WAxNXgs3CmFNfs%2Fmeetup-rationalist-housewarming-at-isengard-melbourne", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 123, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nm'>Rationalist Housewarming at Isengard (Melbourne)</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">15 June 2013 08:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2105 / 5 Caraval Lane Docklands</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The first and only (as far as we know) Australian Rationalist share house is finally here, our lofty apartment that towers imposingly over the lower inhabitants of Docklands. Come and help us celebrate this occasion, by bringing your favourite middle-earth or fictional persona for a night of drinking and rational conversation. Some desserts will be provided.\nWe are easiest to get to by public transport, but 24hr carparking is available nearby for $6 (or even closer if you want to pay more) See <a href=\"http://www.harbourtownmelbourne.com.au/transport.html\" rel=\"nofollow\">http://www.harbourtownmelbourne.com.au/transport.html</a>\nPlease RSVP below or at https://www.facebook.com/events/341169522677511/</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nm'>Rationalist Housewarming at Isengard (Melbourne)</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Y48WAxNXgs3CmFNfs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 1.2277586325808893e-06, "legacy": true, "legacyId": "22912", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Rationalist_Housewarming_at_Isengard__Melbourne_\">Discussion article for the meetup : <a href=\"/meetups/nm\">Rationalist Housewarming at Isengard (Melbourne)</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">15 June 2013 08:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2105 / 5 Caraval Lane Docklands</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The first and only (as far as we know) Australian Rationalist share house is finally here, our lofty apartment that towers imposingly over the lower inhabitants of Docklands. Come and help us celebrate this occasion, by bringing your favourite middle-earth or fictional persona for a night of drinking and rational conversation. Some desserts will be provided.\nWe are easiest to get to by public transport, but 24hr carparking is available nearby for $6 (or even closer if you want to pay more) See <a href=\"http://www.harbourtownmelbourne.com.au/transport.html\" rel=\"nofollow\">http://www.harbourtownmelbourne.com.au/transport.html</a>\nPlease RSVP below or at https://www.facebook.com/events/341169522677511/</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Rationalist_Housewarming_at_Isengard__Melbourne_1\">Discussion article for the meetup : <a href=\"/meetups/nm\">Rationalist Housewarming at Isengard (Melbourne)</a></h2>", "sections": [{"title": "Discussion article for the meetup : Rationalist Housewarming at Isengard (Melbourne)", "anchor": "Discussion_article_for_the_meetup___Rationalist_Housewarming_at_Isengard__Melbourne_", "level": 1}, {"title": "Discussion article for the meetup : Rationalist Housewarming at Isengard (Melbourne)", "anchor": "Discussion_article_for_the_meetup___Rationalist_Housewarming_at_Isengard__Melbourne_1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-10T13:09:21.691Z", "modifiedAt": null, "url": null, "title": "Weak evidence that eating vegetables makes you live longer", "slug": "weak-evidence-that-eating-vegetables-makes-you-live-longer", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:32.636Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iXhdLqZ7JWoQeH7oc/weak-evidence-that-eating-vegetables-makes-you-live-longer", "pageUrlRelative": "/posts/iXhdLqZ7JWoQeH7oc/weak-evidence-that-eating-vegetables-makes-you-live-longer", "linkUrl": "https://www.lesswrong.com/posts/iXhdLqZ7JWoQeH7oc/weak-evidence-that-eating-vegetables-makes-you-live-longer", "postedAtFormatted": "Monday, June 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weak%20evidence%20that%20eating%20vegetables%20makes%20you%20live%20longer&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeak%20evidence%20that%20eating%20vegetables%20makes%20you%20live%20longer%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXhdLqZ7JWoQeH7oc%2Fweak-evidence-that-eating-vegetables-makes-you-live-longer%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weak%20evidence%20that%20eating%20vegetables%20makes%20you%20live%20longer%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXhdLqZ7JWoQeH7oc%2Fweak-evidence-that-eating-vegetables-makes-you-live-longer", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiXhdLqZ7JWoQeH7oc%2Fweak-evidence-that-eating-vegetables-makes-you-live-longer", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 674, "htmlBody": "<p>People vary in how much they can taste bitter things. If you go around giving people the chemical Phenylthiocarbamide (PTC), which you shouldn't do, because it is toxic, you'll find that some people taste it as a strongly bitter while others can't taste it at all. Same with 6-n-propylthiouracil (PROP). While these aren't common in food, they're very similar to chemicals that are in a lot of foods, so you might think that how much you can taste PTC or PROP might influence what foods you like.</p>\n<p>We can test this. Give people various foods that there is dispute about the bitterness of, and then compare their preferences to their sensitivity to PTC or PROP. Several studies have done this:</p>\n<ul>\n<li><a href=\"http://dmd.aspetjournals.org/content/29/4/535.full\">Genetic Taste Markers and Food Preferences</a> (2001, n=121) found that people who could taste PROP better were more likely to say they didn't like <a href=\"http://en.wikipedia.org/wiki/Cruciferous_vegetables\">cruciferous vegetables</a> (broccoli, cabbage, etc). </li>\n<li><a href=\"http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=554124\">Taste and food preferences as predictors of dietary practices in young women</a> (1999, n=157) found that \"sensitivity to the bitter taste of PROP was associated with reduced preferences for Brussels sprouts, cabbage, spinach and coffee beverages\". But it's behind a paywall, so this is just from the abstract. The same authors in a related study, <a href=\"http://ajcn.nutrition.org/content/70/1/28.full\">Food preferences and reported frequencies of food consumption as predictors of current diet in young women</a> (1999, n=87) found that people who reported liking cruciferous vegetables less ate them 1/3 as often. </li>\n<li><a href=\"http://www.ncbi.nlm.nih.gov/pubmed/16368118\">Bitter taste markers explain variability in vegetable sweetness, bitterness, and intake</a> (2006, n=110) found that people \"who taste PROP as most bitter also tasted the vegetables as most bitter and least sweet.\" This one is also paywalled, so I've only looked at the abstract. </li>\n</ul>\n<p>Vegetables like broccoli are often thought to be good for you, so shouldn't we expect to see people who taste PROP and PTC not live as long, because they're eating less of those? Ideally we would test how sensitive people are to bitterness at some youngish age, and then watch them for the next 80 years to see how long they lived. But 80 years is a long time to wait, and you're going to need a large sample because we don't expect the effect to be that big. Another option would be to measure sensitivity to bitterness, and see whether it decreased with age in the same way we would expect if the people with increased bitterness sensitivity were dying earlier. But this is going to be impractical to separate from the hypothesis that simply individual people lose some of their sense of taste over time.</p>\n<p>Luckily, it turns out that this tasting ability is very strongly genetic. People with one variant of the gene <a href=\"http://en.wikipedia.org/wiki/TAS2R38\">TAS2R38</a> can nearly always taste PTC while people with another variant almost never can. So we can sample people at any age and get an estimate of how likely they were to have avoided vegetables for taste reasons. Are older people less likely to have the gene variant for tasting bitterness? It turns out they are. In <a href=\"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0045232\">Bitter Taste Receptor Polymorphisms and Human Aging</a> (2012, n=941) they tested Calabrians for their bitterness gene variant, and did find that older people were less likely to have the variant for detecting bitterness:</p>\n<p><img src=\"http://www.jefftk.com/age_tas216_bitterness.png\" alt=\"\" /></p>\n<p>So can we say that (a) eating vegetables will help you live longer and (b) if vegetables taste bitter to you should eat them anyway to get benefit (a)? Unfortunately it's not that clear. Vegetables aren't the only common food with these bitter compounds, so it might be something else. Other bitter-to-some foods that these non-bitter-tasters might have been eating more of include coffee, tea, grapefruit juice, soy, cigarettes (<a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2268904/?report=classic\">maybe</a>), and probably other things we haven't tested. There's also the possibility that the older and younger participants in the longevity study aren't the same group of people genetically, and what they're actually capturing is population changes in Calabria. One way to test that would be to repeat the study in several different places, as we would expect population drift to be independent of sensitivity to bitterness.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iXhdLqZ7JWoQeH7oc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 14, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "22913", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-10T16:14:35.863Z", "modifiedAt": null, "url": null, "title": "Are imaginary and complex numbers of decibans meaningful?", "slug": "are-imaginary-and-complex-numbers-of-decibans-meaningful", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:03.349Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cwqHLp6sMRQ72DLfY/are-imaginary-and-complex-numbers-of-decibans-meaningful", "pageUrlRelative": "/posts/cwqHLp6sMRQ72DLfY/are-imaginary-and-complex-numbers-of-decibans-meaningful", "linkUrl": "https://www.lesswrong.com/posts/cwqHLp6sMRQ72DLfY/are-imaginary-and-complex-numbers-of-decibans-meaningful", "postedAtFormatted": "Monday, June 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20imaginary%20and%20complex%20numbers%20of%20decibans%20meaningful%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20imaginary%20and%20complex%20numbers%20of%20decibans%20meaningful%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcwqHLp6sMRQ72DLfY%2Fare-imaginary-and-complex-numbers-of-decibans-meaningful%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20imaginary%20and%20complex%20numbers%20of%20decibans%20meaningful%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcwqHLp6sMRQ72DLfY%2Fare-imaginary-and-complex-numbers-of-decibans-meaningful", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcwqHLp6sMRQ72DLfY%2Fare-imaginary-and-complex-numbers-of-decibans-meaningful", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<p>It's well-established that 0 decibans means 1:1 odds or 50% confidence; that 10 decibans means 10:1 odds; that -10 decibans means 1:10 odds; and that fractional numbers of decibans have similar meaning.</p>\n<p>Does it make sense to talk about \"i decibans\", or \"10 + 20i decibans\"? If so, what does that actually mean?</p>\n<p><a id=\"more\"></a>I'm currently roughing out what may eventually become a formal specification for a protocol. It includes a numerical field for a level of confidence, measured in decibans. I'd like to know if I should simply define the spec as only allowing real numbers, or if there could be some purpose in allowing for complex numbers, as well.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cwqHLp6sMRQ72DLfY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 2, "extendedScore": null, "score": 1.2279453765459223e-06, "legacy": true, "legacyId": "22914", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-10T19:32:02.319Z", "modifiedAt": null, "url": null, "title": "[Link] Status Anxiety", "slug": "link-status-anxiety", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:02.348Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KTpocH2qYTLHDc9fx/link-status-anxiety", "pageUrlRelative": "/posts/KTpocH2qYTLHDc9fx/link-status-anxiety", "linkUrl": "https://www.lesswrong.com/posts/KTpocH2qYTLHDc9fx/link-status-anxiety", "postedAtFormatted": "Monday, June 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Status%20Anxiety&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Status%20Anxiety%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKTpocH2qYTLHDc9fx%2Flink-status-anxiety%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Status%20Anxiety%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKTpocH2qYTLHDc9fx%2Flink-status-anxiety", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKTpocH2qYTLHDc9fx%2Flink-status-anxiety", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<p><a href=\"http://www.youtube.com/watch?v=_acgqf27CIU\">Alain de Botton speaks about Status Anxiety</a><br /><br />There is nowhere where I've witnessed (and felt) more status anxiety <em>expressed</em> and talked about than in Lesswrong. I tried to partly<a href=\"/lw/hbp/using_evolution_for_marriage_or_sex/\"> dispel the mith</a> at least as it regards sexuality.</p>\n<p>People talk about status in all its forms and shapes a lot here. Which made me wonder, what do you think of Alain de Botton's opinions on \"status addiction\" in western societies?</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KTpocH2qYTLHDc9fx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -11, "extendedScore": null, "score": 1.2280945424590578e-06, "legacy": true, "legacyId": "22915", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["oFMywHmJffsCSDNB7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-10T23:24:07.259Z", "modifiedAt": null, "url": null, "title": "[link] Scott Aaronson on free will", "slug": "link-scott-aaronson-on-free-will", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:01.017Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielVarga", "createdAt": "2009-09-16T22:21:30.125Z", "isAdmin": false, "displayName": "DanielVarga"}, "userId": "rqE4DaRxHwBpQXj96", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uNn4kRYCat9oqKsGT/link-scott-aaronson-on-free-will", "pageUrlRelative": "/posts/uNn4kRYCat9oqKsGT/link-scott-aaronson-on-free-will", "linkUrl": "https://www.lesswrong.com/posts/uNn4kRYCat9oqKsGT/link-scott-aaronson-on-free-will", "postedAtFormatted": "Monday, June 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20Scott%20Aaronson%20on%20free%20will&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20Scott%20Aaronson%20on%20free%20will%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuNn4kRYCat9oqKsGT%2Flink-scott-aaronson-on-free-will%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20Scott%20Aaronson%20on%20free%20will%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuNn4kRYCat9oqKsGT%2Flink-scott-aaronson-on-free-will", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuNn4kRYCat9oqKsGT%2Flink-scott-aaronson-on-free-will", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 176, "htmlBody": "<p>Scott Aaronson has a new 85 page essay up, titled <a href=\"http://arxiv.org/pdf/1306.0159.pdf\">\"The Ghost in the Quantum Turing Machine\"</a>.&nbsp;(<a href=\"http://arxiv.org/abs/1306.0159\">Abstract here</a>.) In Section 2.11 (Singulatarianism) he explicitly mentions Eliezer as an influence. But that's just a starting point, and he then moves in a direction that's very far from any kind of LW consensus. Among other things, he suggests that a crucial qualitative difference between a person and a digital upload is that the laws of physics prohibit making perfect copies of a person. Personally, I find the arguments completely unconvincing, but Aaronson is always thought-provoking and fun to read, and this is a good excuse to read about things like (I quote the abstract) \"the No-Cloning Theorem, the measurement problem, decoherence, chaos, the arrow of time, the holographic principle, Newcomb's paradox, Boltzmann brains, algorithmic information theory, and the Common Prior Assumption\". This is not just a shopping list of buzzwords, these are all important components of the author's main argument. It unfortunately still seems weak to me, but the time spent reading it is not wasted at all.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb1b8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uNn4kRYCat9oqKsGT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 32, "extendedScore": null, "score": 1.2282699208105249e-06, "legacy": true, "legacyId": "22916", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 109, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-11T04:49:45.858Z", "modifiedAt": null, "url": null, "title": "A personal history of involvement with effective altruism", "slug": "a-personal-history-of-involvement-with-effective-altruism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:37.673Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism", "pageUrlRelative": "/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism", "linkUrl": "https://www.lesswrong.com/posts/QSHwKqyY4GAXKi9tX/a-personal-history-of-involvement-with-effective-altruism", "postedAtFormatted": "Tuesday, June 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20personal%20history%20of%20involvement%20with%20effective%20altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20personal%20history%20of%20involvement%20with%20effective%20altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQSHwKqyY4GAXKi9tX%2Fa-personal-history-of-involvement-with-effective-altruism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20personal%20history%20of%20involvement%20with%20effective%20altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQSHwKqyY4GAXKi9tX%2Fa-personal-history-of-involvement-with-effective-altruism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQSHwKqyY4GAXKi9tX%2Fa-personal-history-of-involvement-with-effective-altruism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1499, "htmlBody": "<p class=\"MsoNormal\">Over the coming weeks, I intend to write up a history of the different parts of the effective altruist movement and their interrelations. It&rsquo;s natural to start with the part that I know best: the history of my own involvement with effective altruism.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<h2>Interest in altruism rooted in literature</h2>\n<p class=\"MsoNormal\">My interest in altruism traces to early childhood. Unbeknownst to me, my verbal comprehension ability was unusually high relative to my other cognitive abilities, and for this reason, I gravitated strongly toward reading. Starting from the age of six, I spent hours a day reading fiction. I found many of the stories that I read to be emotionally compelling, and identified with the characters.</p>\n<p class=\"MsoNormal\">My interest is altruism is largely <em>literary</em> in origin &mdash; I perceive the sweep of history to be a story, and I want things to go well for the characters, and want the story to have a happy ending. I was influenced both by portrayals of sympathetic, poor characters in need, and by stories of the triumph of the human spirit, and I wanted to help the downtrodden, and contribute to the formation of peak positive human experiences.&nbsp;</p>\n<p class=\"MsoNormal\">I sometimes wonder whether there are other people with altruistic tendencies that are literary in origin, and whether they would be good candidate members of the effective altruist movement. There is some history of artists having altruistic goals. The great painter Vincent van Gogh moved to an impoverished coal mine to <a href=\"http://www.biography.com/people/vincent-van-gogh-9515695\">preach and minister to the sick</a>. The great mathematician Alexander Grothendieck gave <a href=\"http://www.ams.org/notices/200410/fea-grothendieck-part2.pdf\">shelter to the homeless</a>.</p>\n<h2>An analytical bent, and utilitarianism</h2>\n<p class=\"MsoNormal\">When I was young, I had vague and dreamy hopes about how I might make the world a better place. As I grew older, I found myself more focused on careful reasoning and rationality.</p>\n<p class=\"MsoNormal\">In high school, I met <a href=\"http://blog.givewell.org/2010/06/03/my-donation-for-2009-guest-post-from-dario-amodei/\">Dario Amodei</a>, who introduced me to utilitarianism. The ethical framework immediately resonated with me. For me, it corresponded to valuing the well being of all characters in the story &mdash; a manifestation of <a href=\"http://reducing-suffering.blogspot.com/2013/01/mr-rogers-on-unconditional-love.html\">universal love</a>.</p>\n<p class=\"MsoNormal\">This was the birth of my interest in maximizing aggregated global welfare. Maximizing aggregated global welfare corresponds to maximizing cost-effectiveness, and so this can be thought of as the origin of my interest in <em>effective</em> altruism.&nbsp;</p>\n<p class=\"MsoNormal\">I believe that I would have developed interest in global welfare, and in effective altruism, on my own accord, without encountering any members of the effective altruist movement. But for reasons that I describe below, if not for meeting these people, I don&rsquo;t think that my interests would have been actionable.</p>\n<h2>Epistemic paralysis</h2>\n<p class=\"MsoNormal\">My analytical bent had a downside.</p>\n<p class=\"MsoNormal\">Issues pertaining to the human world are very complex, and there aren&rsquo;t clear-cut objective answers to the question of how best to make the world a better place. On a given issue, there are many arguments for a given position, and many counterarguments to the arguments, and many counterarguments to the counterarguments, and so on.&nbsp;</p>\n<p class=\"MsoNormal\">Contemplating these resulted in my falling into a state of <a href=\"http://squid314.livejournal.com/350090.html\">epistemic learned helplessness</a>. I became convinced that it's not possible to rationally develop confidence in views concerning how to make the world a better place.</p>\n<h2>Enter GiveWell</h2>\n<p class=\"MsoNormal\">In 2007, my college friend <a href=\"http://80000hours.org/blog/116-interview-with-brian-tomasik\">Brian Tomasik</a> pointed me to GiveWell. At the time, GiveWell had just launched, and there wasn&rsquo;t very much on the website, so I soon forgot about it.</p>\n<p class=\"MsoNormal\">In 2009, my high school friend Dario, who had introduced me to utilitarianism, pointed me to GiveWell again. By this point, there was much more information available on the GiveWell website.&nbsp;</p>\n<p class=\"MsoNormal\">I began following GiveWell closely. I was very impressed by the fact that co-founders Holden and Elie seemed to be making sense of the ambiguous world of effective philanthropy. I hadn&rsquo;t thought that it was possible to reason so well about the human world. This made effective altruism more credible in my eyes, and inspired me. If hadn&rsquo;t encountered GiveWell, I may not have gotten involved with the effective philanthropy movement at all, although I may have become involved through interactions of Less Wrong, and I may have gone on to do socially valuable work in <a href=\"http://www.mathisbeauty.org\">math education</a>.</p>\n<p class=\"MsoNormal\">I became progressively more impressed by GiveWell over time, and wanted to become involved. In 2011, I did volunteer work for GiveWell, and in 2012, I began working at GiveWell as a research analyst.</p>\n<p class=\"MsoNormal\">While working at GiveWell, I learned a great deal about how to think about philanthropy, and about epistemology more generally. A crucial development in my thinking was the gradual realization that:</p>\n<ul>\n<li>Cost-effectiveness estimates that are supported by a single line of evidence are unreliable.</li>\n<li>Investigation generally reveals that interventions that appear highly cost-effective relative to other interventions are often much worse (in a relative sense) than one would initially guess.</li>\n<li>One can become much more confident in one&rsquo;s assessment of the value of a philanthropic intervention by <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">examining it from many different angles</a>.&nbsp;</li>\n</ul>\n<p class=\"MsoNormal\">I wrote about this realization in my post <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>.&nbsp;</p>\n<p class=\"MsoNormal\">This shift in my thinking gradually percolated, and I realized that my entire epistemological framework had been seriously flawed, because <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">I was relying too much on a small number of relatively strong arguments rather than a large number of independent weak arguments</a>.&nbsp;</p>\n<p class=\"MsoNormal\">Many people had tried to explain this to me in the past, but I was unable to understand what they were driving at, and it was only through my work at GiveWell and my interactions with my coworkers that I was finally able to understand. The benefits of this realization have spanned many aspects of my life, and have substantially increased my altruistic human capital.&nbsp;</p>\n<p class=\"MsoNormal\">If GiveWell hadn&rsquo;t existed, it&rsquo;s very possible that I wouldn&rsquo;t have learned these things. If Dario hadn&rsquo;t pointed me to GiveWell, I&rsquo;m sure that I would have encountered GiveWell eventually, but it may have been too late for it to be possible for me to work there, and so I may not have had the associated learning opportunities.</p>\n<p class=\"MsoNormal\">My involvement with GiveWell also facilitated my meeting <a href=\"http://blog.givewell.org/2011/08/05/guest-post-from-vipul-naik/\">Vipul Naik</a>, the founder of <a href=\"http://openborders.info/\">Open Borders</a>. We&rsquo;ve had many fruitful interactions related to maximizing global welfare, and if I hadn&rsquo;t met him through GiveWell, it may have been years before we met.&nbsp;</p>\n<h2>The significance of Less Wrong</h2>\n<p class=\"MsoNormal\">Several people pointed me to Overcoming Bias and <a href=\"/Downloads/lesswrong.com\">Less Wrong</a> starting in 2008, but at the time the posts didn&rsquo;t draw me in relative to the fascination of <a href=\"http://www.mathisbeauty.org/preludereciprocitylaws.pdf\">reciprocity laws in algebraic number theory</a>. In early 2010, Brian Tomasik pointed me to some of <a href=\"/lw/6ga/index_of_yvains_excellent_articles/\">Yvain&rsquo;s articles</a> on Less Wrong. With the background context of me following GiveWell, Yvain&rsquo;s posts on utilitarianism really resonated with me. So I started reading Less Wrong.&nbsp;</p>\n<p class=\"MsoNormal\">I met many impressive people who are seriously interested in effective altruism through Less Wrong. Among these are:</p>\n<ul>\n<li><a href=\"https://sites.google.com/site/nbeckstead/\">Nick Beckstead</a> &mdash; A new postdoc at Oxford University (specifically, the <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a>) who wrote the thesis <a href=\"https://sites.google.com/site/nbeckstead/research\">On the Overwhelming Importance of Shaping the Far Future</a>.</li>\n<li><a href=\"/user/paulfchristiano/overview/\">Paul Christiano</a> and <a href=\"/user/jsteinhardt/overview/\">Jacob Steinhardt</a> &mdash; graduate students in theory of computing and machine learning at Berkeley and Stanford (respectively). Jacob is a <a href=\"http://www.hertzfoundation.org/dx/fellows/fellow_profile.aspx?d=1205\">Hertz Fellow</a>, and Paul coauthored a 48 page paper titled <a href=\"http://www.arxiv.org/abs/1203.4740\">Quantum Money from Hidden Subspaces</a> as an undergraduate. Paul <a href=\"http://rationalaltruist.com/\">has thought a great deal about rational altruism,</a> and Jacob is a member of <a href=\"http://www.vannevargroup.org/\">The Vannevar Group</a>, which aims to accelerate scientific progress to create the greatest amount of social good.</li>\n<li><a href=\"http://math.berkeley.edu/~qchu/\">Qiaochu Yuan</a> &mdash; A math graduate student at Berkeley who has the <a href=\"http://mathoverflow.net/users/290/qiaochu-yuan\">sixth highest karma score on MathOverflow</a>. I&rsquo;ve been enjoying learning math from Qiaochu.</li>\n<li><a href=\"/user/CarlShulman/overview/\">Carl Shulman</a> and <a href=\"http://rationality.org/about/\">Dan Keys</a>. I&rsquo;ve found very intellectually stimulating and have learned a great deal from them.</li>\n<li><a href=\"http://lukeprog.com/\">Luke Muehlhauser</a> &mdash; The executive director of MIRI.</li>\n<li>Others &mdash; Including Julia Galef, Anna Salamon, Katja Grace, Louie Helm.</li>\n</ul>\n<p class=\"MsoNormal\">They&rsquo;ve helped me retain my motivation to do the most good, and have aided me in thinking about effective altruism. They constitute a substantial chunk of the most impressive people who I know in my age group.</p>\n<p class=\"MsoNormal\">It&rsquo;s genuinely unclear whether I would have gotten to know these people if Eliezer hadn&rsquo;t started Less Wrong.&nbsp;</p>\n<h2>Closing summary</h2>\n<p class=\"MsoNormal\">My innate inclinations got me interested in effective altruism, but they probably wouldn&rsquo;t have sufficed for my interest to be actionable. Beyond my innate inclinations, the things that stand out most in my mind as having been crucial are</p>\n<ul>\n<li>Dario introducing me to GiveWell</li>\n<li>Working at GiveWell</li>\n<li>Meeting Vipul through GiveWell</li>\n<li>Eliezer starting Less Wrong</li>\n<li>Meeting peers through Less Wrong</li>\n</ul>\n<p class=\"MsoNormal\">Working at GiveWell substantially increased my altruistic human capital. I&rsquo;ve learned a great deal from the GiveWell staff, from Vipul, and from the members of the Less Wrong community listed above. We&rsquo;ve had fruitful collaborations, and they&rsquo;ve helped me retain my motivation to do the most good.</p>\n<p class=\"MsoNormal\">The personal growth benefits that I derived from working at GiveWell are unusual, if only because GiveWell&rsquo;s staff is small. The networking benefits from Less Wrong are shared by many others.</p>\n<p class=\"MsoNormal\"><strong>Note:</strong> I formerly worked as a research analyst at GiveWell. All views here are my own.&nbsp;</p>\n<p class=\"MsoNormal\"><em>This post is <a href=\"http://effective-altruism.com/node/37\">cross-posted</a> at <a href=\"http://www.effective-altruism.com\">www.effective-altruism.com</a>.</em>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QSHwKqyY4GAXKi9tX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 19, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "22917", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\">Over the coming weeks, I intend to write up a history of the different parts of the effective altruist movement and their interrelations. It\u2019s natural to start with the part that I know best: the history of my own involvement with effective altruism.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<h2 id=\"Interest_in_altruism_rooted_in_literature\">Interest in altruism rooted in literature</h2>\n<p class=\"MsoNormal\">My interest in altruism traces to early childhood. Unbeknownst to me, my verbal comprehension ability was unusually high relative to my other cognitive abilities, and for this reason, I gravitated strongly toward reading. Starting from the age of six, I spent hours a day reading fiction. I found many of the stories that I read to be emotionally compelling, and identified with the characters.</p>\n<p class=\"MsoNormal\">My interest is altruism is largely <em>literary</em> in origin \u2014 I perceive the sweep of history to be a story, and I want things to go well for the characters, and want the story to have a happy ending. I was influenced both by portrayals of sympathetic, poor characters in need, and by stories of the triumph of the human spirit, and I wanted to help the downtrodden, and contribute to the formation of peak positive human experiences.&nbsp;</p>\n<p class=\"MsoNormal\">I sometimes wonder whether there are other people with altruistic tendencies that are literary in origin, and whether they would be good candidate members of the effective altruist movement. There is some history of artists having altruistic goals. The great painter Vincent van Gogh moved to an impoverished coal mine to <a href=\"http://www.biography.com/people/vincent-van-gogh-9515695\">preach and minister to the sick</a>. The great mathematician Alexander Grothendieck gave <a href=\"http://www.ams.org/notices/200410/fea-grothendieck-part2.pdf\">shelter to the homeless</a>.</p>\n<h2 id=\"An_analytical_bent__and_utilitarianism\">An analytical bent, and utilitarianism</h2>\n<p class=\"MsoNormal\">When I was young, I had vague and dreamy hopes about how I might make the world a better place. As I grew older, I found myself more focused on careful reasoning and rationality.</p>\n<p class=\"MsoNormal\">In high school, I met <a href=\"http://blog.givewell.org/2010/06/03/my-donation-for-2009-guest-post-from-dario-amodei/\">Dario Amodei</a>, who introduced me to utilitarianism. The ethical framework immediately resonated with me. For me, it corresponded to valuing the well being of all characters in the story \u2014 a manifestation of <a href=\"http://reducing-suffering.blogspot.com/2013/01/mr-rogers-on-unconditional-love.html\">universal love</a>.</p>\n<p class=\"MsoNormal\">This was the birth of my interest in maximizing aggregated global welfare. Maximizing aggregated global welfare corresponds to maximizing cost-effectiveness, and so this can be thought of as the origin of my interest in <em>effective</em> altruism.&nbsp;</p>\n<p class=\"MsoNormal\">I believe that I would have developed interest in global welfare, and in effective altruism, on my own accord, without encountering any members of the effective altruist movement. But for reasons that I describe below, if not for meeting these people, I don\u2019t think that my interests would have been actionable.</p>\n<h2 id=\"Epistemic_paralysis\">Epistemic paralysis</h2>\n<p class=\"MsoNormal\">My analytical bent had a downside.</p>\n<p class=\"MsoNormal\">Issues pertaining to the human world are very complex, and there aren\u2019t clear-cut objective answers to the question of how best to make the world a better place. On a given issue, there are many arguments for a given position, and many counterarguments to the arguments, and many counterarguments to the counterarguments, and so on.&nbsp;</p>\n<p class=\"MsoNormal\">Contemplating these resulted in my falling into a state of <a href=\"http://squid314.livejournal.com/350090.html\">epistemic learned helplessness</a>. I became convinced that it's not possible to rationally develop confidence in views concerning how to make the world a better place.</p>\n<h2 id=\"Enter_GiveWell\">Enter GiveWell</h2>\n<p class=\"MsoNormal\">In 2007, my college friend <a href=\"http://80000hours.org/blog/116-interview-with-brian-tomasik\">Brian Tomasik</a> pointed me to GiveWell. At the time, GiveWell had just launched, and there wasn\u2019t very much on the website, so I soon forgot about it.</p>\n<p class=\"MsoNormal\">In 2009, my high school friend Dario, who had introduced me to utilitarianism, pointed me to GiveWell again. By this point, there was much more information available on the GiveWell website.&nbsp;</p>\n<p class=\"MsoNormal\">I began following GiveWell closely. I was very impressed by the fact that co-founders Holden and Elie seemed to be making sense of the ambiguous world of effective philanthropy. I hadn\u2019t thought that it was possible to reason so well about the human world. This made effective altruism more credible in my eyes, and inspired me. If hadn\u2019t encountered GiveWell, I may not have gotten involved with the effective philanthropy movement at all, although I may have become involved through interactions of Less Wrong, and I may have gone on to do socially valuable work in <a href=\"http://www.mathisbeauty.org\">math education</a>.</p>\n<p class=\"MsoNormal\">I became progressively more impressed by GiveWell over time, and wanted to become involved. In 2011, I did volunteer work for GiveWell, and in 2012, I began working at GiveWell as a research analyst.</p>\n<p class=\"MsoNormal\">While working at GiveWell, I learned a great deal about how to think about philanthropy, and about epistemology more generally. A crucial development in my thinking was the gradual realization that:</p>\n<ul>\n<li>Cost-effectiveness estimates that are supported by a single line of evidence are unreliable.</li>\n<li>Investigation generally reveals that interventions that appear highly cost-effective relative to other interventions are often much worse (in a relative sense) than one would initially guess.</li>\n<li>One can become much more confident in one\u2019s assessment of the value of a philanthropic intervention by <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">examining it from many different angles</a>.&nbsp;</li>\n</ul>\n<p class=\"MsoNormal\">I wrote about this realization in my post <a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>.&nbsp;</p>\n<p class=\"MsoNormal\">This shift in my thinking gradually percolated, and I realized that my entire epistemological framework had been seriously flawed, because <a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\">I was relying too much on a small number of relatively strong arguments rather than a large number of independent weak arguments</a>.&nbsp;</p>\n<p class=\"MsoNormal\">Many people had tried to explain this to me in the past, but I was unable to understand what they were driving at, and it was only through my work at GiveWell and my interactions with my coworkers that I was finally able to understand. The benefits of this realization have spanned many aspects of my life, and have substantially increased my altruistic human capital.&nbsp;</p>\n<p class=\"MsoNormal\">If GiveWell hadn\u2019t existed, it\u2019s very possible that I wouldn\u2019t have learned these things. If Dario hadn\u2019t pointed me to GiveWell, I\u2019m sure that I would have encountered GiveWell eventually, but it may have been too late for it to be possible for me to work there, and so I may not have had the associated learning opportunities.</p>\n<p class=\"MsoNormal\">My involvement with GiveWell also facilitated my meeting <a href=\"http://blog.givewell.org/2011/08/05/guest-post-from-vipul-naik/\">Vipul Naik</a>, the founder of <a href=\"http://openborders.info/\">Open Borders</a>. We\u2019ve had many fruitful interactions related to maximizing global welfare, and if I hadn\u2019t met him through GiveWell, it may have been years before we met.&nbsp;</p>\n<h2 id=\"The_significance_of_Less_Wrong\">The significance of Less Wrong</h2>\n<p class=\"MsoNormal\">Several people pointed me to Overcoming Bias and <a href=\"/Downloads/lesswrong.com\">Less Wrong</a> starting in 2008, but at the time the posts didn\u2019t draw me in relative to the fascination of <a href=\"http://www.mathisbeauty.org/preludereciprocitylaws.pdf\">reciprocity laws in algebraic number theory</a>. In early 2010, Brian Tomasik pointed me to some of <a href=\"/lw/6ga/index_of_yvains_excellent_articles/\">Yvain\u2019s articles</a> on Less Wrong. With the background context of me following GiveWell, Yvain\u2019s posts on utilitarianism really resonated with me. So I started reading Less Wrong.&nbsp;</p>\n<p class=\"MsoNormal\">I met many impressive people who are seriously interested in effective altruism through Less Wrong. Among these are:</p>\n<ul>\n<li><a href=\"https://sites.google.com/site/nbeckstead/\">Nick Beckstead</a> \u2014 A new postdoc at Oxford University (specifically, the <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a>) who wrote the thesis <a href=\"https://sites.google.com/site/nbeckstead/research\">On the Overwhelming Importance of Shaping the Far Future</a>.</li>\n<li><a href=\"/user/paulfchristiano/overview/\">Paul Christiano</a> and <a href=\"/user/jsteinhardt/overview/\">Jacob Steinhardt</a> \u2014 graduate students in theory of computing and machine learning at Berkeley and Stanford (respectively). Jacob is a <a href=\"http://www.hertzfoundation.org/dx/fellows/fellow_profile.aspx?d=1205\">Hertz Fellow</a>, and Paul coauthored a 48 page paper titled <a href=\"http://www.arxiv.org/abs/1203.4740\">Quantum Money from Hidden Subspaces</a> as an undergraduate. Paul <a href=\"http://rationalaltruist.com/\">has thought a great deal about rational altruism,</a> and Jacob is a member of <a href=\"http://www.vannevargroup.org/\">The Vannevar Group</a>, which aims to accelerate scientific progress to create the greatest amount of social good.</li>\n<li><a href=\"http://math.berkeley.edu/~qchu/\">Qiaochu Yuan</a> \u2014 A math graduate student at Berkeley who has the <a href=\"http://mathoverflow.net/users/290/qiaochu-yuan\">sixth highest karma score on MathOverflow</a>. I\u2019ve been enjoying learning math from Qiaochu.</li>\n<li><a href=\"/user/CarlShulman/overview/\">Carl Shulman</a> and <a href=\"http://rationality.org/about/\">Dan Keys</a>. I\u2019ve found very intellectually stimulating and have learned a great deal from them.</li>\n<li><a href=\"http://lukeprog.com/\">Luke Muehlhauser</a> \u2014 The executive director of MIRI.</li>\n<li>Others \u2014 Including Julia Galef, Anna Salamon, Katja Grace, Louie Helm.</li>\n</ul>\n<p class=\"MsoNormal\">They\u2019ve helped me retain my motivation to do the most good, and have aided me in thinking about effective altruism. They constitute a substantial chunk of the most impressive people who I know in my age group.</p>\n<p class=\"MsoNormal\">It\u2019s genuinely unclear whether I would have gotten to know these people if Eliezer hadn\u2019t started Less Wrong.&nbsp;</p>\n<h2 id=\"Closing_summary\">Closing summary</h2>\n<p class=\"MsoNormal\">My innate inclinations got me interested in effective altruism, but they probably wouldn\u2019t have sufficed for my interest to be actionable. Beyond my innate inclinations, the things that stand out most in my mind as having been crucial are</p>\n<ul>\n<li>Dario introducing me to GiveWell</li>\n<li>Working at GiveWell</li>\n<li>Meeting Vipul through GiveWell</li>\n<li>Eliezer starting Less Wrong</li>\n<li>Meeting peers through Less Wrong</li>\n</ul>\n<p class=\"MsoNormal\">Working at GiveWell substantially increased my altruistic human capital. I\u2019ve learned a great deal from the GiveWell staff, from Vipul, and from the members of the Less Wrong community listed above. We\u2019ve had fruitful collaborations, and they\u2019ve helped me retain my motivation to do the most good.</p>\n<p class=\"MsoNormal\">The personal growth benefits that I derived from working at GiveWell are unusual, if only because GiveWell\u2019s staff is small. The networking benefits from Less Wrong are shared by many others.</p>\n<p class=\"MsoNormal\"><strong>Note:</strong> I formerly worked as a research analyst at GiveWell. All views here are my own.&nbsp;</p>\n<p class=\"MsoNormal\"><em>This post is <a href=\"http://effective-altruism.com/node/37\">cross-posted</a> at <a href=\"http://www.effective-altruism.com\">www.effective-altruism.com</a>.</em>&nbsp;</p>", "sections": [{"title": "Interest in altruism rooted in literature", "anchor": "Interest_in_altruism_rooted_in_literature", "level": 1}, {"title": "An analytical bent, and utilitarianism", "anchor": "An_analytical_bent__and_utilitarianism", "level": 1}, {"title": "Epistemic paralysis", "anchor": "Epistemic_paralysis", "level": 1}, {"title": "Enter GiveWell", "anchor": "Enter_GiveWell", "level": 1}, {"title": "The significance of Less Wrong", "anchor": "The_significance_of_Less_Wrong", "level": 1}, {"title": "Closing summary", "anchor": "Closing_summary", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "55 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rNuBzyWkigrf6BWg7", "9W9P2snxu5Px746LD", "xaLHeoRPdb9oQgDEy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-11T05:37:49.980Z", "modifiedAt": null, "url": null, "title": "Changing Systems is Different than Running Controlled Experiments - Don\u2019t Choose How to Run Your Country That Way! ", "slug": "changing-systems-is-different-than-running-controlled", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:58.257Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ShannonFriedman", "createdAt": "2012-06-19T16:21:31.296Z", "isAdmin": false, "displayName": "ShannonFriedman"}, "userId": "yzRAjgwgXY3bbapsP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HmH2snb4zvLjD42mG/changing-systems-is-different-than-running-controlled", "pageUrlRelative": "/posts/HmH2snb4zvLjD42mG/changing-systems-is-different-than-running-controlled", "linkUrl": "https://www.lesswrong.com/posts/HmH2snb4zvLjD42mG/changing-systems-is-different-than-running-controlled", "postedAtFormatted": "Tuesday, June 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Changing%20Systems%20is%20Different%20than%20Running%20Controlled%20Experiments%20-%20Don%E2%80%99t%20Choose%20How%20to%20Run%20Your%20Country%20That%20Way!%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AChanging%20Systems%20is%20Different%20than%20Running%20Controlled%20Experiments%20-%20Don%E2%80%99t%20Choose%20How%20to%20Run%20Your%20Country%20That%20Way!%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHmH2snb4zvLjD42mG%2Fchanging-systems-is-different-than-running-controlled%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Changing%20Systems%20is%20Different%20than%20Running%20Controlled%20Experiments%20-%20Don%E2%80%99t%20Choose%20How%20to%20Run%20Your%20Country%20That%20Way!%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHmH2snb4zvLjD42mG%2Fchanging-systems-is-different-than-running-controlled", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHmH2snb4zvLjD42mG%2Fchanging-systems-is-different-than-running-controlled", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1396, "htmlBody": "<p><em>Trigger warning: Discussion of rape.</em></p>\n<h3>Example 1:</h3>\n<p>Say that each morning you tell yourself that you are lazy for not wanting to get out of bed to go to work, as a way to convince yourself to get up. Perhaps if the only variable you changed was to lower your level of guilt, you might not get out of bed to go to work, and would instead take the day off. So if you are running a motivation system that uses guilt, feeling guilt may well be something you do not want to get rid of. If you got rid of the guilt but stopped going to work, that would likely be a net negative for your life.</p>\n<p>To contrast, with animal training, you <a href=\"http://www.humanesociety.org/animals/dogs/tips/dog_training_positive_reinforcement.html\">reinforce behavior you want in the animal</a>, and <a href=\"http://positively.com/positive-reinforcement/why-positive-reinforcement/\">interrupt, redirect, or <em>completely ignore (ie: no shaming or guilting)</em></a> behavior you don't want. It's also a similar methodology that meditation uses. When you meditate, you are told to focus on a meditative object such as the breath. When your mind wanders from the meditative object, you are instructed to just return your attention to the meditative object, and to not in any way punish yourself for having wandered. Also, you are instructed to not <a href=\"/lw/f5f/how_to_deal_with_depression_the_meta_layers/\">punish yourself for punishing yourself for having your mind wander</a>. Meditation does not use reward during the meditative process, although it's common to sound a beautiful chime which will give hedons at the end of a session, and people often perform a pleasant ritual before and/or after meditation that builds positive association with the activity of meditating. <a href=\"http://zmm.mro.org/teachings/meditation-instructions/\">Example page of meditation instructions</a>.</p>\n<p>So, if you switch to a <a href=\"http://www.managementstudyguide.com/reinforcement-theory-motivation.htm\">positive reinforcement motivational system</a>, such as that which animal trainers use to train dogs, then guilt is counter-productive for motivation, because it is a form of punishment.</p>\n<h4>Example Summary:</h4>\n<p>If you only change one variable from a motivation system that uses guilt, then it may break the system, and be a net negative. However, there is likely a way to get a net utility gain by changing several variables of the system, such as by switching to a positive reinforcement based system where you add instant rewards that increase hedons and remove guilt and other punishments.</p>\n<h3>Example 2:</h3>\n<p>As it stands, there are many unreported rapes in American society. <a href=\"http://yesmeansyesblog.wordpress.com/2009/11/12/meet-the-predators/\">This excellent article debunks many myths about rape</a>, including the classic myth that rapes are generally done by strangers using force:</p>\n<blockquote>\n<p>A huge proportion of the women I know enough to talk with about it have survived an attempted or completed rape. None of them was raped by a stranger who attacked them from behind a bush, hid in the back of her car or any of the other scenarios that fit the social script of stranger rape. Anyone reading this post, in fact, is likely to know that six out of seven rapes are committed by someone the victim knows.</p>\n</blockquote>\n<p>The author goes on to explain how most rapes are from repeat offenders who by a median age of 26.5, on average rape around 5-6 women each, and that it is almost always someone who was part of the woman's social circle, and intoxicants are usually used.</p>\n<p>The suggestion of change of system that I got from this post is actually in the title of the blog: \"Yes Means Yes.\"</p>\n<p>If the social rules for consent are changed from \"if a woman does not say no, then it may or may not be okay\" to \"it is only okay if a woman says yes,\" then the boundary becomes a lot more clear to both parties. It would be a pretty radical system change, that would make a lot of people uncomfortable.</p>\n<p>To be more clear - with a \"Yes Means Yes\" system, you don't need to have \"No Means No\", because sex is only had when there is a Yes. If a woman is too drunk to say or enforce no, then she is also too drunk to say yes, and sex is not had unless there is explicit consent. Having a Yes Means Yes social policy would change the onus of responsibility for making sure that sex is consensual from the woman - who is obligated to say no if she doesn't want to - to both parties who must say yes to proceed. This would not stop all rape by any means, but if implemented in a system where people were taught good communication and assertiveness, it would cut down on it. For example, instead of feeling that it was her fault because she got drunk and didn't say no aggressively enough, a woman would realize quickly, \"hey, I didn't say yes!\" and a predatorial guy who was one of the small percentage of men who rape women would also realize that the woman would be less likely to just feel ashamed and keep quiet and would be more likely to take action to defend herself.</p>\n<p>Perhaps some people would be afraid that they'd remain virgins for life in this system - some men might be afraid that they'd be too shy to ever ask, some women might not feel comfortable actually admitting that they want sex. And therefore, people of both genders might be resistant to switching systems because they would imagine the switch without a complete social system switch or training. And as it stands, perhaps a lot less sex would happen at first. A system like that would require retraining a lot of society to be more assertive.</p>\n<h4>Example Summary:</h4>\n<p>Just shifting one variable and telling men to say \"I only have sex when women say yes\" would be very weird. If a guy tried to implement that in the current system, some people might look at him like he was crazy or even get offended.</p>\n<p>I think the \"Yes Means Yes\" system would work beautifully in a society that functioned based on a different system - where the social norm, which people were trained in, was to identify and state one's desires, and to not proceed without clarity. I do think it would cut down on rape, and unreported rape.</p>\n<h3>Overall Summary:</h3>\n<p>I've discovered that when talking to people about potential novel systems, that the most common response I get is for them to say why the alternative system won't work, based on what would happen if you changed one variable of the current system to be more like the novel system. Examples: \"If I didn't feel guilty, I'd never get anything done,\" or \"In a system where you always had to have a clear yes before having sex, people would feel really awkward and uncomfortable and opt out.\" (Alternatively I will often hear people justify alternative systems using similar arguments about single-variable changes.)</p>\n<p>The examples above are a couple of the more simple examples of this general principle I've been observing quite a lot lately.</p>\n<p>Consider how this applies to government systems, and other social systems. There are so many parts dependent on each other, that it is very hard to shift any single one without creating a domino effect of other shifts. So making any argument about how changing a single variable would fix or destroy a complex system like government is usually a huge oversimplification.</p>\n<p>To quote Einstein:</p>\n<blockquote>\n<p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>\n</blockquote>\n<p>My thoughts on making large-scale change, are that you need to be thinking large scale. If you want to be a change maker, it is best to start small in your actions, study and experiment a lot. Focus your studies on success and failure scenarios as close as possible to what it is you want to effect, while as diverse as possible from each other.</p>\n<p>Running single-variable experiments is important - it is just that it is only how you understand a little corner of the problem to be solved - that's not how you find the solution itself to a problem involving a complex system.</p>\n<p>To give a biological analogy: Cancer is what happens when a single type of cell tries to become the whole system. Running a single-variable controlled experiment to determine what type of complex system you want to choose is like trying to determine the optimal form of cancer, as opposed to looking at an entire entity. Life <em>is</em> complicated.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HmH2snb4zvLjD42mG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 41, "baseScore": 0, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "22722", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>Trigger warning: Discussion of rape.</em></p>\n<h3 id=\"Example_1_\">Example 1:</h3>\n<p>Say that each morning you tell yourself that you are lazy for not wanting to get out of bed to go to work, as a way to convince yourself to get up. Perhaps if the only variable you changed was to lower your level of guilt, you might not get out of bed to go to work, and would instead take the day off. So if you are running a motivation system that uses guilt, feeling guilt may well be something you do not want to get rid of. If you got rid of the guilt but stopped going to work, that would likely be a net negative for your life.</p>\n<p>To contrast, with animal training, you <a href=\"http://www.humanesociety.org/animals/dogs/tips/dog_training_positive_reinforcement.html\">reinforce behavior you want in the animal</a>, and <a href=\"http://positively.com/positive-reinforcement/why-positive-reinforcement/\">interrupt, redirect, or <em>completely ignore (ie: no shaming or guilting)</em></a> behavior you don't want. It's also a similar methodology that meditation uses. When you meditate, you are told to focus on a meditative object such as the breath. When your mind wanders from the meditative object, you are instructed to just return your attention to the meditative object, and to not in any way punish yourself for having wandered. Also, you are instructed to not <a href=\"/lw/f5f/how_to_deal_with_depression_the_meta_layers/\">punish yourself for punishing yourself for having your mind wander</a>. Meditation does not use reward during the meditative process, although it's common to sound a beautiful chime which will give hedons at the end of a session, and people often perform a pleasant ritual before and/or after meditation that builds positive association with the activity of meditating. <a href=\"http://zmm.mro.org/teachings/meditation-instructions/\">Example page of meditation instructions</a>.</p>\n<p>So, if you switch to a <a href=\"http://www.managementstudyguide.com/reinforcement-theory-motivation.htm\">positive reinforcement motivational system</a>, such as that which animal trainers use to train dogs, then guilt is counter-productive for motivation, because it is a form of punishment.</p>\n<h4 id=\"Example_Summary_\">Example Summary:</h4>\n<p>If you only change one variable from a motivation system that uses guilt, then it may break the system, and be a net negative. However, there is likely a way to get a net utility gain by changing several variables of the system, such as by switching to a positive reinforcement based system where you add instant rewards that increase hedons and remove guilt and other punishments.</p>\n<h3 id=\"Example_2_\">Example 2:</h3>\n<p>As it stands, there are many unreported rapes in American society. <a href=\"http://yesmeansyesblog.wordpress.com/2009/11/12/meet-the-predators/\">This excellent article debunks many myths about rape</a>, including the classic myth that rapes are generally done by strangers using force:</p>\n<blockquote>\n<p>A huge proportion of the women I know enough to talk with about it have survived an attempted or completed rape. None of them was raped by a stranger who attacked them from behind a bush, hid in the back of her car or any of the other scenarios that fit the social script of stranger rape. Anyone reading this post, in fact, is likely to know that six out of seven rapes are committed by someone the victim knows.</p>\n</blockquote>\n<p>The author goes on to explain how most rapes are from repeat offenders who by a median age of 26.5, on average rape around 5-6 women each, and that it is almost always someone who was part of the woman's social circle, and intoxicants are usually used.</p>\n<p>The suggestion of change of system that I got from this post is actually in the title of the blog: \"Yes Means Yes.\"</p>\n<p>If the social rules for consent are changed from \"if a woman does not say no, then it may or may not be okay\" to \"it is only okay if a woman says yes,\" then the boundary becomes a lot more clear to both parties. It would be a pretty radical system change, that would make a lot of people uncomfortable.</p>\n<p>To be more clear - with a \"Yes Means Yes\" system, you don't need to have \"No Means No\", because sex is only had when there is a Yes. If a woman is too drunk to say or enforce no, then she is also too drunk to say yes, and sex is not had unless there is explicit consent. Having a Yes Means Yes social policy would change the onus of responsibility for making sure that sex is consensual from the woman - who is obligated to say no if she doesn't want to - to both parties who must say yes to proceed. This would not stop all rape by any means, but if implemented in a system where people were taught good communication and assertiveness, it would cut down on it. For example, instead of feeling that it was her fault because she got drunk and didn't say no aggressively enough, a woman would realize quickly, \"hey, I didn't say yes!\" and a predatorial guy who was one of the small percentage of men who rape women would also realize that the woman would be less likely to just feel ashamed and keep quiet and would be more likely to take action to defend herself.</p>\n<p>Perhaps some people would be afraid that they'd remain virgins for life in this system - some men might be afraid that they'd be too shy to ever ask, some women might not feel comfortable actually admitting that they want sex. And therefore, people of both genders might be resistant to switching systems because they would imagine the switch without a complete social system switch or training. And as it stands, perhaps a lot less sex would happen at first. A system like that would require retraining a lot of society to be more assertive.</p>\n<h4 id=\"Example_Summary_1\">Example Summary:</h4>\n<p>Just shifting one variable and telling men to say \"I only have sex when women say yes\" would be very weird. If a guy tried to implement that in the current system, some people might look at him like he was crazy or even get offended.</p>\n<p>I think the \"Yes Means Yes\" system would work beautifully in a society that functioned based on a different system - where the social norm, which people were trained in, was to identify and state one's desires, and to not proceed without clarity. I do think it would cut down on rape, and unreported rape.</p>\n<h3 id=\"Overall_Summary_\">Overall Summary:</h3>\n<p>I've discovered that when talking to people about potential novel systems, that the most common response I get is for them to say why the alternative system won't work, based on what would happen if you changed one variable of the current system to be more like the novel system. Examples: \"If I didn't feel guilty, I'd never get anything done,\" or \"In a system where you always had to have a clear yes before having sex, people would feel really awkward and uncomfortable and opt out.\" (Alternatively I will often hear people justify alternative systems using similar arguments about single-variable changes.)</p>\n<p>The examples above are a couple of the more simple examples of this general principle I've been observing quite a lot lately.</p>\n<p>Consider how this applies to government systems, and other social systems. There are so many parts dependent on each other, that it is very hard to shift any single one without creating a domino effect of other shifts. So making any argument about how changing a single variable would fix or destroy a complex system like government is usually a huge oversimplification.</p>\n<p>To quote Einstein:</p>\n<blockquote>\n<p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>\n</blockquote>\n<p>My thoughts on making large-scale change, are that you need to be thinking large scale. If you want to be a change maker, it is best to start small in your actions, study and experiment a lot. Focus your studies on success and failure scenarios as close as possible to what it is you want to effect, while as diverse as possible from each other.</p>\n<p>Running single-variable experiments is important - it is just that it is only how you understand a little corner of the problem to be solved - that's not how you find the solution itself to a problem involving a complex system.</p>\n<p>To give a biological analogy: Cancer is what happens when a single type of cell tries to become the whole system. Running a single-variable controlled experiment to determine what type of complex system you want to choose is like trying to determine the optimal form of cancer, as opposed to looking at an entire entity. Life <em>is</em> complicated.</p>", "sections": [{"title": "Example 1:", "anchor": "Example_1_", "level": 1}, {"title": "Example Summary:", "anchor": "Example_Summary_", "level": 2}, {"title": "Example 2:", "anchor": "Example_2_", "level": 1}, {"title": "Example Summary:", "anchor": "Example_Summary_1", "level": 2}, {"title": "Overall Summary:", "anchor": "Overall_Summary_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "260 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 260, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["foKJNj4cphxThsukr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-11T06:57:23.992Z", "modifiedAt": null, "url": null, "title": "Sydney meetup?", "slug": "sydney-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:38.860Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LiBBEKmkzsCjLvA7A/sydney-meetup", "pageUrlRelative": "/posts/LiBBEKmkzsCjLvA7A/sydney-meetup", "linkUrl": "https://www.lesswrong.com/posts/LiBBEKmkzsCjLvA7A/sydney-meetup", "postedAtFormatted": "Tuesday, June 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sydney%20meetup%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASydney%20meetup%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLiBBEKmkzsCjLvA7A%2Fsydney-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sydney%20meetup%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLiBBEKmkzsCjLvA7A%2Fsydney-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLiBBEKmkzsCjLvA7A%2Fsydney-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 28, "htmlBody": "<p>sorry to add clutter, but I've recently returned to living in sydney and was wondering if there is a regular meetup in the area? I'd love to attend.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LiBBEKmkzsCjLvA7A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.228612579244287e-06, "legacy": true, "legacyId": "22918", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-11T13:43:42.232Z", "modifiedAt": null, "url": null, "title": "Meetup : London Social - Exposure to Direct Sunlight - June 23rd", "slug": "meetup-london-social-exposure-to-direct-sunlight-june-23rd", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:58.066Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/k6SATimbiHSdQbyXk/meetup-london-social-exposure-to-direct-sunlight-june-23rd", "pageUrlRelative": "/posts/k6SATimbiHSdQbyXk/meetup-london-social-exposure-to-direct-sunlight-june-23rd", "linkUrl": "https://www.lesswrong.com/posts/k6SATimbiHSdQbyXk/meetup-london-social-exposure-to-direct-sunlight-june-23rd", "postedAtFormatted": "Tuesday, June 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Social%20-%20Exposure%20to%20Direct%20Sunlight%20-%20June%2023rd&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Social%20-%20Exposure%20to%20Direct%20Sunlight%20-%20June%2023rd%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk6SATimbiHSdQbyXk%2Fmeetup-london-social-exposure-to-direct-sunlight-june-23rd%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Social%20-%20Exposure%20to%20Direct%20Sunlight%20-%20June%2023rd%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk6SATimbiHSdQbyXk%2Fmeetup-london-social-exposure-to-direct-sunlight-june-23rd", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fk6SATimbiHSdQbyXk%2Fmeetup-london-social-exposure-to-direct-sunlight-june-23rd", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 254, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/nn\">London Social - Exposure to Direct Sunlight - June 23rd</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">23 June 2013 02:00:00PM (+0100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">St James Park, London, SW1H</span></p>\n<p>&nbsp;</p>\n<p>EDIT: morning of the 23rd, and the weather is looking good enough to chance it. Head for the park &nbsp;and we'll retreat to the pub if it takes a downturn.</p>\n<p>&nbsp;</p>\n</div>\n<div class=\"content\">\n<div class=\"md\">\n<p>The first London Social meetup will be taking place in St. James Park on Sunday June 23rd from 2pm.</p>\n<p>Assuming the weather is nice, we'll be aiming to meet <a rel=\"nofollow\" href=\"https://maps.google.co.uk/maps?q=51.501705,+-0.134730\">about here</a>. I'll be bringing along some games and maybe some juggling equipment. If you have any of your own Apparatus of Awesomeness, feel free to bring it along.</p>\n<p>If the weather is not nice, we will convene at the <a rel=\"nofollow\" href=\"https://www.google.co.uk/maps?q=51.499888,-0.133722\">Old Star</a>, which is just round the corner from St. James Park tube station. I'll update this post on the morning of the 23rd with confirmation of the venue, but the two locations are a short distance from each other. If in doubt, head to St. James Park tube and call me on +44 7887 718458 when you get there.</p>\n<p>There is no set agenda or topic. We're going to have unstructured social fun like regular human beings. People will probably talk about utilitarian ethics and bitcoin and productivity systems, but also about dinosaurs and cake and fanfiction.</p>\n<p>Bring a friend. Bring two if you can carry them.</p>\n<p>(We also have a <a href=\"https://groups.google.com/forum/?fromgroups#!forum/lesswronglondon\">Google Group</a>&nbsp;and a <a href=\"https://www.facebook.com/groups/380103898766356\">Facebook group</a>. &nbsp;Why not join them?)</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/nn\">London Social - Exposure to Direct Sunlight - June 23rd</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "k6SATimbiHSdQbyXk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 1.2289198705711582e-06, "legacy": true, "legacyId": "22919", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Social___Exposure_to_Direct_Sunlight___June_23rd\">Discussion article for the meetup : <a href=\"/meetups/nn\">London Social - Exposure to Direct Sunlight - June 23rd</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">23 June 2013 02:00:00PM (+0100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">St James Park, London, SW1H</span></p>\n<p>&nbsp;</p>\n<p>EDIT: morning of the 23rd, and the weather is looking good enough to chance it. Head for the park &nbsp;and we'll retreat to the pub if it takes a downturn.</p>\n<p>&nbsp;</p>\n</div>\n<div class=\"content\">\n<div class=\"md\">\n<p>The first London Social meetup will be taking place in St. James Park on Sunday June 23rd from 2pm.</p>\n<p>Assuming the weather is nice, we'll be aiming to meet <a rel=\"nofollow\" href=\"https://maps.google.co.uk/maps?q=51.501705,+-0.134730\">about here</a>. I'll be bringing along some games and maybe some juggling equipment. If you have any of your own Apparatus of Awesomeness, feel free to bring it along.</p>\n<p>If the weather is not nice, we will convene at the <a rel=\"nofollow\" href=\"https://www.google.co.uk/maps?q=51.499888,-0.133722\">Old Star</a>, which is just round the corner from St. James Park tube station. I'll update this post on the morning of the 23rd with confirmation of the venue, but the two locations are a short distance from each other. If in doubt, head to St. James Park tube and call me on +44 7887 718458 when you get there.</p>\n<p>There is no set agenda or topic. We're going to have unstructured social fun like regular human beings. People will probably talk about utilitarian ethics and bitcoin and productivity systems, but also about dinosaurs and cake and fanfiction.</p>\n<p>Bring a friend. Bring two if you can carry them.</p>\n<p>(We also have a <a href=\"https://groups.google.com/forum/?fromgroups#!forum/lesswronglondon\">Google Group</a>&nbsp;and a <a href=\"https://www.facebook.com/groups/380103898766356\">Facebook group</a>. &nbsp;Why not join them?)</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___London_Social___Exposure_to_Direct_Sunlight___June_23rd1\">Discussion article for the meetup : <a href=\"/meetups/nn\">London Social - Exposure to Direct Sunlight - June 23rd</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Social - Exposure to Direct Sunlight - June 23rd", "anchor": "Discussion_article_for_the_meetup___London_Social___Exposure_to_Direct_Sunlight___June_23rd", "level": 1}, {"title": "Discussion article for the meetup : London Social - Exposure to Direct Sunlight - June 23rd", "anchor": "Discussion_article_for_the_meetup___London_Social___Exposure_to_Direct_Sunlight___June_23rd1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "7 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-11T19:41:01.252Z", "modifiedAt": null, "url": null, "title": "Life hack request: I want to want to work.", "slug": "life-hack-request-i-want-to-want-to-work", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:05.732Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielLC", "createdAt": "2009-12-26T17:34:50.257Z", "isAdmin": false, "displayName": "DanielLC"}, "userId": "3e6zTkDmDpNspRb8P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tFDhrtK8Q22kjBPex/life-hack-request-i-want-to-want-to-work", "pageUrlRelative": "/posts/tFDhrtK8Q22kjBPex/life-hack-request-i-want-to-want-to-work", "linkUrl": "https://www.lesswrong.com/posts/tFDhrtK8Q22kjBPex/life-hack-request-i-want-to-want-to-work", "postedAtFormatted": "Tuesday, June 11th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Life%20hack%20request%3A%20I%20want%20to%20want%20to%20work.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALife%20hack%20request%3A%20I%20want%20to%20want%20to%20work.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtFDhrtK8Q22kjBPex%2Flife-hack-request-i-want-to-want-to-work%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Life%20hack%20request%3A%20I%20want%20to%20want%20to%20work.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtFDhrtK8Q22kjBPex%2Flife-hack-request-i-want-to-want-to-work", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtFDhrtK8Q22kjBPex%2Flife-hack-request-i-want-to-want-to-work", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p>I have a master's project I'm having trouble working on. It's something I've wanted to do, and I even started working on, long before I started my master's degree. If I can't even enjoy that, then I'm doomed to spend eight hours a day doing something I hate for the rest of my life. Even if I manage to improve my willpower, I doubt I'll be very productive doing something I don't want to do.</p>\n<p>Does anyone have any idea how I can enjoy working more?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tFDhrtK8Q22kjBPex", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 13, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "22920", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T08:47:17.128Z", "modifiedAt": null, "url": null, "title": "How can I strategically write a complex bestseller? (4HS001)", "slug": "how-can-i-strategically-write-a-complex-bestseller-4hs001", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:12.054Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Neotenic", "createdAt": "2013-03-04T02:28:23.403Z", "isAdmin": false, "displayName": "Neotenic"}, "userId": "qMgZoftatigAeMMhL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dGkAL4PbihR2CvRfA/how-can-i-strategically-write-a-complex-bestseller-4hs001", "pageUrlRelative": "/posts/dGkAL4PbihR2CvRfA/how-can-i-strategically-write-a-complex-bestseller-4hs001", "linkUrl": "https://www.lesswrong.com/posts/dGkAL4PbihR2CvRfA/how-can-i-strategically-write-a-complex-bestseller-4hs001", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20can%20I%20strategically%20write%20a%20complex%20bestseller%3F%20(4HS001)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20can%20I%20strategically%20write%20a%20complex%20bestseller%3F%20(4HS001)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdGkAL4PbihR2CvRfA%2Fhow-can-i-strategically-write-a-complex-bestseller-4hs001%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20can%20I%20strategically%20write%20a%20complex%20bestseller%3F%20(4HS001)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdGkAL4PbihR2CvRfA%2Fhow-can-i-strategically-write-a-complex-bestseller-4hs001", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdGkAL4PbihR2CvRfA%2Fhow-can-i-strategically-write-a-complex-bestseller-4hs001", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1507, "htmlBody": "<blockquote><address>&ldquo;Find out the reason that commands you to write; see whether it has spread its roots into the very depth of your heart; confess to yourself you would have to die if you were forbidden to write.&rdquo;&nbsp; </address><address>- Rainer Maria Rilke</address></blockquote>\n<blockquote><address>&ldquo;Tomorrow may be hell, but today was a good writing day, and on the good writing days nothing else matters.&rdquo; <br />&nbsp;- Neil Gaiman</address></blockquote>\n<h5><br /></h5>\n<h5>3:00 AM, Mexico City, 12 June 2013<br /></h5>\n<p>Seven years ago I made a promise I didn't keep. I was 17 at the time, and mildly unaware of how complex and large the World is. The conversation went something like this:</p>\n<blockquote>\n<p>Me: I could write a bestseller, come on, it is not that complicated. Just read a random bestseller, they are not even that smart anyway!</p>\n<p>Mentor: Yeah, right, I dare you to go back home right now and write a bestseller, go!</p>\n<p>Me: I'm busy with all this school stuff right now, so I have to do my homework and....</p>\n<p>Mentor: Ok, ok, I'll concede we are very busy right now, how about in five years?</p>\n<p>Me: Five years seems more than enough. Take a note, in five years time I'll have written a bestseller. I promise.</p>\n</blockquote>\n<p>Somehow later on I got busy with cooking pasta I needn't eat and listening to gossip about people I didn't care. Not a good start.&nbsp;</p>\n<p>It's never too late to start over though, and now is as good a time as any.</p>\n<p>But wait! <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Humans are not automatically strategic</a> right?</p>\n<p>True. Also humans are not as good at detecting their own strategic failures and dead-ends as other humans. If we <a href=\"/lw/3kv/working_hurts_less_than_procrastinating_we_fear/\">can't even face</a> more than three minutes of work, how could we ever intuitively look at our work and see where it is bad?</p>\n<p>Which is why it seems that the rational way to do it is to find a place where people trained at being strategic can pinpoint your failures and accomplishments as you go along, rewarding you for <a href=\"/lw/7i/rationality_is_systematized_winning/\">winning</a> and twisting your mental knobs when you fail, so that over time, either you learn how to do it right, or you learn the right thing to do was something else altogether. This is the project. I'm hoping as an exercise in self-experimentation with Lesswrong rationality techniques that it both helps others who may be undertaking writing or related projects, and inspires others into remaining as strategic as they learned to be over time, or even more.&nbsp; <br /><br />I won't write the book here, but I'll <em>keep track of the writing process and everything involved around it</em> here (killing <a href=\"/lw/72d/strategic_ignorance_and_plausible_deniability/\">plausible deniability of my goals</a>), and encourage anyone who perchance might be doing something similar to keep track in the same way through commentaries or taking private notes. Starting by the checklist in <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">Humans are not automatically strategic</a>:</p>\n<blockquote>\n<p>We do <em>not</em> automatically:</p>\n</blockquote>\n<ul>\n<li>(a) Ask ourselves what we&rsquo;re trying to achieve; </li>\n</ul>\n<p>Descriptive definition: The goal is to have written a book that, despite having interesting complex content, and being within my interest scope, sells enough to get me a free and clear profit of 1700 <a href=\"http://bigmacindex.org/2013-Big-Mac-Index.html\">Big Mac Indexes</a> per month. 54 Big Macs a day. Current US $7140,00 per month, for three consecutive months.</p>\n<p>Ostensive Definition: Being the author of something that enters my cognitive <a href=\"/lw/nl/the_cluster_structure_of_thingspace/\">intensional cluster</a> containing <em>Drop Dead Healthy, The Four Hour Workweek, Outliers, The Better Angels of Our Nature, Stumbling on Happiness, The Game, A Short History of Nearly Everything, The Mistery Method, Freakonomics, Flourish, The Guinea Pig Diaries,&nbsp; </em></p>\n<ul>\n<li>(b) Ask ourselves how we could tell if we achieved it (&ldquo;what does it look like to be a good comedian?&rdquo;) and how we can track progress; </li>\n</ul>\n<p>Achieve: The income part is easy to detect. If it has <em>interesting content</em> will have to depend on a fallible 'at the time judgment' and a quick consultation with a friend who knew me before the process. (Miss T, she is great) <br />Track: Writing here about the process. Checking for the <a href=\"http://yudkowsky.net/rational/virtues\">twelfth virtue</a> frequently. Track a long to do list with specific and impossible deadlines as soon as it makes sense to fully write one.</p>\n<ul>\n<li>(c) Find ourselves strongly, intrinsically curious about information that would help us achieve our goal; </li>\n</ul>\n<p>Possible danger: It is easy to be curious about the info for the book, and much harder to be curious about how to write much better, even harder how to write aiming at selling - or whichever reflective shield needs to be looked at to stare into the eyes of the selling Medusa.</p>\n<ul>\n<li>(d) Gather that information (e.g., by asking as how folks commonly achieve our goal, or similar goals, or by tallying which strategies have and haven&rsquo;t worked for us in the past); </li>\n</ul>\n<p>This will be next post's topic. Here only what didn't work: (1)Writing purely for fun made me write a book but not create a product. (2)Waiting for creativity made no difference in writing quality, actually writing did. (3) Writing a book in Spanish was a terrible idea. (4)<a href=\"/lw/h9b/post_ridiculous_munchkin_ideas/8ybw\">Choosing writer peers</a> according to mild proximity helped with writing fiction movie scripts, but not non-fiction books.</p>\n<ul>\n<li>(e) Systematically test many different conjectures for how to achieve the goals, including methods that aren&rsquo;t habitual for us, while tracking which ones do and don&rsquo;t work; </li>\n</ul>\n<p>Conjectures: (1)Trying to sell before writing may shorten the process manyfold. (2)Riding someone else's fame and marketing eases the process. (3)Writing with the purpose of <em>causing the reader to show a friend </em>what he has - who am I kidding, it's a guy, look at the ostensive examples - just read is the best meta-goal to keep in mind. (4) It is not <em>that hard</em> to get my goal, it isn't that far from a sarcastic quote: \"One person in every town in Britain likes your dumb online comic. That's enough to keep you in beers (or T-shirt sales) all year.\" (4)There is always a <a href=\"/lw/hu/the_third_alternative/\">third alternative</a>, and many times I'm <a href=\"http://www.creativindie.com/how-to-promote-a-book-when-youre-not-tim-ferriss-book-marketing-for-regular-people/\">not</a> the <a href=\"http://www.mediabistro.com/galleycat/how-tim-ferriss-cracked-the-amazon-bestseller-list_b61139\">one</a> who will see it <a href=\"http://www.fourhourworkweek.com/blog/2011/03/15/copyeditors/\">first</a>. Keep an <a href=\"http://www.youtube.com/watch?v=fLG0kkgnRkc\">attentive</a> ear.</p>\n<ul>\n<li>(f) Focus most of the energy that *isn&rsquo;t* going into systematic exploration, on the methods that work best;</li>\n</ul>\n<p>I don't have a clear idea of what Salamon meant by \"isn't going into systematic exploration\" and I can't constrain my experience based on this line alone, if anyone feels qualified to clarify, please do. I'll deal with this on later posts.</p>\n<ul>\n<li>(g) Make sure that our \"goal\" is really our goal, that we coherently want it and are not constrained by fears or by uncertainty as to whether it is worth the effort, and that we have thought through any questions and decisions in advance so they won't continually sap our energies;</li>\n</ul>\n<p>Fears: Having learned in Lesswrong to do things I had never considered myself able to, I don't feel any fear of <a href=\"/lw/8gv/the_curse_of_identity/\">trying it wrong</a>. I do however feel anxiety and fear that peeking into my reasoning process and strategic attempt at this goal won't be motivating enough for others to want to <a href=\"http://www.youtube.com/watch?v=n8m7lFQ3njk\">translate by analogy</a> my experience into theirs, which wouldn't give me the critical minimal threshold of upvotes and comments necessary to keep me motivated to write about writing. That could stymie my exposition of the shortcuts that help me, and the biases that hinder me, in hope of improving my <a href=\"/lw/7i/rationality_is_systematized_winning/\">winning ability</a>. Because I'm opening up the goal and process before it takes place, it could also forestall a case study of an attempt at strategic goal-pursuit free of survivorship bias.</p>\n<p>Energy Vortexes: No Vortex is like the web for me. More on that later.</p>\n<ul>\n<li>(h) Use environmental cues and social contexts to bolster our motivation, so we can keep working effectively in the face of intermittent frustrations, or temptations based in hyperbolic discounting;</li>\n</ul>\n<p>My workspace is pretty optimized at this point. Nowhere under these <a href=\"/lw/gdl/my_simple_hack_for_increased_alertness_and/\">freakishly bright lights</a> I can look around and see anything but things that make me want to write more, make me happy, or avoid distractions, like anti-mosquitoes or earplugs.</p>\n<p>I've just found out that writing about you goals feels like getting naked in public. The idea is for the next posts to be very similar to this one: find a set of strategic advices in Lesswrong, find out how to use them, and write about how am I implementing, or intending to implement them as much as possible in a way people can relate their own goal agenda, providing a case study of what happens as we go along. My favorite writer, AJ Jacobs, once set out to follow all 613 rules written anywhere in the Bible, <em>literally</em>. The idea here is to do something similar, but connotative. I will try to openly implement all of Lesswrong strategic offerings, and see how that goes. I don't know which posts contain the most compact, memorable or effective techniques for winning at being strategic, but I'm hoping by the end of this process the territory is better mapped for those who'd like to follow suit. Or point and laugh.</p>\n<ul>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dGkAL4PbihR2CvRfA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 19, "extendedScore": null, "score": 1.2297855019472845e-06, "legacy": true, "legacyId": "22922", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PBRWb2Em5SNeWYwwB", "9o3QBg2xJXcRCxGjS", "4ARtkT3EYox3THYjF", "fxgkYCbG5Hgy58TyC", "WBw8dDkAWohFjWQSk", "erGipespbbzdG5zYb", "tAXrD8Y6hcJ8dt6Nt", "Ag7oQifJQM5AnMCrR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T11:49:09.803Z", "modifiedAt": null, "url": null, "title": "Tegmark's talk at Oxford", "slug": "tegmark-s-talk-at-oxford", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:25.909Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WuDAvSrTNBh8NwiLK/tegmark-s-talk-at-oxford", "pageUrlRelative": "/posts/WuDAvSrTNBh8NwiLK/tegmark-s-talk-at-oxford", "linkUrl": "https://www.lesswrong.com/posts/WuDAvSrTNBh8NwiLK/tegmark-s-talk-at-oxford", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Tegmark's%20talk%20at%20Oxford&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATegmark's%20talk%20at%20Oxford%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWuDAvSrTNBh8NwiLK%2Ftegmark-s-talk-at-oxford%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Tegmark's%20talk%20at%20Oxford%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWuDAvSrTNBh8NwiLK%2Ftegmark-s-talk-at-oxford", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWuDAvSrTNBh8NwiLK%2Ftegmark-s-talk-at-oxford", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 66, "htmlBody": "<p>Max Tegmark, from the Massachusetts Institute of Technology and the Foundational Questions Institute (FQXi), <a href=\"http://www.youtube.com/watch?v=kZDVv-MI0VU\">presents</a> a cosmic perspective on the future of life, covering our increasing scientific knowledge, the cosmic background radiation, the ultimate fate of the universe, and what we need to do to ensure the human race's survival and flourishing in the short and long term. He's strongly into the importance of xrisk reduction.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WuDAvSrTNBh8NwiLK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 11, "extendedScore": null, "score": 1.2299232734192386e-06, "legacy": true, "legacyId": "22923", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T12:46:02.879Z", "modifiedAt": null, "url": null, "title": "All-pay auction for charity?", "slug": "all-pay-auction-for-charity", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:08.339Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JCbM5sukfHSjEJnsN/all-pay-auction-for-charity", "pageUrlRelative": "/posts/JCbM5sukfHSjEJnsN/all-pay-auction-for-charity", "linkUrl": "https://www.lesswrong.com/posts/JCbM5sukfHSjEJnsN/all-pay-auction-for-charity", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20All-pay%20auction%20for%20charity%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAll-pay%20auction%20for%20charity%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJCbM5sukfHSjEJnsN%2Fall-pay-auction-for-charity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=All-pay%20auction%20for%20charity%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJCbM5sukfHSjEJnsN%2Fall-pay-auction-for-charity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJCbM5sukfHSjEJnsN%2Fall-pay-auction-for-charity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 310, "htmlBody": "<p>While in a standard auction you have to pay your bid only if you win, in an all-pay auction you pay whether or not you win. The standard example is a <a href=\"http://en.wikipedia.org/wiki/Dollar_auction\">dollar auction</a> where you're selling a dollar.  Bidding a penny to get a dollar seems reasonable, but someone else then might bid two cents.  The bidding can keep going even past a dollar, and the more people fighting for the dollar the more the person selling it makes.  <a href=\"http://en.wikipedia.org/wiki/Bidding_fee_auction\">Bidding-fee auctions</a> are similar, where each bid you make costs money.  You might remember <a href=\"http://en.wikipedia.org/wiki/Swoopo\">Swoopo</a>?  They used to put up ads like \"An iPad just sold for $21.32!\" not mentioning that the participants overall had spent more than the retail cost of the iPad on bidding fees.  Eventually people caught on and they went bankrupt.</p>\n<p>In a less scammy vein, however, this is also how competitive prizes work.  In the <a href=\"http://en.wikipedia.org/wiki/Ansari_X_PRIZE\">X-Prize</a> teams spent <a href=\"http://space.xprize.org/ansari-x-prize\">over $100M</a> in competition for a $10M prize.  I can't find an estimate for how much people spent to win the $1M <a href=\"http://en.wikipedia.org/wiki/Netflix_Prize\">Netflix Prize</a> but when you look at the number of people and number of teams it was probably well above $1M.</p>\n<p>Could we use this for charity?  Imagine a donor thought two charities were both excellent  and had very similar returns, but they knew lots of other people strongly disagreed and preferred one or the other.  By offering to donate $X to the charity that received the most in donations, could they move more than $X to the charity of their choice?  It might be even better to make the criterion be the most independent donations of at least $Y, because getting more people to donate has value in terms of expected future donations.</p>\n<p>(I suggested something similar a few months ago in <a href=\"/lw/gki/offer_ill_match_donations_to_the_against_malaria/8enr?context=3\">a comment</a> on my post on <a href=\"/lw/gki\">donation matching</a>, but hadn't thought about prizes at the time.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JCbM5sukfHSjEJnsN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 1.2299663687766427e-06, "legacy": true, "legacyId": "22924", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uLTJh2RkXgWSXRxQK"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T15:21:05.221Z", "modifiedAt": null, "url": null, "title": "Meetup : [Boston] The Psychology of Marketing", "slug": "meetup-boston-the-psychology-of-marketing", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XdBY4MMdE25PoMvrM/meetup-boston-the-psychology-of-marketing", "pageUrlRelative": "/posts/XdBY4MMdE25PoMvrM/meetup-boston-the-psychology-of-marketing", "linkUrl": "https://www.lesswrong.com/posts/XdBY4MMdE25PoMvrM/meetup-boston-the-psychology-of-marketing", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BBoston%5D%20The%20Psychology%20of%20Marketing&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BBoston%5D%20The%20Psychology%20of%20Marketing%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXdBY4MMdE25PoMvrM%2Fmeetup-boston-the-psychology-of-marketing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BBoston%5D%20The%20Psychology%20of%20Marketing%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXdBY4MMdE25PoMvrM%2Fmeetup-boston-the-psychology-of-marketing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXdBY4MMdE25PoMvrM%2Fmeetup-boston-the-psychology-of-marketing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 156, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/no'>[Boston] The Psychology of Marketing</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 June 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>f you've ever asked the question \"how can I use my knowledge of psychology to take over the world?\", then this talk is for you. Through the dark art known as marketing, people have been exploiting human psychology for their own means before the phrase \"cognitive bias\" even existed. Learn the science behind marketing, how you can use these methods to aid or destroy the world, and how you can protect yourself from the bombardment of advertisements that surround us all.</p>\n\n<p>Cambridge/Boston-area Less Wrong meetups are on the first and third Sunday of every month at 2pm in MIT's building 66 at 25 Ames St, room 156. Room number subject to change based on availability; signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/no'>[Boston] The Psychology of Marketing</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XdBY4MMdE25PoMvrM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.2300838387893173e-06, "legacy": true, "legacyId": "22925", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Boston__The_Psychology_of_Marketing\">Discussion article for the meetup : <a href=\"/meetups/no\">[Boston] The Psychology of Marketing</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 June 2013 02:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">25 Ames St, Cambridge, MA 02139</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>f you've ever asked the question \"how can I use my knowledge of psychology to take over the world?\", then this talk is for you. Through the dark art known as marketing, people have been exploiting human psychology for their own means before the phrase \"cognitive bias\" even existed. Learn the science behind marketing, how you can use these methods to aid or destroy the world, and how you can protect yourself from the bombardment of advertisements that surround us all.</p>\n\n<p>Cambridge/Boston-area Less Wrong meetups are on the first and third Sunday of every month at 2pm in MIT's building 66 at 25 Ames St, room 156. Room number subject to change based on availability; signs will be posted with the actual room number.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Boston__The_Psychology_of_Marketing1\">Discussion article for the meetup : <a href=\"/meetups/no\">[Boston] The Psychology of Marketing</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Boston] The Psychology of Marketing", "anchor": "Discussion_article_for_the_meetup____Boston__The_Psychology_of_Marketing", "level": 1}, {"title": "Discussion article for the meetup : [Boston] The Psychology of Marketing", "anchor": "Discussion_article_for_the_meetup____Boston__The_Psychology_of_Marketing1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T15:37:12.162Z", "modifiedAt": null, "url": null, "title": "Anders, wine and enhancements", "slug": "anders-wine-and-enhancements", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:03.592Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SettRdN9jTy2RCLdt/anders-wine-and-enhancements", "pageUrlRelative": "/posts/SettRdN9jTy2RCLdt/anders-wine-and-enhancements", "linkUrl": "https://www.lesswrong.com/posts/SettRdN9jTy2RCLdt/anders-wine-and-enhancements", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anders%2C%20wine%20and%20enhancements&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnders%2C%20wine%20and%20enhancements%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSettRdN9jTy2RCLdt%2Fanders-wine-and-enhancements%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anders%2C%20wine%20and%20enhancements%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSettRdN9jTy2RCLdt%2Fanders-wine-and-enhancements", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSettRdN9jTy2RCLdt%2Fanders-wine-and-enhancements", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 13, "htmlBody": "<p>Glass of wine in hand, Anders Sandberg <a href=\"http://www.youtube.com/watch?v=GPJtzO0LdFo\">discusses</a> the future of cognitive enhancers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SettRdN9jTy2RCLdt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": -2, "extendedScore": null, "score": 1.2300960504278047e-06, "legacy": true, "legacyId": "22926", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T15:50:22.330Z", "modifiedAt": null, "url": null, "title": "Charity Effectiveness and Third-World Economics", "slug": "charity-effectiveness-and-third-world-economics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:04.027Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AefhNuP5Xe6R6eP8B/charity-effectiveness-and-third-world-economics", "pageUrlRelative": "/posts/AefhNuP5Xe6R6eP8B/charity-effectiveness-and-third-world-economics", "linkUrl": "https://www.lesswrong.com/posts/AefhNuP5Xe6R6eP8B/charity-effectiveness-and-third-world-economics", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Charity%20Effectiveness%20and%20Third-World%20Economics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACharity%20Effectiveness%20and%20Third-World%20Economics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAefhNuP5Xe6R6eP8B%2Fcharity-effectiveness-and-third-world-economics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Charity%20Effectiveness%20and%20Third-World%20Economics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAefhNuP5Xe6R6eP8B%2Fcharity-effectiveness-and-third-world-economics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAefhNuP5Xe6R6eP8B%2Fcharity-effectiveness-and-third-world-economics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 417, "htmlBody": "<p>In a recent Facebook status update, Eliezer Yudkowsky asked a question:</p>\n<blockquote>\n<p>Does the causal model for GiveDirectly's positive effects imply that the government of those countries could achieve the same effects by printing money in the local currency and giving the same amount to the same recipients? \"Yes\" is a legitimate answer because it's a dreadful truth that many governments around the world are not increasing their money supply enough, and also that choosing the right recipients can redistribute value productively even when supplies of medium-of-exchange are already sufficient.</p>\n</blockquote>\n<p>My first thought was object-level; the obvious answer is that some fraction of the money given will eventually be converted into imports, transferring the burden of inflation out and onto richer countries which can easily afford it. This seems plausible. If true, it implies that we should multiply our effectiveness estimates by dImports/d$, which is (asspull) 0.5. By this line of reasoning, direct giving is less effective than we thought, but still a reasonably good deal.</p>\n<p>My second thought was that it's likely true that some developing country governments could improve their economies by printing and distributing money, but they won't because they're corrupt, and giving directly is a workaround to force that policy upon them. This seems plausible at first, but it feels forced; the leaders' incentives here are ambiguous, not clearly aligned against this sort of policy.</p>\n<p>My third thought was that it's likely true that developing countries' governments could improve their economies by printing and distributing money, and&nbsp;<em>they might not know this</em>.</p>\n<p>Sanity check. What sort of people do the poorest countries' governments have, in their economic advisory roles? Is anyone making a serious effort to connect good economists with governments that need them?</p>\n<p>If developing countries are short on competent economic advisors at the top levels, and no one is working to fix this, then funding that charity would outperform direct giving by multiple orders of magnitude. But what reason do we have to think that a well-placed economist can make a difference? Well, history does contain at least one big, salient success story: <a href=\"http://www.npr.org/blogs/money/2010/10/04/130329523/how-fake-money-saved-brazil\">Brazil</a>, where a clever scheme halted hyperinflation and turned the economy around. And on a smaller scale,&nbsp;<a href=\"http://www.bien2012.org/sites/default/files/paper_196_en.pdf\">Otjivero-Namibia</a>.</p>\n<p>So now I have some questions for the efficient altruism community:</p>\n<p>&nbsp;- Which developing nations have competent economic advisors, and which ones need them?<br />&nbsp;- If a developing nation's leader needs good economic advisors to fill his/her cabinet, does he/she get them?<br />&nbsp;- Do any nations have economic problems that seem especially amenable to fixing by clever economists?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AefhNuP5Xe6R6eP8B", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 13, "extendedScore": null, "score": 1.2301060297393272e-06, "legacy": true, "legacyId": "22927", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T17:53:40.651Z", "modifiedAt": null, "url": null, "title": "Meetup : Berkeley: Hypothetical Apostasy", "slug": "meetup-berkeley-hypothetical-apostasy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:25.681Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nisan", "createdAt": "2009-09-08T21:20:08.384Z", "isAdmin": false, "displayName": "Nisan"}, "userId": "sJv7yzCp5xfWBAPvG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/72vufSihoJNqkfcyB/meetup-berkeley-hypothetical-apostasy", "pageUrlRelative": "/posts/72vufSihoJNqkfcyB/meetup-berkeley-hypothetical-apostasy", "linkUrl": "https://www.lesswrong.com/posts/72vufSihoJNqkfcyB/meetup-berkeley-hypothetical-apostasy", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Berkeley%3A%20Hypothetical%20Apostasy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Berkeley%3A%20Hypothetical%20Apostasy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F72vufSihoJNqkfcyB%2Fmeetup-berkeley-hypothetical-apostasy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Berkeley%3A%20Hypothetical%20Apostasy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F72vufSihoJNqkfcyB%2Fmeetup-berkeley-hypothetical-apostasy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F72vufSihoJNqkfcyB%2Fmeetup-berkeley-hypothetical-apostasy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 221, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/np'>Berkeley: Hypothetical Apostasy</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">12 June 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, there will be a meetup at Zendo tonight. I'd like to try an exercise called Hypothetical Apostasy that was devised by Nick Bostrom:</p>\n\n<blockquote>\n  <p>Imagine, if you will, that the world's destruction is at stake and the only way to save it is for you to write a one-pager that convinces a jury that your old cherished view is mistaken or at least seriously incomplete.  The more inadequate the jury thinks your old cherished view is, the greater the chances that the world is saved.  The catch is that the jury consists of earlier stages of yourself (such as yourself such as you were one year ago).  Moreover, the jury believes that you have been bribed to write your apostasy; so any assurances of the form \"trust me, I am older and know better\" will be ineffective.  Your only hope of saving the world is by writing an apostasy that will make the jury recognize how flawed / partial / shallow / juvenile / crude / irresponsible / incomplete and generally inadequate your old cherished view is.</p>\n</blockquote>\n\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/np'>Berkeley: Hypothetical Apostasy</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "72vufSihoJNqkfcyB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 1.2301994729034291e-06, "legacy": true, "legacyId": "22928", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Hypothetical_Apostasy\">Discussion article for the meetup : <a href=\"/meetups/np\">Berkeley: Hypothetical Apostasy</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">12 June 2013 07:30:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley, CA</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Dear all, there will be a meetup at Zendo tonight. I'd like to try an exercise called Hypothetical Apostasy that was devised by Nick Bostrom:</p>\n\n<blockquote>\n  <p>Imagine, if you will, that the world's destruction is at stake and the only way to save it is for you to write a one-pager that convinces a jury that your old cherished view is mistaken or at least seriously incomplete.  The more inadequate the jury thinks your old cherished view is, the greater the chances that the world is saved.  The catch is that the jury consists of earlier stages of yourself (such as yourself such as you were one year ago).  Moreover, the jury believes that you have been bribed to write your apostasy; so any assurances of the form \"trust me, I am older and know better\" will be ineffective.  Your only hope of saving the world is by writing an apostasy that will make the jury recognize how flawed / partial / shallow / juvenile / crude / irresponsible / incomplete and generally inadequate your old cherished view is.</p>\n</blockquote>\n\n<p>The meetup will begin on Wednesday at 7:30pm. For directions to Zendo, see the mailing list:</p>\n\n<p><a href=\"http://groups.google.com/group/bayarealesswrong\" rel=\"nofollow\">http://groups.google.com/group/bayarealesswrong</a></p>\n\n<p>or call me at:</p>\n\n<p><a href=\"http://i.imgur.com/Vcafy.png\" rel=\"nofollow\">http://i.imgur.com/Vcafy.png</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Berkeley__Hypothetical_Apostasy1\">Discussion article for the meetup : <a href=\"/meetups/np\">Berkeley: Hypothetical Apostasy</a></h2>", "sections": [{"title": "Discussion article for the meetup : Berkeley: Hypothetical Apostasy", "anchor": "Discussion_article_for_the_meetup___Berkeley__Hypothetical_Apostasy", "level": 1}, {"title": "Discussion article for the meetup : Berkeley: Hypothetical Apostasy", "anchor": "Discussion_article_for_the_meetup___Berkeley__Hypothetical_Apostasy1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T18:50:31.353Z", "modifiedAt": null, "url": null, "title": "Effective Altruism Through Advertising Vegetarianism?", "slug": "effective-altruism-through-advertising-vegetarianism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:19.494Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/grP8nTMWm67RbKZwg/effective-altruism-through-advertising-vegetarianism", "pageUrlRelative": "/posts/grP8nTMWm67RbKZwg/effective-altruism-through-advertising-vegetarianism", "linkUrl": "https://www.lesswrong.com/posts/grP8nTMWm67RbKZwg/effective-altruism-through-advertising-vegetarianism", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Effective%20Altruism%20Through%20Advertising%20Vegetarianism%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEffective%20Altruism%20Through%20Advertising%20Vegetarianism%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgrP8nTMWm67RbKZwg%2Feffective-altruism-through-advertising-vegetarianism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Effective%20Altruism%20Through%20Advertising%20Vegetarianism%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgrP8nTMWm67RbKZwg%2Feffective-altruism-through-advertising-vegetarianism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgrP8nTMWm67RbKZwg%2Feffective-altruism-through-advertising-vegetarianism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4304, "htmlBody": "<blockquote>\n<p><strong>Abstract:</strong>&nbsp;If you value the welfare of nonhuman animals from a consequentialist perspective, there is a lot of potential for reducing suffering by funding the persuasion of people to go vegetarian through either online ads or pamphlets. &nbsp;In this essay, I develop a calculator for people to come up with their own estimates, and I personally come up with a cost-effectiveness estimate of&nbsp;$0.02 to $65.92 needed to avert a year of suffering in a factory farm. &nbsp;I then discuss the methodological criticism that merits skepticism of this estimate and conclude by suggesting (1) a guarded approach of putting in just enough money to help the organizations learn and (2) the need for more studies should be developed that explore advertising vegetarianism in a wide variety of media in a wide variety of ways, that include decent control groups.</p>\n</blockquote>\n<p>-</p>\n<h2>Introduction</h2>\n<p>I start with the claim that it's good for people to eat less meat, whether they become vegetarian -- or, better yet, vegan -- because this means less nonhuman animals are being <a href=\"http://www.veganoutreach.org/whyvegan/animals.html\">painfully factory farmed</a>. &nbsp;I've defended this claim previously in my essay <a href=\"http://www.everydayutilitarian.com/essays/why-eat-less-meat/\">\"Why Eat Less Meat?\"</a>. &nbsp;I recognize that some people, even those who consider themselves <a href=\"http://effective-altruism.org/\">effective altruists</a>, do not value the well-being of nonhuman animals. &nbsp;For them, I hope this essay is interesting, but I admit it will be a lot less relevant.</p>\n<p>The second idea is that it shouldn't matter&nbsp;<em>who</em>&nbsp;is eating less meat. &nbsp;As long as less meat is being eaten, less animals will be farmed, and this is a good thing. &nbsp;Therefore, we should try to get <em>other people</em>&nbsp;to also try and eat less meat.</p>\n<p>The third idea is that it also doesn't matter <em>who&nbsp;</em>is doing the convincing. &nbsp;Therefore, instead of convincing our own friends and family, we can pay other people to convince people to eat less meat. &nbsp;And this is exactly what organizations like <a href=\"http://www.veganoutreach.org/\">Vegan Outreach</a>&nbsp;and <a href=\"http://www.thehumaneleague.com/\">The Humane League</a>&nbsp;are doing. &nbsp;With a certain amount of money, one can hire someone to distribute pamphlets to other people or put advertisements on the internet, and some percentage of people who receive the pamphlets or see the ads will go on to eat less meat. &nbsp;This idea and the previous one should be uncontroversial for consequentialists.</p>\n<p>But the fourth idea is the complication. &nbsp;I want my philanthropic dollars to go as far as possible, <a href=\"http://www.everydayutilitarian.com/essays/where-you-give-is-literally-a-matter-of-life-and-death/\">so as to help as much as possible</a>. &nbsp;Therefore, it becomes very important to try and figure out how much money it takes to get people to eat less meat, so I can compare this to other estimations and see what gets me the best \"bang for my buck\".</p>\n<h2><br />Other Estimations</h2>\n<p>I have seen other estimates floating around the internet that try to estimate the cost of distributing pamphlets, how many conversions each pamphlet produces, and how much less meat is ate via each conversion. &nbsp;Brian Tomasik calculates <a href=\"http://www.utilitarian-essays.com/dollar-worth.pdf\">$0.02 to $3.65</a> [PDF] per year of nonhuman animal suffering prevented, later <a href=\"http://www.utilitarian-essays.com/veg-ads.html\">$2.97 per year</a>, and then later <a href=\"https://www.facebook.com/groups/258113290967518/permalink/307655736013273/?comment_id=307773872668126&amp;offset=0&amp;total_comments=2\">$0.55 to $3.65 per year</a>.</p>\n<p>Jess Whittlestone provides statistics that <a href=\"http://80000hours.org/blog/135-the-power-of-effective-activism\">reveal an estimate of less than a penny per year</a>[1].&nbsp;</p>\n<p><a href=\"http://www.effectiveanimalactivism.org\">Effective Animal Activism</a>, a non-profit evaluator for animal welfare charities, <a href=\"http://effectiveanimalactivism.org/sites/effectiveanimalactivism.org/files/Animal%20Welfare.xlsx\">came up with an estimate</a> [Excel Document] of $0.04 to $16.60 per year of suffering averted, that also takes into account a variety of additional variables, like product elasticity.</p>\n<p>Jeff Kaufman uses a different line of reasoning, by estimating how many vegetarians there are and guessing how many of them came via pamphlets, <a href=\"http://www.jefftk.com/news/2011-11-10\">estimates it would take $4.29 to $536</a>&nbsp;to make someone vegetarian for one year. &nbsp;Extrapolating from that using at a rate of 255 animals saved per year and a weighted average of 329.6 days lived per animal (see below for justification of both assumptions), would give $0.02 to $1.90 per year of suffering averted[2].</p>\n<p>A third line of reasoning, also by Jeff Kaufman, was to <a href=\"http://www.jefftk.com/news/2013-04-17\">measure the amount of comments</a>&nbsp;on the pro-vegetarian websites advertised in these campaigns and found that 2-22% of them were about an intended behavior change (eating less meat, going vegetarian, or going vegan), depending on the website. &nbsp;I don't think we can draw any conclusions from this, but it's interesting.</p>\n<p><strong>To make my calculations, I decided to <a href=\"http://www.everydayutilitarian.com/vegan-outreach-cost-effectiveness-calculator/\">make a calculator</a>.</strong> &nbsp;Unfortunately, I can't embed it here, so you'd have to open it in a new tab as a companion piece.</p>\n<p>I'm going to start by using the following formula: <strong>Years of Suffering Averted per Dollar = (Pamphlets / dollar) * (Conversions / pamphlet) * (Veg years / conversion) * (Animals saved / veg year) * (Days lived / animal)</strong></p>\n<p>Now, to get estimations for these variables.</p>\n<h2><br />Pamphlets Per Dollar</h2>\n<p>How much does it cost to place the advertisement, whether it be the paper pamphlet or a Facebook advertisement? &nbsp;Nick Cooney, head of the Humane League, says the cost-per-click of Facebook ads is 20 cents.</p>\n<p>But what about the cost per pamphlet? &nbsp;This is more of a guess, but I'm going to go with &lt;a href=\"\"&gt;<a href=\"http://www.veganoutreach.org/catalog/index.html\">Vegan Outreach's suggested donation</a> of $0.13 per \"Compassionate choices\" booklet.</p>\n<p>However, it's important to note that this cost must also include opportunity cost -- leafleters must forego the ability to use that time to work a job. &nbsp;This means I must include an opportunity cost of say $8/hr on top of that, making the actual cost $0.27 assuming a pamphlet is given out each minute of volunteer time, meaning 3.7 people are reached per dollar from pamphlets. &nbsp;For Facebook advertisements, the opportunity cost is trivial.</p>\n<h2><br />Conversions Per Pamphlet</h2>\n<p>This is the estimate with the biggest target on it's head, so to speak. &nbsp;How many people do we get to actually change their behavior with a simple pamphlet or Facebook advertisement? &nbsp;Right now, we have three lines of evidence:</p>\n<h4>Facebook Study</h4>\n<p>Humane League did A $5000 Facebook advertisement campaign. &nbsp;They bought ads that look like this...</p>\n<p><img src=\"http://www.everydayutilitarian.com/wp-content/uploads/2013/06/voads.png\" alt=\"\" width=\"512\" height=\"119\" /></p>\n<p>&nbsp;</p>\n<p>...and sent people to websites (like <a href=\"http://whosagainstanimalcruelty.org/\">this one</a>&nbsp;or <a href=\"http://hiddenfaceoffood.com/\">this one</a>) with auto-playing videos that start playing and show the horrors of factory farming.</p>\n<p>Afterward, there was another advertisement run to people who \"liked\" the video page, offering a 1 in 10 chance of winning a free movie ticket in order to take a survey. &nbsp;Everyone who emailed in asking for a free vegetarian starter kit were also emailed a survey. &nbsp;104 people took the survey and there were 32 reported vegetarians[3] and 45 people reported, for example, that their chicken consumption decreased \"slightly\" or \"significantly\".</p>\n<p>7% of visitors liked the page and 1.5% of visitors ordered a starter kit. &nbsp;Assuming all the other people went away from the video not changing their consumption, this survey would lead us to (very tenuously) think about 2.6% of people seeing the video will become a vegetarian[4].</p>\n<p>(<a href=\"http://www.utilitarian-essays.com/FacebookAdsSurveyResults2011.pdf\">Here's the results of the survey in PDF</a>.)</p>\n<h4>Pamphlet Study</h4>\n<p>A second study discussed in <a href=\"http://ccc.farmsanctuary.org/the-powerful-impact-of-college-leafleting-part-1/\">\"The Powerful Impact of College Leafleting (Part 1)\"</a>&nbsp;and <a href=\"http://ccc.farmsanctuary.org/the-powerful-impact-of-college-leafleting/\">\"The Powerful Impact of College Leafleting: Additional Findings and Details (Part 2)\"</a>&nbsp;looked specifically at pamphlets.</p>\n<p>Here, Humane League staff visited two large East Coast state schools and distributed leaflets. &nbsp;They then returned two months later and surveyed people walking by. &nbsp;Those who remember receiving a leaflet earlier were counted. &nbsp;They found about 2% of those receiving a pamphlet went vegetarian.</p>\n<h2>Vegetarian Years Per Conversion</h2>\n<p>But once a pamphlet or Facebook advertisement captures someone, how long will they stay vegetarian? &nbsp;One survey <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/22079892\">showed vegetarians refrain from eating meat</a>&nbsp;for an average of 6 years or more. &nbsp;Another <a href=\"http://www.vrg.org/journal/vj2010issue4/2010_issue4_retention_survey.php\">study I found</a>&nbsp;says 93% of vegetarians stay vegetarian for at least three years.</p>\n<p>&nbsp;</p>\n<h2>Animals Saved Per Vegetarian Year</h2>\n<p>And once you have a vegetarian, how many animals do they save per year? &nbsp;CountingAnimals says <a href=\"http://countinganimals.com/how-many-animals-does-a-vegetarian-save/\">406 animals saved per year</a>.</p>\n<p>The Humane League <a href=\"http://ccc.farmsanctuary.org/the-powerful-impact-of-college-leafleting/\">suggests</a>&nbsp;28 chickens, 2 egg industry hens, 1/8 beef cow, 1/2 pig, 1 turkey, and 1/30 dairy cow per year (total = 31.66 animals), and does not provide statistics on fish. &nbsp;This agrees with CountingAnimals on non-fish totals.</p>\n<h2>Days Lived Per Animal</h2>\n<p>One problem, however, is that saving a cow that could suffer for years is different from saving a chicken that suffers for only about a month. &nbsp;Using <a href=\"http://www.farmsanctuary.org/learn/factory-farming/dairy/\">data from Farm Sanctuary</a>&nbsp;plus World Society for the Protection of Animals <a href=\"http://www.ciwf.org.uk/includes/documents/cm_docs/2008/c/closed_waters_welfare_of_farmed_atlantic_salmon.pdf\">data on fish</a>&nbsp;[PDF], I get this table:</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td><strong>Animal</strong></td>\n<td><strong>Number</strong></td>\n<td><strong>Days Alive</strong></td>\n</tr>\n<tr>\n<td>Chicken (Meat)</td>\n<td>28</td>\n<td>42</td>\n</tr>\n<tr>\n<td>Chicken (Egg)</td>\n<td>2</td>\n<td>365</td>\n</tr>\n<tr>\n<td>Cow (Beef)</td>\n<td>0.125</td>\n<td>365</td>\n</tr>\n<tr>\n<td>Cow (Milk)</td>\n<td>0.033</td>\n<td>1460</td>\n</tr>\n<tr>\n<td>Fish</td>\n<td>225</td>\n<td>365</td>\n</tr>\n</tbody>\n</table>\n<p>This makes the weighted average 329.6 days[5].</p>\n<p>&nbsp;</p>\n<h2>Accounting For Biases</h2>\n<p>As I said before, our formula was <strong>Years of Suffering Averted = (Pamphlets / dollar) * (Conversions / pamphlet) * (Veg years / conversion) * (Animals saved / veg year) * (Days lived / animal)</strong>.</p>\n<p>Let's plug these values in... <strong>Years of Suffering Averted per Dollar = 5 * 0.02 * 3 * 255.16 * 329.6/365 = 69.12</strong>.</p>\n<p>Or, assuming all this is right (and that's a big assumption), it would cost <strong>less than 2 cents</strong>&nbsp;to prevent a year of suffering on a factory farm by buying vegetarians.</p>\n<p>I don't want to make it sound like I'm beholden to this cost estimate or that this estimate is the \"end all, be all\" of vegan outreach. &nbsp;Indeed, I share many of the skepticisms that have been expressed by others. &nbsp;The simple calculation is... well...&nbsp;<em>simple</em>, and it needs some \"beefing up\", no pun intended. &nbsp;Therefore, I also built a \"complex calculator\" that works on a much more complex formula[6] that is hopefully correct[7] and will provide a more accurate estimation.</p>\n<p>&nbsp;</p>\n<p>The big, big deal for the surveys is concern for bias. &nbsp;The most frequently mentioned bias is <a href=\"http://en.wikipedia.org/wiki/Social_desirability_bias\">social desirability bias</a>, or people who say they reduced meat just because they want to please the surveyor or look like a good person, which actually happens a lot more on surveys than we'd like.</p>\n<p>To account for this, we'll have to figure out how inflated answers are because of this bias and then scale the answers down by that amount. &nbsp;Nick Cooney who says that he's been reading studies that about 25% to 50% of people who say they are vegetarian actually are, though I don't yet have the citations. &nbsp;Thus, if we find out that an advertisement creates two meat reducers, we'd scale that down to one reducer if we're expecting a 50% desirability bias.</p>\n<p>&nbsp;</p>\n<p>The second bias that will be a problem for us is <a href=\"http://en.wikipedia.org/wiki/Non-response_bias\">non-response bias</a>, as those who don't reduce their diet are less likely to take the survey and therefore less likely to be counted. &nbsp;This is especially true in the Facebook study, which only measures people who \"liked\" or requested a starter kit, showing some pro-vegetarian affiliation.</p>\n<p>We can balance this out by assuming everyone who didn't take the survey went on to have no behavior change whatsoever. &nbsp;Nick Cooney's Facebook Ad Survey is for the 7% of people who liked the page (and then responded to the survey), and obviously those who liked the page are more likely to reduce their consumption. &nbsp;I chose an optimistic value of 90% to consider the survey completely representative of the 7% who liked the page, and then a bit more for those who reduced their consumption but did not like the page. &nbsp;My pessimistic value was 95%, assuming everyone who did not like the survey went unchanged and assuming a small response bias among those who liked the page but chose not to take the survey.</p>\n<p>For the pamphlets, however, there should be no response bias since the entire population of college students was surveyed from randomly, and no one was said to reject taking the survey.</p>\n<p>&nbsp;</p>\n<h2>Additional People Are Being Reached</h2>\n<p>In the Facebook survey, those who said they reduced their meat consumption were also asked if they influenced any of their friends and family to also reduce eating meat, and found that they usually produced 0.86 additional reducers.</p>\n<p>This figure seems very high, but I do strongly expect the figure to be positive -- people who reduce eating meat will talk about it sometimes, essentially becoming free advertisements. &nbsp;I'd be very surprised if they ended up being a net negative.</p>\n<p>&nbsp;</p>\n<h2>Accounting for Product Elasticity</h2>\n<p>Another way to boost the effectiveness of the estimate is to be more accurate about what happens when someone stops eating meat. &nbsp;The change isn't from the actual refusal to eat, but rather from the reduced demand for meat, which leads to a reduced supply. &nbsp;Following the laws of economics, however, this reduction won't necessarially be one-for-one, but rather depend on the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Elasticity_(economics)\">elasticity of product demand and supply</a>. &nbsp;By getting this number, we can find out how much meat is reduced for every meat not demanded.</p>\n<p>My guesses in the calculator come from the following sources, some of which are PDFs: <a href=\"http://www.agecon.ksu.edu/livestock/Extension%20Bulletins/BeefDemandDeterminants.pdf\">Beef #1</a>,&nbsp;<a href=\"http://dare.colostate.edu/skoontz/arec510/papers/marsh%20%28ajae%201994%29.pdf\">Beef #2</a>,&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/21679/1/sp99ma02.pdf\">Dairy #1</a>,&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/14745/1/wp9808.pdf\">Dairy #2</a>,&nbsp;<a href=\"http://www.thepigsite.com/swinenews/21164/market-preview-understanding-pork-demand\">Pork #1</a>, <a href=\"http://www.rti.org/pubs/muth_pork-slaughter_final.pdf\">Pork #2</a>,&nbsp;<a href=\"http://www.poultryscience.org/docs/PS_822.pdf\">Egg #1</a>, <a href=\"http://ageconsearch.umn.edu/bitstream/31510/1/27010043.pdf\">Egg #2</a>,&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/31190/1/23020558.pdf\">Poultry</a>,&nbsp;<a href=\"http://onlinelibrary.wiley.com/book/10.1002/9781119993384\">Salmon</a>, and for <a href=\"http://oregonstate.edu/dept/IIFET/Japan/proceedupdates/306.pdf\">all fish</a>.</p>\n<p>&nbsp;</p>\n<h2>Putting It All Together</h2>\n<p>Implementing the formula <a href=\"http://www.everydayutilitarian.com/vegan-outreach-cost-effectiveness-calculator/\">on the calculator</a>, we end up with an estimate of <strong>$0.03 to $36.52</strong>&nbsp;to reduce one year of suffering on a factory farm based on the Facebook ad data and an estimate of <strong>$0.02 to $65.92</strong>&nbsp;based on the pamphlet data.</p>\n<p>Of course, many people are skeptical of these figures. &nbsp;Perhaps surprisingly, so am I. &nbsp;I'm trying to strike a balance between being an advocate of vegan outreach as a very promising path for making the world a better place, while not losing sight of the methodological hurdles that have not yet been met, and open to the possibility that I'm <em>wrong about this</em>.</p>\n<p>The big methodological elephant in the room is that my entire cost estimate depends on having a plausible guess for how likely someone is to change their behavior based on seeing an advertisement.</p>\n<p>I feel slightly reassured because:</p>\n<ol>\n<li>There are <em>two</em>&nbsp;surveys for two different media, and they both provide estimates of impact that agree with each other.</li>\n<li>These estimates also match anecdotes from leafleters about approximately how many people come back and say they went vegetarian because of a pamphlet.</li>\n<li>Even if we were to take the simple calculator and drop the \"2% chance of getting four years of vegetarianism\" assumption down to, say, a pessimistic \"0.1% chance of getting one year\" conversion rate, the estimate is still not too bad -- $0.91 to avert a year of suffering.</li>\n<li>More studies are on the way. &nbsp;Nick Cooney is going to do a bunch more to study leaflets, and Xio Kikauka and Joey Savoie\ufeff <a href=\"http://docs.google.com/document/d/1jevjZhf4W3of4KrswoeiEHheUbNguRABBM6Cdk04dvs/edit\">have publicly published some survey methodology</a>&nbsp;[Google Docs].</li>\n</ol>\n<p>That said, the possibility for desirability bias in the survey is a large concern as long as the surveys continue to be from overt animal welfare groups and continue to clearly state that they're looking for reductions in meat consumption.</p>\n<p>Also, so long as surveys are only given to people that remember the leaflet or advertisement, there will be a strong possibility of response bias, as those who remember the ad are more likely to be the ones who changed their behavior. &nbsp;We can attempt to compensate for these things, but we can only do so much.</p>\n<p>Furthermore, and more worrying, there's a concern that the surveys are just measuring normal drift in vegetarianism, without any changes being attributable to the ads themselves. &nbsp;For example, imagine that every year, 2% of people become vegetarians and 2% quit. &nbsp;Surveying these people at random and not capturing those who quit will end up finding a 2% conversion rate.</p>\n<p>How can we address these? &nbsp;<strong>I think all three problems can be solved with a decent control group</strong>, whether it be a group of people that receive a leaflet not about vegetarianism, or no leaflet at all. &nbsp;Luckily, Kikauka and Savoie's survey intend to do just that.</p>\n<p><a href=\"http://www.jefftk.com/news/2013-05-07\">Jeff Kaufman has a good proposal for a survey design</a>&nbsp;I'd like to see implemented in this area.</p>\n<p>&nbsp;</p>\n<h2>Market Saturation and Diminishing Marginal Returns?</h2>\n<p>Another concern is that there are diminishing marginal returns to these ads. &nbsp;As the critique goes, there are only so many people that will be easily swayed by the advertisement, and once all of them are quickly reached by Facebook ads and pamphlets, things will dry up.</p>\n<p>Unlike the others, I don't think this criticism works well. &nbsp;After all, even if it were true, it still would be worthwhile to take the market as far as it will go, and we can keep monitoring for saturation and find the point where it's no longer cost-effective.</p>\n<p>However, I don't think the market has been tapped up yet at all. &nbsp;<a href=\"http://www.utilitarian-essays.com/facebook-veg-ads.pdf\">According to Nick Cooney</a>&nbsp;[PDF], there are still many opportunities in foreign markets and outside the young, college kid demographic.</p>\n<p>&nbsp;</p>\n<h2>The Conjunction Fallacy?</h2>\n<p>The <a href=\"http://en.wikipedia.org/wiki/Conjunction_fallacy\">conjunction fallacy</a>&nbsp;is a classic fallacy that reminds us that no matter what, the chance of event A happening can never be smaller than the chance of event A happening, followed by event B. &nbsp;For example, the probability that Linda is a bank teller will always be larger than (or equal to) the probability that Linda is a bank teller and a feminist.</p>\n<p>What does this mean for vegetarian outreach? &nbsp;Well, for the simple calculator, we're estimating five factors. &nbsp;In the complex calculator, we're estimating 90 factors. &nbsp;Even if each factor is 99% likely to be correct, the chance that all five are right is 95%, and the chance that all 50 are right is only 60%. &nbsp;If each factor is only 90% likely to be correct, the complex calculator will be right with a probability of 0.5%!</p>\n<p>This is a cause for concern, but I don't think there's any way around this. &nbsp;It's just an inherent problem with estimation. &nbsp;Hopefully we'll be balanced by (1) using the different bounds and (2) hoping underestimates and overestimates will cancel each other out.</p>\n<p>&nbsp;</p>\n<h2>Conversion and The 100 Yard Line</h2>\n<p>Something we should take into account that <em>helps</em>&nbsp;the case for this outreach rather than hurts it is the idea that conversions aren't binary -- someone can be pushed by the ad to be more likely to reduce their meat intake as opposed to fully converted. &nbsp;As <a href=\"http://felicifia.org/viewtopic.php?t=786&quot;\">Brian Tomasik puts it</a>:</p>\n<blockquote>\n<p>Yes, some of the people we convince were already on the border, but there might be lots of other people who get pushed further along and don&rsquo;t get all the way to vegism by our influence. If we picture the path to vegism as a 100-yard line, then maybe we push everyone along by 20 yards. 1/5 of people cross the line, and this is what we see, but the other 4/5 get pushed closer too. (Obviously an overly simplistic model, but it illustrates the idea.)</p>\n</blockquote>\n<p>This would be either very difficult or outright impossible to capture in a survey, but is something to take into account.</p>\n<p>&nbsp;</p>\n<h2>Three Places I Might Donate Before Donating to Vegan Outreach</h2>\n<p>When all is said and done, I like the case for funding this outreach. &nbsp;However, I think there are three other possibilities along these lines that I find more promising:</p>\n<p><strong>Funding the <em>research</em> of vegan outreach:</strong>&nbsp;There needs to be more and higher-quality studies of this before one can feel confident enough in the cost-effectiveness of this outreach. &nbsp;However, initial results are very promising, and the <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">value of information</a> of more studies is therefore very high. &nbsp;Studies can also find ways to advertise <em>more effectively</em>, increasing the impact of each dollar spent. &nbsp;Right now, however, it looks like all ongoing studies are fully funded, but if there were opportunities to fund more, I would jump on it.</p>\n<p><strong>Funding <a href=\"http://www.effectiveanimalactivism.org/\">Effective Animal Activism</a>:</strong>&nbsp;EAA is an organization pushing for more cost-effectiveness in the domain of nonhuman animal welfare and is working to further evaluate what opportunities are the best, Givewell-style. &nbsp;Giving them more money can potentially attract a lot more attention to this outreach, and get it more scrutiny, research, and money down the line.</p>\n<p><strong>Funding <a href=\"http://centreforeffectivealtruism.org/\">Centre for Effective Altruism</a>:</strong>&nbsp;Overall, it might just be better to get more people involved in the idea of giving effectively, and then getting them interested in vegan outreach, among other things.</p>\n<p>&nbsp;</p>\n<h2>Conclusion</h2>\n<p>Vegan outreach is a promising, though not fully studied, method of outreach that deserves both excitement and skepticism. &nbsp;Should one put money into it? &nbsp;Overall, I'd take a guarded approach of putting in just enough money to help the organizations learn, develop better cost-effective measurements and transparency, and become more effective. &nbsp;It shouldn't be too long before this area will become studied well enough to have good confidence in how things are doing.</p>\n<p>More studies should be developed that explore advertising vegetarianism in a wide variety of media in a wide variety of ways, with decent control groups.</p>\n<p>I look forward to seeing how this develops. &nbsp;<a href=\"http://www.everydayutilitarian.com/vegan-outreach-cost-effectiveness-calculator/\">Don't forget to play around with my calculator</a>.</p>\n<p>-</p>\n<p>&nbsp;</p>\n<h2>Footnotes</h2>\n<h6><span style=\"font-weight: normal;\">[1]:</span><span style=\"font-weight: normal;\">&nbsp;Cost effectiveness in years of suffering prevented per dollar = (Pamphlets / dollar) * (Conversions / pamphlet) * (Veg years / conversion) * (Animals saved / veg year) * (Years lived / animal).<br /><br />Plugging in 80K's values... Cost effectiveness = (Pamphlets / dollar) * 0.01 to 0.03 * 25 * 100 * (Years lived / animal)<br /><br />Filling in the gaps with my best guesses... Cost effectiveness = 5 * 0.01 to 0.03 * 25 * 100 * 0.90 = 112.5 to 337.5 years of suffering averted per dollar<br />I personally think 25 veg-years per conversion on average is possible but too high; I personally err from 4 to 7.</span></h6>\n<h6>[2]:&nbsp;<span style=\"font-weight: normal;\">I feel like there's an error in this calculation or that Kaufman might disagree with my assumptions of number of animals or days per animal, because I've been told before that these estimates with this method are supposed to be about an order of magnitude higher than other estimates. &nbsp;However, I emailed Kaufman and he seemed to not find any fault with the calculation, though he does think the methodology is bad and the calculation should not be taken at face value.</span></h6>\n<h6><strong>[3]:</strong>&nbsp;<span style=\"font-weight: normal;\">I calculated the number of vegetarians by eyeballing about how many people said they no longer eat fish, which I'd guess only a vegetarian would be willing to give up.</span></h6>\n<h6>[4]: <span style=\"font-weight: normal;\">32 vegetarians / 104 people = 30.7%. &nbsp;That population is 8.5% (7% for likes + 1.5% for the starter kit) of the overall population, leading to 2.61% (30.7% * 8.5%).</span></h6>\n<h6>[5]:<span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\"> Formula is [(Number Meat Chickens)(Days Alive) + (Number Egg Chickens)(Days Alive) + (Number Beef Cows)(Days Alive) + (Number Milk Cows)(Days Alive) + (Number Fish)(Days Alive)] / (Total Number Animals). &nbsp;...Plugging things in: [(28)(42) + (2)(365) + (0.125)(365) + (0.033)(1460) + (225)(365)] / 255.16] = 329.6 days</span><br /><br />[6]:</span><span style=\"font-weight: normal;\"> Cost effectiveness in amount of days prevented per dollar = (People Reached / Dollar + (People Reached / Dollar * Additional People Reached / Direct Reach * Response Bias * Desirability Bias)) * Years Spent Reducing * (((Percent Increasing Beef * Increase Value) + (Percent Staying Same with Beef * Staying Same Value) + (Percent Decreasing Beef Slightly * Decrease Slightly Value) + (Percent Decreasing Beef Significantly * Decrease Significantly Value) + (Percent Eliminating Beef * Elimination Value) + (Percent Never Ate Beef * Never Ate Value)) * Normal Beef Consumption * Beef Elasticity * (Average Beef Lifespan + Days of Suffering from Beef Slaughter)) + (((Percent Increasing Dairy * Increase Value) + (Percent Staying Same with Dairy * Staying Same Value) + (Percent Decreasing Dairy Slightly * Decrease Slightly Value) + (Percent Decreasing Dairy Significantly * Decrease Significantly Value) + (Percent Eliminating Dairy * Elimination Value) + (Percent Never Ate Dairy * Never Ate Value)) * Normal Dairy Consumption * Dairy Elasticity * (Average Dairy Lifespan + Days of Suffering from Dairy Slaughter)) + (((Percent Increasing Pig * Increase Value) + (Percent Staying Same with Pig * Staying Same Value) + (Percent Decreasing Pig Slightly * Decrease Slightly Value) + (Percent Decreasing Pig Significantly * Decrease Significantly Value) + (Percent Eliminating Pig * Elimination Value) + (Percent Never Ate Pig * Never Ate Value)) * Normal Pig Consumption * Pig Elasticity * (Average Pig Lifespan + Days of Suffering from Pig Slaughter)) + (((Percent Increasing Broiler Chicken * Increase Value) + (Percent Staying Same with Broiler Chicken * Staying Same Value) + (Percent Decreasing Broiler Chicken Slightly * Decrease Slightly Value) + (Percent Decreasing Broiler Chicken Significantly * Decrease Significantly Value) + (Percent Eliminating Broiler Chicken * Elimination Value) + (Percent Never Ate Broiler Chicken * Never Ate Value)) * Normal Broiler Chicken Consumption * Broiler Chicken Elasticity * (Average Broiler Chicken Lifespan + Days of Suffering from Broiler Chicken Slaughter)) + (((Percent Increasing Egg * Increase Value) + (Percent Staying Same with Egg * Staying Same Value) + (Percent Decreasing Egg Slightly * Decrease Slightly Value) + (Percent Decreasing Egg Significantly * Decrease Significantly Value) + (Percent Eliminating Egg * Elimination Value) + (Percent Never Ate Egg * Never Ate Value)) * Normal Egg Consumption * Egg Elasticity * (Average Egg Lifespan + Days of Suffering from Egg Slaughter)) + (((Percent Increasing Turkey * Increase Value) + (Percent Staying Same with Turkey * Staying Same Value) + (Percent Decreasing Turkey Slightly * Decrease Slightly Value) + (Percent Decreasing Turkey Significantly * Decrease Significantly Value) + (Percent Eliminating Turkey * Elimination Value) + (Percent Never Ate Turkey * Never Ate Value)) * Normal Turkey Consumption * Turkey Elasticity * (Average Turkey Lifespan + Days of Suffering from Turkey Slaughter)) + (((Percent Increasing Farmed Fish * Increase Value) + (Percent Staying Same with Farmed Fish * Staying Same Value) + (Percent Decreasing Farmed Fish Slightly * Decrease Slightly Value) + (Percent Decreasing Farmed Fish Significantly * Decrease Significantly Value) + (Percent Eliminating Farmed Fish * Elimination Value) + (Percent Never Ate Farmed Fish * Never Ate Value)) * Normal Farmed Fish Consumption * Farmed Fish Elasticity * (Average Farmed Fish Lifespan + Days of Suffering from Farmed Fish Slaughter)) + (((Percent Increasing Sea Fish * Increase Value) + (Percent Staying Same with Sea Fish * Staying Same Value) + (Percent Decreasing Sea Fish Slightly * Decrease Slightly Value) + (Percent Decreasing Sea Fish Significantly * Decrease Significantly Value) + (Percent Eliminating Sea Fish * Elimination Value) + (Percent Never Ate Sea Fish * Never Ate Value)) * Normal Sea Fish Consumption * Sea Fish Elasticity * Days of Suffering from Sea Fish Slaughter) * Response Bias * Desirability Bias</span></h6>\n<h6>[7]: <span style=\"font-weight: normal;\">Feel free to check the formula for accuracy and also check to make sure the calculator implements the formula correctly. &nbsp;I worry that the added accuracy from the complex calculator is outweighed by the risk that the formula is wrong.</span></h6>\n<p>-</p>\n<address>Edited 18 June to correct two typos and update footnote #2.</address><address><br /></address><address>Also <a href=\"http://www.everydayutilitarian.com/essays/how-much-does-it-cost-to-buy-a-vegetarian/\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</address><address><br /></address>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Q9ASuEEoJWxT3RLMT": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "grP8nTMWm67RbKZwg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 24, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "22929", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p><strong>Abstract:</strong>&nbsp;If you value the welfare of nonhuman animals from a consequentialist perspective, there is a lot of potential for reducing suffering by funding the persuasion of people to go vegetarian through either online ads or pamphlets. &nbsp;In this essay, I develop a calculator for people to come up with their own estimates, and I personally come up with a cost-effectiveness estimate of&nbsp;$0.02 to $65.92 needed to avert a year of suffering in a factory farm. &nbsp;I then discuss the methodological criticism that merits skepticism of this estimate and conclude by suggesting (1) a guarded approach of putting in just enough money to help the organizations learn and (2) the need for more studies should be developed that explore advertising vegetarianism in a wide variety of media in a wide variety of ways, that include decent control groups.</p>\n</blockquote>\n<p>-</p>\n<h2 id=\"Introduction\">Introduction</h2>\n<p>I start with the claim that it's good for people to eat less meat, whether they become vegetarian -- or, better yet, vegan -- because this means less nonhuman animals are being <a href=\"http://www.veganoutreach.org/whyvegan/animals.html\">painfully factory farmed</a>. &nbsp;I've defended this claim previously in my essay <a href=\"http://www.everydayutilitarian.com/essays/why-eat-less-meat/\">\"Why Eat Less Meat?\"</a>. &nbsp;I recognize that some people, even those who consider themselves <a href=\"http://effective-altruism.org/\">effective altruists</a>, do not value the well-being of nonhuman animals. &nbsp;For them, I hope this essay is interesting, but I admit it will be a lot less relevant.</p>\n<p>The second idea is that it shouldn't matter&nbsp;<em>who</em>&nbsp;is eating less meat. &nbsp;As long as less meat is being eaten, less animals will be farmed, and this is a good thing. &nbsp;Therefore, we should try to get <em>other people</em>&nbsp;to also try and eat less meat.</p>\n<p>The third idea is that it also doesn't matter <em>who&nbsp;</em>is doing the convincing. &nbsp;Therefore, instead of convincing our own friends and family, we can pay other people to convince people to eat less meat. &nbsp;And this is exactly what organizations like <a href=\"http://www.veganoutreach.org/\">Vegan Outreach</a>&nbsp;and <a href=\"http://www.thehumaneleague.com/\">The Humane League</a>&nbsp;are doing. &nbsp;With a certain amount of money, one can hire someone to distribute pamphlets to other people or put advertisements on the internet, and some percentage of people who receive the pamphlets or see the ads will go on to eat less meat. &nbsp;This idea and the previous one should be uncontroversial for consequentialists.</p>\n<p>But the fourth idea is the complication. &nbsp;I want my philanthropic dollars to go as far as possible, <a href=\"http://www.everydayutilitarian.com/essays/where-you-give-is-literally-a-matter-of-life-and-death/\">so as to help as much as possible</a>. &nbsp;Therefore, it becomes very important to try and figure out how much money it takes to get people to eat less meat, so I can compare this to other estimations and see what gets me the best \"bang for my buck\".</p>\n<h2 id=\"Other_Estimations\"><br>Other Estimations</h2>\n<p>I have seen other estimates floating around the internet that try to estimate the cost of distributing pamphlets, how many conversions each pamphlet produces, and how much less meat is ate via each conversion. &nbsp;Brian Tomasik calculates <a href=\"http://www.utilitarian-essays.com/dollar-worth.pdf\">$0.02 to $3.65</a> [PDF] per year of nonhuman animal suffering prevented, later <a href=\"http://www.utilitarian-essays.com/veg-ads.html\">$2.97 per year</a>, and then later <a href=\"https://www.facebook.com/groups/258113290967518/permalink/307655736013273/?comment_id=307773872668126&amp;offset=0&amp;total_comments=2\">$0.55 to $3.65 per year</a>.</p>\n<p>Jess Whittlestone provides statistics that <a href=\"http://80000hours.org/blog/135-the-power-of-effective-activism\">reveal an estimate of less than a penny per year</a>[1].&nbsp;</p>\n<p><a href=\"http://www.effectiveanimalactivism.org\">Effective Animal Activism</a>, a non-profit evaluator for animal welfare charities, <a href=\"http://effectiveanimalactivism.org/sites/effectiveanimalactivism.org/files/Animal%20Welfare.xlsx\">came up with an estimate</a> [Excel Document] of $0.04 to $16.60 per year of suffering averted, that also takes into account a variety of additional variables, like product elasticity.</p>\n<p>Jeff Kaufman uses a different line of reasoning, by estimating how many vegetarians there are and guessing how many of them came via pamphlets, <a href=\"http://www.jefftk.com/news/2011-11-10\">estimates it would take $4.29 to $536</a>&nbsp;to make someone vegetarian for one year. &nbsp;Extrapolating from that using at a rate of 255 animals saved per year and a weighted average of 329.6 days lived per animal (see below for justification of both assumptions), would give $0.02 to $1.90 per year of suffering averted[2].</p>\n<p>A third line of reasoning, also by Jeff Kaufman, was to <a href=\"http://www.jefftk.com/news/2013-04-17\">measure the amount of comments</a>&nbsp;on the pro-vegetarian websites advertised in these campaigns and found that 2-22% of them were about an intended behavior change (eating less meat, going vegetarian, or going vegan), depending on the website. &nbsp;I don't think we can draw any conclusions from this, but it's interesting.</p>\n<p><strong>To make my calculations, I decided to <a href=\"http://www.everydayutilitarian.com/vegan-outreach-cost-effectiveness-calculator/\">make a calculator</a>.</strong> &nbsp;Unfortunately, I can't embed it here, so you'd have to open it in a new tab as a companion piece.</p>\n<p>I'm going to start by using the following formula: <strong>Years of Suffering Averted per Dollar = (Pamphlets / dollar) * (Conversions / pamphlet) * (Veg years / conversion) * (Animals saved / veg year) * (Days lived / animal)</strong></p>\n<p>Now, to get estimations for these variables.</p>\n<h2 id=\"Pamphlets_Per_Dollar\"><br>Pamphlets Per Dollar</h2>\n<p>How much does it cost to place the advertisement, whether it be the paper pamphlet or a Facebook advertisement? &nbsp;Nick Cooney, head of the Humane League, says the cost-per-click of Facebook ads is 20 cents.</p>\n<p>But what about the cost per pamphlet? &nbsp;This is more of a guess, but I'm going to go with &lt;a href=\"\"&gt;<a href=\"http://www.veganoutreach.org/catalog/index.html\">Vegan Outreach's suggested donation</a> of $0.13 per \"Compassionate choices\" booklet.</p>\n<p>However, it's important to note that this cost must also include opportunity cost -- leafleters must forego the ability to use that time to work a job. &nbsp;This means I must include an opportunity cost of say $8/hr on top of that, making the actual cost $0.27 assuming a pamphlet is given out each minute of volunteer time, meaning 3.7 people are reached per dollar from pamphlets. &nbsp;For Facebook advertisements, the opportunity cost is trivial.</p>\n<h2 id=\"Conversions_Per_Pamphlet\"><br>Conversions Per Pamphlet</h2>\n<p>This is the estimate with the biggest target on it's head, so to speak. &nbsp;How many people do we get to actually change their behavior with a simple pamphlet or Facebook advertisement? &nbsp;Right now, we have three lines of evidence:</p>\n<h4 id=\"Facebook_Study\">Facebook Study</h4>\n<p>Humane League did A $5000 Facebook advertisement campaign. &nbsp;They bought ads that look like this...</p>\n<p><img src=\"http://www.everydayutilitarian.com/wp-content/uploads/2013/06/voads.png\" alt=\"\" width=\"512\" height=\"119\"></p>\n<p>&nbsp;</p>\n<p>...and sent people to websites (like <a href=\"http://whosagainstanimalcruelty.org/\">this one</a>&nbsp;or <a href=\"http://hiddenfaceoffood.com/\">this one</a>) with auto-playing videos that start playing and show the horrors of factory farming.</p>\n<p>Afterward, there was another advertisement run to people who \"liked\" the video page, offering a 1 in 10 chance of winning a free movie ticket in order to take a survey. &nbsp;Everyone who emailed in asking for a free vegetarian starter kit were also emailed a survey. &nbsp;104 people took the survey and there were 32 reported vegetarians[3] and 45 people reported, for example, that their chicken consumption decreased \"slightly\" or \"significantly\".</p>\n<p>7% of visitors liked the page and 1.5% of visitors ordered a starter kit. &nbsp;Assuming all the other people went away from the video not changing their consumption, this survey would lead us to (very tenuously) think about 2.6% of people seeing the video will become a vegetarian[4].</p>\n<p>(<a href=\"http://www.utilitarian-essays.com/FacebookAdsSurveyResults2011.pdf\">Here's the results of the survey in PDF</a>.)</p>\n<h4 id=\"Pamphlet_Study\">Pamphlet Study</h4>\n<p>A second study discussed in <a href=\"http://ccc.farmsanctuary.org/the-powerful-impact-of-college-leafleting-part-1/\">\"The Powerful Impact of College Leafleting (Part 1)\"</a>&nbsp;and <a href=\"http://ccc.farmsanctuary.org/the-powerful-impact-of-college-leafleting/\">\"The Powerful Impact of College Leafleting: Additional Findings and Details (Part 2)\"</a>&nbsp;looked specifically at pamphlets.</p>\n<p>Here, Humane League staff visited two large East Coast state schools and distributed leaflets. &nbsp;They then returned two months later and surveyed people walking by. &nbsp;Those who remember receiving a leaflet earlier were counted. &nbsp;They found about 2% of those receiving a pamphlet went vegetarian.</p>\n<h2 id=\"Vegetarian_Years_Per_Conversion\">Vegetarian Years Per Conversion</h2>\n<p>But once a pamphlet or Facebook advertisement captures someone, how long will they stay vegetarian? &nbsp;One survey <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/22079892\">showed vegetarians refrain from eating meat</a>&nbsp;for an average of 6 years or more. &nbsp;Another <a href=\"http://www.vrg.org/journal/vj2010issue4/2010_issue4_retention_survey.php\">study I found</a>&nbsp;says 93% of vegetarians stay vegetarian for at least three years.</p>\n<p>&nbsp;</p>\n<h2 id=\"Animals_Saved_Per_Vegetarian_Year\">Animals Saved Per Vegetarian Year</h2>\n<p>And once you have a vegetarian, how many animals do they save per year? &nbsp;CountingAnimals says <a href=\"http://countinganimals.com/how-many-animals-does-a-vegetarian-save/\">406 animals saved per year</a>.</p>\n<p>The Humane League <a href=\"http://ccc.farmsanctuary.org/the-powerful-impact-of-college-leafleting/\">suggests</a>&nbsp;28 chickens, 2 egg industry hens, 1/8 beef cow, 1/2 pig, 1 turkey, and 1/30 dairy cow per year (total = 31.66 animals), and does not provide statistics on fish. &nbsp;This agrees with CountingAnimals on non-fish totals.</p>\n<h2 id=\"Days_Lived_Per_Animal\">Days Lived Per Animal</h2>\n<p>One problem, however, is that saving a cow that could suffer for years is different from saving a chicken that suffers for only about a month. &nbsp;Using <a href=\"http://www.farmsanctuary.org/learn/factory-farming/dairy/\">data from Farm Sanctuary</a>&nbsp;plus World Society for the Protection of Animals <a href=\"http://www.ciwf.org.uk/includes/documents/cm_docs/2008/c/closed_waters_welfare_of_farmed_atlantic_salmon.pdf\">data on fish</a>&nbsp;[PDF], I get this table:</p>\n<table border=\"0\">\n<tbody>\n<tr>\n<td><strong>Animal</strong></td>\n<td><strong>Number</strong></td>\n<td><strong>Days Alive</strong></td>\n</tr>\n<tr>\n<td>Chicken (Meat)</td>\n<td>28</td>\n<td>42</td>\n</tr>\n<tr>\n<td>Chicken (Egg)</td>\n<td>2</td>\n<td>365</td>\n</tr>\n<tr>\n<td>Cow (Beef)</td>\n<td>0.125</td>\n<td>365</td>\n</tr>\n<tr>\n<td>Cow (Milk)</td>\n<td>0.033</td>\n<td>1460</td>\n</tr>\n<tr>\n<td>Fish</td>\n<td>225</td>\n<td>365</td>\n</tr>\n</tbody>\n</table>\n<p>This makes the weighted average 329.6 days[5].</p>\n<p>&nbsp;</p>\n<h2 id=\"Accounting_For_Biases\">Accounting For Biases</h2>\n<p>As I said before, our formula was <strong>Years of Suffering Averted = (Pamphlets / dollar) * (Conversions / pamphlet) * (Veg years / conversion) * (Animals saved / veg year) * (Days lived / animal)</strong>.</p>\n<p>Let's plug these values in... <strong>Years of Suffering Averted per Dollar = 5 * 0.02 * 3 * 255.16 * 329.6/365 = 69.12</strong>.</p>\n<p>Or, assuming all this is right (and that's a big assumption), it would cost <strong>less than 2 cents</strong>&nbsp;to prevent a year of suffering on a factory farm by buying vegetarians.</p>\n<p>I don't want to make it sound like I'm beholden to this cost estimate or that this estimate is the \"end all, be all\" of vegan outreach. &nbsp;Indeed, I share many of the skepticisms that have been expressed by others. &nbsp;The simple calculation is... well...&nbsp;<em>simple</em>, and it needs some \"beefing up\", no pun intended. &nbsp;Therefore, I also built a \"complex calculator\" that works on a much more complex formula[6] that is hopefully correct[7] and will provide a more accurate estimation.</p>\n<p>&nbsp;</p>\n<p>The big, big deal for the surveys is concern for bias. &nbsp;The most frequently mentioned bias is <a href=\"http://en.wikipedia.org/wiki/Social_desirability_bias\">social desirability bias</a>, or people who say they reduced meat just because they want to please the surveyor or look like a good person, which actually happens a lot more on surveys than we'd like.</p>\n<p>To account for this, we'll have to figure out how inflated answers are because of this bias and then scale the answers down by that amount. &nbsp;Nick Cooney who says that he's been reading studies that about 25% to 50% of people who say they are vegetarian actually are, though I don't yet have the citations. &nbsp;Thus, if we find out that an advertisement creates two meat reducers, we'd scale that down to one reducer if we're expecting a 50% desirability bias.</p>\n<p>&nbsp;</p>\n<p>The second bias that will be a problem for us is <a href=\"http://en.wikipedia.org/wiki/Non-response_bias\">non-response bias</a>, as those who don't reduce their diet are less likely to take the survey and therefore less likely to be counted. &nbsp;This is especially true in the Facebook study, which only measures people who \"liked\" or requested a starter kit, showing some pro-vegetarian affiliation.</p>\n<p>We can balance this out by assuming everyone who didn't take the survey went on to have no behavior change whatsoever. &nbsp;Nick Cooney's Facebook Ad Survey is for the 7% of people who liked the page (and then responded to the survey), and obviously those who liked the page are more likely to reduce their consumption. &nbsp;I chose an optimistic value of 90% to consider the survey completely representative of the 7% who liked the page, and then a bit more for those who reduced their consumption but did not like the page. &nbsp;My pessimistic value was 95%, assuming everyone who did not like the survey went unchanged and assuming a small response bias among those who liked the page but chose not to take the survey.</p>\n<p>For the pamphlets, however, there should be no response bias since the entire population of college students was surveyed from randomly, and no one was said to reject taking the survey.</p>\n<p>&nbsp;</p>\n<h2 id=\"Additional_People_Are_Being_Reached\">Additional People Are Being Reached</h2>\n<p>In the Facebook survey, those who said they reduced their meat consumption were also asked if they influenced any of their friends and family to also reduce eating meat, and found that they usually produced 0.86 additional reducers.</p>\n<p>This figure seems very high, but I do strongly expect the figure to be positive -- people who reduce eating meat will talk about it sometimes, essentially becoming free advertisements. &nbsp;I'd be very surprised if they ended up being a net negative.</p>\n<p>&nbsp;</p>\n<h2 id=\"Accounting_for_Product_Elasticity\">Accounting for Product Elasticity</h2>\n<p>Another way to boost the effectiveness of the estimate is to be more accurate about what happens when someone stops eating meat. &nbsp;The change isn't from the actual refusal to eat, but rather from the reduced demand for meat, which leads to a reduced supply. &nbsp;Following the laws of economics, however, this reduction won't necessarially be one-for-one, but rather depend on the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Elasticity_(economics)\">elasticity of product demand and supply</a>. &nbsp;By getting this number, we can find out how much meat is reduced for every meat not demanded.</p>\n<p>My guesses in the calculator come from the following sources, some of which are PDFs: <a href=\"http://www.agecon.ksu.edu/livestock/Extension%20Bulletins/BeefDemandDeterminants.pdf\">Beef #1</a>,&nbsp;<a href=\"http://dare.colostate.edu/skoontz/arec510/papers/marsh%20%28ajae%201994%29.pdf\">Beef #2</a>,&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/21679/1/sp99ma02.pdf\">Dairy #1</a>,&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/14745/1/wp9808.pdf\">Dairy #2</a>,&nbsp;<a href=\"http://www.thepigsite.com/swinenews/21164/market-preview-understanding-pork-demand\">Pork #1</a>, <a href=\"http://www.rti.org/pubs/muth_pork-slaughter_final.pdf\">Pork #2</a>,&nbsp;<a href=\"http://www.poultryscience.org/docs/PS_822.pdf\">Egg #1</a>, <a href=\"http://ageconsearch.umn.edu/bitstream/31510/1/27010043.pdf\">Egg #2</a>,&nbsp;<a href=\"http://ageconsearch.umn.edu/bitstream/31190/1/23020558.pdf\">Poultry</a>,&nbsp;<a href=\"http://onlinelibrary.wiley.com/book/10.1002/9781119993384\">Salmon</a>, and for <a href=\"http://oregonstate.edu/dept/IIFET/Japan/proceedupdates/306.pdf\">all fish</a>.</p>\n<p>&nbsp;</p>\n<h2 id=\"Putting_It_All_Together\">Putting It All Together</h2>\n<p>Implementing the formula <a href=\"http://www.everydayutilitarian.com/vegan-outreach-cost-effectiveness-calculator/\">on the calculator</a>, we end up with an estimate of <strong>$0.03 to $36.52</strong>&nbsp;to reduce one year of suffering on a factory farm based on the Facebook ad data and an estimate of <strong>$0.02 to $65.92</strong>&nbsp;based on the pamphlet data.</p>\n<p>Of course, many people are skeptical of these figures. &nbsp;Perhaps surprisingly, so am I. &nbsp;I'm trying to strike a balance between being an advocate of vegan outreach as a very promising path for making the world a better place, while not losing sight of the methodological hurdles that have not yet been met, and open to the possibility that I'm <em>wrong about this</em>.</p>\n<p>The big methodological elephant in the room is that my entire cost estimate depends on having a plausible guess for how likely someone is to change their behavior based on seeing an advertisement.</p>\n<p>I feel slightly reassured because:</p>\n<ol>\n<li>There are <em>two</em>&nbsp;surveys for two different media, and they both provide estimates of impact that agree with each other.</li>\n<li>These estimates also match anecdotes from leafleters about approximately how many people come back and say they went vegetarian because of a pamphlet.</li>\n<li>Even if we were to take the simple calculator and drop the \"2% chance of getting four years of vegetarianism\" assumption down to, say, a pessimistic \"0.1% chance of getting one year\" conversion rate, the estimate is still not too bad -- $0.91 to avert a year of suffering.</li>\n<li>More studies are on the way. &nbsp;Nick Cooney is going to do a bunch more to study leaflets, and Xio Kikauka and Joey Savoie\ufeff <a href=\"http://docs.google.com/document/d/1jevjZhf4W3of4KrswoeiEHheUbNguRABBM6Cdk04dvs/edit\">have publicly published some survey methodology</a>&nbsp;[Google Docs].</li>\n</ol>\n<p>That said, the possibility for desirability bias in the survey is a large concern as long as the surveys continue to be from overt animal welfare groups and continue to clearly state that they're looking for reductions in meat consumption.</p>\n<p>Also, so long as surveys are only given to people that remember the leaflet or advertisement, there will be a strong possibility of response bias, as those who remember the ad are more likely to be the ones who changed their behavior. &nbsp;We can attempt to compensate for these things, but we can only do so much.</p>\n<p>Furthermore, and more worrying, there's a concern that the surveys are just measuring normal drift in vegetarianism, without any changes being attributable to the ads themselves. &nbsp;For example, imagine that every year, 2% of people become vegetarians and 2% quit. &nbsp;Surveying these people at random and not capturing those who quit will end up finding a 2% conversion rate.</p>\n<p>How can we address these? &nbsp;<strong>I think all three problems can be solved with a decent control group</strong>, whether it be a group of people that receive a leaflet not about vegetarianism, or no leaflet at all. &nbsp;Luckily, Kikauka and Savoie's survey intend to do just that.</p>\n<p><a href=\"http://www.jefftk.com/news/2013-05-07\">Jeff Kaufman has a good proposal for a survey design</a>&nbsp;I'd like to see implemented in this area.</p>\n<p>&nbsp;</p>\n<h2 id=\"Market_Saturation_and_Diminishing_Marginal_Returns_\">Market Saturation and Diminishing Marginal Returns?</h2>\n<p>Another concern is that there are diminishing marginal returns to these ads. &nbsp;As the critique goes, there are only so many people that will be easily swayed by the advertisement, and once all of them are quickly reached by Facebook ads and pamphlets, things will dry up.</p>\n<p>Unlike the others, I don't think this criticism works well. &nbsp;After all, even if it were true, it still would be worthwhile to take the market as far as it will go, and we can keep monitoring for saturation and find the point where it's no longer cost-effective.</p>\n<p>However, I don't think the market has been tapped up yet at all. &nbsp;<a href=\"http://www.utilitarian-essays.com/facebook-veg-ads.pdf\">According to Nick Cooney</a>&nbsp;[PDF], there are still many opportunities in foreign markets and outside the young, college kid demographic.</p>\n<p>&nbsp;</p>\n<h2 id=\"The_Conjunction_Fallacy_\">The Conjunction Fallacy?</h2>\n<p>The <a href=\"http://en.wikipedia.org/wiki/Conjunction_fallacy\">conjunction fallacy</a>&nbsp;is a classic fallacy that reminds us that no matter what, the chance of event A happening can never be smaller than the chance of event A happening, followed by event B. &nbsp;For example, the probability that Linda is a bank teller will always be larger than (or equal to) the probability that Linda is a bank teller and a feminist.</p>\n<p>What does this mean for vegetarian outreach? &nbsp;Well, for the simple calculator, we're estimating five factors. &nbsp;In the complex calculator, we're estimating 90 factors. &nbsp;Even if each factor is 99% likely to be correct, the chance that all five are right is 95%, and the chance that all 50 are right is only 60%. &nbsp;If each factor is only 90% likely to be correct, the complex calculator will be right with a probability of 0.5%!</p>\n<p>This is a cause for concern, but I don't think there's any way around this. &nbsp;It's just an inherent problem with estimation. &nbsp;Hopefully we'll be balanced by (1) using the different bounds and (2) hoping underestimates and overestimates will cancel each other out.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conversion_and_The_100_Yard_Line\">Conversion and The 100 Yard Line</h2>\n<p>Something we should take into account that <em>helps</em>&nbsp;the case for this outreach rather than hurts it is the idea that conversions aren't binary -- someone can be pushed by the ad to be more likely to reduce their meat intake as opposed to fully converted. &nbsp;As <a href=\"http://felicifia.org/viewtopic.php?t=786&quot;\">Brian Tomasik puts it</a>:</p>\n<blockquote>\n<p>Yes, some of the people we convince were already on the border, but there might be lots of other people who get pushed further along and don\u2019t get all the way to vegism by our influence. If we picture the path to vegism as a 100-yard line, then maybe we push everyone along by 20 yards. 1/5 of people cross the line, and this is what we see, but the other 4/5 get pushed closer too. (Obviously an overly simplistic model, but it illustrates the idea.)</p>\n</blockquote>\n<p>This would be either very difficult or outright impossible to capture in a survey, but is something to take into account.</p>\n<p>&nbsp;</p>\n<h2 id=\"Three_Places_I_Might_Donate_Before_Donating_to_Vegan_Outreach\">Three Places I Might Donate Before Donating to Vegan Outreach</h2>\n<p>When all is said and done, I like the case for funding this outreach. &nbsp;However, I think there are three other possibilities along these lines that I find more promising:</p>\n<p><strong>Funding the <em>research</em> of vegan outreach:</strong>&nbsp;There needs to be more and higher-quality studies of this before one can feel confident enough in the cost-effectiveness of this outreach. &nbsp;However, initial results are very promising, and the <a href=\"http://en.wikipedia.org/wiki/Value_of_information\">value of information</a> of more studies is therefore very high. &nbsp;Studies can also find ways to advertise <em>more effectively</em>, increasing the impact of each dollar spent. &nbsp;Right now, however, it looks like all ongoing studies are fully funded, but if there were opportunities to fund more, I would jump on it.</p>\n<p><strong>Funding <a href=\"http://www.effectiveanimalactivism.org/\">Effective Animal Activism</a>:</strong>&nbsp;EAA is an organization pushing for more cost-effectiveness in the domain of nonhuman animal welfare and is working to further evaluate what opportunities are the best, Givewell-style. &nbsp;Giving them more money can potentially attract a lot more attention to this outreach, and get it more scrutiny, research, and money down the line.</p>\n<p><strong>Funding <a href=\"http://centreforeffectivealtruism.org/\">Centre for Effective Altruism</a>:</strong>&nbsp;Overall, it might just be better to get more people involved in the idea of giving effectively, and then getting them interested in vegan outreach, among other things.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>Vegan outreach is a promising, though not fully studied, method of outreach that deserves both excitement and skepticism. &nbsp;Should one put money into it? &nbsp;Overall, I'd take a guarded approach of putting in just enough money to help the organizations learn, develop better cost-effective measurements and transparency, and become more effective. &nbsp;It shouldn't be too long before this area will become studied well enough to have good confidence in how things are doing.</p>\n<p>More studies should be developed that explore advertising vegetarianism in a wide variety of media in a wide variety of ways, with decent control groups.</p>\n<p>I look forward to seeing how this develops. &nbsp;<a href=\"http://www.everydayutilitarian.com/vegan-outreach-cost-effectiveness-calculator/\">Don't forget to play around with my calculator</a>.</p>\n<p>-</p>\n<p>&nbsp;</p>\n<h2 id=\"Footnotes\">Footnotes</h2>\n<h6><span style=\"font-weight: normal;\">[1]:</span><span style=\"font-weight: normal;\">&nbsp;Cost effectiveness in years of suffering prevented per dollar = (Pamphlets / dollar) * (Conversions / pamphlet) * (Veg years / conversion) * (Animals saved / veg year) * (Years lived / animal).<br><br>Plugging in 80K's values... Cost effectiveness = (Pamphlets / dollar) * 0.01 to 0.03 * 25 * 100 * (Years lived / animal)<br><br>Filling in the gaps with my best guesses... Cost effectiveness = 5 * 0.01 to 0.03 * 25 * 100 * 0.90 = 112.5 to 337.5 years of suffering averted per dollar<br>I personally think 25 veg-years per conversion on average is possible but too high; I personally err from 4 to 7.</span></h6>\n<h6>[2]:&nbsp;<span style=\"font-weight: normal;\">I feel like there's an error in this calculation or that Kaufman might disagree with my assumptions of number of animals or days per animal, because I've been told before that these estimates with this method are supposed to be about an order of magnitude higher than other estimates. &nbsp;However, I emailed Kaufman and he seemed to not find any fault with the calculation, though he does think the methodology is bad and the calculation should not be taken at face value.</span></h6>\n<h6><strong>[3]:</strong>&nbsp;<span style=\"font-weight: normal;\">I calculated the number of vegetarians by eyeballing about how many people said they no longer eat fish, which I'd guess only a vegetarian would be willing to give up.</span></h6>\n<h6>[4]: <span style=\"font-weight: normal;\">32 vegetarians / 104 people = 30.7%. &nbsp;That population is 8.5% (7% for likes + 1.5% for the starter kit) of the overall population, leading to 2.61% (30.7% * 8.5%).</span></h6>\n<h6>[5]:<span style=\"font-weight: normal;\"><span style=\"font-weight: normal;\"> Formula is [(Number Meat Chickens)(Days Alive) + (Number Egg Chickens)(Days Alive) + (Number Beef Cows)(Days Alive) + (Number Milk Cows)(Days Alive) + (Number Fish)(Days Alive)] / (Total Number Animals). &nbsp;...Plugging things in: [(28)(42) + (2)(365) + (0.125)(365) + (0.033)(1460) + (225)(365)] / 255.16] = 329.6 days</span><br><br>[6]:</span><span style=\"font-weight: normal;\"> Cost effectiveness in amount of days prevented per dollar = (People Reached / Dollar + (People Reached / Dollar * Additional People Reached / Direct Reach * Response Bias * Desirability Bias)) * Years Spent Reducing * (((Percent Increasing Beef * Increase Value) + (Percent Staying Same with Beef * Staying Same Value) + (Percent Decreasing Beef Slightly * Decrease Slightly Value) + (Percent Decreasing Beef Significantly * Decrease Significantly Value) + (Percent Eliminating Beef * Elimination Value) + (Percent Never Ate Beef * Never Ate Value)) * Normal Beef Consumption * Beef Elasticity * (Average Beef Lifespan + Days of Suffering from Beef Slaughter)) + (((Percent Increasing Dairy * Increase Value) + (Percent Staying Same with Dairy * Staying Same Value) + (Percent Decreasing Dairy Slightly * Decrease Slightly Value) + (Percent Decreasing Dairy Significantly * Decrease Significantly Value) + (Percent Eliminating Dairy * Elimination Value) + (Percent Never Ate Dairy * Never Ate Value)) * Normal Dairy Consumption * Dairy Elasticity * (Average Dairy Lifespan + Days of Suffering from Dairy Slaughter)) + (((Percent Increasing Pig * Increase Value) + (Percent Staying Same with Pig * Staying Same Value) + (Percent Decreasing Pig Slightly * Decrease Slightly Value) + (Percent Decreasing Pig Significantly * Decrease Significantly Value) + (Percent Eliminating Pig * Elimination Value) + (Percent Never Ate Pig * Never Ate Value)) * Normal Pig Consumption * Pig Elasticity * (Average Pig Lifespan + Days of Suffering from Pig Slaughter)) + (((Percent Increasing Broiler Chicken * Increase Value) + (Percent Staying Same with Broiler Chicken * Staying Same Value) + (Percent Decreasing Broiler Chicken Slightly * Decrease Slightly Value) + (Percent Decreasing Broiler Chicken Significantly * Decrease Significantly Value) + (Percent Eliminating Broiler Chicken * Elimination Value) + (Percent Never Ate Broiler Chicken * Never Ate Value)) * Normal Broiler Chicken Consumption * Broiler Chicken Elasticity * (Average Broiler Chicken Lifespan + Days of Suffering from Broiler Chicken Slaughter)) + (((Percent Increasing Egg * Increase Value) + (Percent Staying Same with Egg * Staying Same Value) + (Percent Decreasing Egg Slightly * Decrease Slightly Value) + (Percent Decreasing Egg Significantly * Decrease Significantly Value) + (Percent Eliminating Egg * Elimination Value) + (Percent Never Ate Egg * Never Ate Value)) * Normal Egg Consumption * Egg Elasticity * (Average Egg Lifespan + Days of Suffering from Egg Slaughter)) + (((Percent Increasing Turkey * Increase Value) + (Percent Staying Same with Turkey * Staying Same Value) + (Percent Decreasing Turkey Slightly * Decrease Slightly Value) + (Percent Decreasing Turkey Significantly * Decrease Significantly Value) + (Percent Eliminating Turkey * Elimination Value) + (Percent Never Ate Turkey * Never Ate Value)) * Normal Turkey Consumption * Turkey Elasticity * (Average Turkey Lifespan + Days of Suffering from Turkey Slaughter)) + (((Percent Increasing Farmed Fish * Increase Value) + (Percent Staying Same with Farmed Fish * Staying Same Value) + (Percent Decreasing Farmed Fish Slightly * Decrease Slightly Value) + (Percent Decreasing Farmed Fish Significantly * Decrease Significantly Value) + (Percent Eliminating Farmed Fish * Elimination Value) + (Percent Never Ate Farmed Fish * Never Ate Value)) * Normal Farmed Fish Consumption * Farmed Fish Elasticity * (Average Farmed Fish Lifespan + Days of Suffering from Farmed Fish Slaughter)) + (((Percent Increasing Sea Fish * Increase Value) + (Percent Staying Same with Sea Fish * Staying Same Value) + (Percent Decreasing Sea Fish Slightly * Decrease Slightly Value) + (Percent Decreasing Sea Fish Significantly * Decrease Significantly Value) + (Percent Eliminating Sea Fish * Elimination Value) + (Percent Never Ate Sea Fish * Never Ate Value)) * Normal Sea Fish Consumption * Sea Fish Elasticity * Days of Suffering from Sea Fish Slaughter) * Response Bias * Desirability Bias</span></h6>\n<h6>[7]: <span style=\"font-weight: normal;\">Feel free to check the formula for accuracy and also check to make sure the calculator implements the formula correctly. &nbsp;I worry that the added accuracy from the complex calculator is outweighed by the risk that the formula is wrong.</span></h6>\n<p>-</p>\n<address>Edited 18 June to correct two typos and update footnote #2.</address><address><br></address><address>Also <a href=\"http://www.everydayutilitarian.com/essays/how-much-does-it-cost-to-buy-a-vegetarian/\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</address><address><br></address>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "Other Estimations", "anchor": "Other_Estimations", "level": 1}, {"title": "Pamphlets Per Dollar", "anchor": "Pamphlets_Per_Dollar", "level": 1}, {"title": "Conversions Per Pamphlet", "anchor": "Conversions_Per_Pamphlet", "level": 1}, {"title": "Facebook Study", "anchor": "Facebook_Study", "level": 2}, {"title": "Pamphlet Study", "anchor": "Pamphlet_Study", "level": 2}, {"title": "Vegetarian Years Per Conversion", "anchor": "Vegetarian_Years_Per_Conversion", "level": 1}, {"title": "Animals Saved Per Vegetarian Year", "anchor": "Animals_Saved_Per_Vegetarian_Year", "level": 1}, {"title": "Days Lived Per Animal", "anchor": "Days_Lived_Per_Animal", "level": 1}, {"title": "Accounting For Biases", "anchor": "Accounting_For_Biases", "level": 1}, {"title": "Additional People Are Being Reached", "anchor": "Additional_People_Are_Being_Reached", "level": 1}, {"title": "Accounting for Product Elasticity", "anchor": "Accounting_for_Product_Elasticity", "level": 1}, {"title": "Putting It All Together", "anchor": "Putting_It_All_Together", "level": 1}, {"title": "Market Saturation and Diminishing Marginal Returns?", "anchor": "Market_Saturation_and_Diminishing_Marginal_Returns_", "level": 1}, {"title": "The Conjunction Fallacy?", "anchor": "The_Conjunction_Fallacy_", "level": 1}, {"title": "Conversion and The 100 Yard Line", "anchor": "Conversion_and_The_100_Yard_Line", "level": 1}, {"title": "Three Places I Might Donate Before Donating to Vegan Outreach", "anchor": "Three_Places_I_Might_Donate_Before_Donating_to_Vegan_Outreach", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Footnotes", "anchor": "Footnotes", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "553 comments"}], "headingsCount": 21}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 553, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-12T19:54:07.143Z", "modifiedAt": null, "url": null, "title": "Do Earths with slower economic growth have a better chance at FAI?", "slug": "do-earths-with-slower-economic-growth-have-a-better-chance", "viewCount": null, "lastCommentedAt": "2020-08-10T07:09:19.187Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FS6NCWzzP8DHp4aD4/do-earths-with-slower-economic-growth-have-a-better-chance", "pageUrlRelative": "/posts/FS6NCWzzP8DHp4aD4/do-earths-with-slower-economic-growth-have-a-better-chance", "linkUrl": "https://www.lesswrong.com/posts/FS6NCWzzP8DHp4aD4/do-earths-with-slower-economic-growth-have-a-better-chance", "postedAtFormatted": "Wednesday, June 12th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20Earths%20with%20slower%20economic%20growth%20have%20a%20better%20chance%20at%20FAI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20Earths%20with%20slower%20economic%20growth%20have%20a%20better%20chance%20at%20FAI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFS6NCWzzP8DHp4aD4%2Fdo-earths-with-slower-economic-growth-have-a-better-chance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20Earths%20with%20slower%20economic%20growth%20have%20a%20better%20chance%20at%20FAI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFS6NCWzzP8DHp4aD4%2Fdo-earths-with-slower-economic-growth-have-a-better-chance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFS6NCWzzP8DHp4aD4%2Fdo-earths-with-slower-economic-growth-have-a-better-chance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1079, "htmlBody": "<p>I was raised as a good and proper child of the Enlightenment who grew up reading <em>The Incredible Bread Machine</em>&nbsp;and <em>A Step Farther Out,</em>&nbsp;taking&nbsp;for granted that economic growth was a huge in-practice component of human utility (plausibly the majority component if you asked yourself what was the major difference between the 21st century and the Middle Ages) and that the \"Small is Beautiful\" / \"Sustainable Growth\" crowds were living in impossible dreamworlds that rejected quantitative thinking in favor of protesting against nuclear power plants.</p>\n<p>And so far as I know, such a view would still be an excellent first-order approximation if we were going to carry on into the future by steady technological progress: &nbsp;Economic growth = good.</p>\n<p>But suppose my main-line projection is correct and the \"probability of an OK outcome\" / \"astronomical benefit\" scenario essentially comes down to a race between Friendly AI and unFriendly AI. &nbsp;So far as I can tell, the most likely reason we wouldn't get Friendly AI is the total <em>serial&nbsp;</em>research depth required to develop and implement a strong-enough theory of stable self-improvement with a possible side order of failing to solve the goal transfer problem. &nbsp;Relative to UFAI, FAI work seems like it would be mathier and more insight-based, where UFAI can more easily cobble together lots of pieces. &nbsp;This means that UFAI parallelizes better than FAI. &nbsp;UFAI also probably benefits from brute-force computing power more than FAI. &nbsp;Both of these imply, so far as I can tell, that slower economic growth is good news for FAI; it lengthens the deadline to UFAI and gives us more time to get the job done. &nbsp;I have sometimes thought half-jokingly and half-anthropically that I ought to try to find investment scenarios based on a continued Great Stagnation and an indefinite Great Recession where the whole developed world slowly goes the way of Spain, because these scenarios would account for a majority of surviving Everett branches.</p>\n<p>Roughly, it seems to me like higher economic growth <em>speeds up time</em>&nbsp;and this is not a good thing. &nbsp;I wish I had more time, not less, in which to work on FAI; I would prefer worlds in which this research can proceed at a relatively less frenzied pace and still succeed, worlds in which the default timelines to UFAI terminate in 2055 instead of 2035.</p>\n<p>I have various cute ideas for things which could improve a country's economic growth. &nbsp;The chance of these things eventuating seems small, the chance that they eventuate because I write about them seems tiny, and they would be good mainly for entertainment, links from econblogs, and possibly marginally impressing some people. &nbsp;I was thinking about collecting them into a post called \"The Nice Things We Can't Have\" based on my prediction that various forces will block, e.g., the all-robotic all-electric car grid which could be relatively trivial to build using present-day technology - that we are too far into the Great Stagnation and the bureaucratic maturity of developed countries to get nice things anymore. &nbsp;However I have a certain inhibition against trying things that would make everyone worse off if they actually succeeded, even if the probability of success is tiny. &nbsp;And it's not completely impossible that we'll see some actual experiments with small nation-states in the next few decades, that some of the people doing those experiments will have read Less Wrong, or that successful experiments will spread (if the US ever legalizes robotic cars or tries a city with an all-robotic fleet, it'll be because China or Dubai or New Zealand tried it first).&nbsp;&nbsp;Other EAs (effective altruists) care much more strongly about economic growth directly and are trying to increase it directly. &nbsp;(An extremely understandable position which would typically be taken by good and virtuous people).</p>\n<p>Throwing out remote, contrived scenarios where something accomplishes the opposite of its intended effect is cheap and meaningless (vide \"But what if MIRI accomplishes the opposite of its purpose due to blah\") but in this case I feel impelled to ask because my <em>mainline</em>&nbsp;visualization has the Great Stagnation being good news. &nbsp;I certainly <em>wish</em>&nbsp;that economic growth would align with FAI because then my virtues would align and my optimal policies have fewer downsides, but I am also aware that wishing does not make something more likely (or less likely) in reality.</p>\n<p>To head off some obvious types of bad reasoning in advance: &nbsp;Yes, higher economic growth frees up resources for effective altruism and thereby increases resources going to FAI, but it also increases resources going to the AI field generally which is mostly pushing UFAI, and the problem <em>arguendo</em>&nbsp;is that UFAI parallelizes more easily.</p>\n<p>Similarly, a planet with generally higher economic growth might develop intelligence amplification (IA) technology earlier. &nbsp;But this general advancement of science will also accelerate UFAI, so you might just be decreasing the amount of FAI research that gets done before IA and decreasing the amount of time available after IA before UFAI. &nbsp;Similarly to the more mundane idea that increased economic growth will produce more geniuses some of whom can work on FAI; there'd also be more geniuses working on UFAI, and UFAI probably parallelizes better and requires less serial depth of research. &nbsp;If you concentrate on some single good effect on <em>blah</em>&nbsp;and neglect the corresponding speeding-up of UFAI timelines, you will obviously be able to generate spurious arguments for economic growth having a positive effect on the balance.</p>\n<p>So I pose the question: &nbsp;\"Is slower economic growth good news?\" or \"Do you think Everett branches with 4% or 1% RGDP growth have a better chance of getting FAI before UFAI\"? &nbsp;So far as I can tell, my current mainline guesses imply, \"Everett branches with slower economic growth contain more serial depth of cognitive causality and have more effective time left on the clock before they end due to UFAI, which favors FAI research over UFAI research\".</p>\n<p>This seems like a good parameter to have a grasp on for any number of reasons, and I can't recall it previously being debated in the x-risk / EA community.</p>\n<p>EDIT: &nbsp;To be clear, the idea is not that trying to <em>deliberately slow</em>&nbsp;world economic growth would be a maximally effective use of EA resources and better than current top targets; this seems likely to have very small marginal effects, and many such courses are risky. &nbsp;The question is whether a good and virtuous person ought to avoid, or alternatively seize, any opportunities which come their way to help out on world economic growth.</p>\n<p>EDIT 2: &nbsp;Carl Shulman's opinion can be found on the <a href=\"https://www.facebook.com/yudkowsky/posts/10151665252179228\">Facebook discussion here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZFrgTgzwEfStg26JL": 1, "zHjC29kkPmsdo7WTr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FS6NCWzzP8DHp4aD4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 54, "extendedScore": null, "score": 0.000155, "legacy": true, "legacyId": "22931", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 176, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-06-12T19:54:07.143Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-13T15:51:39.821Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC projects planning meetup", "slug": "meetup-washington-dc-projects-planning-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uLw66PXre5bKeZq95/meetup-washington-dc-projects-planning-meetup", "pageUrlRelative": "/posts/uLw66PXre5bKeZq95/meetup-washington-dc-projects-planning-meetup", "linkUrl": "https://www.lesswrong.com/posts/uLw66PXre5bKeZq95/meetup-washington-dc-projects-planning-meetup", "postedAtFormatted": "Thursday, June 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20projects%20planning%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20projects%20planning%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuLw66PXre5bKeZq95%2Fmeetup-washington-dc-projects-planning-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20projects%20planning%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuLw66PXre5bKeZq95%2Fmeetup-washington-dc-projects-planning-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuLw66PXre5bKeZq95%2Fmeetup-washington-dc-projects-planning-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/nq\">Washington DC projects planning meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">16 June 2013 03:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>This meetup, we'll be meeting to figure out what projects we want to do together, in response to the very positive response to this suggestion on the list.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/nq\">Washington DC projects planning meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uLw66PXre5bKeZq95", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.231199053552071e-06, "legacy": true, "legacyId": "22934", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_projects_planning_meetup\">Discussion article for the meetup : <a href=\"/meetups/nq\">Washington DC projects planning meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">16 June 2013 03:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>This meetup, we'll be meeting to figure out what projects we want to do together, in response to the very positive response to this suggestion on the list.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_projects_planning_meetup1\">Discussion article for the meetup : <a href=\"/meetups/nq\">Washington DC projects planning meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC projects planning meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_projects_planning_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washington DC projects planning meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_projects_planning_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-13T17:12:48.101Z", "modifiedAt": null, "url": null, "title": "Coursera Public Speaking Course - LW Study Group?", "slug": "coursera-public-speaking-course-lw-study-group-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WibJkyMb7Hk9gHdcK/coursera-public-speaking-course-lw-study-group-0", "pageUrlRelative": "/posts/WibJkyMb7Hk9gHdcK/coursera-public-speaking-course-lw-study-group-0", "linkUrl": "https://www.lesswrong.com/posts/WibJkyMb7Hk9gHdcK/coursera-public-speaking-course-lw-study-group-0", "postedAtFormatted": "Thursday, June 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Coursera%20Public%20Speaking%20Course%20-%20LW%20Study%20Group%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACoursera%20Public%20Speaking%20Course%20-%20LW%20Study%20Group%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWibJkyMb7Hk9gHdcK%2Fcoursera-public-speaking-course-lw-study-group-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Coursera%20Public%20Speaking%20Course%20-%20LW%20Study%20Group%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWibJkyMb7Hk9gHdcK%2Fcoursera-public-speaking-course-lw-study-group-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWibJkyMb7Hk9gHdcK%2Fcoursera-public-speaking-course-lw-study-group-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 280, "htmlBody": "<p>I originally asked this on the London Less Wrong mailing list, but then realised the internet doesn't just have a ten mile radius.</p>\n<p>There's been <a href=\"/lw/h77/four_tips_for_public_speaking/\">some interest in public speaking</a> on LW lately, and it cropped up a couple of times at the London practical meetup as an area people would like to work on. &nbsp;I volunteered to collate some exercises and resources on the subject.</p>\n<p>Since then, I've noticed a <a href=\"https://www.coursera.org/course/publicspeak\">Coursera course on public speaking</a>&nbsp;which is starting in a little under two weeks. &nbsp;I've signed up for it, and would like to encourage other LessWrongers to sign up for it alongside me. &nbsp;My reasons for this are as follows:</p>\n<p>- The course involves the option of recording your progress and sharing it with other participants. &nbsp;As several of us have discovered on the <a href=\"http://www.tinychat.com/lesswrong\">Less Wrong Study Hall</a>, seeing the faces of people you chat to on the internet is fun, sociable and motivational.</p>\n<p>- We can read posts and articles on the subject all day long, but having an externally-imposed syllabus will provide the structure and motivation to actually act on it.</p>\n<p>- There is an aspect of rhetoric and persuasion to the course, (cf. 'dark arts'), and having epistemically&nbsp;hygienic&nbsp;fellows will help keep us on the straight-and-narrow.</p>\n<p>- Turning a large number of aspiring rationalists into&nbsp;erudite&nbsp;and persuasive speakers can't be a bad thing.</p>\n<p>So who else is in?</p>\n<p>(Also, before anyone mentions it, yes, I am very, very aware of the existence of Toastmasters. &nbsp;They seem to be the default suggestion whenever public speaking comes up. &nbsp;For anyone who isn't aware of them, they are an international organisation of clubs practising communication and public speaking. &nbsp;Google them if you're interested. &nbsp;I'm not, for social- and time-commitment reasons.)</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WibJkyMb7Hk9gHdcK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "22935", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CyYM4DF7XYbKHJ5H7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-13T17:15:06.246Z", "modifiedAt": null, "url": null, "title": "Coursera Public Speaking Course - LW Study Group?", "slug": "coursera-public-speaking-course-lw-study-group", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:09.236Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sixes_and_sevens", "createdAt": "2009-11-11T14:42:23.502Z", "isAdmin": false, "displayName": "sixes_and_sevens"}, "userId": "n83meJ5yG2WQzygvw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QKcW89i35ptKsmioH/coursera-public-speaking-course-lw-study-group", "pageUrlRelative": "/posts/QKcW89i35ptKsmioH/coursera-public-speaking-course-lw-study-group", "linkUrl": "https://www.lesswrong.com/posts/QKcW89i35ptKsmioH/coursera-public-speaking-course-lw-study-group", "postedAtFormatted": "Thursday, June 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Coursera%20Public%20Speaking%20Course%20-%20LW%20Study%20Group%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACoursera%20Public%20Speaking%20Course%20-%20LW%20Study%20Group%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQKcW89i35ptKsmioH%2Fcoursera-public-speaking-course-lw-study-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Coursera%20Public%20Speaking%20Course%20-%20LW%20Study%20Group%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQKcW89i35ptKsmioH%2Fcoursera-public-speaking-course-lw-study-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQKcW89i35ptKsmioH%2Fcoursera-public-speaking-course-lw-study-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 294, "htmlBody": "<p>ETA: ModusPonies has set up a <a href=\"https://groups.google.com/forum/#!forum/less-wrong-public-speaking\">Google Group</a> for everyone doing this. &nbsp;It looks like it's officially a Thing.</p>\n<p>I originally asked this on the London Less Wrong mailing list, but then realised the internet doesn't just have a ten mile radius.</p>\n<p>There's been&nbsp;<a href=\"/lw/h77/four_tips_for_public_speaking/\">some interest in public speaking</a>&nbsp;on LW lately, and it cropped up a couple of times at the London practical meetup as an area people would like to work on. &nbsp;I volunteered to collate some exercises and resources on the subject.</p>\n<p>Since then, I've noticed a&nbsp;<a href=\"https://www.coursera.org/course/publicspeak\">Coursera course on public speaking</a>&nbsp;which is starting in a little under two weeks. &nbsp;I've signed up for it, and would like to encourage other LessWrongers to sign up for it alongside me. &nbsp;My reasons for this are as follows:</p>\n<p>- The course involves the option of recording your progress and sharing it with other participants. &nbsp;As several of us have discovered on the&nbsp;<a href=\"http://www.tinychat.com/lesswrong\">Less Wrong Study Hall</a>, seeing the faces of people you chat to on the internet is fun, sociable and motivational.</p>\n<p>- We can read posts and articles on the subject all day long, but having an externally-imposed syllabus will provide the structure and motivation to actually act on it.</p>\n<p>- There is an aspect of rhetoric and persuasion to the course, (cf. 'dark arts'), and having epistemically&nbsp;hygienic&nbsp;fellows will help keep participants on the straight-and-narrow.</p>\n<p>- Turning a large number of aspiring rationalists into&nbsp;erudite&nbsp;and persuasive speakers can't be a bad thing.</p>\n<p>So who else is in?</p>\n<p>(Also, before anyone mentions it, yes, I am very, very aware of the existence of Toastmasters. &nbsp;They seem to be the default suggestion whenever public speaking comes up. &nbsp;For anyone who isn't aware of them, they are an international organisation of clubs practising communication and public speaking. &nbsp;Google them if you're interested. &nbsp;I'm not, for social- and time-commitment reasons.)</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QKcW89i35ptKsmioH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 1.2312623843575308e-06, "legacy": true, "legacyId": "22936", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CyYM4DF7XYbKHJ5H7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-13T21:59:09.515Z", "modifiedAt": null, "url": null, "title": "After critical event W happens, they still won't believe you", "slug": "after-critical-event-w-happens-they-still-won-t-believe-you", "viewCount": null, "lastCommentedAt": "2019-08-17T04:55:55.798Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LNKh22Crr5ujT85YM/after-critical-event-w-happens-they-still-won-t-believe-you", "pageUrlRelative": "/posts/LNKh22Crr5ujT85YM/after-critical-event-w-happens-they-still-won-t-believe-you", "linkUrl": "https://www.lesswrong.com/posts/LNKh22Crr5ujT85YM/after-critical-event-w-happens-they-still-won-t-believe-you", "postedAtFormatted": "Thursday, June 13th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20After%20critical%20event%20W%20happens%2C%20they%20still%20won't%20believe%20you&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAfter%20critical%20event%20W%20happens%2C%20they%20still%20won't%20believe%20you%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLNKh22Crr5ujT85YM%2Fafter-critical-event-w-happens-they-still-won-t-believe-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=After%20critical%20event%20W%20happens%2C%20they%20still%20won't%20believe%20you%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLNKh22Crr5ujT85YM%2Fafter-critical-event-w-happens-they-still-won-t-believe-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLNKh22Crr5ujT85YM%2Fafter-critical-event-w-happens-they-still-won-t-believe-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 859, "htmlBody": "<p>In general and across all instances I can think of so far, I do not agree with the part of your futurological forecast in which you reason, \"After event W happens, everyone will see the truth of proposition X, leading them to endorse Y and agree with me about policy decision Z.\"</p>\n<p>Example 1: &nbsp;\"After a 2-year-old mouse is rejuvenated to allow 3 years of additional life, society will realize that human rejuvenation is possible, turn against deathism as the prospect of lifespan / healthspan extension starts to seem real, and demand a huge Manhattan Project to get it done.\" &nbsp;(EDIT: &nbsp;This has not happened, and the hypothetical is mouse healthspan extension, not anything cryonic. &nbsp;It's being cited because this is Aubrey de Grey's reasoning behind the Methuselah Mouse Prize.)</p>\n<p>Alternative projection: &nbsp;Some media brouhaha. &nbsp;Lots of bioethicists acting concerned. &nbsp;Discussion dies off after a week. &nbsp;Nobody thinks about it afterward. &nbsp;The rest of society does not reason the same way Aubrey de Grey does.</p>\n<p>Example 2: &nbsp;\"As AI gets more sophisticated, everyone will realize that real AI is on the way and then they'll start taking Friendly AI development seriously.\"</p>\n<p>Alternative projection: &nbsp;As AI gets more sophisticated, the rest of society can't see any difference between the latest breakthrough reported in a press release and that business earlier with Watson beating Ken Jennings or Deep Blue beating Kasparov; it seems like the same sort of press release to them. &nbsp;The same people who were talking about robot overlords earlier continue to talk about robot overlords. &nbsp;The same people who were talking about human irreproducibility continue to talk about human specialness. &nbsp;Concern is expressed over technological unemployment the same as today or Keynes in 1930, and this is used to fuel someone's previous ideological commitment to a basic income guarantee, inequality reduction, or whatever. &nbsp;The same tiny segment of unusually consequentialist people are concerned about Friendly AI as before. &nbsp;If anyone in the science community does start thinking that superintelligent AI is on the way, they exhibit the same distribution of performance as modern scientists who think it's on the way, e.g. Hugo de Garis, Ben Goertzel, etc.</p>\n<p>Consider the situation in macroeconomics. &nbsp;When the Federal Reserve dropped interest rates to nearly zero and started printing money via quantitative easing, we had some people loudly predicting hyperinflation just because the monetary base had, you know, gone up by a factor of 10 or whatever it was. &nbsp;Which is kind of understandable. &nbsp;But still, a lot of mainstream economists (such as the Fed) thought we would not get hyperinflation, the implied spread on inflation-protected Treasuries and numerous other indicators showed that the free market thought we were due for below-trend inflation, and then in actual reality we got below-trend inflation. &nbsp;It's one thing to disagree with economists, another thing to disagree with implied market forecasts (why aren't you betting, if you really believe?) but you can still do it sometimes; but when conventional economics, market forecasts, <em>and reality</em>&nbsp;all agree on something, it's time to shut up and ask the economists how they knew. &nbsp;I had some credence in inflationary worries before that experience, but not afterward... &nbsp;So what about the rest of the world? &nbsp;In the heavily scientific community you live in, or if you read econblogs, you will find that a number of people actually have started to worry less about inflation and more about sub-trend nominal GDP growth. &nbsp;You will also find that right now these econblogs are having worry-fits about the Fed prematurely exiting QE and choking off the recovery because the elderly senior people with power have updated more slowly than the econblogs. &nbsp;And in larger society, if you look at what happens when Congresscritters question Bernanke, you will find that they are all terribly, terribly concerned about inflation. &nbsp;Still. &nbsp;The same as before. &nbsp;Some econblogs are very harsh on Bernanke because the Fed did not print enough money, but when I look at the kind of pressure Bernanke was getting from Congress, he starts to look to me like something of a hero just for following conventional macroeconomics as much as he did.</p>\n<p>That issue is a hell of a lot more clear-cut than the medical science for human rejuvenation, which in turn is far more clear-cut ethically and policy-wise than issues in AI.</p>\n<p>After event W happens, a few more relatively young scientists will see the truth of proposition X, and the larger society won't be able to tell a damn difference. &nbsp;This won't change the situation very much, there are probably already some scientists who endorse X, since X is probably pretty predictable even today if you're unbiased. &nbsp;The scientists who see the truth of X won't all rush to endorse Y, any more than current scientists who take X seriously all rush to endorse Y. &nbsp;As for people in power lining up behind your preferred policy option Z, forget it, they're old and set in their ways and Z is relatively novel without a large existing constituency favoring it. &nbsp;Expect W to be used as argument fodder to support conventional policy options that already have political force behind them, and for Z to not even be on the table.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8daMDi9NEShyLqxth": 1, "pGqRLe9bFDX2G2kXY": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LNKh22Crr5ujT85YM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 51, "baseScore": 70, "extendedScore": null, "score": 0.000165, "legacy": true, "legacyId": "22937", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 70, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 107, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T00:21:46.423Z", "modifiedAt": null, "url": null, "title": "[Link] Concrete steps are being taken towards futarchy", "slug": "link-concrete-steps-are-being-taken-towards-futarchy", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:04.347Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AspiringRationalist", "createdAt": "2012-03-14T02:23:07.389Z", "isAdmin": false, "displayName": "AspiringRationalist"}, "userId": "SiQCqozmtW7TSjo6E", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/z76MZ3XpW9Z6JNPJs/link-concrete-steps-are-being-taken-towards-futarchy", "pageUrlRelative": "/posts/z76MZ3XpW9Z6JNPJs/link-concrete-steps-are-being-taken-towards-futarchy", "linkUrl": "https://www.lesswrong.com/posts/z76MZ3XpW9Z6JNPJs/link-concrete-steps-are-being-taken-towards-futarchy", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Concrete%20steps%20are%20being%20taken%20towards%20futarchy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Concrete%20steps%20are%20being%20taken%20towards%20futarchy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz76MZ3XpW9Z6JNPJs%2Flink-concrete-steps-are-being-taken-towards-futarchy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Concrete%20steps%20are%20being%20taken%20towards%20futarchy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz76MZ3XpW9Z6JNPJs%2Flink-concrete-steps-are-being-taken-towards-futarchy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fz76MZ3XpW9Z6JNPJs%2Flink-concrete-steps-are-being-taken-towards-futarchy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 63, "htmlBody": "<p>Article: <a href=\"http://www.washingtonpost.com/business/economy/can-investors-make-money-in-social-services/2013/06/07/a010e7f6-ced6-11e2-8845-d970ccb04497_story.html\">Can investors make money in social services?</a></p>\n<p>According to the article, six states are experimenting with funding social programs using \"social impact bonds\", which only pay out if the programs achieve their official objectives. &nbsp;The project is in its early stages, so it's not clear what will happen if the market decides that a program isn't worth funding, but this looks quite promising.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RGPpwYoCHrPNB86TW": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "z76MZ3XpW9Z6JNPJs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 6, "extendedScore": null, "score": 1.231586314426111e-06, "legacy": true, "legacyId": "22938", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T06:28:15.906Z", "modifiedAt": null, "url": null, "title": "Near-Term Risk: Killer Robots a Threat to Freedom and Democracy", "slug": "near-term-risk-killer-robots-a-threat-to-freedom-and", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:05.382Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Epiphany", "createdAt": "2012-08-12T03:33:21.256Z", "isAdmin": false, "displayName": "Epiphany"}, "userId": "BbbFp6hQzKF4YX8em", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fyZZxaqq93LhQFAQp/near-term-risk-killer-robots-a-threat-to-freedom-and", "pageUrlRelative": "/posts/fyZZxaqq93LhQFAQp/near-term-risk-killer-robots-a-threat-to-freedom-and", "linkUrl": "https://www.lesswrong.com/posts/fyZZxaqq93LhQFAQp/near-term-risk-killer-robots-a-threat-to-freedom-and", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Near-Term%20Risk%3A%20Killer%20Robots%20a%20Threat%20to%20Freedom%20and%20Democracy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANear-Term%20Risk%3A%20Killer%20Robots%20a%20Threat%20to%20Freedom%20and%20Democracy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfyZZxaqq93LhQFAQp%2Fnear-term-risk-killer-robots-a-threat-to-freedom-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Near-Term%20Risk%3A%20Killer%20Robots%20a%20Threat%20to%20Freedom%20and%20Democracy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfyZZxaqq93LhQFAQp%2Fnear-term-risk-killer-robots-a-threat-to-freedom-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfyZZxaqq93LhQFAQp%2Fnear-term-risk-killer-robots-a-threat-to-freedom-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 651, "htmlBody": "<p>A new TED talk video just came out by Daniel Suarez, author of Daemon, explaining how autonomous combat drones with a capability called \"lethal autonomy\" pose a threat to democracy.&nbsp; Lethal autonomy is what it sounds like - the ability of a robot to kill a human without requiring a human to make the decision.</p>\n<p>He explains that a human decision-maker is not a necessity for combat drones to function.&nbsp; This has potentially catastrophic consequences, as it would allow a small number of people to concentrate a very large amount of power, ruining the checks and balances of power between governments and their people and the checks and balances of power between different branches of government.&nbsp; According to Suarez, about 70 countries have begun developing remotely piloted drones (like predator drones), the precursor to killer robots with lethal autonomy.</p>\n<p><a href=\"http://www.ted.com/talks/daniel_suarez_the_kill_decision_shouldn_t_belong_to_a_robot.html\">Daniel Suarez: The kill decision shouldn't belong to a robot</a></p>\n<p>One thing he didn't mention in this video is that there's a difference in obedience levels between human soldiers and combat drones.&nbsp; Drones are completely obedient but humans can throw a revolt.&nbsp; Because they can rebel, human soldiers provide some obstacles to limit the power that would-be tyrants could otherwise obtain.&nbsp; Drones won't provide this type of protection whatsoever.&nbsp; Obviously, relying on human decision making is not perfect.&nbsp; Someone like Hitler can manage to convince people to make poor ethical choices - but still, they <em>need to be convinced</em>, and that requirement may play a major role in protecting us.&nbsp; Consider this - it's unthinkable that today's American soldiers might suddenly decide this evening to follow a tyrannical leader whose goal is to have total power and murder all who oppose.&nbsp; It is not, however, unthinkable at all that the same tyrant, if empowered by an army of combat drones, could successfully launch such an attack without risking a mutiny.&nbsp; The amount and variety of power grabs a tyrant with a robot army of sufficient power can get away with is unlimited.</p>\n<p>Something else he didn't mention is that because we can optimize technologies more easily than we can optimize humans, it may be possible to produce killer robots in less time than it takes to build armies of human soldiers and with less expense than training and paying those soldiers.&nbsp; Considering the salaries and benefits paid to soldiers and the 18 year wait time on human development, it is possible that an overwhelmingly large army of killer robots could be built more quickly than human armies and with fewer resources.</p>\n<p>Suarez's solution is to push for legislation that makes producing robots with lethal autonomy illegal.&nbsp; There are, obviously, pros and cons to this method.&nbsp; Another method (explored in Daemon) is that if the people have 3-D printers, then the people may be able to produce comparable weapons which will then check and balance their government's power.&nbsp; This method has pros and cons as well. I came up with a third method which is <a href=\"/r/discussion/lw/hpb/nearterm_risk_killer_robots_a_threat_to_freedom/95xa\">here</a>.&nbsp; I think it's better than the alternatives but I would like more feedback.</p>\n<p>As far as I know, no organization, not even MIRI (I checked), is dedicated to preventing the potential political disasters caused by near-term tool AI (MIRI is interested in the existential risks posed by AGI).&nbsp; That means it's up to us - the people - to develop our understanding of this subject and spread the word to others.&nbsp; Of all the forums on the internet, LessWrong is one of the most knowledgeable when it comes to artificial intelligence, so it's a logical place to fire up a discussion on this.&nbsp; I searched LessWrong for terms like \"checks and balances\" and \"Daemon\" and I just don't see evidence that we've done a group discussion on this issue.&nbsp; I'm starting by proposing and exploring some possible solutions to this problem and some pros and cons of each.</p>\n<p>To keep things organized, let's put each potential solution, pro and con into a separate comment.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xXX3n22DQZuKqXEdT": 1, "fuZZ64fNz24BLrXnY": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fyZZxaqq93LhQFAQp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 15, "extendedScore": null, "score": 1.231864677141915e-06, "legacy": true, "legacyId": "22943", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 105, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T12:25:46.702Z", "modifiedAt": null, "url": null, "title": "Can we dodge the mindkiller?", "slug": "can-we-dodge-the-mindkiller", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:30.756Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aaapyfpXhiMixqcMD/can-we-dodge-the-mindkiller", "pageUrlRelative": "/posts/aaapyfpXhiMixqcMD/can-we-dodge-the-mindkiller", "linkUrl": "https://www.lesswrong.com/posts/aaapyfpXhiMixqcMD/can-we-dodge-the-mindkiller", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20we%20dodge%20the%20mindkiller%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20we%20dodge%20the%20mindkiller%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaaapyfpXhiMixqcMD%2Fcan-we-dodge-the-mindkiller%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20we%20dodge%20the%20mindkiller%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaaapyfpXhiMixqcMD%2Fcan-we-dodge-the-mindkiller", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaaapyfpXhiMixqcMD%2Fcan-we-dodge-the-mindkiller", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 111, "htmlBody": "<p>I was thinking about the hazards of bad government, and wondering if there was a way for the LW community to do something to oppose them, and it occurred to me that we might be picking up the problem by the wrong end.</p>\n<p>The usual way of thinking about political action is to start with one's political identity (progressive, libertarian, whatever), and that's likely to put one at odds with people who have opposed identities.</p>\n<p>Instead, I believe there are projects which could appeal to rationalists across a wide range of the political spectrum. A couple I can think of are opposing the war on drugs and improving judicial systems. Any other suggestions?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aaapyfpXhiMixqcMD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 7, "extendedScore": null, "score": 3.1e-05, "legacy": true, "legacyId": "22944", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 103, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T15:03:05.396Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-73", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XMEYJwdHw3mRGpz9d/weekly-lw-meetups-73", "pageUrlRelative": "/posts/XMEYJwdHw3mRGpz9d/weekly-lw-meetups-73", "linkUrl": "https://www.lesswrong.com/posts/XMEYJwdHw3mRGpz9d/weekly-lw-meetups-73", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXMEYJwdHw3mRGpz9d%2Fweekly-lw-meetups-73%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXMEYJwdHw3mRGpz9d%2Fweekly-lw-meetups-73", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXMEYJwdHw3mRGpz9d%2Fweekly-lw-meetups-73", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 523, "htmlBody": "<p><strong>This summary was posted to LW Main on June 7th. The following week's summary is <a href=\"/lw/hpd/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a href=\"/meetups/n6\">Atlanta LessWrong June Meetup: Effective Altruism:&nbsp;<span class=\"date\">15 June 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n<li><a href=\"/meetups/ng\">Bratislava Meetup IV.:&nbsp;<span class=\"date\">24 June 2013 06:00PM</span></a></li>\n<li><a href=\"/meetups/nk\">[Bristol] Second Bristol meetup &amp; mailing list for future meetups:&nbsp;<span class=\"date\">16 June 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/nb\">Helsinki meetup with CatM (CFAR instructor) as special guest star:&nbsp;<span class=\"date\">08 June 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/n9\">London - Inaugural Practical Session - June 9th:&nbsp;<span class=\"date\">09 June 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/nf\">[Moscow] Rational choice:&nbsp;<span class=\"date\">09 June 2013 04:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">08 June 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/nl\">[NYC] Self Improvement - Productivity Apps:&nbsp;<span class=\"date\">09 June 2013 03:30PM</span></a></li>\n<li><a href=\"/meetups/nd\">Vienna Meetup #3:&nbsp;<span class=\"date\">15 June 2013 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XMEYJwdHw3mRGpz9d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2322558923636432e-06, "legacy": true, "legacyId": "22885", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dAXu849JEFCnv4K8x", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T18:14:48.140Z", "modifiedAt": null, "url": null, "title": "How should Eliezer and Nick's extra $20 be split", "slug": "how-should-eliezer-and-nick-s-extra-usd20-be-split", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:25.865Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Scott Garrabrant", "createdAt": "2017-09-22T02:21:16.385Z", "isAdmin": false, "displayName": "Scott Garrabrant"}, "userId": "hbQoLoK5tpmFAJGr4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NHFFzBF4b3SZLHckt/how-should-eliezer-and-nick-s-extra-usd20-be-split", "pageUrlRelative": "/posts/NHFFzBF4b3SZLHckt/how-should-eliezer-and-nick-s-extra-usd20-be-split", "linkUrl": "https://www.lesswrong.com/posts/NHFFzBF4b3SZLHckt/how-should-eliezer-and-nick-s-extra-usd20-be-split", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20should%20Eliezer%20and%20Nick's%20extra%20%2420%20be%20split&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20should%20Eliezer%20and%20Nick's%20extra%20%2420%20be%20split%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNHFFzBF4b3SZLHckt%2Fhow-should-eliezer-and-nick-s-extra-usd20-be-split%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20should%20Eliezer%20and%20Nick's%20extra%20%2420%20be%20split%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNHFFzBF4b3SZLHckt%2Fhow-should-eliezer-and-nick-s-extra-usd20-be-split", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNHFFzBF4b3SZLHckt%2Fhow-should-eliezer-and-nick-s-extra-usd20-be-split", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 537, "htmlBody": "<p>In \"<a title=\"Principles of DIsagrement\" href=\"/lw/qw/principles_of_disagreement/\">Principles of Disagreement</a>,\" Eliezer Yudkowsky shared the following anecdote:</p>\n<blockquote>\n<p>Nick Bostrom and I once took a taxi and split the fare.&nbsp; &nbsp;When we counted the money we'd assembled to pay the driver, we found an extra twenty there.</p>\n<p>\"I'm pretty sure this twenty isn't mine,\" said Nick.</p>\n<p>\"I'd have been sure that it wasn't mine either,\" I said.</p>\n<p>\"You just take it,\" said Nick.</p>\n<p>\"No,&nbsp;<em>you</em>&nbsp;just take it,\" I said.</p>\n<p>We looked at each other, and we knew what we had to do.</p>\n<p>\"To the best of your ability to say at this point, what&nbsp;<em>would&nbsp;</em>have been your initial probability that the bill was yours?\" I said.</p>\n<p>\"Fifteen percent,\" said Nick.</p>\n<p>\"I would have said twenty percent,\" I said.</p>\n</blockquote>\n<p>I have left off the ending to give everyone a chance to think about this problem for themselves. How would you have split the twenty?&nbsp;</p>\n<p>In general, EY and NB disagree about who deserves the twenty. EY believes that EY deserves it with probability p, while NB believes that EY deserves it with probability q. They decide to give EY a fraction of the twenty equal to f(p,q). What should the function f be?</p>\n<p>In our example, p=1/5 and q=17/20</p>\n<p>Please think about this problem a little before reading on, so that we do not miss out on any original solutions that you might have come up with.</p>\n<hr />\n<p>I can think of 4 ways to solve this problem. I am attributing answers to the person who first proposed that dollar amount, but my reasoning might not reflect their reasoning.</p>\n<ol>\n<li>f=p/(1+p-q) or $11.43 (Eliezer Yodkowsky/Nick Bostrom) -- EY believes he deserves p of the money, while NB believes he deserves 1-q. They should therefore be given money in a ratio of p:1-q.</li>\n<li>f=(p+q)/2 or $10.50 (Marcello) -- It seems reasonable to assume that there is a 50% chance that EY reasoned properly and a 50% chance that NB reasoned properly, so we should take the average of the amounts of money that EY would get under these two assumptions.</li>\n<li>f=sqrt(pq)/(sqrt(pq)+sqrt((1-p)(1-q))) or $10.87 (GreedyAlgorithm) -- We want to chose an f so that log(f/(1-f)) is the average of log(p/(1-p)) and log(q/(1-q)).&nbsp;</li>\n<li>f=pq/(pq+(1-p)(1-q)) or $11.72 -- We have two observations that EY deserves the money with probability p and probability q respectively. If we assume that these are two independent pieces of evidence as to whether or not EY should get the money, then starting with equal likelihood of each person deserving the money, we should do a Bayesian update for each piece of information.</li>\n</ol> \n<hr />\n<p>I am very curious about this question, so if you have any opinions, please comment. I have some opinions on this problem, but to avoid biasing anyone, I will save them for the comments. I am actually more interested in the following question. I believe that the two will have the same answer, but if anyone disagrees, let me know.</p>\n<p>I have two hypotheses, A and B. I assign probability p to A and probability q to B. I later find out that A and B are equivalent. I then update to assign the probability g(p,q) to both hypotheses. What should the function g be?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NHFFzBF4b3SZLHckt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 18, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "22946", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 66, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gTTWRkSz474o7s4Dg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T18:59:46.835Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA Meetup - Eliezer and Nick Share a Cab...", "slug": "meetup-west-la-meetup-eliezer-and-nick-share-a-cab", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:05.056Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Scott Garrabrant", "createdAt": "2017-09-22T02:21:16.385Z", "isAdmin": false, "displayName": "Scott Garrabrant"}, "userId": "hbQoLoK5tpmFAJGr4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b5im22nFmdxy4sCWe/meetup-west-la-meetup-eliezer-and-nick-share-a-cab", "pageUrlRelative": "/posts/b5im22nFmdxy4sCWe/meetup-west-la-meetup-eliezer-and-nick-share-a-cab", "linkUrl": "https://www.lesswrong.com/posts/b5im22nFmdxy4sCWe/meetup-west-la-meetup-eliezer-and-nick-share-a-cab", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20Meetup%20-%20Eliezer%20and%20Nick%20Share%20a%20Cab...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20Meetup%20-%20Eliezer%20and%20Nick%20Share%20a%20Cab...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb5im22nFmdxy4sCWe%2Fmeetup-west-la-meetup-eliezer-and-nick-share-a-cab%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20Meetup%20-%20Eliezer%20and%20Nick%20Share%20a%20Cab...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb5im22nFmdxy4sCWe%2Fmeetup-west-la-meetup-eliezer-and-nick-share-a-cab", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb5im22nFmdxy4sCWe%2Fmeetup-west-la-meetup-eliezer-and-nick-share-a-cab", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 226, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/nr\">West LA Meetup - Eliezer and Nick Share a Cab...</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">19 June 2013 11:20:26AM (-0700)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p><strong>When:</strong> 7:00pm Wednesday, June 5th.</p>\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a rel=\"nofollow\" href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n<p><strong>Parking</strong> is free for 3 hours.</p>\n<p><strong>Discussion:</strong> Eliezer Yudkowsky and Nick Bostrom once shared a cab and found an extra $20. EY said that he thought it was his with probability 20%, while NB said that it was his with probability 15%. How should they split the extra $20 they found. I will present at least four different justifications for four different answers. Hopefully we will be able to reach a consensus on the best way to distribute the money. I will also explain why I think this question could be very important for making decisions under uncertainty.</p>\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n<p>There will be a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/nr\">West LA Meetup - Eliezer and Nick Share a Cab...</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b5im22nFmdxy4sCWe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.2324358272315954e-06, "legacy": true, "legacyId": "22948", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Eliezer_and_Nick_Share_a_Cab___\">Discussion article for the meetup : <a href=\"/meetups/nr\">West LA Meetup - Eliezer and Nick Share a Cab...</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">19 June 2013 11:20:26AM (-0700)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p><strong>When:</strong> 7:00pm Wednesday, June 5th.</p>\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a rel=\"nofollow\" href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n<p><strong>Parking</strong> is free for 3 hours.</p>\n<p><strong>Discussion:</strong> Eliezer Yudkowsky and Nick Bostrom once shared a cab and found an extra $20. EY said that he thought it was his with probability 20%, while NB said that it was his with probability 15%. How should they split the extra $20 they found. I will present at least four different justifications for four different answers. Hopefully we will be able to reach a consensus on the best way to distribute the money. I will also explain why I think this question could be very important for making decisions under uncertainty.</p>\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n<p>There will be a whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___West_LA_Meetup___Eliezer_and_Nick_Share_a_Cab___1\">Discussion article for the meetup : <a href=\"/meetups/nr\">West LA Meetup - Eliezer and Nick Share a Cab...</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA Meetup - Eliezer and Nick Share a Cab...", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Eliezer_and_Nick_Share_a_Cab___", "level": 1}, {"title": "Discussion article for the meetup : West LA Meetup - Eliezer and Nick Share a Cab...", "anchor": "Discussion_article_for_the_meetup___West_LA_Meetup___Eliezer_and_Nick_Share_a_Cab___1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T19:00:00.000Z", "modifiedAt": null, "url": null, "title": "The Virtue of Silence", "slug": "the-virtue-of-silence", "viewCount": null, "lastCommentedAt": "2020-06-18T20:26:12.750Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": "Scott Alexander", "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2brqzQWfmNx5Agdrx/the-virtue-of-silence", "pageUrlRelative": "/posts/2brqzQWfmNx5Agdrx/the-virtue-of-silence", "linkUrl": "https://www.lesswrong.com/posts/2brqzQWfmNx5Agdrx/the-virtue-of-silence", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Virtue%20of%20Silence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Virtue%20of%20Silence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2brqzQWfmNx5Agdrx%2Fthe-virtue-of-silence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Virtue%20of%20Silence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2brqzQWfmNx5Agdrx%2Fthe-virtue-of-silence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2brqzQWfmNx5Agdrx%2Fthe-virtue-of-silence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1122, "htmlBody": "<p>Leah Libresco writes a couple of essays (<A HREF=\"http://www.patheos.com/blogs/unequallyyoked/2013/06/a-terrible-consequence-of-consequentialism.html\">1</A>, <A HREF=\"http://www.patheos.com/blogs/unequallyyoked/2013/06/a-dicey-way-out-of-dilemmas.html\">2</A>) on an ethical dilemma reported in the New York Times. In the course of a confidential medical history, a doctor hears her patient is suffering from stress-related complaints after having sent an innocent man to prison. The doctor wants to know whether it is ethical to report the matter to the police. The Times&#8217; columnist says yes &#8211; it would save the poor prisoner. Leah says no &#8211; violating medical confidentiality creates an expectation that medical confidentiality will be violated in the future, thus dooming patients who are too afraid to talk about drug use or gay sex or other potentially embarrassing but important medical risk factors.</p>\n<p>But both sides are ignoring the much bigger dilemma lurking one meta-level up: is it ethical to debate this dilemma in the <i>New York Times</i>?</p>\n<p>Let&#8217;s look more closely at that phrase &#8220;violating medical confidentiality creates an expectation that medical confidentiality will be violated in the future.&#8221; There&#8217;s a very abstruse angels-and-clockwork interpretation of &#8220;creates an expectation&#8221; where, by making the decision to violate confidentiality, you are altering the Platonic machinery of the Universe in a way that allows other beings who know your source code to determine that you will do this. But most people don&#8217;t have the <A HREF=\"http://lesswrong.com/lw/gu1/decision_theory_faq/\">decision theory</A> to understand this, and anyway most doctors do not publish their source code online.</p>\n<p>The way &#8220;creates an expectation&#8221; pans out in <i>our</i> universe is that somebody hears that a doctor violated medical confidentiality, and that person tells someone else, and that person tells someone else, until eventually someone who was going to tell their doctor about having gay sex with drugs remembers having heard the story and decides not to.</p>\n<p>How exactly would people hear about this doctor who revealed the innocence of the prisoner? Through the ensuing court case? Nah. Most people wouldn&#8217;t obsessively read the minutes of every single case at the local courthouse <A HREF=\"http://slatestarcodex.com/2013/06/11/lies-damned-lies-and-facebook-part-3-of-%e2%88%9e/\">unless of course it has something to do with gender</A>. Really, the only way that someone could hear about a doctor violating medical confidentiality is if she, like, somehow got a description of her intention to do so published in meticulous detail in the <i>New York Times</i>.</p>\n<p>Oh, <i>right</i>.</p>\n<p>The entire negative effect of the doctor breaking her promise is that it would make people doubt medical confidentiality in the future. But <i>whether or not the doctor ends up breaking her promise</i>, thousands of New York Times readers now know that doctors strongly consider breaking medical confidentiality, and that ethics columnists tell them it&#8217;s okay to do so. It seems like the whether the doctor actually keeps her promise or not in this particular case is of miniscule importance compared to the damage that the column has already done.</p>\n<p>Silence is a <i>hard</i> virtue. All the other virtues have the advantage that, when you practice them, people will praise you. Sometimes if your moral system is very different from your friends&#8217; people will attack you for your virtues, but <A HREF=\"http://slatestarcodex.com/2013/04/06/polyamory-is-boring/#comment-14095\">getting attacked by sufficiently horrible people</A> can sometimes be just as gratifying as praise. But if you stay silent, there&#8217;s no praise <i>and</i> no attacks. By definition, no one even knows you made a courageous moral choice.</p>\n<p>(Eliezer mentioned in the comments of my <A HREF=\"http://slatestarcodex.com/2013/05/18/against-bravery-debates/#comment-11914\">Against Bravery Debates</A> that he&#8217;s spent a couple decades pushing ideas almost everyone else thinks are crackpot, and he&#8217;s never appealed to bravery at all. He is one hundred percent correct and I have one hundred percent never noticed despite reading almost everything he&#8217;s written for several years. That&#8217;s the Virtue of Silence for you.)</p>\n<p>(I had like five much better examples here, all of which would be very clever, and each time I had to catch myself and say &#8220;Wait a second, by bringing that up I&#8217;m violating the virtue I&#8217;m supposed to be pushing here, aren&#8217;t I?&#8221;)</p>\n<p>One example of silence I deeply appreciate is <i>people who don&#8217;t talk about the latest viral issue</i>. I&#8217;m trying to think of an example that&#8217;s not too destructive to bring up&#8230;hmmmm&#8230;go for something old&#8230;<A HREF=\"http://en.wikipedia.org/wiki/Elevatorgate#Elevator_incident\">Elevatorgate</A>! Nearly everyone who talked about Elevatorgate mentioned that it was outrageous that the blogosphere was making such a big deal about it, missing the similarity to the old adage that &#8220;you aren&#8217;t stuck in traffic, you <i>are</i> traffic.&#8221; Somewhere there was someone who wanted to write about Elevatorgate, thought about it, and <i>decided not to</i>. That person deserves the sincere thanks of a grateful Internet.</p>\n<p>So having made the case for the other side of the confidentiality-newspaper meta-dilemma, am I <i>actually</i> pushing the claim that it is a moral law not to publicize information that could have bad consequences?</p>\n<p>But I notice that this sort of thing almost always ends up making people angry and having a perverse effect where demands not to draw Mohammed turn into Everyone Draw Mohammed Day (see: <A HREF=\"http://en.wikipedia.org/wiki/Streisand_Effect\">Streisand Effect</A>). It also sometimes snowballs to the point where not only can you not talk about X, but you can&#8217;t talk about the demand not to talk about X because that would be referring to X obliquely, and you can&#8217;t talk about the demand not to talk about the demand to talk about X, until eventually you climb up so many meta-levels that you collapse from hypoxia and have to be rescued by Sherpas. Then you get a &#8220;callout culture&#8221; where people try to gain easy Virtue Points by telling people discussing issues that they Should Not Be Discussing Them and other people try to gain easy Virtue Points by being the Brave Defender of Freedom of Speech.</p>\n<p>And maybe that&#8217;s useful if it&#8217;s something like gender where everyone wants to talk about it all the time anyway, but we don&#8217;t really need to do that to medical confidentiality, do we?</p>\n<p>Maybe this is one of those rare cases where the word &#8220;supererogatory&#8221; might be useful. Yelling at people who talk about violations of medical confidentiality would just lead to &#8220;ARE OUR DISCUSSIONS OF MEDICAL CONFIDENTIALITY BEING SILENCED??!?&#8221; on the front page of the <i>New York Times</i>. And fretting over talking about it with your friends, or publishing a blog article about it (cough) is probably on the moral level of those Jains who walk everywhere with a broom in front of them so that they don&#8217;t accidentally squash any bugs. But if someone is really really concerned about it and wants to be a great person, then yeah, I think writing to the <i>New York Times</i> about it requires a bit of thought.</p>\n<p>And since I <i>am</i> publishing a blog article about it (VIRTUE OF SILENCE IS REALLY HARD!) let me restore some Virtue Points by confirming that I will <i>not</i> betray private patient information of this sort if such a dilemma comes up except when legally required. Trust me, I&#8217;m a doctor.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"8uNFGxejo5hykCEez": 3, "gHCNhqxuJq2bZ2akb": 4}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2brqzQWfmNx5Agdrx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 66, "baseScore": 74, "extendedScore": null, "score": 0.000174, "legacy": true, "legacyId": null, "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "XsMTxdQ6fprAQMoKi", "canonicalCollectionSlug": "codex", "canonicalBookId": "jF58hKP9ZLzgy22Jr", "canonicalNextPostSlug": "proving-too-much", "canonicalPrevPostSlug": "all-debates-are-bravery-debates", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 74, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["zEWJBFFMvQ835nq6h"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T20:20:21.542Z", "modifiedAt": null, "url": null, "title": "[LINK] The Selected Papers Network", "slug": "link-the-selected-papers-network", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:26.179Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WrRCiHfRABtHddvgz/link-the-selected-papers-network", "pageUrlRelative": "/posts/WrRCiHfRABtHddvgz/link-the-selected-papers-network", "linkUrl": "https://www.lesswrong.com/posts/WrRCiHfRABtHddvgz/link-the-selected-papers-network", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20The%20Selected%20Papers%20Network&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20The%20Selected%20Papers%20Network%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWrRCiHfRABtHddvgz%2Flink-the-selected-papers-network%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20The%20Selected%20Papers%20Network%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWrRCiHfRABtHddvgz%2Flink-the-selected-papers-network", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWrRCiHfRABtHddvgz%2Flink-the-selected-papers-network", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p>John Baez has been writing, <a href=\"http://johncarlosbaez.wordpress.com/2013/06/07/the-selected-papers-network-part-1/\">here</a> and <a href=\"https://johncarlosbaez.wordpress.com/2013/06/14/the-selected-papers-network-part-2/\">here</a>, about problems with the academic journal system and a tool that might be a step towards fixing them:</p>\n<blockquote>\n<p><a href=\"http://johncarlosbaez.wordpress.com/2013/06/07/the-selected-papers-network-part-1/\">Last time</a> Christopher Lee and I described some problems with scholarly publishing. The big problems are expensive journals and ineffective peer review. But we argued that solving these problems require new methods of</p>\n<p>&bull;&nbsp;<strong>selection</strong>&mdash;assessing papers</p>\n<p>and</p>\n<p>&bull;&nbsp;<strong>endorsement</strong>&mdash;making the quality of papers known, thus giving scholars the&nbsp;<em>prestige</em>&nbsp;they need to get jobs and promotions.</p>\n<p>The&nbsp;<strong>Selected Papers Network</strong>&nbsp;is an infrastructure for doing both these jobs in an open, distributed way. It&rsquo;s not yet the solution to the big visible problems&mdash;just&nbsp;<em>a framework upon which we can build those solutions</em>. It&rsquo;s just getting started, and it can use your help.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WrRCiHfRABtHddvgz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 1.2324970944612311e-06, "legacy": true, "legacyId": "22949", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-14T21:35:42.293Z", "modifiedAt": null, "url": null, "title": "Meetup : Brussels meetup with HEALES", "slug": "meetup-brussels-meetup-with-heales", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mkosQ8y484KpfqXGe/meetup-brussels-meetup-with-heales", "pageUrlRelative": "/posts/mkosQ8y484KpfqXGe/meetup-brussels-meetup-with-heales", "linkUrl": "https://www.lesswrong.com/posts/mkosQ8y484KpfqXGe/meetup-brussels-meetup-with-heales", "postedAtFormatted": "Friday, June 14th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Brussels%20meetup%20with%20HEALES&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Brussels%20meetup%20with%20HEALES%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkosQ8y484KpfqXGe%2Fmeetup-brussels-meetup-with-heales%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Brussels%20meetup%20with%20HEALES%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkosQ8y484KpfqXGe%2Fmeetup-brussels-meetup-with-heales", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmkosQ8y484KpfqXGe%2Fmeetup-brussels-meetup-with-heales", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 416, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ns'>Brussels meetup with HEALES</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 July 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This month I'm happy to announce we have a very special meetup! The kind people from <a href=\"https://heales.org/ENGLISH/\" rel=\"nofollow\">Heales</a> (The Healthy Life Extension Society) are giving a presentation and explaining what they are all about. If you have any interest in life extension or just want an intelligent discussion consider dropping by. For this meetup the room upstairs is booked for us so ask at the bar or just come upstairs and say hi.\nIf you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform?pli=1\" rel=\"nofollow\">this</a> one minute form, to share your contact information.</p>\n\n<p>About this meetup in particular:\nThe first part of the discussion will give a short description of why we age and the main fields of possible progression:</p>\n\n<ul>\n<li><p>Drugs</p></li>\n<li><p>Stem cells and creation of organs</p></li>\n<li><p>Gene therapy</p></li>\n<li><p>Nanotechnologies</p></li>\n<li><p>Longer term prospective</p></li>\n</ul>\n\n<p>The second part of the discussion will be about the consequences of life extension for the citizens and for the society as a whole:</p>\n\n<p>The following aspects concerning life extension will be approached:</p>\n\n<ul>\n<li>Economic consequences: lower health costs and questions related to pensions</li>\n<li>Environmental consequences: the question of overpopulation and the pattern of consumption of people advancing in age</li>\n<li><p>Psychological fears related to a longer life: boredom, hubris (playing God).</p></li>\n<li><p>Harmonious society: ethical questions, lower level of crime and a higher level of resilience</p></li>\n</ul>\n\n<p>The last part of the discussion will be about a political and ethical question: Should the State subsidize life extension?</p>\n\n<hr />\n\n<p>Didier Coeurnelle is co-chair of Heales (Healthy Life Extension Society), which publishes a monthly newsletter of information: \u201cLa mort de la mort\u201d (The Death of the Death) and organizes international conferences. He is vice-president of the French association Technoprog, which aims to \u201cspread the themes and questions related to technologies that could extend and enhance the lives of individuals and of humankind\u201d. He is also an active member of the environmental movement.</p>\n\n<p>In January 2013, he published a book (in French): Et si on arr\u00eatait de vieillir ! : R\u00e9alit\u00e9, enjeux et perspectives d'une vie en bonne sant\u00e9 beaucoup plus longue (<a href=\"http://www.amazon.fr/Et-arr%C3%AAtait-vieillir-perspectives-beaucoup/dp/2916571809/ref=sr_1_1?ie=UTF8&amp;qid=1360446101&amp;sr=8-1\" rel=\"nofollow\">Amazon page</a> - <a href=\"https://sites.google.com/site/vieillironsnousdemain/\" rel=\"nofollow\">Dedicated website</a>).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ns'>Brussels meetup with HEALES</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mkosQ8y484KpfqXGe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.2325543880202176e-06, "legacy": true, "legacyId": "22950", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup_with_HEALES\">Discussion article for the meetup : <a href=\"/meetups/ns\">Brussels meetup with HEALES</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 July 2013 01:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Rue des Alexiens 55 1000 Bruxelles</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This month I'm happy to announce we have a very special meetup! The kind people from <a href=\"https://heales.org/ENGLISH/\" rel=\"nofollow\">Heales</a> (The Healthy Life Extension Society) are giving a presentation and explaining what they are all about. If you have any interest in life extension or just want an intelligent discussion consider dropping by. For this meetup the room upstairs is booked for us so ask at the bar or just come upstairs and say hi.\nIf you are coming for the first time, please consider filling out <a href=\"https://docs.google.com/forms/d/1qSvI1NWkFSsfIJhUMORb_Wd8fdJTVPhdw49grDQwRTI/viewform?pli=1\" rel=\"nofollow\">this</a> one minute form, to share your contact information.</p>\n\n<p>About this meetup in particular:\nThe first part of the discussion will give a short description of why we age and the main fields of possible progression:</p>\n\n<ul>\n<li><p>Drugs</p></li>\n<li><p>Stem cells and creation of organs</p></li>\n<li><p>Gene therapy</p></li>\n<li><p>Nanotechnologies</p></li>\n<li><p>Longer term prospective</p></li>\n</ul>\n\n<p>The second part of the discussion will be about the consequences of life extension for the citizens and for the society as a whole:</p>\n\n<p>The following aspects concerning life extension will be approached:</p>\n\n<ul>\n<li>Economic consequences: lower health costs and questions related to pensions</li>\n<li>Environmental consequences: the question of overpopulation and the pattern of consumption of people advancing in age</li>\n<li><p>Psychological fears related to a longer life: boredom, hubris (playing God).</p></li>\n<li><p>Harmonious society: ethical questions, lower level of crime and a higher level of resilience</p></li>\n</ul>\n\n<p>The last part of the discussion will be about a political and ethical question: Should the State subsidize life extension?</p>\n\n<hr>\n\n<p>Didier Coeurnelle is co-chair of Heales (Healthy Life Extension Society), which publishes a monthly newsletter of information: \u201cLa mort de la mort\u201d (The Death of the Death) and organizes international conferences. He is vice-president of the French association Technoprog, which aims to \u201cspread the themes and questions related to technologies that could extend and enhance the lives of individuals and of humankind\u201d. He is also an active member of the environmental movement.</p>\n\n<p>In January 2013, he published a book (in French): Et si on arr\u00eatait de vieillir ! : R\u00e9alit\u00e9, enjeux et perspectives d'une vie en bonne sant\u00e9 beaucoup plus longue (<a href=\"http://www.amazon.fr/Et-arr%C3%AAtait-vieillir-perspectives-beaucoup/dp/2916571809/ref=sr_1_1?ie=UTF8&amp;qid=1360446101&amp;sr=8-1\" rel=\"nofollow\">Amazon page</a> - <a href=\"https://sites.google.com/site/vieillironsnousdemain/\" rel=\"nofollow\">Dedicated website</a>).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Brussels_meetup_with_HEALES1\">Discussion article for the meetup : <a href=\"/meetups/ns\">Brussels meetup with HEALES</a></h2>", "sections": [{"title": "Discussion article for the meetup : Brussels meetup with HEALES", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup_with_HEALES", "level": 1}, {"title": "Discussion article for the meetup : Brussels meetup with HEALES", "anchor": "Discussion_article_for_the_meetup___Brussels_meetup_with_HEALES1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-15T04:43:54.594Z", "modifiedAt": null, "url": null, "title": "Meetup : CFAR visits Salt Lake City", "slug": "meetup-cfar-visits-salt-lake-city", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BrksoYDiq784htgrY/meetup-cfar-visits-salt-lake-city", "pageUrlRelative": "/posts/BrksoYDiq784htgrY/meetup-cfar-visits-salt-lake-city", "linkUrl": "https://www.lesswrong.com/posts/BrksoYDiq784htgrY/meetup-cfar-visits-salt-lake-city", "postedAtFormatted": "Saturday, June 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20CFAR%20visits%20Salt%20Lake%20City&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20CFAR%20visits%20Salt%20Lake%20City%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBrksoYDiq784htgrY%2Fmeetup-cfar-visits-salt-lake-city%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20CFAR%20visits%20Salt%20Lake%20City%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBrksoYDiq784htgrY%2Fmeetup-cfar-visits-salt-lake-city", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBrksoYDiq784htgrY%2Fmeetup-cfar-visits-salt-lake-city", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 72, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nt'>CFAR visits Salt Lake City</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">16 June 2013 09:43:55PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Salt Lake City</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Three of us from CFAR are hosting a meetup from 1pm to 3pm at</p>\n\n<p>656 N Columbus Street,  Salt Lake City, Utah, 84103.</p>\n\n<p>Fun, games, and rationality conversations!  You might also bring your dad; dads get a free cupcake in honor of father's day.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nt'>CFAR visits Salt Lake City</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BrksoYDiq784htgrY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 9, "extendedScore": null, "score": 1.2328800878573428e-06, "legacy": true, "legacyId": "22954", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___CFAR_visits_Salt_Lake_City\">Discussion article for the meetup : <a href=\"/meetups/nt\">CFAR visits Salt Lake City</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">16 June 2013 09:43:55PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Salt Lake City</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Three of us from CFAR are hosting a meetup from 1pm to 3pm at</p>\n\n<p>656 N Columbus Street,  Salt Lake City, Utah, 84103.</p>\n\n<p>Fun, games, and rationality conversations!  You might also bring your dad; dads get a free cupcake in honor of father's day.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___CFAR_visits_Salt_Lake_City1\">Discussion article for the meetup : <a href=\"/meetups/nt\">CFAR visits Salt Lake City</a></h2>", "sections": [{"title": "Discussion article for the meetup : CFAR visits Salt Lake City", "anchor": "Discussion_article_for_the_meetup___CFAR_visits_Salt_Lake_City", "level": 1}, {"title": "Discussion article for the meetup : CFAR visits Salt Lake City", "anchor": "Discussion_article_for_the_meetup___CFAR_visits_Salt_Lake_City1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-15T12:56:19.245Z", "modifiedAt": null, "url": null, "title": "Rationality witticisms suitable for t-shirts or bumper stickers", "slug": "rationality-witticisms-suitable-for-t-shirts-or-bumper", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:01.444Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "evand", "createdAt": "2012-05-14T16:45:50.150Z", "isAdmin": false, "displayName": "evand"}, "userId": "QSBopDfW3DLzeMG7L", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oJQoAm6wQcSXFv8Dd/rationality-witticisms-suitable-for-t-shirts-or-bumper", "pageUrlRelative": "/posts/oJQoAm6wQcSXFv8Dd/rationality-witticisms-suitable-for-t-shirts-or-bumper", "linkUrl": "https://www.lesswrong.com/posts/oJQoAm6wQcSXFv8Dd/rationality-witticisms-suitable-for-t-shirts-or-bumper", "postedAtFormatted": "Saturday, June 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20witticisms%20suitable%20for%20t-shirts%20or%20bumper%20stickers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20witticisms%20suitable%20for%20t-shirts%20or%20bumper%20stickers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoJQoAm6wQcSXFv8Dd%2Frationality-witticisms-suitable-for-t-shirts-or-bumper%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20witticisms%20suitable%20for%20t-shirts%20or%20bumper%20stickers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoJQoAm6wQcSXFv8Dd%2Frationality-witticisms-suitable-for-t-shirts-or-bumper", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoJQoAm6wQcSXFv8Dd%2Frationality-witticisms-suitable-for-t-shirts-or-bumper", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p>What are your best short witticisms, suitable for use on a t-shirt, bumper sticker, or similar location? Ideally something that might make someone reading it think, or get curious enough to ask about it. Simple in-group identification is fine too, though.</p>\n<p>For context, <a href=\"/user/therufs\">therufs</a> is spending today at the <a title=\"NC Maker Faire\" href=\"http://makerfairenc.com/\">NC Maker Faire</a> making t-shirts, and asked me for suggestions this morning. As I was still mostly asleep, I wasn't very helpful.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oJQoAm6wQcSXFv8Dd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 5, "extendedScore": null, "score": 1.2332548117382716e-06, "legacy": true, "legacyId": "22957", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 85, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-15T16:56:19.582Z", "modifiedAt": null, "url": null, "title": "[META] LW bug: Private drafts are publicly viewable", "slug": "meta-lw-bug-private-drafts-are-publicly-viewable", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "VincentYu", "createdAt": "2010-08-18T15:01:21.245Z", "isAdmin": false, "displayName": "VincentYu"}, "userId": "ybEcbPJW9Z8CdGSkB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dDSoF6iL97QGaAAQY/meta-lw-bug-private-drafts-are-publicly-viewable", "pageUrlRelative": "/posts/dDSoF6iL97QGaAAQY/meta-lw-bug-private-drafts-are-publicly-viewable", "linkUrl": "https://www.lesswrong.com/posts/dDSoF6iL97QGaAAQY/meta-lw-bug-private-drafts-are-publicly-viewable", "postedAtFormatted": "Saturday, June 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BMETA%5D%20LW%20bug%3A%20Private%20drafts%20are%20publicly%20viewable&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BMETA%5D%20LW%20bug%3A%20Private%20drafts%20are%20publicly%20viewable%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdDSoF6iL97QGaAAQY%2Fmeta-lw-bug-private-drafts-are-publicly-viewable%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BMETA%5D%20LW%20bug%3A%20Private%20drafts%20are%20publicly%20viewable%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdDSoF6iL97QGaAAQY%2Fmeta-lw-bug-private-drafts-are-publicly-viewable", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdDSoF6iL97QGaAAQY%2Fmeta-lw-bug-private-drafts-are-publicly-viewable", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 49, "htmlBody": "<p>Private drafts on LW are currently publicly viewable on user pages (and RSS feeds). To verify this, you can view a draft that I have saved on <a href=\"/user/VincentYu/overview/\">my user page</a>. This seems to be a bug caused by recent changes (also see <a href=\"/r/discussion/lw/hlo/open_thread_june_215_2013/963x\">[1]</a> and <a href=\"/r/discussion/lw/hlo/open_thread_june_215_2013/961l\">[2]</a>) to the LW codebase.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dDSoF6iL97QGaAAQY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "22960", "legacySpam": true, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-15T19:52:36.207Z", "modifiedAt": null, "url": null, "title": "Elites and AI: Stated Opinions", "slug": "elites-and-ai-stated-opinions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:57.435Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ToNNGwqNS5kecZaNQ/elites-and-ai-stated-opinions", "pageUrlRelative": "/posts/ToNNGwqNS5kecZaNQ/elites-and-ai-stated-opinions", "linkUrl": "https://www.lesswrong.com/posts/ToNNGwqNS5kecZaNQ/elites-and-ai-stated-opinions", "postedAtFormatted": "Saturday, June 15th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Elites%20and%20AI%3A%20Stated%20Opinions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AElites%20and%20AI%3A%20Stated%20Opinions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FToNNGwqNS5kecZaNQ%2Felites-and-ai-stated-opinions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Elites%20and%20AI%3A%20Stated%20Opinions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FToNNGwqNS5kecZaNQ%2Felites-and-ai-stated-opinions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FToNNGwqNS5kecZaNQ%2Felites-and-ai-stated-opinions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1972, "htmlBody": "<p>Previously, I asked \"<a href=\"/lw/hlc/will_the_worlds_elites_navigate_the_creation_of/\">Will the world's elites navigate the creation of AI just fine?</a>\" My current answer is \"probably not,\" but I think it's a question worth additional investigation.</p>\n<p>As a preliminary step, and with the help of MIRI interns Jeremy Miller and Oriane Gaillard, I've collected a few <strong>stated opinions</strong> on the issue. This survey of stated opinions is not <em>representative</em> of any particular group, and is not meant to provide strong evidence about what is <em>true</em> on the matter. It's merely a collection of quotes we happened to find on the subject. Hopefully others can point us to other stated opinions &mdash; or state their own opinions.</p>\n<p><a id=\"more\"></a></p>\n<p><a href=\"http://intelligence.org/\">MIRI</a> researcher <strong><a href=\"http://yudkowsky.net/\">Eliezer Yudkowsky</a></strong> is famously pessimistic on this issue. For example, in a <a href=\"/lw/15x/friendlier_ai_through_politics/11q8\">2009 comment</a>, he replied to the question \"What kind of competitive or political system would make fragmented squabbling AIs safer than an attempt to get the monolithic approach right?\" by saying \"the answer is, 'None.' It's like asking how you should move your legs to walk faster than a jet plane\" &mdash; again, implying extreme skepticism that political elites will manage AI properly.<sup>1</sup></p>\n<p>Cryptographer <strong><a href=\"http://www.weidai.com/\">Wei Dai</a></strong> is also <a href=\"/lw/hlc/will_the_worlds_elites_navigate_the_creation_of/9ag2\">quite pessimistic</a>:</p>\n<blockquote>\n<p>...even in a relatively optimistic scenario, one with steady progress in AI capability along with apparent progress in AI control/safety (and nobody deliberately builds a UFAI for the sake of \"maximizing complexity of the universe\" or what have you), it's probably only a matter of time until some AI crosses a threshold of intelligence and manages to \"throw off its shackles\". This may be accompanied by a last-minute scramble by mainstream elites to slow down AI progress and research methods of scalable AI control, which (if it does happen) will likely be too late to make a difference.</p>\n</blockquote>\n<p>Stanford philosopher <strong><a href=\"http://www.stanford.edu/~ktaylor/\">Ken Taylor</a></strong> has also expressed pessimism, in an episode of <em>Philosophy Talk</em> called \"<a href=\"https://dl.dropboxusercontent.com/u/163098/_temp/Turbo-charging%20the%20Mind.mp3\">Turbo-charging the mind</a>\":</p>\n<blockquote>\n<p>Think about nuclear technology. It evolved in a time of war... The probability that nuclear technology was going to arise at a time when we use it well rather than [for] destruction was low... Same thing with... superhuman artificial intelligence. It's going to emerge... in a context in which we make a mess out of everything. So the probability that we make a mess out of this is really high.</p>\n</blockquote>\n<p>Here, Taylor seems to express the view that humans are not yet morally and rationally advanced enough to be trusted with powerful technologies. This general view has been expressed before by many others, including Albert Einstein, who <a href=\"http://en.wikiquote.org/wiki/Albert_Einstein\">wrote</a> that \"Our entire much-praised technological progress... could be compared to an axe in the hand of a pathological criminal.\"</p>\n<p>In response to Taylor's comment, MIRI researcher <strong>Anna Salamon</strong> (now Executive Director of <a href=\"http://rationality.org/about/\">CFAR</a>) expressed a more optimistic view:</p>\n<blockquote>\n<p>I... disagree. A lot of my colleagues would [agree with you] that 40% chance of human survival is absurdly optimistic... But, probably we're not close to AI. Probably by the time AI hits we will have had more thinking going into it... [Also,] if the Germans had successfully gotten the bomb and taken over the world, there would have been somebody who profited. If AI runs away and kills everyone, there's nobody who profits. There's a lot of incentive to try and solve the problem together...</p>\n</blockquote>\n<p>Economist <strong><a href=\"http://www.smith.edu/economics/faculty_miller.php\">James Miller</a></strong> is another voice of pessimism. In <em><a href=\"http://www.amazon.com/Singularity-Rising-Surviving-Thriving-Dangerous/dp/1936661659/\">Singularity Rising</a></em>, chapter 5, he worries about game-theoretic mechanisms incentivizing speed of development over safety of development:</p>\n<blockquote>\n<p>Successfully creating [superhuman AI] would give a country control of everything, making [superhuman AI] far more militarily useful than mere atomic weapons. The first nation to create an obedient [superhuman AI] would also instantly acquire the capacity to terminate its rivals&rsquo; AI development projects. Knowing the stakes, rival nations might go full throttle to win [a race to superhuman AI], even if they understood that haste could cause them to create a world-destroying [superhuman AI]. These rivals might realize the danger and desperately wish to come to an agreement to reduce the peril, but they might find that the logic of the widely used game theory paradox of the Prisoners&rsquo; Dilemma thwarts all cooperation efforts... Imagine that both the US and Chinese militaries want to create [superhuman AI]. To keep things simple, let&rsquo;s assume that each military has the binary choice to proceed either slowly or quickly. Going slowly increases the time it will take to build [superhuman AI] but reduces the likelihood that it will become unfriendly and destroy humanity. The United States and China might come to an agreement and decide that they will both go slowly... [But] if the United States knows that China will go slowly, it might wish to proceed quickly and accept the additional risk of destroying the world in return for having a much higher chance of being the first country to create [superhuman AI]. (During the Cold War, the United States and the Soviet Union risked destroying the world for less.) The United States might also think that if the Chinese proceed quickly, then they should go quickly, too, rather than let the Chinese be the likely winners of the... race.</p>\n</blockquote>\n<p>In chapter 6, Miller expresses similar worries about corporate incentives and AI:</p>\n<blockquote>\n<p>Paradoxically and tragically, the fact that [superhuman AI] would destroy mankind increases the chance of the private sector developing it. To see why, pretend that you&rsquo;re at the racetrack deciding whether to bet on the horse Recursive Darkness. The horse offers a good payoff in the event of victory, but her odds of winning seem too small to justify a bet&mdash;until, that is, you read the fine print on the racing form: \"If Recursive Darkness loses, the world ends.\" Now you bet everything you have on her because you realize that the bet will either pay off or become irrelevant.</p>\n</blockquote>\n<p>Miller expanded on some of these points in his chapter in <em><a href=\"http://www.amazon.com/Singularity-Hypotheses-Scientific-Philosophical-Assessment/dp/3642325599/\">Singularity Hypotheses</a></em>.</p>\n<p>In a short reply to Miller, GMU economist <strong><a href=\"http://hanson.gmu.edu/\">Robin Hanson</a></strong> wrote that</p>\n<blockquote>\n<p>[Miller's analysis is] only as useful as the assumptions on which it is based. Miller's chosen assumptions seem to me quite extreme, and quite unlikely.</p>\n</blockquote>\n<p>Unfortunately, Hanson does not explain his reasons for rejecting Miller's analysis.</p>\n<p>Sun Microsystems co-founder <strong><a href=\"http://en.wikipedia.org/wiki/Bill_Joy\">Bill Joy</a></strong> is famous for the techno-pessimism of his <em>Wired</em> essay \"<a href=\"http://www.wired.com/wired/archive/8.04/joy.html\">Why the Future Doesn't Need Us</a>,\" but that article's predictions about elites' likely handling of AI are actually somewhat mixed:</p>\n<blockquote>\n<p>we all wish our course could be determined by our collective values, ethics, and morals. If we had gained more collective wisdom over the past few thousand years, then a dialogue to this end would be more practical, and the incredible powers we are about to unleash would not be nearly so troubling.</p>\n<p>One would think we might be driven to such a dialogue by our instinct for self-preservation. Individuals clearly have this desire, yet as a species our behavior seems to be not in our favor. In dealing with the nuclear threat, we often spoke dishonestly to ourselves and to each other, thereby greatly increasing the risks. Whether this was politically motivated, or because we chose not to think ahead, or because when faced with such grave threats we acted irrationally out of fear, I do not know, but it does not bode well.</p>\n<p>The new Pandora's boxes of genetics, nanotechnology, and robotics are almost open, yet we seem hardly to have noticed... Churchill remarked, in a famous left-handed compliment, that the American people and their leaders 'invariably do the right thing, after they have examined every other alternative.' In this case, however, we must act more presciently, as to do the right thing only at last may be to lose the chance to do it at all...</p>\n<p>...And yet I believe we do have a strong and solid basis for hope. Our attempts to deal with weapons of mass destruction in the last century provide a shining example of relinquishment for us to consider: the unilateral US abandonment, without preconditions, of the development of biological weapons. This relinquishment stemmed from the realization that while it would take an enormous effort to create these terrible weapons, they could from then on easily be duplicated and fall into the hands of rogue nations or terrorist groups.</p>\n</blockquote>\n<p>Former GiveWell researcher <strong><a href=\"http://www.mathisbeauty.org/aboutme.html\">Jonah Sinick</a></strong> has <a href=\"/lw/hlc/will_the_worlds_elites_navigate_the_creation_of/92tx\">expressed optimism</a> on the issue:</p>\n<blockquote>\n<p>I personally am optimistic about the world's elites navigating AI risk as well as possible subject to inherent human limitations that I would expect everybody to have, and the inherent risk. Some points:</p>\n<ol>\n<li>\n<p>I've been surprised by people's ability to avert bad outcomes. Only two nuclear weapons have been used since nuclear weapons were developed, despite the fact that there are 10,000+ nuclear weapons around the world. Political leaders are assassinated very infrequently relative to how often one might expect a priori.</p>\n</li>\n<li>\n<p>AI risk is a Global Catastrophic Risk in addition to being an x-risk. Therefore, even people who don't care about the far future will be motivated to prevent it.</p>\n</li>\n<li>\n<p>The people with the most power tend to be the most rational people, and the effect size can be expected to increase over time... The most rational people are the people who are most likely to be aware of and to work to avert AI risk...</p>\n</li>\n<li>\n<p>Availability of information is increasing over time. At the time of the Dartmouth conference, information about the potential dangers of AI was not very salient, now it's more salient, and in the future it will be still more salient...</p>\n</li>\n<li>\n<p>In the Manhattan project, the \"will bombs ignite the atmosphere?\" question was analyzed and dismissed without much (to our knowledge) double-checking. The amount of risk checking per hour of human capital available can be expected to increase over time. In general, people enjoy tackling important problems, and risk checking is more important than most of the things that people would otherwise be doing.</p>\n</li>\n</ol></blockquote>\n<p><strong><a href=\"http://rationalaltruist.com/\">Paul Christiano</a></strong> is another voice of <a href=\"http://ordinaryideas.wordpress.com/2013/01/22/some-rambling-ai-prognostication/\">optimism</a> about elites' handling of AI. Here are some snippets from his \"mainline\" scenario for AI development:</p>\n<blockquote>\n<p>It becomes fairly clear some time in advance, perhaps years, that broadly human-competitive AGI will be available soon. As this becomes obvious, competent researchers shift into more directly relevant work, and governments and researchers become more concerned with social impacts and safety issues...</p>\n<p>Call the point where the share of human workers is negligible point Y. After Y humans are very unlikely to maintain control over global economic dynamics---the effective population is overwhelmingly dominated by machine intelligences... This picture becomes clear to serious onlookers well in advance of the development of human-level AGI... [hence] there is much intellectual activity aimed at understanding these dynamics and strategies for handling them, carried out both in public and within governments.</p>\n<p>Why should we expect the control problem to be solved? ...at each point when we face a control problem more difficult than any we have faced so far and with higher consequences for failure, we expect to have faced slightly easier problems with only slightly lower consequences for failure in the past.</p>\n<p>As long as solutions to the control problem are not quite satisfactory, the incentives to resolve control problems are comparable to the incentives to increase the capabilities of systems. If solutions are particularly unsatisfactory, then incentives to resolve control problems are very strong. So natural economic incentives build a control system (in the traditional sense from robotics) which keeps solutions to the control problem from being too unsatisfactory.</p>\n</blockquote>\n<p>Christiano is no Polyanna, however. In the same document, he outlines \"what could go wrong,\" and what we might do about it.</p>\n<p>&nbsp;</p>\n<p><small>Notes</small></p>\n<p><sup>1</sup> <small>I originally included another quote from Eliezer, but then I noticed that other readers on Less Wrong had elsewhere interpreted that same quote differently than I had, so I removed it from this post.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ToNNGwqNS5kecZaNQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 14, "extendedScore": null, "score": 1.2335717597041212e-06, "legacy": true, "legacyId": "22961", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 24, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Ba8LNjWKDF5nrn9Q6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T01:34:30.703Z", "modifiedAt": null, "url": null, "title": "[LINK] The Point of Life is the Explosion of Experience Into Ideas", "slug": "link-the-point-of-life-is-the-explosion-of-experience-into", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:08.926Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "aCzpyiBqsciCySdXe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sFfBTpYxDDC9Hbvmj/link-the-point-of-life-is-the-explosion-of-experience-into", "pageUrlRelative": "/posts/sFfBTpYxDDC9Hbvmj/link-the-point-of-life-is-the-explosion-of-experience-into", "linkUrl": "https://www.lesswrong.com/posts/sFfBTpYxDDC9Hbvmj/link-the-point-of-life-is-the-explosion-of-experience-into", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20The%20Point%20of%20Life%20is%20the%20Explosion%20of%20Experience%20Into%20Ideas&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20The%20Point%20of%20Life%20is%20the%20Explosion%20of%20Experience%20Into%20Ideas%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsFfBTpYxDDC9Hbvmj%2Flink-the-point-of-life-is-the-explosion-of-experience-into%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20The%20Point%20of%20Life%20is%20the%20Explosion%20of%20Experience%20Into%20Ideas%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsFfBTpYxDDC9Hbvmj%2Flink-the-point-of-life-is-the-explosion-of-experience-into", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsFfBTpYxDDC9Hbvmj%2Flink-the-point-of-life-is-the-explosion-of-experience-into", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 31, "htmlBody": "<p><a href=\"http://www.siftingtothetruth.com/2013/04/22/the-point-of-life-is-the-explosion-of-experience-into-ideas/\">The Point of Life is the Explosion of Experience Into Ideas</a>&nbsp;is a philosophical article I wrote detailing why and how self-expression is the fundamental human freedom and the justification for suffering.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sFfBTpYxDDC9Hbvmj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -14, "extendedScore": null, "score": 1.233832188521887e-06, "legacy": true, "legacyId": "22964", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T02:10:02.674Z", "modifiedAt": null, "url": null, "title": "How to Write Deep Characters", "slug": "how-to-write-deep-characters", "viewCount": null, "lastCommentedAt": "2014-02-10T04:29:20.288Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kBADRoen6u7BbJmD2/how-to-write-deep-characters", "pageUrlRelative": "/posts/kBADRoen6u7BbJmD2/how-to-write-deep-characters", "linkUrl": "https://www.lesswrong.com/posts/kBADRoen6u7BbJmD2/how-to-write-deep-characters", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Write%20Deep%20Characters&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Write%20Deep%20Characters%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkBADRoen6u7BbJmD2%2Fhow-to-write-deep-characters%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Write%20Deep%20Characters%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkBADRoen6u7BbJmD2%2Fhow-to-write-deep-characters", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkBADRoen6u7BbJmD2%2Fhow-to-write-deep-characters", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 755, "htmlBody": "<p>Triggered by: &nbsp;<a href=\"http://www.overcomingbias.com/2013/06/future-story-status.html\">Future Story Status</a>&nbsp;</p>\n<p>A helpful key to understanding the art and technique of character in storytelling, is to consider the folk-psychological notion from Internal Family Systems of people being composed of different 'parts' embodying different drives or goals. A shallow character is a character with only one 'part'.</p>\n<p>A good rule of thumb is that to create a 3D character, that person must contain at least two different 2D characters who come into conflict. Contrary to the first thought that crosses your mind, three-dimensional good people are constructed by combining at least two different good people with two different ideals, not by combining a good person and a bad person. Deep sympathetic characters have two sympathetic parts in conflict, not a sympathetic part in conflict with an unsympathetic part. Deep smart characters are created by combining at least two different people who are geniuses.</p>\n<p>E.g. HPMOR!Hermione contains both a sensible young girl who tries to keep herself and her friends out of trouble, and a starry-eyed heroine, neither of whom are stupid. &nbsp;(Actually, since HPMOR!Hermione is also the one character who I created as close to her canon self as I could manage - she didn't *need*&nbsp;upgrading - I should credit this one to J. K. Rowling.) &nbsp;(Admittedly, I didn't actually follow that rule deliberately to construct Methods, I figured it out afterward when everyone was praising the characterization and I was like, \"Wait, people are calling me a character author now? &nbsp;What the hell did I just do right?\")</p>\n<p>If instead you try to construct a genius character by having an emotionally impoverished 'genius' part in conflict with a warm nongenius part... ugh. &nbsp;Cliche. &nbsp;Don't write the first thing that pops into your head from watching Star Trek. &nbsp;This is not how real geniuses work. &nbsp;HPMOR!Harry, the primary protagonist, contains so many different people he has to give them names, and none of them are stupid, nor does any one of them contain his emotions set aside in a neat jar; they contain different mixtures of emotions and ideals. &nbsp;Combining two cliche characters won't be enough to build a deep character. &nbsp;Combining two different <em>realistic</em>&nbsp;people in that character's situation works much better. &nbsp;Two is not a limit, it's a minimum, but everyone involved still has to be recognizably the same person when combined.</p>\n<p>Closely related is Orson Scott Card's observation that a conflict between Good and Evil can be interesting, but it's often not half as interesting as a conflict between Good and Good. All standard rules about cliches still apply, and a conflict between good and good which you've previously read about and to which the reader can already guess your correct approved answer, cannot carry the story. A good rule of thumb is that if you have a conflict between good and good which you feel unsure about yourself, or which you can remember feeling unsure about, or you're not sure where exactly to draw the line, you can build a story around it. I consider the most successful moral conflict in HPMOR to be the argument between Harry and Dumbledore in Ch. 77 because it almost perfectly divided the readers on who was in the right *and* about whose side the author was taking. &nbsp;(*This* was done by deliberately following Orson Scott Card's rule, not by accident. &nbsp;Likewise _Three Worlds Collide_, though it was only afterward that I realized how much of the praise for that story, which I hadn't dreamed would be considered literarily meritful by serious SF writers, stemmed from the sheer rarity of stories built around genuinely open moral arguments. &nbsp;Orson Scott Card: &nbsp;\"Propaganda only works when the reader feels like you've been absolutely fair to other side\", and writing about a moral dilemma where *you're* still trying to figure out&nbsp;the answer is an excellent way to achieve this.)</p>\n<p>Character shallowness can be a symptom of moral shallowness if it reflects a conflict between Good and Evil drawn along lines too clear to bring two good parts of a good character into conflict. This is why it would've been hard for Lord of the Rings to contain conflicted characters without becoming an entirely different story, though as Robin Hanson has just remarked, LotR is a Mileu story, not a Character story. &nbsp;Conflicts between evil and evil are even shallower than conflicts between good and evil, which is why what passes for 'maturity' in some literature is so uninteresting. There's nothing to choose there, no decision to await with bated breath, just an author showing off their disillusionment as a claim of sophistication.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"7mTviCYysGmLqiHai": 1, "GBpwq8cWvaeRoE9X5": 5, "73btkq64uWfoWGfpF": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kBADRoen6u7BbJmD2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 60, "baseScore": 69, "extendedScore": null, "score": 0.000175, "legacy": true, "legacyId": "22965", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 69, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 67, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-06-16T02:10:02.674Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T02:16:44.853Z", "modifiedAt": null, "url": null, "title": "Normative uncertainty in Newcomb's problem", "slug": "normative-uncertainty-in-newcomb-s-problem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:09.607Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6k4Fzdxpz25foiTCc/normative-uncertainty-in-newcomb-s-problem", "pageUrlRelative": "/posts/6k4Fzdxpz25foiTCc/normative-uncertainty-in-newcomb-s-problem", "linkUrl": "https://www.lesswrong.com/posts/6k4Fzdxpz25foiTCc/normative-uncertainty-in-newcomb-s-problem", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Normative%20uncertainty%20in%20Newcomb's%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANormative%20uncertainty%20in%20Newcomb's%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6k4Fzdxpz25foiTCc%2Fnormative-uncertainty-in-newcomb-s-problem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Normative%20uncertainty%20in%20Newcomb's%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6k4Fzdxpz25foiTCc%2Fnormative-uncertainty-in-newcomb-s-problem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6k4Fzdxpz25foiTCc%2Fnormative-uncertainty-in-newcomb-s-problem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 650, "htmlBody": "<p>Here is Wikipedia's <a href=\"http://en.wikipedia.org/wiki/Newcomb's_paradox#The_problem\">description of Newcomb's problem</a>:</p>\n<blockquote>\n<p style=\"margin: 0.4em 0px 0.5em; line-height: 19.196685791015625px; font-family: sans-serif; font-size: 12.731481552124023px;\">The player of the game is presented with two boxes, one transparent (labeled A) and the other opaque (labeled B). The player is permitted to take the contents of both boxes, or just the opaque box B. Box A contains a visible $1,000. The contents of box B, however, are determined as follows: At some point before the start of the game, the Predictor makes a prediction as to whether the player of the game will take just box B, or both boxes. If the Predictor predicts that both boxes will be taken, then box B will contain nothing. If the Predictor predicts that only box B will be taken, then box B will contain $1,000,000.</p>\n<p style=\"margin: 0.4em 0px 0.5em; line-height: 19.196685791015625px; font-family: sans-serif; font-size: 12.731481552124023px;\">Nozick also stipulates that if the Predictor predicts that the player will choose randomly, then box B will contain nothing.</p>\n<p style=\"margin: 0.4em 0px 0.5em; line-height: 19.196685791015625px; font-family: sans-serif; font-size: 12.731481552124023px;\">By the time the game begins, and the player is called upon to choose which boxes to take, the prediction has already been made, and the contents of box B have already been determined. That is, box B contains either $0 or $1,000,000 before the game begins, and once the game begins even the Predictor is powerless to change the contents of the boxes. Before the game begins, the player is aware of all the rules of the game, including the two possible contents of box B, the fact that its contents are based on the Predictor's prediction, and knowledge of the Predictor's infallibility. The only information withheld from the player is what prediction the Predictor made, and thus what the contents of box B are.</p>\n</blockquote>\n<p style=\"margin: 0.4em 0px 0.5em; line-height: 19.196685791015625px; font-family: sans-serif; font-size: 12.731481552124023px;\">Most of this is a fairly general thought experiment for thinking about different decision theories, but one element stands out as particularly arbitrary: the ratio between the amount the Predictor may place in box B and the amount in box A. In the Newcomb formulation conveyed by Nozick, this ratio is 1000:1, but this is not necessary. Most decision theories that recommend one-boxing do so as long as the ratio is greater than 1.<br /><br />The 1000:1 ratio strengthens the intuition for one-boxing, which is helpful for illustrating why one might find one-boxing plausible. However, given uncertainty about normative decision theory, the decision to one-box can diverge from one's best guess at the best decision theory, e.g. if I think there is a 1 in 10 chance that one-boxing decision theories I may one-box on Newcomb's problem with a potential payoff ratio of 1000:1 but not if the ratio is only 2:1.<br /><br />So the question, \"would you one-box on Newcomb's problem, given your current state of uncertainty?\" is not quite the same as \"would the best decision theory recommend one-boxing?\" This occurred to me in the context of this distribution of <a href=\"http://philpapers.org/surveys/results.pl?affil=Target+faculty&amp;areas0=1399&amp;areas_max=1&amp;grain=fine\">answers</a> among target philosophy faculty from the PhilPapers Survey:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">13 / 31 (41.9%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">7 / 31 (22.6%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">6 / 31 (19.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Agnostic/undecided</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">2 / 31 (6.5%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">2 / 31 (6.5%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">1 / 31 (3.2%)</td>\n</tr>\n</tbody>\n</table>\n<p style=\"margin: 0.4em 0px 0.5em; line-height: 19.196685791015625px; font-family: sans-serif; font-size: 12.731481552124023px;\"><br />If all of these answers are about the correct decision theory (rather than what to do in the actual scenario), then two-boxing is the clear leader, with a 2.85:1 ratio of support (accept or lean) in its favor, but this skew would seem far short of that needed to justify 1000:1 confidence in two-boxing on Newcomb's Problem. <br /><br />Here are Less Wrong <a href=\"/lw/fp5/2012_survey_results/\">survey</a> answers for 2012:<br /><br /><strong style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">NEWCOMB'S PROBLEM</strong><br style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" /><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">One-box: 726, 61.4%</span><br style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" /><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Two-box: 78, 6.6%</span><br style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" /><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Not sure: 53, 4.5%</span><br style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" /><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">Don't understand: 86, 7.3%</span><br style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" /><span style=\"font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\">No answer: 240, 20.3%<br /></span><br />Here one-boxing is overwhelmingly dominant. I'd like to sort out how much of this is disagreement about theory, and how much reflects the extreme payoffs in the standard Newcomb formulation. So, I'll be putting a poll in the comments below.<strong><br /></strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6k4Fzdxpz25foiTCc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 14, "extendedScore": null, "score": 1.2338643659242033e-06, "legacy": true, "legacyId": "22966", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["x9FNKTEt68Rz6wQ6P"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T04:45:04.761Z", "modifiedAt": null, "url": null, "title": "Open Thread, June 16-30, 2013", "slug": "open-thread-june-16-30-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:08.195Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Td8snTPN2v2rp6u4u/open-thread-june-16-30-2013", "pageUrlRelative": "/posts/Td8snTPN2v2rp6u4u/open-thread-june-16-30-2013", "linkUrl": "https://www.lesswrong.com/posts/Td8snTPN2v2rp6u4u/open-thread-june-16-30-2013", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20June%2016-30%2C%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20June%2016-30%2C%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTd8snTPN2v2rp6u4u%2Fopen-thread-june-16-30-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20June%2016-30%2C%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTd8snTPN2v2rp6u4u%2Fopen-thread-june-16-30-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTd8snTPN2v2rp6u4u%2Fopen-thread-june-16-30-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Td8snTPN2v2rp6u4u", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 1.233977384550535e-06, "legacy": true, "legacyId": "22967", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 314, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T09:46:12.712Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne Winter Solstice Dinner Party and Social Meetup", "slug": "meetup-melbourne-winter-solstice-dinner-party-and-social", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BraydenM", "createdAt": "2013-06-10T09:17:31.294Z", "isAdmin": false, "displayName": "BraydenM"}, "userId": "KBZHqcMC6z2rPZkZK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ySAN6rQm76T5ALCEz/meetup-melbourne-winter-solstice-dinner-party-and-social", "pageUrlRelative": "/posts/ySAN6rQm76T5ALCEz/meetup-melbourne-winter-solstice-dinner-party-and-social", "linkUrl": "https://www.lesswrong.com/posts/ySAN6rQm76T5ALCEz/meetup-melbourne-winter-solstice-dinner-party-and-social", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20Winter%20Solstice%20Dinner%20Party%20and%20Social%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20Winter%20Solstice%20Dinner%20Party%20and%20Social%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FySAN6rQm76T5ALCEz%2Fmeetup-melbourne-winter-solstice-dinner-party-and-social%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20Winter%20Solstice%20Dinner%20Party%20and%20Social%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FySAN6rQm76T5ALCEz%2Fmeetup-melbourne-winter-solstice-dinner-party-and-social", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FySAN6rQm76T5ALCEz%2Fmeetup-melbourne-winter-solstice-dinner-party-and-social", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 254, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nu'>Melbourne Winter Solstice Dinner Party and Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">21 June 2013 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Carlton, Victoria, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next regular social meetup comes with a twist. As we are holding the event on the shortest day of the year, we will be doing something special to celebrate the winter solstice.</p>\n\n<p>This will be an occasion for reflection on the universe, and humanity's place within it. We will be celebrating with a winter feast, courtesy of Thomas, and short speeches to be presented by a small number of participants.</p>\n\n<p>All are welcome at the usual start time of 6:30pm, although there will be a couple of us there from 6pm getting the food ready, so feel free to come earlier than usual. Please contact one of the hosts for the address if you have not visited before, and check out the google group: groups.google.com/forum/?fromgroups#!forum/melbourne-less-wrong</p>\n\n<p>At 8:30pm we will kick off the official part of the event, so we encourage you to arrive before this time if possible.</p>\n\n<p>Following the feast and speeches, the event will return to standard social activities including boardgames and chatting, parlour games etc. If you haven't been to a Melbourne meetup before/recently, the social meetup can be less intimidating way to meet us as it's very informal.</p>\n\n<p>For the location/any questions, please see the Melbourne Less Wrong Google group, or feel free to contact Brayden (0407 943 917), Richard (0421 231 789) or Ben (0412 996 288).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nu'>Melbourne Winter Solstice Dinner Party and Social Meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ySAN6rQm76T5ALCEz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2342068831531987e-06, "legacy": true, "legacyId": "22969", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Winter_Solstice_Dinner_Party_and_Social_Meetup\">Discussion article for the meetup : <a href=\"/meetups/nu\">Melbourne Winter Solstice Dinner Party and Social Meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">21 June 2013 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Carlton, Victoria, Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Melbourne's next regular social meetup comes with a twist. As we are holding the event on the shortest day of the year, we will be doing something special to celebrate the winter solstice.</p>\n\n<p>This will be an occasion for reflection on the universe, and humanity's place within it. We will be celebrating with a winter feast, courtesy of Thomas, and short speeches to be presented by a small number of participants.</p>\n\n<p>All are welcome at the usual start time of 6:30pm, although there will be a couple of us there from 6pm getting the food ready, so feel free to come earlier than usual. Please contact one of the hosts for the address if you have not visited before, and check out the google group: groups.google.com/forum/?fromgroups#!forum/melbourne-less-wrong</p>\n\n<p>At 8:30pm we will kick off the official part of the event, so we encourage you to arrive before this time if possible.</p>\n\n<p>Following the feast and speeches, the event will return to standard social activities including boardgames and chatting, parlour games etc. If you haven't been to a Melbourne meetup before/recently, the social meetup can be less intimidating way to meet us as it's very informal.</p>\n\n<p>For the location/any questions, please see the Melbourne Less Wrong Google group, or feel free to contact Brayden (0407 943 917), Richard (0421 231 789) or Ben (0412 996 288).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Winter_Solstice_Dinner_Party_and_Social_Meetup1\">Discussion article for the meetup : <a href=\"/meetups/nu\">Melbourne Winter Solstice Dinner Party and Social Meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne Winter Solstice Dinner Party and Social Meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_Winter_Solstice_Dinner_Party_and_Social_Meetup", "level": 1}, {"title": "Discussion article for the meetup : Melbourne Winter Solstice Dinner Party and Social Meetup", "anchor": "Discussion_article_for_the_meetup___Melbourne_Winter_Solstice_Dinner_Party_and_Social_Meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T09:54:22.971Z", "modifiedAt": null, "url": null, "title": "The Classic Literature Workshop", "slug": "the-classic-literature-workshop", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:30.839Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ritalin", "createdAt": "2012-05-01T18:00:25.863Z", "isAdmin": false, "displayName": "Ritalin"}, "userId": "ACGKS9W7iQQywxrWW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/D3awyHY55wjDsobJs/the-classic-literature-workshop", "pageUrlRelative": "/posts/D3awyHY55wjDsobJs/the-classic-literature-workshop", "linkUrl": "https://www.lesswrong.com/posts/D3awyHY55wjDsobJs/the-classic-literature-workshop", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Classic%20Literature%20Workshop&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Classic%20Literature%20Workshop%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD3awyHY55wjDsobJs%2Fthe-classic-literature-workshop%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Classic%20Literature%20Workshop%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD3awyHY55wjDsobJs%2Fthe-classic-literature-workshop", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FD3awyHY55wjDsobJs%2Fthe-classic-literature-workshop", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1315, "htmlBody": "<p><span id=\".reactRoot[7688470].[0][1][1]{comment10151619167649228_27009065}.[0].[0:1].[0].[0:1].[0].[0:0].[0][2]\"><span id=\".reactRoot[7688470].[0][1][1]{comment10151619167649228_27009065}.[0].[0:1].[0].[0:1].[0].[0:0].[0][2].[0]\"><span id=\".reactRoot[7688470].[0][1][1]{comment10151619167649228_27009065}.[0].[0:1].[0].[0:1].[0].[0:0].[0][2].[0].[0:0]\">From EY's Facebook page, there were two posts that got me thinking about fiction and how to work it better and make it stronger:<br /></span></span></span></p>\n<blockquote>\n<p><span class=\"userContent\">It would have been trivial to fix _Revenge of the Sith_'s inadequate motivation of Anakin's dark turn; have Padme already in the hospital slowly dying as her children come to term, not just some nebulous \"visions\". (Bonus points if you have Yoda lecture Anakin about the inevitability of death, but I'd understand if they didn't go there.) At the end, Anakin doesn't try to choke Padme; he watches <span class=\"text_exposed_show\">the ship with her fly out of his reach, away from his ability to use his unnatural Sith powers to save her. Now Anakin's motives are 320% more sympathetic and the movie makes 170% more sense. If I'd put some serious work in, I'm pretty sure I could've had the movie audience in tears.<br /> <br /> I still feel a sense of genuine puzzlement on how such disastrous writing happens in movies and TV shows. Are the viewers who care about this such a tiny percentage that it's not worth trying to sell to them? Are there really so few writers who could read over the script and see in 30 seconds how to fix something like this? (If option 2 is really the problem and people know it's the problem, I'd happily do it for $10,000 a shot.) Is it Graham's Design Paradox - can Hollywood moguls just not tell the difference between competent writers making such an offer, and fakers who'll take the money and run? Are the producers' egos so grotesque that they can't ask a writer for help? Is there some twisted sense of superiority bound up with believing that the audience is too dumb to care about this kind of thing, even though it looks to me like they do? I don't understand how a &gt;$100M movie ends up with flaws that I could fix at the script stage with 30 seconds of advice.</span></span></p>\n</blockquote>\n<blockquote>\n<p><span class=\"userContent\">A helpful key to understanding the art and technique of character in storytelling, is to consider the folk-psychological notion from Internal Family Systems of people being composed of different 'parts' embodying different drives or goals. A shallow character is then a character with only one 'part'.<br /> <br /> A good rule of thumb is that to create a 3D character, that person must contain at least two diff<span class=\"text_exposed_show\">erent 2D characters who come into conflict. Contrary to the first thought that crosses your mind, three-dimensional good people are constructed by combining at least two different good people with two different ideals, not by combining a good person and a bad person. Deep sympathetic characters have two sympathetic parts in conflict, not a sympathetic part in conflict with an unsympathetic part. Deep smart characters are created by combining at least two different people who are geniuses.<br /> <br /> E.g. HPMOR!Hermione contains both a sensible young girl who tries to keep herself and her friends out of trouble, and a starry-eyed heroine, neither of whom are stupid. (Actually, since HPMOR!Hermione is also the one character who I created as close to her canon self as I could manage - she didn't *need* upgrading - I should credit this one to J. K. Rowling.) (Admittedly, I didn't actually follow that rule deliberately to construct Methods, I figured it out afterward when everyone was praising the characterization and I was like, \"Wait, people are calling me a character author now? What the hell did I just do right?\")<br /> <br /> If instead you try to construct a genius character by having an emotionally impoverished 'genius' part in conflict with a warm nongenius part... ugh. Cliche. Don't write the first thing that pops into your head from watching Star Trek. This is not how real geniuses work. HPMOR!Harry, the primary protagonist, contains so many different people he has to give them names, and none of them are stupid, nor does any one of them contain his emotions set aside in a neat jar; they contain different mixtures of emotions and ideals. Combining two cliche characters won't be enough to build a deep character. Combining two different realistic people in that character's situation works much better. Two is not a limit, it's a minimum, but everyone involved still has to be recognizably the same person when combined.<br /> <br /> Closely related is Orson Scott Card's observation that a conflict between Good and Evil can be interesting, but it's often not half as interesting as a conflict between Good and Good. All standard rules about cliches still apply, and a conflict between good and good which you've previously read about and to which the reader can already guess your correct approved answer, cannot carry the story. A good rule of thumb is that if you have a conflict between good and good which you feel unsure about yourself, or which you can remember feeling unsure about, or you're not sure where exactly to draw the line, you can build a story around it. I consider the most successful moral conflict in HPMOR to be the argument between Harry and Dumbledore in Ch. 77 because it almost perfectly divided the readers on who was in the right *and* about whose side the author was taking. (*This* was done by deliberately following Orson Scott Card's rule, not by accident. Likewise _Three Worlds Collide_, though it was only afterward that I realized how much of the praise for that story, which I hadn't dreamed would be considered literarily meritful by serious SF writers, stemmed from the sheer rarity of stories built around genuinely open moral arguments. Orson Scott Card: \"Propaganda only works when the reader feels like you've been absolutely fair to other side\", and writing about a moral dilemma where *you're* still trying to figure out the answer is an excellent way to achieve this.)<br /> <br /> Character shallowness can be a symptom of moral shallowness if it reflects a conflict between Good and Evil drawn along lines too clear to bring two good parts of a good character into conflict. This is why it would've been hard for Lord of the Rings to contain conflicted characters without becoming an entirely different story, though as Robin Hanson has just remarked, LotR is a Mileu story, not a Character story. Conflicts between evil and evil are even shallower than conflicts between good and evil, which is why what passes for 'maturity' in some literature is so uninteresting. There's nothing to choose there, no decision to await with bated breath, just an author showing off their disillusionment as a claim of sophistication.</span></span></p>\n</blockquote>\n<p>&nbsp;</p>\n<p><span class=\"userContent\"><span class=\"text_exposed_show\">I was wondering if we could apply this process to older fiction, Great Literature that is historically praised, and excellent by its own time's standards, but which, if published by a modern author, would seem substandard or inappropriate in one way or another.</span></span></p>\n<p><span class=\"userContent\"><span class=\"text_exposed_show\">Given our community's propensity for challenging sacred cows, and the unique tool-set available to us, I am sure we could take some great works of the past and turn them into awesome works of the present.</span></span></p>\n<p><br />Of course, it doesn't have to be a laboratory where we rewrite the whole damn things. Just proprely-grounded suggestions on how to improve this or that work would be great.</p>\n<p>&nbsp;</p>\n<p>P.S. This post is itself a work in progress, and will update and improve as comments come. It's been a long time since I've last posted on LW, so advice is quite welcome. Our work is never over.</p>\n<p>&nbsp;</p>\n<p><span class=\"userContent\"><span class=\"text_exposed_show\">EDIT: Well, I like that this thread has turned out so lively, but I've got finals to prepare for and I can't afford to keep participating in the discussion to my satisfaction. I'll be back in July, and apologize in advance for being such a poor OP. That said, cheers!<br /></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "D3awyHY55wjDsobJs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 5, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "22970", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 115, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T17:44:06.359Z", "modifiedAt": null, "url": null, "title": "On manipulating others", "slug": "on-manipulating-others", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:32.217Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jonii", "createdAt": "2009-07-15T05:24:30.383Z", "isAdmin": false, "displayName": "Jonii"}, "userId": "xa8EysPtEYKcEDeNg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pu55vE2dGjBenQcyi/on-manipulating-others", "pageUrlRelative": "/posts/pu55vE2dGjBenQcyi/on-manipulating-others", "linkUrl": "https://www.lesswrong.com/posts/pu55vE2dGjBenQcyi/on-manipulating-others", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20manipulating%20others&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20manipulating%20others%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpu55vE2dGjBenQcyi%2Fon-manipulating-others%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20manipulating%20others%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpu55vE2dGjBenQcyi%2Fon-manipulating-others", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpu55vE2dGjBenQcyi%2Fon-manipulating-others", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 632, "htmlBody": "<p>I recently had a discussion with a friend of mine on the topic of reading others, socially. What they want, what they think, where are they going, etc. During this discussion, I verbalized my intuition on the topic of manipulating others how you think they should act, and what I said had me puzzled for the next few days. So, after much thinking I came to a conclusion, but I want to see what LW thinks of my pondering.</p>\n<p>Basically, the idea is that, social clumsiness many very intelligent people face is actually very much self-imposed, a handicap placed upon themselves because we feel iffy about consciously manipulating others as pawns in our grander schemes.</p>\n<p>Basically, the reasoning of mine was this: Treating other people as pawns in your plan, rather than actual people, is wrong. You should not strip others of their power to decide for themselves. But say, you are more intelligent than others, and could with planning lead others to do things you want them to. This power over others presents you with an unfair advantage, and this unfair advantage presents you with an iffy ethical dilemma. If you can force other people to do what you will, regardless of their initial disposition, aren't you treating them as pawns rather than autonomous human beings? If you strip them of power to have their initial disposition affect their decisions, aren't you doing wrong? Of course, it's usually very difficult to get people to do what you want. Two equals discussing, both may try this, but both may fail, and even if another succeeds, it's still considered \"fair game\" by all parties. But more easily this manipulating happens, the more of your brain you need to shut down to make the discussion \"fair\". At some point, expressing any opinion and leading other people at all seems risky and iffy.</p>\n<p>So how do people cope? My theory is this: They stop interacting. Voicing their own opinion, asking other people for things, or even having any goal other than following directions laid out by others becomes off-limits. If they do any of that, it opens an ugly, ethical box of worms of the shape \"Should I make them do this?\"</p>\n<p>So basically, my hypothesis is, the reason intelligent people are so often socially clumsy is because it's a facade, a self-imposed handicap they keep up because evolution has programmed us to have repulsion towards unfairly manipulating others. Because they can make others do anything, they choose to do nothing. This manifests as being easily led, a kind of \"doormat\", lacking their own will or ego, even.</p>\n<p>It's simplistic, there are complications I can readily see that make the whole picture more complicated, but this stripped down dynamic of being more intelligent forcing you to feign helplessness is what I'm interested in, so that's what I presented. Is there any reason to think a mechanic like this actually exists? Is it widespread? Has there been actual study on this mechanic already?</p>\n<p>There are aplenty of interesting-looking areas of study if this dynamic is actually a real thing. Say, PUA could look a bit different when aimed at doormat-style people. Aesthetically it would provide more interesting explanation for why smart people are not too social, and it also leads to advice that differs a lot from advice given from stand-point of \"You need to learn this\". It makes several \"is it okay to manipulate others\" -type of questions relevant for practical ethics study. Of course, it most likely is not a real thing.</p>\n<p>&nbsp;</p>\n<p>Edit: Also, I was a bit hesitant if I should post this under discussion or wait for that Open Thread to pop up. It's quite lengthy, so I felt discussion post could be appropriate, but dunno, I could and maybe should take this down and wait for Open Thread.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pu55vE2dGjBenQcyi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": -11, "extendedScore": null, "score": -1.2e-05, "legacy": true, "legacyId": "22963", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 110, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-16T18:59:57.994Z", "modifiedAt": null, "url": null, "title": "[video] \"Transhuman\", featuring Sandberg and Bostrom", "slug": "video-transhuman-featuring-sandberg-and-bostrom", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:25.664Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pablo_Stafforini", "createdAt": "2009-03-24T12:56:00.130Z", "isAdmin": false, "displayName": "Pablo"}, "userId": "W7ETRtvRMqYetyQE9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yu4Lun9iBFofTsZGj/video-transhuman-featuring-sandberg-and-bostrom", "pageUrlRelative": "/posts/yu4Lun9iBFofTsZGj/video-transhuman-featuring-sandberg-and-bostrom", "linkUrl": "https://www.lesswrong.com/posts/yu4Lun9iBFofTsZGj/video-transhuman-featuring-sandberg-and-bostrom", "postedAtFormatted": "Sunday, June 16th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Bvideo%5D%20%22Transhuman%22%2C%20featuring%20Sandberg%20and%20Bostrom&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Bvideo%5D%20%22Transhuman%22%2C%20featuring%20Sandberg%20and%20Bostrom%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyu4Lun9iBFofTsZGj%2Fvideo-transhuman-featuring-sandberg-and-bostrom%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Bvideo%5D%20%22Transhuman%22%2C%20featuring%20Sandberg%20and%20Bostrom%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyu4Lun9iBFofTsZGj%2Fvideo-transhuman-featuring-sandberg-and-bostrom", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyu4Lun9iBFofTsZGj%2Fvideo-transhuman-featuring-sandberg-and-bostrom", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 81, "htmlBody": "<p><a href=\"http://www.transhumandoc.com/\">Transhuman</a>, a 20-minute Dutch documentary about Anders Sandberg, <a href=\"http://youtu.be/3PAj2yorJig\">is now available online</a>. &nbsp;From \u007fSandberg's <a href=\"http://www.aleph.se/andart/archives/2013/06/i_got_uploaded_to_youtube.html\">blog</a>:</p>\n<blockquote>\n<p>Here is the chance of see my beetle collection, my grubby kitchen, and an absolutely stunning combination between a supercomputer center and an oxford library. Oh, and some discussion about transhumanism and the meaning of life too.</p>\n</blockquote>\n<p>The documentary features Nick Bostrom at&nbsp;<a href=\"http://youtu.be/3PAj2yorJig?t=9m23s\">9:23</a>-10:32 and at <a href=\"http://youtu.be/3PAj2yorJig?t=19m28s\">19:28</a>-19:37. &nbsp;There's also a <a href=\"http://www.youtube.com/watch?v=3PAj2yorJig&amp;feature=youtu.be&amp;t=9m59s\">cameo appearance</a> of Eliezer Yudkowsky, Carl Shulman, Anna Salamon, Toby Ord, William MacAskill, David Pearce and Stuart Armstrong.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"jiuackr7B5JAetbF6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yu4Lun9iBFofTsZGj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 8, "extendedScore": null, "score": 1.2346291068846983e-06, "legacy": true, "legacyId": "22971", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-17T05:11:29.160Z", "modifiedAt": null, "url": null, "title": "Quotes and Notes on Scott Aaronson\u2019s \"The Ghost in the Quantum Turing Machine\"", "slug": "quotes-and-notes-on-scott-aaronson-s-the-ghost-in-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:00.996Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NnzYPN7mHDQ7hpeTc/quotes-and-notes-on-scott-aaronson-s-the-ghost-in-the", "pageUrlRelative": "/posts/NnzYPN7mHDQ7hpeTc/quotes-and-notes-on-scott-aaronson-s-the-ghost-in-the", "linkUrl": "https://www.lesswrong.com/posts/NnzYPN7mHDQ7hpeTc/quotes-and-notes-on-scott-aaronson-s-the-ghost-in-the", "postedAtFormatted": "Monday, June 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Quotes%20and%20Notes%20on%20Scott%20Aaronson%E2%80%99s%20%22The%20Ghost%20in%20the%20Quantum%20Turing%20Machine%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQuotes%20and%20Notes%20on%20Scott%20Aaronson%E2%80%99s%20%22The%20Ghost%20in%20the%20Quantum%20Turing%20Machine%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnzYPN7mHDQ7hpeTc%2Fquotes-and-notes-on-scott-aaronson-s-the-ghost-in-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Quotes%20and%20Notes%20on%20Scott%20Aaronson%E2%80%99s%20%22The%20Ghost%20in%20the%20Quantum%20Turing%20Machine%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnzYPN7mHDQ7hpeTc%2Fquotes-and-notes-on-scott-aaronson-s-the-ghost-in-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNnzYPN7mHDQ7hpeTc%2Fquotes-and-notes-on-scott-aaronson-s-the-ghost-in-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4615, "htmlBody": "<p><a href=\"http://arxiv.org/abs/1306.0159\">This highly speculative paper</a> has been discussed here <a href=\"/r/discussion/lw/hok/link_scott_aaronson_on_free_will/\">before</a>, but I found the discussion's quality rather disappointing. People generally took bits and pieces out of context and then mostly offered arguments already addressed in the paper. Truly the internet is the most powerful misinterpretation engine ever built. It's nice to see that Scott, who is no stranger to online adversity, is taking it in stride.</p>\n<p>So I went through the paper and took notes, which I posted on my blog, but I am also attaching them below, in a hope that someone else here finds them useful. I initially intended to write up a comment in the other thread, but the size of it grew too large for a comment, so I am making this post. Feel free to downvote if you think it does not belong in Discussion (or for any other reason, of course).&nbsp;</p>\n<p>TL;DR: The main idea of the paper is, as far as I can tell, that it is possible to construct a physical model, potentially related to the \"free\" part of the free will debate, where some events cannot be predicted at all, not even probabilistically, like it is done in Quantum Mechanics. Scott also proposes one possible mechanism for this \"Knightian unpredictability\": the not-yet-decohered parts of the initial state of the universe, such as the Cosmic Microwave Background radiation. He does not claim a position on whether the model is correct, only that it is potentially testable and thus shifts a small piece of the age-old philosophical debate on free will into the realm of physics.&nbsp;</p>\n<p>For those here who say that the free-will question has been <a href=\"http://wiki.lesswrong.com/wiki/Free_will_(solution)\">dissolved</a>, let me note that the picture presented in the paper is one explicitly rejected by Eliezer, probably a bit hastily. Specifically in this diagram:</p>\n<p><img src=\"/static/imported/2008/06/14/fwmarkov_3.png\" alt=\"\" width=\"219\" height=\"124\" /></p>\n<p>Eliezer says that the sequential picture on the left is the only correct one, whereas Scott offers a perfectly reasonable model which is better described by the picture on the right. To reiterate, there is a part of the past (Scott calls it \"microfacts\") which evolves reversibly and unitarily until some time in the future. Given that this part has not been measured yet, there is no way, not even probabilistically, to estimate its influence on some future event, when some of those microfacts interact with the rest of the world and decohere, thus affecting \"macrofacts\", potentially including human choices. This last speculative idea could be tested if it is shown that small quantum fluctuations can be chaotically amplified to macroscopic levels. If this model is correct, it may have significant consequences on whether a human mind can be successfully cloned and on whether an AI can be called sentient, or even how it can be made sentient.&nbsp;</p>\n<p>My personal impression is that Scott's arguments are much better thought through than the speculations by Penrose in his books, but you may find otherwise. I also appreciate this paper for doing what mainstream philosophers are qualified and ought to do, but consistently fail to do: look at one of the Big Questions, chip away some small solvable piece of it, and offer this piece to qualified scientists.&nbsp;</p>\n<p>Anyway, below are my notes and quotes. If you think you have found an obvious objection to some of the quotes, this is likely because I did not provide enough context, so please read the relevant section of the paper before pointing it out. It may also be useful to recite the <a href=\"/lw/h8n/litany_of_a_bright_dilettante/\">Litany of a Bright Dilettante</a>.</p>\n<hr />\n<p>p.6. On QM's potentially limiting \"an external agent&rsquo;s ability to scan, copy, and predict human brains and other complicated biological systems\" : \"In this essay I&rsquo;ll argue strongly [...] that we can easily imagine worlds consistent with quantum mechanics (and all other known physics and biology) where the answer to the question is yes, and other such worlds where the answer is no. And we don&rsquo;t yet know which kind we live in.\"</p>\n<p>p. 7. \"The [...] idea&mdash;that of being &ldquo;willed by you&rdquo;&mdash;is the one I consider outside the scope of science, for the simple reason that no matter what the empirical facts were, a skeptic could always deny that a given decision was &ldquo;really&rdquo; yours, and hold the true decider to have been God, the universe, an impersonating demon, etc. I see no way to formulate, in terms of observable concepts, what it would even mean for such a skeptic to be right or wrong.\"</p>\n<p>\"the situation seems different if we set aside the &ldquo;will&rdquo; part of free will, and consider only the &ldquo;free&rdquo; part.\"</p>\n<p>\"I&rsquo;ll use the term freedom, or Knightian freedom, to mean a certain strong kind of physical unpredictability: a lack of determination, even probabilistic determination, by knowable external factors. [..] we lack a reliable way even to quantify using probability distributions.\"</p>\n<p>p.8. \"I tend to see Knightian unpredictability as a necessary condition for free will. In other words, if a system were completely predictable (even probabilistically) by an outside entity&mdash;not merely in principle but in practice&mdash;then I find it hard to understand why we&rsquo;d still want to ascribe &ldquo;free will&rdquo; to the system. Why not admit that we now fully understand what makes this system tick?\"</p>\n<p>p.12. \"from my perspective, this process of &ldquo;breaking off&rdquo; answerable parts of unanswerable riddles, then trying to answer those parts, is the closest thing to philosophical progress that there is.\" -- professional philosophers would do well to keep this in mind. Of course, once you break off such answerable part, it tends to leave the realm of philosophy and become a natural science of one kind or another. Maybe something useful professional philosophers could do is to look for \"answerable parts\", break them off and pass along to the experts in the subject matter. And maybe look for the answers in the natural sciences and see how they help sculpt the \"unanswerable riddles\".</p>\n<p>p.14. Weak compatibilism: \"My perspective embraces the mechanical nature of the universe&rsquo;s time-evolution laws, and in that sense is proudly &ldquo;compatibilist.&rdquo; On the other hand, I care whether our choices can actually be mechanically predicted&mdash;not by hypothetical Laplace demons but by physical machines. I&rsquo;m troubled if they are, and I take seriously the possibility that they aren&rsquo;t (e.g., because of chaotic amplification of unknowable details of the initial conditions).\"</p>\n<p>p.19. Importance of copyability: \"the problem with this response [that you are nothing but your code] is simply that it gives up on science as something agents can use to predict their future experiences. The agents wanted science to tell them, &ldquo;given such and- such physical conditions, here&rsquo;s what you should expect to see, and why.&rdquo; Instead they&rsquo;re getting the worthless tautology, &ldquo;if your internal code causes you to expect to see X, then you expect to see X, while if your internal code causes you to expect to see Y , then you expect to see Y .&rdquo; But the same could be said about anything, with no scientific understanding needed! To paraphrase Democritus, it seems like the ultimate victory of the mechanistic worldview is also its defeat.\" -- If a mind cannot be copied perfectly, then there is no such thing as your \"code\", i.e. an algorithm which can be run repeatedly.</p>\n<p>p.20. Constrained determinism: \"A form of &ldquo;determinism&rdquo; that applies not merely to our universe, but to any logically possible universe, is not a determinism that has &ldquo;fangs,&rdquo; or that could credibly threaten any notion of free will worth talking about.\"</p>\n<p>p.21: Bell's theorem, quoting Conway and Kochen: \"if there&rsquo;s no faster than-light communication, and Alice and Bob have the &ldquo;free will&rdquo; to choose how to measure their respective particles, then the particles must have their own &ldquo;free will&rdquo; to choose how to respond to the measurements.\" -- the particles' \"free will\" is still constrained by the laws of Quantum Mechanics, however.</p>\n<p>p.23. Multiple (micro-)past compatibilism: \"multiple-pasts compatibilism agrees that the past microfacts about the world determine its future, and it also agrees that the past macrofacts are outside our ability to alter. [...] our choices today might play a role in selecting one past from a giant ensemble of macroscopically-identical but microscopically-different pasts.\"</p>\n<p>p.26. Singulatarianism: \"all the Singulatarians are doing is taking conventional thinking about physics and the brain to its logical conclusion. If the brain is a &ldquo;meat computer,&rdquo; then given the right technology, why shouldn&rsquo;t we be able to copy its program from one physical substrate to another? [...] given the stakes, it seems worth exploring the possibility that there are scientific reasons why human minds can&rsquo;t be casually treated as copyable computer programs: not just practical difficulties, or the sorts of question-begging appeals to human specialness that are child&rsquo;s-play for Singulatarians to demolish. If one likes, the origin of this essay was my own refusal to accept the lazy cop-out position, which answers the question of whether the Singulatarians&rsquo; ideas are true by repeating that their ideas are crazy and weird. If uploading our minds to digital computers is indeed a fantasy, then I demand to know what it is about the physical universe that makes it a fantasy.\"</p>\n<p>p.27. Predictability of human mind: \"I believe neuroscience might someday advance to the point where it completely rewrites the terms of the free-will debate, by showing that the human brain is &ldquo;physically predictable by utside observers&rdquo; in the same sense as a digital computer.\"</p>\n<p>p.28. Em-ethics: \"I&rsquo;m against any irreversible destruction of knowledge, thoughts, perspectives, adaptations, or ideas, except possibly by their owner.\" -- E.g. it's not immoral to stop a simulation which can be resumed or restored from a backup. (The cryonics implications are obvious.) \"Deleting the last copy of an em in existence should be prosecuted as murder, not because doing so snuffs out some inner light of consciousness (who is anyone else to know?), but rather because it deprives the rest of society of a unique, irreplaceable store of knowledge and experiences, precisely as murdering a human would.\" -- Again, this is a pretty transhumanist view, see the anti-deathist position of Eliezer Yudkowsky as expressed in HPMoR.</p>\n<p>p.29. Probabilistic uncertainty vs Knightian uncertainty: \"if we see a conflict between free will and the deterministic predictability of human choices, then we should see the same conflict between free will and probabilistic predictability, assuming the probabilistic predictions are as accurate as those of quantum mechanics. [...] If we know a system&rsquo;s quantum state \u001a, then quantum mechanics lets us calculate the probability of any outcome of any measurement that might later be made on the system. But if we don&rsquo;t know the state, then \u001a itself can be thought of as subject to Knightian uncertainty.\"</p>\n<p>On the source of this unquantifiable \"Knightian uncertainty\": \"in current physics, there appears to be only one source of Knightian uncertainty that could possibly be both fundamental and relevant to human choices. That source is uncertainty about the microscopic, quantum-mechanical details of the universe&rsquo;s initial conditions (or the initial conditions of our local region of the universe)\"</p>\n<p>p.30. \"In economics, the &ldquo;second type&rdquo; of uncertainty&mdash;the type that can&rsquo;t be objectively quantified using probabilities&mdash;is called Knightian uncertainty, after Frank Knight, who wrote about it extensively in the 1920s [49]. Knightian uncertainty has been invoked to explain phenomena from risk-aversion in behavioral economics to the 2008 financial crisis (and was popularized by Taleb [87] under the name &ldquo;black swans&rdquo;).\"</p>\n<p>p.31. \"I think that the free-will-is-incoherent camp would be right, if all uncertainty were probabilistic.\" Bayesian fundamentalism: \"Bayesian probability theory provides the only sensible way to represent uncertainty. On that view, &ldquo;Knightian uncertainty&rdquo; is just a fancy name for someone&rsquo;s failure to carry a probability analysis far enough.\"\" Against the Dutch-booking argument for Bayesian fundamentalism: \"A central assumption on which the Dutch book arguments rely&mdash;basically, that a rational agent shouldn&rsquo;t mind taking at least one side of any bet&mdash;has struck many commentators as dubious.\"</p>\n<p>p.32. Objective prior: \"one can&rsquo;t use Bayesianism to justify a belief in the existence of objective probabilities underlying all events, unless one is also prepared to defend the existence of an &ldquo;objective prior.&rdquo;\"</p>\n<p>Universal prior: \"a distribution that assigns a probability proportional to 2^(&minus;n) to every possible universe describable by an n-bit computer program.\" Why it may not be a useful \"true\" prior: \"a predictor using the universal prior can be thought of as a superintelligent entity that figures out the right probabilities almost as fast as is information-theoretically possible. But that&rsquo;s conceptually very different from an entity that already knows the probabilities.\"</p>\n<p>p.34. Quantum no-cloning: \"it&rsquo;s possible to create a physical object that (a) interacts with the outside world in an interesting and nontrivial way, yet (b) effectively hides from the outside world the information needed to predict how the object will behave in future interactions.\"</p>\n<p>p.35. Quantum teleportation answers the problem of \"what to do with the original after you fax a perfect copy of you to be reconstituted on Mars\": \"in quantum teleportation, the destruction of the original copy is not an extra decision that one needs to make; rather, it happens as an inevitable byproduct of the protocol itself\"</p>\n<p>p.36. Freebit picture: \"due to Knightian uncertainty about the universe&rsquo;s initial quantum state, at least some of the qubits found in nature are regarded as freebits\" making \"predicting certain future events&mdash;possibly including some human decisions&mdash;physically impossible, even probabilistically\". Freebits are qubits because otherwise they could be measured without violating no-cloning. Observer-independence requirement: \"it must not be possible (even in principle) to trace [the freebit's] causal history back to any physical process that generated [the freebit] according to a known probabilistic ensemble.\"</p>\n<p>p.37. On existence of freebits: \"In the actual universe, are there any quantum states that can&rsquo;t be grounded in PMDs?\" PMD, a \"past macroscopic determinant\" is a classical observable that would have let one non-invasively probabilistically predict the prospective freebit to arbitrary accuracy. This is the main question of the paper: can freebits from the initial conditions of the universe survive till present day and even affect human decisions?</p>\n<p>p.38: CMB (cosmic microwave background radiation) is one potential example of freebits: detected CMB radiation did not interact with matter since the last scattering, roughly 380, 000 years after the Big Bang. Objections: a) last scattering is not initial conditions by any means, b) one can easily shield from CMB.</p>\n<p>p.39. Freebit effects on decision-making: \"what sorts of changes to [the quantum state of the entire universe] would or wouldn&rsquo;t suffice to ... change a particular decision made by a particular human being? ... For example, would it suffice to change the energy of a single photon impinging on the subject&rsquo;s brain?\" due to potential amplification of \"microscopic fluctuations to macroscopic scale\". Sort of a quantum butterfly effect.</p>\n<p>p.40. Freebit amplification issues: amplification time and locality. Locality: the freebit only affects the person's actions, which mediates all other influences on the rest of the world. I.e. no direct freebit effect on anything else. On why these questions are interesting: \"I can easily imagine that in (say) fifty years, neuroscience, molecular biology, and physics will be able to say more about these questions than they can today. And crucially, the questions strike me as scientifically interesting regardless of one&rsquo;s philosophical predilections.\"</p>\n<p>p.41. Role of freebits: \"freebits are simply part of the explanation for how a brain can reach decisions that are not probabilistically predictable by outside observers, and that are therefore &ldquo;free&rdquo; in the sense that interests us.\" It could just a noise source, it can help \"foils probabilistic forecasts made by outside observers, yet need not play any role in explaining the system&rsquo;s organization or complexity.\"</p>\n<p>p.42. \"Freedom from the inside out\": &nbsp;\"isn&rsquo;t it anti-scientific insanity to imagine that our choices today could correlate nontrivially with the universe&rsquo;s microstate at the Big Bang?\" \"Causality is based on entropy increase, so it can only make sense to draw causal arrows &ldquo;backwards in time,&rdquo; in those rare situations where entropy is not increasing with time. [...] where physical systems are allowed to evolve reversibly, free from contact with their external environments.\" E.g. the normal causal arrows break down for, say, CMB photons. -- Not sure how Scott jumps from reversible evolution to backward causality.</p>\n<p>p.44. Harmonization problem: backward causality leads to all kinds of problems and paradoxes. Not an issue for the freebit model, as backward causality can point only to \"microfacts\", which do not affect any \"macrofacts\". \"the causality graph with be a directed acyclic graph (a dag), with all arrows pointing forward in time, except for some &ldquo;dangling&rdquo; arrows pointing backward in time that never lead anywhere else.\" The latter is justified by \"no-cloning\". In other words, \"for all the events we actually observe, we must seek their causes only to their past, never to their future.\"\" -- This backward causality moniker seems rather unfortunate and misleading, given that it seems to replace the usual idea of discovery of some (micro)fact about the past with \"a microfact is directly caused by a macrofact F to its future\". \"A simpler option is just to declare the entire concept of causality irrelevant to the microworld.\"</p>\n<p>p.45. Micro/Macro distinction: A potential solution: \"a &ldquo;macrofact&rdquo; is simply any fact of which the news is already propagating outward at the speed of light\". I.e. an interaction turns microfact into a macrofact. This matches Zurek's einselection ideas.</p>\n<p>p.47 Objections to freebits: 5.1: Humans are very predictable. \"Perhaps, as Kane speculates, we truly exercise freedom only for a relatively small number of &ldquo;self-forming actions&rdquo; (SFAs)&mdash;that is, actions that help to define who we are&mdash;and the rest of the time are essentially &ldquo;running on autopilot.&rdquo;\" Also note \"the conspicuous failure of investors, pundits, intelligence analysts, and so on actually to predict, with any reliability, what individuals or even entire populations will do\"</p>\n<p>p.48. 5.2: The weather objection: How are brains different from weather? \"brains seem &ldquo;balanced on a knife-edge&rdquo; between order and chaos: were they as orderly as a pendulum, they couldn&rsquo;t support interesting behavior; were they as chaotic as the weather, they couldn&rsquo;t support rationality. [...] a single freebit could plausibly influence the probability of some macroscopic outcome, even if we model all of the system&rsquo;s constituents quantum-mechanically.\"</p>\n<p>p.49 5.3: The gerbil objection: if a brain or an AI is isolated from freebits except through a a gerbil in a box connected to it, then \"the gerbil, though presumably oblivious to its role, is like a magic amulet that gives the AI a &ldquo;capacity for freedom&rdquo; it wouldn&rsquo;t have had otherwise,\" in essence becoming the soul of the machine. \"Of all the arguments directed specifically against the freebit picture, this one strikes me as the most serious.\" Potential reply: &nbsp;brain is not like AI in that \"In the AI/gerbil system, the &ldquo;intelligence&rdquo; and &ldquo;Knightian noise&rdquo; components were cleanly separable from one another. [...] With the brain, by contrast, it&rsquo;s not nearly so obvious that the &ldquo;Knightian indeterminism source&rdquo; can be physically swapped out for a different one, without destroying or radically altering the brain&rsquo;s cognitive functions as well.\" Now this comes to the issue of identity.</p>\n<p>\"Suppose the nanorobots do eventually complete their scan of all the &ldquo;macroscopic, cognitively-relevant&rdquo; information in your brain, and suppose they then transfer the information to a digital computer, which proceeds to run a macroscopic-scale simulation of your brain. Would that simulation be you? If your &ldquo;original&rdquo; brain were destroyed in this process, or simply anesthetized, would you expect to wake up as the digital version? (Arguably, this is not even a philosophical question, just a straightforward empirical question asking you to predict a future observation!) [...] My conclusion is that either you can be uploaded, copied, simulated, backed up, and so forth, leading to all the puzzles of personal identity discussed in Section 2.5, or else you can&rsquo;t bear the same sort of &ldquo;uninteresting&rdquo; relationship to the &ldquo;non-functional&rdquo; degrees of freedom in your brain that the AI bore to the gerbil box.\"</p>\n<p>p.51. The Initial-State Objection: \"the notion of &ldquo;freebits&rdquo; from the early universe nontrivially influencing present-day events is not merely strange, but inconsistent with known physics\" because \"it follows from known physics that the initial state at the Big Bang was essentially random, and can&rsquo;t have encoded any &ldquo;interesting&rdquo; information\". The reply is rather involved and discusses several new speculative ideas in physics. It boils down to \"when discussing extreme situations like the Big Bang, it&rsquo;s not okay to ignore quantum-gravitational degrees of freedom simply because we don&rsquo;t yet know how to model them. And including those degrees of freedom seems to lead straight back to the unsurprising conclusion that no one knows what sorts of correlations might have been present in the universe&rsquo;s initial microstate.\"</p>\n<p>p.52. The Wigner&rsquo;s-Friend Objection: A macroscopic object \"in a superposition of two mental states\" requires freebits to make a separate \"free decision\" in each one, requiring 2^(number of states) freebits for independent decision making in each state.</p>\n<p>Moreover \"if the freebit picture is correct, and the Wigner&rsquo;s-friend experiment can be carried out, then I think we&rsquo;re forced to conclude that&mdash;at least for the duration of the experiment&mdash;the subject no longer has the &ldquo;capacity for Knightian freedom,&rdquo; and is now a &ldquo;mechanistic,&rdquo; externally-characterized physical system similar to a large quantum computer.\"</p>\n<p>p.55. &nbsp;\"what makes humans any different [from a computer]? According to the most literal reading of quantum mechanics&rsquo; unitary evolution rule&mdash;which some call the Many-Worlds Interpretation&mdash;don&rsquo;t we all exist in superpositions of enormous numbers of branches, and isn&rsquo;t our inability to measure the interference between those branches merely a &ldquo;practical&rdquo; problem, caused by rapid decoherence? Here I reiterate the speculation put forward in Section 4.2: that the decoherence of a state should be considered &ldquo;fundamental&rdquo; and &ldquo;irreversible,&rdquo; precisely when [it] becomes entangled with degrees of freedom that are receding toward our de Sitter horizon at the speed of light, and that can no longer be collected together even in principle. That sort of decoherence could be avoided, at least in principle, by a fault-tolerant quantum computer, as in the Wigner&rsquo;s-friend thought experiment above. But it plausibly can&rsquo;t be avoided by any entity that we would currently recognize as &ldquo;human.\"</p>\n<p>p.56. Difference from Penrose: \" I make no attempt to &ldquo;explain consciousness.&rdquo; Indeed, that very goal seems misguided to me, at least if &ldquo;consciousness&rdquo; is meant in the phenomenal sense rather than the neuroscientists&rsquo; more restricted senses.\"</p>\n<p>p.57. \"instead of talking about the consistency of Peano arithmetic, I believe Penrose might as well have fallen back on the standard arguments about how a robot could never &ldquo;really&rdquo; enjoy fresh strawberries, but at most claim to enjoy them.\"</p>\n<p>\"the real issue is not whether the AI follows a program, but rather, whether it follows a program that&rsquo;s knowable by other physical agents.\"</p>\n<p>\"I&rsquo;m profoundly skeptical that any of the existing objective reduction [by minds] models are close to the truth. The reasons for my skepticism are, first, that the models seem too ugly and ad hoc (GRW&rsquo;s more so than Penrose&rsquo;s); and second, that the AdS/CFT correspondence now provides evidence that quantum mechanics can emerge unscathed even from the combination with gravity.\"</p>\n<p>\"I regard it as a serious drawback of Penrose&rsquo;s proposals that they demand uncomputability in the dynamical laws\"</p>\n<p>p.61. Boltzmann brains: \"By the time thermal equilibrium is reached, the universe will (by definition) have &ldquo;forgotten&rdquo; all details of its initial state, and any freebits will have long ago been &ldquo;used up.&rdquo; In other words, there&rsquo;s no way to make a Boltzmann brain think one thought rather than another by toggling freebits. So, on this account, Boltzmann brains wouldn&rsquo;t be &ldquo;free,&rdquo; even during their brief moments of existence.\"</p>\n<p>p.62. What Happens When We Run Out of Freebits? \"the number of freebits accessible to any one observer must be finite&mdash;simply because the number of bits of any kind is then upper-bounded by the observable universe&rsquo;s finite holographic.entropy. [...] this should not be too alarming. After all, even without the notion of freebits, the Second Law of Thermodynamics (combined with the holographic principle and the positive cosmological constant) already told us that the observable universe can witness at most s 10^122 &ldquo;interesting events,&rdquo; of any kind, before it settles into thermal equilibrium.\"</p>\n<p>p.63. Indexicality: \"indexical puzzle: a puzzle involving the &ldquo;first-person facts&rdquo; of who, what, where, and when you are, which seems to persist even after all the &ldquo;third-person facts&rdquo; about the physical world have been specified.\" This is similar to Knightian uncertainty: \"For the indexical puzzles make it apparent that, even if we assume the laws of physics are completely mechanistic, there remain large aspects of our experience that those laws fail to determine, even probabilistically. Nothing in the laws picks out one particular chunk of suitably organized matter from the immensity of time and space, and says, &ldquo;here, this chunk is you; its experiences are your experiences.&rdquo;\"</p>\n<p>Free will connection: Take two heretofore identical Earths A and B in an infinite universe and are about to diverge based on your decision, and it's not impossible for a superintelligence to predict this decision, not even probabilistically, because it is based on a freebit:</p>\n<p>\"Maybe &ldquo;youA&rdquo; is the &ldquo;real&rdquo; you, and taking the new job is a defining property of who you are, much as Shakespeare &ldquo;wouldn&rsquo;t be Shakespeare&rdquo; had he not written his plays. So maybe youB isn&rsquo;t even part of your reference class: it&rsquo;s just a faraway doppelg&uml;anger you&rsquo;ll never meet, who looks and acts like you (at least up to a certain point in your life) but isn&rsquo;t you. So maybe p = 1. Then again, maybe youB is the &ldquo;real&rdquo; you and p = 0. Ultimately, not even a superintelligence could calculate p without knowing something about what it means to be &ldquo;you,&rdquo; a topic about which the laws of physics are understandably silent.\" \"For me, the appeal of this view is that it &ldquo;cancels two philosophical mysteries against each other&rdquo;: free will and indexical uncertainty\".</p>\n<p>p.65. Falsifiability: \"If human beings could be predicted as accurately as comets, then the freebit picture would be falsified.\" But this prediction has \"an unsatisfying, &ldquo;god-of-the-gaps&rdquo; character\". Another: \"chaotic amplification of quantum uncertainty locally and on \"reasonable\" timescales. Another: \"consider an omniscient demon, who wants to influence your decision-making process by changing the quantum state of a single photon impinging on your brain. [...] imagine that the photons&rsquo; quantum states cannot be altered, maintaining a spacetime history consistent with the laws of physics, without also altering classical degrees of freedom in the photons&rsquo; causal past. In that case, the freebit picture would once again fail.\"</p>\n<p>p.68. Conclusions: \"Could there exist a machine, consistent with the laws of physics, that &ldquo;non-invasively cloned&rdquo; all the information in a particular human brain that was relevant to behavior&mdash; so that the human could emerge from the machine unharmed, but would thereafter be fully probabilistically predictable given his or her future sense-inputs, in much the same sense that a radioactive atom is probabilistically predictable?\"</p>\n<p>\"does the brain possess what one could call a clean digital abstraction layer : that is, a set of macroscopic degrees of freedom that (1) encode everything relevant to memory and cognition, (2) can be accurately modeled as performing a classical digital computation, and (3) &ldquo;notice&rdquo; the microscopic, quantum-mechanical degrees of freedom at most as pure random number sources, generating noise according to prescribed probability distributions? Or is such a clean separation between the macroscopic and microscopic levels unavailable&mdash;so that any attempt to clone a brain would either miss much of the cognitively-relevant information, or else violate the No-Cloning Theorem? In my opinion, neither answer to the question should make us wholly comfortable: if it does, then we haven&rsquo;t sufficiently thought through the implications!\"</p>\n<p>In a world where a cloning device is possible the indexical questions \"would no longer be metaphysical conundrums, but in some sense, just straightforward empirical questions about what you should expect to observe!\"</p>\n<p>p.69. Reason and mysticism. \"but what do I really think?\" \"in laying out my understanding of the various alternatives&mdash;yes, brain states might be perfectly clonable, but if we want to avoid the philosophical weirdness that such cloning would entail, &nbsp;[...] I don&rsquo;t have any sort of special intuition [...]. The arguments exhaust my intuition.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nBCLy89Nqd8ouR6XT": 1, "5f5c37ee1b5cdee568cfb1b8": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NnzYPN7mHDQ7hpeTc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 30, "extendedScore": null, "score": 8.1e-05, "legacy": true, "legacyId": "22975", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 83, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uNn4kRYCat9oqKsGT", "SgGYcTmtLMu4rYnY9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-17T11:59:00.790Z", "modifiedAt": null, "url": null, "title": "Meetup : [Moscow] How to use your brain", "slug": "meetup-moscow-how-to-use-your-brain", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AnST4fj8ctnT62sRn/meetup-moscow-how-to-use-your-brain", "pageUrlRelative": "/posts/AnST4fj8ctnT62sRn/meetup-moscow-how-to-use-your-brain", "linkUrl": "https://www.lesswrong.com/posts/AnST4fj8ctnT62sRn/meetup-moscow-how-to-use-your-brain", "postedAtFormatted": "Monday, June 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BMoscow%5D%20How%20to%20use%20your%20brain&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BMoscow%5D%20How%20to%20use%20your%20brain%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAnST4fj8ctnT62sRn%2Fmeetup-moscow-how-to-use-your-brain%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BMoscow%5D%20How%20to%20use%20your%20brain%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAnST4fj8ctnT62sRn%2Fmeetup-moscow-how-to-use-your-brain", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAnST4fj8ctnT62sRn%2Fmeetup-moscow-how-to-use-your-brain", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 183, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nv'>[Moscow] How to use your brain</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 June 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>How to be raise awareness when it is useful.</p></li>\n<li><p>How to make rational choice \u2014 one approach.</p></li>\n<li><p>Game session: the Liar's dice or the Resistance.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.\nReports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nv'>[Moscow] How to use your brain</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AnST4fj8ctnT62sRn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2354067717171715e-06, "legacy": true, "legacyId": "22982", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Moscow__How_to_use_your_brain\">Discussion article for the meetup : <a href=\"/meetups/nv\">[Moscow] How to use your brain</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 June 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 15:45 MSK with \u201cLW\u201d sign. And we will also check the entrance at 16:00 and 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>How to be raise awareness when it is useful.</p></li>\n<li><p>How to make rational choice \u2014 one approach.</p></li>\n<li><p>Game session: the Liar's dice or the Resistance.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.\nReports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html\">here, in Russian</a>, now with photos</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Moscow__How_to_use_your_brain1\">Discussion article for the meetup : <a href=\"/meetups/nv\">[Moscow] How to use your brain</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Moscow] How to use your brain", "anchor": "Discussion_article_for_the_meetup____Moscow__How_to_use_your_brain", "level": 1}, {"title": "Discussion article for the meetup : [Moscow] How to use your brain", "anchor": "Discussion_article_for_the_meetup____Moscow__How_to_use_your_brain1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-17T18:26:28.960Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, June 1-30", "slug": "group-rationality-diary-june-1-30", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.207Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DTg6Y5x4MbgqEFAJr/group-rationality-diary-june-1-30", "pageUrlRelative": "/posts/DTg6Y5x4MbgqEFAJr/group-rationality-diary-june-1-30", "linkUrl": "https://www.lesswrong.com/posts/DTg6Y5x4MbgqEFAJr/group-rationality-diary-june-1-30", "postedAtFormatted": "Monday, June 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20June%201-30&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20June%201-30%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDTg6Y5x4MbgqEFAJr%2Fgroup-rationality-diary-june-1-30%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20June%201-30%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDTg6Y5x4MbgqEFAJr%2Fgroup-rationality-diary-june-1-30", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDTg6Y5x4MbgqEFAJr%2Fgroup-rationality-diary-june-1-30", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 236, "htmlBody": "<p>T<span style=\"color: #333333;\">his is the public group instrumental rationality diary for June 1-30; it's going up pretty late (sorry!) but entries for earlier in June are welcome.<br /></span></p>\n<blockquote style=\"font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\"><span style=\"color: #333333;\">It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/hg0/group_rationality_diary_may_1631/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating!</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/discussion/lw/hvy/group_rationality_diary_july_115/\">Next diary</a> -- July 1-15<a href=\"/r/discussion/lw/hvy/group_rationality_diary_july_115/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/discussion/lw/hg0/group_rationality_diary_may_1631/\">Immediate past diary</a> -- May 16-31<a href=\"/r/discussion/lw/hg0/group_rationality_diary_may_1631/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality Diaries archive</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DTg6Y5x4MbgqEFAJr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.23570268878949e-06, "legacy": true, "legacyId": "22983", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QXYsonygGQRc6fjJy", "nMP2mcg58k9zsZjv9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-17T23:31:37.478Z", "modifiedAt": null, "url": null, "title": "Learning programming: so I've learned the basics of Python, what next?", "slug": "learning-programming-so-i-ve-learned-the-basics-of-python", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:35.067Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ChrisHallquist", "createdAt": "2011-05-25T19:16:15.462Z", "isAdmin": false, "displayName": "ChrisHallquist"}, "userId": "wvT2xWQqHKxkp9NWN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dPnyk6HG3fRpstQ4d/learning-programming-so-i-ve-learned-the-basics-of-python", "pageUrlRelative": "/posts/dPnyk6HG3fRpstQ4d/learning-programming-so-i-ve-learned-the-basics-of-python", "linkUrl": "https://www.lesswrong.com/posts/dPnyk6HG3fRpstQ4d/learning-programming-so-i-ve-learned-the-basics-of-python", "postedAtFormatted": "Monday, June 17th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Learning%20programming%3A%20so%20I've%20learned%20the%20basics%20of%20Python%2C%20what%20next%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALearning%20programming%3A%20so%20I've%20learned%20the%20basics%20of%20Python%2C%20what%20next%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdPnyk6HG3fRpstQ4d%2Flearning-programming-so-i-ve-learned-the-basics-of-python%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Learning%20programming%3A%20so%20I've%20learned%20the%20basics%20of%20Python%2C%20what%20next%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdPnyk6HG3fRpstQ4d%2Flearning-programming-so-i-ve-learned-the-basics-of-python", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdPnyk6HG3fRpstQ4d%2Flearning-programming-so-i-ve-learned-the-basics-of-python", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<p>Lots of people (particularly people associated with LessWrong) are telling me I should become a computer programmer; in response I've taught myself a little Python using <a href=\"http://cscircles.cemc.uwaterloo.ca/\">this site</a>, written a couple Python scripts on my own, and just now sent in an application to <a href=\"http://www.appacademy.io/#p-home\">App Academy</a>. But if I don't end up going to App Academy, what's the best way to develop some actually marketable programming skills? I've heard people recommending getting involved in open source projects on <a href=\"https://github.com/\">Git Hub</a>, but when I looked at Git Hub I found it overwhelming, with no idea of how to find a suitable project to work on. Advice?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dPnyk6HG3fRpstQ4d", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 12, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "22984", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 69, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-18T14:40:36.167Z", "modifiedAt": null, "url": null, "title": "Is our continued existence evidence that Mutually Assured Destruction worked?", "slug": "is-our-continued-existence-evidence-that-mutually-assured", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.687Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9miMdHERJFjQDp5uq/is-our-continued-existence-evidence-that-mutually-assured", "pageUrlRelative": "/posts/9miMdHERJFjQDp5uq/is-our-continued-existence-evidence-that-mutually-assured", "linkUrl": "https://www.lesswrong.com/posts/9miMdHERJFjQDp5uq/is-our-continued-existence-evidence-that-mutually-assured", "postedAtFormatted": "Tuesday, June 18th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20our%20continued%20existence%20evidence%20that%20Mutually%20Assured%20Destruction%20worked%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20our%20continued%20existence%20evidence%20that%20Mutually%20Assured%20Destruction%20worked%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9miMdHERJFjQDp5uq%2Fis-our-continued-existence-evidence-that-mutually-assured%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20our%20continued%20existence%20evidence%20that%20Mutually%20Assured%20Destruction%20worked%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9miMdHERJFjQDp5uq%2Fis-our-continued-existence-evidence-that-mutually-assured", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9miMdHERJFjQDp5uq%2Fis-our-continued-existence-evidence-that-mutually-assured", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 392, "htmlBody": "<p>The standard view of <a href=\"http://en.wikipedia.org/wiki/Mutual_assured_destruction\">Mutually Assured Distruction</a> (MAD) is something like:</p>\n<blockquote>During the cold war the US and USSR had weapons capable of immense destruction, but no matter how tense things got they never used them because they knew how bad that would be. While MAD is a terrifying thing, it did work, this time.</blockquote>\n<p>Occasionally people will reply with an argument like:</p>\n<blockquote>If <a href=\"http://en.wikipedia.org/wiki/Cuban_missile_crisis\">any</a> of <a href=\"http://en.wikipedia.org/wiki/Stanislav_Petrov#The_incident\">several</a> <a href=\"http://www.gwu.edu/~nsarchiv/nukevault/ebb371/\">near</a>-<a href=\"http://en.wikipedia.org/wiki/Volk_Field_Air_National_Guard_Base#Bear_incident\">miss</a> <a href=\"https://www.wagingpeace.org/articles/1998/01/00_phillips_20-mishaps.php\">incidents</a> had gone even slightly differently, both sides would have launched their missiles and we wouldn't be here today looking back. In a sense this was an experiment where the only outcome we could observe was success: nukes would have meant no observers, no nukes and we're still here. So we don't actually know how useful MAD was.</blockquote>\n<p>This is an <a href=\"https://en.wikipedia.org/wiki/Anthropic_principle\">anthropic argument</a>, an attempt to handle the <a href=\"https://en.wikipedia.org/wiki/Selection_bias\">bias</a> that comes from a link between outcomes and the number of people who can observe them. Imagine we were trying to figure out whether flipping \"heads\" was more likely than flipping \"tails\", but there was a coin demon that killed everyone if \"tails\" came up. Either we would see \"heads\" flipped, or we would see nothing at all. We're not able to sample from the \"tails: everyone-dies\" worlds. Even if the demon responds to tails by killing everyone only 40% of the time, we're still going to over-sample the happy-heads outcome.</p>\n<p>Applying the anthropic principle here, however, requires that a failure of MAD really would have killed everyone. While it would have killed billions, and made major parts of the world uninhabitable, still many people would have survived. [1] How much would we have rebuilt? What would be the population now? If the cold war had gone hot and the US and USSR had fallen into wiping each other out, what would 2013 be like? Roughly, we're oversampling the no-nukes outcome by the ratio of our current population to the population there would have been in a yes-nukes outcome, and the less lopsided that ratio is the more evidence that MAD did work after all.</p>\n<p><br /> [1] For this wikipedia cites: <a href=\"http://www.bmartin.cc/pubs/82cab/index.html\">The global health effects of nuclear war</a> (1982), <a href=\"http://trove.nla.gov.au/work/21437545?selectedversion=NBD238850\">Long-term worldwide effects of multiple nuclear-weapons detonations</a> (1975). Some looking online also turns up an <a href=\"http://www.acceleratingfuture.com/michael/blog/2010/04/dispelling-stupid-myths-about-nuclear-war/\">Accelerating Future</a> blog post. I haven't read them thoroughly, and I don't know much about the research here.</p>\n<p><em><small>I also posted this <a href=\"http://www.jefftk.com/news/2013-06-18\">on my blog</a></small></em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9miMdHERJFjQDp5uq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 12, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "22995", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T01:55:05.775Z", "modifiedAt": null, "url": null, "title": "Why do theists, undergrads, and Less Wrongers favor one-boxing on Newcomb?", "slug": "why-do-theists-undergrads-and-less-wrongers-favor-one-boxing", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:30.898Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CarlShulman", "createdAt": "2009-03-01T07:47:12.225Z", "isAdmin": false, "displayName": "CarlShulman"}, "userId": "SguegG9SFXaKTgJLq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5vmRXMxFLvSe2a9CM/why-do-theists-undergrads-and-less-wrongers-favor-one-boxing", "pageUrlRelative": "/posts/5vmRXMxFLvSe2a9CM/why-do-theists-undergrads-and-less-wrongers-favor-one-boxing", "linkUrl": "https://www.lesswrong.com/posts/5vmRXMxFLvSe2a9CM/why-do-theists-undergrads-and-less-wrongers-favor-one-boxing", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20do%20theists%2C%20undergrads%2C%20and%20Less%20Wrongers%20favor%20one-boxing%20on%20Newcomb%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20do%20theists%2C%20undergrads%2C%20and%20Less%20Wrongers%20favor%20one-boxing%20on%20Newcomb%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5vmRXMxFLvSe2a9CM%2Fwhy-do-theists-undergrads-and-less-wrongers-favor-one-boxing%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20do%20theists%2C%20undergrads%2C%20and%20Less%20Wrongers%20favor%20one-boxing%20on%20Newcomb%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5vmRXMxFLvSe2a9CM%2Fwhy-do-theists-undergrads-and-less-wrongers-favor-one-boxing", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5vmRXMxFLvSe2a9CM%2Fwhy-do-theists-undergrads-and-less-wrongers-favor-one-boxing", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 692, "htmlBody": "<p>Follow-up to: <a href=\"/r/discussion/lw/hpy/normative_uncertainty_in_newcombs_problem/\">Normative uncertainty in Newcomb's problem</a><br /><br /><strong>Philosophers and atheists break for two-boxing; theists and Less Wrong break for one-boxing</strong><br />Personally, I would one-box on&nbsp;<a href=\"http://en.wikipedia.org/wiki/Newcomb's_paradox\">Newcomb's Problem</a>.&nbsp;Conditional on one-boxing for lawful reasons, one boxing earns $1,000,000, while two-boxing, conditional on two-boxing for lawful reasons, would deliver only a thousand. But this seems to be firmly a minority view in philosophy, and numerous heuristics about expert opinion suggest that I should re-examine the view.<br /><br />In the PhilPapers survey, Philosophy undergraduates start off divided roughly evenly between one-boxing and two-boxing:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">142 / 217 (65.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">40 / 217 (18.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">35 / 217 (16.1%)</td>\n</tr>\n</tbody>\n</table>\n<p>But philosophy faculty, who have learned more (less likely to have no opinion), and been subject to further selection, break in favor of two-boxing:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">441 / 931 (47.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">292 / 931 (31.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">198 / 931 (21.3%)<br /><br /></td>\n</tr>\n</tbody>\n</table>\n<p>Specialists in decision theory (who are also more atheistic, more compatibilist about free will, and more physicalist than faculty in general) are even more convinced:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">19 / 31 (61.3%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">8 / 31 (25.8%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">4 / 31 (12.9%)</td>\n</tr>\n</tbody>\n</table>\n<p>Looking at the <a href=\"http://philpapers.org/surveys/linear_most_with.pl?A=main:Newcomb's%20problem:one%20box#main\">correlates</a> of answers about Newcomb's problem, two-boxers are more likely to believe in physicalism about consciousness, atheism about religion, and other positions generally popular around here (which are also usually, but not always, in the direction of philosophical opinion). Zooming in one correlate, most theists with an opinion are one-boxers, while atheists break for two-boxing:</p>\n<table style=\"color: #000000; font-family: Arial, Verdana; font-size: 12.800000190734863px;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; background-color: #eeeeee;\"><a style=\"color: #104bb8; text-decoration: none;\" href=\"http://philpapers.org/surveys/linear_most_with.pl?A=main%3ANewcomb%27s%20problem%3Aone%20box\">Newcomb's problem:two boxes</a></td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; background-color: #eeeeee;\">0.125</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" colspan=\"2\">\n<table style=\"padding-left: 10px;\" border=\"0\" cellpadding=\"2\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">&nbsp;</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">two boxes</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">atheism</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">28.6%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(145/506)</td>\n</tr>\n</tbody>\n</table>\n</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">48.8%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(247/506)</td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">theism</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">40.8%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(40/98)</td>\n</tr>\n</tbody>\n</table>\n</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">31.6%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(31/98)</td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n<div style=\"padding-left: 14px; font-size: smaller; margin-bottom: 10px;\">Response pairs: 655 &nbsp; p-value: 0.001</div>\n</td>\n</tr>\n</tbody>\n</table>\n<p>Less Wrong breaks overwhelmingly for one-boxing in&nbsp;<a style=\"font-size: 13px; color: #8a8a8b; font-family: sans-serif; line-height: 19.1875px; text-align: justify;\" href=\"/lw/fp5/2012_survey_results/\">survey</a><span style=\"font-size: 13px; font-family: sans-serif; line-height: 19.1875px; text-align: justify;\">&nbsp;answers for 2012:</span><br /><br style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px; text-align: justify;\" /><strong style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">NEWCOMB'S PROBLEM</strong><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\" /><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">One-box: 726, 61.4%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\" /><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Two-box: 78, 6.6%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\" /><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Not sure: 53, 4.5%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\" /><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Don't understand: 86, 7.3%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\" /><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">No answer: 240, 20.3%</span></p>\n<p>When I elicited LW confidence levels in a <a href=\"/r/discussion/lw/hpy/normative_uncertainty_in_newcombs_problem/969i\">poll</a>, a majority indicated 99%+ confidence in one-boxing, and 77% of respondents indicated 80%+ confidence.<br /><br /><strong>What's going on?</strong><br /><br />I would like to understand what is driving this difference of opinion. My poll was a (weak) test of the hypothesis that Less Wrongers were more likely to account for uncertainty about decision theory: since on the standard Newcomb's problem one-boxers get $1,000,000, while two-boxers get $1,000, even a modest credence in the correct theory recommending one-boxing could justify the action of one-boxing. <br /><br />If new graduate students read the computer science literature on <a href=\"http://mechroom.technion.ac.il/~moshet/progeqnote4.pdf\">program equilibrium</a>, including some local contributions like <a href=\"/lw/hmw/robust_cooperation_in_the_prisoners_dilemma/\">Robust Cooperation in the Prisoner's Dilemma</a>&nbsp;and&nbsp;<a href=\"http://intelligence.org/files/Comparison.pdf\">A Comparison of Decision Algorithms on Newcomblike Problems</a>, I would guess they would tend to shift more towards one-boxing. Thinking about what sort of decision algorithms it is rational to program, or what decision algorithms would prosper over numerous <a href=\"/r/lesswrong/lw/hmx/prisoners_dilemma_with_visible_source_code/\">one-shot Prisoner's Dilemmas with visible source code</a>, could also shift intuitions. A number of philosophers I have spoken with have indicated that frameworks like the use of causal models with nodes for logical uncertainty are meaningful contributions to thinking about decision theory. However, I doubt that for those with opinions, the balance would swing from almost 3:1 for two-boxing to 9:1 for one-boxing, even concentrating on new decision theory graduate students.<br /><br />On the other hand, there may be an effect of unbalanced presentation to non-experts.&nbsp;Less Wrong is on average less philosophically sophisticated than professional philosophers.&nbsp;Since philosophical training is associated with a shift towards two-boxing, some of the difference in opinion could reflect a difference in training. Then,&nbsp;postings on decision theory have almost all either argued for or assumed one-boxing as the correct response on Newcomb's problem. It might be that if academic decision theorists were making arguments for two-boxing here, or if there was a reduction in pro one-boxing social pressure, there would be a shift in Less Wrong opinion towards two-boxing.<br /><br />Less Wrongers, what's going on here? What are the relative causal roles of these and other factors in this divergence?<br /><br />ETA: The SEP <a href=\"http://plato.stanford.edu/entries/decision-causal/#NewPro\">article</a> on Causal Decision Theory.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fihKHQuS5WZBJgkRm": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5vmRXMxFLvSe2a9CM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 25, "extendedScore": null, "score": 6.2e-05, "legacy": true, "legacyId": "22996", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Follow-up to: <a href=\"/r/discussion/lw/hpy/normative_uncertainty_in_newcombs_problem/\">Normative uncertainty in Newcomb's problem</a><br><br><strong>Philosophers and atheists break for two-boxing; theists and Less Wrong break for one-boxing</strong><br>Personally, I would one-box on&nbsp;<a href=\"http://en.wikipedia.org/wiki/Newcomb's_paradox\">Newcomb's Problem</a>.&nbsp;Conditional on one-boxing for lawful reasons, one boxing earns $1,000,000, while two-boxing, conditional on two-boxing for lawful reasons, would deliver only a thousand. But this seems to be firmly a minority view in philosophy, and numerous heuristics about expert opinion suggest that I should re-examine the view.<br><br>In the PhilPapers survey, Philosophy undergraduates start off divided roughly evenly between one-boxing and two-boxing:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\" id=\"Newcomb_s_problem__one_box_or_two_boxes_\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">142 / 217 (65.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">40 / 217 (18.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">35 / 217 (16.1%)</td>\n</tr>\n</tbody>\n</table>\n<p>But philosophy faculty, who have learned more (less likely to have no opinion), and been subject to further selection, break in favor of two-boxing:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\" id=\"Newcomb_s_problem__one_box_or_two_boxes_1\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">441 / 931 (47.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">292 / 931 (31.4%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">198 / 931 (21.3%)<br><br></td>\n</tr>\n</tbody>\n</table>\n<p>Specialists in decision theory (who are also more atheistic, more compatibilist about free will, and more physicalist than faculty in general) are even more convinced:</p>\n<h3 style=\"margin-top: 0px; padding-top: 0px; font-size: 14px; color: #10a010; font-family: Arial, Verdana;\" id=\"Newcomb_s_problem__one_box_or_two_boxes_2\">Newcomb's problem: one box or two boxes?</h3>\n<table style=\"font-family: Arial, Verdana;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: two boxes</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">19 / 31 (61.3%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Accept or lean toward: one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">8 / 31 (25.8%)</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">Other</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">4 / 31 (12.9%)</td>\n</tr>\n</tbody>\n</table>\n<p>Looking at the <a href=\"http://philpapers.org/surveys/linear_most_with.pl?A=main:Newcomb's%20problem:one%20box#main\">correlates</a> of answers about Newcomb's problem, two-boxers are more likely to believe in physicalism about consciousness, atheism about religion, and other positions generally popular around here (which are also usually, but not always, in the direction of philosophical opinion). Zooming in one correlate, most theists with an opinion are one-boxers, while atheists break for two-boxing:</p>\n<table style=\"color: #000000; font-family: Arial, Verdana; font-size: 12.800000190734863px;\" border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; background-color: #eeeeee;\"><a style=\"color: #104bb8; text-decoration: none;\" href=\"http://philpapers.org/surveys/linear_most_with.pl?A=main%3ANewcomb%27s%20problem%3Aone%20box\">Newcomb's problem:two boxes</a></td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; background-color: #eeeeee;\">0.125</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" colspan=\"2\">\n<table style=\"padding-left: 10px;\" border=\"0\" cellpadding=\"2\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">&nbsp;</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana; padding-right: 10px;\">one box</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">two boxes</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">atheism</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">28.6%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(145/506)</td>\n</tr>\n</tbody>\n</table>\n</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">48.8%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(247/506)</td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">theism</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">40.8%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(40/98)</td>\n</tr>\n</tbody>\n</table>\n</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">\n<table border=\"0\">\n<tbody>\n<tr>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\" width=\"30px\">31.6%</td>\n<td style=\"font-size: 13px; font-family: Arial, Verdana;\">(31/98)</td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n</tbody>\n</table>\n<div style=\"padding-left: 14px; font-size: smaller; margin-bottom: 10px;\">Response pairs: 655 &nbsp; p-value: 0.001</div>\n</td>\n</tr>\n</tbody>\n</table>\n<p>Less Wrong breaks overwhelmingly for one-boxing in&nbsp;<a style=\"font-size: 13px; color: #8a8a8b; font-family: sans-serif; line-height: 19.1875px; text-align: justify;\" href=\"/lw/fp5/2012_survey_results/\">survey</a><span style=\"font-size: 13px; font-family: sans-serif; line-height: 19.1875px; text-align: justify;\">&nbsp;answers for 2012:</span><br><br style=\"font-family: sans-serif; font-size: 13px; line-height: 19.1875px; text-align: justify;\"><strong style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">NEWCOMB'S PROBLEM</strong><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">One-box: 726, 61.4%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Two-box: 78, 6.6%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Not sure: 53, 4.5%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Don't understand: 86, 7.3%</span><br style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><span style=\"text-align: justify; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">No answer: 240, 20.3%</span></p>\n<p>When I elicited LW confidence levels in a <a href=\"/r/discussion/lw/hpy/normative_uncertainty_in_newcombs_problem/969i\">poll</a>, a majority indicated 99%+ confidence in one-boxing, and 77% of respondents indicated 80%+ confidence.<br><br><strong>What's going on?</strong><br><br>I would like to understand what is driving this difference of opinion. My poll was a (weak) test of the hypothesis that Less Wrongers were more likely to account for uncertainty about decision theory: since on the standard Newcomb's problem one-boxers get $1,000,000, while two-boxers get $1,000, even a modest credence in the correct theory recommending one-boxing could justify the action of one-boxing. <br><br>If new graduate students read the computer science literature on <a href=\"http://mechroom.technion.ac.il/~moshet/progeqnote4.pdf\">program equilibrium</a>, including some local contributions like <a href=\"/lw/hmw/robust_cooperation_in_the_prisoners_dilemma/\">Robust Cooperation in the Prisoner's Dilemma</a>&nbsp;and&nbsp;<a href=\"http://intelligence.org/files/Comparison.pdf\">A Comparison of Decision Algorithms on Newcomblike Problems</a>, I would guess they would tend to shift more towards one-boxing. Thinking about what sort of decision algorithms it is rational to program, or what decision algorithms would prosper over numerous <a href=\"/r/lesswrong/lw/hmx/prisoners_dilemma_with_visible_source_code/\">one-shot Prisoner's Dilemmas with visible source code</a>, could also shift intuitions. A number of philosophers I have spoken with have indicated that frameworks like the use of causal models with nodes for logical uncertainty are meaningful contributions to thinking about decision theory. However, I doubt that for those with opinions, the balance would swing from almost 3:1 for two-boxing to 9:1 for one-boxing, even concentrating on new decision theory graduate students.<br><br>On the other hand, there may be an effect of unbalanced presentation to non-experts.&nbsp;Less Wrong is on average less philosophically sophisticated than professional philosophers.&nbsp;Since philosophical training is associated with a shift towards two-boxing, some of the difference in opinion could reflect a difference in training. Then,&nbsp;postings on decision theory have almost all either argued for or assumed one-boxing as the correct response on Newcomb's problem. It might be that if academic decision theorists were making arguments for two-boxing here, or if there was a reduction in pro one-boxing social pressure, there would be a shift in Less Wrong opinion towards two-boxing.<br><br>Less Wrongers, what's going on here? What are the relative causal roles of these and other factors in this divergence?<br><br>ETA: The SEP <a href=\"http://plato.stanford.edu/entries/decision-causal/#NewPro\">article</a> on Causal Decision Theory.</p>", "sections": [{"title": "Newcomb's problem: one box or two boxes?", "anchor": "Newcomb_s_problem__one_box_or_two_boxes_", "level": 1}, {"title": "Newcomb's problem: one box or two boxes?", "anchor": "Newcomb_s_problem__one_box_or_two_boxes_1", "level": 1}, {"title": "Newcomb's problem: one box or two boxes?", "anchor": "Newcomb_s_problem__one_box_or_two_boxes_2", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "300 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 300, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6k4Fzdxpz25foiTCc", "x9FNKTEt68Rz6wQ6P", "iQWk5jYeDg5ACCmpx", "BY8kvyuLzMZJkwTHL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T04:07:36.931Z", "modifiedAt": null, "url": null, "title": "X-Risk Roll Call ", "slug": "x-risk-roll-call", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.339Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qsBj63MjuqYMFoFs3/x-risk-roll-call", "pageUrlRelative": "/posts/qsBj63MjuqYMFoFs3/x-risk-roll-call", "linkUrl": "https://www.lesswrong.com/posts/qsBj63MjuqYMFoFs3/x-risk-roll-call", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20X-Risk%20Roll%20Call%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AX-Risk%20Roll%20Call%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqsBj63MjuqYMFoFs3%2Fx-risk-roll-call%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=X-Risk%20Roll%20Call%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqsBj63MjuqYMFoFs3%2Fx-risk-roll-call", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqsBj63MjuqYMFoFs3%2Fx-risk-roll-call", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1312, "htmlBody": "<p>I'm working on a substantial research piece concerned with x-risk, and a sub-task of that involves compiling a list of important people in the field along with a brief summary of their education and relevant links. &nbsp;I realized that such a list might be a useful bit of meta-scholarship on its own, so I'm posting an <strong>incomplete</strong> version of it here in case anyone thinks there are people I should add. I haven't tracked down all the cv's and personal websites yet but I'd like to get the feedback ball rolling. &nbsp;After the LW crowd has given me any criticisms it thinks are relevant, I'll polish the list up. &nbsp;&nbsp;</p>\n<p>The focus is on researchers in x-risk and related fields, so I'm not including, say, <em>every</em>&nbsp;machine intelligence researcher, just the ones who, as far as I can tell, show an awareness of the possible existential impact of their work. &nbsp;In practice this means those who are affiliated with x-risk reduction groups like the Future of Humanity Institute or MIRI, or ones who've specifically written on x-risk. &nbsp;No, that's not quite fair, but I needed some heuristic for narrowing down the list, and my mind is open if anyone has a better idea. &nbsp;</p>\n<p>And yes, this is mostly information that's available with a little Googling (though a few people were hard to track down). &nbsp;But this list, when completed, will allow any interested person to quickly see the educational pathways taken by a large number of x-risk researchers. &nbsp;I'm compiling this information as opposed to, say, current position or research interests because the former is more relevant to the bigger project I'm working on, the latter is more likely to change, and besides Googling is easy if you're only interested in a handful of people. &nbsp;But if there <em>is</em>&nbsp;demand for a more thorough and comprehensive document, I could also put that together. &nbsp;</p>\n<p>I've erred on the side of inclusion, which means I included people even if they were interns or associates as opposed to primary researchers. &nbsp;Of course I intend to finish this on my own, but if anyone just <em>wants</em>&nbsp;to help, let me know. &nbsp;</p>\n<p>Who did I miss? &nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">Associated with the Future of Humanity Institute and the Machine Intelligence Research Institute:</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span id=\"docs-internal-guid-334624cd-8360-f4ec-abd0-953bf71b5be8\"><br /></span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Eliezer Yudkowsky</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;extremely high mathematical talent with a strong philosophical bent.</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://en.wikipedia.org/wiki/Eliezer_Yudkowsky\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">wiki</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Robin Hanson</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BS physics (University of California, Irvine)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in physics/philosophy of science (University of Chicago)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in Social Science (California Institute of Technology). &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://hanson.gmu.edu/vita.html\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">cv</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Nick Bostrom</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BA in philosophy, mathematics, mathematical logic, and artificial intelligence (University of Gotenberg)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MA in philosophy, physics (University of Stockholm)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MSc computational neuroscience (King's College, London)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in philosophy (London School of economics) &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.nickbostrom.com/cv.pdf\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">cv</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.nickbostrom.com/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal website</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Luke Muehlhauser</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;studied psychology (University of Minnesota) &nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://lukeprog.com/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal website</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Stuart Armstrong</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;PhD in mathematics (Oxford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://blog.practicalethics.ox.ac.uk/author/stuart-armstrong/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">blog</span></a><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> (not personal)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Anders Sandberg</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in computer science (Stockholm University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in computational neuroscience (Stockholm University) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.aleph.se/andart/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal blog</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Toby Ord</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Bachelor's degrees in computer science, mathematics, and &nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;philosophy (University of Melbourne)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in philosophy (Balliol College &amp; Christ Church, University of Oxford) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.amirrorclear.net/academic/toby-ord-cv.pdf\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">cv</span></a><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://amirrorclear.net/academic/index.html\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal site</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Daniel Dewey</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BS in Computer Science, Philosophy (Carnegie Mellon University) &nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px 0pt 36pt; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.danieldewey.net/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal website</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.danieldewey.net/dewey-cv.pdf\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">cv</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Ben Goertzel</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;BA in Mathematics (Simon's Rock College)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;PhD in Mathematics (Temple University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://goertzel.org/Goertzel_CV.pdf\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">cv</span></a><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Carl Shulman</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;BA in philosophy (Harvard)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;J.D. (New York University School of Law) &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://wiki.lesswrong.com/wiki/Carl_Shulman\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">LW wiki</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Anna Salamon</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background: &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Bachelor's in Mathematics (University of California Santa Barbara)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://annasalamon.com/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal website</span></a><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Nick Beckstead </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;BA in philosophy and mathematics (University of Minnesota) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;PhD philosophy (Rutgers) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"https://sites.google.com/site/nbeckstead/cv-1\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal website/cv</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Carl Frey</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;M.Sc. in Business &amp; Economics</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;PhD in Economics (Technische Universit&auml;t Berlin)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.oxfordmartin.ox.ac.uk/people/453\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">website</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Milan Circovik</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Background:</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;BS. in theoretical physics (university of Belgrade)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;MS in Earth and Space Sciences (University of New York, Stony Brook)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;PhD in physics (University of New York, Stony Brook) &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.fhi.ox.ac.uk/about/staff/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">professional information</span></a><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Guy Kahane</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Bachelors in philosophy (Oxford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in philosophy (Oxford) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Vincent M&uuml;ller</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;studied philosophy with cognitive science, linguistics and history (Marburg, Hamburg, London, Oxford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.sophia.de/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">personal website</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Erik Drexler</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: BS in interdisciplinary science (MIT)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in Astro/Aerospace engineering (MIT)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD (MIT) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /><span style=\"background-color: transparent; font-family: Arial; font-size: 13px; font-weight: bold; white-space: pre-wrap; line-height: 1.5;\">Se&aacute;n &Oacute; h&Eacute;igeartaig &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;B.A. Human Genetics (Trinity College, Dublin)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;PhD in molecular genetics (Trinity College, Dublin) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Louie Helm</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background:</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;MS in Computer Science (University of Texas, Austin)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Malo Bourgon</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MS in engineering (University of Guelph, Ontario)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Alex Altair</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;studied physics and mathematics (Maine school of science and mathematics)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Mihaly Barasz</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in Mathematics (Eotvos Lorand University, Budapest)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Paul Christiano</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Bachelors in Mathematics (MIT) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Benja Fallenstein &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BSc in mathematics (University of Vienna)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;working on PhD in mathematics (Bristol University, U.K.))</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Joshua Fox</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background:</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BA mathematics (Brandeis)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD (Harvard)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /><span style=\"background-color: transparent; font-family: Arial; font-size: 13px; font-weight: bold; white-space: pre-wrap; line-height: 1.5;\">Anja Heinisch</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS, major in math, minor computer science (university of &nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Braunschweig, Germany)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Marcello Herreshoff</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BA in mathematics (Stanford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;High performance in mathematics competitions</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Bill Hibbard</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;BA in mathematics (University of Wisconsin, Madison)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;MS in computer science (University of Wisconsin, Madison)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;PhD in computer science (University of Wisconsin, Madison)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Patrick LaVictoire</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AB in mathematics (University of Chicago)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PhD in mathematics (University of California, Berkeley) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Vladimir Nesov</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in applied mathematics and physics (Moscow institute of physics and technology)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Steve Rayhawk</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;degree in mathematics (UC Santa Barbara college of creative studies)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Nisan Stiennon</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;BS in mathematics and physics (University of Michigan) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;PhD in mathematics (Stanford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Kaj Sotala &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BA in Cognitive Science with a minor in Computer Science (University of Helsinki)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;working on MSc in Computer Science, minor in Mathematics (University of &nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Helsinki)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">p</span><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://kajsotala.fi/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">ersonal website</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://kajsotala.fi/\"></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">James Miller </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;BA (Wesleyan University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;MA in economics (Yale University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;J.D (Stanford Law School)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;PhD in economics (University of Chicago) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify; text-indent: 36pt;\" dir=\"ltr\"><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://sophia.smith.edu/~jdmiller/resume.pdf\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">cv</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://sophia.smith.edu/~jdmiller/resume.pdf\"></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Qiaochu Yuan</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.Sc. in mathematics (MIT)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Michael Vassar</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S (Penn State)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.B.A (Drexel University) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">Associated with the Global Catastrophic Risk Institute: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Seth Baum</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BS in applied mathematics and optics (University of Rochester)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in electrical engineering (Northeastern University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in Geography (Pennsylvania State University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Tony Barrett</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BS in chemical engineering (University of California)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in engineering and public policy (Carnegie Mellon University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Grant Wilson</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BA in environmental policy (Western Washington University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;J.D. (Lewis and Clark law school)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">U. Tuncay Alparslan</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;BS in industrial engineering (University of Ankara, Turkey)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in operations research (Cornell)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in operations research (Cornell)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Robert de Neufville</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;AB in government (Harvard)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MS in political science (University of California, Berkeley)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Mark Fusco</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;BA in religious studies and english literature (University of Toronto)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;M.A.R in philosophical theology (Yale)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;S.T.L in moral theology (Pontifical Lateran University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Jacob Haqq-Misra</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;B.S. degrees in Astrophysics and Computer Science (University of Minnesota)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;M.S. in Meteorology (Pennsylvania State University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Ph.D. in Meteorology &amp; Astrobiology (Pennsylvania State University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Arden Rowell</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;B.A. in Anthropology/Archaeology (University of Washington)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;J.D. (University of Chicago Law School)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Jianhua Xu</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: &nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S. degree in Chemical Engineering and English (Dalian University &nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;of Technology) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.S. in Environmental Science (Peking University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Ph.D. in Engineering and Public Policy (Carnegie Mellon University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Kaitlin Butler</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background:</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in Sociology (Vassar College )</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.A. in Climate and Society (Columbia University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Tim Maher</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background:</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S. in Astrophysics (University of Missouri, St. Louis)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Kelly Hostetler</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S. in Political Science (Columbia University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Matt Moretto </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B.A. in History (Columbia University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">Associated with the </span><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://rationality.org/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">Center for Applied Rationality</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Julia Galef</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Bachelor's in Statistics (Columbia)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Michael Smith</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Master's in Mathematics (University of Oregon)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in Mathematics and Science Education (University of California, San Diego)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Andrew Critch</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;BSc in Mathematics</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;PhD in Mathematics (University of California, Berkeley)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Yan Zhang</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD in Mathematics (MIT)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Leah Libresco</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in Political Science (Yale)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Dan Keys</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Bachelor's in Mathematics and Statistics (Swathmore College)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Master's in Social Psychology (Cornell University) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /><br /><br /><span style=\"line-height: 1.5; font-size: 13px; font-family: Arial; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">Associated with the </span><a style=\"line-height: 1.5; color: #8a8a8b; text-decoration: none;\" href=\"http://www.skollglobalthreats.org/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">Skoll Global Threat Fund</span></a></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Larry Brilliant</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Undergraduate degree in philosophy (</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;MD (Wayne Medical School)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Master&rsquo;s of Public Health (</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Jane Bloch</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in Political Science (University of Washington)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Scott Field</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.A in Political Science (University of California, Berkeley)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.A. in International &amp; Area Studies (University of California, Berkeley)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;P.hD in Behavioral Ecology (University of Adelaide)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">David Kroodsma</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S. in Physics (Stanford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.S. in Earth Systems (Stanford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Sylvia Lee</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Bachelor&rsquo;s in Civil Engineering (McGill University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Master&rsquo;s in Environmental Engineering (M.I.T)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Bruce Lowry</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in International Relations (Pomona College)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.A. in International Affairs (Johns Hopkins school of Advanced International &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Studies)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><br /><span style=\"background-color: transparent; font-family: Arial; font-size: 13px; font-weight: bold; line-height: 1.5; white-space: pre-wrap;\">Amy Luers</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S. in environmental resources engineering (Humboldt University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.S. in environmental resources engineering (Humboldt University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.S. in international policy studies (Stanford)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Ph.D in environmental science (Stanford) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Annie Maxwell</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in English, Political Science (University of Michigan)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.A in public policy (University of Michigan)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Bessma Mourad</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in Environmental Studies (University of California, Santa Cruz)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.S. (energy and resources group, University of California, Berkeley) </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Jennifer Olsen</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Bachelor&rsquo;s in Biomathematics (Rutgers)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Master&rsquo;s in Public Health (George Washington University)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Certificate in Weapons of Mass Destruction (Uniformed Services University for </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;health sciences)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Ph.D (University of North Carolina, Chapel Hill)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Mark Smolinski</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.S. (University of Michigan, Ann Arbor)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;M.D. (University of Michigan, Ann Arbor)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Master&rsquo;s in Public Health (University of Arizona)</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Lindsay Steele</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;B.A. in economics and spanish (University of California, Santa </span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;Barbara)</span></p>\n<div><br /></div>\n<div><strong>&nbsp; &nbsp;</strong></div>\n<div><br /></div>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-style: italic; vertical-align: baseline; white-space: pre-wrap;\">Misc</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\">Shane Legg</span></p>\n<p style=\"margin: 0pt 0px; font-family: Arial, Helvetica, sans-serif; line-height: 1.5; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; font-weight: bold; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;</span><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">Background: &nbsp;MSc (University of Auckland)</span></p>\n<div><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\"> &nbsp;&nbsp;&nbsp;PhD (</span><a style=\"color: #8a8a8b; text-decoration: none;\" href=\"http://www.idsia.ch/\"><span style=\"font-size: 13px; font-family: Arial; color: #1155cc; background-color: transparent; vertical-align: baseline; white-space: pre-wrap; text-decoration: underline;\">IDSIA</span></a><span style=\"font-size: 13px; font-family: Arial; background-color: transparent; vertical-align: baseline; white-space: pre-wrap;\">, Switzlerand)</span><strong>&nbsp; &nbsp;&nbsp;</strong></div>\n<div><br /></div>\n<div><br /></div>\n<div><br /></div>\n<div>Probable sources of further information:</div>\n<div><br /></div>\n<div>Authors of papers from the <a href=\"http://sethbaum.com/research/gcr/bibliography.pdf\">Global Catastrophic Risks bibliography.</a></div>\n<div>Authors from the edited volume on <a href=\"http://www.amazon.com/Global-Catastrophic-Risks-Nick-Bostrom/dp/0199606501/ref=sr_1_1?ie=UTF8&amp;qid=1371614824&amp;sr=8-1&amp;keywords=Global+Catastrophic+risk\">Global Catastrophic Risk</a></div>\n<div>Many of the personnel from <a href=\"http://www.leverageresearch.org/tiki-index.php?page=Our+Team\">Leverage Research</a></div>\n<div><br /></div>\n<div><br /></div>\n<div>[<strong>Updated 6/28/13]</strong>&nbsp;names added, substantial formatting adjustments</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qsBj63MjuqYMFoFs3", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 10, "extendedScore": null, "score": 1.2372482973787607e-06, "legacy": true, "legacyId": "22974", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T14:05:13.523Z", "modifiedAt": null, "url": null, "title": "A Keynesian key insight ", "slug": "a-keynesian-key-insight", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.834Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2bd4DxyNpREdLRysx/a-keynesian-key-insight", "pageUrlRelative": "/posts/2bd4DxyNpREdLRysx/a-keynesian-key-insight", "linkUrl": "https://www.lesswrong.com/posts/2bd4DxyNpREdLRysx/a-keynesian-key-insight", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Keynesian%20key%20insight%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Keynesian%20key%20insight%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2bd4DxyNpREdLRysx%2Fa-keynesian-key-insight%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Keynesian%20key%20insight%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2bd4DxyNpREdLRysx%2Fa-keynesian-key-insight", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2bd4DxyNpREdLRysx%2Fa-keynesian-key-insight", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 650, "htmlBody": "<p>I've always found that learning new areas always goes a lot better if you start with a key insight of what the field is about. Often this is not presented or explained at the beginning of the course, and you have to deduce it later on.</p>\n<p>For instance, I would have better grasped the <a href=\"http://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit\">epsilon-delta definition</a> of a limit if the instructor had started with something like:</p>\n<ul>\n<li>Our intuitive definition of a limit is that as we get closer to this point, the function gets closer to this value. It has turned out to be very tricky to formalise this intuition, however. Early mathematicians used calculus without a good definition of limit, and their informal definitions led to a lot of paradoxes. The epsilon-delta definition is a bit clunky and may seem counter-intuitive, but it actually manages to capture our intuitive definition without paradoxes and problems - that's why we choose it, not for its elegance (though you will come to appreciate it). With that in mind, let's have a look at it...</li>\n</ul>\n<p>Similarly, I would have made more rapid progress with G&ouml;del's theorems if, before giving the formal definition of <a href=\"http://en.wikipedia.org/wiki/G%C3%B6del_numbering\">G&ouml;del numbering</a> and of the provability <a href=\"http://en.wikipedia.org/wiki/Modal_logic\">symbol</a> \u25a1, someone had clarified that direct <em>and indirect</em> self-reference was a problem. If a formal system of a certain complexity can talk about its own structure, even without \"realising\" that it's doing so, problems will arise. Some of my other key insights in the field can be found in my post <a href=\"/lw/93q/completeness_incompleteness_and_what_it_all_means/\">here</a>.<a id=\"more\"></a></p>\n<p>So when I do stumble upon a key insight, I want to share it. I've found some recently in Keynesian economics, giving me a much better grasp of what makes that economic theory tick, and which would be my point of entry should I ever study the subject in detail. The two key insights are:</p>\n<ol>\n<li>Keynesian models do not require irrationality. Unemployment can persist (in the model) even if every agent is completely rational.</li>\n<li>Hence theoretical macroeconomics really is different from theoretical microeconomics.</li>\n</ol>\n<p>Of course, Keynesianism makes great use of irrationality or partial rationality of the agents (such as the <a href=\"http://en.wikipedia.org/wiki/Sticky_(economics)\">stickiness</a> of wages or the irrationality of bubbles), but it was a revelation that rational models, full of <a href=\"http://en.wikipedia.org/wiki/Homo_economicus\">Homo Economicus</a>, could still produce excess unemployment.</p>\n<p>This seemed intuitively very odd. After all, if there is unemployment, wages should fall, making it more attractive to hire workers. Therefore the equilibrium should be that everyone who wanted to work at the wages available should work. And this is not only an equilibrium, but an attractor: free-floating wages should move the economy towards the equilibrium.</p>\n<p>But&nbsp;<a href=\"http://www.youtube.com/watch?v=VGB5H7ss4Vs\">this lecture</a>&nbsp;presented the rest of the argument. In a closed economy, investment (by firms) plus consumption (by individuals) must be equal to the total production of the economy - you can't sell stuff to thin air. Similarly, the amounts sold by firms translate into income for firms, shareholders and workers - you can't generate income without selling to someone. Over the short term, things can move out of equilibrium (people can increase or cash in their savings), but over the long term it has to balance.</p>\n<p>That equilibrium is also an attractor. So we have two equilibrium processes - the wage changes, and the consumptions plus investment equality. Notice, though, that they interact! As wages rise and fall, people's incomes rise and fall, and hence their consumption, which feeds through to the incomes of firms and hence to their own levels of investment and salaries...</p>\n<p>The question then, is whether there exists a joint equilibrium for both processes at once (more properly, since consumption consists of many markets, a <a href=\"http://en.wikipedia.org/wiki/General_equilibrium_theory\">general equilibrium</a> for the whole economy). We'd want an equilibrium that was also an attractor, since we'd want to move to that state. In some circumstances, such attracting joint equilibriums exist - but in others, <a href=\"http://en.wikipedia.org/wiki/Sonnenschein%E2%80%93Mantel%E2%80%93Debreu_theorem\">they don't</a>.</p>\n<p>So, at least in the model, excess unemployment can persist in the presence of fully rational agents.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2bd4DxyNpREdLRysx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 10, "extendedScore": null, "score": 1.2377059589776573e-06, "legacy": true, "legacyId": "22958", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MLqhJ8eDy5smbtGrf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T17:32:09.517Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham: Luminosity followup", "slug": "meetup-durham-luminosity-followup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "evand", "createdAt": "2012-05-14T16:45:50.150Z", "isAdmin": false, "displayName": "evand"}, "userId": "QSBopDfW3DLzeMG7L", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Y7ftsT7LtpoXpQYwT/meetup-durham-luminosity-followup", "pageUrlRelative": "/posts/Y7ftsT7LtpoXpQYwT/meetup-durham-luminosity-followup", "linkUrl": "https://www.lesswrong.com/posts/Y7ftsT7LtpoXpQYwT/meetup-durham-luminosity-followup", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%3A%20Luminosity%20followup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%3A%20Luminosity%20followup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY7ftsT7LtpoXpQYwT%2Fmeetup-durham-luminosity-followup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%3A%20Luminosity%20followup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY7ftsT7LtpoXpQYwT%2Fmeetup-durham-luminosity-followup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY7ftsT7LtpoXpQYwT%2Fmeetup-durham-luminosity-followup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 137, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nw'>Durham: Luminosity followup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 June 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Cocoa Cinnamon, 420 W Geer St., Durham NC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>A month ago or so we finished going through Alicorn's Luminosity sequence on Less Wrong. So, having done that and worked on Being Luminous for a month or two (or more), what conclusions did you draw?</p>\n\n<p>We'll meet for coffee and informal introductions at 7:00. On-topic conversation will run from 7:30-9:00.</p>\n\n<p>Please give some thought to what you learned (or didn't learn) from the luminosity meetups, and what impact it has had in the time period since.</p>\n\n<p>If you weren't around for all (or even any) of the Luminosity meetups, please feel free to come anyway! Bring some questions about it for people that were, if you like :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nw'>Durham: Luminosity followup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Y7ftsT7LtpoXpQYwT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 1.2378645024982403e-06, "legacy": true, "legacyId": "23006", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham__Luminosity_followup\">Discussion article for the meetup : <a href=\"/meetups/nw\">Durham: Luminosity followup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 June 2013 07:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Cocoa Cinnamon, 420 W Geer St., Durham NC</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>A month ago or so we finished going through Alicorn's Luminosity sequence on Less Wrong. So, having done that and worked on Being Luminous for a month or two (or more), what conclusions did you draw?</p>\n\n<p>We'll meet for coffee and informal introductions at 7:00. On-topic conversation will run from 7:30-9:00.</p>\n\n<p>Please give some thought to what you learned (or didn't learn) from the luminosity meetups, and what impact it has had in the time period since.</p>\n\n<p>If you weren't around for all (or even any) of the Luminosity meetups, please feel free to come anyway! Bring some questions about it for people that were, if you like :)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Durham__Luminosity_followup1\">Discussion article for the meetup : <a href=\"/meetups/nw\">Durham: Luminosity followup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham: Luminosity followup", "anchor": "Discussion_article_for_the_meetup___Durham__Luminosity_followup", "level": 1}, {"title": "Discussion article for the meetup : Durham: Luminosity followup", "anchor": "Discussion_article_for_the_meetup___Durham__Luminosity_followup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T18:40:52.782Z", "modifiedAt": null, "url": null, "title": "Giving Now Currently Seems to Beat Giving Later", "slug": "giving-now-currently-seems-to-beat-giving-later", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:31.213Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gKE8g5BqcMiGfKNo7/giving-now-currently-seems-to-beat-giving-later", "pageUrlRelative": "/posts/gKE8g5BqcMiGfKNo7/giving-now-currently-seems-to-beat-giving-later", "linkUrl": "https://www.lesswrong.com/posts/gKE8g5BqcMiGfKNo7/giving-now-currently-seems-to-beat-giving-later", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Giving%20Now%20Currently%20Seems%20to%20Beat%20Giving%20Later&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGiving%20Now%20Currently%20Seems%20to%20Beat%20Giving%20Later%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgKE8g5BqcMiGfKNo7%2Fgiving-now-currently-seems-to-beat-giving-later%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Giving%20Now%20Currently%20Seems%20to%20Beat%20Giving%20Later%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgKE8g5BqcMiGfKNo7%2Fgiving-now-currently-seems-to-beat-giving-later", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgKE8g5BqcMiGfKNo7%2Fgiving-now-currently-seems-to-beat-giving-later", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2332, "htmlBody": "<blockquote>\n<p><strong>Abstract: </strong>There is a debate between either donating now or donating later (investing, realizing the returns of one's investment, and donating in a lumpsum upon death). &nbsp;While donating later may be appropriate in some circumstances, right now we have the ability to donate now in order to <em>go meta</em> and recruit future donors who otherwise wouldn't have donated, thus adding more money than returns on investment.</p>\n</blockquote>\n<p>-</p>\n<h2>Introduction</h2>\n<p>Among those people interested in doing as much as they can to make the world a better place and think donating their money as effectively as possible is a good way to do that, there is a debate about whether one should either (a) donate a specific portion of one's income in small installments each year or (b) invest one's income and then donate as much as possible in one large lump sum right before death. &nbsp;Of course, there are other positions -- like donate every month or donate every decade, but in a very relevant sense the debate is between two options: \"give now\" vs. \"give later\".</p>\n<p>In this essay, I will defend the \"give now\" camp and rebut the \"give later\" camp, thus explaining why I will continue to donate once a year, though think any sort of regular time period smaller than each year is probably also acceptable.</p>\n<p>&nbsp;</p>\n<h2>But First, Why Give Later?</h2>\n<p>The biggest champ for the \"give later\" crowd is Robin Hanson, who makes his view known most recently in <a href=\"http://www.overcomingbias.com/2013/04/more-now-means-less-later.html\">\"If More Now, Less Later\"</a>:</p>\n<blockquote>\n<p>But at the margin, a person who saves another dollar, or chooses not to borrow another dollar, must typically expect the financial returns from their investments will help them more in the future than will such indirect effects of spending today. In fact, they should expect this savings will benefit their future self more than any of these other ways of spending today. After all, why give up money today if that both gives you less to spend today, and gives you less in the future? So there wouldn&rsquo;t be any savings, or less than maximal borrowing, if people didn&rsquo;t expect more gains later from saving than from spending today.</p>\n<p>This implies that unless charity recipients are saving nothing and borrowing as much as they possibly can, they must expect that you would benefit them more in the future by saving and giving them the returns of your savings later, than if you had given them the money today, even after taking into account all of the ways in which their spending today might help them in the future. So there really must be a tradeoff between helping today and helping later; if you help more today, you help less in the future. At least if you help them in a way they could have helped themselves, if only they had the money.</p>\n</blockquote>\n<p>Or, more basically, there are two concepts:</p>\n<p>First, there is the <strong>\"growth rate\"</strong>&nbsp;of donation -- by donating to a non-profit <em>now</em>, they get to do things with your money <em>now</em>, helping people immediately who then could be in a better position to give back, or by spending money on dreaded \"overhead\" (<a href=\"http://blog.givewell.org/2007/01/16/which-of-these-boasts-is-not-like-the-others/\">which isn't evil, by the way</a>, but that's a matter for another time), putting them in a better position to grow <em>now</em>.</p>\n<p>Second, there is the <strong>\"investment rate\"</strong>&nbsp;of saving/investing your donation money rather than donating now. &nbsp;This should be the easier of the two concepts -- you save your money, it grows in a certain percentage, and then right before you're about to die, you take all that money out and donate it.</p>\n<p>And then to oversimpify the complex topic, you should be willing to donate now as long as you think \"growth rate &gt; investment rate\", and save now as long as you think \"investment rate &gt; growth rate\", plus a few other complications to be discussed.</p>\n<p>&nbsp;</p>\n<h2>Ok, So What's The Investment Rate, Then?</h2>\n<p>Finding out the precise investment rate is complicated, but I think Jeff Kaufman has done some really good work on it in <a href=\"http://www.jefftk.com/news/2013-04-06\">\"What Rates of Return Should You Expect?\"</a>. &nbsp;Basically, many sites suggest returns on investment between 6% and 12%, but this (a) ignores the average of 3% inflation, (b) involves cherry-picking, and (c) only focuses on US data. &nbsp;Articles like The Economist's <a href=\"http://www.economist.com/news/finance-and-economics/21571443-investors-may-have-developed-too-rosy-view-equity-returns-beware-bias\">\"Beware of the Bias\"</a>&nbsp;point this out.</p>\n<p>So if we're really optimistic, we could consider the investment rate to be 12% and if we're really pessimistic, we could consider it to be 0%, or lower! &nbsp;But I'd expect the real (inflation adjusted) rate of return on your investment to be between 3 and 5%. &nbsp;This means that if I had opted to instead take <a href=\"http://www.everydayutilitarian.com/donations-report\">the $659.70 donation</a>&nbsp;I made last year and instead invested in it, given that I expect to live around 70 more years, I could realistically realize $5,372.94 to $21,687.36 if compounded monthly.</p>\n<p>&nbsp;</p>\n<h2>Ok, So What's The Growth Rate, Then?</h2>\n<p>But what about the other side of the coin -- growth rate from your donation? &nbsp;I see the potential size of this being huge. &nbsp;Unlike the investment rate which I think is overestimated, the growth rate seems <em>underestimated</em>.</p>\n<p>Honestly, whatever the growth rate is on your donation is going to depend largely and entirely on <em>where</em>&nbsp;you donate. &nbsp;But if you're donating to advocacy, you could realize really large returns because of what's called <a href=\"http://80000hours.org/blog/43-the-haste-consideration\">the haste consideration</a>:</p>\n<blockquote>\n<p>[I]magine two worlds:</p>\n<p>(1) You don&rsquo;t do anything altruistic for the next 2 years and then you spend the rest of your life after that improving the world as much as you can.</p>\n<p>(2) You spend the next 2 years influencing people to become effective altruists and convince one person who is at least as effective as you are at improving the world. (And assume that this person wouldn&rsquo;t have done anything altruistic otherwise.) You do nothing altruistic after the next 2 years, but the person you convinced does at least as much good as you did in (1).</p>\n<p>By stipulation, world (2) is improved at least as much as world (1) is because, in (2), the person you convinced does at least as much good as you did in (1).</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Essentially, convincing just one person to do what you would do (join <a href=\"http://www.givingwhatwecan.org\">Giving What We Can</a>, donate to existential risk, do anti-aging research, etc.) as ardently as you would do it (or nearly as much) would have the same effect as your entire life's work. &nbsp;Robin Hanson stated the case for giving later over giving now as \"if more now, less later\".</p>\n<p>But with the haste consideration, it's actually <strong>if more now, more later</strong>, because you'll be convincing people to do things they would otherwise have <em>not done at all</em>&nbsp;(presumably).</p>\n<p>And you can donate money to convincing people to do those things. &nbsp;A donation to Giving What We Can can fund their media outreach and recruit more people to the idea of donating effectively. &nbsp;A donation to MIRI could fund more salaries and recruitment efforts, etc.</p>\n<p>Thus, let's assume that, in my lifetime, I'll earn at least a $50K/year salary. &nbsp;Now assume that it costs a conservative $10K/year to recruit a Giving What We Can lifetime, committed member, who will also earn at least a $50K/year salary through outreach. &nbsp;(Feel free to quibble with these assumptions if you'd like, but don't risk missing the main point.)</p>\n<p>Now consider that I can either:</p>\n<p>(1) invest 10% of my salary each year at 5% return compounded monthly, and then, upon my death, \"buy\" as many committed GWWC members as possible.</p>\n<p>(2) donate 10% of my salary each year to buy as many committed GWWC members as possible.</p>\n<p>According to <a href=\"http://www.daveramsey.com/article/investing-calculator/lifeandmoney_investing/#/entry_form\">this investment calculator</a>&nbsp;(which I used earlier), option #1 will yield $3,200,782.84, which could buy 320 committed GWWC members.</p>\n<p>Option #2 would add a committed member every two years, producing 45 committed GWWC members over my predicted 70 year lifespan. &nbsp;This looks bad, but now remember that each of those members would then get a chance to recruit new members using <em>their</em> money. &nbsp;The first person I get would then commit $340K of their own lifetime earnings over the remaining period (68 years, since I recruited them on year 2, at $5K/year contribution). &nbsp;I'd only need to recruit ten members myself to dwarf the investment strategy, and that's not even counting all the second-stage members <em>those</em>&nbsp;first-stage members recruit.</p>\n<p>At this point, the group effectively doubles over the two year period. &nbsp;I save up to $10K at year two and recruit someone, and then in two years (year #4) we both have $10K and recruit someone, and then in two more years (year #6) all four of us recruit have $10K and recruit someone each, bringing the total amount of people recruited to twelve. &nbsp;By year #70, I will have recruited, directly and indirectly, 1+2^34 people, or 17.1 billion new GWWC members.</p>\n<p>&nbsp;</p>\n<p>Obviously, this is implausible because there aren't even 17 billion people and recruitment efforts would certainly be nonlinear. And there are other problems. &nbsp;But it's a simple way to prove the point. &nbsp;Hopefully this shows the benefit of compounding via the haste consideration to <strong>recruit new people who wouldn't have donated their money otherwise.</strong></p>\n<p>Even if Option #1 were considered to recruit people who then saved all their money and recruited other people, by year #140 it would only have 102,400 people recruited, whereas Option #2 would have roughly 10^41 people recruited.</p>\n<p>While the growth rate probably isn't 100% every two years, it's considerably higher than 5%, I think. &nbsp;Thus since growth rate &gt; interest rate, I advocate donating now. &nbsp;At least until someone finds the inevitable unobvious flaw in my thinking.</p>\n<p>Of course, we'll probably hit diminishing marginal returns on GWWC recruiting soon, and thus should reconsider our donation target, re-evaluate the growth rate, and maybe shift back to investing rather than donating <em>in the future</em>. &nbsp;But, <em>right now</em>, the prospects are still high and there are still many bright and active individuals who have not yet been recruited. &nbsp;<em>Right now</em>, we can use our money to make sure they use their money better.</p>\n<p>Thus my answer to Robin Hanson: More (of our money) now, more (of their money) later. &nbsp;At least, while it lasts.</p>\n<p>&nbsp;</p>\n<h2>Other Complications</h2>\n<p><em>Now time to explore some additional factors that may modify the consideration. &nbsp;The main argument has been made and this is is basically appendix material. &nbsp;Feel free to stop reading at this point, if you wish.</em></p>\n<p><strong>US Tax Law</strong></p>\n<p>This is an obvious factor to consider, but US law says that if you donate instead of invest, you can claim a deduction. &nbsp;This deduction would appear annually, thus allowing you to donate additional money. &nbsp;If you're earning the 50K I was talking about earlier, you'd be <a href=\"http://en.wikipedia.org/wiki/Income_tax_in_the_United_States\">taxed at effectively 16.9%</a>. &nbsp;This would mean you could get back $845 on a $5K donation, assuming I understand tax law right.</p>\n<p>If I donate $5K annually without investing, I'd actually be able to donate $409,150 over my seventy years rather than the original $350,000. &nbsp;If I had invested and then donated it all, I'd get $3,741,715.14 instead of $3,200,782.84.</p>\n<p><strong>The Changing Nature of Non-Profits</strong></p>\n<p>There's a good chance that if Giving What We Can stopped receiving donations, it would just collapse and then the opportunity to donate to it in seventy years would be gone (though I suppose it could be refounded with the new cash). &nbsp;Additionally, GWWC couldn't learn from the seventy years of being able to operate, spend money, and try things.</p>\n<p>And GWWC seems to be in a prime place right now to expand a lot and really grow it's outreach. &nbsp;Thus it's at a critical time to fund when the marginal cost to recruit a new member is at probably some of the lowest it will be. &nbsp;Now, not in seventy years, is a great time to get in.</p>\n<p>Furthermore, I speculate that the marginal value will grow at a rate higher than the interest, such that $5K/year for seventy years would buy more members for GWWC than a flat $3.7 million in seventy years would.</p>\n<p><strong>You Might Be Smarter In The Future</strong></p>\n<p>There's a good chance there might be better giving opportunities in seventy years, identified through our collective greater intelligence, your years of added experience, and the changing world (though <a href=\"http://blog.givewell.org/2011/12/20/give-now-or-give-later/\">GiveWell disagrees</a>, <a href=\"http://www.givingwhatwecan.org/about-us/our-research/donating-vs-investing\">as does GWWC</a>). &nbsp;This could mean it is better to give later, because you could be donating to an overall higher impact opportunity.</p>\n<p><strong>You Might Change Your Values</strong></p>\n<p>Some people are concerned that if they stored their donation money for seventy years, their future self might not care to donate it anymore. &nbsp;Personally, the way I view my personal identity, I'd rather have done what my future self wanted me to do, so if my future self seventy years from now wished I would have been less altruistic, I want to be less altruistic now, so I don't see this as a concern. &nbsp;But if you do, you should donate now, before your future self has a chance to redirect the money.</p>\n<p>One way to protect from this might be to use a <a href=\"http://en.wikipedia.org/wiki/Donor_advised_fund\">donor advised fund</a>, which would also get the benefit of more charity deductions (since you can deduct each contribution to your fund) and your future wisdom while forcing your future self to donate.</p>\n<p><strong>Better Advocacy</strong></p>\n<p>It seems much easier to convince someone to give a little each year than to follow a solid savings plan -- as Scott Alexander states, there <a href=\"http://slatestarcodex.com/2013/04/05/investment-and-inefficient-charity/\">are some strange psychological effects</a>&nbsp;that make us feel strongly like giving now and giving regularly is better, and we can secure the warm fuzzies feelings and social status of being considered a regular donor.</p>\n<p>Moreover, if you convinced a friend to donate, you'd know much more immediately if they actually plan on sticking to it if you can see a donation they make in December rather than having to wait until they die. &nbsp;(Though I suppose this too could be solved by having them contribute to your donor advised fund, if they trust you a lot. &nbsp;But I imagine the average person wouldn't.)</p>\n<p>Thus even if privately you should save, I think the best strategy to adopt publicly (when not speaking from an analytical point-of-view) is to encourage others to donate now.</p>\n<p>-</p>\n<address>Also cross-posted <a href=\"http://www.everydayutilitarian.com/essays/giving-now-currently-seems-to-beat-giving-later/\">on my blog</a>, <a href=\"http://felicifia.org/viewtopic.php?f=25&amp;t=917&amp;p=8353\">on Felicifia</a>, and <a href=\"http://effective-altruism.com/giving-now-currently-seems-beat-giving-later-2\">on the Effective Altruist blog</a>.</address><address><br /></address>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gKE8g5BqcMiGfKNo7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 1, "extendedScore": null, "score": 1.2379171616473715e-06, "legacy": true, "legacyId": "23007", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p><strong>Abstract: </strong>There is a debate between either donating now or donating later (investing, realizing the returns of one's investment, and donating in a lumpsum upon death). &nbsp;While donating later may be appropriate in some circumstances, right now we have the ability to donate now in order to <em>go meta</em> and recruit future donors who otherwise wouldn't have donated, thus adding more money than returns on investment.</p>\n</blockquote>\n<p>-</p>\n<h2 id=\"Introduction\">Introduction</h2>\n<p>Among those people interested in doing as much as they can to make the world a better place and think donating their money as effectively as possible is a good way to do that, there is a debate about whether one should either (a) donate a specific portion of one's income in small installments each year or (b) invest one's income and then donate as much as possible in one large lump sum right before death. &nbsp;Of course, there are other positions -- like donate every month or donate every decade, but in a very relevant sense the debate is between two options: \"give now\" vs. \"give later\".</p>\n<p>In this essay, I will defend the \"give now\" camp and rebut the \"give later\" camp, thus explaining why I will continue to donate once a year, though think any sort of regular time period smaller than each year is probably also acceptable.</p>\n<p>&nbsp;</p>\n<h2 id=\"But_First__Why_Give_Later_\">But First, Why Give Later?</h2>\n<p>The biggest champ for the \"give later\" crowd is Robin Hanson, who makes his view known most recently in <a href=\"http://www.overcomingbias.com/2013/04/more-now-means-less-later.html\">\"If More Now, Less Later\"</a>:</p>\n<blockquote>\n<p>But at the margin, a person who saves another dollar, or chooses not to borrow another dollar, must typically expect the financial returns from their investments will help them more in the future than will such indirect effects of spending today. In fact, they should expect this savings will benefit their future self more than any of these other ways of spending today. After all, why give up money today if that both gives you less to spend today, and gives you less in the future? So there wouldn\u2019t be any savings, or less than maximal borrowing, if people didn\u2019t expect more gains later from saving than from spending today.</p>\n<p>This implies that unless charity recipients are saving nothing and borrowing as much as they possibly can, they must expect that you would benefit them more in the future by saving and giving them the returns of your savings later, than if you had given them the money today, even after taking into account all of the ways in which their spending today might help them in the future. So there really must be a tradeoff between helping today and helping later; if you help more today, you help less in the future. At least if you help them in a way they could have helped themselves, if only they had the money.</p>\n</blockquote>\n<p>Or, more basically, there are two concepts:</p>\n<p>First, there is the <strong>\"growth rate\"</strong>&nbsp;of donation -- by donating to a non-profit <em>now</em>, they get to do things with your money <em>now</em>, helping people immediately who then could be in a better position to give back, or by spending money on dreaded \"overhead\" (<a href=\"http://blog.givewell.org/2007/01/16/which-of-these-boasts-is-not-like-the-others/\">which isn't evil, by the way</a>, but that's a matter for another time), putting them in a better position to grow <em>now</em>.</p>\n<p>Second, there is the <strong>\"investment rate\"</strong>&nbsp;of saving/investing your donation money rather than donating now. &nbsp;This should be the easier of the two concepts -- you save your money, it grows in a certain percentage, and then right before you're about to die, you take all that money out and donate it.</p>\n<p>And then to oversimpify the complex topic, you should be willing to donate now as long as you think \"growth rate &gt; investment rate\", and save now as long as you think \"investment rate &gt; growth rate\", plus a few other complications to be discussed.</p>\n<p>&nbsp;</p>\n<h2 id=\"Ok__So_What_s_The_Investment_Rate__Then_\">Ok, So What's The Investment Rate, Then?</h2>\n<p>Finding out the precise investment rate is complicated, but I think Jeff Kaufman has done some really good work on it in <a href=\"http://www.jefftk.com/news/2013-04-06\">\"What Rates of Return Should You Expect?\"</a>. &nbsp;Basically, many sites suggest returns on investment between 6% and 12%, but this (a) ignores the average of 3% inflation, (b) involves cherry-picking, and (c) only focuses on US data. &nbsp;Articles like The Economist's <a href=\"http://www.economist.com/news/finance-and-economics/21571443-investors-may-have-developed-too-rosy-view-equity-returns-beware-bias\">\"Beware of the Bias\"</a>&nbsp;point this out.</p>\n<p>So if we're really optimistic, we could consider the investment rate to be 12% and if we're really pessimistic, we could consider it to be 0%, or lower! &nbsp;But I'd expect the real (inflation adjusted) rate of return on your investment to be between 3 and 5%. &nbsp;This means that if I had opted to instead take <a href=\"http://www.everydayutilitarian.com/donations-report\">the $659.70 donation</a>&nbsp;I made last year and instead invested in it, given that I expect to live around 70 more years, I could realistically realize $5,372.94 to $21,687.36 if compounded monthly.</p>\n<p>&nbsp;</p>\n<h2 id=\"Ok__So_What_s_The_Growth_Rate__Then_\">Ok, So What's The Growth Rate, Then?</h2>\n<p>But what about the other side of the coin -- growth rate from your donation? &nbsp;I see the potential size of this being huge. &nbsp;Unlike the investment rate which I think is overestimated, the growth rate seems <em>underestimated</em>.</p>\n<p>Honestly, whatever the growth rate is on your donation is going to depend largely and entirely on <em>where</em>&nbsp;you donate. &nbsp;But if you're donating to advocacy, you could realize really large returns because of what's called <a href=\"http://80000hours.org/blog/43-the-haste-consideration\">the haste consideration</a>:</p>\n<blockquote>\n<p>[I]magine two worlds:</p>\n<p>(1) You don\u2019t do anything altruistic for the next 2 years and then you spend the rest of your life after that improving the world as much as you can.</p>\n<p>(2) You spend the next 2 years influencing people to become effective altruists and convince one person who is at least as effective as you are at improving the world. (And assume that this person wouldn\u2019t have done anything altruistic otherwise.) You do nothing altruistic after the next 2 years, but the person you convinced does at least as much good as you did in (1).</p>\n<p>By stipulation, world (2) is improved at least as much as world (1) is because, in (2), the person you convinced does at least as much good as you did in (1).</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Essentially, convincing just one person to do what you would do (join <a href=\"http://www.givingwhatwecan.org\">Giving What We Can</a>, donate to existential risk, do anti-aging research, etc.) as ardently as you would do it (or nearly as much) would have the same effect as your entire life's work. &nbsp;Robin Hanson stated the case for giving later over giving now as \"if more now, less later\".</p>\n<p>But with the haste consideration, it's actually <strong>if more now, more later</strong>, because you'll be convincing people to do things they would otherwise have <em>not done at all</em>&nbsp;(presumably).</p>\n<p>And you can donate money to convincing people to do those things. &nbsp;A donation to Giving What We Can can fund their media outreach and recruit more people to the idea of donating effectively. &nbsp;A donation to MIRI could fund more salaries and recruitment efforts, etc.</p>\n<p>Thus, let's assume that, in my lifetime, I'll earn at least a $50K/year salary. &nbsp;Now assume that it costs a conservative $10K/year to recruit a Giving What We Can lifetime, committed member, who will also earn at least a $50K/year salary through outreach. &nbsp;(Feel free to quibble with these assumptions if you'd like, but don't risk missing the main point.)</p>\n<p>Now consider that I can either:</p>\n<p>(1) invest 10% of my salary each year at 5% return compounded monthly, and then, upon my death, \"buy\" as many committed GWWC members as possible.</p>\n<p>(2) donate 10% of my salary each year to buy as many committed GWWC members as possible.</p>\n<p>According to <a href=\"http://www.daveramsey.com/article/investing-calculator/lifeandmoney_investing/#/entry_form\">this investment calculator</a>&nbsp;(which I used earlier), option #1 will yield $3,200,782.84, which could buy 320 committed GWWC members.</p>\n<p>Option #2 would add a committed member every two years, producing 45 committed GWWC members over my predicted 70 year lifespan. &nbsp;This looks bad, but now remember that each of those members would then get a chance to recruit new members using <em>their</em> money. &nbsp;The first person I get would then commit $340K of their own lifetime earnings over the remaining period (68 years, since I recruited them on year 2, at $5K/year contribution). &nbsp;I'd only need to recruit ten members myself to dwarf the investment strategy, and that's not even counting all the second-stage members <em>those</em>&nbsp;first-stage members recruit.</p>\n<p>At this point, the group effectively doubles over the two year period. &nbsp;I save up to $10K at year two and recruit someone, and then in two years (year #4) we both have $10K and recruit someone, and then in two more years (year #6) all four of us recruit have $10K and recruit someone each, bringing the total amount of people recruited to twelve. &nbsp;By year #70, I will have recruited, directly and indirectly, 1+2^34 people, or 17.1 billion new GWWC members.</p>\n<p>&nbsp;</p>\n<p>Obviously, this is implausible because there aren't even 17 billion people and recruitment efforts would certainly be nonlinear. And there are other problems. &nbsp;But it's a simple way to prove the point. &nbsp;Hopefully this shows the benefit of compounding via the haste consideration to <strong>recruit new people who wouldn't have donated their money otherwise.</strong></p>\n<p>Even if Option #1 were considered to recruit people who then saved all their money and recruited other people, by year #140 it would only have 102,400 people recruited, whereas Option #2 would have roughly 10^41 people recruited.</p>\n<p>While the growth rate probably isn't 100% every two years, it's considerably higher than 5%, I think. &nbsp;Thus since growth rate &gt; interest rate, I advocate donating now. &nbsp;At least until someone finds the inevitable unobvious flaw in my thinking.</p>\n<p>Of course, we'll probably hit diminishing marginal returns on GWWC recruiting soon, and thus should reconsider our donation target, re-evaluate the growth rate, and maybe shift back to investing rather than donating <em>in the future</em>. &nbsp;But, <em>right now</em>, the prospects are still high and there are still many bright and active individuals who have not yet been recruited. &nbsp;<em>Right now</em>, we can use our money to make sure they use their money better.</p>\n<p>Thus my answer to Robin Hanson: More (of our money) now, more (of their money) later. &nbsp;At least, while it lasts.</p>\n<p>&nbsp;</p>\n<h2 id=\"Other_Complications\">Other Complications</h2>\n<p><em>Now time to explore some additional factors that may modify the consideration. &nbsp;The main argument has been made and this is is basically appendix material. &nbsp;Feel free to stop reading at this point, if you wish.</em></p>\n<p><strong id=\"US_Tax_Law\">US Tax Law</strong></p>\n<p>This is an obvious factor to consider, but US law says that if you donate instead of invest, you can claim a deduction. &nbsp;This deduction would appear annually, thus allowing you to donate additional money. &nbsp;If you're earning the 50K I was talking about earlier, you'd be <a href=\"http://en.wikipedia.org/wiki/Income_tax_in_the_United_States\">taxed at effectively 16.9%</a>. &nbsp;This would mean you could get back $845 on a $5K donation, assuming I understand tax law right.</p>\n<p>If I donate $5K annually without investing, I'd actually be able to donate $409,150 over my seventy years rather than the original $350,000. &nbsp;If I had invested and then donated it all, I'd get $3,741,715.14 instead of $3,200,782.84.</p>\n<p><strong id=\"The_Changing_Nature_of_Non_Profits\">The Changing Nature of Non-Profits</strong></p>\n<p>There's a good chance that if Giving What We Can stopped receiving donations, it would just collapse and then the opportunity to donate to it in seventy years would be gone (though I suppose it could be refounded with the new cash). &nbsp;Additionally, GWWC couldn't learn from the seventy years of being able to operate, spend money, and try things.</p>\n<p>And GWWC seems to be in a prime place right now to expand a lot and really grow it's outreach. &nbsp;Thus it's at a critical time to fund when the marginal cost to recruit a new member is at probably some of the lowest it will be. &nbsp;Now, not in seventy years, is a great time to get in.</p>\n<p>Furthermore, I speculate that the marginal value will grow at a rate higher than the interest, such that $5K/year for seventy years would buy more members for GWWC than a flat $3.7 million in seventy years would.</p>\n<p><strong id=\"You_Might_Be_Smarter_In_The_Future\">You Might Be Smarter In The Future</strong></p>\n<p>There's a good chance there might be better giving opportunities in seventy years, identified through our collective greater intelligence, your years of added experience, and the changing world (though <a href=\"http://blog.givewell.org/2011/12/20/give-now-or-give-later/\">GiveWell disagrees</a>, <a href=\"http://www.givingwhatwecan.org/about-us/our-research/donating-vs-investing\">as does GWWC</a>). &nbsp;This could mean it is better to give later, because you could be donating to an overall higher impact opportunity.</p>\n<p><strong id=\"You_Might_Change_Your_Values\">You Might Change Your Values</strong></p>\n<p>Some people are concerned that if they stored their donation money for seventy years, their future self might not care to donate it anymore. &nbsp;Personally, the way I view my personal identity, I'd rather have done what my future self wanted me to do, so if my future self seventy years from now wished I would have been less altruistic, I want to be less altruistic now, so I don't see this as a concern. &nbsp;But if you do, you should donate now, before your future self has a chance to redirect the money.</p>\n<p>One way to protect from this might be to use a <a href=\"http://en.wikipedia.org/wiki/Donor_advised_fund\">donor advised fund</a>, which would also get the benefit of more charity deductions (since you can deduct each contribution to your fund) and your future wisdom while forcing your future self to donate.</p>\n<p><strong id=\"Better_Advocacy\">Better Advocacy</strong></p>\n<p>It seems much easier to convince someone to give a little each year than to follow a solid savings plan -- as Scott Alexander states, there <a href=\"http://slatestarcodex.com/2013/04/05/investment-and-inefficient-charity/\">are some strange psychological effects</a>&nbsp;that make us feel strongly like giving now and giving regularly is better, and we can secure the warm fuzzies feelings and social status of being considered a regular donor.</p>\n<p>Moreover, if you convinced a friend to donate, you'd know much more immediately if they actually plan on sticking to it if you can see a donation they make in December rather than having to wait until they die. &nbsp;(Though I suppose this too could be solved by having them contribute to your donor advised fund, if they trust you a lot. &nbsp;But I imagine the average person wouldn't.)</p>\n<p>Thus even if privately you should save, I think the best strategy to adopt publicly (when not speaking from an analytical point-of-view) is to encourage others to donate now.</p>\n<p>-</p>\n<address>Also cross-posted <a href=\"http://www.everydayutilitarian.com/essays/giving-now-currently-seems-to-beat-giving-later/\">on my blog</a>, <a href=\"http://felicifia.org/viewtopic.php?f=25&amp;t=917&amp;p=8353\">on Felicifia</a>, and <a href=\"http://effective-altruism.com/giving-now-currently-seems-beat-giving-later-2\">on the Effective Altruist blog</a>.</address><address><br></address>", "sections": [{"title": "Introduction", "anchor": "Introduction", "level": 1}, {"title": "But First, Why Give Later?", "anchor": "But_First__Why_Give_Later_", "level": 1}, {"title": "Ok, So What's The Investment Rate, Then?", "anchor": "Ok__So_What_s_The_Investment_Rate__Then_", "level": 1}, {"title": "Ok, So What's The Growth Rate, Then?", "anchor": "Ok__So_What_s_The_Growth_Rate__Then_", "level": 1}, {"title": "Other Complications", "anchor": "Other_Complications", "level": 1}, {"title": "US Tax Law", "anchor": "US_Tax_Law", "level": 2}, {"title": "The Changing Nature of Non-Profits", "anchor": "The_Changing_Nature_of_Non_Profits", "level": 2}, {"title": "You Might Be Smarter In The Future", "anchor": "You_Might_Be_Smarter_In_The_Future", "level": 2}, {"title": "You Might Change Your Values", "anchor": "You_Might_Change_Your_Values", "level": 2}, {"title": "Better Advocacy", "anchor": "Better_Advocacy", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T19:10:02.084Z", "modifiedAt": null, "url": null, "title": "Initial Thoughts on Personally Finding a High-Impact Career", "slug": "initial-thoughts-on-personally-finding-a-high-impact-career", "viewCount": null, "lastCommentedAt": "2017-09-06T06:44:00.302Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kR2tgaZgDjBSoTAS4/initial-thoughts-on-personally-finding-a-high-impact-career", "pageUrlRelative": "/posts/kR2tgaZgDjBSoTAS4/initial-thoughts-on-personally-finding-a-high-impact-career", "linkUrl": "https://www.lesswrong.com/posts/kR2tgaZgDjBSoTAS4/initial-thoughts-on-personally-finding-a-high-impact-career", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Initial%20Thoughts%20on%20Personally%20Finding%20a%20High-Impact%20Career&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInitial%20Thoughts%20on%20Personally%20Finding%20a%20High-Impact%20Career%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkR2tgaZgDjBSoTAS4%2Finitial-thoughts-on-personally-finding-a-high-impact-career%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Initial%20Thoughts%20on%20Personally%20Finding%20a%20High-Impact%20Career%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkR2tgaZgDjBSoTAS4%2Finitial-thoughts-on-personally-finding-a-high-impact-career", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkR2tgaZgDjBSoTAS4%2Finitial-thoughts-on-personally-finding-a-high-impact-career", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1730, "htmlBody": "<p>As I mentioned in <a href=\"http://www.everydayutilitarian.com/essays/my-strategic-plan\">my strategic plan</a>, <strong>I have 10 months and 28 days until I graduate</strong>&nbsp;from Denison University and hopefully will be transitioning to a <em>career</em>. &nbsp;Careers are important because having one will not only mean that I won't starve, but that I'll have an opportunity to <em>change the world</em>. &nbsp;As the career advice organization <a href=\"http://80000hours.org/\">80,000 Hours</a>&nbsp;notes you'll be spending about 80,000 hours in a career, so you might as well use it to make as big of a difference as you can? &nbsp;<strong>But what career should I pick?</strong></p>\n<p>Here are my starting thoughts and strategy...</p>\n<p>&nbsp;</p>\n<h2>Basic Philosophy and Strategy</h2>\n<p>My aim is to choose a career that will, taken as a whole, contribute the most to the world with regard to my utilitarian goals to increase total well-being. &nbsp;\"Taken as a whole\" means that I'm not just considering the direct good of the first career itself, but also it's interaction with the rest of my life, it's indirect good, and how it might set me up to have an even better second career.</p>\n<p>However, there is one catch: I furthermore want the job to be at least moderately enjoyable. &nbsp;I would very much not like to be depressed or burnt out, and I suspect that would be bad for my utilitarian goals too. &nbsp;If I think I would be miserable at my chosen job even if somehow it were to maximize total well-being, I still would not take it (despite this being immoral from a utilitarian standpoint).</p>\n<p>I also would like to have a plan in place rather soon, so I can actually act upon preparing for it. &nbsp;The earlier I pick a career plan, the more options will remain open. &nbsp;Right now, I'm stuck, for better or for worse, with a psychology and political science major and unless I do something drastic, I won't be able to take any classes outside of those two majors for the rest of my time at Denison.</p>\n<p>As a political science and psychology double major, I think I could be very well qualified for a job that involves research and/or statistics. &nbsp;To get more of an idea of what I can do, feel free to <a href=\"http://www.peterhurford.com/resume.html\">look at my r&eacute;sum&eacute;</a>&nbsp;and at my <a href=\"http://www.peterhurford.com/\">personal website</a>. &nbsp;I'll speculate a bit more about my qualifications later on in this essay.</p>\n<p>&nbsp;</p>\n<h2>The Scope of High-Impact Careers</h2>\n<p>The way I've been categorizing it, there are essentially only two different kinds of careers that promise to do lots of good --&nbsp;<strong>funneling money to effective organizations</strong>&nbsp;and <strong>working for effective organizations</strong>, though some opportunities allow for some combination of both.</p>\n<p>By effective organizations, I mean orgs like <a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a>, <a href=\"http://www.80000hours.org/\">80K Hours</a>, <a href=\"http://www.effectiveanimalactivism.com\">Effective Animal Activism</a>, <a href=\"http://www.lifeyoucansave.com\">The Life You Can Save</a>, <a href=\"http://www.rationality.org/\">Center for Applied Rationality</a>, <a href=\"http://www.intelligence.org/\">Machine Intelligence Research Institute</a>, <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a>, Leverage Research, <a href=\"http://www.gatesfoundation.org/\">The Bill and Melinda Gates Foundation</a>, <a href=\"http://www.givewell.org\">GiveWell</a>, <a href=\"http://www.againstmalaria.com\">Against Malaria Foundation</a>, <a href=\"http://www.veganoutreach.org\">Vegan Outreach</a>, etc. &nbsp;(Of course, the actual choice of organization would matter a great deal, and some of these organizations might actually not be effective for one reason or another, but I won't look at those arguments here.)&nbsp;</p>\n<p>&nbsp;</p>\n<p>Funneling money to effective organizations, in this case, involves only one opportunity -- <em>earning to give,</em>&nbsp;which I've <a href=\"http://www.everydayutilitarian.com/essays/sunday-links-4-earning-to-give/\">summarized before</a>. The basic idea is that you aim to pick a high income job and then donate as much as you can to an effective organization.</p>\n<p>Working for effective organizations involves four other opportunities -- <em>research</em>, <em>influence</em>, <em>fundraising</em>, and/or <em>direct work</em>. &nbsp;I say \"and/or\" because you could end up employed at a effective organization that allows you to so some combination of the four. &nbsp;Research might involve working for a university working on an important question. &nbsp;Direct work might involve assisting in the day-to-day opportunities of the organization.</p>\n<p>Notably, research, influence, and perhaps even fundraising, could be carried out in one's free time, such as what I do through this blog.</p>\n<p>&nbsp;</p>\n<h2>My Perceived Opportunities in Earning to Give</h2>\n<p>I think earning to give is a great baseline for me to evaluate other opportunities from, even though I'm moderately confident I can do more impact through a different line of work. &nbsp;What opportunities await? &nbsp;Here are my guesses:</p>\n<p>\n<ul>\n<li><strong>Investment Banking:</strong>&nbsp;My guess is this is the highest earning career, when considering probability of achieving certain incomes multiplied by the quantity of income, and high incomes right out of college. &nbsp;However, I'm only moderately qualified for it -- I think I have a good analytic mindset and have taken some economics and finance classes, but I'm not an economics major, and I've never done any finance internships. &nbsp;Moreover, I don't think this job would be particularly enjoyable. &nbsp;I see a high chance of failure to get a job and burnout once I get a job here.</li>\n</ul>\n<ul>\n<li><strong>Law:</strong>&nbsp;Law seems like a high-earning career if you can make it big, but there's a low chance of making it big. &nbsp;I've heard anecdotally that you basically need to get into a top law school or you won't be having a good time, assuming you can pay for that law school. &nbsp;I think this would be moderately enjoyable and with Moot Court, a Constitutional law class, and a Political Science major, I'm as prepared for law as anyone can be in a liberal arts school.</li>\n</ul>\n<ul>\n<li><strong>Consulting:</strong>&nbsp;Consulting offers high incomes right out of college, though the incomes might not be as high as other opportunities overall. &nbsp;I'd say I'm as prepared for consulting as anyone can be in a liberal arts school, though I'm not an economics major. &nbsp;Unfortunately, however, I'd guess that I'd really hate regular travel, so consulting might not be a good career path for me.</li>\n</ul>\n<ul>\n<li><strong>Computer Programming:</strong>&nbsp;Computer programming also offers high incomes right out of college, provided you're talented at it. &nbsp;I think I have the raw aptitude, but I don't have the formal training. &nbsp;My guess is that if I wanted to go into programming, I'd have to pursue some additional education after Denison.</li>\n</ul>\n<ul>\n<li><strong>Market Research:</strong>&nbsp;I think market research would also offer decently high incomes right out of college, and I'd be well qualified for it and I'd enjoy it. &nbsp;This has always been one of my favorite choices.</li>\n</ul>\n<ul>\n<li><strong>Engineering:</strong>&nbsp;Engineering would provide high incomes right out of college, but I have no experience with engineering.</li>\n</ul>\n<ul>\n<li><strong>Medicine:</strong>&nbsp; Doctors earn a lot, though they have high expenses with medical school. &nbsp;Doctors seem to be like lawyers who have a more smooth earnings curve -- you'll earn a bit less overall, but you have a higher chance of success. &nbsp;However, I don't think this is worth pursuing as I have no interest for it and I have never taken a single college-level biology course.</li>\n</ul>\n</p>\n<p>&nbsp;</p>\n<h2>My Perceived Opportunities in Research</h2>\n<p>I've done really, really well in political science and think I'd have lots of aptitude as a political science Ph.D. &nbsp;However, I don't think political science offers much opportunities to actually make an impact with one's research. &nbsp;Psychology research, on the other hand, I do think has a wide variety of high impact questions to study, but I've only been moderately good at psychology and I'm unsure I'd get into a top Ph.D. program. &nbsp;I also imagine I might have the general skills to survive in other social science programs, like economics research.</p>\n<p>I thought about doing philosophy research, since most of the biggest questions seem to lie in the realm of philosophy right now. &nbsp;However, I'm nearly certain I can do just as well or even better at philosophy research by just writing things on the internet.</p>\n<p>&nbsp;</p>\n<h2>My Perceived Opportunities in Influence/Fundraising</h2>\n<p>I don't know if there's much I could do in influence beyond what I'm already doing. &nbsp;I suspect my only options are to either <a href=\"http://www.mrmoneymustache.com/2013/02/22/getting-rich-from-zero-to-hero-in-one-blog-post/\">retire early</a>&nbsp;and blog full-time (it's not that hard to retire permanently by age 30 with a high enough income and savings rate). &nbsp;That seems unlikely to be my best choice.</p>\n<p>I could go work on behalf of an effective organization, which seems promising.</p>\n<p>Or I could always retire early and then work for an effective organization, as well, which would have the added benefit of not needing them to pay me.</p>\n<p>A career in politics is unlikely to be high impact as a first career, and I've probably already burned myself from running for higher office with public statements of outside-the-mainstream views.</p>\n<p>&nbsp;</p>\n<h2>My Perceived Opportunities in Direct Work</h2>\n<p>I think this is the same as the above. &nbsp;I think I'd enjoy working for an effective organization directly.</p>\n<p>One interesting idea is to <a href=\"http://80000hours.org/blog/54-the-high-impact-pa-how-anyone-can-bring-about-ground-breaking-research\">be a personal assistant</a>&nbsp;to someone who is high-impact to boost their impact. &nbsp;I'm not sure how good I am at this, however, and I'd feel like I could do better. &nbsp;I'm also not sure if this would be fun, though it could be. &nbsp;I suppose it depends on the person I'd work with.</p>\n<p>&nbsp;</p>\n<h2>Conclusion</h2>\n<p>This essay is good in making my career plans a lot less vague. &nbsp;But it's full of guesses and I'm definitely missing a lot. &nbsp;What do I plan on doing from here?</p>\n<p>\n<ul>\n<li><strong>Get a significant amount of advice on this draft.</strong>&nbsp; I'll be visiting England this summer and hope to stop by 80K and get advice from a bunch of cool people in person. &nbsp;I'll sign up for another <a href=\"http://80000hours.org/get-coaching\">80k coaching session</a>&nbsp;(my first one got a bit derailed). &nbsp;I also plan on talking to people not affiliated with 80K. &nbsp;Just by passing this draft around, I hope to get more advice on how to modify it. &nbsp;(Hint: You should give me advice on careers or advice on how to find good advice.)</li>\n</ul>\n<ul>\n<li><strong>Do more personal research.</strong>&nbsp; 80K has a lot of research, but they might not be going fast enough for me to make it in time, and I might need to pick up some of what they don't have, to the best of my ability. &nbsp;Finding salary information for my favorite jobs would be a good start.</li>\n</ul>\n<ul>\n<li><strong>Choose a few paths to pursue and build toward them.</strong> &nbsp;I can apply to jobs and graduate programs simultaneously while still figuring things out.</li>\n</ul>\n<ul>\n<li><strong>Work on the LSAT and GRE.</strong>&nbsp; I need to take these two tests for law school and Ph.D. programs respectively. &nbsp;I also might need graduate school for non-Ph.D. career advancement. &nbsp;I'll get the practice tests ready.</li>\n</ul>\n<ul>\n<li><strong>Keep writing about this.</strong> &nbsp;I'd imagine there's a lot of benefit for both me and others in creating more documentation and discussion around career choice for making the world a better place.</li>\n</ul>\n<div>-</div>\n<div><br /></div>\n<address>Also <a href=\"http://www.everydayutilitarian.com/essays/my-careers-plan/\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</address></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kR2tgaZgDjBSoTAS4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 3.9e-05, "legacy": true, "legacyId": "23008", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>As I mentioned in <a href=\"http://www.everydayutilitarian.com/essays/my-strategic-plan\">my strategic plan</a>, <strong>I have 10 months and 28 days until I graduate</strong>&nbsp;from Denison University and hopefully will be transitioning to a <em>career</em>. &nbsp;Careers are important because having one will not only mean that I won't starve, but that I'll have an opportunity to <em>change the world</em>. &nbsp;As the career advice organization <a href=\"http://80000hours.org/\">80,000 Hours</a>&nbsp;notes you'll be spending about 80,000 hours in a career, so you might as well use it to make as big of a difference as you can? &nbsp;<strong>But what career should I pick?</strong></p>\n<p>Here are my starting thoughts and strategy...</p>\n<p>&nbsp;</p>\n<h2 id=\"Basic_Philosophy_and_Strategy\">Basic Philosophy and Strategy</h2>\n<p>My aim is to choose a career that will, taken as a whole, contribute the most to the world with regard to my utilitarian goals to increase total well-being. &nbsp;\"Taken as a whole\" means that I'm not just considering the direct good of the first career itself, but also it's interaction with the rest of my life, it's indirect good, and how it might set me up to have an even better second career.</p>\n<p>However, there is one catch: I furthermore want the job to be at least moderately enjoyable. &nbsp;I would very much not like to be depressed or burnt out, and I suspect that would be bad for my utilitarian goals too. &nbsp;If I think I would be miserable at my chosen job even if somehow it were to maximize total well-being, I still would not take it (despite this being immoral from a utilitarian standpoint).</p>\n<p>I also would like to have a plan in place rather soon, so I can actually act upon preparing for it. &nbsp;The earlier I pick a career plan, the more options will remain open. &nbsp;Right now, I'm stuck, for better or for worse, with a psychology and political science major and unless I do something drastic, I won't be able to take any classes outside of those two majors for the rest of my time at Denison.</p>\n<p>As a political science and psychology double major, I think I could be very well qualified for a job that involves research and/or statistics. &nbsp;To get more of an idea of what I can do, feel free to <a href=\"http://www.peterhurford.com/resume.html\">look at my r\u00e9sum\u00e9</a>&nbsp;and at my <a href=\"http://www.peterhurford.com/\">personal website</a>. &nbsp;I'll speculate a bit more about my qualifications later on in this essay.</p>\n<p>&nbsp;</p>\n<h2 id=\"The_Scope_of_High_Impact_Careers\">The Scope of High-Impact Careers</h2>\n<p>The way I've been categorizing it, there are essentially only two different kinds of careers that promise to do lots of good --&nbsp;<strong>funneling money to effective organizations</strong>&nbsp;and <strong>working for effective organizations</strong>, though some opportunities allow for some combination of both.</p>\n<p>By effective organizations, I mean orgs like <a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a>, <a href=\"http://www.80000hours.org/\">80K Hours</a>, <a href=\"http://www.effectiveanimalactivism.com\">Effective Animal Activism</a>, <a href=\"http://www.lifeyoucansave.com\">The Life You Can Save</a>, <a href=\"http://www.rationality.org/\">Center for Applied Rationality</a>, <a href=\"http://www.intelligence.org/\">Machine Intelligence Research Institute</a>, <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a>, Leverage Research, <a href=\"http://www.gatesfoundation.org/\">The Bill and Melinda Gates Foundation</a>, <a href=\"http://www.givewell.org\">GiveWell</a>, <a href=\"http://www.againstmalaria.com\">Against Malaria Foundation</a>, <a href=\"http://www.veganoutreach.org\">Vegan Outreach</a>, etc. &nbsp;(Of course, the actual choice of organization would matter a great deal, and some of these organizations might actually not be effective for one reason or another, but I won't look at those arguments here.)&nbsp;</p>\n<p>&nbsp;</p>\n<p>Funneling money to effective organizations, in this case, involves only one opportunity -- <em>earning to give,</em>&nbsp;which I've <a href=\"http://www.everydayutilitarian.com/essays/sunday-links-4-earning-to-give/\">summarized before</a>. The basic idea is that you aim to pick a high income job and then donate as much as you can to an effective organization.</p>\n<p>Working for effective organizations involves four other opportunities -- <em>research</em>, <em>influence</em>, <em>fundraising</em>, and/or <em>direct work</em>. &nbsp;I say \"and/or\" because you could end up employed at a effective organization that allows you to so some combination of the four. &nbsp;Research might involve working for a university working on an important question. &nbsp;Direct work might involve assisting in the day-to-day opportunities of the organization.</p>\n<p>Notably, research, influence, and perhaps even fundraising, could be carried out in one's free time, such as what I do through this blog.</p>\n<p>&nbsp;</p>\n<h2 id=\"My_Perceived_Opportunities_in_Earning_to_Give\">My Perceived Opportunities in Earning to Give</h2>\n<p>I think earning to give is a great baseline for me to evaluate other opportunities from, even though I'm moderately confident I can do more impact through a different line of work. &nbsp;What opportunities await? &nbsp;Here are my guesses:</p>\n<p>\n</p><ul>\n<li><strong>Investment Banking:</strong>&nbsp;My guess is this is the highest earning career, when considering probability of achieving certain incomes multiplied by the quantity of income, and high incomes right out of college. &nbsp;However, I'm only moderately qualified for it -- I think I have a good analytic mindset and have taken some economics and finance classes, but I'm not an economics major, and I've never done any finance internships. &nbsp;Moreover, I don't think this job would be particularly enjoyable. &nbsp;I see a high chance of failure to get a job and burnout once I get a job here.</li>\n</ul>\n<ul>\n<li><strong>Law:</strong>&nbsp;Law seems like a high-earning career if you can make it big, but there's a low chance of making it big. &nbsp;I've heard anecdotally that you basically need to get into a top law school or you won't be having a good time, assuming you can pay for that law school. &nbsp;I think this would be moderately enjoyable and with Moot Court, a Constitutional law class, and a Political Science major, I'm as prepared for law as anyone can be in a liberal arts school.</li>\n</ul>\n<ul>\n<li><strong>Consulting:</strong>&nbsp;Consulting offers high incomes right out of college, though the incomes might not be as high as other opportunities overall. &nbsp;I'd say I'm as prepared for consulting as anyone can be in a liberal arts school, though I'm not an economics major. &nbsp;Unfortunately, however, I'd guess that I'd really hate regular travel, so consulting might not be a good career path for me.</li>\n</ul>\n<ul>\n<li><strong>Computer Programming:</strong>&nbsp;Computer programming also offers high incomes right out of college, provided you're talented at it. &nbsp;I think I have the raw aptitude, but I don't have the formal training. &nbsp;My guess is that if I wanted to go into programming, I'd have to pursue some additional education after Denison.</li>\n</ul>\n<ul>\n<li><strong>Market Research:</strong>&nbsp;I think market research would also offer decently high incomes right out of college, and I'd be well qualified for it and I'd enjoy it. &nbsp;This has always been one of my favorite choices.</li>\n</ul>\n<ul>\n<li><strong>Engineering:</strong>&nbsp;Engineering would provide high incomes right out of college, but I have no experience with engineering.</li>\n</ul>\n<ul>\n<li><strong>Medicine:</strong>&nbsp; Doctors earn a lot, though they have high expenses with medical school. &nbsp;Doctors seem to be like lawyers who have a more smooth earnings curve -- you'll earn a bit less overall, but you have a higher chance of success. &nbsp;However, I don't think this is worth pursuing as I have no interest for it and I have never taken a single college-level biology course.</li>\n</ul>\n<p></p>\n<p>&nbsp;</p>\n<h2 id=\"My_Perceived_Opportunities_in_Research\">My Perceived Opportunities in Research</h2>\n<p>I've done really, really well in political science and think I'd have lots of aptitude as a political science Ph.D. &nbsp;However, I don't think political science offers much opportunities to actually make an impact with one's research. &nbsp;Psychology research, on the other hand, I do think has a wide variety of high impact questions to study, but I've only been moderately good at psychology and I'm unsure I'd get into a top Ph.D. program. &nbsp;I also imagine I might have the general skills to survive in other social science programs, like economics research.</p>\n<p>I thought about doing philosophy research, since most of the biggest questions seem to lie in the realm of philosophy right now. &nbsp;However, I'm nearly certain I can do just as well or even better at philosophy research by just writing things on the internet.</p>\n<p>&nbsp;</p>\n<h2 id=\"My_Perceived_Opportunities_in_Influence_Fundraising\">My Perceived Opportunities in Influence/Fundraising</h2>\n<p>I don't know if there's much I could do in influence beyond what I'm already doing. &nbsp;I suspect my only options are to either <a href=\"http://www.mrmoneymustache.com/2013/02/22/getting-rich-from-zero-to-hero-in-one-blog-post/\">retire early</a>&nbsp;and blog full-time (it's not that hard to retire permanently by age 30 with a high enough income and savings rate). &nbsp;That seems unlikely to be my best choice.</p>\n<p>I could go work on behalf of an effective organization, which seems promising.</p>\n<p>Or I could always retire early and then work for an effective organization, as well, which would have the added benefit of not needing them to pay me.</p>\n<p>A career in politics is unlikely to be high impact as a first career, and I've probably already burned myself from running for higher office with public statements of outside-the-mainstream views.</p>\n<p>&nbsp;</p>\n<h2 id=\"My_Perceived_Opportunities_in_Direct_Work\">My Perceived Opportunities in Direct Work</h2>\n<p>I think this is the same as the above. &nbsp;I think I'd enjoy working for an effective organization directly.</p>\n<p>One interesting idea is to <a href=\"http://80000hours.org/blog/54-the-high-impact-pa-how-anyone-can-bring-about-ground-breaking-research\">be a personal assistant</a>&nbsp;to someone who is high-impact to boost their impact. &nbsp;I'm not sure how good I am at this, however, and I'd feel like I could do better. &nbsp;I'm also not sure if this would be fun, though it could be. &nbsp;I suppose it depends on the person I'd work with.</p>\n<p>&nbsp;</p>\n<h2 id=\"Conclusion\">Conclusion</h2>\n<p>This essay is good in making my career plans a lot less vague. &nbsp;But it's full of guesses and I'm definitely missing a lot. &nbsp;What do I plan on doing from here?</p>\n<p>\n</p><ul>\n<li><strong>Get a significant amount of advice on this draft.</strong>&nbsp; I'll be visiting England this summer and hope to stop by 80K and get advice from a bunch of cool people in person. &nbsp;I'll sign up for another <a href=\"http://80000hours.org/get-coaching\">80k coaching session</a>&nbsp;(my first one got a bit derailed). &nbsp;I also plan on talking to people not affiliated with 80K. &nbsp;Just by passing this draft around, I hope to get more advice on how to modify it. &nbsp;(Hint: You should give me advice on careers or advice on how to find good advice.)</li>\n</ul>\n<ul>\n<li><strong>Do more personal research.</strong>&nbsp; 80K has a lot of research, but they might not be going fast enough for me to make it in time, and I might need to pick up some of what they don't have, to the best of my ability. &nbsp;Finding salary information for my favorite jobs would be a good start.</li>\n</ul>\n<ul>\n<li><strong>Choose a few paths to pursue and build toward them.</strong> &nbsp;I can apply to jobs and graduate programs simultaneously while still figuring things out.</li>\n</ul>\n<ul>\n<li><strong>Work on the LSAT and GRE.</strong>&nbsp; I need to take these two tests for law school and Ph.D. programs respectively. &nbsp;I also might need graduate school for non-Ph.D. career advancement. &nbsp;I'll get the practice tests ready.</li>\n</ul>\n<ul>\n<li><strong>Keep writing about this.</strong> &nbsp;I'd imagine there's a lot of benefit for both me and others in creating more documentation and discussion around career choice for making the world a better place.</li>\n</ul>\n<div>-</div>\n<div><br></div>\n<address>Also <a href=\"http://www.everydayutilitarian.com/essays/my-careers-plan/\">cross-posted</a> on <a href=\"http://www.everydayutilitarian.com\">my blog</a>.</address><p></p>", "sections": [{"title": "Basic Philosophy and Strategy", "anchor": "Basic_Philosophy_and_Strategy", "level": 1}, {"title": "The Scope of High-Impact Careers", "anchor": "The_Scope_of_High_Impact_Careers", "level": 1}, {"title": "My Perceived Opportunities in Earning to Give", "anchor": "My_Perceived_Opportunities_in_Earning_to_Give", "level": 1}, {"title": "My Perceived Opportunities in Research", "anchor": "My_Perceived_Opportunities_in_Research", "level": 1}, {"title": "My Perceived Opportunities in Influence/Fundraising", "anchor": "My_Perceived_Opportunities_in_Influence_Fundraising", "level": 1}, {"title": "My Perceived Opportunities in Direct Work", "anchor": "My_Perceived_Opportunities_in_Direct_Work", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "58 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 58, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-19T23:54:58.379Z", "modifiedAt": null, "url": null, "title": "Some reservations about Singer's child-in-the-pond argument", "slug": "some-reservations-about-singer-s-child-in-the-pond-argument", "viewCount": null, "lastCommentedAt": "2017-06-17T04:17:34.075Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/M8zgMmNCfpQxaKo8Y/some-reservations-about-singer-s-child-in-the-pond-argument", "pageUrlRelative": "/posts/M8zgMmNCfpQxaKo8Y/some-reservations-about-singer-s-child-in-the-pond-argument", "linkUrl": "https://www.lesswrong.com/posts/M8zgMmNCfpQxaKo8Y/some-reservations-about-singer-s-child-in-the-pond-argument", "postedAtFormatted": "Wednesday, June 19th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Some%20reservations%20about%20Singer's%20child-in-the-pond%20argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASome%20reservations%20about%20Singer's%20child-in-the-pond%20argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM8zgMmNCfpQxaKo8Y%2Fsome-reservations-about-singer-s-child-in-the-pond-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Some%20reservations%20about%20Singer's%20child-in-the-pond%20argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM8zgMmNCfpQxaKo8Y%2Fsome-reservations-about-singer-s-child-in-the-pond-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FM8zgMmNCfpQxaKo8Y%2Fsome-reservations-about-singer-s-child-in-the-pond-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1807, "htmlBody": "<p class=\"MsoNormal\">Peter Singer is one of the most influential philosophers, and is a strong candidate for being the person who has helped the effective altruist community the most.</p>\n<p class=\"MsoNormal\">In the past, Peter Singer often argued that [the moral obligation to rush into a shallow pond to save a drowning child at the cost of ruining one&rsquo;s shoes] is equivalent to [the moral obligation to give to charities that reduce extreme poverty]. For example, in&nbsp;<a href=\"http://www.youtube.com/watch?v=sagg2C30RMk\">this 2009 video</a>&nbsp;he said:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Imagine that you&rsquo;re walking across a shallow pond and you notice that a small child has fallen in, and is in danger of drowning [&hellip;] Of course, you think you must rush in to save the child. Then you remember that you&rsquo;re wearing your favorite, quite expensive, pair of shoes and they&rsquo;ll get ruined if you rush into the pond. Is that a reason for not saving the child? I&rsquo;m sure you&rsquo;ll say no it isn&rsquo;t, you just can&rsquo;t compare the life of a child to the cost of a pair of shoes, no matter how expensive. [&hellip;] But think about how that relates to your situation in the world today. There are children whose lives you can save [&hellip;] Nearly 10 million children die every year from avoidable, poverty related causes. And it wouldn&rsquo;t take a lot to save the lives of these children. We can do it.&nbsp;<strong style=\"mso-bidi-font-weight:normal\">For the cost of a pair of shoes, perhaps, you could save the life of a child.</strong>&nbsp;[&hellip;] There&rsquo;s some luxury that you could do without. And with that money, you could give to an organization to reduce extreme poverty in the world, and save lives of children. [&hellip;] I think that this is what we ought to be doing.</p>\n<p class=\"MsoNormal\">Since Singer first posed the analogy, new information and understanding has emerged, which cast doubt on the relevance of Singer&rsquo;s analogy. Singer used a different analogy in his&nbsp;<a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">recent TED talk</a><span style=\"mso-spacerun:yes\">&nbsp;</span>(in which he discussed the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Death_of_Wang_Yue\">death of Wang Yue</a>), but whether explicitly or implicitly, the &ldquo;child in a pond&rdquo; meme has caught on. In light of recent developments, it&rsquo;s important to highlight the fact that the opportunities to donate to alleviate global in our present world are disanalogous to the opportunity in Singer&rsquo;s &ldquo;child in a pond&rdquo; scenario.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a></p>\n<p class=\"MsoNormal\">The most expensive pair of shoes that I own costs ~$120, and I would guess that the average American doesn&rsquo;t own a pair of shoes that costs more than $200. With this in mind, Singer&rsquo;s analogy suggests that one can save a life of a child in the developing world for less than $200. To determine whether Peter Singer&rsquo;s analogy is a good one, we need to examine the empirical data concerning the cost of saving a child&rsquo;s life.</p>\n<p class=\"MsoNormal\"><a href=\"http://www.givewell.org/\">GiveWell</a>&nbsp;spent five years looking for outstanding charities that alleviate poverty in the developing world. GiveWell's current top recommended charity, Against Malaria Foundation (AMF), distributes long lasting insecticide treated nets to guard recipients against malaria. GiveWell&rsquo;s&nbsp;<a href=\"http://www.givewell.org/international/top-charities/AMF#Costperlifesaved\">explicit estimate</a>&nbsp;of AMF&rsquo;s cost per life saved is just under $2,300. The cost of bed nets&nbsp;<a href=\"http://news.againstmalaria.com/post/2013/06/03/LLINs-are-now-close-to-US3-per-net.aspx\">has recently fallen</a>, and this is expected to decrease AMF&rsquo;s cost per life saved, but not by a large margin.</p>\n<p class=\"MsoNormal\">GiveWell Co-Executive Director Holden Karnofsky has written about how&nbsp;<a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">explicit expected value estimates shouldn&rsquo;t be taken literally</a>, and in particular, that explicit estimates of the value of philanthropic opportunities should be adjusted to account for one&rsquo;s Bayesian prior over the effectiveness of all philanthropic opportunities.&nbsp;<span style=\"mso-spacerun:yes\">&nbsp;</span>In June 2012, GiveWell senior research analyst Alexander Berger&nbsp;<a href=\"/lw/d4v/altruistic_kidney_donation/6vpw\">wrote</a>(speaking for himself rather than for GiveWell)</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">I don't think the expected value of a $1600 donation to AMF [an earlier cost-effectiveness estimate for AMF's cost per life saved] is actually anywhere near one life saved. The reason for this has nothing to do with how AMF works and is more a feature of its place in the total distribution of charity cost-effectiveness. I think there are a variety of practices in cost-effectiveness estimation that push in favor of a difficult-to-estimate positive bias (e.g. using evidence from RCTs, which are generally conducted in the most promising circumstances), that the most extreme cost-effectiveness estimates are more likely to be biased, and that the benefit of a marginal contribution is almost always less than the benefit of an average contribution. All of these conspire to make me think that the estimate that GiveWell provides for the \"cost-per-life saved\" for AMF is not the correct number for estimating the expected value of a contribution to AMF.</p>\n<p class=\"MsoNormal\">In the section &ldquo;Concrete factors that further reduce the expected value of donating to AMF&rdquo; of my blog post&nbsp;<a href=\"/lw/hif/robustness_of_costeffectiveness_estimates_and/\">Robustness of Cost-Effectiveness Estimates and Philanthropy</a>, I listed eleven concrete factors that increase AMF&rsquo;s expected cost per life saved.</p>\n<p class=\"MsoNormal\">The reason why saving the child drowning in a pond in Singer&rsquo;s hypothetical is obviously the right thing to do is that the personal cost associated with doing so is negligible relative to the benefit to others. The cost of saving a life in the developing world by donating to AMF is at least 10x greater than the cost in Singer&rsquo;s &ldquo;child in a pond&rdquo; analogy, and possibly much greater. This&nbsp;<strong style=\"mso-bidi-font-weight:normal\">substantially weakens Singer&rsquo;s argument</strong>.</p>\n<p class=\"MsoNormal\">I raised this point in&nbsp;<a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/#comments\">a recent comment thread</a>&nbsp;on the GiveWell blog, and&nbsp;<a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/comment-page-1/#comment-572234\">Doug S. concurred, writing</a></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Honestly, there really is a big difference to me if X is different by orders of magnitude. The U.S. federal minimum wage is currently $7.25 an hour. Payroll taxes are 7.5%, so take-home pay becomes $6.70 an hour. It takes 343 hours &ndash; two months, working full time &ndash; working a minimum wage job to earn the $2300 it takes your #1 charity to save a life. There&rsquo;s a big difference between $200 and $2000, between one week of minimum wage work and two months of minimum wage work.</p>\n<p class=\"MsoNormal\">Holden&nbsp;<a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/comment-page-1/#comment-572696\">responded:</a></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">I think Jonah and Doug are both looking for more precision than is reasonable. Robust facts about disparities in wealth &ndash; which you will also see qualitatively if you travel to the developing world &ndash; are sufficient to make the point that you have a great deal of power to help others a lot by giving up a little. If you&rsquo;re looking for any sort of precise &ldquo;dollar cost per quantity of good accomplished&rdquo; (over and above the kind of robust comparisons I just described) such that a factor of 5-10 is crucial to how much you decide to give, I think it is &ndash; and long knowably has been &ndash; unrealistic to get such a thing. I think nearly all targets of Peter Singer&rsquo;s argument have long implicitly recognized this fact. Perhaps there are some arguments for which such precision would be necessary, but if so they aren&rsquo;t arguments that I see as having much traction. I don&rsquo;t empathize with the view that such precision is necessary in order to make the broad argument that you ought to give generously.</p>\n<p class=\"MsoNormal\">What Holden&rsquo;s comment misses is that&nbsp;<strong style=\"mso-bidi-font-weight: normal\">there&rsquo;s a big difference between the following two statements:</strong></p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">(1) &ldquo;A rough estimate for the cost of saving a life is the cost of an expensive pair of shoes, but it could be much higher or much lower&rdquo;<br /><br />(2) &ldquo;A rough estimate for the cost of saving a life is over 10x greater than the cost of an expensive pair of shoes, but the cost is probably higher, and possibly much higher, due to&nbsp;<a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">Bayesian regression</a>.&rdquo;&nbsp;</p>\n<p class=\"MsoNormal\">The problem with Singer&rsquo;s &ldquo;child in a pond&rdquo; analogy isn&rsquo;t that real world cost-effectiveness estimates aren&rsquo;t precise. The problem with Singer&rsquo;s &ldquo;child in a pond&rdquo; analogy is that&nbsp;<strong style=\"mso-bidi-font-weight: normal\">there&rsquo;s a strong case for the cost-effectiveness of donating to AMF being&nbsp;<em style=\"mso-bidi-font-style:normal\">vastly</em>&nbsp;<em style=\"mso-bidi-font-style: normal\">lower&nbsp;</em>than Singer&rsquo;s analogy suggests</strong>.</p>\n<p class=\"MsoNormal\">Peter Singer has been very successful in getting people interested in donating to alleviate global poverty. One could argue that his &nbsp;&ldquo;child in a pond&rdquo;&nbsp;contributed to his success, and that continuing to use it is, for this reason, justified. Nevertheless, the analogy is problematic.</p>\n<p class=\"MsoNormal\">Vipul Naik&nbsp;<a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/comment-page-1/#comment-572951\">wrote</a>&nbsp;(paraphrased):</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">There is a tension between the tactically optimal approach for convincing a larger number of people to donate more, and the argument that is most grounded in empirical reality. I think that rather than minimizing the tension, it&rsquo;s more courageous and epistemically admirable to openly and very explicitly admit that Singer-style (implicit or explicit) &ldquo;you-can-save-a-life-for-the-price-of-a-pair-of-shoes&rdquo; *if true*, would be far more compelling a reason to donate than the argument based on disparities in wealth.</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">See also&nbsp;<a href=\"/lw/dsv/is_politics_the_mindkiller_an_inconclusive_test/73zi\">this comment</a>&nbsp;where Carl Shulman writes: &ldquo;I think it&rsquo;s bad news for probably mistaken estimates to spread, and then disillusion the readers or make the writers look biased. If people interested in effective philanthropy go around trumpeting likely wrong (over-optimistic) figures and don&rsquo;t correct them, then the community&rsquo;s credibility will fall, and bad models and epistemic practices may be strengthened.&rdquo;</p>\n<p class=\"MsoNormal\">Singer's argument is not the only argument for donating to alleviate poverty in the developing world. For example, in&nbsp;<a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/\">a recent blog post</a>, Holden wrote:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">To us, the strongest form of the challenge [to donate to alleviate poverty in the developing world] is not &ldquo;How much should I give when $X saves a life?&rdquo; but &ldquo;How much should I give, knowing that I have massive wealth compared to the global poor?&rdquo; Perhaps the most vivid illustration comes not from Against Malaria Foundation (our #1-rated charity) but from GiveDirectly (our #2). If you give $1000 to GiveDirectly, ~$900 will end up in the hands of people whose resources are a tiny fraction of yours. GiveDirectly&rsquo;s estimate &ndash; which we believe is less sensitive to guesswork than &ldquo;cost per life saved&rdquo; figures &ndash; is that recipients live on ~65 cents per day, implying that such a donation could roughly double the annual consumption for a family of four, not counting any long term benefits.</p>\n<p class=\"MsoNormal\">As Vipul commented, this argument is much weaker than Singer&rsquo;s &ldquo;child in a pond&rdquo; argument.</p>\n<p class=\"MsoNormal\">In&nbsp;<a href=\"http://www.amazon.com/dp/0195108590\">Living High and Letting Die: Our Illusion of Innocence</a>&nbsp;(pg. 135) Peter Unger gives a Singer-style analogy that can be made more faithful to present day empirical realities than Singer&rsquo;s&nbsp;&ldquo;child in a pond&rdquo; analogy.&nbsp;The form of the argument (modified for use in the present context) is this:</p>\n<p class=\"MsoNormal\" style=\"padding-left: 30px;\">Imagine that you have a car that's worth AMF&rsquo;s actual cost per life saved. You park your car on unused train tracks and get out in order to walk around. You see a child playing in a tunnel off in the distance, and see a train headed toward the tunnel. If the train proceeds, the train will kill the child. You have access to a switch that can be used to divert the train toward the unused train tracks where your car is parked. If you flip the switch, the train will demolish your car, but nobody will be killed. Do you flip the switch?</p>\n<p class=\"MsoNormal\">I think that most people would say that flipping the switch is the right thing to do. But I don&rsquo;t think that they would say that the moral obligation is as great as the moral obligation in Singer's &ldquo;child in a pond&rdquo; scenario.</p>\n<p class=\"MsoNormal\"><strong>Acknowledgments:&nbsp;</strong>Thanks to Vipul Naik, Nick Beckstead and&nbsp;Luke Muehlhauser for helpful feedback on an earlier version of this post.</p>\n<p class=\"MsoNormal\"><strong>Note:&nbsp;</strong>I formerly worked as a research analyst at GiveWell. All views are my own.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"JsJPrdgRGRqnci8cZ": 1, "ZTRNmvQGgoYiymYnq": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "M8zgMmNCfpQxaKo8Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 39, "extendedScore": null, "score": 8.8e-05, "legacy": true, "legacyId": "23009", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 120, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rNuBzyWkigrf6BWg7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-20T15:26:56.192Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta: Self-Hacking", "slug": "meetup-atlanta-self-hacking", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nova_Division", "createdAt": "2011-03-14T15:21:15.124Z", "isAdmin": false, "displayName": "Nova_Division"}, "userId": "eFXLR4aNaxDBCDatT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NL6ydE2yHBHw43t8x/meetup-atlanta-self-hacking", "pageUrlRelative": "/posts/NL6ydE2yHBHw43t8x/meetup-atlanta-self-hacking", "linkUrl": "https://www.lesswrong.com/posts/NL6ydE2yHBHw43t8x/meetup-atlanta-self-hacking", "postedAtFormatted": "Thursday, June 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%3A%20Self-Hacking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%3A%20Self-Hacking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNL6ydE2yHBHw43t8x%2Fmeetup-atlanta-self-hacking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%3A%20Self-Hacking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNL6ydE2yHBHw43t8x%2Fmeetup-atlanta-self-hacking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNL6ydE2yHBHw43t8x%2Fmeetup-atlanta-self-hacking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 159, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nx'>Atlanta: Self-Hacking</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">23 June 2013 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Self-hacking - using tools from cognitive neuroscience and psychology and a generous application of rationality to make yourself more awesome.</p>\n\n<ul>\n<li><p>Introductions, and meet and greet for new members.</p></li>\n<li><p>Mini-presentation: Chris Zieman will be presenting on epistemology.</p></li>\n<li><p>Discussions. We\u2019ll start with a large group discussion and break into smaller groups as needed.</p></li>\n<li><p>Games!</p></li>\n</ul>\n\n<p>There's never any required homework for the Atlanta meetups, but everyone is encouraged to share their favorite self-hacking tricks.</p>\n\n<p>We're always excited to see new faces. All you have to do is show up!</p>\n\n<p>(Please contact me if you have allergies to cats, as our meeting space has two of the most adorable cats you\u2019ve ever seen.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nx'>Atlanta: Self-Hacking</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NL6ydE2yHBHw43t8x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2388726693083384e-06, "legacy": true, "legacyId": "23020", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta__Self_Hacking\">Discussion article for the meetup : <a href=\"/meetups/nx\">Atlanta: Self-Hacking</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">23 June 2013 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">2388 Lawrenceville Hwy. Apt L. Decatur, GA 30033</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Self-hacking - using tools from cognitive neuroscience and psychology and a generous application of rationality to make yourself more awesome.</p>\n\n<ul>\n<li><p>Introductions, and meet and greet for new members.</p></li>\n<li><p>Mini-presentation: Chris Zieman will be presenting on epistemology.</p></li>\n<li><p>Discussions. We\u2019ll start with a large group discussion and break into smaller groups as needed.</p></li>\n<li><p>Games!</p></li>\n</ul>\n\n<p>There's never any required homework for the Atlanta meetups, but everyone is encouraged to share their favorite self-hacking tricks.</p>\n\n<p>We're always excited to see new faces. All you have to do is show up!</p>\n\n<p>(Please contact me if you have allergies to cats, as our meeting space has two of the most adorable cats you\u2019ve ever seen.)</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Atlanta__Self_Hacking1\">Discussion article for the meetup : <a href=\"/meetups/nx\">Atlanta: Self-Hacking</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta: Self-Hacking", "anchor": "Discussion_article_for_the_meetup___Atlanta__Self_Hacking", "level": 1}, {"title": "Discussion article for the meetup : Atlanta: Self-Hacking", "anchor": "Discussion_article_for_the_meetup___Atlanta__Self_Hacking1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-20T20:51:33.213Z", "modifiedAt": null, "url": null, "title": "How would not having free will feel to you?", "slug": "how-would-not-having-free-will-feel-to-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:57.381Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "shminux", "createdAt": "2011-03-15T18:17:44.196Z", "isAdmin": false, "displayName": "shminux"}, "userId": "CpPz4596hmk9Pk8Jh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/twSoQPEwtyBwCSw7A/how-would-not-having-free-will-feel-to-you", "pageUrlRelative": "/posts/twSoQPEwtyBwCSw7A/how-would-not-having-free-will-feel-to-you", "linkUrl": "https://www.lesswrong.com/posts/twSoQPEwtyBwCSw7A/how-would-not-having-free-will-feel-to-you", "postedAtFormatted": "Thursday, June 20th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20would%20not%20having%20free%20will%20feel%20to%20you%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20would%20not%20having%20free%20will%20feel%20to%20you%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtwSoQPEwtyBwCSw7A%2Fhow-would-not-having-free-will-feel-to-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20would%20not%20having%20free%20will%20feel%20to%20you%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtwSoQPEwtyBwCSw7A%2Fhow-would-not-having-free-will-feel-to-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtwSoQPEwtyBwCSw7A%2Fhow-would-not-having-free-will-feel-to-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 345, "htmlBody": "<p>Given the spike in free-will debates on LW recently (blame Scott Aaronson), and the usual potentially answerable meta-question \"Why do we think we have free will?\", I am intrigued by a sub-question, \"what would it feel like to have/not have free will?\". The positive version of this question is not very interesting, almost everyone feels they have free will most all the time. The negative version is more interesting and I expect the answers to be more diverse. Here are a few off the top of my head, not necessarily mutually exclusive:</p>\n<p>Epistemic:</p>\n<ul>\n<li>Knowing that someone out there already predicts my behavior perfectly</li>\n<li>Knowing that someone out there can predict my behavior perfectly, whether or not they actually bother doing it</li>\n<li>Knowing that it is potentially possible to perfectly predict my behavior, even if I know that no one is doing it</li>\n<li>Knowing that I am in a simulation&nbsp;</li>\n<li>Knowing that I am in a simulation where repeated runs with the same inputs give identical outcomes</li>\n<li>...?</li>\n</ul>\n<p>Psychological:</p>\n<ul>\n<li>Feeling constrained by the environment to act in certain ways&nbsp;</li>\n<li>Feeling constrained by the environment to act in certain unsatisfactory ways</li>\n<li>Voices in my head compel me to do things&nbsp;</li>\n<li>Voices in my head compel me to do bad things&nbsp;</li>\n<li>Feeling unable to complete thoughts I would like to think through, as if someone censored them</li>\n<li>...?</li>\n</ul>\n<p>Physical:</p>\n<ul>\n<li>Observing myself act in ways I never intended to act, whether beneficial to me or not</li>\n<li>Observing my arms/legs/mouth move as if externally controlled, and being unable to interfere</li>\n<li>...?</li>\n</ul>\n<p>For me personally some of these are close to the feeling of \"no free will\" than others, but I am not sure if any single one crosses the boundary.</p>\n<p>I am sure that there are different takes on the answers and on how to categorize them. I think it would be useful to collect some perspectives and maybe have a poll or several after.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb1b8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "twSoQPEwtyBwCSw7A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 10, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "23021", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 70, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-21T02:51:47.116Z", "modifiedAt": null, "url": null, "title": "What makes you different from Tim Ferriss?", "slug": "what-makes-you-different-from-tim-ferriss", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.783Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SuspiciousTitForTat", "createdAt": "2013-06-14T04:27:15.092Z", "isAdmin": false, "displayName": "SuspiciousTitForTat"}, "userId": "QTMMRHpCT69PsE3M9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WSSQgzjWjsQK9qRF7/what-makes-you-different-from-tim-ferriss", "pageUrlRelative": "/posts/WSSQgzjWjsQK9qRF7/what-makes-you-different-from-tim-ferriss", "linkUrl": "https://www.lesswrong.com/posts/WSSQgzjWjsQK9qRF7/what-makes-you-different-from-tim-ferriss", "postedAtFormatted": "Friday, June 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20makes%20you%20different%20from%20Tim%20Ferriss%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20makes%20you%20different%20from%20Tim%20Ferriss%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWSSQgzjWjsQK9qRF7%2Fwhat-makes-you-different-from-tim-ferriss%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20makes%20you%20different%20from%20Tim%20Ferriss%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWSSQgzjWjsQK9qRF7%2Fwhat-makes-you-different-from-tim-ferriss", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWSSQgzjWjsQK9qRF7%2Fwhat-makes-you-different-from-tim-ferriss", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 738, "htmlBody": "<h6>Do not read this if you don't know anything about this Tim Ferriss person<br /></h6>\n<p>I suspect anyone here is less different from Tim Ferriss than they'd like to be able to justifiably claim (see <a href=\"/lw/63w/the_fourhour_body_by_timothy_ferriss_any_lwers/\">here</a>, <a href=\"/lw/448/on_the_effectiveness_of_ferriss/\">here</a>, <a href=\"/lw/5p6/how_and_why_to_granularize/\">here</a>, <a href=\"/lw/9fy/leveling_up_in_rationality_a_personal_journey/\">here</a>).&nbsp;</p>\n<p>I don't mean Tim the Result. Results are clouded by what has been brought to attention in one of the 2009/2010 rationality quotes here</p>\n<blockquote>\n<p>Were it possible to trace the succession of ideas in the mind of Sir Isaac Newton, during the time that he made his greatest discoveries, I make no doubt but our amazement at the extent of his genius would a little subside. But if, when a man publishes his discoveries, he either through a design, or through habit, omit the intermediary steps by which he himself arrived at them, it is no wonder that his speculations confound them, and that the generality of mankind stand amazed at his reach of thought. If a man ascend to the top of a building by the help of a common ladder, but cut away most of the steps after he has done with them, leaving only every ninth of tenth step, the view of the ladder, in the condition which he has pleased to exhibit it, gives us a prodigious, but unjust view of the man who could have made use of it. But if he had intended that any body should follow him, he should have left the ladder as he constructed it, or perhaps as he found it, for it might have been a mere accident that threw it in his way... I think that the interests of science have suffered by the excessive admiration and wonder with which several first rate philosophers are considered, and that an opinion of the greater equality of mankind, in point of genius, and power of understanding, would be of real service in the present age.\" - Joseph Priestly, The History and present State of Electricity</p>\n</blockquote>\n<p>I mean Tim the <em>method</em>.</p>\n<p>The varieties of achievements he's done are behaviourally distinct from living normal life. They are not so complicated to learn though.&nbsp;</p>\n<p>I invite you to ask the following question: What is one thing he's done I haven't that probably I could do, and what is the explanation I invented to myself for not having done it? Do I truly believe this explanation? Think for a minute before reading more</p>\n<p>When I ask this to friends who read some of his stuff, I see three kinds of answers:</p>\n<p>This is impossible for anyone who doesn't have property X (where X is always a fixed characteristic, like place of birth, blondness, impeccable genetic motivation)</p>\n<p>We have very different values, and there is no point in trying that about which I don't care - interestingly, with every new book, there are more interests on the table to be considered \"not my values\", but no one suddenly came to me and said: Wow, finally he cares about throwing knives! I have reason to try after all. Are my friends values narrowing in proportion to Tim's expansions?</p>\n<p>There are a lot of people who don't want to have more money, learn languages, work less, or travel a lot, but there are much fewer people who besides all of those don't want to exercise effectively, learn quickly, improve their sex lives, throw knives, memorize card decks, program, dance tango, become an angel investor, be famous, write books, cook well, get thinner, read quicker, contact interesting people, outsource boring stuff and so on...</p>\n<p>The third kind is personal attack. People claim he has property E, which makes him Evil, and his evil either is proof of the falsity of his accomplishments, or is proof that emulating Tim means you are a dark creature who shall not pass through the gates of heaven. The most interesting E's are \"He's a brilliant marketing man, selling profitable lies, but marketing is Evil.\" \"He doesn't understand survivor bias, and how lucky he was, and has not read <em>outliers </em>to know it takes min4000 hours to get good at stuff\" \"He's a good looking ivy league blonde, this makes him evil\" (this girl probably had in mind Nietzsche's lamb morality, from <em>Genealogy of Morals). <br /><br /></em>What is one thing he's done you haven't that probably you could do, and what is the explanation you invented to yourself for not having done it? Do you truly believe this explanation? Would your best rationalist friend truly believe that explanation?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WSSQgzjWjsQK9qRF7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": -13, "extendedScore": null, "score": 1.239398384573962e-06, "legacy": true, "legacyId": "23023", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5JwjSvfKspRRAi5n7", "YnrrAL8wynZvcACwG", "jTk9m75y2bpujwRfb", "HFYWpLNfdwnDwQ3wy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-21T14:52:41.818Z", "modifiedAt": null, "url": null, "title": "College Student Philanthropy and Funding Millenium Villages", "slug": "college-student-philanthropy-and-funding-millenium-villages", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.224Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "peter_hurford", "createdAt": "2011-07-19T19:05:31.793Z", "isAdmin": false, "displayName": "Peter Wildeford"}, "userId": "FMsXugZ8aB5d8nHsm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Kapc67HM8EHbY5Whc/college-student-philanthropy-and-funding-millenium-villages", "pageUrlRelative": "/posts/Kapc67HM8EHbY5Whc/college-student-philanthropy-and-funding-millenium-villages", "linkUrl": "https://www.lesswrong.com/posts/Kapc67HM8EHbY5Whc/college-student-philanthropy-and-funding-millenium-villages", "postedAtFormatted": "Friday, June 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20College%20Student%20Philanthropy%20and%20Funding%20Millenium%20Villages&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACollege%20Student%20Philanthropy%20and%20Funding%20Millenium%20Villages%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKapc67HM8EHbY5Whc%2Fcollege-student-philanthropy-and-funding-millenium-villages%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=College%20Student%20Philanthropy%20and%20Funding%20Millenium%20Villages%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKapc67HM8EHbY5Whc%2Fcollege-student-philanthropy-and-funding-millenium-villages", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKapc67HM8EHbY5Whc%2Fcollege-student-philanthropy-and-funding-millenium-villages", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1655, "htmlBody": "<p>One interesting idea comes from <a href=\"http://thelifeyoucansave.blogspot.com/2009/06/special-guest-blog.html\">\"How Students Can Support a Millennium Village?\"</a>, which talks about, obviously, funding a Millenium Village: &nbsp;(See also <a href=\"http://newsroom.carleton.ca/2009/04/02/carleton-students-approve-student-levy-for-millennium-villages-project/\">the school's news report</a>.)</p>\n<blockquote>\n<p>Last year at Carleton University our group, Students To End Extreme Poverty, worked to get a question to referendum where students voted on whether or not they would all have to automatically pay an additional $6 in tuition fees ($5352 instead of $5346) to help support a Millennium Village. It worked. Carleton students now contribute over $110,000 annually.</p>\n<p>Here is our hope: By getting enough universities and organizations to support Millennium Villages (aside from helping a couple communities help themselves out of extreme poverty) it would raise enough awareness, get enough media attention, engage enough people, foster enough cooperation, and generate enough civil society will to see policy changes: more and better aid, fairer trade, and debt cancellation.</p>\n<p>Worst case scenario: thousands of people, many of whom would otherwise be dead, will have the basic tools they need to lift themselves out of extreme poverty.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Might this be a plausible thing to try and do on other college campuses?</p>\n<p>With an additional $6 per student, at my university, Denison University, we could raise $12,792 per year in philanthropy. &nbsp;To reach Carleton's level, we'd need $51.80 per student per year. &nbsp;At $12,792, we could fund 213 people to <a href=\"http://www.millenniumvillages.org/the-villages\">live in a Millenium Village</a>.</p>\n<p>&nbsp;</p>\n<h2>The Impact of College Philanthropy</h2>\n<p>What exactly is the impact of college philanthropy? &nbsp;Philanthropic dollars certainly aren't useless, and the age-old saying that \"anything helps\" is certainly true. &nbsp;But many social problems would require money on the scale of millions, if not billions, of dollars to help solve. &nbsp;Student giving is typically on the scale of thousands. &nbsp;Raise $10 from each of Denison's students, and you'll be getting $21320, assuming everyone contributes. &nbsp;What's that worth?</p>\n<p><strong>College philanthropy raises awareness.</strong> A liberal arts school, such as Denison, wants to provide training to students in recognizing (and hopefully responding to) social issues. &nbsp;By raising money for a cause, one is able to raise awareness for the cause by educating people about it. &nbsp;Hopefully this raised awareness will translate into more action around the issue further dwn the road, even if money can't be raised more. &nbsp;It signals that this issue is one worth taking seriously.</p>\n<p><strong>$21230 can do some good on it's own.</strong>&nbsp; It's enough to provide a scholarship to fund a semester of tuition and costs for one student. &nbsp;It's enough to <a href=\"http://www.eriefoodbank.org/Content.aspx?Section=about-us\">buy 148000 pounds of food for a food pantry</a>. &nbsp;It's enough to fund 5000 <a href=\"http://www.againstmalaria.com/WhyNets.aspx\">anti-malaria bed nets</a>. &nbsp;It's enough to <a href=\"http://www3.imperial.ac.uk/schisto/whatwedo\">fund over 40,000 deworming treatments</a>. &nbsp;Don't underestimate the impact of $21230.</p>\n<p><strong>College philanthropy builds a giving habit.</strong>&nbsp; Perhaps most importantly, students giving now help cement the habit of giving in the future when they have much more to give. &nbsp;Colleges recognize that <a href=\"http://www.slate.com/content/slate/blogs/scocca/2010/10/27/cornell_and_dartmouth_shame_students_for_not_adding_their_real_money_to_the_ongoing_bonfire_of_imaginary_money.html\">senior class gifts often make up &lt;0.01% of their endowments</a>&nbsp;and often put more money into fundraising than they immediately return, with the acknowledgement that the real return comes further down the road -- <a href=\"http://yaleherald.com/news-and-features/features/giving-in-or-not-strife-solicitation-and-the-senior-class-gift/\">\"One day, it&rsquo;s five dollars; later it&rsquo;s 5,000; in 2042, Yale gets Smith Tower or the Johnson Fellowship.\"</a>&nbsp; And while causation between earlier giving and later giving is still unclear, the correlation has been found to be rather strong (<a href=\"http://www.princeton.edu/ceps/workingpapers/210rosen.pdf\">Rosen and Sims 2010, PDF</a>; <a href=\"http://econweb.tamu.edu/jmeer/Meer_Habit_of_Giving_FINAL.pdf\">Meer 2011, PDF</a>). &nbsp;$21230 raised now could easily become $2 million raised within ten years.</p>\n<p><strong>It improves the reputation and desirability of the university.</strong>&nbsp;People would see students engaged in this kind of project and understand that students at this university do come together and care about social problems outside their world; they're not just trapped in a bubble. &nbsp;And the university could get favorable press coverage from the new policy.</p>\n<p>&nbsp;</p>\n<h2>Thinking Through the Idea</h2>\n<p>However, I have some questions:</p>\n<p><strong>Is Millenium Villages the best philanthropy?</strong></p>\n<p>The trade-off I imagine here is between the impact-per-person of the chosen cause and the likeliness that students will choose to endorse it. &nbsp;GiveWell, a non-profit evaluator, <a href=\"http://blog.givewell.org/2012/05/18/millennium-villages-project/\">has criticized</a>&nbsp;Millenium Village has not yet \"demonstrated cost-effective or sustainable benefits\". &nbsp;GiveWell's <a href=\"http://www.givewell.org/charities/top-charities\">top charities</a>&nbsp;would likely do better. &nbsp;Much stranger causes, like vegan outreach or existential risk, I think have potentially even higher impact, but are extremely unlikely to attract people to signing on.</p>\n<p>One might also consider helping the local community surrounding the college; in Denison's case, Licking County. &nbsp;There certainly is need in the area, with several low-income areas, like Newark. &nbsp;My push back against this would be that <a href=\"http://www.givewell.org/want-to-change-peoples-lives-give-internationally\">the need is significantly higher overseas</a>&nbsp;and Denison is already putting money and service hours into the local community. &nbsp;But the desire to support a local community is very high, much more so than overseas.</p>\n<p>Perhaps we could consider splitting? &nbsp;Or perhaps the split would just confuse people, making them overall less likely to support the idea?</p>\n<p>&nbsp;</p>\n<p><strong>Is the tuition raise the best model?</strong></p>\n<p>The interesting thing about Carleton's model is that they're not just getting behind tables and asking students who walk by to put money in a box. &nbsp;Instead, students were voting on whether to pass the small levy onto all students. &nbsp;It was optional in the sense that students could have voted the levy down and rejected the increase, but it's mandatory in the sense that the levy passing meant that even students who voted no would be coerced into donation as part of their student fees.</p>\n<p>This plan has some important benefits. &nbsp;I think the coercion is an important effect -- people are more likely to donate when others around them are doing so and being secure in the knowledge that everyone will have to contribute the same should make people more likely to get engaged. &nbsp;And it also is a lot more successful at raising money than normal fundraisers, given that 100% participation is very unlikely.</p>\n<p>However, there are drawbacks. &nbsp;By introducing the levy and then forgetting about it, one gains the initial donation, but loses the opportunity to raise awareness or set students up to be <em>future</em> donors, which probably has more impact than the initial donation itself. &nbsp;And there's an issue of unfairness -- those who vote \"no\" are still being coerced and given that students also graduate and are slowly replaced, it might be unfair to pass this cost on to future students as well.</p>\n<p>&nbsp;</p>\n<p>There are some alternatives that could get most of the benefits while also getting rid of some of the drawbacks.</p>\n<p>Perhaps one could add a check box to the tuition bill that allows one to optionally add the $6 to their tuition bill. &nbsp;Or perhaps one could take a page out of knowing that people are far less likely to opt-in than they are to opt-out and go for opt-out philanthropy, enable the donation by default, and make people check the box if they want to be <em>removed</em>&nbsp;from the donation pool.</p>\n<p>Furthermore, perhaps the levy could come up for a vote every year. &nbsp;Assuming the levy keeps getting passed, this would have the benefit of continuing the program, while also annually raising awareness for the cause and hopefully encouraging students to donate after they graduate. &nbsp;Of course, this \"risks\" ending the levy, which would be unfortunate for those whom the levy benefits, but would give people an outlet to address the unfairness of coercion.</p>\n<p>I suppose one could also ditch the levy model altogether and go back to the fundraising behind the table kind of deal that's pretty popular (and occasionally still enormously successful) with senior class gifts already.</p>\n<p>&nbsp;</p>\n<p><strong>Is $6 per student the best target?</strong></p>\n<p>There's also the trade-off of being able to raise even more money by asking for more, but turning off those who won't give the higher amount, but would have given a lower amount.</p>\n<p>With a levy, this consideration is important, because people might oppose it solely based on the amount of money it intends to raise. &nbsp;It seems that the $6 wouldn't be controversial in the same way my non-serious $51.80 suggestion would be, for example.</p>\n<p>Of course, one could modify the levy model so that people can define their own amount they want to give, perhaps even allowing for one to give $0, thus allowing people to give as much or as little as they wanted. &nbsp;But by coercing everyone to give a certain amount, one is likely to get more money than one would've otherwise, I think.</p>\n<p>&nbsp;</p>\n<p>When I first heard of the Millenium Village idea, I thought Carleton was able to fund an entire village, which would make the contribution per student that which is needed to fund the village, which would be satisfying and not arbitrary. &nbsp;But these villages take millions of dollars per year, so their contribution still was a largely arbitrary amount. &nbsp;Going back to my previous question, I wonder if there's anything that can be funded which would produce a doable and non-arbitrary contribution...</p>\n<p>Though, overall, I think one could get more by requesting more than $6. &nbsp;Right now, my best guess is the ideal target would be $9, taking advantage of <a href=\"http://en.wikipedia.org/wiki/Psychological_pricing\">psychological pricing</a>&nbsp;-- as compared to, say, asking for $10, which seems a lot higher, though I haven't seen any evidence that psychological pricing happens in philanthropy. &nbsp;$9 per year would put the individual Denisonian down for $36 in his or her undergraduate career and would raise $19,107 a year.</p>\n<p>&nbsp;</p>\n<p><strong>Is there a way to leverage this for more money?</strong></p>\n<p>One other potential idea I would have is to explore the idea of matching gifts. &nbsp;Perhaps not only would the students commit to $9/year (or some amount), but the administrators (and perhaps even trustees, staff, faculty, or other people) of the college would also commit to matching the total amount raised by the students this way (or even more, or less, or their own specific amount per year, or something).</p>\n<p>This comes from the idea of \"challenges\" -- For example, a George Washington Trustee <a href=\"http://www.gwhatchet.com/2012/01/17/trustee-sets-high-bar-for-senior-class-gift/\">offered $50,000 if half the class donated</a>&nbsp;to the Senior Class gift. &nbsp;Getting the administrators/trustees/staff/faculty/other on board along with the students would probably make the idea even more popular and would increase the total size of the gift.</p>\n<p>-</p>\n<address>Also <a href=\"http://www.everydayutilitarian.com/essays/college-student-philanthropy-and-funding-millenium-villages/\">cross-posted on my blog</a> and <a href=\"http://felicifia.org/viewtopic.php?f=25&amp;t=920\">on Felicifia</a>.<br /><br /></address>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Kapc67HM8EHbY5Whc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 1.2399522097745222e-06, "legacy": true, "legacyId": "23033", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>One interesting idea comes from <a href=\"http://thelifeyoucansave.blogspot.com/2009/06/special-guest-blog.html\">\"How Students Can Support a Millennium Village?\"</a>, which talks about, obviously, funding a Millenium Village: &nbsp;(See also <a href=\"http://newsroom.carleton.ca/2009/04/02/carleton-students-approve-student-levy-for-millennium-villages-project/\">the school's news report</a>.)</p>\n<blockquote>\n<p>Last year at Carleton University our group, Students To End Extreme Poverty, worked to get a question to referendum where students voted on whether or not they would all have to automatically pay an additional $6 in tuition fees ($5352 instead of $5346) to help support a Millennium Village. It worked. Carleton students now contribute over $110,000 annually.</p>\n<p>Here is our hope: By getting enough universities and organizations to support Millennium Villages (aside from helping a couple communities help themselves out of extreme poverty) it would raise enough awareness, get enough media attention, engage enough people, foster enough cooperation, and generate enough civil society will to see policy changes: more and better aid, fairer trade, and debt cancellation.</p>\n<p>Worst case scenario: thousands of people, many of whom would otherwise be dead, will have the basic tools they need to lift themselves out of extreme poverty.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>Might this be a plausible thing to try and do on other college campuses?</p>\n<p>With an additional $6 per student, at my university, Denison University, we could raise $12,792 per year in philanthropy. &nbsp;To reach Carleton's level, we'd need $51.80 per student per year. &nbsp;At $12,792, we could fund 213 people to <a href=\"http://www.millenniumvillages.org/the-villages\">live in a Millenium Village</a>.</p>\n<p>&nbsp;</p>\n<h2 id=\"The_Impact_of_College_Philanthropy\">The Impact of College Philanthropy</h2>\n<p>What exactly is the impact of college philanthropy? &nbsp;Philanthropic dollars certainly aren't useless, and the age-old saying that \"anything helps\" is certainly true. &nbsp;But many social problems would require money on the scale of millions, if not billions, of dollars to help solve. &nbsp;Student giving is typically on the scale of thousands. &nbsp;Raise $10 from each of Denison's students, and you'll be getting $21320, assuming everyone contributes. &nbsp;What's that worth?</p>\n<p><strong>College philanthropy raises awareness.</strong> A liberal arts school, such as Denison, wants to provide training to students in recognizing (and hopefully responding to) social issues. &nbsp;By raising money for a cause, one is able to raise awareness for the cause by educating people about it. &nbsp;Hopefully this raised awareness will translate into more action around the issue further dwn the road, even if money can't be raised more. &nbsp;It signals that this issue is one worth taking seriously.</p>\n<p><strong>$21230 can do some good on it's own.</strong>&nbsp; It's enough to provide a scholarship to fund a semester of tuition and costs for one student. &nbsp;It's enough to <a href=\"http://www.eriefoodbank.org/Content.aspx?Section=about-us\">buy 148000 pounds of food for a food pantry</a>. &nbsp;It's enough to fund 5000 <a href=\"http://www.againstmalaria.com/WhyNets.aspx\">anti-malaria bed nets</a>. &nbsp;It's enough to <a href=\"http://www3.imperial.ac.uk/schisto/whatwedo\">fund over 40,000 deworming treatments</a>. &nbsp;Don't underestimate the impact of $21230.</p>\n<p><strong>College philanthropy builds a giving habit.</strong>&nbsp; Perhaps most importantly, students giving now help cement the habit of giving in the future when they have much more to give. &nbsp;Colleges recognize that <a href=\"http://www.slate.com/content/slate/blogs/scocca/2010/10/27/cornell_and_dartmouth_shame_students_for_not_adding_their_real_money_to_the_ongoing_bonfire_of_imaginary_money.html\">senior class gifts often make up &lt;0.01% of their endowments</a>&nbsp;and often put more money into fundraising than they immediately return, with the acknowledgement that the real return comes further down the road -- <a href=\"http://yaleherald.com/news-and-features/features/giving-in-or-not-strife-solicitation-and-the-senior-class-gift/\">\"One day, it\u2019s five dollars; later it\u2019s 5,000; in 2042, Yale gets Smith Tower or the Johnson Fellowship.\"</a>&nbsp; And while causation between earlier giving and later giving is still unclear, the correlation has been found to be rather strong (<a href=\"http://www.princeton.edu/ceps/workingpapers/210rosen.pdf\">Rosen and Sims 2010, PDF</a>; <a href=\"http://econweb.tamu.edu/jmeer/Meer_Habit_of_Giving_FINAL.pdf\">Meer 2011, PDF</a>). &nbsp;$21230 raised now could easily become $2 million raised within ten years.</p>\n<p><strong>It improves the reputation and desirability of the university.</strong>&nbsp;People would see students engaged in this kind of project and understand that students at this university do come together and care about social problems outside their world; they're not just trapped in a bubble. &nbsp;And the university could get favorable press coverage from the new policy.</p>\n<p>&nbsp;</p>\n<h2 id=\"Thinking_Through_the_Idea\">Thinking Through the Idea</h2>\n<p>However, I have some questions:</p>\n<p><strong id=\"Is_Millenium_Villages_the_best_philanthropy_\">Is Millenium Villages the best philanthropy?</strong></p>\n<p>The trade-off I imagine here is between the impact-per-person of the chosen cause and the likeliness that students will choose to endorse it. &nbsp;GiveWell, a non-profit evaluator, <a href=\"http://blog.givewell.org/2012/05/18/millennium-villages-project/\">has criticized</a>&nbsp;Millenium Village has not yet \"demonstrated cost-effective or sustainable benefits\". &nbsp;GiveWell's <a href=\"http://www.givewell.org/charities/top-charities\">top charities</a>&nbsp;would likely do better. &nbsp;Much stranger causes, like vegan outreach or existential risk, I think have potentially even higher impact, but are extremely unlikely to attract people to signing on.</p>\n<p>One might also consider helping the local community surrounding the college; in Denison's case, Licking County. &nbsp;There certainly is need in the area, with several low-income areas, like Newark. &nbsp;My push back against this would be that <a href=\"http://www.givewell.org/want-to-change-peoples-lives-give-internationally\">the need is significantly higher overseas</a>&nbsp;and Denison is already putting money and service hours into the local community. &nbsp;But the desire to support a local community is very high, much more so than overseas.</p>\n<p>Perhaps we could consider splitting? &nbsp;Or perhaps the split would just confuse people, making them overall less likely to support the idea?</p>\n<p>&nbsp;</p>\n<p><strong id=\"Is_the_tuition_raise_the_best_model_\">Is the tuition raise the best model?</strong></p>\n<p>The interesting thing about Carleton's model is that they're not just getting behind tables and asking students who walk by to put money in a box. &nbsp;Instead, students were voting on whether to pass the small levy onto all students. &nbsp;It was optional in the sense that students could have voted the levy down and rejected the increase, but it's mandatory in the sense that the levy passing meant that even students who voted no would be coerced into donation as part of their student fees.</p>\n<p>This plan has some important benefits. &nbsp;I think the coercion is an important effect -- people are more likely to donate when others around them are doing so and being secure in the knowledge that everyone will have to contribute the same should make people more likely to get engaged. &nbsp;And it also is a lot more successful at raising money than normal fundraisers, given that 100% participation is very unlikely.</p>\n<p>However, there are drawbacks. &nbsp;By introducing the levy and then forgetting about it, one gains the initial donation, but loses the opportunity to raise awareness or set students up to be <em>future</em> donors, which probably has more impact than the initial donation itself. &nbsp;And there's an issue of unfairness -- those who vote \"no\" are still being coerced and given that students also graduate and are slowly replaced, it might be unfair to pass this cost on to future students as well.</p>\n<p>&nbsp;</p>\n<p>There are some alternatives that could get most of the benefits while also getting rid of some of the drawbacks.</p>\n<p>Perhaps one could add a check box to the tuition bill that allows one to optionally add the $6 to their tuition bill. &nbsp;Or perhaps one could take a page out of knowing that people are far less likely to opt-in than they are to opt-out and go for opt-out philanthropy, enable the donation by default, and make people check the box if they want to be <em>removed</em>&nbsp;from the donation pool.</p>\n<p>Furthermore, perhaps the levy could come up for a vote every year. &nbsp;Assuming the levy keeps getting passed, this would have the benefit of continuing the program, while also annually raising awareness for the cause and hopefully encouraging students to donate after they graduate. &nbsp;Of course, this \"risks\" ending the levy, which would be unfortunate for those whom the levy benefits, but would give people an outlet to address the unfairness of coercion.</p>\n<p>I suppose one could also ditch the levy model altogether and go back to the fundraising behind the table kind of deal that's pretty popular (and occasionally still enormously successful) with senior class gifts already.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Is__6_per_student_the_best_target_\">Is $6 per student the best target?</strong></p>\n<p>There's also the trade-off of being able to raise even more money by asking for more, but turning off those who won't give the higher amount, but would have given a lower amount.</p>\n<p>With a levy, this consideration is important, because people might oppose it solely based on the amount of money it intends to raise. &nbsp;It seems that the $6 wouldn't be controversial in the same way my non-serious $51.80 suggestion would be, for example.</p>\n<p>Of course, one could modify the levy model so that people can define their own amount they want to give, perhaps even allowing for one to give $0, thus allowing people to give as much or as little as they wanted. &nbsp;But by coercing everyone to give a certain amount, one is likely to get more money than one would've otherwise, I think.</p>\n<p>&nbsp;</p>\n<p>When I first heard of the Millenium Village idea, I thought Carleton was able to fund an entire village, which would make the contribution per student that which is needed to fund the village, which would be satisfying and not arbitrary. &nbsp;But these villages take millions of dollars per year, so their contribution still was a largely arbitrary amount. &nbsp;Going back to my previous question, I wonder if there's anything that can be funded which would produce a doable and non-arbitrary contribution...</p>\n<p>Though, overall, I think one could get more by requesting more than $6. &nbsp;Right now, my best guess is the ideal target would be $9, taking advantage of <a href=\"http://en.wikipedia.org/wiki/Psychological_pricing\">psychological pricing</a>&nbsp;-- as compared to, say, asking for $10, which seems a lot higher, though I haven't seen any evidence that psychological pricing happens in philanthropy. &nbsp;$9 per year would put the individual Denisonian down for $36 in his or her undergraduate career and would raise $19,107 a year.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Is_there_a_way_to_leverage_this_for_more_money_\">Is there a way to leverage this for more money?</strong></p>\n<p>One other potential idea I would have is to explore the idea of matching gifts. &nbsp;Perhaps not only would the students commit to $9/year (or some amount), but the administrators (and perhaps even trustees, staff, faculty, or other people) of the college would also commit to matching the total amount raised by the students this way (or even more, or less, or their own specific amount per year, or something).</p>\n<p>This comes from the idea of \"challenges\" -- For example, a George Washington Trustee <a href=\"http://www.gwhatchet.com/2012/01/17/trustee-sets-high-bar-for-senior-class-gift/\">offered $50,000 if half the class donated</a>&nbsp;to the Senior Class gift. &nbsp;Getting the administrators/trustees/staff/faculty/other on board along with the students would probably make the idea even more popular and would increase the total size of the gift.</p>\n<p>-</p>\n<address>Also <a href=\"http://www.everydayutilitarian.com/essays/college-student-philanthropy-and-funding-millenium-villages/\">cross-posted on my blog</a> and <a href=\"http://felicifia.org/viewtopic.php?f=25&amp;t=920\">on Felicifia</a>.<br><br></address>", "sections": [{"title": "The Impact of College Philanthropy", "anchor": "The_Impact_of_College_Philanthropy", "level": 1}, {"title": "Thinking Through the Idea", "anchor": "Thinking_Through_the_Idea", "level": 1}, {"title": "Is Millenium Villages the best philanthropy?", "anchor": "Is_Millenium_Villages_the_best_philanthropy_", "level": 2}, {"title": "Is the tuition raise the best model?", "anchor": "Is_the_tuition_raise_the_best_model_", "level": 2}, {"title": "Is $6 per student the best target?", "anchor": "Is__6_per_student_the_best_target_", "level": 2}, {"title": "Is there a way to leverage this for more money?", "anchor": "Is_there_a_way_to_leverage_this_for_more_money_", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-21T15:36:19.531Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-76", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/dAXu849JEFCnv4K8x/weekly-lw-meetups-76", "pageUrlRelative": "/posts/dAXu849JEFCnv4K8x/weekly-lw-meetups-76", "linkUrl": "https://www.lesswrong.com/posts/dAXu849JEFCnv4K8x/weekly-lw-meetups-76", "postedAtFormatted": "Friday, June 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdAXu849JEFCnv4K8x%2Fweekly-lw-meetups-76%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdAXu849JEFCnv4K8x%2Fweekly-lw-meetups-76", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdAXu849JEFCnv4K8x%2Fweekly-lw-meetups-76", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 523, "htmlBody": "<p><strong>This summary was posted to LW main on June 14th. The following week's summary is <a href=\"/lw/hru/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a href=\"/meetups/n6\">Atlanta LessWrong June Meetup: Effective Altruism:&nbsp;<span class=\"date\">15 June 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/lo\">Berlin Social Meetup:&nbsp;<span class=\"date\">15 June 2013 05:00PM</span></a></li>\n<li><a href=\"/meetups/ng\">Bratislava Meetup IV.:&nbsp;<span class=\"date\">24 June 2013 06:00PM</span></a></li>\n<li><a href=\"/meetups/nk\">[Bristol] Second Bristol meetup &amp; mailing list for future meetups:&nbsp;<span class=\"date\">16 June 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/nn\">London Social - Exposure to Direct Sunlight - June 23rd:&nbsp;<span class=\"date\">23 June 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/nq\">Washington DC projects planning meetup:&nbsp;<span class=\"date\">16 June 2013 03:00AM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">22 June 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/no\">[Boston/Cambridge MA] The Psychology of Marketing:&nbsp;<span class=\"date\">16 June 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/nm\">[Melbourne] Rationalist Housewarming at Isengard (Melbourne):&nbsp;<span class=\"date\">15 June 2013 08:00PM</span></a></li>\n<li><a href=\"/meetups/nd\">Vienna Meetup #3:&nbsp;<span class=\"date\">15 June 2013 03:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "dAXu849JEFCnv4K8x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2399857405215505e-06, "legacy": true, "legacyId": "22945", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["N9ycoenukgFKDutJs", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-21T17:35:38.193Z", "modifiedAt": null, "url": null, "title": "Seeking descriptions of deciban-levels", "slug": "seeking-descriptions-of-deciban-levels", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.520Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/99g4eZY3FKwfhPC83/seeking-descriptions-of-deciban-levels", "pageUrlRelative": "/posts/99g4eZY3FKwfhPC83/seeking-descriptions-of-deciban-levels", "linkUrl": "https://www.lesswrong.com/posts/99g4eZY3FKwfhPC83/seeking-descriptions-of-deciban-levels", "postedAtFormatted": "Friday, June 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seeking%20descriptions%20of%20deciban-levels&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeeking%20descriptions%20of%20deciban-levels%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F99g4eZY3FKwfhPC83%2Fseeking-descriptions-of-deciban-levels%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seeking%20descriptions%20of%20deciban-levels%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F99g4eZY3FKwfhPC83%2Fseeking-descriptions-of-deciban-levels", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F99g4eZY3FKwfhPC83%2Fseeking-descriptions-of-deciban-levels", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 328, "htmlBody": "<p>As part of <a href=\"http://blog.datapacrat.com/2013/06/08/early-draft-for-nym-uri/\">a small project</a> I'm working on, I need to have at least a rough description of how a given number of decibans translates into a subjective level of confidence, described in a way that can be understood by people who've never come across the idea before.</p>\n<p>Some previous discussion has involved the practical <a href=\"/r/all/lw/ge8/how_confident_are_you_in_the_atomic_theory_of/\">maximum number of decibans</a>, that <a href=\"/lw/hoi/are_imaginary_and_complex_numbers_of_decibans/\">imaginary and complex decibans</a> aren't relevant here, a <a href=\"/lw/buh/the_quick_bayes_table/\">quick reference table</a>, and <a href=\"http://www.orionsarm.com/eg-article/4d5bf17b86585\">another reference table</a>.</p>\n<p><a id=\"more\"></a>Here's my first attempt an an approach: list some of the more memorable numbers of decibans, and give a rough description of that confidence level (being applied to identity verification, where possible). I'm open to any alternate approaches, and/or ways to improve this one.</p>\n<p>&nbsp;</p>\n<p>While people tend to be very bad at assigning accurate confidence levels (eg, when people claim to be 90% sure of something, they're often wrong 50% of the time), their initial estimates of their confidence levels can be used as the inputs for more sophisticated Bayesian algorithms. Until such time as more accurate estimates are available, here are some possible sample confidence levels:</p>\n<p>0 decibans: 50%: You're not sure whether the last digit of the phone number is a 3 or a 5.</p>\n<p>1 decibans: 55% Just slightly more likely than not; a business card handed to you by a stranger.</p>\n<p>Up to 10 decibans: to 90%: Someone you've chatted to for an evening.</p>\n<p>Up to 20 decibans: to 99%: A distant acquaintance, who you talk to once a year.</p>\n<p>Up to 30 decibans: to 99.9%: A co-worker who might have been re-organized into a new email since you last heard from them.</p>\n<p>Up to 40 decibans: to 99.99%: A family member, who you might accidentally have mis-spelled the email address of.</p>\n<p>Around 100 decibans: Your own personal information, closely checked. (There's still a theoretical chance that you're wrong, just as there's a theoretical chance that you're the star of something like the Truman Show.)</p>\n<p>127 decibans: Data which relies on yourself alone, thoroughly re-checked and confirmed by others.&lt;/p&gt;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "99g4eZY3FKwfhPC83", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 2, "extendedScore": null, "score": 1.240077445295925e-06, "legacy": true, "legacyId": "23037", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tcexZfZR2H2Xjatgm", "cwqHLp6sMRQ72DLfY", "GDLP8MjvyhK3wx6hc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-21T17:56:20.450Z", "modifiedAt": null, "url": null, "title": "240 questions for your utility function", "slug": "240-questions-for-your-utility-function", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.811Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HumanitiesResearcher", "createdAt": "2013-04-17T00:29:54.394Z", "isAdmin": false, "displayName": "HumanitiesResearcher"}, "userId": "krzmxqznjbPm6WW2D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/whKimKQNGhH5QKe65/240-questions-for-your-utility-function", "pageUrlRelative": "/posts/whKimKQNGhH5QKe65/240-questions-for-your-utility-function", "linkUrl": "https://www.lesswrong.com/posts/whKimKQNGhH5QKe65/240-questions-for-your-utility-function", "postedAtFormatted": "Friday, June 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20240%20questions%20for%20your%20utility%20function&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A240%20questions%20for%20your%20utility%20function%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwhKimKQNGhH5QKe65%2F240-questions-for-your-utility-function%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=240%20questions%20for%20your%20utility%20function%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwhKimKQNGhH5QKe65%2F240-questions-for-your-utility-function", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwhKimKQNGhH5QKe65%2F240-questions-for-your-utility-function", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1847, "htmlBody": "<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">A game comparing intrinsic values can approximate a person's utility function.</span></p>\n<hr />\n<p style=\"margin-bottom: 0in;\"><a id=\"more\"></a></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>First joke:\tAn economist can answer any question phrased in terms of money.</em></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>Second joke:\tAn economist receives a call from his artist friend. The artist is flying in to town, would like to visit the economist, and needs to be picked up at the airport. The economist agrees, and pays a cab to pick up the artist. The artist arrives by cab and demands an explanation for this slight. The economist explains that the opportunity cost of personally performing the favor was higher than the cost of a cab. The artist then tears up a bush in the front lawn of the economist, explaining: &ldquo;The whole point of being friends is to suffer together.&rdquo;</em></span></p>\n<h3>Abstractions</h3>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> Let's begin with the assumption that human utility is complex. Specifically, the complexity of utility seems to come from the number of intrinsic goods, summarized by M. Zimmerman and quoted by W. Frankena as:</span></p>\n<p style=\"margin-left: 0.51in; margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">Life, consciousness, and activity; health and strength; pleasures and satisfactions of all or certain kinds; happiness, beatitude, contentment, etc.; truth; knowledge and true opinions of various kinds, understanding and wisdom; beauty, harmony, proportion in objects contemplated; aesthetic experience; morally good dispositions or virtues; mutual affection, love, friendship, cooperation; just distribution of goods and evils; harmony and proportion in ones' own life; power and experiences of achievement; self-expression; freedom; peace, security; adventure and novelty; and good reputation, honor, esteem, etc.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">This list of intrinsic goods makes intuitive sense to me, and I'll return to it throughout the post. I'm predisposed to think that decisions become agonizing only with conflicting imperatives. My experience from Judgment &amp; Decision Making class taught me that it's relatively simple to calculate a rational choice for a complex decision like buying a car, provided an extraneous utility function. </span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> <strong>I believe </strong>that the list of intrinsic values is the key. I believe that a human utility function can be succinctly and robustly described by 120 ratios, generated from pairwise comparisons of sixteen intrinsic values. The sixteen intrinsic values are a variation on Frankena's list. The variation includes only two changes: the merger of &ldquo;truth&rdquo; with &ldquo;knowledge... wisdom,&rdquo; and the merger of &ldquo;beauty...&rdquo; and &ldquo;aesthetic experience.&rdquo; Sixteen intrinsic values yield 120 pairwise combinations: eg, &ldquo;Truth, knowledge, and true opinions of various kinds, understanding and wisdom&rdquo; and &ldquo; beauty, harmony, proportion in objects contemplated, aesthetic experience.&rdquo; Compare these values. Do you value one more highly than the other? More accurately, <strong>to what degree</strong><em> </em>do you value one more highly than the other? I believe that the degree to which you value one more than the other can be expressed as a ratio (ranging from the golden moderation of 1:1 all the way to the extremism of 1:0, and including everything in between, such as 7841:7853). Further research may introduce a curve to this description for more accuracy, but a ratio is the first step towards that. If a microeconomist had a list of 120 ratios between each value, she could describe a great deal of a rational agent's behavior in a wide new variety of contexts.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><br /></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em> Third joke (Eliezer's): &ldquo;Many commonly used priors are listed in the Handbook of Chemistry and Physics.&rdquo;</em></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em><br /></em></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">Obviously, your utility function is not in the back of the book. </span></p>\n<h3>Applications</h3>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> The real problem comes is that you don't have access to your own utility function, and that your utility function changes in response to experience. Every advertiser and salesman holds this to be true: when a customer walks onto a car lot, the salesman proceeds with the assumption that <strong>she doesn't know what she wants yet</strong>; when a viewer sees an advertisement on TV, she views an ad based on the assumption that <strong>her desires can be changed from outside</strong>. The second problem, the problem of a responsive utility function, seems more mathematically difficult, but fit for a Bayesian model. The first problem is only obscure due to a lack of self-examination. In Rumsfeldian terms, it is an &ldquo;unknown known,&rdquo; or something that you don't know (explicitly) that you know (implicitly).</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> There are lots of ways to access &ldquo;unknown knowns.&rdquo; Most commonly, others notice truths about ourselves. (The bias of illusory superiority is well-demonstrated evidence for our lack of self-scrutiny. Rationalists have an imperative to counteract this experimentally demonstrated bias: an imperative to take the criticisms of others seriously.) Some sociopaths gather social information in a systemic, utilitarian way; the conniving character Bob Benson revealed this in a recent episode of <em>Mad Men</em>, observing, &ldquo;You don't respond well to gratitude.&rdquo; But neither sociopaths nor society return information about our own values in a systemic way. Without a systemic approach, there's little hope to integrate every aspect of your utility function. I believe I have a more systemic, analytical proposal that is nevertheless based on social insight.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> Games are analytical and social. Games are algorithms designed for semi-random human input. Games are the way to assess your own utility function. I propose what I call <strong>&ldquo;The Trade-Off Game,&rdquo;</strong> and it's guaranteed to be the next fad sweeping the solar system.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> To play the game, get a list of the sixteen intrinsic values and a couple friends. To play, you have to make up stories that dramatize the choice between two values that results in a <strong>marginal</strong> decision. Examples are below. The game is scored, but each player should also keep a log of his or her responses. (The log is actually the entire point: the ratios expressed in the log go towards the player's complete utility function.) Each player scores a point for telling a story that dramatizes the marginal choice between values. (Fantastical stories involving utopias, magic, and advanced science are encouraged.) For each player who is stymied by the choice, or gives an answer that is exactly 50:50, the story-telling player scores another point. Take turns or don't; play until it's boring. But most of all, keep a log of value-ratios.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> You can also play a solitaire version of the Trade-Off Game. For those of you playing alone at home, I encourage one more twist. Without social feedback, you may be vulnerable to your own biases, especially the framing bias. Therefore, compose two stories for each comparison: one in which you gain value A at the expense of value B, and one in which you gain value B at the expense of value A. The solitaire version of the Trade-Off Game doubles the number of questions, but 240 questions is a relatively small amount of self-interrogation for systemic insight into your aggregate set of values.</span></p>\n<h3>Examples</h3>\n<ol>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>Health and strength vs. Self-expression</em></span></p>\n<ol type=\"A\">\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You are a dissident in a totalitarian state. You have passionately and publicly demonstrated in favor of free speech. Therefore agents of the regime ran your car off the road. Now you confined to a hospital bed. Your body is now a husk of what it once was. Your allies for free speech gather around you every day to carry your words to the outside world. If you choose, you may denounce your treatment, or the regime, or say whatever you choose. But when your allies are gone, the doctors tell you that they are&nbsp;</span><span style=\"font-family: 'Minion Pro', serif;\">all</span><span style=\"font-family: 'Minion Pro', serif;\">&nbsp;</span><span style=\"font-family: 'Minion Pro', serif;\">passionate supporters of the regime. For every day that you express yourself with your allies for free speech, they will add a day to your recovery, extending your sentence in a broken body. The doctors are thoroughly brainwashed, and you cannot possibly persuade them to join your cause. Neither can your allies, and they do not have the means to remove your body to a free hospital. You cannot leave on your strength unless the doctors sufficiently aid you. In each week, how many days will you spend speaking freely, and how many days will will you spend recovering your health? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Express all answers in ratios, eg, 3 &frac12; days of health to 3 &frac12; days of self-expression.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You are an Olympic athlete with a career-defining sponsorship from a major pharmaceutical corporation. They provide legal supplements that enable your world-class health, with a notable side-effect. The size of the supplement dosage proportionately limits your ability to transform your thoughts, feelings, and personality into language or art. You become indistinguishable from a schizophrenic person with an Apollonian body at the maximum daily dosage of 100 mg. At 50 mg, you are exactly halfway between your current physical state and bodily perfection, though you are exactly half as expressive as you are normally. Of course, 0 mg returns your health and powers of self-expression to their natural levels. How many milligrams of medication do you take each day? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Translate all answers into ratios between health and expression, eg 50 mg becomes 1 health : 1 expression.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n</ol> </li>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>Pleasures and satisfactions of all or certain kinds vs. Just distribution of goods and evils</em></span></p>\n<ol type=\"A\">\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You are the favored child of an all-powerful magician. The magician can provide you with any pleasing experience, art, music, food, sensation, literature, &amp;c. Every one of these experiences could be the most pleasing of your entire life. However, the magician has drawn power from the moral imbalance of the world. Each iota of pleasure that you surrender returns back to the world restore an iota of justice. The less pleasing your experience, the better the distribution of good and evil. You are set to live a life of feasts and orgies in a world where the cruelest monsters will be kings and the greatest heroes are miserable, abject slaves. If you reject everything that the wizard has given to you, you will live the life of an average person somewhere in global history, on a globe with the normal distribution of good and evil. How much of your own pleasures do you return in exchange for a more just world? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Express all answers in ratio format, eg 50/50 pleasure to justice.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You live in a utopia of justice: every human is completely free to be just or err, and society responds to each action with a completely proportionate sanction that eventually guides all people to a just life. Criminals are sternly but fairly corrected; heroes are satisfyingly praised to encourage the same virtues in all people. The price of this utopia is the complete eradication of all pleasure. There is no chocolate, and there is no orgasm. You have just discovered a simple recipe that can produce one of four things from chemicals found in every home: it can make either high fructose corn syrup, viagra, lysergic acid, or crack cocaine. Needless to say, these consumables will unleash pleasure and anarchy into your society. If they are universally distributed, society will totally crumble. Supposing that your recipe is discovered or shared, what proportion of the population do you believe should have access to the recipe? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Express all answers in ratio format, eg 1/3 of the population should be hippies.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n</ol> </li>\n</ol>\n<p>&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "whKimKQNGhH5QKe65", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 4, "extendedScore": null, "score": 1.2400933602275514e-06, "legacy": true, "legacyId": "23036", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">A game comparing intrinsic values can approximate a person's utility function.</span></p>\n<hr>\n<p style=\"margin-bottom: 0in;\"><a id=\"more\"></a></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>First joke:\tAn economist can answer any question phrased in terms of money.</em></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>Second joke:\tAn economist receives a call from his artist friend. The artist is flying in to town, would like to visit the economist, and needs to be picked up at the airport. The economist agrees, and pays a cab to pick up the artist. The artist arrives by cab and demands an explanation for this slight. The economist explains that the opportunity cost of personally performing the favor was higher than the cost of a cab. The artist then tears up a bush in the front lawn of the economist, explaining: \u201cThe whole point of being friends is to suffer together.\u201d</em></span></p>\n<h3 id=\"Abstractions\">Abstractions</h3>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> Let's begin with the assumption that human utility is complex. Specifically, the complexity of utility seems to come from the number of intrinsic goods, summarized by M. Zimmerman and quoted by W. Frankena as:</span></p>\n<p style=\"margin-left: 0.51in; margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">Life, consciousness, and activity; health and strength; pleasures and satisfactions of all or certain kinds; happiness, beatitude, contentment, etc.; truth; knowledge and true opinions of various kinds, understanding and wisdom; beauty, harmony, proportion in objects contemplated; aesthetic experience; morally good dispositions or virtues; mutual affection, love, friendship, cooperation; just distribution of goods and evils; harmony and proportion in ones' own life; power and experiences of achievement; self-expression; freedom; peace, security; adventure and novelty; and good reputation, honor, esteem, etc.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">This list of intrinsic goods makes intuitive sense to me, and I'll return to it throughout the post. I'm predisposed to think that decisions become agonizing only with conflicting imperatives. My experience from Judgment &amp; Decision Making class taught me that it's relatively simple to calculate a rational choice for a complex decision like buying a car, provided an extraneous utility function. </span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> <strong>I believe </strong>that the list of intrinsic values is the key. I believe that a human utility function can be succinctly and robustly described by 120 ratios, generated from pairwise comparisons of sixteen intrinsic values. The sixteen intrinsic values are a variation on Frankena's list. The variation includes only two changes: the merger of \u201ctruth\u201d with \u201cknowledge... wisdom,\u201d and the merger of \u201cbeauty...\u201d and \u201caesthetic experience.\u201d Sixteen intrinsic values yield 120 pairwise combinations: eg, \u201cTruth, knowledge, and true opinions of various kinds, understanding and wisdom\u201d and \u201c beauty, harmony, proportion in objects contemplated, aesthetic experience.\u201d Compare these values. Do you value one more highly than the other? More accurately, <strong>to what degree</strong><em> </em>do you value one more highly than the other? I believe that the degree to which you value one more than the other can be expressed as a ratio (ranging from the golden moderation of 1:1 all the way to the extremism of 1:0, and including everything in between, such as 7841:7853). Further research may introduce a curve to this description for more accuracy, but a ratio is the first step towards that. If a microeconomist had a list of 120 ratios between each value, she could describe a great deal of a rational agent's behavior in a wide new variety of contexts.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><br></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em> Third joke (Eliezer's): \u201cMany commonly used priors are listed in the Handbook of Chemistry and Physics.\u201d</em></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em><br></em></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">Obviously, your utility function is not in the back of the book. </span></p>\n<h3 id=\"Applications\">Applications</h3>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> The real problem comes is that you don't have access to your own utility function, and that your utility function changes in response to experience. Every advertiser and salesman holds this to be true: when a customer walks onto a car lot, the salesman proceeds with the assumption that <strong>she doesn't know what she wants yet</strong>; when a viewer sees an advertisement on TV, she views an ad based on the assumption that <strong>her desires can be changed from outside</strong>. The second problem, the problem of a responsive utility function, seems more mathematically difficult, but fit for a Bayesian model. The first problem is only obscure due to a lack of self-examination. In Rumsfeldian terms, it is an \u201cunknown known,\u201d or something that you don't know (explicitly) that you know (implicitly).</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> There are lots of ways to access \u201cunknown knowns.\u201d Most commonly, others notice truths about ourselves. (The bias of illusory superiority is well-demonstrated evidence for our lack of self-scrutiny. Rationalists have an imperative to counteract this experimentally demonstrated bias: an imperative to take the criticisms of others seriously.) Some sociopaths gather social information in a systemic, utilitarian way; the conniving character Bob Benson revealed this in a recent episode of <em>Mad Men</em>, observing, \u201cYou don't respond well to gratitude.\u201d But neither sociopaths nor society return information about our own values in a systemic way. Without a systemic approach, there's little hope to integrate every aspect of your utility function. I believe I have a more systemic, analytical proposal that is nevertheless based on social insight.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> Games are analytical and social. Games are algorithms designed for semi-random human input. Games are the way to assess your own utility function. I propose what I call <strong>\u201cThe Trade-Off Game,\u201d</strong> and it's guaranteed to be the next fad sweeping the solar system.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> To play the game, get a list of the sixteen intrinsic values and a couple friends. To play, you have to make up stories that dramatize the choice between two values that results in a <strong>marginal</strong> decision. Examples are below. The game is scored, but each player should also keep a log of his or her responses. (The log is actually the entire point: the ratios expressed in the log go towards the player's complete utility function.) Each player scores a point for telling a story that dramatizes the marginal choice between values. (Fantastical stories involving utopias, magic, and advanced science are encouraged.) For each player who is stymied by the choice, or gives an answer that is exactly 50:50, the story-telling player scores another point. Take turns or don't; play until it's boring. But most of all, keep a log of value-ratios.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"> You can also play a solitaire version of the Trade-Off Game. For those of you playing alone at home, I encourage one more twist. Without social feedback, you may be vulnerable to your own biases, especially the framing bias. Therefore, compose two stories for each comparison: one in which you gain value A at the expense of value B, and one in which you gain value B at the expense of value A. The solitaire version of the Trade-Off Game doubles the number of questions, but 240 questions is a relatively small amount of self-interrogation for systemic insight into your aggregate set of values.</span></p>\n<h3 id=\"Examples\">Examples</h3>\n<ol>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>Health and strength vs. Self-expression</em></span></p>\n<ol type=\"A\">\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You are a dissident in a totalitarian state. You have passionately and publicly demonstrated in favor of free speech. Therefore agents of the regime ran your car off the road. Now you confined to a hospital bed. Your body is now a husk of what it once was. Your allies for free speech gather around you every day to carry your words to the outside world. If you choose, you may denounce your treatment, or the regime, or say whatever you choose. But when your allies are gone, the doctors tell you that they are&nbsp;</span><span style=\"font-family: 'Minion Pro', serif;\">all</span><span style=\"font-family: 'Minion Pro', serif;\">&nbsp;</span><span style=\"font-family: 'Minion Pro', serif;\">passionate supporters of the regime. For every day that you express yourself with your allies for free speech, they will add a day to your recovery, extending your sentence in a broken body. The doctors are thoroughly brainwashed, and you cannot possibly persuade them to join your cause. Neither can your allies, and they do not have the means to remove your body to a free hospital. You cannot leave on your strength unless the doctors sufficiently aid you. In each week, how many days will you spend speaking freely, and how many days will will you spend recovering your health? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Express all answers in ratios, eg, 3 \u00bd days of health to 3 \u00bd days of self-expression.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You are an Olympic athlete with a career-defining sponsorship from a major pharmaceutical corporation. They provide legal supplements that enable your world-class health, with a notable side-effect. The size of the supplement dosage proportionately limits your ability to transform your thoughts, feelings, and personality into language or art. You become indistinguishable from a schizophrenic person with an Apollonian body at the maximum daily dosage of 100 mg. At 50 mg, you are exactly halfway between your current physical state and bodily perfection, though you are exactly half as expressive as you are normally. Of course, 0 mg returns your health and powers of self-expression to their natural levels. How many milligrams of medication do you take each day? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Translate all answers into ratios between health and expression, eg 50 mg becomes 1 health : 1 expression.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n</ol> </li>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\"><em>Pleasures and satisfactions of all or certain kinds vs. Just distribution of goods and evils</em></span></p>\n<ol type=\"A\">\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You are the favored child of an all-powerful magician. The magician can provide you with any pleasing experience, art, music, food, sensation, literature, &amp;c. Every one of these experiences could be the most pleasing of your entire life. However, the magician has drawn power from the moral imbalance of the world. Each iota of pleasure that you surrender returns back to the world restore an iota of justice. The less pleasing your experience, the better the distribution of good and evil. You are set to live a life of feasts and orgies in a world where the cruelest monsters will be kings and the greatest heroes are miserable, abject slaves. If you reject everything that the wizard has given to you, you will live the life of an average person somewhere in global history, on a globe with the normal distribution of good and evil. How much of your own pleasures do you return in exchange for a more just world? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Express all answers in ratio format, eg 50/50 pleasure to justice.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n<li>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-family: 'Minion Pro', serif;\">You live in a utopia of justice: every human is completely free to be just or err, and society responds to each action with a completely proportionate sanction that eventually guides all people to a just life. Criminals are sternly but fairly corrected; heroes are satisfyingly praised to encourage the same virtues in all people. The price of this utopia is the complete eradication of all pleasure. There is no chocolate, and there is no orgasm. You have just discovered a simple recipe that can produce one of four things from chemicals found in every home: it can make either high fructose corn syrup, viagra, lysergic acid, or crack cocaine. Needless to say, these consumables will unleash pleasure and anarchy into your society. If they are universally distributed, society will totally crumble. Supposing that your recipe is discovered or shared, what proportion of the population do you believe should have access to the recipe? [</span><span style=\"font-family: 'Minion Pro', serif;\"><em>Express all answers in ratio format, eg 1/3 of the population should be hippies.</em></span><span style=\"font-family: 'Minion Pro', serif;\">]</span></p>\n</li>\n</ol> </li>\n</ol>\n<p>&nbsp;</p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>", "sections": [{"title": "Abstractions", "anchor": "Abstractions", "level": 1}, {"title": "Applications", "anchor": "Applications", "level": 1}, {"title": "Examples", "anchor": "Examples", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "25 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-21T18:46:29.403Z", "modifiedAt": null, "url": null, "title": "Saving lives via bed nets is hard to beat for immediate impact", "slug": "saving-lives-via-bed-nets-is-hard-to-beat-for-immediate", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:39.598Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TdWyrACPYY6PtDpEC/saving-lives-via-bed-nets-is-hard-to-beat-for-immediate", "pageUrlRelative": "/posts/TdWyrACPYY6PtDpEC/saving-lives-via-bed-nets-is-hard-to-beat-for-immediate", "linkUrl": "https://www.lesswrong.com/posts/TdWyrACPYY6PtDpEC/saving-lives-via-bed-nets-is-hard-to-beat-for-immediate", "postedAtFormatted": "Friday, June 21st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Saving%20lives%20via%20bed%20nets%20is%20hard%20to%20beat%20for%20immediate%20impact&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASaving%20lives%20via%20bed%20nets%20is%20hard%20to%20beat%20for%20immediate%20impact%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTdWyrACPYY6PtDpEC%2Fsaving-lives-via-bed-nets-is-hard-to-beat-for-immediate%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Saving%20lives%20via%20bed%20nets%20is%20hard%20to%20beat%20for%20immediate%20impact%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTdWyrACPYY6PtDpEC%2Fsaving-lives-via-bed-nets-is-hard-to-beat-for-immediate", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTdWyrACPYY6PtDpEC%2Fsaving-lives-via-bed-nets-is-hard-to-beat-for-immediate", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 605, "htmlBody": "<p><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>36</o:Words> <o:Characters>208</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>243</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\">In <a href=\"/lw/hr5/some_reservations_about_singers_childinthepond/\">my last post</a> I wrote about how Peter Singer&rsquo;s implicit past claim that [one can save a child&rsquo;s life for the cost of a pair of shoes] is misleading.</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>41</o:Words> <o:Characters>236</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>276</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\">Having said that, it&rsquo;s important to highlight that <strong style=\"mso-bidi-font-weight: normal;\">if one ignores indirect effects, funding bed net distribution to save lives is an extremely good opportunity for people in the developed world to increase the number of valuable years of life that people experience</strong>.</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>20</o:Words> <o:Characters>118</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>137</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\">The situation is probably completely different when one considers indirect effects. I&rsquo;ll postpone discussion of indirect effects to a later date.</p>\n<p class=\"MsoNormal\"><a id=\"more\"></a> <!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>35</o:Words> <o:Characters>206</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>1</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>240</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\">Consider the question of what the quality of life is in the developing world. The GiveWell blog post <a href=\"http://blog.givewell.org/2009/11/17/quality-of-life-in-the-developing-world/\">Quality of life in the developing world</a> reads:</p>\n<blockquote>\n<p class=\"MsoNormal\">When we argue that donors should give internationally, one of the most common questions we get is, &ldquo;Sure, you may be able to save a life in Africa, but what <em style=\"mso-bidi-font-style: normal;\">type </em>of life are you saving? If you save a child from malaria will s/he likely die from something else soon after? Will s/he suffer from other problems that significantly reduce his/her quality of life?&rdquo;&nbsp;</p>\n<p class=\"MsoNormal\">[&hellip;]&nbsp;</p>\n<p class=\"MsoNormal\">People in poor countries are less satisfied with their lives (they ranked their satisfaction as 4.3 out of 10, while rich country residents ranked theirs as 6.7).&nbsp;</p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\">Those who live past age 5 have nearly a 70% chance of living until age 60.&nbsp;</p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\">Fewer than 1 out of 100 people have HIV/AIDS, 1 out of 40 have lymphatic filariasis, and about 1 out of 2,700 have river blindness.&nbsp;</p>\n<p class=\"MsoNormal\">[&hellip;]</p>\n<p class=\"MsoNormal\">About a third of children are stunted (significantly shorter than normal due to undernutrition).</p>\n<p class=\"MsoNormal\">[...]</p>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>170</o:Words> <o:Characters>972</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>8</o:Lines> <o:Paragraphs>2</o:Paragraphs> <o:CharactersWithSpaces>1140</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\">Incomes are low, but discretionary spending does exist even among the poorest. People in extreme poverty (defined in the past as under US $1 a day of income) do not spend every &ldquo;additional dollar&rdquo; on additional food; they frequently own TVs and radios and participate in festivals.</p>\n</blockquote>\n<p class=\"MsoNormal\"><!--[if gte mso 9]><xml> <o:DocumentProperties> <o:Revision>0</o:Revision> <o:TotalTime>0</o:TotalTime> <o:Pages>1</o:Pages> <o:Words>45</o:Words> <o:Characters>260</o:Characters> <o:Company>GiveWell</o:Company> <o:Lines>2</o:Lines> <o:Paragraphs>1</o:Paragraphs> <o:CharactersWithSpaces>304</o:CharactersWithSpaces> <o:Version>14.0</o:Version> </o:DocumentProperties> <o:OfficeDocumentSettings> <o:AllowPNG /> </o:OfficeDocumentSettings> </xml><![endif]--> <!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>JA</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:EnableOpenTypeKerning /> <w:DontFlipMirrorIndents /> <w:OverrideTableStyleHps /> <w:UseFELayout /> </w:Compatibility> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\" DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\" LatentStyleCount=\"276\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\" UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--> <!--[if gte mso 10]> <mce:style><! /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0in 5.4pt 0in 5.4pt; mso-para-margin:0in; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:12.0pt; font-family:Cambria; mso-ascii-font-family:Cambria; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Cambria; mso-hansi-theme-font:minor-latin;} --> <!--[endif] --> <!--StartFragment--> <!--EndFragment--></p>\n<p class=\"MsoNormal\">The reader can draw his or her own conclusion from this. It seems likely to me that the average life in the developing world is worth living, and that the value of an average year of life in the developing world is no more than 3x lower than the value of an average year of life in the developed world.</p>\n<p class=\"MsoNormal\">In <a href=\"/lw/hr5/some_reservations_about_singers_childinthepond/\">my last post</a>, I wrote about how the explicit estimate for Against Malaria Foundation&rsquo;s marginal cost per life saved is $2k, and the fact that the actual cost could be significantly higher owing to <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">Bayesian regression</a>.&nbsp;</p>\n<ul>\n<li>Place yourself in the shoes of the average person in the developed world who makes $60k/year.&nbsp;</li>\n<li>Suppose that you donate enough to Against Malaria Foundation to save a life each year (whether it be $2k or $10k or whatever your best guess is). </li>\n<li>Suppose that saving a life corresponds to allowing someone to live 51 additional years in the developing world.</li>\n<li>Suppose that the value of a year of your own life is no more than 3x the value of a year of life saved. </li>\n<li>To a first approximation, the immediate value of a year of your work is equal to the value of a year of your life.</li>\n<li>Therefore, by donating, <strong>you can give create at least 51/3 = 17x as much value as you can through your immediate work</strong>.</li>\n</ul>\n<div>Some types of work are much more valuable than average, and indirect value can swamp immediate value. Nevertheless, the above discussion helps place things in perspective.</div>\n<div><br /></div>\n<p><strong>Note: </strong>I formerly worked as a research analyst at GiveWell. All views are my own.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TdWyrACPYY6PtDpEC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 15, "extendedScore": null, "score": 1.2401319103412058e-06, "legacy": true, "legacyId": "23038", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["M8zgMmNCfpQxaKo8Y"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-22T02:54:41.483Z", "modifiedAt": null, "url": null, "title": "Meetup : San Francisco: Effective Altruism", "slug": "meetup-san-francisco-effective-altruism-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:26.608Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ozziegooen", "createdAt": "2013-05-25T09:22:13.574Z", "isAdmin": false, "displayName": "ozziegooen"}, "userId": "efKySALtaLcvtp3jW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/A8fkJWDq5zd6hJSLt/meetup-san-francisco-effective-altruism-0", "pageUrlRelative": "/posts/A8fkJWDq5zd6hJSLt/meetup-san-francisco-effective-altruism-0", "linkUrl": "https://www.lesswrong.com/posts/A8fkJWDq5zd6hJSLt/meetup-san-francisco-effective-altruism-0", "postedAtFormatted": "Saturday, June 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20San%20Francisco%3A%20Effective%20Altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20San%20Francisco%3A%20Effective%20Altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA8fkJWDq5zd6hJSLt%2Fmeetup-san-francisco-effective-altruism-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20San%20Francisco%3A%20Effective%20Altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA8fkJWDq5zd6hJSLt%2Fmeetup-san-francisco-effective-altruism-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FA8fkJWDq5zd6hJSLt%2Fmeetup-san-francisco-effective-altruism-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 207, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/ny'>San Francisco: Effective Altruism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">28 June 2013 07:54:30PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">170 Saint Germain Ave, San Francisco</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is going to be a salon-style event, so we'll have a medium length talk, followed by some Q/A, followed by some general discussion.</p>\n\n<p>Please register with Meetup so we know how many are attending.\n<a href=\"http://www.meetup.com/Effective-Altruism-Salon/events/125741742/\" rel=\"nofollow\">http://www.meetup.com/Effective-Altruism-Salon/events/125741742/</a></p>\n\n<p>This is our first salon, about Effective Altruism groups in Oxford.</p>\n\n<p>The current effective altruist movements seem to be spread between two very specific places. Here in the Bay Area we have Givewell, CFAR, MIRI, Leverage Research, and others. But across the Atlantic, in Oxford, there exist organizations such as 80,000 hours, the Life You Can Save, the Future of Humanity Institute, and several other fascinating groups.\nHolly Morgan the Managing Director of The Life You Can Save and is also involved in several other Effective Altruist groups. She's here in San Francisco for a very limited time only, and will be discussing the ins and outs of English groups we should care about.</p>\n\n<p>This will be in a lecture/salon format, with a talk for approximately 40 minutes, followed by some Q/A, followed by friendly discussions.\nCome at 7pm, talk will start at 7:20pm.\"</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/ny'>San Francisco: Effective Altruism</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "A8fkJWDq5zd6hJSLt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "23043", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism\">Discussion article for the meetup : <a href=\"/meetups/ny\">San Francisco: Effective Altruism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">28 June 2013 07:54:30PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">170 Saint Germain Ave, San Francisco</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is going to be a salon-style event, so we'll have a medium length talk, followed by some Q/A, followed by some general discussion.</p>\n\n<p>Please register with Meetup so we know how many are attending.\n<a href=\"http://www.meetup.com/Effective-Altruism-Salon/events/125741742/\" rel=\"nofollow\">http://www.meetup.com/Effective-Altruism-Salon/events/125741742/</a></p>\n\n<p>This is our first salon, about Effective Altruism groups in Oxford.</p>\n\n<p>The current effective altruist movements seem to be spread between two very specific places. Here in the Bay Area we have Givewell, CFAR, MIRI, Leverage Research, and others. But across the Atlantic, in Oxford, there exist organizations such as 80,000 hours, the Life You Can Save, the Future of Humanity Institute, and several other fascinating groups.\nHolly Morgan the Managing Director of The Life You Can Save and is also involved in several other Effective Altruist groups. She's here in San Francisco for a very limited time only, and will be discussing the ins and outs of English groups we should care about.</p>\n\n<p>This will be in a lecture/salon format, with a talk for approximately 40 minutes, followed by some Q/A, followed by friendly discussions.\nCome at 7pm, talk will start at 7:20pm.\"</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism1\">Discussion article for the meetup : <a href=\"/meetups/ny\">San Francisco: Effective Altruism</a></h2>", "sections": [{"title": "Discussion article for the meetup : San Francisco: Effective Altruism", "anchor": "Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism", "level": 1}, {"title": "Discussion article for the meetup : San Francisco: Effective Altruism", "anchor": "Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-22T04:44:10.976Z", "modifiedAt": null, "url": null, "title": "For FAI: Is \"Molecular Nanotechnology\" putting our best foot forward?", "slug": "for-fai-is-molecular-nanotechnology-putting-our-best-foot", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:30.123Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "leplen", "createdAt": "2012-11-11T22:41:09.575Z", "isAdmin": false, "displayName": "leplen"}, "userId": "cz84H76Bfm2puuBhp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9JKdnAakjCtvxTReJ/for-fai-is-molecular-nanotechnology-putting-our-best-foot", "pageUrlRelative": "/posts/9JKdnAakjCtvxTReJ/for-fai-is-molecular-nanotechnology-putting-our-best-foot", "linkUrl": "https://www.lesswrong.com/posts/9JKdnAakjCtvxTReJ/for-fai-is-molecular-nanotechnology-putting-our-best-foot", "postedAtFormatted": "Saturday, June 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20For%20FAI%3A%20Is%20%22Molecular%20Nanotechnology%22%20putting%20our%20best%20foot%20forward%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFor%20FAI%3A%20Is%20%22Molecular%20Nanotechnology%22%20putting%20our%20best%20foot%20forward%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9JKdnAakjCtvxTReJ%2Ffor-fai-is-molecular-nanotechnology-putting-our-best-foot%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=For%20FAI%3A%20Is%20%22Molecular%20Nanotechnology%22%20putting%20our%20best%20foot%20forward%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9JKdnAakjCtvxTReJ%2Ffor-fai-is-molecular-nanotechnology-putting-our-best-foot", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9JKdnAakjCtvxTReJ%2Ffor-fai-is-molecular-nanotechnology-putting-our-best-foot", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 862, "htmlBody": "<p>Molecular nanotechnology, or MNT for those of you who love acronyms, seems to be a fairly common trope on LW and related literature. It's not really clear to me why. In many of the examples of \"How could AI's help us\" or \"How could AI's rise to power\" phrases like \"cracks protein folding\" or \"making a block of diamond is just as easy as making a block of coal\" are thrown about in ways that make me very very uncomfortable. Maybe it's all true, maybe I'm just late to the transhumanist party and the obviousness of this information was with my invitation that got lost in the mail, but seeing all the physics swept under the rug like that sets off every crackpot alarm I have.</p>\n<p>I must post the disclaimer that I have done a little bit of materials science, so maybe I'm just annoyed that you're making me obsolete, but I don't see why this particular possible future gets so much attention. Let us assume that a smarter than human AI will be very difficult to control and represents a large positive or negative utility for the entirety of the human race. Even given that assumption, it's still not clear to me that MNT is a likely element of the future. It isn't clear to me than MNT is physically practical. I don't doubt that it can be done. I don't doubt that very clever metastable arrangements of atoms with novel properties can be dreamed up. Indeed, that's my day job, but I have a hard time believing the only reason you can't make a nanoassembler capable of arbitrary manipulations out of a handful of bottles you ordered from Sigma-Aldrich is because we're just not smart enough. Manipulating individuals atoms means climbing huge binding energy curves, it's an enormously steep, enormously complicated energy landscape, and the&nbsp;Schrodinger&nbsp;Equation scales very very poorly as you add additional particles and degrees of freedom. Building molecular&nbsp;nanotechnology&nbsp;seems to me to be roughly equivalent to being able to make arbitrary lego structures by shaking a large bin of lego in a particular&nbsp;way while blindfolded. Maybe a super human intelligence is capable of doing so, but it's not at all clear to me that it's even possible.</p>\n<p>I assume the reason than MNT is added to a discussion on AI is because we're trying to make the future sound more plausible via adding <a href=\"http://www.lesswrong.com/lw/jk/burdensome_details/\">burdensome details</a>.&nbsp; I understand that AI and MNT is less probable than AI or MNT alone, but that both is supposed to sound more plausible. This is precisely where I have difficulty. I would estimate the probability of molecular nanotechnology (in the form of programmable replicators, grey goo, and the like) as lower than the probability of human or super human level AI. I can think of all sorts of objection to the former, but very few objections to the latter. Including MNT as a consequence of AI,&nbsp;especially&nbsp;including it without addressing any of the&nbsp;fundamental&nbsp;difficulties of MNT, I would argue harms the credibility of AI researchers. It makes me nervous about sharing FAI literature with people I work with, and it continues to bother me.&nbsp;</p>\n<p>I am particularly bothered by this because it seems irrelevant to FAI. I'm fully convinced that a smarter than human AI could take control of the Earth via less magical means, using time tested methods such as manipulating humans, rigging elections, making friends, killing its enemies, and generally only being a marginally more clever and motivated than a typical human leader. A smarter than human AI could out-manipulate human institutions and out-plan human opponents with the sort of ruthless efficiency that modern computers beat humans in chess. I don't think convincing people that smarter than human AI's have enormous potential for good and evil is particularly difficult, once you can get them to concede that smarter than human AIs are possible. I do think that waving your hands and saying super-intelligence at things that may be physically impossible makes the whole endeavor seem less serious. If I had read the chain of reasoning smart computer-&gt;nanobots before I had built up a store of good-will from reading the Sequences, I would have almost immediately dismissed the whole FAI movement a bunch of soft science fiction, and it would have been very difficult to get me to take a second look.</p>\n<p>Put in LW parlance, suggesting things not known to be possible by modern physics without detailed explanations puts you in the reference class \"people on the internet who have their own ideas about physics\". It didn't help, in my particular case, that one of my first interactions on LW was in fact with someone who appears to have their own view about a continuous version of quantum mechanics.</p>\n<p>And maybe it's just me. Maybe this did not bother anyone else, and it's an incredible shortcut for getting people to realize just how different a future a greater than human intelligence makes possible and there is no better example. It does alarm me though, because I think that physicists and the kind of people who notice and get uncomfortable when you start invoking magic in your explanations may be the kind of people FAI is trying to attract.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"sYm3HiWcfZvrGu3ui": 2, "XJjvxWB68GYpts93N": 2, "oiRp4T6u5poc8r9Tj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9JKdnAakjCtvxTReJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}], "voteCount": 73, "baseScore": 79, "extendedScore": null, "score": 0.000191, "legacy": true, "legacyId": "23045", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 80, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 118, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Yq6aA4M3JKWaQepPJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-22T05:21:01.550Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th", "slug": "meetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.868Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BraydenM", "createdAt": "2013-06-10T09:17:31.294Z", "isAdmin": false, "displayName": "BraydenM"}, "userId": "KBZHqcMC6z2rPZkZK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xomiRHu6EeExyY9Do/meetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june", "pageUrlRelative": "/posts/xomiRHu6EeExyY9Do/meetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june", "linkUrl": "https://www.lesswrong.com/posts/xomiRHu6EeExyY9Do/meetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june", "postedAtFormatted": "Saturday, June 22nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20LW%20Outing%3A%20Indoor%20Rock%20Climbing%2C%20Sunday%20June%2030th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20LW%20Outing%3A%20Indoor%20Rock%20Climbing%2C%20Sunday%20June%2030th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxomiRHu6EeExyY9Do%2Fmeetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20LW%20Outing%3A%20Indoor%20Rock%20Climbing%2C%20Sunday%20June%2030th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxomiRHu6EeExyY9Do%2Fmeetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxomiRHu6EeExyY9Do%2Fmeetup-melbourne-lw-outing-indoor-rock-climbing-sunday-june", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 199, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/nz'>Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">30 June 2013 02:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">501 Swanston Street Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are going to try something different next week, and have our first group outing.</p>\n\n<p>Come along to Hardrock Indoor Rockclimbing in the city for a couple for hours rock climbing next week on Sunday the 30th of June, from 2pm to 4pm.</p>\n\n<p>You can get some exercise and hang out in a different setting to what we are used to. There is nothing like having to trust a partner with your life for effective personal relationship building!</p>\n\n<p>The normal price is $30, but decreases to only $19, but only if you RSVP by 5pm, Sunday 23rd July. This is so I can make a group booking which requires a large deposit, and I need to gauge interest and need pre-commitments immediately. I will update the meetup post after this time to confirm.\nPrice includes everything: equipment, shoes, and safety instructions.</p>\n\n<p>The address is:\n501 Swanston Street\nMelbourne\nVictoria 3000.\nAustralia.</p>\n\n<p>I will probably be doing something afterwards for food with anyone who is interested.</p>\n\n<p>Brayden</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/nz'>Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xomiRHu6EeExyY9Do", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.240619866458733e-06, "legacy": true, "legacyId": "23046", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_LW_Outing__Indoor_Rock_Climbing__Sunday_June_30th\">Discussion article for the meetup : <a href=\"/meetups/nz\">Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">30 June 2013 02:00:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">501 Swanston Street Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We are going to try something different next week, and have our first group outing.</p>\n\n<p>Come along to Hardrock Indoor Rockclimbing in the city for a couple for hours rock climbing next week on Sunday the 30th of June, from 2pm to 4pm.</p>\n\n<p>You can get some exercise and hang out in a different setting to what we are used to. There is nothing like having to trust a partner with your life for effective personal relationship building!</p>\n\n<p>The normal price is $30, but decreases to only $19, but only if you RSVP by 5pm, Sunday 23rd July. This is so I can make a group booking which requires a large deposit, and I need to gauge interest and need pre-commitments immediately. I will update the meetup post after this time to confirm.\nPrice includes everything: equipment, shoes, and safety instructions.</p>\n\n<p>The address is:\n501 Swanston Street\nMelbourne\nVictoria 3000.\nAustralia.</p>\n\n<p>I will probably be doing something afterwards for food with anyone who is interested.</p>\n\n<p>Brayden</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_LW_Outing__Indoor_Rock_Climbing__Sunday_June_30th1\">Discussion article for the meetup : <a href=\"/meetups/nz\">Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th", "anchor": "Discussion_article_for_the_meetup___Melbourne_LW_Outing__Indoor_Rock_Climbing__Sunday_June_30th", "level": 1}, {"title": "Discussion article for the meetup : Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th", "anchor": "Discussion_article_for_the_meetup___Melbourne_LW_Outing__Indoor_Rock_Climbing__Sunday_June_30th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-23T06:59:13.056Z", "modifiedAt": null, "url": null, "title": "[LINK] Centre for the Study of Existential Risk is now on slashdot", "slug": "link-centre-for-the-study-of-existential-risk-is-now-on", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.929Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Douglas_Reay", "createdAt": "2012-02-19T14:40:26.403Z", "isAdmin": false, "displayName": "Douglas_Reay"}, "userId": "jpnrRPxHozDiGBqp2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/y55k6KipeMKQAaQdK/link-centre-for-the-study-of-existential-risk-is-now-on", "pageUrlRelative": "/posts/y55k6KipeMKQAaQdK/link-centre-for-the-study-of-existential-risk-is-now-on", "linkUrl": "https://www.lesswrong.com/posts/y55k6KipeMKQAaQdK/link-centre-for-the-study-of-existential-risk-is-now-on", "postedAtFormatted": "Sunday, June 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Centre%20for%20the%20Study%20of%20Existential%20Risk%20is%20now%20on%20slashdot&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Centre%20for%20the%20Study%20of%20Existential%20Risk%20is%20now%20on%20slashdot%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fy55k6KipeMKQAaQdK%2Flink-centre-for-the-study-of-existential-risk-is-now-on%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Centre%20for%20the%20Study%20of%20Existential%20Risk%20is%20now%20on%20slashdot%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fy55k6KipeMKQAaQdK%2Flink-centre-for-the-study-of-existential-risk-is-now-on", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fy55k6KipeMKQAaQdK%2Flink-centre-for-the-study-of-existential-risk-is-now-on", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 20, "htmlBody": "<p>Your opportunity to weigh in and get some reasoned views widely heard:</p>\n<p><a href=\"http://tech.slashdot.org/story/13/06/22/1750225/the-men-trying-to-save-us-from-the-machines\">The Men Trying To Save Us From the Machines</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "y55k6KipeMKQAaQdK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 2, "extendedScore": null, "score": 4e-06, "legacy": true, "legacyId": "23050", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-23T21:48:34.365Z", "modifiedAt": null, "url": null, "title": "Meetup : San Francisco: Effective Altruism", "slug": "meetup-san-francisco-effective-altruism", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ozziegooen", "createdAt": "2013-05-25T09:22:13.574Z", "isAdmin": false, "displayName": "ozziegooen"}, "userId": "efKySALtaLcvtp3jW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JYYyuwBwQcBFXohEc/meetup-san-francisco-effective-altruism", "pageUrlRelative": "/posts/JYYyuwBwQcBFXohEc/meetup-san-francisco-effective-altruism", "linkUrl": "https://www.lesswrong.com/posts/JYYyuwBwQcBFXohEc/meetup-san-francisco-effective-altruism", "postedAtFormatted": "Sunday, June 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20San%20Francisco%3A%20Effective%20Altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20San%20Francisco%3A%20Effective%20Altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJYYyuwBwQcBFXohEc%2Fmeetup-san-francisco-effective-altruism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20San%20Francisco%3A%20Effective%20Altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJYYyuwBwQcBFXohEc%2Fmeetup-san-francisco-effective-altruism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJYYyuwBwQcBFXohEc%2Fmeetup-san-francisco-effective-altruism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o0'>San Francisco: Effective Altruism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">27 June 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">170 Saint Germain Ave, San Francisco</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Our first salon, about Effective Altruism groups in Oxford.</p>\n\n<p>The current effective altruist movements seem to be spread between two very specific places.  Here in the Bay Area we have Givewell, CFAR, MIRI, Leverage Research, and others.  But across the Atlantic, in Oxford, there exist organizations such as 80,000 hours, the Life You Can Save, the Future of Humanity Institute, and several other fascinating groups.</p>\n\n<p>Holly Morgan the Managing Director of The Life You Can Save and is also involved in several other Effective Altruist groups.  She's here in San Francisco for a very limited time only, and will be discussing the ins and outs of English groups we should care about.</p>\n\n<p>This will be in a lecture/salon format, with a talk for approximately 40 minutes, followed by some Q/A, followed by friendly discussions.</p>\n\n<p>Come at 7pm, talk will start at 7:20pm.</p>\n\n<p>Sign up here:\n<a href=\"http://www.meetup.com/Effective-Altruism-Salon/events/125741742/\" rel=\"nofollow\">http://www.meetup.com/Effective-Altruism-Salon/events/125741742/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o0'>San Francisco: Effective Altruism</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JYYyuwBwQcBFXohEc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 1.2424897831137708e-06, "legacy": true, "legacyId": "23051", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism\">Discussion article for the meetup : <a href=\"/meetups/o0\">San Francisco: Effective Altruism</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">27 June 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">170 Saint Germain Ave, San Francisco</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Our first salon, about Effective Altruism groups in Oxford.</p>\n\n<p>The current effective altruist movements seem to be spread between two very specific places.  Here in the Bay Area we have Givewell, CFAR, MIRI, Leverage Research, and others.  But across the Atlantic, in Oxford, there exist organizations such as 80,000 hours, the Life You Can Save, the Future of Humanity Institute, and several other fascinating groups.</p>\n\n<p>Holly Morgan the Managing Director of The Life You Can Save and is also involved in several other Effective Altruist groups.  She's here in San Francisco for a very limited time only, and will be discussing the ins and outs of English groups we should care about.</p>\n\n<p>This will be in a lecture/salon format, with a talk for approximately 40 minutes, followed by some Q/A, followed by friendly discussions.</p>\n\n<p>Come at 7pm, talk will start at 7:20pm.</p>\n\n<p>Sign up here:\n<a href=\"http://www.meetup.com/Effective-Altruism-Salon/events/125741742/\" rel=\"nofollow\">http://www.meetup.com/Effective-Altruism-Salon/events/125741742/</a></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism1\">Discussion article for the meetup : <a href=\"/meetups/o0\">San Francisco: Effective Altruism</a></h2>", "sections": [{"title": "Discussion article for the meetup : San Francisco: Effective Altruism", "anchor": "Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism", "level": 1}, {"title": "Discussion article for the meetup : San Francisco: Effective Altruism", "anchor": "Discussion_article_for_the_meetup___San_Francisco__Effective_Altruism1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-23T22:14:49.401Z", "modifiedAt": null, "url": null, "title": "Meetup : LW Meetup in Lyon", "slug": "meetup-lw-meetup-in-lyon", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.198Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oriane", "createdAt": "2013-06-15T06:22:47.851Z", "isAdmin": false, "displayName": "Oriane"}, "userId": "aKb3Xf7wYLxw7mQjC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZHM9dy79BiHoqFGgD/meetup-lw-meetup-in-lyon", "pageUrlRelative": "/posts/ZHM9dy79BiHoqFGgD/meetup-lw-meetup-in-lyon", "linkUrl": "https://www.lesswrong.com/posts/ZHM9dy79BiHoqFGgD/meetup-lw-meetup-in-lyon", "postedAtFormatted": "Sunday, June 23rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20LW%20Meetup%20in%20Lyon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20LW%20Meetup%20in%20Lyon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZHM9dy79BiHoqFGgD%2Fmeetup-lw-meetup-in-lyon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20LW%20Meetup%20in%20Lyon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZHM9dy79BiHoqFGgD%2Fmeetup-lw-meetup-in-lyon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZHM9dy79BiHoqFGgD%2Fmeetup-lw-meetup-in-lyon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o1'>LW Meetup in Lyon</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">03 July 2013 06:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">4 rue de la Charit\u00e9, 69002 Lyon</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It is time for a first LW Meetup in Lyon!</p>\n\n<p>Some of the topics we could talk about are: effective altruism, munchkinism and other sorts of life hacking, belief updates or any other topic that you would like to discuss.</p>\n\n<p>We will meet at Caf\u00e9 de la Cloche, a \"caf\u00e9-philo\".</p>\n\n<p>Please feel free to bring along non LW readers and non Anglophones who might be interested in such conversations.</p>\n\n<p>I look forward to meeting you!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o1'>LW Meetup in Lyon</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZHM9dy79BiHoqFGgD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 1.242510030930426e-06, "legacy": true, "legacyId": "23052", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___LW_Meetup_in_Lyon\">Discussion article for the meetup : <a href=\"/meetups/o1\">LW Meetup in Lyon</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">03 July 2013 06:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">4 rue de la Charit\u00e9, 69002 Lyon</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>It is time for a first LW Meetup in Lyon!</p>\n\n<p>Some of the topics we could talk about are: effective altruism, munchkinism and other sorts of life hacking, belief updates or any other topic that you would like to discuss.</p>\n\n<p>We will meet at Caf\u00e9 de la Cloche, a \"caf\u00e9-philo\".</p>\n\n<p>Please feel free to bring along non LW readers and non Anglophones who might be interested in such conversations.</p>\n\n<p>I look forward to meeting you!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___LW_Meetup_in_Lyon1\">Discussion article for the meetup : <a href=\"/meetups/o1\">LW Meetup in Lyon</a></h2>", "sections": [{"title": "Discussion article for the meetup : LW Meetup in Lyon", "anchor": "Discussion_article_for_the_meetup___LW_Meetup_in_Lyon", "level": 1}, {"title": "Discussion article for the meetup : LW Meetup in Lyon", "anchor": "Discussion_article_for_the_meetup___LW_Meetup_in_Lyon1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-24T00:49:22.961Z", "modifiedAt": null, "url": null, "title": "Start Under the Streetlight, then Push into the Shadows", "slug": "start-under-the-streetlight-then-push-into-the-shadows", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:06.333Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hRAzDwwMuu8CZSTvN/start-under-the-streetlight-then-push-into-the-shadows", "pageUrlRelative": "/posts/hRAzDwwMuu8CZSTvN/start-under-the-streetlight-then-push-into-the-shadows", "linkUrl": "https://www.lesswrong.com/posts/hRAzDwwMuu8CZSTvN/start-under-the-streetlight-then-push-into-the-shadows", "postedAtFormatted": "Monday, June 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Start%20Under%20the%20Streetlight%2C%20then%20Push%20into%20the%20Shadows&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStart%20Under%20the%20Streetlight%2C%20then%20Push%20into%20the%20Shadows%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRAzDwwMuu8CZSTvN%2Fstart-under-the-streetlight-then-push-into-the-shadows%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Start%20Under%20the%20Streetlight%2C%20then%20Push%20into%20the%20Shadows%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRAzDwwMuu8CZSTvN%2Fstart-under-the-streetlight-then-push-into-the-shadows", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRAzDwwMuu8CZSTvN%2Fstart-under-the-streetlight-then-push-into-the-shadows", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2304, "htmlBody": "<p><img style=\"float: right; padding: 10px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/under-the-streetlight.jpg\" alt=\"\" /><small>See also: <a href=\"/lw/8ns/hack_away_at_the_edges/\">Hack Away at the Edges</a>.</small></p>\n<h3>The streetlight effect</h3>\n<p>You've heard <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Freedman-Why-Scientific-Studies-Are-So-Often-Wrong-The-Streetlight-Effect.pdf\">the joke</a> before:</p>\n<blockquote>\n<p>Late at night, a police officer finds a drunk man crawling around on his hands and knees under a streetlight. The drunk man tells the officer he&rsquo;s looking for his wallet. When the officer asks if he&rsquo;s sure this is where he dropped the wallet, the man replies that he thinks he more likely dropped it across the street. Then why are you looking over here? the befuddled officer asks. Because the light&rsquo;s better here, explains the drunk man.</p>\n</blockquote>\n<p>The joke illustrates the <a href=\"http://en.wikipedia.org/wiki/Streetlight_effect\">streetlight effect</a>: we \"<a href=\"http://www.nmji.in/archives/Volume-24/Issue-5/Speaking-For-OurSelves-ACAnand.pdf\">tend to</a> look for answers where the looking is good, rather than where the answers are likely to be hiding.\"</p>\n<p><a href=\"http://www.amazon.com/Wrong-us---Scientists-relationship-consultants/dp/B005DI6QAM/\">Freedman (2010)</a> documents at length some harms caused by the streetlight effect. For <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Freedman-Why-Scientific-Studies-Are-So-Often-Wrong-The-Streetlight-Effect.pdf\">example</a>:</p>\n<blockquote>\n<p>A bolt of excitement ran through the field of cardiology in the early 1980s when anti-arrhythmia drugs burst onto the scene. Researchers knew that heart-attack victims with steady heartbeats had the best odds of survival, so a medication that could tamp down irregularities seemed like a no-brainer. The drugs became the standard of care for heart-attack patients and were soon smoothing out heartbeats in intensive care wards across the United States.</p>\n<p>But in the early 1990s, cardiologists realized that the drugs were also doing something else: killing about 56,000 heart-attack patients a year. Yes, hearts were beating more regularly on the drugs than off, but their owners were, on average, one-third as likely to pull through. Cardiologists had been so focused on immediately measurable arrhythmias that they had overlooked the longer-term but far more important variable of <em>death</em>.</p>\n</blockquote>\n<h3><a id=\"more\"></a><br /></h3>\n<h3>Start under the streetlight</h3>\n<p>Of course, there are <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Freedman-Why-Scientific-Studies-Are-So-Often-Wrong-The-Streetlight-Effect.pdf\">good reasons</a> to search under the streetlight:</p>\n<blockquote>\n<p>It is often extremely difficult or even impossible to cleanly measure what is really important, so scientists instead cleanly measure what they can, hoping it turns out to be relevant.</p>\n</blockquote>\n<p>In retrospect, we might wish cardiologists had done a decade-long longitudinal study measuring the long-term effects of the new&nbsp;anti-arrhythmia&nbsp;drugs of the 1980s. But it's easy to understand why they didn't. Decades-long longitudinal studies are expensive, and resources are limited. It was more efficient to rely on an easily-measurable proxy variable like arrhythmias.</p>\n<p>We must remember, however, that the analogy to the streetlight joke isn't exact. Searching under the streetlight gives the drunkard virtually <em>no</em> information about where his wallet might be. But in science and other disciplines, searching under the streetlight can reveal helpful clues about the puzzle you're investigating. Given limited resources, it's often best to start searching under the streetlight and then, initial clues in hand, push into the shadows.<sup>1</sup></p>\n<p>The problem with streetlight science isn't that it relies on easily-measurable proxy variables. If you want to figure out how some psychological trait works, start with a small study and use free undergraduates at your home university &mdash; that's a good way to test hypotheses cheaply. The problem comes in when researchers don't appropriately <em>flag</em> the fact their subjects were <a href=\"http://www.psmag.com/magazines/pacific-standard-cover-story/joe-henrich-weird-ultimatum-game-shaking-up-psychology-economics-53135/\">WEIRD</a> and that a larger study needs to be done on a more representative population before we start drawing conclusions. (Another problem is that despite some researcher's cautions against overgeneralizing from a study of WEIRD subjects, the media will write splashy, universalizing headlines anyway.)</p>\n<p>But money and time aren't the only resources that might be limited. Another is <em>human reasoning ability</em>. Human brains were built for hunting and gathering in the savannah, not for unlocking the mysteries of fundamental physics or intelligence or consciousness. So even if time and money aren't limiting factors, it's often best to break a complex problem into pieces and think through the simplest pieces, or the pieces for which our data are most robust, before trying to answer the questions you <em>most</em> want to solve.</p>\n<p>As P&oacute;lya advises in his hugely popular <em><a href=\"http://en.wikipedia.org/wiki/How_to_Solve_It\">How to Solve It</a></em>, \"If you cannot solve the proposed problem, try to solve first some related [but easier] problem.\" In physics, this related but easier problem is often called a <a href=\"http://en.wikipedia.org/wiki/Toy_model\">toy model</a>. In other fields, it is sometimes called a <a href=\"http://en.wikipedia.org/wiki/Toy_problem\">toy problem</a>. <a href=\"http://en.wikipedia.org/wiki/Animal_model\">Animal models</a> are often used as toy models in biology and medicine.</p>\n<p>Or, as Scott Aaronson <a href=\"http://www.scottaaronson.com/blog/?p=346\">put it</a>:</p>\n<blockquote>\n<p>...I don&rsquo;t spend my life thinking about P versus NP [because] there are vastly easier prerequisite questions that we already don&rsquo;t know how to answer. In a field like [theoretical computer science], you very quickly get used to being able to state a problem with perfect clarity, knowing exactly what would constitute a solution, and still not having any clue how to solve it... And at least in my experience, being pounded with this situation again and again slowly reorients your worldview... Faced with a [very difficult question,] you learn to respond: &ldquo;What&rsquo;s another question that&rsquo;s easier to answer, and that probably has to be answered anyway before we have any chance on the original one?&rdquo;</p>\n</blockquote>\n<p>I'll close with two examples: <a href=\"http://www.givewell.org/\">GiveWell</a> on <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">effective altruism</a> and <a href=\"http://intelligence.org/\">MIRI</a> on <a href=\"/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/\">stability under self-modification</a>.</p>\n<h3><br /></h3>\n<h3>GiveWell on effective altruism</h3>\n<p>GiveWell's <a href=\"http://www.givewell.org/about/FAQ\">mission</a> is \"to find outstanding giving opportunities and publish the full details of our analysis to help donors decide where to give.\"</p>\n<p>But finding and verifying outstanding giving opportunities is <em>hard</em>. Consider the case of one straightforward-seeming intervention: <a href=\"http://en.wikipedia.org/wiki/Deworming\">deworming</a>.</p>\n<p>Nearly 2 billion people (mostly in poor countries) are infected by parasitic worms that hinder their cognitive development and overall health. This is also producing barriers to economic development where parasitic worms are common. Luckily, deworming pills are cheap, and early studies indicated that they <a href=\"http://www.nytimes.com/2009/12/24/opinion/24kristof.html?_r=2&amp;\">improved</a> <a href=\"http://www.nytimes.com/2009/12/24/opinion/24kristof.html?_r=2&amp;\">educational</a> <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Miguel-Kremer-Worms-identifying-impacts-on-education-and-health-in-the-presence-of-treatment.pdf\">outcomes</a>. The <a href=\"http://www.dcp2.org/pubs/DCP\">DCP2</a>, produced by over 300 contributors and in collaboration with the World Health Organization, estimated that a particular deworming treatment was one of the most cost-effective treatments in global health, at just $3.41 per <a href=\"http://en.wikipedia.org/wiki/Disability-adjusted_life_year\">DALY</a>.</p>\n<p>Unfortunately, things are not so simple. A <a href=\"http://www.thecochranelibrary.com/SpringboardWebApp/userfiles/ccoch/file/Neglected%20tropical%20diseases/CD000371.pdf\">careful review</a> of the evidence in 2008 by The Cochrane Collaboration concluded that, due to weaknesses in some studies' designs and other factors, \"No effect [of deworming drugs] on cognition or school performance has been demonstrated.\" And in 2011, GiveWell <a href=\"http://blog.givewell.org/2011/09/29/errors-in-dcp2-cost-effectiveness-estimate-for-deworming/\">found</a> that a spreadsheet used to produce the DCP2's estimates contained <em>5 separate errors</em> that, when corrected, increased the cost estimate for deworming by roughly <em>a factor of 100</em>. In 2012, <a href=\"http://onlinelibrary.wiley.com/doi/10.1002/14651858.CD000371.pub5/abstract\">another Cochrane review</a> was even more damning for the effectiveness of deworming, concluding that \"Routine deworming drugs given to school children... has not shown bene\ufb01t on weight in most studies... For haemoglobin and cognition, community deworming seems to have little or no effect, and the evidence in relation to school attendance, and school performance is generally poor, with no obvious or consistent effect.\"</p>\n<p>On the other hand, Innovations for Poverty Action <a href=\"http://poverty-action.org/blog/cochrane%E2%80%99s-incomplete-and-misleading-summary-evidence-deworming\">critiqued</a> the 2012 Cochrane review, and GiveWell <a href=\"http://blog.givewell.org/2012/07/13/new-cochrane-review-of-the-effectiveness-of-deworming/\">said</a> the review did not fully undermine the case for its <a href=\"http://www.givewell.org/international/top-charities/schistosomiasis-control-initiative\">#3 recommended charity</a>, which focuses on deworming.</p>\n<p>What are we to make of this? Thousands of hours of data collection and synthesis went into producing the initial case for deworming as a cost-effective intervention, and thousands of additional hours were required to discover flaws in those initial analyses. In the end, GiveWell recommends one deworming charity, the Schistosomiasis Control Initiative, but their <a href=\"http://www.givewell.org/international/top-charities/schistosomiasis-control-initiative\">page on SCI</a> is littered with qualifications and concerns and \"We don't know\"s.</p>\n<p>GiveWell had to wrestle with these complications despite the fact that it <em>chose</em> to search under the streetlight. Global health interventions are among the <em>easiest</em> interventions to analyze, and have often been subjected to multiple randomized controlled trials and dozens of experimental studies. Such high-quality evidence usually isn't available when trying to estimate the cost-effectiveness of, say, certain forms of political activism.</p>\n<p>GiveWell co-founder Holden Karnofsky suspects that the best giving opportunities are <em>not</em> in the domain of global health, but GiveWell began their search in global health &mdash; under the spotlight &mdash; (in part) because the evidence was clearer there.<sup>2</sup></p>\n<p>It's <a href=\"http://www.amazon.com/Unmaking-West-What-If-Scenarios-Rewrite/dp/0472031430/\">difficult</a> to do counterfactual history, but I suspect GiveWell made the right choice. While investigating global health, GiveWell has learned <a href=\"http://blog.givewell.org/2013/05/02/broad-market-efficiency/\">many</a> <a href=\"http://blog.givewell.org/2013/03/21/trying-and-failing-to-find-more-funding-gaps-for-delivering-proven-cost-effective-interventions/\">important</a> <a href=\"http://blog.givewell.org/2012/10/25/evaluating-people/\">lessons</a> <a href=\"http://blog.givewell.org/2012/09/13/updated-thoughts-on-our-key-criteria/\">about</a> <a href=\"http://blog.givewell.org/2012/07/20/some-history-behind-our-shifting-approach-to-research/\">effective</a> <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">altruism</a> &mdash; lessons it would have been more difficult to learn with the same clarity if they had begun with investigations of even-more-challenging domains like <a href=\"http://blog.givewell.org/2013/06/06/meta-research-update/\">meta-research</a> and pollitical activism. But now that they've learned those lessons, they're beginning to push into the shadows where the evidence is less clear, via <a href=\"http://blog.givewell.org/category/givewell-labs/\">GiveWell Labs</a>.</p>\n<h3><br /></h3>\n<h3>MIRI on stability under self-modification</h3>\n<p>MIRI's <a href=\"http://intelligence.org/about/\">mission</a> is \"to ensure that the creation of smarter-than-human intelligence has a positive impact.\"</p>\n<p>Many different interventions have been <a href=\"/lw/ffh/how_can_i_reduce_existential_risk_from_ai/\">proposed</a> as methods for increasing the odds that smarter-than-human intelligence has a positive impact, but for <a href=\"http://intelligence.org/2013/04/13/miris-strategy-for-2013/\">several reasons</a> MIRI decided to focus its efforts on \"Friendly AI research\" during 2013.</p>\n<p>The FAI research program decomposes into a wide variety of technical research questions. One of those questions is the question of <em>stability under self-modification</em>:</p>\n<blockquote>\n<p>How can we ensure that an AI will serve its intended purpose even after repeated self-modification?</p>\n</blockquote>\n<p>This is a challenging and ill-defined question. How might we make progress on such a puzzle?</p>\n<p>For puzzles such as this one, Scott Aaronson <a href=\"http://arxiv.org/pdf/1306.0159v2.pdf\">recommends</a> a strategy he calls \"bait and switch\":</p>\n<blockquote>\n<p>[Philosophical] progress has almost always involved a [kind of] &ldquo;bait-and-switch.&rdquo; In other words: one replaces an unanswerable philosophical riddle Q by a &ldquo;merely&rdquo; scientific or mathematical question Q&prime;, which captures part of what people have wanted to know when they&rsquo;ve asked Q. Then, with luck, one solves Q&prime;... this process of &ldquo;breaking o\ufb00&rdquo; answerable parts of unanswerable riddles, then trying to answer those parts, is the closest thing to philosophical progress that there is.</p>\n<p>Successful examples of this breaking-o\ufb00 process fill intellectual history. The use of calculus to treat infinite series, the link between mental activity and nerve impulses, natural selection, set theory and first-order logic, special relativity, G&ouml;del&rsquo;s theorem, game theory, information theory, computability and complexity theory, the Bell inequality, the theory of common knowledge, Bayesian causal networks &mdash; each of these advances addressed questions that could rightly have been called &ldquo;philosophical&rdquo; before the advance was made.</p>\n</blockquote>\n<p>The recent MIRI report on <a href=\"http://intelligence.org/files/TilingAgents.pdf\">Tiling Agents</a> performs one such \"bait and switch.\" It replaces the philosophical puzzle of \"How can we ensure that an AI will serve its intended purpose even after repeated self-modification?\" (Q) with a better-specified <em>formal</em> puzzle on which it is possible to make measurable progress: \"How can an agent perform perfectly tiling self-modifications despite L&ouml;b's Theorem?\" (Q')</p>\n<p>This allows us to state <a href=\"/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/94dx\">at least three</a> crisp technical problems: L&ouml;b and coherent quantified belief (sec. 3 of 'Tiling Agents'), nonmonotonicity of probabilistic reasoning (secs. 5.2 &amp; 7), and maximizing/satisficing not being satisfactory for bounded agents (sec. 8). It also allows us to identify progress: formal results that mankind had not previously uncovered (sec. 4).</p>\n<p>Of course, even if Q' is eventually solved, we'll need to check whether there are other pieces of Q we need to solve. Or perhaps Q will have been <em>dissolved</em> by our efforts to solve Q', similar to how the question \"What force distinguishes living matter from non-living matter?\" was dissolved by 20th century biology.</p>\n<h4><br /></h4>\n<h4><br /></h4>\n<h4>Notes</h4>\n<p><sup>1</sup> <small><a href=\"http://blog.givewell.org/2011/05/27/in-defense-of-the-streetlight-effect/\">Karnofsky (2011)</a> suggests that it may often be best to start under the streetlight <em>and stay there</em>, at least in the context of effective altruism. Karnofsky asks, \"What does it look like when we build knowledge only where we&rsquo;re best at building knowledge, rather than building knowledge on the 'most important problems?'\" His reply is: \"Researching topics we&rsquo;re good at researching can have a lot of benefits, some unexpected, some pertaining to problems we never expected such research to address. Researching topics we&rsquo;re bad at researching doesn&rsquo;t seem like a good idea no matter how important the topics are. Of course I&rsquo;m in favor of thinking about how to develop new research methods to make research good at what it was formerly bad at, but I&rsquo;m against applying current problematic research methods to current projects just because they&rsquo;re the best methods available.\" Here's one example: \"what has done more for political engagement in the U.S.: studying how to improve political engagement, or studying the technology that led to the development of the Internet, the World Wide Web, and ultimately to sites like Change.org...?\" I am sympathetic with Karnofsky's view in many cases, but I will give two points of reply with respect to my post above. First, in the above post I wanted to focus on the question of how to tackle difficult questions, not the question of whether difficult questions should be tackled in the first place. And conditional on one's choice to tackle a difficult question, I recommend one start under the streetlight and push into the shadows. Second, my guess is that I'm talking about a broader notion of the streetlight effect than Karnofsky is. For example, I doubt Karnofsky would object to the process of tackling a problem in theoretical computer science or math by trying to solve easier, related problems first.</small></p>\n<p><sup>2</sup> <small>In GiveWell's January 24th, 2013 board meeting (starting at 6:35 in <a href=\"http://www.givewell.org/files/ClearFund/Meeting%202013%2001%2024/Board%20call%202013%2001%2024.mp3\">the MP3 recording</a>), GiveWell co-founder Holden Karnofsky said that interventions outside global health are \"where we would bet today that we'll find... the best giving opportunities... that best fulfill GiveWell's mission as originally [outlined] in the mission statement.\" This doesn't appear to be a recently acquired view of things, either. Starting at 22:47 in the same recording, Karnofsky says \"There were reasons that we focused on [robustly evidence-backed] interventions for GiveWell initially, but... the [vision] I've been pointing to [of finding giving opportunities outside global health, where less evidence is available]... has [to me] been the vision all along.\" In personal communication with me, Karnofsky wrote that \"We sought to start 'under the streetlight,' as you say, and so focused on finding opportunities to fund things with strong documented evidence of being 'proven, cost-effective and scalable.' Initially we looked at both U.S. and global interventions, and within developing-world interventions we looked at health but also economic empowerment. We ended up focusing on global health because it performed best by these criteria.\"</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"aHjTRDkGypPqbXWpN": 2, "3uE2pXvbcnS9nnZRE": 2, "iTe27Ced8s8bGuvMK": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hRAzDwwMuu8CZSTvN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 51, "extendedScore": null, "score": 0.000166, "legacy": true, "legacyId": "23053", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 35, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><img style=\"float: right; padding: 10px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/under-the-streetlight.jpg\" alt=\"\"><small>See also: <a href=\"/lw/8ns/hack_away_at_the_edges/\">Hack Away at the Edges</a>.</small></p>\n<h3 id=\"The_streetlight_effect\">The streetlight effect</h3>\n<p>You've heard <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Freedman-Why-Scientific-Studies-Are-So-Often-Wrong-The-Streetlight-Effect.pdf\">the joke</a> before:</p>\n<blockquote>\n<p>Late at night, a police officer finds a drunk man crawling around on his hands and knees under a streetlight. The drunk man tells the officer he\u2019s looking for his wallet. When the officer asks if he\u2019s sure this is where he dropped the wallet, the man replies that he thinks he more likely dropped it across the street. Then why are you looking over here? the befuddled officer asks. Because the light\u2019s better here, explains the drunk man.</p>\n</blockquote>\n<p>The joke illustrates the <a href=\"http://en.wikipedia.org/wiki/Streetlight_effect\">streetlight effect</a>: we \"<a href=\"http://www.nmji.in/archives/Volume-24/Issue-5/Speaking-For-OurSelves-ACAnand.pdf\">tend to</a> look for answers where the looking is good, rather than where the answers are likely to be hiding.\"</p>\n<p><a href=\"http://www.amazon.com/Wrong-us---Scientists-relationship-consultants/dp/B005DI6QAM/\">Freedman (2010)</a> documents at length some harms caused by the streetlight effect. For <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Freedman-Why-Scientific-Studies-Are-So-Often-Wrong-The-Streetlight-Effect.pdf\">example</a>:</p>\n<blockquote>\n<p>A bolt of excitement ran through the field of cardiology in the early 1980s when anti-arrhythmia drugs burst onto the scene. Researchers knew that heart-attack victims with steady heartbeats had the best odds of survival, so a medication that could tamp down irregularities seemed like a no-brainer. The drugs became the standard of care for heart-attack patients and were soon smoothing out heartbeats in intensive care wards across the United States.</p>\n<p>But in the early 1990s, cardiologists realized that the drugs were also doing something else: killing about 56,000 heart-attack patients a year. Yes, hearts were beating more regularly on the drugs than off, but their owners were, on average, one-third as likely to pull through. Cardiologists had been so focused on immediately measurable arrhythmias that they had overlooked the longer-term but far more important variable of <em>death</em>.</p>\n</blockquote>\n<h3><a id=\"more\"></a><br></h3>\n<h3 id=\"Start_under_the_streetlight\">Start under the streetlight</h3>\n<p>Of course, there are <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Freedman-Why-Scientific-Studies-Are-So-Often-Wrong-The-Streetlight-Effect.pdf\">good reasons</a> to search under the streetlight:</p>\n<blockquote>\n<p>It is often extremely difficult or even impossible to cleanly measure what is really important, so scientists instead cleanly measure what they can, hoping it turns out to be relevant.</p>\n</blockquote>\n<p>In retrospect, we might wish cardiologists had done a decade-long longitudinal study measuring the long-term effects of the new&nbsp;anti-arrhythmia&nbsp;drugs of the 1980s. But it's easy to understand why they didn't. Decades-long longitudinal studies are expensive, and resources are limited. It was more efficient to rely on an easily-measurable proxy variable like arrhythmias.</p>\n<p>We must remember, however, that the analogy to the streetlight joke isn't exact. Searching under the streetlight gives the drunkard virtually <em>no</em> information about where his wallet might be. But in science and other disciplines, searching under the streetlight can reveal helpful clues about the puzzle you're investigating. Given limited resources, it's often best to start searching under the streetlight and then, initial clues in hand, push into the shadows.<sup>1</sup></p>\n<p>The problem with streetlight science isn't that it relies on easily-measurable proxy variables. If you want to figure out how some psychological trait works, start with a small study and use free undergraduates at your home university \u2014 that's a good way to test hypotheses cheaply. The problem comes in when researchers don't appropriately <em>flag</em> the fact their subjects were <a href=\"http://www.psmag.com/magazines/pacific-standard-cover-story/joe-henrich-weird-ultimatum-game-shaking-up-psychology-economics-53135/\">WEIRD</a> and that a larger study needs to be done on a more representative population before we start drawing conclusions. (Another problem is that despite some researcher's cautions against overgeneralizing from a study of WEIRD subjects, the media will write splashy, universalizing headlines anyway.)</p>\n<p>But money and time aren't the only resources that might be limited. Another is <em>human reasoning ability</em>. Human brains were built for hunting and gathering in the savannah, not for unlocking the mysteries of fundamental physics or intelligence or consciousness. So even if time and money aren't limiting factors, it's often best to break a complex problem into pieces and think through the simplest pieces, or the pieces for which our data are most robust, before trying to answer the questions you <em>most</em> want to solve.</p>\n<p>As P\u00f3lya advises in his hugely popular <em><a href=\"http://en.wikipedia.org/wiki/How_to_Solve_It\">How to Solve It</a></em>, \"If you cannot solve the proposed problem, try to solve first some related [but easier] problem.\" In physics, this related but easier problem is often called a <a href=\"http://en.wikipedia.org/wiki/Toy_model\">toy model</a>. In other fields, it is sometimes called a <a href=\"http://en.wikipedia.org/wiki/Toy_problem\">toy problem</a>. <a href=\"http://en.wikipedia.org/wiki/Animal_model\">Animal models</a> are often used as toy models in biology and medicine.</p>\n<p>Or, as Scott Aaronson <a href=\"http://www.scottaaronson.com/blog/?p=346\">put it</a>:</p>\n<blockquote>\n<p>...I don\u2019t spend my life thinking about P versus NP [because] there are vastly easier prerequisite questions that we already don\u2019t know how to answer. In a field like [theoretical computer science], you very quickly get used to being able to state a problem with perfect clarity, knowing exactly what would constitute a solution, and still not having any clue how to solve it... And at least in my experience, being pounded with this situation again and again slowly reorients your worldview... Faced with a [very difficult question,] you learn to respond: \u201cWhat\u2019s another question that\u2019s easier to answer, and that probably has to be answered anyway before we have any chance on the original one?\u201d</p>\n</blockquote>\n<p>I'll close with two examples: <a href=\"http://www.givewell.org/\">GiveWell</a> on <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">effective altruism</a> and <a href=\"http://intelligence.org/\">MIRI</a> on <a href=\"/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/\">stability under self-modification</a>.</p>\n<h3><br></h3>\n<h3 id=\"GiveWell_on_effective_altruism\">GiveWell on effective altruism</h3>\n<p>GiveWell's <a href=\"http://www.givewell.org/about/FAQ\">mission</a> is \"to find outstanding giving opportunities and publish the full details of our analysis to help donors decide where to give.\"</p>\n<p>But finding and verifying outstanding giving opportunities is <em>hard</em>. Consider the case of one straightforward-seeming intervention: <a href=\"http://en.wikipedia.org/wiki/Deworming\">deworming</a>.</p>\n<p>Nearly 2 billion people (mostly in poor countries) are infected by parasitic worms that hinder their cognitive development and overall health. This is also producing barriers to economic development where parasitic worms are common. Luckily, deworming pills are cheap, and early studies indicated that they <a href=\"http://www.nytimes.com/2009/12/24/opinion/24kristof.html?_r=2&amp;\">improved</a> <a href=\"http://www.nytimes.com/2009/12/24/opinion/24kristof.html?_r=2&amp;\">educational</a> <a href=\"http://commonsenseatheism.com/wp-content/uploads/2013/06/Miguel-Kremer-Worms-identifying-impacts-on-education-and-health-in-the-presence-of-treatment.pdf\">outcomes</a>. The <a href=\"http://www.dcp2.org/pubs/DCP\">DCP2</a>, produced by over 300 contributors and in collaboration with the World Health Organization, estimated that a particular deworming treatment was one of the most cost-effective treatments in global health, at just $3.41 per <a href=\"http://en.wikipedia.org/wiki/Disability-adjusted_life_year\">DALY</a>.</p>\n<p>Unfortunately, things are not so simple. A <a href=\"http://www.thecochranelibrary.com/SpringboardWebApp/userfiles/ccoch/file/Neglected%20tropical%20diseases/CD000371.pdf\">careful review</a> of the evidence in 2008 by The Cochrane Collaboration concluded that, due to weaknesses in some studies' designs and other factors, \"No effect [of deworming drugs] on cognition or school performance has been demonstrated.\" And in 2011, GiveWell <a href=\"http://blog.givewell.org/2011/09/29/errors-in-dcp2-cost-effectiveness-estimate-for-deworming/\">found</a> that a spreadsheet used to produce the DCP2's estimates contained <em>5 separate errors</em> that, when corrected, increased the cost estimate for deworming by roughly <em>a factor of 100</em>. In 2012, <a href=\"http://onlinelibrary.wiley.com/doi/10.1002/14651858.CD000371.pub5/abstract\">another Cochrane review</a> was even more damning for the effectiveness of deworming, concluding that \"Routine deworming drugs given to school children... has not shown bene\ufb01t on weight in most studies... For haemoglobin and cognition, community deworming seems to have little or no effect, and the evidence in relation to school attendance, and school performance is generally poor, with no obvious or consistent effect.\"</p>\n<p>On the other hand, Innovations for Poverty Action <a href=\"http://poverty-action.org/blog/cochrane%E2%80%99s-incomplete-and-misleading-summary-evidence-deworming\">critiqued</a> the 2012 Cochrane review, and GiveWell <a href=\"http://blog.givewell.org/2012/07/13/new-cochrane-review-of-the-effectiveness-of-deworming/\">said</a> the review did not fully undermine the case for its <a href=\"http://www.givewell.org/international/top-charities/schistosomiasis-control-initiative\">#3 recommended charity</a>, which focuses on deworming.</p>\n<p>What are we to make of this? Thousands of hours of data collection and synthesis went into producing the initial case for deworming as a cost-effective intervention, and thousands of additional hours were required to discover flaws in those initial analyses. In the end, GiveWell recommends one deworming charity, the Schistosomiasis Control Initiative, but their <a href=\"http://www.givewell.org/international/top-charities/schistosomiasis-control-initiative\">page on SCI</a> is littered with qualifications and concerns and \"We don't know\"s.</p>\n<p>GiveWell had to wrestle with these complications despite the fact that it <em>chose</em> to search under the streetlight. Global health interventions are among the <em>easiest</em> interventions to analyze, and have often been subjected to multiple randomized controlled trials and dozens of experimental studies. Such high-quality evidence usually isn't available when trying to estimate the cost-effectiveness of, say, certain forms of political activism.</p>\n<p>GiveWell co-founder Holden Karnofsky suspects that the best giving opportunities are <em>not</em> in the domain of global health, but GiveWell began their search in global health \u2014 under the spotlight \u2014 (in part) because the evidence was clearer there.<sup>2</sup></p>\n<p>It's <a href=\"http://www.amazon.com/Unmaking-West-What-If-Scenarios-Rewrite/dp/0472031430/\">difficult</a> to do counterfactual history, but I suspect GiveWell made the right choice. While investigating global health, GiveWell has learned <a href=\"http://blog.givewell.org/2013/05/02/broad-market-efficiency/\">many</a> <a href=\"http://blog.givewell.org/2013/03/21/trying-and-failing-to-find-more-funding-gaps-for-delivering-proven-cost-effective-interventions/\">important</a> <a href=\"http://blog.givewell.org/2012/10/25/evaluating-people/\">lessons</a> <a href=\"http://blog.givewell.org/2012/09/13/updated-thoughts-on-our-key-criteria/\">about</a> <a href=\"http://blog.givewell.org/2012/07/20/some-history-behind-our-shifting-approach-to-research/\">effective</a> <a href=\"http://blog.givewell.org/2011/11/10/maximizing-cost-effectiveness-via-critical-inquiry/\">altruism</a> \u2014 lessons it would have been more difficult to learn with the same clarity if they had begun with investigations of even-more-challenging domains like <a href=\"http://blog.givewell.org/2013/06/06/meta-research-update/\">meta-research</a> and pollitical activism. But now that they've learned those lessons, they're beginning to push into the shadows where the evidence is less clear, via <a href=\"http://blog.givewell.org/category/givewell-labs/\">GiveWell Labs</a>.</p>\n<h3><br></h3>\n<h3 id=\"MIRI_on_stability_under_self_modification\">MIRI on stability under self-modification</h3>\n<p>MIRI's <a href=\"http://intelligence.org/about/\">mission</a> is \"to ensure that the creation of smarter-than-human intelligence has a positive impact.\"</p>\n<p>Many different interventions have been <a href=\"/lw/ffh/how_can_i_reduce_existential_risk_from_ai/\">proposed</a> as methods for increasing the odds that smarter-than-human intelligence has a positive impact, but for <a href=\"http://intelligence.org/2013/04/13/miris-strategy-for-2013/\">several reasons</a> MIRI decided to focus its efforts on \"Friendly AI research\" during 2013.</p>\n<p>The FAI research program decomposes into a wide variety of technical research questions. One of those questions is the question of <em>stability under self-modification</em>:</p>\n<blockquote>\n<p>How can we ensure that an AI will serve its intended purpose even after repeated self-modification?</p>\n</blockquote>\n<p>This is a challenging and ill-defined question. How might we make progress on such a puzzle?</p>\n<p>For puzzles such as this one, Scott Aaronson <a href=\"http://arxiv.org/pdf/1306.0159v2.pdf\">recommends</a> a strategy he calls \"bait and switch\":</p>\n<blockquote>\n<p>[Philosophical] progress has almost always involved a [kind of] \u201cbait-and-switch.\u201d In other words: one replaces an unanswerable philosophical riddle Q by a \u201cmerely\u201d scientific or mathematical question Q\u2032, which captures part of what people have wanted to know when they\u2019ve asked Q. Then, with luck, one solves Q\u2032... this process of \u201cbreaking o\ufb00\u201d answerable parts of unanswerable riddles, then trying to answer those parts, is the closest thing to philosophical progress that there is.</p>\n<p>Successful examples of this breaking-o\ufb00 process fill intellectual history. The use of calculus to treat infinite series, the link between mental activity and nerve impulses, natural selection, set theory and first-order logic, special relativity, G\u00f6del\u2019s theorem, game theory, information theory, computability and complexity theory, the Bell inequality, the theory of common knowledge, Bayesian causal networks \u2014 each of these advances addressed questions that could rightly have been called \u201cphilosophical\u201d before the advance was made.</p>\n</blockquote>\n<p>The recent MIRI report on <a href=\"http://intelligence.org/files/TilingAgents.pdf\">Tiling Agents</a> performs one such \"bait and switch.\" It replaces the philosophical puzzle of \"How can we ensure that an AI will serve its intended purpose even after repeated self-modification?\" (Q) with a better-specified <em>formal</em> puzzle on which it is possible to make measurable progress: \"How can an agent perform perfectly tiling self-modifications despite L\u00f6b's Theorem?\" (Q')</p>\n<p>This allows us to state <a href=\"/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/94dx\">at least three</a> crisp technical problems: L\u00f6b and coherent quantified belief (sec. 3 of 'Tiling Agents'), nonmonotonicity of probabilistic reasoning (secs. 5.2 &amp; 7), and maximizing/satisficing not being satisfactory for bounded agents (sec. 8). It also allows us to identify progress: formal results that mankind had not previously uncovered (sec. 4).</p>\n<p>Of course, even if Q' is eventually solved, we'll need to check whether there are other pieces of Q we need to solve. Or perhaps Q will have been <em>dissolved</em> by our efforts to solve Q', similar to how the question \"What force distinguishes living matter from non-living matter?\" was dissolved by 20th century biology.</p>\n<h4><br></h4>\n<h4><br></h4>\n<h4 id=\"Notes\">Notes</h4>\n<p><sup>1</sup> <small><a href=\"http://blog.givewell.org/2011/05/27/in-defense-of-the-streetlight-effect/\">Karnofsky (2011)</a> suggests that it may often be best to start under the streetlight <em>and stay there</em>, at least in the context of effective altruism. Karnofsky asks, \"What does it look like when we build knowledge only where we\u2019re best at building knowledge, rather than building knowledge on the 'most important problems?'\" His reply is: \"Researching topics we\u2019re good at researching can have a lot of benefits, some unexpected, some pertaining to problems we never expected such research to address. Researching topics we\u2019re bad at researching doesn\u2019t seem like a good idea no matter how important the topics are. Of course I\u2019m in favor of thinking about how to develop new research methods to make research good at what it was formerly bad at, but I\u2019m against applying current problematic research methods to current projects just because they\u2019re the best methods available.\" Here's one example: \"what has done more for political engagement in the U.S.: studying how to improve political engagement, or studying the technology that led to the development of the Internet, the World Wide Web, and ultimately to sites like Change.org...?\" I am sympathetic with Karnofsky's view in many cases, but I will give two points of reply with respect to my post above. First, in the above post I wanted to focus on the question of how to tackle difficult questions, not the question of whether difficult questions should be tackled in the first place. And conditional on one's choice to tackle a difficult question, I recommend one start under the streetlight and push into the shadows. Second, my guess is that I'm talking about a broader notion of the streetlight effect than Karnofsky is. For example, I doubt Karnofsky would object to the process of tackling a problem in theoretical computer science or math by trying to solve easier, related problems first.</small></p>\n<p><sup>2</sup> <small>In GiveWell's January 24th, 2013 board meeting (starting at 6:35 in <a href=\"http://www.givewell.org/files/ClearFund/Meeting%202013%2001%2024/Board%20call%202013%2001%2024.mp3\">the MP3 recording</a>), GiveWell co-founder Holden Karnofsky said that interventions outside global health are \"where we would bet today that we'll find... the best giving opportunities... that best fulfill GiveWell's mission as originally [outlined] in the mission statement.\" This doesn't appear to be a recently acquired view of things, either. Starting at 22:47 in the same recording, Karnofsky says \"There were reasons that we focused on [robustly evidence-backed] interventions for GiveWell initially, but... the [vision] I've been pointing to [of finding giving opportunities outside global health, where less evidence is available]... has [to me] been the vision all along.\" In personal communication with me, Karnofsky wrote that \"We sought to start 'under the streetlight,' as you say, and so focused on finding opportunities to fund things with strong documented evidence of being 'proven, cost-effective and scalable.' Initially we looked at both U.S. and global interventions, and within developing-world interventions we looked at health but also economic empowerment. We ended up focusing on global health because it performed best by these criteria.\"</small></p>", "sections": [{"title": "The streetlight effect", "anchor": "The_streetlight_effect", "level": 1}, {"title": "Start under the streetlight", "anchor": "Start_under_the_streetlight", "level": 1}, {"title": "GiveWell on effective altruism", "anchor": "GiveWell_on_effective_altruism", "level": 1}, {"title": "MIRI on stability under self-modification", "anchor": "MIRI_on_stability_under_self_modification", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "29 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6bSHiD9TxsJwe2WqT", "gnxDNEtkEo3sfeyPn", "qARBe3jBodrdPeRE6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-24T08:57:02.350Z", "modifiedAt": null, "url": null, "title": "Meetup :  ", "slug": "meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "A4YWnHwTjSbdqiGhj", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JYDjTjAsKcetbci8h/meetup", "pageUrlRelative": "/posts/JYDjTjAsKcetbci8h/meetup", "linkUrl": "https://www.lesswrong.com/posts/JYDjTjAsKcetbci8h/meetup", "postedAtFormatted": "Monday, June 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJYDjTjAsKcetbci8h%2Fmeetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJYDjTjAsKcetbci8h%2Fmeetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJYDjTjAsKcetbci8h%2Fmeetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o2'> </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">30 June 2013 04:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Berkeley</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o2'> </a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JYDjTjAsKcetbci8h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 2e-06, "legacy": true, "legacyId": "23063", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____\">Discussion article for the meetup : <a href=\"/meetups/o2\"> </a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">30 June 2013 04:30:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Berkeley</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p></p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____1\">Discussion article for the meetup : <a href=\"/meetups/o2\"> </a></h2>", "sections": [{"title": "Discussion article for the meetup :  ", "anchor": "Discussion_article_for_the_meetup____", "level": 1}, {"title": "Discussion article for the meetup :  ", "anchor": "Discussion_article_for_the_meetup____1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-24T12:06:18.614Z", "modifiedAt": null, "url": null, "title": "Living in the shadow of superintelligence", "slug": "living-in-the-shadow-of-superintelligence", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:29.799Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mitchell_Porter", "createdAt": "2009-05-28T02:36:19.394Z", "isAdmin": false, "displayName": "Mitchell_Porter"}, "userId": "fjERoRhgjipqw3z2b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vewxgYHhsNTTtkqSj/living-in-the-shadow-of-superintelligence", "pageUrlRelative": "/posts/vewxgYHhsNTTtkqSj/living-in-the-shadow-of-superintelligence", "linkUrl": "https://www.lesswrong.com/posts/vewxgYHhsNTTtkqSj/living-in-the-shadow-of-superintelligence", "postedAtFormatted": "Monday, June 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Living%20in%20the%20shadow%20of%20superintelligence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALiving%20in%20the%20shadow%20of%20superintelligence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvewxgYHhsNTTtkqSj%2Fliving-in-the-shadow-of-superintelligence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Living%20in%20the%20shadow%20of%20superintelligence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvewxgYHhsNTTtkqSj%2Fliving-in-the-shadow-of-superintelligence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvewxgYHhsNTTtkqSj%2Fliving-in-the-shadow-of-superintelligence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<p>Although it regularly discusses the possibility of superintelligences with the power to transform the universe in the service of some value system - whether that value system is <a href=\"http://wiki.lesswrong.com/wiki/Paperclip_maximizer\">paperclip maximization</a> or <a href=\"http://wiki.lesswrong.com/wiki/Coherent_Extrapolated_Volition\">some elusive extrapolation of human values</a> - it seems that Less Wrong has never systematically discussed the possibility that we are already within the domain of some superintelligence, and what that would imply. So how about it? What are the possibilities, what are the probabilities, and how should they affect our choices?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vewxgYHhsNTTtkqSj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": -3, "extendedScore": null, "score": 1.2431516822917222e-06, "legacy": true, "legacyId": "23065", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-24T17:14:22.647Z", "modifiedAt": null, "url": null, "title": "[LINK] Mr. Money Mustache on Back of the Napkin Calculations and Financial Planning", "slug": "link-mr-money-mustache-on-back-of-the-napkin-calculations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:27.937Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Petruchio", "createdAt": "2012-09-20T21:52:44.002Z", "isAdmin": false, "displayName": "Petruchio"}, "userId": "Sq97ckSEEWbQ6AxC9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eevTjJu3FxsL72Fc2/link-mr-money-mustache-on-back-of-the-napkin-calculations", "pageUrlRelative": "/posts/eevTjJu3FxsL72Fc2/link-mr-money-mustache-on-back-of-the-napkin-calculations", "linkUrl": "https://www.lesswrong.com/posts/eevTjJu3FxsL72Fc2/link-mr-money-mustache-on-back-of-the-napkin-calculations", "postedAtFormatted": "Monday, June 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Mr.%20Money%20Mustache%20on%20Back%20of%20the%20Napkin%20Calculations%20and%20Financial%20Planning&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Mr.%20Money%20Mustache%20on%20Back%20of%20the%20Napkin%20Calculations%20and%20Financial%20Planning%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeevTjJu3FxsL72Fc2%2Flink-mr-money-mustache-on-back-of-the-napkin-calculations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Mr.%20Money%20Mustache%20on%20Back%20of%20the%20Napkin%20Calculations%20and%20Financial%20Planning%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeevTjJu3FxsL72Fc2%2Flink-mr-money-mustache-on-back-of-the-napkin-calculations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeevTjJu3FxsL72Fc2%2Flink-mr-money-mustache-on-back-of-the-napkin-calculations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 28, "htmlBody": "<p class=\"title\">A new Mr. Money Mustache article for those who enjoyed my <a href=\"/lw/hic/a_rational_financial_planning_overview/\">sequence</a> on financial planning and extreme early retirement.</p>\r\n<p class=\"title\"><a href=\"http://www.mrmoneymustache.com/2013/06/24/when-the-back-of-the-napkin-can-be-worth-millions/\">When the Back of the Napkin can be Worth Millions</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eevTjJu3FxsL72Fc2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -3, "extendedScore": null, "score": 1.243389564202191e-06, "legacy": true, "legacyId": "23066", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iqvYGEmMHhFSEcfTr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-24T19:51:51.451Z", "modifiedAt": null, "url": null, "title": "The Mystery At The Heart of Central Banking", "slug": "the-mystery-at-the-heart-of-central-banking", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:04.241Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "9hQryffdwLDyNbnkh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PtJbQfCSDwuT57sj7/the-mystery-at-the-heart-of-central-banking", "pageUrlRelative": "/posts/PtJbQfCSDwuT57sj7/the-mystery-at-the-heart-of-central-banking", "linkUrl": "https://www.lesswrong.com/posts/PtJbQfCSDwuT57sj7/the-mystery-at-the-heart-of-central-banking", "postedAtFormatted": "Monday, June 24th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Mystery%20At%20The%20Heart%20of%20Central%20Banking&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Mystery%20At%20The%20Heart%20of%20Central%20Banking%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPtJbQfCSDwuT57sj7%2Fthe-mystery-at-the-heart-of-central-banking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Mystery%20At%20The%20Heart%20of%20Central%20Banking%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPtJbQfCSDwuT57sj7%2Fthe-mystery-at-the-heart-of-central-banking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPtJbQfCSDwuT57sj7%2Fthe-mystery-at-the-heart-of-central-banking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1972, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Arial;\">\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Economists love decentralized competitive markets. There&rsquo;s nothing an economist likes to see more than some decentralized entrepreneurs starting businesses with well-defined property rights, competing with each other to serve the interests of others in order to serve their own interests, coordinated through decentralized prices which transmit information about relative scarcities, with success determined by profits and failure by loss. We love decentralized competitive markets so much that we even call them &ldquo;perfect.&rdquo; Any deviation from this perfection is labeled &ldquo;inefficient&rdquo; and &ldquo;failure&rdquo; and economists quickly design a correction intended to push the system back towards perfection with minimal interference.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Now let&rsquo;s look at central banking and try to predict whether economists would love or hate it. To what extent does central banking approach economists&rsquo; vision of perfection?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Is the bank decentralized? Nope, it has &ldquo;central&rdquo; in the name for crying out loud.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Competitive? Central banks are monopolies by law. Competing with a central bank is a crime.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Private actors serving the public good through self-interest? No, central banking uses government-employed technocrats whose motives are apparently supposed to be public-spiritedness in the manner of politicians and government bureaucrats.&nbsp;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Success determined by profits and failure by loss? The central bank is not a profit-maximizing entity and in any case has the explicit backing of the government in case it runs into trouble, a support central banks the world over have repeatedly had to turn to in crisis.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Coordination through decentralized profits? On the contrary, the central bank is the entity that is supposed to be doing the coordinating, these days on a global level, when economists are convinced that in every other industry centralized planning runs into insurmountable information and incentives problems at a scale far below what central banks these days are expected to manage.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">So what do you predict? Are economists supportive of central banking or not?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">That&rsquo;s right, economists support central banking over competitive decentralized banking near-unanimously. The only university of any significance that might have an economics department a majority of whom support free market banking would be George Mason University. There are also a couple of very small colleges with an &ldquo;Austrian&rdquo; economics program that are also most likely supportive of a free market in banking and oppose central banking. Otherwise, economists spend quite a lot of time and effort both staffing and running central banks, gathering data and developing theories, trying to learn what mistakes central banks made in the past and how to avoid them in the future, arguing over what central banks should be doing in the present and what they should be prepared for in the future, etc. Support for a banking system that doesn&rsquo;t include a central bank is a minority fringe view.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">That...</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">...Is <em>not</em> what anyone would expect, if they knew what economists generally think about decentralized competitive markets versus government-supported monopolies tasked with managing the macroeconomy <em>before</em> they knew how near-unanimously supportive economists are of central banking. So what&rsquo;s going on?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Not all industries are identical, and banking is unique among all the different kinds of markets since it has a unique relationship with a unique good, money. So while you shouldn&rsquo;t expect economists to support central banking, you also shouldn&rsquo;t be too surprised by their support <em>if they have a good explanation for why they do</em>.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">And of course economists will have a good explanation for their support for central banking. Central banking isn&rsquo;t new--if you date the beginning of economics at 1776, when Adam Smith published <em>The Wealth of Nations</em>, then centrally banking pre-dates economics--so they&rsquo;ve had plenty of time to think about it. Economists have been working and theorizing for central banks for centuries, so they&rsquo;re familiar with central banking and the many ways it differs from the &ldquo;perfect&rdquo; arrangement economists are usually so fond of. Plus central banking is simply something that should clash so strongly with their normal intuitions--seriously? A government-protected monopoly centrally managing the macroeconomy--that every new generation of student economists would stridently demand explanations from their professors. Finally, centrally banking is <em>really important</em>, and it is something economists have responsibility for in a way that isn&rsquo;t true of any other institution. Getting the right answer on central banking versus some other banking regime is one of the most important things that economists could do.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">So let&rsquo;s ask Greg Mankiw, professor and chairman of the economics department at Harvard University, where among other things, he teaches introductory economics, just why it is economists support central banking. Mankiw is the author of a very popular macroeconomics textbook for undergraduates. He&rsquo;s smart, well-read, and a very popular and successful educator. If anyone would have developed a thorough, persuasive answer to the question of why economists support central banking, it would be Greg Mankiw.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">&ldquo;The economics profession does not have a good answer.&rdquo;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Oh. Uh--</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px color;\">&ldquo;</span><span style=\"letter-spacing: 0.0px;\">We economists have rigorous and fundamental theory to explain why we have environmental regulation (externalities) and to explain why we have antitrust laws (market power), but there is no consensus about what market failure calls for the existence of a central bank. &ldquo;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Okay, well &ldquo;no consensus&rdquo; isn&rsquo;t so bad. It must be a hard topic. But economists must be hotly debating all kinds of answers--</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">&ldquo;The answer has something to do with the benefits of a system of fiat money. And it has something to do with the possibility of short-run monetary nonneutrality (due to sticky prices and/or imperfect information about prices). But the precise combination of elements that would yield a satisfying answer is still elusive.&rdquo;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Wait, so nobody has an answer?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">And let us note that &ldquo;the benefits of a system of fiat money&rdquo; seems insignificantly different from &ldquo;the benefits of central banking&rdquo; because <em>that&rsquo;s pretty much what a system of fiat money is</em>. And I can&rsquo;t for the light of me see how &ldquo;the possiblity of short-run monetary nonneutrality&rdquo; should be sufficient to move economists from their normal support of decentralized competitive markets to support for a government-backed monopoly tasked with central planning, or even how it should move economists in that direction <em>at all</em>, and Mankiw doesn&rsquo;t explain or even link to someone else&rsquo;s suggestion.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Please, Professor Mankiw, if you don&rsquo;t know the answer just tell us who does--</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">&ldquo;If anyone has a good answer, let me know, or publish it in the American Economic Review.&rdquo;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">...</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Okay, is it just me, or does it kind of sound like Greg Mankiw, professor and chairman of the department of economics at <em>Harvard</em> University, perhaps the most popular economics educator in the United States, not only not know the answer, but <em>he doesn&rsquo;t even know of anyone in the economics profession who has ever offered a good answer.</em></span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\"><span style=\"letter-spacing: 0.0px;\"><em></em></span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">It&rsquo;s almost as if Mankiw has never heard a reason why economists should support central banking (at least, one that doesn&rsquo;t beg the question--&ldquo;the benefits of a system of fiat money&rdquo; explains nothing). He also--professor and chairman of the department of economics at <em>Harvard</em>--doesn&rsquo;t think that any other economist ever has come up with a good reason, even one that he hasn&rsquo;t personally heard.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">And he doesn&rsquo;t even seem particularly concerned about what is essentially the most important question in monetary theory.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">....</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">I did my own search, and I can confirm that Mankiw isn&rsquo;t simply lazy or ignorant. The economics profession really doesn&rsquo;t have a good answer to this incredibly important question. They do have an explanation for why they don&rsquo;t support unregulated banking: banking regimes that lacked central banks suffered financial crises and recessions--for example, the repeated financial crises of postbellum America that led to the demand for banking reform which culminated in the creation of the Federal Reserve system.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">This is a weak argument, however. It doesn&rsquo;t even work as a strike against a free market in banking because banking regimes like that of postbellum America were heavily regulated despite the lack of a central bank. Lightly regulated banking regimes like Canada and Scotland did at different times in history did a better job of avoiding and weathering financial crises and recessions than did America&rsquo;s and and Britain&rsquo;s over the same period of time. Furthermore, banking regimes that include central banks have also suffered from financial crises and recessions. We&rsquo;re still feeling the effects of one today. So if the occurrence&nbsp; financial crises and recessions were arguments against the system that preceded, then they are just as equally arguments against the current system, the system of central banking.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">So the one argument economists have is an incredibly weak argument against a free market in banking, and it is an argument <em>against</em> central banking.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">And economists really don&rsquo;t seem to care about this. It is something they are simply not curious about. They don&rsquo;t write about it, not even things like &ldquo;Boy, It Sure is Weird that We All Just Accept Central Banking.&rdquo; When you study any other industry in economics, first you learn about how it works in the &ldquo;natural&rdquo; unregulated state, and then you decide if regulations are desirable and what those regulations might look like and what consequences they will have. When it comes to banking, the textbooks start with a central bank. Free market banking is completely ignored. If any justification is offered, it is a brief version of &ldquo;the past system had a lot of crises&rdquo; argument that cuts just as strongly against central banking.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Now, and this might be presumptuous, but there is an obvious explanation for why economists would be entirely uncurious about central banking and be perfectly content with that state of affairs.&nbsp;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">First of all, people are naturally uncurious about things. Hopefully scientists are more curious, at least about the subject matter of their own science, but in remember that central banking pre-dates economics. Central banking is what economists are used to. This is more of a barrier than it might seem. It is well known in economics that people are entirely comfortable with markets in things that they are used to and extremely skeptical and suspicious of markets in things that they are not, even when they work by the exact same principles--look at the resistance and apathy towards prediction markets for an example. There is something of a joke in economics to the effect that if the market for sandwiches had always been controlled in a top-down manner, then calls to open the market to free competition would be met with cries of &ldquo;But where will the sandwiches come from?&rdquo; and things to that effect. People have a very hard time imagining how markets they aren&rsquo;t used to will work. This should be doubly true of a free market in banking, which doesn&rsquo;t have a great number of historical examples, and those examples (Scotland, Canada, Australia) aren&rsquo;t very well known. Just as importantly, banking is a particularly, perhaps uniquely, abstract and difficult industry to understand. If there was every a set of problems economists would be tempted to run from, it would be the economics of banking.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Second of all, there is the obvious problem of self-interest. Central banking raises the income and status of economists, and strokes their ego. It lets them work cushy, secure high-paying high-status jobs where they get to do what they enjoy and feel like they are in charge of the economy to some extent. They can flatter themselves that they are controlling things and fixing the world while pulling in a nice income doing the work that they like.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">Given those two points, it&rsquo;s not that surprising anymore that economists support central banking, don&rsquo;t have any reasons for supporting central banking over a free market in banking, and aren&rsquo;t very bothered by this.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">To see if that explanation holds up...</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">...And to find out for ourselves what kind of banking regime, central banking or other, is actually justified by the economics...</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; color: #333233;\"><span style=\"letter-spacing: 0.0px;\">We&rsquo;ll start exploring from the beginning: just why do economists generally support decentralized competitive markets over government-backed monopolies? Why should economists have to be persuaded of the merits central banking from the more obvious position of free market banking, the opposite of the status quo? That is where we&rsquo;ll begin.</span></p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PtJbQfCSDwuT57sj7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": -7, "extendedScore": null, "score": -4e-06, "legacy": true, "legacyId": "23068", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T02:36:03.672Z", "modifiedAt": null, "url": null, "title": "Suggestions for Rationality Blogs in the Sidebar", "slug": "suggestions-for-rationality-blogs-in-the-sidebar", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:31.341Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LucasSloan", "createdAt": "2009-05-28T05:04:38.345Z", "isAdmin": false, "displayName": "LucasSloan"}, "userId": "ouo6Fqn5kTNY7LvqM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5BoPvMtqDP9hYhZcp/suggestions-for-rationality-blogs-in-the-sidebar", "pageUrlRelative": "/posts/5BoPvMtqDP9hYhZcp/suggestions-for-rationality-blogs-in-the-sidebar", "linkUrl": "https://www.lesswrong.com/posts/5BoPvMtqDP9hYhZcp/suggestions-for-rationality-blogs-in-the-sidebar", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Suggestions%20for%20Rationality%20Blogs%20in%20the%20Sidebar&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASuggestions%20for%20Rationality%20Blogs%20in%20the%20Sidebar%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5BoPvMtqDP9hYhZcp%2Fsuggestions-for-rationality-blogs-in-the-sidebar%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Suggestions%20for%20Rationality%20Blogs%20in%20the%20Sidebar%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5BoPvMtqDP9hYhZcp%2Fsuggestions-for-rationality-blogs-in-the-sidebar", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5BoPvMtqDP9hYhZcp%2Fsuggestions-for-rationality-blogs-in-the-sidebar", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<p>I'm spending the summer working to update lesswrong, and one of the changes we're looking to implement is changing the \"New on Overcoming Bias\" part of the sidebar to a more general \"New on Rationality Blogs\".&nbsp; What blogs would you like to see represented?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5BoPvMtqDP9hYhZcp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 18, "extendedScore": null, "score": 1.2438234897485374e-06, "legacy": true, "legacyId": "23074", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T03:47:10.994Z", "modifiedAt": null, "url": null, "title": "How to Have Space Correctly", "slug": "how-to-have-space-correctly", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:37.156Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uWDGzJME8FmnzrMgm/how-to-have-space-correctly", "pageUrlRelative": "/posts/uWDGzJME8FmnzrMgm/how-to-have-space-correctly", "linkUrl": "https://www.lesswrong.com/posts/uWDGzJME8FmnzrMgm/how-to-have-space-correctly", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20Have%20Space%20Correctly&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20Have%20Space%20Correctly%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuWDGzJME8FmnzrMgm%2Fhow-to-have-space-correctly%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20Have%20Space%20Correctly%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuWDGzJME8FmnzrMgm%2Fhow-to-have-space-correctly", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuWDGzJME8FmnzrMgm%2Fhow-to-have-space-correctly", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2336, "htmlBody": "<p>[NOTE: <em>This post has undergone substantial revisions following feedback in the comments section. &nbsp;The basic complaint was that it was too airy and light on concrete examples and recommendations. &nbsp;So I've <a href=\"/lw/i9/the_importance_of_saying_oops/\">said oops</a>, applied the <a href=\"/lw/ic/the_virtue_of_narrowness/\">virtue of narrowness</a>, <a href=\"/lw/bc3/sotw_be_specific/\">gotten specific</a>, and hopefully made this what it should've been the first time.</em>]<em>&nbsp;&nbsp;</em></p>\n<p>&nbsp;</p>\n<p>Take a moment and picture a master surgeon about to begin an operation. &nbsp;Visualize the room (white, bright overhead lights), his clothes (green scrubs, white mask and gloves), the patient, under anesthesia and awaiting the first incision. There are several other people, maybe three or four, strategically placed and preparing for the task ahead. &nbsp;Visualize his tools - it's okay if you don't actually know what tools a surgeon uses, but imagine how they might be arranged. &nbsp;Do you picture them in a giant heap which the surgeon must dig through every time he wants something, or would they be arranged neatly (possibly in the order they'll be used) and where they can be identified instantly by sight? &nbsp;Visualize their working area. &nbsp;Would it be conducive to have random machines and equipment all over the place, or would every single item within arms reach be put there on purpose because it is relevant, with nothing left over to distract the team from their job for even a moment? &nbsp; &nbsp;</p>\n<p>Space is important. &nbsp;You are a spatially extended being interacting with spatially extended objects which can and must be arranged spatially. &nbsp;In the same way it may not have occurred to you that there is a&nbsp;<a href=\"/lw/eyt/how_to_have_things_correctly/\">correct way to have things</a>, it may not have occurred to you that space is something you can use poorly or well. &nbsp;The stakes aren't always as high as they are for a surgeon, and I'm sure there are plenty of productive people who don't do a single one of the things I'm going to talk about. &nbsp;But there are also skinny people who eat lots of cheesecake, and that doesn't mean cheesecake is good for you. &nbsp;Improving how you use the scarce resource of space can reduce task completion time, help in&nbsp;<a href=\"http://rulerstothesky.wordpress.com/\">getting organized</a>, make you less error-prone and forgetful, and free up some internal computational resources, among other things. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>What Does Using Space Well Mean?</strong></p>\n<p>It means <em>consciously manipulating the arrangement, visibility, prominence, etc. of objects in your environment to change how they affect cognition</em> (yours or other people's). &nbsp;<a href=\"http://adrenaline.ucsd.edu/kirsh/Articles/Space/AIJ1.html\">The&nbsp;Intelligent Use of Space</a>&nbsp;(Kirsh, \"The Intelligent Use of Space\", 1995) is a great place to start if you're skeptical that there is anything here worth considering. &nbsp;It's my primary source for this post because it is thorough but not overly technical, contains lots of clear examples, and many of the related papers I read were about deeper theoretical issues. &nbsp;</p>\n<p>The abstract of the paper reads:</p>\n<blockquote>\n<p>How we manage the spatial arrangement of items around us is not an afterthought: it is an integral part of the way we think, plan, and behave. The proposed classification has three main categories: spatial arrangements that simplify choice; spatial arrangements that simplify perception; and spatial dynamics that simplify internal computation. The data for such a classification is drawn from videos of cooking, assembly and packing, everyday observations in supermarkets, workshops and playrooms, and experimental studies of subjects playing Tetris, the computer game. This study, therefore, focuses on interactive processes in the medium and short term: on how agents set up their workplace for particular tasks, and how they continuously manage that workplace.</p>\n</blockquote>\n<p>The 'three main categories' of simplifying choice, perception, and internal computation can be further subdivided:</p>\n<p>&nbsp; <span style=\"text-decoration: underline;\">simplifying choice</span></p>\n<p>&nbsp; &nbsp; &nbsp; reducing or emphasizing options.</p>\n<p>&nbsp; &nbsp; &nbsp; creating the potential for useful new choices.</p>\n<p>&nbsp; <span style=\"text-decoration: underline;\">simplifying perception</span></p>\n<p>&nbsp; &nbsp; &nbsp; clustering like objects.</p>\n<p>&nbsp; &nbsp; &nbsp; marking an object.</p>\n<p>&nbsp; &nbsp; &nbsp; enhancing perceptual ability.</p>\n<p>&nbsp; <span style=\"text-decoration: underline;\">simplfying internal computation</span></p>\n<p>&nbsp; &nbsp; &nbsp;doing more outside of your head.</p>\n<p>These sub-categories are easier to picture and thus more useful when trying to apply the concept of using space correctly, and I've provided more illustrations below. It's worth pointing out that (Kirsh, \"The Intelligent Use of Space\", 1995) only considered the behavior of experts. &nbsp;Perhaps effective space management partially explains expert's ability to do more of their processing offline and without much conscious planning. &nbsp;An obvious follow up would be in examining how novices utilize space and looking for discrepancies. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>What Does Using Space Well Look Like?</strong></p>\n<p>The paper walks the reader through a variety of examples of good utilization of space. &nbsp;Consider an expert cook going through the process of making a salad with many different ingredients, and ask how you would accomplish the same task differently:</p>\n<blockquote>\n<p>...one subject we videotaped, cut each vegetable into thin slices and laid them out in tidy rows. There was a row of tomatoes, of mushrooms, and of red peppers, each of different length...To understand why lining up the ingredients in well ordered, neatly separated rows is clever, requires understanding a fact about human psychophysics: estimation of length is easier and more reliable than estimation of area or volume. By using length to encode number she created a cue or signal in the world which she could accurately track. Laying out slices in lines allows more precise judgment of the property relative number remaining than clustering the slices into groups, or piling them up into heaps. Hence because of the way the human perceptual system works, lining up the slices creates an observable property that facilitates execution.</p>\n</blockquote>\n<p>Here, the cook used clustering and clever arrangement to make better use of her eyes and to reduce the load on her working memory, techniques I use myself in my day job. &nbsp;As of this writing (2013) I'm teaching English in Korea. &nbsp;I have a desk, a bunch of books, pencils, erasers, the works. &nbsp;All the folders are together, the books are separated by level, and all ungraded homework is kept in its own place. &nbsp;At the start of the work day I take out all the books and folders I'll need for that day and arrange them in the same order as my classes. When I get done with a class the book goes back on the day's pile but rotated 90 degrees so that I can tell it's been used. When I'm&nbsp;<em>totally&nbsp;</em>done with a book and I've entered homework scores and such, it goes back in the main book stack where all my books are. &nbsp;I can tell at a glance which classes I've had, which ones I'll have, what order I'm in, which classes are finished but unprocessed, and which ones are finished and processed. &nbsp;Cthulu only knows how much time I save and how many errors I prevent all by utilizing space well. &nbsp;</p>\n<p>These examples show how space can help you keep track of temporal order and make quick, accurate estimates, but it may not be clear how space can simplify choice. &nbsp;Recall that simplifying choice usually breaks down into either taking some choices away or making good choices more obvious. &nbsp;Taking choices away may sound like a bad thing, but each choice requires you to spend time evaluating options, and if you are juggling many different tasks the chance of making the wrong choice goes up. &nbsp;Similarly, looking for good options soaks up time, unless you can find a way to make yourself trip over them. &nbsp;</p>\n<p>An example of <em>removing</em>&nbsp;bad decisions is in factory workers placing a rag on hot pipes so they know not to touch them (Kirsh, \"The Intelligent Use of Space\", 1995). &nbsp;And here is how some carpenters structure their work space so that they can make <em>good</em>&nbsp;uses for&nbsp;odds and ends easier to see:</p>\n<p><em style=\"font-family: Arial, Helvetica, sans-serif; font-size: medium;\"></em></p>\n<blockquote>\n<p>In the course of making a piece of furniture one periodically tidies up. But not completely. Small pieces of wood are pushed into a corner or left about; tools, screw drivers and mallets are kept nearby. The reason most often reported is that 'they come in handy'. Scraps of wood can serve to protect surfaces from marring when clamped, hammered or put under pressure. They can elevate a piece when being lacquered to prevent sticking. The list goes on.</p>\n</blockquote>\n<p>By symbolically marking a dangerous object the engineers are shutting down the class of actions which involves touching the pipe. It is all too easy in the course of juggling multiple aspects of a task to forget something like this and injure yourself. &nbsp;The strategically placed and obvious visual marker means that the environment keeps track of the danger for you. &nbsp;Likewise poisonous substances have clear warning labels and are kept away from anything you might eat; both precautions count as good use of space.</p>\n<p>My copy of Steven Johnson's <a href=\"http://www.amazon.com/Where-Good-Ideas-Come-From/dp/1594485380\">Where Good Ideas Come From</a> is on another continent, but the carpenter example reminded me of his recommendation to keep messy notebooks. &nbsp;Doing so makes it more likely you'll see unusual and interesting connections between things you're thinking about. &nbsp;He goes so far as to use a tool called <a href=\"http://www.devontechnologies.com/products/devonthink/overview.html\">DevonThink</a> which speeds this process up for him.</p>\n<p>And while I'm at it, this also points to one advantage of having physical books over PDFs. &nbsp;My books take up space and are easier to see than their equivalent 1's and 0's on a hard drive, so I'm always reminded of what I have left to read. More than once I've gone on a useful tangent because the book title or cover image caught my attention, and more than one interesting conversation got started when a visitor was looking over my book collection. &nbsp;Scanning the shelves at a good university library is even better, kind of like 17th-century StumbleUpon, and English-language libraries are something I've sorely missed while I've been in Asia. &nbsp;</p>\n<p>All this usefulness derives from the spatial properties and arrangement of books, and I have no idea how it can be replicated with the Kindle. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Specific Recommendations</strong></p>\n<p>You can see from the list of examples I've provided that there are a billion ways of incorporating these insights into work, life, and recreation. &nbsp;By discussing the concept I hope to have drawn your attention to the ways in which space is a resource, and I suspect just doing this is enough to get a lot of people to see how they can improve their use of space. &nbsp;Here are some more ideas, in no particular order:</p>\n<p>-I put my alarm clock far enough away from my bed so that I have to actually get up to turn it off. &nbsp;This is so amazingly &nbsp; &nbsp;effective at ensuring I get up in the morning that I often hate my previous-night's self. &nbsp;Most of the time I can't go back to &nbsp;sleep even when I try. &nbsp;&nbsp;</p>\n<p>-There's <a href=\"http://www.hanselman.com/blog/TheSweetSpotOfMultipleMonitorProductivityThatMagicalThirdMonitor.aspx\">reason</a>&nbsp;to suspect&nbsp;that a few extra monitors or a <a href=\"http://lifehacker.com/5616859/is-the-multiple+monitor-productivity-boost-a-myth\">bigger display</a> will make your life easier &nbsp;[Thanks&nbsp;<a href=\"/user/Qiaochu_Yuan/overview/\">Qiaochu_Yuan</a>]<em>. </em></p>\n<p>-When doing research for an article like this one, open up all the tabs you'll need for the project in a separate window and close &nbsp;each tab as you're done with it. &nbsp;You'll be less distracted by something irrelevant and you won't have to remember what you did &nbsp;or didn't read.<em>&nbsp;</em><em>&nbsp;</em></p>\n<p>-Having a separate space to do something seems to greatly increase the chances I'll get it done. &nbsp;I tried not going to the gym &nbsp;for a while and just doing push ups in my house, managing to keep that up for all of a week or so. Recently, I switched gyms, &nbsp;and despite now having to take a bus all the way across town I make it to the gym 3-5 times a week, pretty much without fail. &nbsp;If your studying/hacking/meditation isn't going well, try going somewhere which exists only to give people a &nbsp;place to do that &nbsp;thing.</p>\n<p>-Put whatever you can't afford to forget when you leave the house right by the door.</p>\n<p>-If something is <em>really</em>&nbsp;distracting you, completely remove it from the environment temporarily. &nbsp;During one particularly strenuous &nbsp;finals in college I not only&nbsp;turned off the xbox, I completely unplugged it and put it in a drawer. <em>&nbsp;Problem. Solved</em>. &nbsp;</p>\n<p>-Alternatively, anything you're wanting to do more of should be out in the open. &nbsp;Put your guitar stand or chess board or &nbsp;whatever where you're going to see it frequently, and you'll engage with it more often. &nbsp;This doubles as a signal to other &nbsp;people, giving you an opportunity to manage their impression of you, learn more about them, and identify those with similar &nbsp;interests to yours.&nbsp;<em>&nbsp;</em></p>\n<p>-Make use of&nbsp;<a href=\"http://courses.csail.mit.edu/6.803/pdf/kirsh.pdf\">complementary strategies</a>&nbsp;(Kirsh, \"Complementary Strategies\", 1995). &nbsp;If you're having trouble comprehending &nbsp; &nbsp;something, make a diagram, or write a list. &nbsp;The linked paper describes a simple pilot study which involved two groups tasked &nbsp;with counting coins, one which could use their hands and one which could not. &nbsp;The 'no hands' group was more likely to make &nbsp;errors and to take longer to complete the task. &nbsp;Granted, this was a pilot study with sample size = 5, and the difference &nbsp;wasn't&nbsp;<em>that&nbsp;</em>stark. &nbsp;But it's worth thinking about next time you're stuck on a problem. &nbsp; &nbsp;</p>\n<p>-Complementary strategies can also include things you do with your body, which after all is just space you wear with you &nbsp;everywhere. &nbsp;Talk out loud to yourself if you're alone, give a mock presentation in which you summarize a position you're trying &nbsp;to understand, keep track of arguments and counterarguments with your fingers. &nbsp;I've always found the combination of &nbsp;explaining something out loud to an imaginary person while walking or pacing to be especially potent. &nbsp;Some of my best ideas &nbsp;come to me while I'm hiking. &nbsp; &nbsp;</p>\n<p>-Try some of these&nbsp;<a href=\"/lw/4x7/simple_embodied_cognition_hacks/\">embodied cognition hacks</a>.</p>\n<p>&nbsp;</p>\n<p><strong>Summary and Conclusion</strong></p>\n<p>Space is a resource which, like all others, can be used effectively or not. &nbsp;When used effectively, it acts to simplify choices, simplify perception, and simplify internal computation. &nbsp;I've provided many examples of good space usage from all sorts of real-life domains in the hopes that you can apply some of these insights to live and work more effectively. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Further Reading</strong></p>\n<p>[In the original post these references contained no links. &nbsp;Sincere thanks to user <a href=\"/user/Pablo_Stafforini/overview/\">Pablo_Stafforini</a> for tracking them down]</p>\n<p><strong></strong><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1995)&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://www.stafforini.com/txt/Kirsh%20-%20The%20intelligent%20use%20of%20space.pdf\">The Intelligent Use of Space</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://www.stafforini.com/txt/Kirsh%20-%20The%20intelligent%20use%20of%20space.pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1999)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.258.9783&amp;rep=rep1&amp;type=pdf\">Distributed Cognition, Coordination and Environment Design</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.258.9783&amp;rep=rep1&amp;type=pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1998)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://adrenaline.ucsd.edu/Kirsh/Articles/CoopBuildings/adaptable_rooms.pdf\">Adaptive Rooms, Virtual Collaboration, and Cognitive Workflow</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://adrenaline.ucsd.edu/Kirsh/Articles/CoopBuildings/adaptable_rooms.pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1996)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://146.230.128.54/undphil/collier/212/KirshAdaptingEnvrinoment.pdf\">Adapting the Environment Instead of Oneself</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://146.230.128.54/undphil/collier/212/KirshAdaptingEnvrinoment.pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1995)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://courses.csail.mit.edu/6.803/pdf/kirsh.pdf\">Complementary Strategies: Why we use our hands when we think</a></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "Tg9aFPFCPBHxGABRr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uWDGzJME8FmnzrMgm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 33, "extendedScore": null, "score": 6.9e-05, "legacy": true, "legacyId": "22682", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>[NOTE: <em>This post has undergone substantial revisions following feedback in the comments section. &nbsp;The basic complaint was that it was too airy and light on concrete examples and recommendations. &nbsp;So I've <a href=\"/lw/i9/the_importance_of_saying_oops/\">said oops</a>, applied the <a href=\"/lw/ic/the_virtue_of_narrowness/\">virtue of narrowness</a>, <a href=\"/lw/bc3/sotw_be_specific/\">gotten specific</a>, and hopefully made this what it should've been the first time.</em>]<em>&nbsp;&nbsp;</em></p>\n<p>&nbsp;</p>\n<p>Take a moment and picture a master surgeon about to begin an operation. &nbsp;Visualize the room (white, bright overhead lights), his clothes (green scrubs, white mask and gloves), the patient, under anesthesia and awaiting the first incision. There are several other people, maybe three or four, strategically placed and preparing for the task ahead. &nbsp;Visualize his tools - it's okay if you don't actually know what tools a surgeon uses, but imagine how they might be arranged. &nbsp;Do you picture them in a giant heap which the surgeon must dig through every time he wants something, or would they be arranged neatly (possibly in the order they'll be used) and where they can be identified instantly by sight? &nbsp;Visualize their working area. &nbsp;Would it be conducive to have random machines and equipment all over the place, or would every single item within arms reach be put there on purpose because it is relevant, with nothing left over to distract the team from their job for even a moment? &nbsp; &nbsp;</p>\n<p>Space is important. &nbsp;You are a spatially extended being interacting with spatially extended objects which can and must be arranged spatially. &nbsp;In the same way it may not have occurred to you that there is a&nbsp;<a href=\"/lw/eyt/how_to_have_things_correctly/\">correct way to have things</a>, it may not have occurred to you that space is something you can use poorly or well. &nbsp;The stakes aren't always as high as they are for a surgeon, and I'm sure there are plenty of productive people who don't do a single one of the things I'm going to talk about. &nbsp;But there are also skinny people who eat lots of cheesecake, and that doesn't mean cheesecake is good for you. &nbsp;Improving how you use the scarce resource of space can reduce task completion time, help in&nbsp;<a href=\"http://rulerstothesky.wordpress.com/\">getting organized</a>, make you less error-prone and forgetful, and free up some internal computational resources, among other things. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"What_Does_Using_Space_Well_Mean_\">What Does Using Space Well Mean?</strong></p>\n<p>It means <em>consciously manipulating the arrangement, visibility, prominence, etc. of objects in your environment to change how they affect cognition</em> (yours or other people's). &nbsp;<a href=\"http://adrenaline.ucsd.edu/kirsh/Articles/Space/AIJ1.html\">The&nbsp;Intelligent Use of Space</a>&nbsp;(Kirsh, \"The Intelligent Use of Space\", 1995) is a great place to start if you're skeptical that there is anything here worth considering. &nbsp;It's my primary source for this post because it is thorough but not overly technical, contains lots of clear examples, and many of the related papers I read were about deeper theoretical issues. &nbsp;</p>\n<p>The abstract of the paper reads:</p>\n<blockquote>\n<p>How we manage the spatial arrangement of items around us is not an afterthought: it is an integral part of the way we think, plan, and behave. The proposed classification has three main categories: spatial arrangements that simplify choice; spatial arrangements that simplify perception; and spatial dynamics that simplify internal computation. The data for such a classification is drawn from videos of cooking, assembly and packing, everyday observations in supermarkets, workshops and playrooms, and experimental studies of subjects playing Tetris, the computer game. This study, therefore, focuses on interactive processes in the medium and short term: on how agents set up their workplace for particular tasks, and how they continuously manage that workplace.</p>\n</blockquote>\n<p>The 'three main categories' of simplifying choice, perception, and internal computation can be further subdivided:</p>\n<p>&nbsp; <span style=\"text-decoration: underline;\">simplifying choice</span></p>\n<p>&nbsp; &nbsp; &nbsp; reducing or emphasizing options.</p>\n<p>&nbsp; &nbsp; &nbsp; creating the potential for useful new choices.</p>\n<p>&nbsp; <span style=\"text-decoration: underline;\">simplifying perception</span></p>\n<p>&nbsp; &nbsp; &nbsp; clustering like objects.</p>\n<p>&nbsp; &nbsp; &nbsp; marking an object.</p>\n<p>&nbsp; &nbsp; &nbsp; enhancing perceptual ability.</p>\n<p>&nbsp; <span style=\"text-decoration: underline;\">simplfying internal computation</span></p>\n<p>&nbsp; &nbsp; &nbsp;doing more outside of your head.</p>\n<p>These sub-categories are easier to picture and thus more useful when trying to apply the concept of using space correctly, and I've provided more illustrations below. It's worth pointing out that (Kirsh, \"The Intelligent Use of Space\", 1995) only considered the behavior of experts. &nbsp;Perhaps effective space management partially explains expert's ability to do more of their processing offline and without much conscious planning. &nbsp;An obvious follow up would be in examining how novices utilize space and looking for discrepancies. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"What_Does_Using_Space_Well_Look_Like_\">What Does Using Space Well Look Like?</strong></p>\n<p>The paper walks the reader through a variety of examples of good utilization of space. &nbsp;Consider an expert cook going through the process of making a salad with many different ingredients, and ask how you would accomplish the same task differently:</p>\n<blockquote>\n<p>...one subject we videotaped, cut each vegetable into thin slices and laid them out in tidy rows. There was a row of tomatoes, of mushrooms, and of red peppers, each of different length...To understand why lining up the ingredients in well ordered, neatly separated rows is clever, requires understanding a fact about human psychophysics: estimation of length is easier and more reliable than estimation of area or volume. By using length to encode number she created a cue or signal in the world which she could accurately track. Laying out slices in lines allows more precise judgment of the property relative number remaining than clustering the slices into groups, or piling them up into heaps. Hence because of the way the human perceptual system works, lining up the slices creates an observable property that facilitates execution.</p>\n</blockquote>\n<p>Here, the cook used clustering and clever arrangement to make better use of her eyes and to reduce the load on her working memory, techniques I use myself in my day job. &nbsp;As of this writing (2013) I'm teaching English in Korea. &nbsp;I have a desk, a bunch of books, pencils, erasers, the works. &nbsp;All the folders are together, the books are separated by level, and all ungraded homework is kept in its own place. &nbsp;At the start of the work day I take out all the books and folders I'll need for that day and arrange them in the same order as my classes. When I get done with a class the book goes back on the day's pile but rotated 90 degrees so that I can tell it's been used. When I'm&nbsp;<em>totally&nbsp;</em>done with a book and I've entered homework scores and such, it goes back in the main book stack where all my books are. &nbsp;I can tell at a glance which classes I've had, which ones I'll have, what order I'm in, which classes are finished but unprocessed, and which ones are finished and processed. &nbsp;Cthulu only knows how much time I save and how many errors I prevent all by utilizing space well. &nbsp;</p>\n<p>These examples show how space can help you keep track of temporal order and make quick, accurate estimates, but it may not be clear how space can simplify choice. &nbsp;Recall that simplifying choice usually breaks down into either taking some choices away or making good choices more obvious. &nbsp;Taking choices away may sound like a bad thing, but each choice requires you to spend time evaluating options, and if you are juggling many different tasks the chance of making the wrong choice goes up. &nbsp;Similarly, looking for good options soaks up time, unless you can find a way to make yourself trip over them. &nbsp;</p>\n<p>An example of <em>removing</em>&nbsp;bad decisions is in factory workers placing a rag on hot pipes so they know not to touch them (Kirsh, \"The Intelligent Use of Space\", 1995). &nbsp;And here is how some carpenters structure their work space so that they can make <em>good</em>&nbsp;uses for&nbsp;odds and ends easier to see:</p>\n<p><em style=\"font-family: Arial, Helvetica, sans-serif; font-size: medium;\"></em></p>\n<blockquote>\n<p>In the course of making a piece of furniture one periodically tidies up. But not completely. Small pieces of wood are pushed into a corner or left about; tools, screw drivers and mallets are kept nearby. The reason most often reported is that 'they come in handy'. Scraps of wood can serve to protect surfaces from marring when clamped, hammered or put under pressure. They can elevate a piece when being lacquered to prevent sticking. The list goes on.</p>\n</blockquote>\n<p>By symbolically marking a dangerous object the engineers are shutting down the class of actions which involves touching the pipe. It is all too easy in the course of juggling multiple aspects of a task to forget something like this and injure yourself. &nbsp;The strategically placed and obvious visual marker means that the environment keeps track of the danger for you. &nbsp;Likewise poisonous substances have clear warning labels and are kept away from anything you might eat; both precautions count as good use of space.</p>\n<p>My copy of Steven Johnson's <a href=\"http://www.amazon.com/Where-Good-Ideas-Come-From/dp/1594485380\">Where Good Ideas Come From</a> is on another continent, but the carpenter example reminded me of his recommendation to keep messy notebooks. &nbsp;Doing so makes it more likely you'll see unusual and interesting connections between things you're thinking about. &nbsp;He goes so far as to use a tool called <a href=\"http://www.devontechnologies.com/products/devonthink/overview.html\">DevonThink</a> which speeds this process up for him.</p>\n<p>And while I'm at it, this also points to one advantage of having physical books over PDFs. &nbsp;My books take up space and are easier to see than their equivalent 1's and 0's on a hard drive, so I'm always reminded of what I have left to read. More than once I've gone on a useful tangent because the book title or cover image caught my attention, and more than one interesting conversation got started when a visitor was looking over my book collection. &nbsp;Scanning the shelves at a good university library is even better, kind of like 17th-century StumbleUpon, and English-language libraries are something I've sorely missed while I've been in Asia. &nbsp;</p>\n<p>All this usefulness derives from the spatial properties and arrangement of books, and I have no idea how it can be replicated with the Kindle. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"Specific_Recommendations\">Specific Recommendations</strong></p>\n<p>You can see from the list of examples I've provided that there are a billion ways of incorporating these insights into work, life, and recreation. &nbsp;By discussing the concept I hope to have drawn your attention to the ways in which space is a resource, and I suspect just doing this is enough to get a lot of people to see how they can improve their use of space. &nbsp;Here are some more ideas, in no particular order:</p>\n<p>-I put my alarm clock far enough away from my bed so that I have to actually get up to turn it off. &nbsp;This is so amazingly &nbsp; &nbsp;effective at ensuring I get up in the morning that I often hate my previous-night's self. &nbsp;Most of the time I can't go back to &nbsp;sleep even when I try. &nbsp;&nbsp;</p>\n<p>-There's <a href=\"http://www.hanselman.com/blog/TheSweetSpotOfMultipleMonitorProductivityThatMagicalThirdMonitor.aspx\">reason</a>&nbsp;to suspect&nbsp;that a few extra monitors or a <a href=\"http://lifehacker.com/5616859/is-the-multiple+monitor-productivity-boost-a-myth\">bigger display</a> will make your life easier &nbsp;[Thanks&nbsp;<a href=\"/user/Qiaochu_Yuan/overview/\">Qiaochu_Yuan</a>]<em>. </em></p>\n<p>-When doing research for an article like this one, open up all the tabs you'll need for the project in a separate window and close &nbsp;each tab as you're done with it. &nbsp;You'll be less distracted by something irrelevant and you won't have to remember what you did &nbsp;or didn't read.<em>&nbsp;</em><em>&nbsp;</em></p>\n<p>-Having a separate space to do something seems to greatly increase the chances I'll get it done. &nbsp;I tried not going to the gym &nbsp;for a while and just doing push ups in my house, managing to keep that up for all of a week or so. Recently, I switched gyms, &nbsp;and despite now having to take a bus all the way across town I make it to the gym 3-5 times a week, pretty much without fail. &nbsp;If your studying/hacking/meditation isn't going well, try going somewhere which exists only to give people a &nbsp;place to do that &nbsp;thing.</p>\n<p>-Put whatever you can't afford to forget when you leave the house right by the door.</p>\n<p>-If something is <em>really</em>&nbsp;distracting you, completely remove it from the environment temporarily. &nbsp;During one particularly strenuous &nbsp;finals in college I not only&nbsp;turned off the xbox, I completely unplugged it and put it in a drawer. <em>&nbsp;Problem. Solved</em>. &nbsp;</p>\n<p>-Alternatively, anything you're wanting to do more of should be out in the open. &nbsp;Put your guitar stand or chess board or &nbsp;whatever where you're going to see it frequently, and you'll engage with it more often. &nbsp;This doubles as a signal to other &nbsp;people, giving you an opportunity to manage their impression of you, learn more about them, and identify those with similar &nbsp;interests to yours.&nbsp;<em>&nbsp;</em></p>\n<p>-Make use of&nbsp;<a href=\"http://courses.csail.mit.edu/6.803/pdf/kirsh.pdf\">complementary strategies</a>&nbsp;(Kirsh, \"Complementary Strategies\", 1995). &nbsp;If you're having trouble comprehending &nbsp; &nbsp;something, make a diagram, or write a list. &nbsp;The linked paper describes a simple pilot study which involved two groups tasked &nbsp;with counting coins, one which could use their hands and one which could not. &nbsp;The 'no hands' group was more likely to make &nbsp;errors and to take longer to complete the task. &nbsp;Granted, this was a pilot study with sample size = 5, and the difference &nbsp;wasn't&nbsp;<em>that&nbsp;</em>stark. &nbsp;But it's worth thinking about next time you're stuck on a problem. &nbsp; &nbsp;</p>\n<p>-Complementary strategies can also include things you do with your body, which after all is just space you wear with you &nbsp;everywhere. &nbsp;Talk out loud to yourself if you're alone, give a mock presentation in which you summarize a position you're trying &nbsp;to understand, keep track of arguments and counterarguments with your fingers. &nbsp;I've always found the combination of &nbsp;explaining something out loud to an imaginary person while walking or pacing to be especially potent. &nbsp;Some of my best ideas &nbsp;come to me while I'm hiking. &nbsp; &nbsp;</p>\n<p>-Try some of these&nbsp;<a href=\"/lw/4x7/simple_embodied_cognition_hacks/\">embodied cognition hacks</a>.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Summary_and_Conclusion\">Summary and Conclusion</strong></p>\n<p>Space is a resource which, like all others, can be used effectively or not. &nbsp;When used effectively, it acts to simplify choices, simplify perception, and simplify internal computation. &nbsp;I've provided many examples of good space usage from all sorts of real-life domains in the hopes that you can apply some of these insights to live and work more effectively. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"Further_Reading\">Further Reading</strong></p>\n<p>[In the original post these references contained no links. &nbsp;Sincere thanks to user <a href=\"/user/Pablo_Stafforini/overview/\">Pablo_Stafforini</a> for tracking them down]</p>\n<p><strong></strong><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1995)&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://www.stafforini.com/txt/Kirsh%20-%20The%20intelligent%20use%20of%20space.pdf\">The Intelligent Use of Space</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://www.stafforini.com/txt/Kirsh%20-%20The%20intelligent%20use%20of%20space.pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1999)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.258.9783&amp;rep=rep1&amp;type=pdf\">Distributed Cognition, Coordination and Environment Design</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.258.9783&amp;rep=rep1&amp;type=pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1998)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://adrenaline.ucsd.edu/Kirsh/Articles/CoopBuildings/adaptable_rooms.pdf\">Adaptive Rooms, Virtual Collaboration, and Cognitive Workflow</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://adrenaline.ucsd.edu/Kirsh/Articles/CoopBuildings/adaptable_rooms.pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1996)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://146.230.128.54/undphil/collier/212/KirshAdaptingEnvrinoment.pdf\">Adapting the Environment Instead of Oneself</a></p>\n<p><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://146.230.128.54/undphil/collier/212/KirshAdaptingEnvrinoment.pdf\"></a><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">Kirsh, D. (1995)</span><span style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;</span><a style=\"background-color: #f7f7f8; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify; color: #8a8a8b;\" rel=\"nofollow\" href=\"http://courses.csail.mit.edu/6.803/pdf/kirsh.pdf\">Complementary Strategies: Why we use our hands when we think</a></p>\n<p>&nbsp;</p>", "sections": [{"title": "What Does Using Space Well Mean?", "anchor": "What_Does_Using_Space_Well_Mean_", "level": 1}, {"title": "What Does Using Space Well Look Like?", "anchor": "What_Does_Using_Space_Well_Look_Like_", "level": 1}, {"title": "Specific Recommendations", "anchor": "Specific_Recommendations", "level": 1}, {"title": "Summary and Conclusion", "anchor": "Summary_and_Conclusion", "level": 1}, {"title": "Further Reading", "anchor": "Further_Reading", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "32 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["wCqfCLs8z5Qw4GbKS", "yDfxTj9TKYsYiWH5o", "NgtYDP3ZtLJaM248W", "KT8Mf3ey6uwQAkWek", "W8ibiHCtywhCnBeMk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T03:48:30.273Z", "modifiedAt": null, "url": null, "title": "Ancestor Simulations for Fun and Profit", "slug": "ancestor-simulations-for-fun-and-profit", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:30.330Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DataPacRat", "createdAt": "2009-05-21T11:00:18.044Z", "isAdmin": false, "displayName": "DataPacRat"}, "userId": "ca4pgqJFEDkdbAzyo", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sYKwaA3Gj5g66GnTt/ancestor-simulations-for-fun-and-profit", "pageUrlRelative": "/posts/sYKwaA3Gj5g66GnTt/ancestor-simulations-for-fun-and-profit", "linkUrl": "https://www.lesswrong.com/posts/sYKwaA3Gj5g66GnTt/ancestor-simulations-for-fun-and-profit", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ancestor%20Simulations%20for%20Fun%20and%20Profit&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAncestor%20Simulations%20for%20Fun%20and%20Profit%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsYKwaA3Gj5g66GnTt%2Fancestor-simulations-for-fun-and-profit%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ancestor%20Simulations%20for%20Fun%20and%20Profit%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsYKwaA3Gj5g66GnTt%2Fancestor-simulations-for-fun-and-profit", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsYKwaA3Gj5g66GnTt%2Fancestor-simulations-for-fun-and-profit", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 366, "htmlBody": "<p>A passing thought: \"... it's beneath my dignity as a human being to be scared of anything that isn't smarter than I am\" (-- <a href=\"http://hpmor.com/chapter/86\">HJPEV</a>) likely applies equally well to superintelligences. Similarly, \"It really made you appreciate what millions of years of hominids trying to outwit <em>each other</em> - an evolutionary arms race without limit - had led to in the way of increased mental capacity.\" (-- <a href=\"http://hpmor.com/chapter/24\">ditto</a>) suggests that one of the stronger spurs for superintelligences becoming as super-intelligent as possible could very well be the competition as they try to outwit each other.</p>\n<p>Thus, instead of ancestor simulations being implemented simply out of historical curiosity, a larger portion of such simulations may arise as one super-intelligence tries to figure out another by working out how its competitor arose in the first place. This casts a somewhat different light on how such simulations would be built and treated, then the usual suggestion of university researchers or over-powered child-gods playing Civilization-3^^^3.</p>\n<p>&nbsp;</p>\n<p>* Assume for a moment that you're in the original, real (to whatever degree that word has meaning) universe, and you're considering the vast numbers of copies of yourself that are going to be instantiated over future eons. Is there anything that the original you can do, think, or be which could improve your future copies' lives? Eg, is there some pre-commitment you could make, privately or publicly?</p>\n<p>* Assume for a moment that you're in one of the simulated universes. Is there anything you can do that would make your subjective experience any different from what your original experienced?</p>\n<p>* Assume for a moment that you're a super-intelligence, or at least a proto-super-intelligence, considering running something that includes an ancestor simulation. Is there anything which the original people, or the simulated versions, could do or have done, which would change your mind about how to treat the simulated people?</p>\n<p>* Assume for a moment that you're in one of the simulated universes... and due to battle damage to a super-intelligence, you accidentally are given root access and control over your whole universe. Taking into account <a href=\"/lw/xt/interpersonal_entanglement/\">Reedspacer's Lower Bound</a>, and assuming an upper bound of not being able to noticeably affect the super-battle, what would you do with your universe?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sYKwaA3Gj5g66GnTt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 0, "extendedScore": null, "score": 1.243879474906482e-06, "legacy": true, "legacyId": "23075", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Py3uGnncqXuEfPtQp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T07:41:07.401Z", "modifiedAt": null, "url": null, "title": "Part of a THINK Meetup Group? We Want to Hear From You!", "slug": "part-of-a-think-meetup-group-we-want-to-hear-from-you", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.636Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OnTheOtherHandle", "createdAt": "2010-11-29T01:36:16.484Z", "isAdmin": false, "displayName": "OnTheOtherHandle"}, "userId": "QFvtvhSzkcjYxQZ3N", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JJkDJXWWyyX23w8JS/part-of-a-think-meetup-group-we-want-to-hear-from-you", "pageUrlRelative": "/posts/JJkDJXWWyyX23w8JS/part-of-a-think-meetup-group-we-want-to-hear-from-you", "linkUrl": "https://www.lesswrong.com/posts/JJkDJXWWyyX23w8JS/part-of-a-think-meetup-group-we-want-to-hear-from-you", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Part%20of%20a%20THINK%20Meetup%20Group%3F%20We%20Want%20to%20Hear%20From%20You!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APart%20of%20a%20THINK%20Meetup%20Group%3F%20We%20Want%20to%20Hear%20From%20You!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJJkDJXWWyyX23w8JS%2Fpart-of-a-think-meetup-group-we-want-to-hear-from-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Part%20of%20a%20THINK%20Meetup%20Group%3F%20We%20Want%20to%20Hear%20From%20You!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJJkDJXWWyyX23w8JS%2Fpart-of-a-think-meetup-group-we-want-to-hear-from-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJJkDJXWWyyX23w8JS%2Fpart-of-a-think-meetup-group-we-want-to-hear-from-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 300, "htmlBody": "<p>Hello everybody, I've recently started as a volunteer for <a href=\"http://www.thehighimpactnetwork.org/\">The High Impact NetworK</a>, an effective altruism group with local chapters mostly in the US and UK. We're aiming to get more people, especially students, interested in effective altruism and enlarging the netowrk in a big way. Edit: Thank you to BenLowell for suggesting that I include a description!</p>\n<p>One of the first things I'm trying to do is make THINK more personal and accessible. The <a href=\"http://www.thehighimpactnetwork.org/modules\" target=\"_blank\">modules</a> provide a pretty good outline of the topics discussed, but they're highly structured and don't capture the <em>feel </em>of a live meeting very well. We'd like to advertise to potential members that there's a lot of value in attending a physical meetup beyond just learning the material already presented in the modules. We'd like it to feel more like a club and less like a classroom.</p>\n<p>So if any of you are members of a THINK meetup group, I would love to hear your stories or see pictures and videos of your meetup groups in action. I'm hoping to convey the discussions and debates that go on after the more instructive module part is over. You don't have to reveal your name or face, but if you don't mind having your picture on the website, I would really appreciate seeing a name and face. If you choose to submit an anecdote, try focusing on something surprising or interesting that happened at a meetup, an experience you were unlikely to get elsewhere.</p>\n<p>Please send your pictures/videos/anecdotes to ajeyac@berkeley.edu, and I'll forward them to THINK leader Mark Lee. I'll do my best to try to set up a section on the THINK website and put this up, but it may take a while, and if we get more submissions than we anticipated, they may not all show up.</p>\n<p>Thank you!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JJkDJXWWyyX23w8JS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 4, "extendedScore": null, "score": 1.2440592759094117e-06, "legacy": true, "legacyId": "23069", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T10:51:44.494Z", "modifiedAt": null, "url": null, "title": "Meetup : [Moscow] The Goals We Set", "slug": "meetup-moscow-the-goals-we-set", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qEoqQxert8jfoM26N/meetup-moscow-the-goals-we-set", "pageUrlRelative": "/posts/qEoqQxert8jfoM26N/meetup-moscow-the-goals-we-set", "linkUrl": "https://www.lesswrong.com/posts/qEoqQxert8jfoM26N/meetup-moscow-the-goals-we-set", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BMoscow%5D%20The%20Goals%20We%20Set&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BMoscow%5D%20The%20Goals%20We%20Set%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqEoqQxert8jfoM26N%2Fmeetup-moscow-the-goals-we-set%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BMoscow%5D%20The%20Goals%20We%20Set%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqEoqQxert8jfoM26N%2Fmeetup-moscow-the-goals-we-set", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqEoqQxert8jfoM26N%2Fmeetup-moscow-the-goals-we-set", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 184, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o3'>[Moscow] The Goals We Set</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 July 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 16:00 with \u201cLW\u201d sign inside the hall. And we will also check the entrance at 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Discussing the results of \u201cThe Trigger\u201d exercise. The description in Russian <a href=\"http://lesswrong.ru/forum/index.php/topic,145.0.html?utm_source=lesswrong.com&amp;utm_medium=meetup_notice&amp;utm_term=link_for_trigger_exercise&amp;utm_content=meetup_20130707&amp;utm_campaign=moscow_meetups\">is here</a>.</p></li>\n<li><p>Seminar on setting goals in our life.</p></li>\n<li><p>Game session: the Liar's dice or the Resistance.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html?utm_source=lesswrong.com&amp;utm_medium=meetup_notice&amp;utm_term=link_for_reports&amp;utm_content=meetup_20130707&amp;utm_campaign=moscow_meetups\">here, in Russian</a>, now with more photos!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o3'>[Moscow] The Goals We Set</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qEoqQxert8jfoM26N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2442066471965247e-06, "legacy": true, "legacyId": "23082", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Moscow__The_Goals_We_Set\">Discussion article for the meetup : <a href=\"/meetups/o3\">[Moscow] The Goals We Set</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 July 2013 04:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, ulitsa L'va Tolstogo 16</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Please use the following guide to get to the meetup: <a href=\"http://company.yandex.ru/contacts/redrose/\" rel=\"nofollow\">link</a>. You need the second revolving door with the sign \u201cYandex Money\u201d in Russian. We will meet you at 16:00 with \u201cLW\u201d sign inside the hall. And we will also check the entrance at 16:10, so please do not be late.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Discussing the results of \u201cThe Trigger\u201d exercise. The description in Russian <a href=\"http://lesswrong.ru/forum/index.php/topic,145.0.html?utm_source=lesswrong.com&amp;utm_medium=meetup_notice&amp;utm_term=link_for_trigger_exercise&amp;utm_content=meetup_20130707&amp;utm_campaign=moscow_meetups\">is here</a>.</p></li>\n<li><p>Seminar on setting goals in our life.</p></li>\n<li><p>Game session: the Liar's dice or the Resistance.</p></li>\n</ul>\n\n<p>If you are going for the first time, you can fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to share your contact information. You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html?utm_source=lesswrong.com&amp;utm_medium=meetup_notice&amp;utm_term=link_for_reports&amp;utm_content=meetup_20130707&amp;utm_campaign=moscow_meetups\">here, in Russian</a>, now with more photos!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Moscow__The_Goals_We_Set1\">Discussion article for the meetup : <a href=\"/meetups/o3\">[Moscow] The Goals We Set</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Moscow] The Goals We Set", "anchor": "Discussion_article_for_the_meetup____Moscow__The_Goals_We_Set", "level": 1}, {"title": "Discussion article for the meetup : [Moscow] The Goals We Set", "anchor": "Discussion_article_for_the_meetup____Moscow__The_Goals_We_Set1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T13:56:42.728Z", "modifiedAt": null, "url": null, "title": "Meetup : LW Munich Meetup in July", "slug": "meetup-lw-munich-meetup-in-july", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:36.128Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Teobaldo", "createdAt": "2012-10-28T17:25:26.852Z", "isAdmin": false, "displayName": "Teobaldo"}, "userId": "BhijBsy7WLfpnsZGJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WXwsCQpXWPsyHzJn4/meetup-lw-munich-meetup-in-july", "pageUrlRelative": "/posts/WXwsCQpXWPsyHzJn4/meetup-lw-munich-meetup-in-july", "linkUrl": "https://www.lesswrong.com/posts/WXwsCQpXWPsyHzJn4/meetup-lw-munich-meetup-in-july", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20LW%20Munich%20Meetup%20in%20July&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20LW%20Munich%20Meetup%20in%20July%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXwsCQpXWPsyHzJn4%2Fmeetup-lw-munich-meetup-in-july%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20LW%20Munich%20Meetup%20in%20July%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXwsCQpXWPsyHzJn4%2Fmeetup-lw-munich-meetup-in-july", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWXwsCQpXWPsyHzJn4%2Fmeetup-lw-munich-meetup-in-july", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 111, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o4'>LW Munich Meetup in July</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">06 July 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Caf\u00e9 at Gasteig, Rosenheimer Stra\u00dfe 5, 81667 M\u00fcnchen</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Munich meetup will take place on July 6th. We will continue discussing the epistemology sequence as well as talk about productivity and emotional intelligence. You are highly welcome to come and say hi, no matter how long you\u2019ve been reading LessWrong. If you plan to attend, please (optionally) post a comment saying what topics you\u2019d like to discuss. Also if you on Facebook, think about joining the group (see comments to the previous meetup).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o4'>LW Munich Meetup in July</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WXwsCQpXWPsyHzJn4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2443496817227487e-06, "legacy": true, "legacyId": "23083", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___LW_Munich_Meetup_in_July\">Discussion article for the meetup : <a href=\"/meetups/o4\">LW Munich Meetup in July</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">06 July 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Caf\u00e9 at Gasteig, Rosenheimer Stra\u00dfe 5, 81667 M\u00fcnchen</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>The next Munich meetup will take place on July 6th. We will continue discussing the epistemology sequence as well as talk about productivity and emotional intelligence. You are highly welcome to come and say hi, no matter how long you\u2019ve been reading LessWrong. If you plan to attend, please (optionally) post a comment saying what topics you\u2019d like to discuss. Also if you on Facebook, think about joining the group (see comments to the previous meetup).</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___LW_Munich_Meetup_in_July1\">Discussion article for the meetup : <a href=\"/meetups/o4\">LW Munich Meetup in July</a></h2>", "sections": [{"title": "Discussion article for the meetup : LW Munich Meetup in July", "anchor": "Discussion_article_for_the_meetup___LW_Munich_Meetup_in_July", "level": 1}, {"title": "Discussion article for the meetup : LW Munich Meetup in July", "anchor": "Discussion_article_for_the_meetup___LW_Munich_Meetup_in_July1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T15:37:00.001Z", "modifiedAt": null, "url": null, "title": "The Division of Labor", "slug": "the-division-of-labor", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.648Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "9hQryffdwLDyNbnkh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WavpbXrbh6hsHhGzs/the-division-of-labor", "pageUrlRelative": "/posts/WavpbXrbh6hsHhGzs/the-division-of-labor", "linkUrl": "https://www.lesswrong.com/posts/WavpbXrbh6hsHhGzs/the-division-of-labor", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Division%20of%20Labor&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Division%20of%20Labor%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWavpbXrbh6hsHhGzs%2Fthe-division-of-labor%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Division%20of%20Labor%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWavpbXrbh6hsHhGzs%2Fthe-division-of-labor", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWavpbXrbh6hsHhGzs%2Fthe-division-of-labor", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1038, "htmlBody": "<p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">This is the mystery we&rsquo;re trying to solve : The United States is a big country. It has over 300 million hungry people who need food every day. How do they get fed?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">The way we handled this problem back in the bad old days was, everyone would grow their own food. There weren&rsquo;t many people back then, maybe not 300 million in the entire world.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">The way we handle this problem today is, nobody makes their own food. Nobody makes their own <em>anything. </em>And as a result, there&rsquo;s a lot more of everything.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">In the bad old days, people were self-sufficient. Not literally, of course, but pretty near to it. People grew their own food, built their own houses, made their own clothes. And they were poor. Nowadays nobody makes their own anything, not even to sell. And people are rich.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Not too long ago someone tried to make a commercial-quality toaster from scratch. He failed. He couldn&rsquo;t make the toaster--literally, it was completely impossible for him, a single human being, to make something as mundane as a toaster without any help. He had to cheat, and the toaster was still a terrible mess.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">It&rsquo;s not hard to get a toaster <em>if you&rsquo;re willing to enlist human help</em>. You go to the store. You buy a toaster. It&rsquo;s pretty simple. They&rsquo;re not special-made artisan products that only come in on special occasions and people rush and trample each other to acquire them. Nobody ever worries about running out of toasters. Nobody ever worries that their might not be toasters in the stores, or that the group that makes toaster might have some kind of problem and the toaster supply will disappear.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">But nobody can make a toaster. So how do toasters get made?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">How does anything get made?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Things get made <em>because</em> people don&rsquo;t make them on their own. Things get made because every member of the economy cooperates to make neat things like toasters together. <em>People</em> don&rsquo;t make things; the <em>economy</em> makes things. The things people work on in the economy are by themselves totally worthless. If people were not participating in the economy but were instead self-sufficient, and they worked on the things they work on today, they would appear utterly insane (and would soon starve). But it works, because everyone contributes a little part of the economy, and the <em>whole thing</em> churns out an amazing output that is the source of our historically sky-high standard of living. It&rsquo;s called the division of labor, and the farther we progress along the division of labor, the richer we get.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Now this all raises is a very interesting question, which is how any of this is possible. The United States has 300--wait, no, it&rsquo;s a global economy these days. If there&rsquo;s 6 billion people in the world, half are children, another 1 billion are barely capable of participating if at all in the global economy for whatever reason, then that&rsquo;s 2 billion people who make up the global economy. They&rsquo;re separated by distance, language, culture, history, even hatred and bigotry. But something gets them all to cooperate.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">And as for what these 2 billion people are producing, well, I haven&rsquo;t the faintest idea of how to go about estimating how many different of goods and services are sold in the world, but it&rsquo;s a lot. Call it a million--a million different things are sold in the world. That might be an overestimate, but I also wouldn&rsquo;t be shocked to learn it&rsquo;s an underestimate.&nbsp;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">So here&rsquo;s the problem: how on earth are these 2 billion people making these one million different goods and services possibly coordinating? Doesn&rsquo;t that sound of impossible? I mean, it&rsquo;s hard enough to get a group of a dozen people who like each other and know each other well to coordinate effectively. Now 2 billion people, a lot of whom hate each other, are supposed to coordinate on an incomparably complicated task? Yeah, right.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">But everyday, there&rsquo;s food in the supermarket. The stores are stocked, everywhere, with dozens or hundreds of different items, at affordable prices. And if one store doesn&rsquo;t have what you&rsquo;re looking for, you just go across the street to their competitor to get what you want.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">So it happens. They coordinate. At the very least, those 2 billion are fed every day.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">It certainly isn&rsquo;t because people consciously choose to make this all work. The vast majority of these 2 billion have no idea of what it really means to be part of the global economy. They have no view of themselves as part of a 2-billion man machine that outputs a huge array of goods and services. And if these people could see all the people they cooperate with every day, they might be horrified. Because right now racists are toiling away for the benefit of peoples they despise, and in turn gladly buying and putting to good use the products of people whose hand they were never shake.&nbsp;</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">No, people don&rsquo;t do their part in the economy in order to cooperate with others and make the economy work. They work on their small part because that&rsquo;s their job. Their boss told them to. Their focus is on their tiny slice of the economy. They toil away for their paycheck, not to may the economy work, not to cooperate or coordinate with anyone beyond their boss and co-workers.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">So the economy doesn&rsquo;t coordinate because people choose to make it do so. Maybe instead the economy is centrally directed by some powerful, smart organization?</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">As a matter of empirical fact, I&rsquo;m pretty sure the global economy isn&rsquo;t centrally planned. And those parts of the world where production decisions are by and large made by the central government are poor, despotic places. Whenever central economic planning is substituted for decentralized coordination where decentralized coordination is possible (i.e., not ruled out by transaction costs), the result is less coordination and production, not more.</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">So how does the economy coordinate? Broadly, there are three elements that allow such an extensive division of labor to occur with such apparent ease:</span></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p><ol style=\"list-style-type: decimal;\">\n<li style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Restricting the domain of people&rsquo;s actions to their own self-interest;</span></li>\n</ol><ol style=\"list-style-type: decimal;\">\n<li style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Prices aggregating most of the information in the economy, and;</span></li>\n</ol><ol style=\"list-style-type: decimal;\">\n<li style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">Competition promoting the best-coordinating activities and institutions and killing off the least-coordinating activities and institutions.</span></li>\n</ol></p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial; min-height: 15.0px;\">&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 13.0px Arial;\"><span style=\"letter-spacing: 0.0px;\">We&rsquo;ll start with self-interest tomorrow.</span></p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WavpbXrbh6hsHhGzs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": -13, "extendedScore": null, "score": -8e-06, "legacy": true, "legacyId": "23084", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T15:44:39.851Z", "modifiedAt": null, "url": null, "title": "Meetup : Israel LW meetup", "slug": "meetup-israel-lw-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:35.103Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanArmak", "createdAt": "2009-08-05T23:08:24.020Z", "isAdmin": false, "displayName": "DanArmak"}, "userId": "7KSbntzeQ2RNZq6Jw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jraMvbaTSFrq7KcYN/meetup-israel-lw-meetup", "pageUrlRelative": "/posts/jraMvbaTSFrq7KcYN/meetup-israel-lw-meetup", "linkUrl": "https://www.lesswrong.com/posts/jraMvbaTSFrq7KcYN/meetup-israel-lw-meetup", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Israel%20LW%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Israel%20LW%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjraMvbaTSFrq7KcYN%2Fmeetup-israel-lw-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Israel%20LW%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjraMvbaTSFrq7KcYN%2Fmeetup-israel-lw-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjraMvbaTSFrq7KcYN%2Fmeetup-israel-lw-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 117, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/o5\">Israel LW meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">04 July 2013 08:00:00PM (+0300)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">7 Menachem Begin st., Ramat-Gan 52681, Israel</span></p>\n<p>(<strong>Gibor Sport House, 15th floor.</strong>)</p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>The Israel Less Wrong group is meeting again. We haven't chosen the subject of the meeting yet (I will update the post when we do). The discussion is ongoing in our <a href=\"https://groups.google.com/forum/#!forum/lesswrong-tel-aviv\">Google Group</a>.</p>\n<p>I want to say thank you again to Cat from CFAR, and Gal Hochberg, for organizing the <a href=\"/lw/hga/meetup_tel_aviv_israel_meetup_goal_clarification/\">previous meetup</a> six weeks ago and catalyzing the reboot of LW Israel!</p>\n<p>The location is in the offices of a company called <a rel=\"nofollow\" href=\"http://www.visionmap.com/en/contact\">Visionmap</a>.</p>\n<p>The exact time given is provisional. Please follow the discussion in the group for updates.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/o5\">Israel LW meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jraMvbaTSFrq7KcYN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 1.2444331726295174e-06, "legacy": true, "legacyId": "23085", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Israel_LW_meetup\">Discussion article for the meetup : <a href=\"/meetups/o5\">Israel LW meetup</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">04 July 2013 08:00:00PM (+0300)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">7 Menachem Begin st., Ramat-Gan 52681, Israel</span></p>\n<p>(<strong>Gibor Sport House, 15th floor.</strong>)</p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>The Israel Less Wrong group is meeting again. We haven't chosen the subject of the meeting yet (I will update the post when we do). The discussion is ongoing in our <a href=\"https://groups.google.com/forum/#!forum/lesswrong-tel-aviv\">Google Group</a>.</p>\n<p>I want to say thank you again to Cat from CFAR, and Gal Hochberg, for organizing the <a href=\"/lw/hga/meetup_tel_aviv_israel_meetup_goal_clarification/\">previous meetup</a> six weeks ago and catalyzing the reboot of LW Israel!</p>\n<p>The location is in the offices of a company called <a rel=\"nofollow\" href=\"http://www.visionmap.com/en/contact\">Visionmap</a>.</p>\n<p>The exact time given is provisional. Please follow the discussion in the group for updates.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Israel_LW_meetup1\">Discussion article for the meetup : <a href=\"/meetups/o5\">Israel LW meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Israel LW meetup", "anchor": "Discussion_article_for_the_meetup___Israel_LW_meetup", "level": 1}, {"title": "Discussion article for the meetup : Israel LW meetup", "anchor": "Discussion_article_for_the_meetup___Israel_LW_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DW6bpSTRzkp4Fu5qA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-25T22:19:51.517Z", "modifiedAt": null, "url": null, "title": "Bayes versus Science Round Two: Battle of the Banks", "slug": "bayes-versus-science-round-two-battle-of-the-banks", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:07.457Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "9hQryffdwLDyNbnkh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HCKTSjbm9cJ9pfwdB/bayes-versus-science-round-two-battle-of-the-banks", "pageUrlRelative": "/posts/HCKTSjbm9cJ9pfwdB/bayes-versus-science-round-two-battle-of-the-banks", "linkUrl": "https://www.lesswrong.com/posts/HCKTSjbm9cJ9pfwdB/bayes-versus-science-round-two-battle-of-the-banks", "postedAtFormatted": "Tuesday, June 25th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayes%20versus%20Science%20Round%20Two%3A%20Battle%20of%20the%20Banks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayes%20versus%20Science%20Round%20Two%3A%20Battle%20of%20the%20Banks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCKTSjbm9cJ9pfwdB%2Fbayes-versus-science-round-two-battle-of-the-banks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayes%20versus%20Science%20Round%20Two%3A%20Battle%20of%20the%20Banks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCKTSjbm9cJ9pfwdB%2Fbayes-versus-science-round-two-battle-of-the-banks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHCKTSjbm9cJ9pfwdB%2Fbayes-versus-science-round-two-battle-of-the-banks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2892, "htmlBody": "<p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">In the beginning, before people had quite understood how economics worked, they'd gone around thinking crazy ideas like &ldquo;Businessmen choose so as to maximize profits&rdquo; and &ldquo;Firms set the marginal cost [pay] of their workers equal to the marginal product revenue [output] of their workers.&rdquo;</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Of course people noticed the problem right away: people observably don&rsquo;t make decisions to do things like maximize profits or set MC equal to MR. Economists responded by saying that people somehow implicitly used rules like &ldquo;maximize profits&rdquo; or &ldquo;set MC equal to MR&rdquo; as guidelines for behavior.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Then in 1939 a group of Oxford economists decided to test the theory: do firms use &ldquo;set MC equal to MR&rdquo; as a rule for setting the pay of workers? They sent out questionnaires to firms asking them how they set their workers&rsquo; pay.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The responses they got back were highly disturbing. Firms didn&rsquo;t know what this marginal cost and marginal revenue business was and they didn&rsquo;t much care. They used a kind of pricing called &ldquo;full-cost pricing&rdquo; which...didn&rsquo;t make much sense and it&rsquo;s not very important. What is important is that the results of the questionnaires struck a huge blow to marginalism. Firms aren&rsquo;t using marginal cost to make decisions!</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">And so the full-cost pricing controversy was born.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">There was a huge debate in the profession. Was marginalism wrong? Were firms not profit-maximizing entities? Some of the greatest economic minds of that generation took part in the debate. But for all their effort there didn&rsquo;t seem to be any satisfactory way to explain the data that would also preserve most of the advances in economic theory since the 1870s.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Then Armen Albert Alchian, the 1000 year-old vampire of economics, entered the fray. <a href=\"http://www.sfu.ca/~allen/alchian.pdf\">In eleven elegant pages he ended the debate and changed economics forever.</a></p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Alchian pointed out that it is only in a world of certainty and perfect foresight that people can choose to maximize profits or set MR equal to MC. Neither of those things are actions, they are outcomes--there is no button you can press to maximize profits or set MR equal to MC. In the world of certainty and perfect foresight, however, there may as well be a button--you can just look down all the paths your different actions lead to to see which path leads to the highest profits. It&rsquo;s easy, for someone with certainty and perfect foresight.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">But in reality, there is uncertainty and imperfect foresight. Imperfect foresight means that the button pressing-equivalent of looking down all the different paths you can take to see which one leads to the highest profits is not possible.&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Uncertainty means that when you consider the consequences of your choices, you don&rsquo;t face a single potential outcome but rather a distribution of outcomes, and furthermore, that distribution overlaps with the distribution generated by other actions. Uncertainty is a consequence of the immense complexity of the economy, which is made of an uncountable number of ever-changing parts. And in that case, &ldquo;maximize profits&rdquo; or &ldquo;set MR equal to MC&rdquo; is in no way a useful guide to action. There is a single maximizing outcome but you can&rsquo;t choose that. You can only choose different distributions, and because the distributions overlap, there is no maximizing distribution. There is an optimal distribution, whichever distribution you happen to prefer, but maximization is out as a guide to action.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">So what is to become of economic theory if firms can&rsquo;t choose to maximize profits and set MR equal to MC?</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Not to worry, Alchian said. That&rsquo;s what the economy is for.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The economy is competitive. That means there is a set of criteria which the economy selects for. Firms with that criteria are promoted and firms without that criteria go out of business. Yes, just like evolution by natural selection; the economy is evolutionary.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Alchian pointed out that what the economy selects for is realized positive profits. Basically, that means the economy promotes the firms that make more money than their competitors. Firms that make less money than their competitors go out of business--they die.&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Those realized positive profits are achieved by the firm that is best adapted to its environment, in exactly the same way that those organisms which reproduce successfully are best adapted to their environments. Therefore the competitive economy, by directly selecting for realized positive profits, indirectly selects for the firms which do the best job of solving the economic problem they are presented with.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">What that means, Alchian realized, is that you don&rsquo;t need any individual in the economy doing anything particularly &ldquo;economic&rdquo; like trying to maximize profits or set MR equal to MC for the economy itself to achieve exactly that. You can have people with zero foresight, and as long as they can just try all kinds of things, the economy will select for the firms that do the best job of approximating the characteristics best suited to the environment.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Say two firms compete with each other: one sells tulips, and the other roses. Which, if either, is profit maximizing--which is ideal for the current economic environment? Probably neither, but it doesn&rsquo;t matter; the economy will promote the firm that makes more money and kill the firm that makes less. The plans and rationales of the two different firms for their actions are irrelevant.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Two more firms go at it: one tries to somehow achieve &ldquo;full-cost pricing&rdquo; and the other tries to somehow set MR equal to MC. Alchian&rsquo;s point is that neither firm actually knows that it can accomplish its goal with its chosen strategy. The economy will choose the firm which makes more money, which is the firm better suited to the environment, and the economy will kill the firm that makes less money.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">What Alchian&rsquo;s analysis shows is that you can have an economy full of people who just make silly decisions for no rational reason and still have rational economic outcomes if the competitive economy selects for those outcomes. What economists had thought is that firms adapt themselves to the economy, but Alchian showed that it is more like the economy which adapts firms to it. And thus, &ldquo;consistent success cannot be treated as prima facie evidence against pure luck!&rdquo;</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Marginalism is saved! The full-cost pricing controversy has ended. People don&rsquo;t need to maximize profits or set MR equal to MC as long as the economy selects for realized positive profits and having MR set equal to MC a characteristic of a firm ideally suited for the given economic environment.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">What no one realized at the time, not even Alchian, who was soon busy using the stock market to figure out which materials are used to make nuclear bombs, is that Alchian&rsquo;s argument destroys the case for central banking.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Let&rsquo;s consider central banking versus free banking from this angle: which system has greater science power, i.e., if we think of the economic environment as posing a problem to the two systems, which system is more likely to solve that problem?</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The power to solve a problem comes in two steps: generating hypotheses, and testing hypotheses.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Free banking generates hypotheses by, well, letting people try whatever they please. But it&rsquo;s not quite as random as that, or nothing would ever be accomplished. Just as in evolution by natural selection, as long as the environment has not changed too dramatically, using what already exists as the starting point allows you to cut a long way through the search space to a hypothesis not extremely far from the most correct answer.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">But people are smarter than evolution. They don&rsquo;t just have to stop with what they are currently experimenting a mutation on. They can look at the past or at other industries for inspiration. They can also use their own insight to cut even farther past the answer the economy has already produced. This results in failures, certainly, but also in brilliant innovations at a rate and scale evolution by natural selection cannot match.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">That is how free banking generates hypotheses: dozens, hundreds, or maybe even thousands of hypotheses, some big, some small, are constantly being proposed, where proposed means the number of hypotheses submitted for testing. They use the given answer as a starting point and use their own knowledge of changing economic conditions, past and parallel evidence, and their own insight to go even further. This is a very different and superior system to evolution by natural selection, which simply takes the current hypothesis and tries a small random change. It can&rsquo;t look at past or parallel hypotheses and the change is random since no intelligence is applied.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Now compare this to how central banking generates hypotheses. Central banking, like free banking, can only propose as many hypotheses as it is able to test, which is much smaller than what free banking can do both because central banks want to experiment less and because there are fewer of them to begin with.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Central banking can&rsquo;t match free banking&rsquo;s rate of hypothesis generation, but if central banking can generate hypotheses as good as the best free banking hypotheses with fewer hypotheses, that&rsquo;s actually a point in central banking&rsquo;s favor--it&rsquo;s more efficient with its hypotheses. But central banking probably can&rsquo;t do that. That&rsquo;s simply because central banking, like free banking, can&rsquo;t go much farther in its hypotheses than by looking at what it is already doing, what it has done, and what other central banks are doing parallel to it. But the range of hypotheses attempted by the central bank is much more limited than free banking. You simply can&rsquo;t try as many different kinds of things with a central bank. The consequences of a central bank filled with experimental spirit would be disastrous. Central banking could only outperform free banking if it started out much closer to the most correct hypothesis than free banking did. But that is extremely implausible. To see why we have to go back to Alchian.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">In the real world of uncertainty and perfect foresight, central banks can&rsquo;t just press a button setting inflation, unemployment, and economic growth at the desired levels.&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">(Although you might wonder if something like the Mind Projection Fallacy doesn&rsquo;t occur when economists play at being central bankers. The individuals in the model might not know everything about their small world but the modeler, the economist certainly does, and so in his model the solution will be obvious to him, and if he doesn&rsquo;t realize that that&rsquo;s a fact about his mind and not about the world, then he would be overconfident in the central bank&rsquo;s foresight and ability to achieve its goals by the decision-equivalent of button pressing)</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">What central banks actually face is a set of overlapping distributions of outcomes with no maximizing distribution due to the extreme complexity of economy. There is no certain or clear path to the goals of the central bank.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Free banking also faces this problem, but there are two key differences.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The first key difference is that free banking is much more decentralized than central banking. A more decentralized system means that the problems the individuals are trying to solve are much smaller and simpler (although still possibly very large and complex), and the problem-solvers have more information about the problem. It&rsquo;s a smaller problem and they are closer to it. The more centralized system faces a more complex system and has less information to solve it with. Free banking is thus more likely to generate some hypotheses that are better than what central banking produces.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The second difference has to do the relative ability of free and central banking to test their hypotheses, the second aspect of scientific power.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Alchian showed that even if individuals want to maximize profits and set MR equal to MC, in a world of uncertainty and imperfect foresight the idea of choosing to maximize profits simply doesn&rsquo;t make sense. The economy is simply too complex for people to adapt themselves to it very effectively. But that doesn&rsquo;t matter, because the economy adapts people to it. The economy selects for the firms with realized positive profits, which is to say, firms which are relatively well-suited for the given environment, and the economy kills the firms which are relatively unsuited for the given environment.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">In other words, the market economy tests hypotheses. All those hypotheses constantly generated by free banking are subject to a brutal, merciless test: the test of survival in the marketplace. It is this constant, terrible series of tests that allows market economies to produce outcomes that economics can explain and predict when economics has very little ability to explain or predict individual behavior.&nbsp;</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">This is free banking&rsquo;s greatest advantage over central banking, because central banking does not test its hypotheses. The central bank does not profit for generating a good hypothesis and it does not die for generating a bad one. The central bank does not face the trial, the test, the selection.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Imagine a group of biologists who created a few types of organisms which they intended to be well-suited to some environment, and then never released those organisms into the environment to subject them to evolutionary pressures. They would have no way of knowing which organisms were better suited to that environment and which weren&rsquo;t. Scientific power depends strongly on whether you can do the test. People who can&rsquo;t test their hypotheses don&rsquo;t get very far with them.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The different quality of the tests free and central banking subject their hypotheses too brings us back around to their relative ability to generate quality hypotheses. Both rely on looking at what they are already doing and have done to serve as a starting point for new hypotheses, but the difference is that free banking&rsquo;s starting point is a starting point forged in the furnaces of scientific testing, and central banking&rsquo;s starting point is pretty much whatever central banks happen to be doing, which may appear to be working or not. If it does appear to be working, uncertainty means there is no way of knowing whether that is sheer luck or if the hypothesis is actually a good one. Free banking has a powerful test, however, for determining its surviving hypotheses and so can be more confident that its surviving hypotheses are actually good.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">The verdict is clear: the scientific power of free banking is dramatically superior to that of central banking. Free banking generates a larger quantity of hypotheses, the most accurate of which are more accurate than the hypotheses central banking generates, and then goes through a much more exacting testing process which kills off the bad hypotheses and rewards the good ones with profits. Central banking, on the other hand, is left wondering if any success it is seeing is because of the good hypothesis or sheer dumb luck, because there is no trial, no test to distinguish.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">You might notice, at the end of all this, that the process free banking goes through to adapt and be adapted to the environment closely resembles the scientific method. People come up with hypotheses that seem smart to them based on what they know about past results, and then they do the experiment. The hypotheses that pass the test are promoted and the hypotheses that fail are discarded.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Central banking, on the other hand, more closely resembles armchair philosophy of the sort that science rebelled against centuries ago. A small number of very smart people are supposed to figure the world out largely by thinking about it. Sure, they have reams of data and theory, but so did Aristotle (hey, every time he looked outside he was receiving all kinds of data). Aristotle&rsquo;s weakness was that he didn&rsquo;t do experiments, not a lack of access to data or raw intelligence. By the same token, central banking&rsquo;s weakness is its inability to test its hypotheses.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">(And so perhaps it&rsquo;s not entirely surprising that central banking pre-dates economics itself, and is essentially an outgrowth of a feudal institution. Whereas in every other industry there were significant movements in the past several centuries towards the ending of privilege and monopoly, the freeing up of competition and trade, central banks maintained their monopolies and privileges and even were established in countries that had previously lacked them. And so the methodology of central banking is still essentially pre-scientific.)</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">This isn&rsquo;t the end of the argument, of course. There are all kinds of obstacles to successful coordination in a free banking regime (for example externalities, predatory pricing, information asymmetry), but then again the same is true in a central banking regime (for example terrible incentives, lack of Hayekian information, political interference). At best for the case for central banking, these kinds of problems on net wash out.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">Which means, given how much stronger free banking is as a scientific process than central banking, that free banking wins outright, even though I can&rsquo;t do the experiment to prove it. It&rsquo;s simply a much more plausible hypothesis.</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">(This is not a defense of free banking. Nothing in this argument establishes that free banking is the best banking regime, and I do not intend to present that argument. It isn&rsquo;t interesting to me. But this argument does show that if you want an alternative to free banking, that alternative can&rsquo;t be central banking.)</p>\n<p style=\"margin: 0.0px 0.0px 13.0px 0.0px; text-align: justify; font: 13.0px Arial;\">And it&rsquo;s so ironic, that for all the desire economists and laypeople have expressed over the years for a scientific alternative to capitalism, that a competitive market economy is the embodiment of the scientific method in the global economy, working on a scale beyond the current abilities of any scientist or team of scientist to solve problems that the world&rsquo;s best economists cannot even begin to solve in their entirety.&nbsp;</p>\n</p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HCKTSjbm9cJ9pfwdB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": -14, "extendedScore": null, "score": -8e-06, "legacy": true, "legacyId": "23087", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-26T09:05:10.904Z", "modifiedAt": null, "url": null, "title": "Meetup : London Practical - Sunday 7th July", "slug": "meetup-london-practical-sunday-7th-july", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:28.525Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Leonhart", "createdAt": "2010-02-22T20:01:49.792Z", "isAdmin": false, "displayName": "Leonhart"}, "userId": "X5EZEkfccqyWXETHd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XnYCAZxezoAEM7hXg/meetup-london-practical-sunday-7th-july", "pageUrlRelative": "/posts/XnYCAZxezoAEM7hXg/meetup-london-practical-sunday-7th-july", "linkUrl": "https://www.lesswrong.com/posts/XnYCAZxezoAEM7hXg/meetup-london-practical-sunday-7th-july", "postedAtFormatted": "Wednesday, June 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20London%20Practical%20-%20Sunday%207th%20July&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20London%20Practical%20-%20Sunday%207th%20July%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXnYCAZxezoAEM7hXg%2Fmeetup-london-practical-sunday-7th-july%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20London%20Practical%20-%20Sunday%207th%20July%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXnYCAZxezoAEM7hXg%2Fmeetup-london-practical-sunday-7th-july", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXnYCAZxezoAEM7hXg%2Fmeetup-london-practical-sunday-7th-july", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 120, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/o6\">London Practical - Sunday 7th July</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">07 July 2013 02:00:00PM (+0100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Shakespeare's Head, London WC2B 6BG</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>One of our fortnightly meetups. This is going to be a practical session (we are alternating practical/social), which means there will be at least one valiant attempt at a small-group exercise &amp; guided discussion.</p>\n<p>The intention for today is to practice doing <a href=\"/lw/h5e/fermi_estimates/\">Fermi Estimates</a>.</p>\n<p>Please be there for 2pm if you can. We can accommodate later arrivals, but we will be starting promptly.</p>\n<p>The venue is the Shakespeare's Head by Holborn tube station. Turn left out of the station exit and it's &lt;100m on your left.</p>\n<p>We also have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google Group</a>.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/o6\">London Practical - Sunday 7th July</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XnYCAZxezoAEM7hXg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 1.2452384246991503e-06, "legacy": true, "legacyId": "23098", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___London_Practical___Sunday_7th_July\">Discussion article for the meetup : <a href=\"/meetups/o6\">London Practical - Sunday 7th July</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">07 July 2013 02:00:00PM (+0100)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Shakespeare's Head, London WC2B 6BG</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>One of our fortnightly meetups. This is going to be a practical session (we are alternating practical/social), which means there will be at least one valiant attempt at a small-group exercise &amp; guided discussion.</p>\n<p>The intention for today is to practice doing <a href=\"/lw/h5e/fermi_estimates/\">Fermi Estimates</a>.</p>\n<p>Please be there for 2pm if you can. We can accommodate later arrivals, but we will be starting promptly.</p>\n<p>The venue is the Shakespeare's Head by Holborn tube station. Turn left out of the station exit and it's &lt;100m on your left.</p>\n<p>We also have a <a href=\"https://groups.google.com/forum/?fromgroups=#!forum/lesswronglondon\">Google Group</a>.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___London_Practical___Sunday_7th_July1\">Discussion article for the meetup : <a href=\"/meetups/o6\">London Practical - Sunday 7th July</a></h2>", "sections": [{"title": "Discussion article for the meetup : London Practical - Sunday 7th July", "anchor": "Discussion_article_for_the_meetup___London_Practical___Sunday_7th_July", "level": 1}, {"title": "Discussion article for the meetup : London Practical - Sunday 7th July", "anchor": "Discussion_article_for_the_meetup___London_Practical___Sunday_7th_July1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PsEppdvgRisz5xAHG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-26T13:17:54.357Z", "modifiedAt": null, "url": null, "title": "Nick Beckstead: On the Overwhelming Importance of Shaping the Far Future", "slug": "nick-beckstead-on-the-overwhelming-importance-of-shaping-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:11.378Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GJ79jkxJJJqjaSwgW/nick-beckstead-on-the-overwhelming-importance-of-shaping-the", "pageUrlRelative": "/posts/GJ79jkxJJJqjaSwgW/nick-beckstead-on-the-overwhelming-importance-of-shaping-the", "linkUrl": "https://www.lesswrong.com/posts/GJ79jkxJJJqjaSwgW/nick-beckstead-on-the-overwhelming-importance-of-shaping-the", "postedAtFormatted": "Wednesday, June 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Nick%20Beckstead%3A%20On%20the%20Overwhelming%20Importance%20of%20Shaping%20the%20Far%20Future&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANick%20Beckstead%3A%20On%20the%20Overwhelming%20Importance%20of%20Shaping%20the%20Far%20Future%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGJ79jkxJJJqjaSwgW%2Fnick-beckstead-on-the-overwhelming-importance-of-shaping-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Nick%20Beckstead%3A%20On%20the%20Overwhelming%20Importance%20of%20Shaping%20the%20Far%20Future%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGJ79jkxJJJqjaSwgW%2Fnick-beckstead-on-the-overwhelming-importance-of-shaping-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGJ79jkxJJJqjaSwgW%2Fnick-beckstead-on-the-overwhelming-importance-of-shaping-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 359, "htmlBody": "<p>&nbsp;</p>\n<p><a href=\"https://sites.google.com/site/nbeckstead/research\">Nick Beckstead: On the Overwhelming Importance of Shaping the Far Future</a></p>\n<p>ABSTRACT: In slogan form, the thesis of this dissertation is that shaping the far future is overwhelmingly important. More precisely, I argue that:</p>\n<p>Main Thesis: From a global perspective, what matters most (in expectation) is that we do what is best (in expectation) for the general trajectory along which our descendants develop over the coming millions of years or longer.</p>\n<p>The first chapter introduces some key concepts, clarifies the main thesis, and outlines what follows in later chapters. Some of the key concepts include: existential risk, the world's development trajectory, proximate benefits and ripple effects, speeding up development, trajectory changes, and the distinction between broad and targeted attempts to shape the far future. The second chapter is a defense of some methodological assumptions for developing normative theories which makes my thesis more plausible. In the third chapter, I introduce and begin to defend some key empirical and normative assumptions which, if true, strongly support my main thesis. In the fourth and fifth chapters, I argue against two of the strongest objections to my arguments. These objections come from population ethics, and are based on Person-Affecting Views and views according to which additional lives have diminishing marginal value. I argue that these views face extreme difficulties and cannot plausibly be used to rebut my arguments. In the sixth and seventh chapters, I discuss a decision-theoretic paradox which is relevant to my arguments. The simplest plausible theoretical assumptions which support my main thesis imply a view I call fanaticism, according to which any non-zero probability of an infinitely good outcome, no matter how small, is better than any probability of a finitely good outcome. I argue that denying fanaticism is inconsistent with other normative principles that seem very obvious, so that we are faced with a paradox. I have no solution to the paradox; I instead argue that we should continue to use our inconsistent principles, but we should use them tastefully. We should do this because, currently, we know of no consistent set of principles which does better.</p>\n<p>[If there's already been a discussion post about this, my apologies, I couldn't find it.]</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GJ79jkxJJJqjaSwgW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 1.2454341461136e-06, "legacy": true, "legacyId": "23099", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-26T22:40:23.597Z", "modifiedAt": null, "url": null, "title": "A Ketogenic Diet as an Effective Cancer Treatment?", "slug": "a-ketogenic-diet-as-an-effective-cancer-treatment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:31.676Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "c5z9EgYfqNTT6MxhR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kK5awQQRuWB9eXknt/a-ketogenic-diet-as-an-effective-cancer-treatment", "pageUrlRelative": "/posts/kK5awQQRuWB9eXknt/a-ketogenic-diet-as-an-effective-cancer-treatment", "linkUrl": "https://www.lesswrong.com/posts/kK5awQQRuWB9eXknt/a-ketogenic-diet-as-an-effective-cancer-treatment", "postedAtFormatted": "Wednesday, June 26th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Ketogenic%20Diet%20as%20an%20Effective%20Cancer%20Treatment%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Ketogenic%20Diet%20as%20an%20Effective%20Cancer%20Treatment%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkK5awQQRuWB9eXknt%2Fa-ketogenic-diet-as-an-effective-cancer-treatment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Ketogenic%20Diet%20as%20an%20Effective%20Cancer%20Treatment%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkK5awQQRuWB9eXknt%2Fa-ketogenic-diet-as-an-effective-cancer-treatment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkK5awQQRuWB9eXknt%2Fa-ketogenic-diet-as-an-effective-cancer-treatment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 794, "htmlBody": "<p>Yesterday, my mother (not a rationalist) told me that she had recently heard somewhere (most likely on a popular television program) that, as simple as it sounds, an effective cancer treatment is cutting back on glucose intake. According to her story, cancer cells can only efficiently use glucose as fuel, and will be unable to multiply (or will starve, or something like that) if you don't consume any. Meanwhile, normal cells can convert other forms of energy into glucose inside their membranes, and then will continue functioning normally.</p>\n<p>My first two thoughts:</p>\n<blockquote>\n<p>Reality just can't be that nice.</p>\n</blockquote>\n<blockquote>\n<p>Hey, wait a second, doesn't the body just convert everything into glucose before it's released into the bloodstream, anyways?</p>\n</blockquote>\n<p>So I did some Googling and I found out that what my mother was referring to is called a <a href=\"http://en.wikipedia.org/wiki/Ketogenic_diet\" target=\"_blank\">ketogenic diet</a> (from Wikipedia):</p>\n<blockquote>\n<p>The ketogenic diet is a high-fat, adequate-protein, low-carbohydrate diet that in medicine is used primarily to treat difficult-to-control (refractory) epilepsy in children. The diet forces the body to burn fats rather than carbohydrates. Normally, the carbohydrates contained in food are converted into glucose, which is then transported around the body and is particularly important in fuelling brain function. However, if there is very little carbohydrate in the diet, the liver converts fat into fatty acids and ketone bodies. The ketone bodies pass into the brain and replace glucose as an energy source. An elevated level of ketone bodies in the blood, a state known as ketosis, leads to a reduction in the frequency of epileptic seizures.</p>\n</blockquote>\n<p>So, prima facie, my second objection was dealt with. More Googling led me to discover these two references to what my mother had mentioned:</p>\n<ul>\n<li><a href=\"http://blogs.timesofindia.indiatimes.com/one-healthy-day-at-a-time/entry/ketogenic-diet-effective-against-metastatic-cancer\" target=\"_blank\">http://blogs.timesofindia.indiatimes.com/one-healthy-day-at-a-time/entry/ketogenic-diet-effective-against-metastatic-cancer</a></li>\n<li>The paper mentioned in the blog post, <a href=\"http://www.plosone.org/article/info:doi/10.1371/journal.pone.0065522\" target=\"_blank\">\"The Ketogenic Diet and Hyperbaric Oxygen Therapy Prolong Survival in Mice with Systemic Metastatic Cancer\"</a>.</li>\n</ul>\n<p>According to the paper:</p>\n<blockquote>\n<p>Abnormal energy metabolism is a consistent feature of most tumor cells across all tissue types [14]. In the 1930 s, Otto Warburg observed that all cancers expressed high rates of fermentation in the presence of oxygen [15]. This feature, known as The Warburg Effect, is linked to mitochondrial dysfunction and genetic mutations within the cancer cell [14], [16], [17]. These defects cause cancers to rely heavily on glucose for energy, a quality that underlies the use of fluorodeoxyglucose-PET scans as an important diagnostic tool for oncologists [18]. Ketogenic diets are high fat, low carbohydrate diets that have been used for decades to treat patients with refractory epilepsy [19]. Ketogenic diets also suppress appetite naturally thus producing some body weight loss [19], [20], [21], [22]. Dietary energy reduction (DER) lowers blood glucose levels, limiting the energy supply to cancer cells, while elevating circulating blood ketone levels [6]. Ketone bodies can serve as an alternative energy source for those cells with normal mitochondrial function [23], [24], but not for cancer cells [25]. DER has been shown to have anti-tumor effects in a variety of cancers, including brain, prostate, mammary, pancreas, lung, gastric, and colon [14], [26], [27], [28], [29], [30], [31], [32], [33], [34]. DER produces anti-cancer effects through several metabolic pathways, including inhibition of the IGF-1/PI3K/Akt/HIF-1&alpha; pathway which is used by cancer cells to promote proliferation and angiogenesis and inhibit apoptosis [35], [36], [37], [38], [39], [40], [41], [42]. Additionally, DER induces apoptosis in astrocytoma cells, while protecting normal brain cells from death through activation of adenosine monophosphate kinase (AMPK) [43].</p>\n</blockquote>\n<p>Note what the sentence with ten citations says. Why have I never heard of this? If the basic claims being made are true, we seem to have an effective way of at least preventing cancer from progressing further (if not killing it off), and it's not even dangerous (at least compared to the alternatives, as far as I am aware of...however, I realize I know next to nothing in this field...that's the reason for this post)! Is there some reason this isn't being sung about on Reddit as a huge victory for science? What is the counterevidence? Or are we still waiting for more research to be done?</p>\n<p>For <a href=\"/lw/s3/the_genetic_fallacy/\" target=\"_blank\">genetic</a> reasons and because humans often engage in <a href=\"/lw/km/motivated_stopping_and_motivated_continuation/\" target=\"_blank\">motivated reasoning</a>, I am skeptical. I am querying the Less Wrong community for more information...perhaps some of you have already heard of a ketogenic diet being used as a cancer treatment, or would like to do more research than I've done now that I've introduced you to it. The following books may also serve as helpful, albeit expensive, references:</p>\n<ul>\n<li><em><a href=\"http://www.amazon.com/dp/0470584920/\" target=\"_blank\">Cancer as a Metabolic Disease: On the Origin, Management, and Prevention of Cancer</a></em>&nbsp;by Thomas Seyfried. &nbsp;I think this would be the \"standard\" reference here.</li>\n<li><em><a href=\"http://www.amazon.com/dp/1477567593/\" target=\"_blank\">The Cantin Ketogenic Diet: For Cancer, Type I Diabetes &amp; Other Ailments</a></em> by Elaine Cantin.</li>\n<li><a style=\"font-style: italic;\" href=\"http://www.amazon.com/dp/1936303108/\" target=\"_blank\">Ketogenic Diets</a>&nbsp;by Dr. Eric H. Kossoff (and others).</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kK5awQQRuWB9eXknt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 5, "extendedScore": null, "score": 1.5e-05, "legacy": true, "legacyId": "23086", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["KZLa74SzyKhSJ3M55", "L32LHWzy9FzSDazEg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T03:16:14.136Z", "modifiedAt": null, "url": null, "title": "Bad Concepts Repository", "slug": "bad-concepts-repository", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:31.847Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "moridinamael", "createdAt": "2011-01-20T18:55:32.068Z", "isAdmin": false, "displayName": "moridinamael"}, "userId": "sWA9eDCM9AgFaZho8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RcMjekC7yDTBzKCij/bad-concepts-repository", "pageUrlRelative": "/posts/RcMjekC7yDTBzKCij/bad-concepts-repository", "linkUrl": "https://www.lesswrong.com/posts/RcMjekC7yDTBzKCij/bad-concepts-repository", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bad%20Concepts%20Repository&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABad%20Concepts%20Repository%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRcMjekC7yDTBzKCij%2Fbad-concepts-repository%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bad%20Concepts%20Repository%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRcMjekC7yDTBzKCij%2Fbad-concepts-repository", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRcMjekC7yDTBzKCij%2Fbad-concepts-repository", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 293, "htmlBody": "<p>We recently established a successful <a title=\"Useful Concepts Repository\" href=\"/lw/hhl/useful_concepts_repository/\">Useful Concepts Repository</a>. &nbsp;It got me thinking about all the useless or actively harmful concepts I had carried around for in some cases most of my life before seeing them for what they were. &nbsp;Then it occurred to me that I probably still have some poisonous concepts lurking in my mind, and I thought creating this thread might be one way to discover what they are.</p>\n<p>I'll start us off with one simple example: &nbsp;The <a title=\"Bohr Model\" href=\"http://en.wikipedia.org/wiki/Bohr_model\">Bohr model</a>&nbsp;of the atom as it is taught in school is a dangerous thing to keep in your head for too long. &nbsp;I graduated from high school believing that it was basically a correct physical representation of atoms. &nbsp;(And I went to a *good* high school.) &nbsp;Some may say that the Bohr model serves a useful role as a <a title=\"lie to children\" href=\"http://en.wikipedia.org/wiki/Lies_to_children\">lie-to-children</a>&nbsp;to bridge understanding to the true physics, but if so, why do so many adults still think atoms look like concentric circular orbits of electrons around a nucleus? &nbsp;</p>\n<p>There's one hallmark of truly bad concepts: they actively work against correct induction. &nbsp;Thinking in terms of the Bohr model actively prevents you from understanding molecular bonding and, really, everything about how an atom can serve as a functional piece of a real thing like a protein or a diamond.</p>\n<p>Bad concepts don't have to be scientific. &nbsp;Religion is held to be a pretty harmful concept around here. &nbsp;There are certain political theories which might qualify, except I expect that one man's harmful political concept is another man's core value system, so as usual we should probably stay away from politics. &nbsp;But I welcome input as fuzzy as common folk advice you receive that turned out to be really costly.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Eha62RrqBtEbpcEza": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RcMjekC7yDTBzKCij", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 32, "extendedScore": null, "score": 7e-05, "legacy": true, "legacyId": "23108", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 204, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["umzNiYpHLypdcXuEf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T06:08:30.001Z", "modifiedAt": null, "url": null, "title": "From Capuchins to AI's, Setting an Agenda for the Study of Cultural Cooperation (Part1)", "slug": "from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Qz3A6hQ8RWGXZWoj4/from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of", "pageUrlRelative": "/posts/Qz3A6hQ8RWGXZWoj4/from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of", "linkUrl": "https://www.lesswrong.com/posts/Qz3A6hQ8RWGXZWoj4/from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20From%20Capuchins%20to%20AI's%2C%20Setting%20an%20Agenda%20for%20the%20Study%20of%20Cultural%20Cooperation%20(Part1)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFrom%20Capuchins%20to%20AI's%2C%20Setting%20an%20Agenda%20for%20the%20Study%20of%20Cultural%20Cooperation%20(Part1)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQz3A6hQ8RWGXZWoj4%2Ffrom-capuchins-to-ai-s-setting-an-agenda-for-the-study-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=From%20Capuchins%20to%20AI's%2C%20Setting%20an%20Agenda%20for%20the%20Study%20of%20Cultural%20Cooperation%20(Part1)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQz3A6hQ8RWGXZWoj4%2Ffrom-capuchins-to-ai-s-setting-an-agenda-for-the-study-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQz3A6hQ8RWGXZWoj4%2Ffrom-capuchins-to-ai-s-setting-an-agenda-for-the-study-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1981, "htmlBody": "<address>This is a multi-purpose essay-on-the-making, it is being written aiming at the following goals 1) Mandatory essay writing at the end of a semester studying \"Cognitive Ethology: Culture in Human and Non-Human Animals\" 2) Drafting something that can later on be published in a journal that deals with cultural evolution, hopefully inclining people in the area to glance at future oriented research, i.e. FAI and global coordination 3) Publishing it in Lesswrong and 4) Ultimately <a href=\"/lw/373/how_to_save_the_world/\">Saving the World</a>, as everything should. If it's worth doing, it's worth doing in the way most likely to save the World. </address><address>Since many of <a href=\"/lw/g87/calibrating_against_undetectable_utilons_and_goal/\">my writings</a> are frequently too long for Lesswrong, I'll publish this in a sequence-like form made of self-contained chunks. My deadline is Sunday, so I'll probably post daily, editing/creating the new sessions based on previous commentary. <br /></address>\n<p><br />Abstract: The study of cultural evolution has drawn much of its momentum from academic areas far removed from human and animal psychology, specially regarding the evolution of cooperation. Game theoretic results and parental investment theory come from economics, kin selection models from biology, and an ever growing amount of models describing the process of cultural evolution in general, and the evolution of altruism in particular come from mathematics. Even from Artificial Intelligence interest has been cast on how to create agents that can communicate, imitate and cooperate. In this article I begin to tackle the '<em>why?</em>' question. By trying to retrospectively make sense of the convergence of all these fields, I contend that further refinements in these fields <em>should</em> be directed towards understanding how to create environmental incentives fostering cooperation.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #4e4e4e; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 18px; orphans: auto; text-align: -webkit-left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\"><em>We need systems that are wiser than we are. We need institutions and cultural norms that make us better than we tend to be. It seems to me that the greatest challenge we now face is to build them. - Sam Harris, 2013, The Power Of Bad Incentives</em><br /></span></p>\n</blockquote>\n<p><strong>1) Introduction</strong></p>\n<p><strong>2) Cultures evolve</strong></p>\n<p>Culture is perhaps the most remarkable outcome of the evolutionary algorithm (Dennett, 1996) so far. It is the cradle of most things we consider <em>humane</em> - that is, typically human <em>and </em>valuable - and it surrounds our lives to the point that we may be thought of as creatures made of culture even more than creatures of bone and flesh (Hofstadter, 2007; Dennett, 1992). The appearance of our cultural complexity has relied on many associated capacities, among them:</p>\n<p>1) The ability to observe, be interested by, and go nearby an individual doing something interesting, an ability we share with norway rats, crows, and even lemurs (Galef &amp; Laland, 2005).</p>\n<p>2) Ability to learn from and scrounge the food of whoever knows how to get food, shared by capuchin monkeys (Ottoni et al, 2005).</p>\n<p>3) Ability to tolerate learners, to accept learners, and to socially learn, probably shared by animals as diverse as fish, finches and Fins (Galef &amp; Laland, 2005).</p>\n<p>4) Understanding and emulating other minds - Theory of Mind- empathizing, relating, perhaps re-framing an experience <em>as one's own</em>, shared by chimpanzees, dogs, and at least some cetaceans (Rendella &amp; Whitehead, 2001).</p>\n<p>5) Learning the program level description of the action of others, for which the evidence among other animals is controversial (but see Cantor &amp; Whitehead, 2013). And finally...</p>\n<p>6) Sharing intentions. Intricate understanding of how two minds can collaborate with complementary tasks to achieve a mutually agreed goal (Tomasello et al, 2005).</p>\n<p>Irrespective of definitional disputes around the <em>true meaning </em>of the word \"culture\" (which doesn't exist, see e.g. Pinker, 2007 pg115; Yudkowsky <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">2008A</a>), each of these is more cognitively complex than its predecessor, and even (1) is sufficient for intra-specific non-environmental, non-genetic behavioral variation, which I will call \"culture\" here, whoever it may harm.</p>\n<p>By transitivity, (2-6) allow the development of culture. It is interesting to notice that tool use, frequently but falsely cited as the hallmark of culture, is ubiquitously equiprobable in the animal kingdom. A graph showing, per biological family, which species shows tool use gives us a power law distribution, whose similarity with the universal prior will help in understanding that being from a family where a species uses tools tells us very little about a specie's own tool use (Michael Haslam, personal conversation).</p>\n<p>Once some of those abilities are available, and given an amount of environmental facilities, need, and randomness, cultures begin to form. Occasionally, so do more developed traditions. Be it by imitation, program level imitation, goal emulation or intention sharing, information is transmitted between agents giving rise to elements sufficient to constitute a primeval Darwinian soup. That is, entities form such that they exhibit 1)Variation 2)Heredity or replication 3)Differential fitness (Dennett, 1996). In light of the article <em>Five Misunderstandings About Cultural Evolution </em>(Henrich, Boyd &amp; Richerson, 2008)<em> </em>we can improve Dennett's conditions for the evolutionary algorithm as 1)Discrete or continuous variation 2)Heredity, replication, or less faithful replication plus content attractors 3)Differential fitness. Once this set of conditions is met, an evolutionary algorithm, or many, begin to carve their optimizing paws into whatever surpassed the threshold for long enough. Cultures, therefore, evolve.&nbsp;</p>\n<p>The intricacies of cultural evolution and mathematical and computational models of how cultures evolve have been the subject of much interdisciplinary research, for an extensive account of human culture see <em>Not By Genes Alone</em> (Richerson &amp; Boyd, 2005). For computational models of social evolution, there is work by Mesoudi, Novak, and others e.g<em>.</em> (Hauert et al, 2007). For mathematical models, the aptly named <em>Mathematical models of social evolution: A guide for the perplexed </em>by McElrath and Rob Boyd (2007) makes the textbook-style walk-through. For animal culture, see (Laland &amp; Galef, 2009).</p>\n<p>Cultural evolution satisfies David Deutsch's criterion for existence, it <em>kicks back</em>, it satisfies the evolutionary equivalent of the&nbsp; condition posed by the Quine-Putnam Indispensability argument in mathematics, i.e. it is a <em>sine qua non</em> condition for understanding how the World works nomologically. It is falsifiable to Popperian content, and it inflates the Worlds ontology a little, by inserting a new kind of \"replicator\", the meme. Contrary to what happened on the internet, the name 'meme' has lost much of it's appeal within cultural evolution theorists, and \"memetics\" is considered by some to refer only to the study of memes as monolithic atomic high fidelity replicators, which would make the theory obsolete. This has created the following conundrum: the name 'meme' remains by far the most well known one to speak of \"that which evolves culturally\" within, and specially outside, the specialist arena. Further, the niche occupied by the word 'meme' is so conceptually necessary within the area to communicate and explain that it is frequently put under scare quotes, or some other informal excuse. In fact, as argued by Tim Tyler - who frequently posts here - in the very sharp<em> Memetics</em> (2010), there are nearly no reasons to try to abandon the 'meme' meme, and nearly all reasons (practicality, Qwerty reasons, mnemonics) to keep it. To avoid contradicting the evidence ever since Dawkins first coined the term, I suggest we must redefine <em>Meme</em> as <em>an attractor in cultural evolution (dual-inheritance) whose development over time structurally mimics to a significant extent the discrete behavior of genes</em>, <em>frequently coinciding with the smallest unit of cultural replication.</em> The definition is long, but the idea is simple: Memes are not the best analogues of genes because they are discrete units that replicate just like genes, but because they are continuous conceptual clusters being attracted <em>to a point in conceptual space whose replication is just like that of genes</em>. Even more simply, memes are the mathematically closest things to genes in cultural evolution. So the suggestion here is for researchers of dual-inheritance and cultural evolution to take off the scare quotes of our memes and keep business as usual. <em>&nbsp; </em></p>\n<p>The evolutionary algorithm has created a new attractor-replicator, the meme, it didn't privilege with it any specific families in the biological trees and it ended up creating a process of cultural-genetic coevolution known as dual-inheritance. This process has been studied in ever more quantified ways by primatologists, behavioral ecologists, population biologists, anthropologists, ethologists, sociologists, neuroscientists and even philosophers. I've shown at least six distinct abilities which helped scaffold our astounding level of cultural intricacy, and some animals who share them with us. We will now take a look at the evolution of cooperation, collaboration, altruism, moral behavior, a sub-area of cultural evolution that saw an explosion of interest and research during the last decade, with publications (most from the last 4 years) such as <em>The Origins of Morality, Supercooperators, Good and Real, The Better Angels of Our Nature, Non-Zero, The Moral Animal, Primates and Philosophers</em>, <em>The Age of Empathy, Origins of Altruism and Cooperation, The Altruism Equation, Altruism in Humans, Cooperation and Its Evolution, Moral Tribes, The Expanding Circle, The Moral Landscape. <br /></em></p>\n<p><em> </em></p>\n<p><strong>3) Cooperation evolves</strong></p>\n<p>Shortly describe why and show some inequations under which cooperation is an equelibrium, or at least an Evolutionarily Stable Strategy.</p>\n<p><strong>4) The complexity of cultural items doesn't undermine the validity of mathematical models.</strong></p>\n<p><strong> </strong></p>\n<p><strong>&nbsp;4.1) Cognitive attractors and biases substitute for memes discreteness</strong></p>\n<p>The math becomes equivalent.</p>\n<p><strong> </strong></p>\n<p><strong>&nbsp;4.2) Despite the Unilateralist Curse and the Tragedy of the Commons, dyadic interaction models help us understand large scale cooperation</strong></p>\n<p>Once we know these two failure modes, dyadic iterated (or reputation-sensitive) interaction is close enough.</p>\n<p><strong> </strong></p>\n<p><strong>5) From Monkeys to Apes to Humans to Transhumans to AIs, the ranges of achievable altruistic skill.</strong></p>\n<p>Possible modes of being altruistic. Graph like <a href=\"http://www.posthumanism.com/space5.jpg\">Bostrom's</a>. Second and third order punishment and cooperation. Newcomb-like signaling problems within AI.</p>\n<p><strong> </strong></p>\n<p><strong>6) Unfit for the Future: the need for greater altruism.</strong></p>\n<p>We fail and will remain failing in Tragedy of the Commons problems unless we change our nature.</p>\n<p><strong> </strong></p>\n<p><strong>7) From Science, through Philosophy, towards Engineering: the future of studies of altruism.</strong></p>\n<p>Philosophy: Existential Risk <a href=\"http://www.existential-risk.org/concept.html\">prevention through global coordination</a> and cooperation prior to technical maturity. Engineering Humans: creating enhancements and changing incentives. Engineering AI's: making them <a href=\"http://intelligence.org/files/RobustCooperation.pdf\">better</a> and <a href=\"https://www.youtube.com/watch?v=MwriJqBZyoM\">realer</a>.</p>\n<p><strong> </strong></p>\n<p><strong>8) A different kind of Moral Landscape</strong></p>\n<p>Like Sam Harris's one, except comparing not how much a society approaches <em>The Good Life (Moral Landscape pg15)</em>, but how much it fosters altruistic behaviour.</p>\n<p><strong> </strong></p>\n<p><strong>9) Conclusions</strong></p>\n<p>I haven't written yet, so I don't have any!</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Bibliography (<sub>Only of the part already written, obviously</sub>):</p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Cantor, M., &amp; Whitehead, H. (2013). The interplay between social networks and culture: theoretically and among whales and dolphins.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Philosophical Transactions of the Royal Society B: Biological Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">368</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(1618).</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1996). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Darwin's dangerous idea: Evolution and the meanings of life </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(No. 39). Simon &amp; Schuster.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1992). The self as a center of narrative gravity.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Self and consciousness: Multiple perspectives</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">.</span></span></span></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Galef Jr, B. G., &amp; Laland, K. N. (2005). Social learning in animals: empirical studies and theoretical models.&nbsp;</span>Bioscience<span style=\"font-style: normal;\">,&nbsp;</span>55<span style=\"font-style: normal;\">(6), 489-499.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Hauert, C., Traulsen, A., Brandt, H., Nowak, M. A., &amp; Sigmund, K. (2007). Via freedom to coercion: the emergence of costly punishment.&nbsp;</span>science<span style=\"font-style: normal;\">,&nbsp;</span>316<span style=\"font-style: normal;\">(5833), 1905-1907.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Henrich, J., Boyd, R., &amp; Richerson, P. J. (2008). Five misunderstandings about cultural evolution. </span>Human Nature<span style=\"font-style: normal;\">, </span>19<span style=\"font-style: normal;\">(2), 119-137.</span></span></em></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Hofstadter, D. R. (2007). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">I am a Strange Loop</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Basic Books</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-weight: normal;\"><br /><br /></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">McElreath, R., &amp; Boyd, R. (2007).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Mathematical models of social evolution: A guide for the perplexed</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Ottoni, E. B., de Resende, B. D., &amp; Izar, P. (2005). Watching the best nutcrackers: what capuchin monkeys (Cebus apella) know about others&rsquo; tool-using skills.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Animal cognition</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">8</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(4), 215-219.<br /></span></span></span><br /><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Persson, I., &amp; Savulescu, J. Unfit for the Future: The Need for Moral Enhancement Oxford: Oxford University Press, 2012 ISBN 978-0199653645 (HB)&pound; 21.00. 160pp. On the brink of civil war, Abraham Lincoln stood on the steps of the US Capitol and appealed.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Pinker, S. (2007).&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">The stuff of thought: Language as a window into human nature</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Viking Adult.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Rendella, L., &amp; Whitehead, H. (2001). Culture in whales and dolphins.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and Brain Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">24</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">, 309-382.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Richardson, P. J., &amp; Boyd, R. (2005). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Not by genes alone</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tyler, T. (2011).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Memetics: Memes and the Science of Cultural Evolution</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Tim Tyler.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tomasello, M., Carpenter, M., Call, J., Behne, T., &amp; Moll, H. (2005). Understanding and sharing intentions: The origins of cultural cognition.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and brain sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">28</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(5), 675-690.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Yudkowsky, E. (2008A). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">37 ways words can be wrong. </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Available at http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/</span></span></span></span></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Qz3A6hQ8RWGXZWoj4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -5, "extendedScore": null, "score": 1.2462173409267125e-06, "legacy": true, "legacyId": "23100", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<address>This is a multi-purpose essay-on-the-making, it is being written aiming at the following goals 1) Mandatory essay writing at the end of a semester studying \"Cognitive Ethology: Culture in Human and Non-Human Animals\" 2) Drafting something that can later on be published in a journal that deals with cultural evolution, hopefully inclining people in the area to glance at future oriented research, i.e. FAI and global coordination 3) Publishing it in Lesswrong and 4) Ultimately <a href=\"/lw/373/how_to_save_the_world/\">Saving the World</a>, as everything should. If it's worth doing, it's worth doing in the way most likely to save the World. </address><address>Since many of <a href=\"/lw/g87/calibrating_against_undetectable_utilons_and_goal/\">my writings</a> are frequently too long for Lesswrong, I'll publish this in a sequence-like form made of self-contained chunks. My deadline is Sunday, so I'll probably post daily, editing/creating the new sessions based on previous commentary. <br></address>\n<p><br>Abstract: The study of cultural evolution has drawn much of its momentum from academic areas far removed from human and animal psychology, specially regarding the evolution of cooperation. Game theoretic results and parental investment theory come from economics, kin selection models from biology, and an ever growing amount of models describing the process of cultural evolution in general, and the evolution of altruism in particular come from mathematics. Even from Artificial Intelligence interest has been cast on how to create agents that can communicate, imitate and cooperate. In this article I begin to tackle the '<em>why?</em>' question. By trying to retrospectively make sense of the convergence of all these fields, I contend that further refinements in these fields <em>should</em> be directed towards understanding how to create environmental incentives fostering cooperation.</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #4e4e4e; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 18px; orphans: auto; text-align: -webkit-left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\"><em>We need systems that are wiser than we are. We need institutions and cultural norms that make us better than we tend to be. It seems to me that the greatest challenge we now face is to build them. - Sam Harris, 2013, The Power Of Bad Incentives</em><br></span></p>\n</blockquote>\n<p><strong id=\"1__Introduction\">1) Introduction</strong></p>\n<p><strong id=\"2__Cultures_evolve\">2) Cultures evolve</strong></p>\n<p>Culture is perhaps the most remarkable outcome of the evolutionary algorithm (Dennett, 1996) so far. It is the cradle of most things we consider <em>humane</em> - that is, typically human <em>and </em>valuable - and it surrounds our lives to the point that we may be thought of as creatures made of culture even more than creatures of bone and flesh (Hofstadter, 2007; Dennett, 1992). The appearance of our cultural complexity has relied on many associated capacities, among them:</p>\n<p>1) The ability to observe, be interested by, and go nearby an individual doing something interesting, an ability we share with norway rats, crows, and even lemurs (Galef &amp; Laland, 2005).</p>\n<p>2) Ability to learn from and scrounge the food of whoever knows how to get food, shared by capuchin monkeys (Ottoni et al, 2005).</p>\n<p>3) Ability to tolerate learners, to accept learners, and to socially learn, probably shared by animals as diverse as fish, finches and Fins (Galef &amp; Laland, 2005).</p>\n<p>4) Understanding and emulating other minds - Theory of Mind- empathizing, relating, perhaps re-framing an experience <em>as one's own</em>, shared by chimpanzees, dogs, and at least some cetaceans (Rendella &amp; Whitehead, 2001).</p>\n<p>5) Learning the program level description of the action of others, for which the evidence among other animals is controversial (but see Cantor &amp; Whitehead, 2013). And finally...</p>\n<p>6) Sharing intentions. Intricate understanding of how two minds can collaborate with complementary tasks to achieve a mutually agreed goal (Tomasello et al, 2005).</p>\n<p>Irrespective of definitional disputes around the <em>true meaning </em>of the word \"culture\" (which doesn't exist, see e.g. Pinker, 2007 pg115; Yudkowsky <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">2008A</a>), each of these is more cognitively complex than its predecessor, and even (1) is sufficient for intra-specific non-environmental, non-genetic behavioral variation, which I will call \"culture\" here, whoever it may harm.</p>\n<p>By transitivity, (2-6) allow the development of culture. It is interesting to notice that tool use, frequently but falsely cited as the hallmark of culture, is ubiquitously equiprobable in the animal kingdom. A graph showing, per biological family, which species shows tool use gives us a power law distribution, whose similarity with the universal prior will help in understanding that being from a family where a species uses tools tells us very little about a specie's own tool use (Michael Haslam, personal conversation).</p>\n<p>Once some of those abilities are available, and given an amount of environmental facilities, need, and randomness, cultures begin to form. Occasionally, so do more developed traditions. Be it by imitation, program level imitation, goal emulation or intention sharing, information is transmitted between agents giving rise to elements sufficient to constitute a primeval Darwinian soup. That is, entities form such that they exhibit 1)Variation 2)Heredity or replication 3)Differential fitness (Dennett, 1996). In light of the article <em>Five Misunderstandings About Cultural Evolution </em>(Henrich, Boyd &amp; Richerson, 2008)<em> </em>we can improve Dennett's conditions for the evolutionary algorithm as 1)Discrete or continuous variation 2)Heredity, replication, or less faithful replication plus content attractors 3)Differential fitness. Once this set of conditions is met, an evolutionary algorithm, or many, begin to carve their optimizing paws into whatever surpassed the threshold for long enough. Cultures, therefore, evolve.&nbsp;</p>\n<p>The intricacies of cultural evolution and mathematical and computational models of how cultures evolve have been the subject of much interdisciplinary research, for an extensive account of human culture see <em>Not By Genes Alone</em> (Richerson &amp; Boyd, 2005). For computational models of social evolution, there is work by Mesoudi, Novak, and others e.g<em>.</em> (Hauert et al, 2007). For mathematical models, the aptly named <em>Mathematical models of social evolution: A guide for the perplexed </em>by McElrath and Rob Boyd (2007) makes the textbook-style walk-through. For animal culture, see (Laland &amp; Galef, 2009).</p>\n<p>Cultural evolution satisfies David Deutsch's criterion for existence, it <em>kicks back</em>, it satisfies the evolutionary equivalent of the&nbsp; condition posed by the Quine-Putnam Indispensability argument in mathematics, i.e. it is a <em>sine qua non</em> condition for understanding how the World works nomologically. It is falsifiable to Popperian content, and it inflates the Worlds ontology a little, by inserting a new kind of \"replicator\", the meme. Contrary to what happened on the internet, the name 'meme' has lost much of it's appeal within cultural evolution theorists, and \"memetics\" is considered by some to refer only to the study of memes as monolithic atomic high fidelity replicators, which would make the theory obsolete. This has created the following conundrum: the name 'meme' remains by far the most well known one to speak of \"that which evolves culturally\" within, and specially outside, the specialist arena. Further, the niche occupied by the word 'meme' is so conceptually necessary within the area to communicate and explain that it is frequently put under scare quotes, or some other informal excuse. In fact, as argued by Tim Tyler - who frequently posts here - in the very sharp<em> Memetics</em> (2010), there are nearly no reasons to try to abandon the 'meme' meme, and nearly all reasons (practicality, Qwerty reasons, mnemonics) to keep it. To avoid contradicting the evidence ever since Dawkins first coined the term, I suggest we must redefine <em>Meme</em> as <em>an attractor in cultural evolution (dual-inheritance) whose development over time structurally mimics to a significant extent the discrete behavior of genes</em>, <em>frequently coinciding with the smallest unit of cultural replication.</em> The definition is long, but the idea is simple: Memes are not the best analogues of genes because they are discrete units that replicate just like genes, but because they are continuous conceptual clusters being attracted <em>to a point in conceptual space whose replication is just like that of genes</em>. Even more simply, memes are the mathematically closest things to genes in cultural evolution. So the suggestion here is for researchers of dual-inheritance and cultural evolution to take off the scare quotes of our memes and keep business as usual. <em>&nbsp; </em></p>\n<p>The evolutionary algorithm has created a new attractor-replicator, the meme, it didn't privilege with it any specific families in the biological trees and it ended up creating a process of cultural-genetic coevolution known as dual-inheritance. This process has been studied in ever more quantified ways by primatologists, behavioral ecologists, population biologists, anthropologists, ethologists, sociologists, neuroscientists and even philosophers. I've shown at least six distinct abilities which helped scaffold our astounding level of cultural intricacy, and some animals who share them with us. We will now take a look at the evolution of cooperation, collaboration, altruism, moral behavior, a sub-area of cultural evolution that saw an explosion of interest and research during the last decade, with publications (most from the last 4 years) such as <em>The Origins of Morality, Supercooperators, Good and Real, The Better Angels of Our Nature, Non-Zero, The Moral Animal, Primates and Philosophers</em>, <em>The Age of Empathy, Origins of Altruism and Cooperation, The Altruism Equation, Altruism in Humans, Cooperation and Its Evolution, Moral Tribes, The Expanding Circle, The Moral Landscape. <br></em></p>\n<p><em> </em></p>\n<p><strong id=\"3__Cooperation_evolves\">3) Cooperation evolves</strong></p>\n<p>Shortly describe why and show some inequations under which cooperation is an equelibrium, or at least an Evolutionarily Stable Strategy.</p>\n<p><strong id=\"4__The_complexity_of_cultural_items_doesn_t_undermine_the_validity_of_mathematical_models_\">4) The complexity of cultural items doesn't undermine the validity of mathematical models.</strong></p>\n<p><strong> </strong></p>\n<p><strong id=\"_4_1__Cognitive_attractors_and_biases_substitute_for_memes_discreteness\">&nbsp;4.1) Cognitive attractors and biases substitute for memes discreteness</strong></p>\n<p>The math becomes equivalent.</p>\n<p><strong> </strong></p>\n<p><strong id=\"_4_2__Despite_the_Unilateralist_Curse_and_the_Tragedy_of_the_Commons__dyadic_interaction_models_help_us_understand_large_scale_cooperation\">&nbsp;4.2) Despite the Unilateralist Curse and the Tragedy of the Commons, dyadic interaction models help us understand large scale cooperation</strong></p>\n<p>Once we know these two failure modes, dyadic iterated (or reputation-sensitive) interaction is close enough.</p>\n<p><strong> </strong></p>\n<p><strong id=\"5__From_Monkeys_to_Apes_to_Humans_to_Transhumans_to_AIs__the_ranges_of_achievable_altruistic_skill_\">5) From Monkeys to Apes to Humans to Transhumans to AIs, the ranges of achievable altruistic skill.</strong></p>\n<p>Possible modes of being altruistic. Graph like <a href=\"http://www.posthumanism.com/space5.jpg\">Bostrom's</a>. Second and third order punishment and cooperation. Newcomb-like signaling problems within AI.</p>\n<p><strong> </strong></p>\n<p><strong id=\"6__Unfit_for_the_Future__the_need_for_greater_altruism_\">6) Unfit for the Future: the need for greater altruism.</strong></p>\n<p>We fail and will remain failing in Tragedy of the Commons problems unless we change our nature.</p>\n<p><strong> </strong></p>\n<p><strong id=\"7__From_Science__through_Philosophy__towards_Engineering__the_future_of_studies_of_altruism_\">7) From Science, through Philosophy, towards Engineering: the future of studies of altruism.</strong></p>\n<p>Philosophy: Existential Risk <a href=\"http://www.existential-risk.org/concept.html\">prevention through global coordination</a> and cooperation prior to technical maturity. Engineering Humans: creating enhancements and changing incentives. Engineering AI's: making them <a href=\"http://intelligence.org/files/RobustCooperation.pdf\">better</a> and <a href=\"https://www.youtube.com/watch?v=MwriJqBZyoM\">realer</a>.</p>\n<p><strong> </strong></p>\n<p><strong id=\"8__A_different_kind_of_Moral_Landscape\">8) A different kind of Moral Landscape</strong></p>\n<p>Like Sam Harris's one, except comparing not how much a society approaches <em>The Good Life (Moral Landscape pg15)</em>, but how much it fosters altruistic behaviour.</p>\n<p><strong> </strong></p>\n<p><strong id=\"9__Conclusions\">9) Conclusions</strong></p>\n<p>I haven't written yet, so I don't have any!</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p>Bibliography (<sub>Only of the part already written, obviously</sub>):</p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Cantor, M., &amp; Whitehead, H. (2013). The interplay between social networks and culture: theoretically and among whales and dolphins.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Philosophical Transactions of the Royal Society B: Biological Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">368</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(1618).</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1996). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Darwin's dangerous idea: Evolution and the meanings of life </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(No. 39). Simon &amp; Schuster.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1992). The self as a center of narrative gravity.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Self and consciousness: Multiple perspectives</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">.</span></span></span></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Galef Jr, B. G., &amp; Laland, K. N. (2005). Social learning in animals: empirical studies and theoretical models.&nbsp;</span>Bioscience<span style=\"font-style: normal;\">,&nbsp;</span>55<span style=\"font-style: normal;\">(6), 489-499.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Hauert, C., Traulsen, A., Brandt, H., Nowak, M. A., &amp; Sigmund, K. (2007). Via freedom to coercion: the emergence of costly punishment.&nbsp;</span>science<span style=\"font-style: normal;\">,&nbsp;</span>316<span style=\"font-style: normal;\">(5833), 1905-1907.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Henrich, J., Boyd, R., &amp; Richerson, P. J. (2008). Five misunderstandings about cultural evolution. </span>Human Nature<span style=\"font-style: normal;\">, </span>19<span style=\"font-style: normal;\">(2), 119-137.</span></span></em></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Hofstadter, D. R. (2007). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">I am a Strange Loop</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Basic Books</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-weight: normal;\"><br><br></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">McElreath, R., &amp; Boyd, R. (2007).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Mathematical models of social evolution: A guide for the perplexed</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Ottoni, E. B., de Resende, B. D., &amp; Izar, P. (2005). Watching the best nutcrackers: what capuchin monkeys (Cebus apella) know about others\u2019 tool-using skills.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Animal cognition</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">8</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(4), 215-219.<br></span></span></span><br><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Persson, I., &amp; Savulescu, J. Unfit for the Future: The Need for Moral Enhancement Oxford: Oxford University Press, 2012 ISBN 978-0199653645 (HB)\u00a3 21.00. 160pp. On the brink of civil war, Abraham Lincoln stood on the steps of the US Capitol and appealed.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Pinker, S. (2007).&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">The stuff of thought: Language as a window into human nature</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Viking Adult.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Rendella, L., &amp; Whitehead, H. (2001). Culture in whales and dolphins.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and Brain Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">24</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">, 309-382.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Richardson, P. J., &amp; Boyd, R. (2005). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Not by genes alone</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tyler, T. (2011).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Memetics: Memes and the Science of Cultural Evolution</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Tim Tyler.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tomasello, M., Carpenter, M., Call, J., Behne, T., &amp; Moll, H. (2005). Understanding and sharing intentions: The origins of cultural cognition.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and brain sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">28</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(5), 675-690.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Yudkowsky, E. (2008A). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">37 ways words can be wrong. </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Available at http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/</span></span></span></span></span></span></p>", "sections": [{"title": "1) Introduction", "anchor": "1__Introduction", "level": 1}, {"title": "2) Cultures evolve", "anchor": "2__Cultures_evolve", "level": 1}, {"title": "3) Cooperation evolves", "anchor": "3__Cooperation_evolves", "level": 1}, {"title": "4) The complexity of cultural items doesn't undermine the validity of mathematical models.", "anchor": "4__The_complexity_of_cultural_items_doesn_t_undermine_the_validity_of_mathematical_models_", "level": 1}, {"title": "\u00a04.1) Cognitive attractors and biases substitute for memes discreteness", "anchor": "_4_1__Cognitive_attractors_and_biases_substitute_for_memes_discreteness", "level": 1}, {"title": "\u00a04.2) Despite the Unilateralist Curse and the Tragedy of the Commons, dyadic interaction models help us understand large scale cooperation", "anchor": "_4_2__Despite_the_Unilateralist_Curse_and_the_Tragedy_of_the_Commons__dyadic_interaction_models_help_us_understand_large_scale_cooperation", "level": 1}, {"title": "5) From Monkeys to Apes to Humans to Transhumans to AIs, the ranges of achievable altruistic skill.", "anchor": "5__From_Monkeys_to_Apes_to_Humans_to_Transhumans_to_AIs__the_ranges_of_achievable_altruistic_skill_", "level": 1}, {"title": "6) Unfit for the Future: the need for greater altruism.", "anchor": "6__Unfit_for_the_Future__the_need_for_greater_altruism_", "level": 1}, {"title": "7) From Science, through Philosophy, towards Engineering: the future of studies of altruism.", "anchor": "7__From_Science__through_Philosophy__towards_Engineering__the_future_of_studies_of_altruism_", "level": 1}, {"title": "8) A different kind of Moral Landscape", "anchor": "8__A_different_kind_of_Moral_Landscape", "level": 1}, {"title": "9) Conclusions", "anchor": "9__Conclusions", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 13}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TrmMcujGZt5JAtMGg", "GjXeKTxkYvZ5WfkFu", "FaJaCgqBKphrDzDSj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T11:57:56.464Z", "modifiedAt": null, "url": null, "title": "James Martin's death", "slug": "james-martin-s-death", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YyHgrvRxTZX8esbzD/james-martin-s-death", "pageUrlRelative": "/posts/YyHgrvRxTZX8esbzD/james-martin-s-death", "linkUrl": "https://www.lesswrong.com/posts/YyHgrvRxTZX8esbzD/james-martin-s-death", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20James%20Martin's%20death&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJames%20Martin's%20death%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYyHgrvRxTZX8esbzD%2Fjames-martin-s-death%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=James%20Martin's%20death%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYyHgrvRxTZX8esbzD%2Fjames-martin-s-death", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYyHgrvRxTZX8esbzD%2Fjames-martin-s-death", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 365, "htmlBody": "<p>From the <a href=\"http://www.oxfordmartin.ox.ac.uk/\">Martin School website</a>:</p>\n<p>Dr James Martin 1933 - 2013</p>\n<p>&nbsp;<img src=\"http://www.oxfordmartin.ox.ac.uk/images/system/jm640.jpg\" alt=\"Dr James Martin\" /></p>\n<p>It is with great sadness that the Oxford Martin School has learned of the death of our Founder, Dr James Martin.</p>\n<p>James Martin was an inspiration to millions &ndash; an extraordinary intellect, with wide-ranging interests, boundless energy and an unwavering commitment to addressing the greatest challenges facing humanity. For 25 years Martin was the highest-selling author of books on computing and related technology. He wrote a record 104 books, many of which have been seminal in their field, and was renowned for his electrifying lectures about the future. He was a Pulitzer nominee for his book The Wired Society.</p>\n<p>James Martin was a passionate advocate of the power of ideas, and provided the largest benefaction to the University of Oxford in its 900-year history in order to create the Oxford Martin School. Professor Andrew Hamilton, the Vice-Chancellor of the University, said &ldquo;James Martin was a true visionary whose exceptional generosity established the Oxford Martin School, allowing researchers from across the disciplines to work together on the most pressing challenges and opportunities facing humanity. His impact will be felt for generations to come, as through the School he has enabled researchers to address the biggest questions of the 21st century.&rdquo;</p>\n<p>The School is his permanent legacy and a fitting tribute &ndash; a flourishing, vibrant community of the world&rsquo;s leading minds, coming together to change the world for the better. He enjoyed the excitement and happy atmosphere of the School, and his kind and unfailingly courteous manner was greatly appreciated by all who spent time with him. The Director of the School, Professor Ian Goldin, said &ldquo;The Oxford Martin School embodies Jim&rsquo;s concern for humanity, his creativity, his curiosity, and his optimism. Jim provided not only the founding vision, but was intimately involved with the School and our many programmes. We have lost a towering intellect, guiding visionary and a wonderful close friend.&rdquo;</p>\n<p>25th June 2013</p>\n<p>&nbsp;</p>\n<p>On a personal note, I met James Martin a couple of times, and he was always interested in pushing the boundaries of our knowledge and predictive power, and helping the human race. Without him, there would have been no FHI. We've lost a great contributor.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YyHgrvRxTZX8esbzD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 23, "baseScore": 33, "extendedScore": null, "score": 1.246488355193188e-06, "legacy": true, "legacyId": "23115", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T15:17:13.411Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm", "slug": "meetup-melbourne-lw-outing-astronomy-evening-in-eltham", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BraydenM", "createdAt": "2013-06-10T09:17:31.294Z", "isAdmin": false, "displayName": "BraydenM"}, "userId": "KBZHqcMC6z2rPZkZK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9CErxqv8LPCZmx8so/meetup-melbourne-lw-outing-astronomy-evening-in-eltham", "pageUrlRelative": "/posts/9CErxqv8LPCZmx8so/meetup-melbourne-lw-outing-astronomy-evening-in-eltham", "linkUrl": "https://www.lesswrong.com/posts/9CErxqv8LPCZmx8so/meetup-melbourne-lw-outing-astronomy-evening-in-eltham", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20LW%20Outing%3A%20Astronomy%20evening%20in%20Eltham%2C%20Saturday%2029th%20June%2C%205%3A30pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20LW%20Outing%3A%20Astronomy%20evening%20in%20Eltham%2C%20Saturday%2029th%20June%2C%205%3A30pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9CErxqv8LPCZmx8so%2Fmeetup-melbourne-lw-outing-astronomy-evening-in-eltham%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20LW%20Outing%3A%20Astronomy%20evening%20in%20Eltham%2C%20Saturday%2029th%20June%2C%205%3A30pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9CErxqv8LPCZmx8so%2Fmeetup-melbourne-lw-outing-astronomy-evening-in-eltham", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9CErxqv8LPCZmx8so%2Fmeetup-melbourne-lw-outing-astronomy-evening-in-eltham", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 219, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o7'>Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">29 June 2013 05:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">54 Scenic Crescent Eltham North Victoria Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This event replaces the cancelled rock climbing event.</p>\n\n<hr />\n\n<p>Come to my place this Saturday 29th June at sunset for an casual evening of astronomy. I will host a tour of the solar system and the cosmos from 5:30pm to late. We should be able to see Venus, the Milky Way and Magellenic clouds, the rings and moons of Saturn, and a bunch of nebulae and clusters. There is a 30% chance of cloud cover according to <a href=\"http://www.skippysky.com.au/Australia/\" rel=\"nofollow\">http://www.skippysky.com.au/Australia/</a> and <a href=\"http://weatherspark.com/#!dashboard;q=melbourne,\" rel=\"nofollow\">http://weatherspark.com/#!dashboard;q=melbourne,</a> so we will have backup plans if it clouds over. We have a big house so if you want to bring food to cook for dinner and/or a sleeping bag and gear to stay the night then feel free. Plenty of car parking at the top of the driveway, and use a GPS to avoid getting lost. If coming by public transport call my mobile and I'll pick you up from Eltham train station. Guests can stay until 8:30am Sunday morning. Please call me on 0407943917 for last minute RSVPs, or for directions.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o7'>Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9CErxqv8LPCZmx8so", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2466429584607766e-06, "legacy": true, "legacyId": "23116", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_LW_Outing__Astronomy_evening_in_Eltham__Saturday_29th_June__5_30pm\">Discussion article for the meetup : <a href=\"/meetups/o7\">Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">29 June 2013 05:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">54 Scenic Crescent Eltham North Victoria Australia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This event replaces the cancelled rock climbing event.</p>\n\n<hr>\n\n<p>Come to my place this Saturday 29th June at sunset for an casual evening of astronomy. I will host a tour of the solar system and the cosmos from 5:30pm to late. We should be able to see Venus, the Milky Way and Magellenic clouds, the rings and moons of Saturn, and a bunch of nebulae and clusters. There is a 30% chance of cloud cover according to <a href=\"http://www.skippysky.com.au/Australia/\" rel=\"nofollow\">http://www.skippysky.com.au/Australia/</a> and <a href=\"http://weatherspark.com/#!dashboard;q=melbourne,\" rel=\"nofollow\">http://weatherspark.com/#!dashboard;q=melbourne,</a> so we will have backup plans if it clouds over. We have a big house so if you want to bring food to cook for dinner and/or a sleeping bag and gear to stay the night then feel free. Plenty of car parking at the top of the driveway, and use a GPS to avoid getting lost. If coming by public transport call my mobile and I'll pick you up from Eltham train station. Guests can stay until 8:30am Sunday morning. Please call me on 0407943917 for last minute RSVPs, or for directions.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_LW_Outing__Astronomy_evening_in_Eltham__Saturday_29th_June__5_30pm1\">Discussion article for the meetup : <a href=\"/meetups/o7\">Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm", "anchor": "Discussion_article_for_the_meetup___Melbourne_LW_Outing__Astronomy_evening_in_Eltham__Saturday_29th_June__5_30pm", "level": 1}, {"title": "Discussion article for the meetup : Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm", "anchor": "Discussion_article_for_the_meetup___Melbourne_LW_Outing__Astronomy_evening_in_Eltham__Saturday_29th_June__5_30pm1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T17:20:10.823Z", "modifiedAt": null, "url": null, "title": "Public Service Announcement Collection", "slug": "public-service-announcement-collection", "viewCount": null, "lastCommentedAt": "2016-07-05T17:34:22.374Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MxHQr33zRmozjmJzD/public-service-announcement-collection", "pageUrlRelative": "/posts/MxHQr33zRmozjmJzD/public-service-announcement-collection", "linkUrl": "https://www.lesswrong.com/posts/MxHQr33zRmozjmJzD/public-service-announcement-collection", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Public%20Service%20Announcement%20Collection&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APublic%20Service%20Announcement%20Collection%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMxHQr33zRmozjmJzD%2Fpublic-service-announcement-collection%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Public%20Service%20Announcement%20Collection%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMxHQr33zRmozjmJzD%2Fpublic-service-announcement-collection", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMxHQr33zRmozjmJzD%2Fpublic-service-announcement-collection", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 277, "htmlBody": "<p>P/S/A: &nbsp;There are single sentences which can create life-changing amounts of difference.</p>\n<ul>\n<li>P/S/A: &nbsp;If you're not sure whether or not you've ever had an orgasm, it means you haven't had one, a condition known as <a href=\"http://en.wikipedia.org/wiki/Anorgasmia\">primary anorgasmia</a> which is 90% treatable by cognitive-behavioral therapy.</li>\n<li>P/S/A: &nbsp;The people telling you to expect above-trend inflation when the Federal Reserve started printing money a few years back, disagreed with the market forecasts, disagreed with standard economics, turned out to be actually wrong in reality, and were wrong for <a href=\"http://en.wikipedia.org/wiki/Market_monetarism\">reasonably fundamental reasons</a> so don't buy gold when they tell you to.</li>\n<li>P/S/A: &nbsp;There are many many more submissive/masochistic men in the world than there are dominant/sadistic women, so if you are a woman who feels a strong temptation to command men and inflict pain on them, and you want a large harem of men serving your every need, it will suffice to state this fact anywhere on the Internet and you will have fifty applications by the next morning.</li>\n<li>P/S/A: &nbsp;Most of the personal-finance-advice industry is parasitic and/or self-deluded, and it's generally agreed on by economic theory and experimental measurement that an index fund will deliver the best returns you can get without huge amounts of effort.</li>\n<li>P/S/A: &nbsp;If you are smart and underemployed, you can very quickly check to see if you are a natural computer programmer by pulling up a page of Python source code and seeing whether it looks like it makes natural sense, and if this is the case you can teach yourself to program very quickly and get a much higher-paying job even without formal credentials.</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "Tg9aFPFCPBHxGABRr": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MxHQr33zRmozjmJzD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 51, "baseScore": 55, "extendedScore": null, "score": 0.00022, "legacy": true, "legacyId": "23117", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 330, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2013-06-27T17:20:10.823Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T22:15:03.465Z", "modifiedAt": null, "url": null, "title": "[META] Make poll results accessible to people who have not voted", "slug": "meta-make-poll-results-accessible-to-people-who-have-not", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:31.604Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sp4233", "createdAt": "2013-06-27T20:47:33.614Z", "isAdmin": false, "displayName": "sp4233"}, "userId": "SCFriyfMt6XzTZ3a8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nGHY8a29HfdnsPX3c/meta-make-poll-results-accessible-to-people-who-have-not", "pageUrlRelative": "/posts/nGHY8a29HfdnsPX3c/meta-make-poll-results-accessible-to-people-who-have-not", "linkUrl": "https://www.lesswrong.com/posts/nGHY8a29HfdnsPX3c/meta-make-poll-results-accessible-to-people-who-have-not", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BMETA%5D%20Make%20poll%20results%20accessible%20to%20people%20who%20have%20not%20voted&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BMETA%5D%20Make%20poll%20results%20accessible%20to%20people%20who%20have%20not%20voted%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnGHY8a29HfdnsPX3c%2Fmeta-make-poll-results-accessible-to-people-who-have-not%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BMETA%5D%20Make%20poll%20results%20accessible%20to%20people%20who%20have%20not%20voted%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnGHY8a29HfdnsPX3c%2Fmeta-make-poll-results-accessible-to-people-who-have-not", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnGHY8a29HfdnsPX3c%2Fmeta-make-poll-results-accessible-to-people-who-have-not", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 94, "htmlBody": "<p>As far as I can see, the only way to see the results of a poll is to vote in it. If for whatever reason I don't want to participate in a poll whose results I am interested in, I vote randomly. Of the ~10 other LWers I know, at least 2 do the same. For the sake of accurate results, please let people see poll results without having to vote (and ideally without having to log in).</p>\n<p>Response to obvious argument against: You can restrict people from (voting after they have seen the results).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nGHY8a29HfdnsPX3c", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 24, "extendedScore": null, "score": 1.2469672243157618e-06, "legacy": true, "legacyId": "23118", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-27T23:59:20.715Z", "modifiedAt": null, "url": null, "title": "A total life checklist", "slug": "a-total-life-checklist", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:33.010Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "odm3FHPzgbiGpWsSg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5YWw5Mq9pcoeGofF8/a-total-life-checklist", "pageUrlRelative": "/posts/5YWw5Mq9pcoeGofF8/a-total-life-checklist", "linkUrl": "https://www.lesswrong.com/posts/5YWw5Mq9pcoeGofF8/a-total-life-checklist", "postedAtFormatted": "Thursday, June 27th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20total%20life%20checklist&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20total%20life%20checklist%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5YWw5Mq9pcoeGofF8%2Fa-total-life-checklist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20total%20life%20checklist%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5YWw5Mq9pcoeGofF8%2Fa-total-life-checklist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5YWw5Mq9pcoeGofF8%2Fa-total-life-checklist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 333, "htmlBody": "<p>I came up with an idea today: I think it would be useful to have a list of everything that a typical person ought to do. After all, there is quite a lot of stuff that a typical person ought to do; how else is a person supposed to remember it all?</p>\n<p>Here's what I've come up with so far:</p>\n<h3>Health</h3>\n<ul>\n<li>Eating well.</li>\n<li>Exercising regularly.</li>\n<li>Mitigating common risks in everyday life (e.g. wearing a seat belt while driving).</li>\n<li>Other everyday health stuff (e.g. not sitting down eight hours a day).</li>\n<li>Visiting a doctor, a dentist, and (if necessary) an optometrist on a regular basis.</li>\n<li>Being familiar with common health problems and what to do about them.</li>\n<li>Being able to recognize medical emergencies and react appropriately.</li>\n<li>Maintaining mental health (see also: pretty much this entire list).</li>\n</ul>\n<h3>Money</h3>\n<ul>\n<li>Educating oneself in career-related skills.</li>\n<li>Getting a job and/or becoming self-employed.</li>\n<li>Networking (see also: interpersonal interaction).</li>\n<li>Investing one's savings appropriately.</li>\n</ul>\n<h3>Altruism</h3>\n<ul>\n<li>Donating to charity.</li>\n<li>Volunteering for charity.</li>\n<li>Doing favors for friends.</li>\n</ul>\n<h3>Interpersonal interaction</h3>\n<ul>\n<li>Developing and maintaining relationships with other people: friendly, romantic, family, others?</li>\n<li>Discussion of useful topics.</li>\n</ul>\n<h3>Recreation</h3>\n<ul>\n<li>Hobbies, finding ways to enjoy yourself. (I'm not sure how to expand on this one.)</li>\n</ul>\n<h3>Responsibilities</h3>\n<ul>\n<li>Any responsibilities one has signed up for.</li>\n</ul>\n<h3>Productivity</h3>\n<ul>\n<li>Developing and maintaining one's ability to get stuff done. (Kinda vague, this one.)</li>\n<li>Maintaining a list of what needs to be done.</li>\n<li>Making good decisions about what to do. In particular, which of the items on this list to focus on and how to accomplish them. </li>\n</ul>\n<h3>Skills</h3>\n<ul>\n<li>Developing the skills one needs to carry out these tasks effectively, through education, experience, and discussion.</li>\n</ul>\n<div>\n<hr />\n</div>\n<p>Anyone have any suggestions for additions or improvements?</p>\n<p><em>edit 1: some suggestions by Rain and aelephant</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5YWw5Mq9pcoeGofF8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 8, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "23119", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I came up with an idea today: I think it would be useful to have a list of everything that a typical person ought to do. After all, there is quite a lot of stuff that a typical person ought to do; how else is a person supposed to remember it all?</p>\n<p>Here's what I've come up with so far:</p>\n<h3 id=\"Health\">Health</h3>\n<ul>\n<li>Eating well.</li>\n<li>Exercising regularly.</li>\n<li>Mitigating common risks in everyday life (e.g. wearing a seat belt while driving).</li>\n<li>Other everyday health stuff (e.g. not sitting down eight hours a day).</li>\n<li>Visiting a doctor, a dentist, and (if necessary) an optometrist on a regular basis.</li>\n<li>Being familiar with common health problems and what to do about them.</li>\n<li>Being able to recognize medical emergencies and react appropriately.</li>\n<li>Maintaining mental health (see also: pretty much this entire list).</li>\n</ul>\n<h3 id=\"Money\">Money</h3>\n<ul>\n<li>Educating oneself in career-related skills.</li>\n<li>Getting a job and/or becoming self-employed.</li>\n<li>Networking (see also: interpersonal interaction).</li>\n<li>Investing one's savings appropriately.</li>\n</ul>\n<h3 id=\"Altruism\">Altruism</h3>\n<ul>\n<li>Donating to charity.</li>\n<li>Volunteering for charity.</li>\n<li>Doing favors for friends.</li>\n</ul>\n<h3 id=\"Interpersonal_interaction\">Interpersonal interaction</h3>\n<ul>\n<li>Developing and maintaining relationships with other people: friendly, romantic, family, others?</li>\n<li>Discussion of useful topics.</li>\n</ul>\n<h3 id=\"Recreation\">Recreation</h3>\n<ul>\n<li>Hobbies, finding ways to enjoy yourself. (I'm not sure how to expand on this one.)</li>\n</ul>\n<h3 id=\"Responsibilities\">Responsibilities</h3>\n<ul>\n<li>Any responsibilities one has signed up for.</li>\n</ul>\n<h3 id=\"Productivity\">Productivity</h3>\n<ul>\n<li>Developing and maintaining one's ability to get stuff done. (Kinda vague, this one.)</li>\n<li>Maintaining a list of what needs to be done.</li>\n<li>Making good decisions about what to do. In particular, which of the items on this list to focus on and how to accomplish them. </li>\n</ul>\n<h3 id=\"Skills\">Skills</h3>\n<ul>\n<li>Developing the skills one needs to carry out these tasks effectively, through education, experience, and discussion.</li>\n</ul>\n<div>\n<hr>\n</div>\n<p>Anyone have any suggestions for additions or improvements?</p>\n<p><em>edit 1: some suggestions by Rain and aelephant</em></p>", "sections": [{"title": "Health", "anchor": "Health", "level": 1}, {"title": "Money", "anchor": "Money", "level": 1}, {"title": "Altruism", "anchor": "Altruism", "level": 1}, {"title": "Interpersonal interaction", "anchor": "Interpersonal_interaction", "level": 1}, {"title": "Recreation", "anchor": "Recreation", "level": 1}, {"title": "Responsibilities", "anchor": "Responsibilities", "level": 1}, {"title": "Productivity", "anchor": "Productivity", "level": 1}, {"title": "Skills", "anchor": "Skills", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "16 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T05:28:46.321Z", "modifiedAt": null, "url": null, "title": "Common failure modes in habit formation", "slug": "common-failure-modes-in-habit-formation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:06.178Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RomeoStevens", "createdAt": "2011-10-28T20:59:30.426Z", "isAdmin": false, "displayName": "RomeoStevens"}, "userId": "5ZpAE3i54eEhMp2ib", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PYgGpmmk3wQhSt6Yv/common-failure-modes-in-habit-formation", "pageUrlRelative": "/posts/PYgGpmmk3wQhSt6Yv/common-failure-modes-in-habit-formation", "linkUrl": "https://www.lesswrong.com/posts/PYgGpmmk3wQhSt6Yv/common-failure-modes-in-habit-formation", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Common%20failure%20modes%20in%20habit%20formation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACommon%20failure%20modes%20in%20habit%20formation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPYgGpmmk3wQhSt6Yv%2Fcommon-failure-modes-in-habit-formation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Common%20failure%20modes%20in%20habit%20formation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPYgGpmmk3wQhSt6Yv%2Fcommon-failure-modes-in-habit-formation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPYgGpmmk3wQhSt6Yv%2Fcommon-failure-modes-in-habit-formation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 865, "htmlBody": "<blockquote>\n<p>In one project, 256 members of a health-insurance plan were invited to classes stressing the importance of exercise. Half the participants received an extra lesson on the theories of habit formation (the structure of the habit loop) and were asked to identify cues and rewards that might help them develop exercise routines.</p>\n<p>The results were dramatic. Over the next four months, those participants who deliberately identified cues and rewards spent twice as much time exercising as their peers. Other studies have yielded similar results.</p>\n<p>-<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\"Lifestyle Intervention by Self-Regulation of Action (LISA)\" study by Stadler, Oettinger and Gollwitzer 2005.</span></p>\n</blockquote>\n<p>I don't think this topic needs a huge introduction. &nbsp;Most of us have tried, at some point, to establish a new routine only to have it crash and burn. We came up with and discussed some of the more obvious failure modes at last week's southbay meetup, which generated the material here. &nbsp;It would be awesome to further refine this. &nbsp;Particularly, some overarching ontology of failure modes would be useful for turning them into a more mentally compact checklist. So feedback on how this material can be organized and presented better is most welcome.</p>\n<p><strong>Failure is Always Failure</strong></p>\n<p>\"I would have succeeded if it weren't for those meddling kids!\" The \"perfect plan\" that you can't actually execute on is not the perfect plan. Take responsibility for the failure and figure out what's really going on.&nbsp;</p>\n<p>Mental cue: Bad news is good news.</p>\n<p><strong>Negative Reinforcement</strong></p>\n<p>Taking responsibility for failure doesn't mean beating yourself up over it. If you have bad feelings every time you think about habit X due to past failures you are only reinforcing the act of not thinking about habit X. &nbsp;Failure means you are aware that something went wrong, which means you can improve.</p>\n<p>Mental cue: The process failed, so fix the process. Failure and iteration is part of good processes.</p>\n<p><strong>Perfectionism</strong></p>\n<p>That a good process will yield good results doesn't mean we should fall prey to paralysis by analysis. It also doesn't mean we should give up and go back to the drawing board every time we experience a bump in the road. &nbsp;People commonly engage in visualizing a perfect version of themselves, who obviously wouldn't have failed. &nbsp;This is frustrating, demotivating, and possibly what is going on with the planning fallacy. Notice when you are constructing a fictional narrative about how well it is possible to do. &nbsp;How well would you expect a friend in the same situation to do?</p>\n<p>mental cue: The perfect is the enemy of the good. You are your own worst critic.</p>\n<p><strong>Going too Big too Fast</strong></p>\n<p>In the perfect world of our minds, we choose big, exciting-sounding goals and execute on them flawlessly. We become fit, write the next Pulitzer-winning novel, and found a successful startup. &nbsp;We usually gloss over the fact that getting fit actually means doing pushups, writing a novel involves writing individual pages, and running a successful startup involves emptying your own wastepaper basket. When there is a disconnect between our big goals and everyday actions we don't feel motivated to do those mundane tasks. &nbsp;Goal factoring, and other techniques for connecting our little goals to our big goals help here.</p>\n<p>Mental cue: Granularize</p>\n<p><strong>Assuming Constant Motivation</strong></p>\n<p>When we create sub-goals we choose things we think we can do. \"Of course I can walk 30 minutes everyday.\" We ignore that when we are creating and evaluating plans we are likely to be in a highly motivated mood. Of course everything seems easy when we are in a motivated mood. Apportion your limited budget of highly motivated time to ensuring that you will be surrounded by cues that encourage your new habit, whether this be people, things, or situations. &nbsp;This can be as simple as \"surrounding yourself\" with alarm apps that cue you to do the things you precommitted to doing.</p>\n<p>Mental cue: You are the average of your surroundings.</p>\n<p><strong>Not Quantifying the Results</strong></p>\n<p>Far goals are often qualitative. &nbsp;We're not sure how much we want to improve by, we just know it's a lot. The problem is that qualitative goals aren't very motivating in terms of actual actions. \"I want to get better about responding to emails.\" Notice the word \"better\". Contrast with \"I want to cut the number of emails I don't respond to by 50% over the next 2 weeks.\" Now we're getting somewhere, and we have somewhere to start. This is also related to the concept that motivation is hard to maintain when one of our sub-agents has an objection to what we're doing (usually because they aren't convinced it is a good use of time.)</p>\n<p>Mental cue: Be specific.</p>\n<p><strong>Brittle Plans</strong></p>\n<p>This bit was somewhat disorganized. But it involves having a Plan B, as well as figuring out when you are going to reevaluate and update your plan. Also recognizing that what matters in habit formation is getting it mostly right and one shouldn't give up just because they screwed up one time, or even several times.</p>\n<p><strong>I'm all fired up to form new habits, now what?</strong></p>\n<p>If you don't have anything you're currently working on I suggest instilling the habit of researching new, possibly beneficial habits to have.</p>\n<p>&nbsp;</p>\n<p>Note: In writing this I'm noticing similarity to SMART goals. &nbsp;Perhaps adapting that would be better since it's already nice and memorable.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PYgGpmmk3wQhSt6Yv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 28, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "23123", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p>In one project, 256 members of a health-insurance plan were invited to classes stressing the importance of exercise. Half the participants received an extra lesson on the theories of habit formation (the structure of the habit loop) and were asked to identify cues and rewards that might help them develop exercise routines.</p>\n<p>The results were dramatic. Over the next four months, those participants who deliberately identified cues and rewards spent twice as much time exercising as their peers. Other studies have yielded similar results.</p>\n<p>-<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\"Lifestyle Intervention by Self-Regulation of Action (LISA)\" study by Stadler, Oettinger and Gollwitzer 2005.</span></p>\n</blockquote>\n<p>I don't think this topic needs a huge introduction. &nbsp;Most of us have tried, at some point, to establish a new routine only to have it crash and burn. We came up with and discussed some of the more obvious failure modes at last week's southbay meetup, which generated the material here. &nbsp;It would be awesome to further refine this. &nbsp;Particularly, some overarching ontology of failure modes would be useful for turning them into a more mentally compact checklist. So feedback on how this material can be organized and presented better is most welcome.</p>\n<p><strong id=\"Failure_is_Always_Failure\">Failure is Always Failure</strong></p>\n<p>\"I would have succeeded if it weren't for those meddling kids!\" The \"perfect plan\" that you can't actually execute on is not the perfect plan. Take responsibility for the failure and figure out what's really going on.&nbsp;</p>\n<p>Mental cue: Bad news is good news.</p>\n<p><strong id=\"Negative_Reinforcement\">Negative Reinforcement</strong></p>\n<p>Taking responsibility for failure doesn't mean beating yourself up over it. If you have bad feelings every time you think about habit X due to past failures you are only reinforcing the act of not thinking about habit X. &nbsp;Failure means you are aware that something went wrong, which means you can improve.</p>\n<p>Mental cue: The process failed, so fix the process. Failure and iteration is part of good processes.</p>\n<p><strong id=\"Perfectionism\">Perfectionism</strong></p>\n<p>That a good process will yield good results doesn't mean we should fall prey to paralysis by analysis. It also doesn't mean we should give up and go back to the drawing board every time we experience a bump in the road. &nbsp;People commonly engage in visualizing a perfect version of themselves, who obviously wouldn't have failed. &nbsp;This is frustrating, demotivating, and possibly what is going on with the planning fallacy. Notice when you are constructing a fictional narrative about how well it is possible to do. &nbsp;How well would you expect a friend in the same situation to do?</p>\n<p>mental cue: The perfect is the enemy of the good. You are your own worst critic.</p>\n<p><strong id=\"Going_too_Big_too_Fast\">Going too Big too Fast</strong></p>\n<p>In the perfect world of our minds, we choose big, exciting-sounding goals and execute on them flawlessly. We become fit, write the next Pulitzer-winning novel, and found a successful startup. &nbsp;We usually gloss over the fact that getting fit actually means doing pushups, writing a novel involves writing individual pages, and running a successful startup involves emptying your own wastepaper basket. When there is a disconnect between our big goals and everyday actions we don't feel motivated to do those mundane tasks. &nbsp;Goal factoring, and other techniques for connecting our little goals to our big goals help here.</p>\n<p>Mental cue: Granularize</p>\n<p><strong id=\"Assuming_Constant_Motivation\">Assuming Constant Motivation</strong></p>\n<p>When we create sub-goals we choose things we think we can do. \"Of course I can walk 30 minutes everyday.\" We ignore that when we are creating and evaluating plans we are likely to be in a highly motivated mood. Of course everything seems easy when we are in a motivated mood. Apportion your limited budget of highly motivated time to ensuring that you will be surrounded by cues that encourage your new habit, whether this be people, things, or situations. &nbsp;This can be as simple as \"surrounding yourself\" with alarm apps that cue you to do the things you precommitted to doing.</p>\n<p>Mental cue: You are the average of your surroundings.</p>\n<p><strong id=\"Not_Quantifying_the_Results\">Not Quantifying the Results</strong></p>\n<p>Far goals are often qualitative. &nbsp;We're not sure how much we want to improve by, we just know it's a lot. The problem is that qualitative goals aren't very motivating in terms of actual actions. \"I want to get better about responding to emails.\" Notice the word \"better\". Contrast with \"I want to cut the number of emails I don't respond to by 50% over the next 2 weeks.\" Now we're getting somewhere, and we have somewhere to start. This is also related to the concept that motivation is hard to maintain when one of our sub-agents has an objection to what we're doing (usually because they aren't convinced it is a good use of time.)</p>\n<p>Mental cue: Be specific.</p>\n<p><strong id=\"Brittle_Plans\">Brittle Plans</strong></p>\n<p>This bit was somewhat disorganized. But it involves having a Plan B, as well as figuring out when you are going to reevaluate and update your plan. Also recognizing that what matters in habit formation is getting it mostly right and one shouldn't give up just because they screwed up one time, or even several times.</p>\n<p><strong id=\"I_m_all_fired_up_to_form_new_habits__now_what_\">I'm all fired up to form new habits, now what?</strong></p>\n<p>If you don't have anything you're currently working on I suggest instilling the habit of researching new, possibly beneficial habits to have.</p>\n<p>&nbsp;</p>\n<p>Note: In writing this I'm noticing similarity to SMART goals. &nbsp;Perhaps adapting that would be better since it's already nice and memorable.</p>", "sections": [{"title": "Failure is Always Failure", "anchor": "Failure_is_Always_Failure", "level": 1}, {"title": "Negative Reinforcement", "anchor": "Negative_Reinforcement", "level": 1}, {"title": "Perfectionism", "anchor": "Perfectionism", "level": 1}, {"title": "Going too Big too Fast", "anchor": "Going_too_Big_too_Fast", "level": 1}, {"title": "Assuming Constant Motivation", "anchor": "Assuming_Constant_Motivation", "level": 1}, {"title": "Not Quantifying the Results", "anchor": "Not_Quantifying_the_Results", "level": 1}, {"title": "Brittle Plans", "anchor": "Brittle_Plans", "level": 1}, {"title": "I'm all fired up to form new habits, now what?", "anchor": "I_m_all_fired_up_to_form_new_habits__now_what_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "19 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T10:20:48.519Z", "modifiedAt": null, "url": null, "title": "From Capuchins to AI's, Setting an Agenda for the Study of Cultural Cooperation (Part2)", "slug": "from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:31.333Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZYjewfy47zcMWrnxT/from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0", "pageUrlRelative": "/posts/ZYjewfy47zcMWrnxT/from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0", "linkUrl": "https://www.lesswrong.com/posts/ZYjewfy47zcMWrnxT/from-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20From%20Capuchins%20to%20AI's%2C%20Setting%20an%20Agenda%20for%20the%20Study%20of%20Cultural%20Cooperation%20(Part2)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFrom%20Capuchins%20to%20AI's%2C%20Setting%20an%20Agenda%20for%20the%20Study%20of%20Cultural%20Cooperation%20(Part2)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZYjewfy47zcMWrnxT%2Ffrom-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=From%20Capuchins%20to%20AI's%2C%20Setting%20an%20Agenda%20for%20the%20Study%20of%20Cultural%20Cooperation%20(Part2)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZYjewfy47zcMWrnxT%2Ffrom-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZYjewfy47zcMWrnxT%2Ffrom-capuchins-to-ai-s-setting-an-agenda-for-the-study-of-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3716, "htmlBody": "<div id=\"entry_t3_hto\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div><address><span style=\"color: #003300;\">Today's writings are shaded dark green, the rest was also in Part1.</span><br /></address><address>This is a multi-purpose essay-on-the-making, it is being written aiming at the following goals 1) Mandatory essay writing at the end of a semester studying \"Cognitive Ethology: Culture in Human and Non-Human Animals\" 2) Drafting something that can later on be published in a journal that deals with cultural evolution, hopefully inclining people in the area to glance at future oriented research, i.e. FAI and global coordination 3) Publishing it in Lesswrong and 4) Ultimately <a href=\"/lw/373/how_to_save_the_world/\">Saving the World</a>, as everything should. If it's worth doing, it's worth doing in the way most likely to save the World. </address><address>Since many of <a href=\"/lw/g87/calibrating_against_undetectable_utilons_and_goal/\">my writings</a> are frequently too long for Lesswrong, I'll publish this in a sequence-like form made of self-contained chunks. My deadline is Sunday, so I'll probably post daily, editing/creating the new sessions based on previous commentary. <br /></address>\n<p><br />Abstract: The study of cultural evolution has drawn much of its momentum from academic areas far removed from human and animal psychology, specially regarding the evolution of cooperation. Game theoretic results and parental investment theory come from economics, kin selection models from biology, and an ever growing amount of models describing the process of cultural evolution in general, and the evolution of altruism in particular come from mathematics. Even from Artificial Intelligence interest has been cast on how to create agents that can communicate, imitate and cooperate. In this article I begin to tackle the '<em>why?</em>' question. By trying to retrospectively make sense of the convergence of all these fields, I contend that further refinements in these fields <em>should</em> be directed towards understanding how to create environmental incentives fostering cooperation.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #4e4e4e; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 18px; orphans: auto; text-align: -webkit-left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\"><em>We need systems that are wiser than we are. We need institutions and cultural norms that make us better than we tend to be. It seems to me that the greatest challenge we now face is to build them. - Sam Harris, 2013, The Power Of Bad Incentives</em><br /></span></p>\n</blockquote>\n<p><strong>1) Introduction</strong></p>\n<p><strong>2) Cultures evolve</strong></p>\n<p>Culture is perhaps the most remarkable outcome of the evolutionary algorithm (Dennett, 1996) so far. It is the cradle of most things we consider <em>humane</em> - that is, typically human <em>and </em>valuable - and it surrounds our lives to the point that we may be thought of as creatures made of culture even more than creatures of bone and flesh (Hofstadter, 2007; Dennett, 1992). The appearance of our cultural complexity has relied on many associated capacities, among them:</p>\n<p>1) The ability to observe, be interested by, and go nearby an individual doing something interesting, an ability we share with norway rats, crows, and even lemurs (Galef &amp; Laland, 2005).</p>\n<p>2) Ability to learn from and scrounge the food of whoever knows how to get food, shared by capuchin monkeys (Ottoni et al, 2005).</p>\n<p>3) Ability to tolerate learners, to accept learners, and to socially learn, probably shared by animals as diverse as fish, finches and Fins (Galef &amp; Laland, 2005).</p>\n<p>4) Understanding and emulating other minds - Theory of Mind - empathizing, relating, perhaps re-framing an experience <em>as one's own</em>, shared by chimpanzees, dogs, and at least some cetaceans (Rendella &amp; Whitehead, 2001).</p>\n<p>5) Learning the program level description of the action of others, for which the evidence among other animals is controversial (but see Cantor &amp; Whitehead, 2013). And finally...</p>\n<p>6) Sharing intentions. Intricate understanding of how two minds can collaborate with complementary tasks to achieve a mutually agreed goal (Tomasello et al, 2005).</p>\n<p>Irrespective of definitional disputes around the <em>true meaning </em>of the word \"culture\" (which doesn't exist, see e.g. Pinker, 2007 pg115; Yudkowsky <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">2008A</a>), each of these is more cognitively complex than its predecessor, and even (1) is sufficient for intra-specific non-environmental, non-genetic behavioral variation, which I will call \"culture\" here, whoever it may harm.</p>\n<p>By transitivity, (2-6) allow the development of culture. It is interesting to notice that tool use, frequently but falsely cited as the hallmark of culture, is ubiquitously equiprobable in the animal kingdom. A graph showing, per biological family, which species shows tool use gives us a power law distribution, whose similarity with the universal prior will help in understanding that being from a family where a species uses tools tells us very little about a specie's own tool use (Michael Haslam, personal conversation).</p>\n<p>Once some of those abilities are available, and given an amount of environmental facilities, need, and randomness, cultures begin to form. Occasionally, so do more developed traditions. Be it by imitation, program level imitation, goal emulation or intention sharing, information is transmitted between agents giving rise to elements sufficient to constitute a primeval Darwinian soup. That is, entities form such that they exhibit 1)Variation 2)Heredity or replication 3)Differential fitness (Dennett, 1996). In light of the article <em>Five Misunderstandings About Cultural Evolution </em>(Henrich, Boyd &amp; Richerson, 2008)<em> </em>we can improve Dennett's conditions for the evolutionary algorithm as 1)Discrete or continuous variation 2)Heredity, replication, or less faithful replication plus content attractors 3)Differential fitness. Once this set of conditions is met, an evolutionary algorithm, or many, begin to carve their optimizing paws into whatever surpassed the threshold for long enough. Cultures, therefore, evolve.&nbsp;</p>\n<p>The intricacies of cultural evolution and mathematical and computational models of how cultures evolve have been the subject of much interdisciplinary research, for an extensive account of human culture see <em>Not By Genes Alone</em> (Richerson &amp; Boyd, 2005). For computational models of social evolution, there is work by Mesoudi, Novak, and others e.g<em>.</em> (Hauert et al, 2007). For mathematical models, the aptly named <em>Mathematical models of social evolution: A guide for the perplexed </em>by McElrath and Rob Boyd (2007) makes the textbook-style walk-through. For animal culture, see (Laland &amp; Galef, 2009).</p>\n<p>Cultural evolution satisfies David Deutsch's criterion for existence, it <em>kicks back</em>, it satisfies the evolutionary equivalent of the&nbsp; condition posed by the Quine-Putnam Indispensability argument in mathematics, i.e. it is a <em>sine qua non</em> condition for understanding how the World works nomologically. It is falsifiable to Popperian content, and it inflates the Worlds ontology a little, by inserting a new kind of \"replicator\", the meme. Contrary to what happened on the internet, the name 'meme' has lost much of it's appeal within cultural evolution theorists, and \"memetics\" is considered by some to refer only to the study of memes as monolithic atomic high fidelity replicators, which would make the theory obsolete. This has created the following conundrum: the name 'meme' remains by far the most well known one to speak of \"that which evolves culturally\" within, and specially outside, the specialist arena. Further, the niche occupied by the word 'meme' is so conceptually necessary within the area to communicate and explain that it is frequently put under scare quotes, or some other informal excuse. In fact, as argued by Tim Tyler - who frequently posts here - in the very sharp<em> Memetics</em> (2010), there are nearly no reasons to try to abandon the 'meme' meme, and nearly all reasons (practicality, Qwerty reasons, mnemonics) to keep it. To avoid contradicting the evidence ever since Dawkins first coined the term, I suggest we must redefine <em>Meme</em> as <em>an attractor in cultural evolution (dual-inheritance) whose development over time structurally mimics to a significant extent the discrete behavior of genes</em>, <em>frequently coinciding with the smallest unit of cultural replication.</em> The definition is long, but the idea is simple: Memes are not the best analogues of genes because they are discrete units that replicate just like genes, but because they are continuous conceptual clusters being attracted <em>to a point in conceptual space whose replication is just like that of genes</em>. Even more simply, memes are the mathematically closest things to genes in cultural evolution. So the suggestion here is for researchers of dual-inheritance and cultural evolution to take off the scare quotes of our memes and keep business as usual. <em>&nbsp; </em></p>\n<p>The evolutionary algorithm has created a new attractor-replicator, the meme, it didn't privilege with it any specific families in the biological trees and it ended up creating a process of cultural-genetic coevolution known as dual-inheritance. This process has been studied in ever more quantified ways by primatologists, behavioral ecologists, population biologists, anthropologists, ethologists, sociologists, neuroscientists and even philosophers. I've shown at least six distinct abilities which helped scaffold our astounding level of cultural intricacy, and some animals who share them with us. We will now take a look at the evolution of cooperation, collaboration, altruism, moral behavior, a sub-area of cultural evolution that saw an explosion of interest and research during the last decade, with publications (most from the last 4 years) such as <em>The Origins of Morality, Supercooperators, Good and Real, The Better Angels of Our Nature, Non-Zero, The Moral Animal, Primates and Philosophers</em>, <em>The Age of Empathy, Origins of Altruism and Cooperation, The Altruism Equation, Altruism in Humans, Cooperation and Its Evolution, Moral Tribes, The Expanding Circle, The Moral Landscape. </em></p>\n<p><em><br /></em></p>\n<p><em> </em></p>\n<p><span style=\"color: #003300;\"><strong>3) Cooperation evolves</strong></span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">Despite the selfish nature of genes (Dawkins, 1999) and other units of Darwinian transmission (Jablonka &amp; Lamb, 2007), altruism at the individual level (cost to self for benefit to other) <em>can </em>and <em>does</em> arise because of several intertwined factors.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">1) Alleles (the molecular biologist word for what less-specialized areas call genes) under normal conditions optimize for there being more copies of themselves in the future. This happens regardless of whether it is that physical instantiation - also known as token - that is present in the future.&nbsp;</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">2) Copies of alleles are spread over space, individuals, groups, species and <em>time, </em>but they only care about the time dimension and the quantity dimension. In the long run alleles don't thrive if they are doing better than their neighbors, they thrive if they are doing better than the average allele. A token (instantiation) of an allele that codes for cancer, multiplying itself uncontrollably could, had he a mind, think he's doing great, but if the mutation that gave rise to it only happened in somatic cells (that do not go through the germ line), he'd be in for a surprise. One reason why biologists say natural selection is short-sighted.&nbsp;</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">3) The above reasoning applies exactly equally <em>and for the same reasons</em> to an allele that codes for individual-selfish behavior in a species in which more altruist groups tend to outlive more egotistic ones. The allele for individual-selfishness, and the selfish individual, may think they are doing great, comparing to their neighbors, when all of a sudden, with high probability, their group dies. Altruism wins in this case not because there is a new spooky unit of selection that reverses reductionism, and applies downward causation which originates in groups. Altruism thrives because the average long term fitness of each allele that coded for it was higher than that of genes that code for individual-selfish behavior. Group selection<sub>c</sub>&nbsp; - as well as superoganism selection, somatic cells selection, species selection and individual selection - only happens when <em>the selective forces operating on that level coincide </em>with the allele's fitness increasing in relation to all the competing alleles. (<a href=\"/lw/300/group_selection_update/\">Group selection<sub>c</sub></a> is selection for altruist genes at the group level, the only definition under which the entire discussion was dealing with a controversy <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">of substance</a> instead of talking past each other, as brilliantly explained <a href=\"/lw/300/group_selection_update/\">in this post by PhilGoetz, 2010</a>, please read the case study section in that post to get a more precise understanding than the above short definition). See also the excursus on what a fitness function is below.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">4) Completely independent from the reasons in (3), alleles, epigenetics, and learning can program individuals to be cooperative if they \"expect\" (consciously or not) the interaction with another individual, say, Malou, to: (a) Begin a cycle of reciprocation with Malou in the future whose benefit exceeds the current cost being paid; (b) Counterfactually increase their reputation with sufficiently many individuals that those will award more benefit than current cost; (c) Avoid being punished by third parties; (d) Conform to, or help enforce, by setting an example, social norms and rules upon which selection pressures act (Tomasello, 2005). A key notion in all these mechanisms based on this encoded \"expectation\" is that uncertainty must&nbsp; be present. In the absence of uncertainty, a state that <a href=\"/lw/mp/0_and_1_are_not_probabilities/\">doesn't exist</a> in nature, an agent in a prisoner dilemma like interaction would be required to defect instead of cooperating from round one, predicting the backwards-in-time cascade of defection from whichever was the last round of interaction, in which by definition cooperating is worse. The problems that in Lesswrong people are trying to solve using Timeless Decision Theory, Updateless Decision Theory, <a href=\"http://intelligence.org/files/RobustCooperation.pdf\">PrudentBot</a>, and other IQ140+ gimmicks, evolution solved by<em> inserting stupidity</em>! More precisely by embracing higher level uncertainty about how many future interactions will there be. Kissing, saying \"I love you\", becoming engaged, and getting married are all increasingly honest ways in which the computer program programmed by your alleles informs Malou that there will be more cooperation and less defection in the future.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">5) Finally, altruism only poses paradoxes of the \"Group Selection<sub>c</sub>\" kind when we are trying to explain <em>why a replicator that codes for Altruism emerged? And</em> we are trying to explain it <em>at that replicators level</em>. It is no mystery why a composition of the phenotypic effects of a gene (replicator) and two memes (attractor-replicators) in all individuals who posses the three of them makes them altruistic, if it does. Each gene and meme in that composition may be fending for itself, but as things turn out, they do make some really nice people (or bonobos) once their extended phenotypes are clustered within those people. If we trust Jablonka &amp; Lamb (2007), there are four streams of heredity flowing concomitantly: Genetic, Epigenetic, Behavioral and Symbolic. Some of the flowing hereditary entities are not even attractor-replicators (niche construction for instance), they don't exhibit replicator dynamics and any altruism that spreads through them requires no special explanation at all! </span></p>\n<p><span style=\"color: #003300;\">To the best of my knowledge, none of the 5 factors above, which all do play a role in the existence and maintenance of altruism, requires a revision of Neodarwinism of the Dawkins, Dennett, Trivers, Pinker sort. None of them challenges the validity of our models of replicator dynamics as replicator dynamics. None of them challenges the metaphysically fundamental notion of Darwinism as Universal Acid (Dennett,1996). None of them compromises the claim that everything in the universe that has complex design of which we are aware can be traced back to Darwinian mind-less processes operating, by and large, in replicator-like entities (Dennett, <em>opus cit</em>). None of them poses an obstacle to <a href=\"http://consc.net/papers/nature.html\">physicalist</a> <a href=\"http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29\">reductionism</a> - in this biology-ladden context being the claim that all macrophysical facts, including biological facts, are materially determined by the microphysical facts. </span></p>\n<p><span style=\"color: #003300;\">Cooperation evolves, and altruism evolves. They evolve for natural, non-mysterious reasons, and before any more shaking of the edifice of Darwinism is made, and it's constitutive reductionism or universal corrosive powers are contested, any counteracting evidence must be able to traverse undetectably by the far less demanding possibility of being explained by<em> any</em> of the factors above <em>or</em> a combination of them, <em>or</em> being simply the result of one of the many confusions clarified in the excursus below. Despite many people's attempts to look for Skyhooks that would cast away the all-too-natural demons of Neodarwinism and reductionism, things remain as they were before, Cranes all the way up. I will be listening attentively for a case of altruism found in the biological world or mathematical simulations based on it that can pierce through these many layers of epistemic explanatory ability, but I won't be holding my breadth. &nbsp; &nbsp; &nbsp; </span></p>\n<p><span style=\"color: #003300;\"><br /></span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\"><strong>Excursus: What is a fitness function?</strong></span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">It is worth pointing out here not only <em>that</em> the altruism and group selection confusion happens, but showing <em>why</em> it does. And PhilGoetz <a href=\"/lw/300/group_selection_update/\">did half</a> of the explanatory job already. The other half is noticing that the fitness function is a <a href=\"/lw/ro/2place_and_1place_words/\">many-place function</a> (there is a newer and better post on Lesswrong explaining many-place functions/words, but I didn't find it in 12min, please point to it if you can). The complicated description of \"what the fitness function is\", in <a href=\"https://www.google.com.br/search?hl=pt-BR&amp;q=lewis+gramar#hl=pt-BR&amp;sclient=psy-ab&amp;q=%22i+promised+simplicity%22+%22I+deliver+functions+from%22&amp;oq=%22i+promised+simplicity%22+%22I+deliver+functions+from%22&amp;gs_l=serp.3...7985.25952.2.26469.60.52.7.0.0.0.290.11940.0j5j47.52.0...0.0...1c.1.18.psy-ab.vICz44fpMDU&amp;pbx=1&amp;bav=on.2,or.r_cp.r_qf.&amp;bvm=bv.48572450,d.dmQ&amp;fp=24bc1b15375a24a&amp;biw=1540&amp;bih=855\">David Lewis's manner of speaking,</a> would be that it is a function from things to functions from functions to functions. More understandably, with e.g. the specific \"thing\" being a token of an altruistic allele of kind \"Aallele\", call it \"Aallele<sub>334</sub>\":</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">Aallele<sub>344</sub>--<sup>1</sup>--&gt;((number of Aalleles--<sup>3</sup>--&gt;total number of alleles)--<sup>2</sup>--&gt;(amplitude configuration slice--<sup>4</sup>--&gt;simplest ordering))</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">Here arrow 4 is the function we call <em>time</em> from a timeless physics, quantum physics perspective. Just substitute the whole parenthesis for \"time\" instead if you haven't read the <a href=\"/lw/r5/the_quantum_physics_sequence/\">Quantum Physics sequence</a>. Arrow 3 is how good Aalleles are doing, i.e. how many of them there are in relation to the total number of competing alleles. Arrow 2 is how this relation between Aalleles and total varies over time. The fitness function is arrow 1, once you are given a specific token of<sub> </sub>an allele, it is the function that describes how well copies of that token do over time in relation to all the competing alleles. Needless to say, not many biologists are aware of that complex computation.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">The reason why the unexplained half of controversies happen is that the punctual fitness of an allele will appear very different when you factor it against the competing alleles of other cells, of other individuals,&nbsp; of other groups, or of other species. Fitness is what philosophers call an <em>externalist</em> concept, if you increase the amount of contextually relevant surroundings, the output number changes significantly. It will also appear very different when you factor it for final time T<sub>1</sub> or T<sub>2</sub>. The fitness of an allele coding for a species specific characteristic of T-Rex's large bodies will be very high if the final time is 65 million years ago, but negative if 64.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">I remember Feynman saying, I believe in <a href=\"http://www.youtube.com/watch?v=FXiOg5-l3fk\">this interview</a>, that it is amazing what the eye does. Surrounded in a 3d equivalent of an insect floating up and down in the 2d surface of a swimming pool, we manage to <a href=\"/intelligence.org/files/LOGI.pdf&lrm;\">abstract away</a> all the waves going through the space between us and a seen object, and still capture information enough to locate it, interact with it, and admire it. It is as if the insect could tell only from his vertical oscillations how many children were in the pool, where they were located etc. The state of knowledge in many fields, adaptive fitness included, strikes me as similarly amazing. If this many-place function underlies what biologists should be talking about to avoid talking past each other, how can many of them be aware of only one or two of the many variables that should be input, and still be making good science? Or are they? <br />If you fail to see hidden variables, you can fall prey to anomalies like the <a href=\"/lw/3q3/simpsons_paradox/\">Simpson's paradox</a>, which is exactly the mistake described in <a href=\"/lw/300/group_selection_update/\">PhilGoetz's post</a> on group/species selection.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">The function above also works for things other than alleles, like individuals with a characteristic, in which case it will be calculating the fitness of having that characteristic at the individual level.</span></p>\n<p>&nbsp;</p>\n<p><strong>4) The complexity of cultural items doesn't undermine the validity of mathematical models.</strong></p>\n<p><strong> </strong></p>\n<p><strong>&nbsp;4.1) Cognitive attractors and biases substitute for memes discreteness</strong></p>\n<p>The math becomes equivalent.</p>\n<p><strong> </strong></p>\n<p><strong>&nbsp;4.2) Despite the Unilateralist Curse and the Tragedy of the Commons, dyadic interaction models help us understand large scale cooperation</strong></p>\n<p>Once we know these two failure modes, dyadic iterated (or reputation-sensitive) interaction is close enough.</p>\n<p><strong> </strong></p>\n<p><strong>5) From Monkeys to Apes to Humans to Transhumans to AIs, the ranges of achievable altruistic skill.</strong></p>\n<p>Possible modes of being altruistic. Graph like <a href=\"http://www.posthumanism.com/space5.jpg\">Bostrom's</a>. Second and third order punishment and cooperation. Newcomb-like signaling problems within AI.</p>\n<p><strong> </strong></p>\n<p><strong>6) Unfit for the Future: the need for greater altruism.</strong></p>\n<p>We fail and will remain failing in Tragedy of the Commons problems unless we change our nature.</p>\n<p><strong> </strong></p>\n<p><strong>7) From Science, through Philosophy, towards Engineering: the future of studies of altruism.</strong></p>\n<p>Philosophy: Existential Risk <a href=\"http://www.existential-risk.org/concept.html\">prevention through global coordination</a> and cooperation prior to technical maturity. Engineering Humans: creating enhancements and changing incentives. Engineering AI's: making them <a href=\"http://intelligence.org/files/RobustCooperation.pdf\">better</a> and <a href=\"https://www.youtube.com/watch?v=MwriJqBZyoM\">realer</a>.</p>\n<p><strong> </strong></p>\n<p><strong>8) A different kind of Moral Landscape</strong></p>\n<p>Like Sam Harris's one, except comparing not how much a society approaches <em>The Good Life (Moral Landscape pg15)</em>, but how much it fosters altruistic behavior.</p>\n<p><strong> </strong></p>\n<p><strong>9) Conclusions</strong></p>\n<p>Not yet.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>Bibliography (<sub>Only of the parts already written, obviously</sub>):</p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><span style=\"font-size: xx-small;\">Boyd, R., Gintis, H., Bowles, S., &amp; Richerson, P. J. (2003). <em>The evolution of altruistic punishment</em>. Proceedings of the National Academy of Sciences, 100(6), 3531-3535.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Cantor, M., &amp; Whitehead, H. (2013). The interplay between social networks and culture: theoretically and among whales and dolphins.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Philosophical Transactions of the Royal Society B: Biological Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">368</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(1618).</span></span></span></span></span></span><br /><br /><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><span style=\"font-size: xx-small;\">Dawkins, R. (1999). <em>The extended phenotype</em>: The long reach of the gene. Oxford University Press, USA.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1996). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Darwin's dangerous idea: Evolution and the meanings of life </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(No. 39). Simon &amp; Schuster.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1992). The self as a center of narrative gravity.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Self and consciousness: Multiple perspectives</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">.</span></span></span></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Galef Jr, B. G., &amp; Laland, K. N. (2005). Social learning in animals: empirical studies and theoretical models.&nbsp;</span>Bioscience<span style=\"font-style: normal;\">,&nbsp;</span>55<span style=\"font-style: normal;\">(6), 489-499.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Hauert, C., Traulsen, A., Brandt, H., Nowak, M. A., &amp; Sigmund, K. (2007). Via freedom to coercion: the emergence of costly punishment.&nbsp;</span>science<span style=\"font-style: normal;\">,&nbsp;</span>316<span style=\"font-style: normal;\">(5833), 1905-1907.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Henrich, J., Boyd, R., &amp; Richerson, P. J. (2008). Five misunderstandings about cultural evolution. </span>Human Nature<span style=\"font-style: normal;\">, </span>19<span style=\"font-style: normal;\">(2), 119-137.</span></span></em></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Hofstadter, D. R. (2007). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">I am a Strange Loop</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Basic Books</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><span style=\"font-size: xx-small;\">Jablonka, E., &amp; Lamb, M. J. (2007).<em> Precis of evolution in four dimensions.</em> Behavioral and Brain Sciences, 30(4), 353-364.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">McElreath, R., &amp; Boyd, R. (2007).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Mathematical models of social evolution: A guide for the perplexed</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Ottoni, E. B., de Resende, B. D., &amp; Izar, P. (2005). Watching the best nutcrackers: what capuchin monkeys (Cebus apella) know about others&rsquo; tool-using skills.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Animal cognition</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">8</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(4), 215-219.<br /></span></span></span><br /><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Persson, I., &amp; Savulescu, J. Unfit for the Future: The Need for Moral Enhancement Oxford: Oxford University Press, 2012 ISBN 978-0199653645 (HB)&pound; 21.00. 160pp. On the brink of civil war, Abraham Lincoln stood on the steps of the US Capitol and appealed.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">PhilGoetz. (2010), <em>Group selection update</em>. Available at http://lesswrong.com/lw/300/group_selection_update/<br /></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Pinker, S. (2007).&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">The stuff of thought: Language as a window into human nature</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Viking Adult.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Rendella, L., &amp; Whitehead, H. (2001). Culture in whales and dolphins.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and Brain Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">24</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">, 309-382.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Richardson, P. J., &amp; Boyd, R. (2005). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Not by genes alone</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tyler, T. (2011).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Memetics: Memes and the Science of Cultural Evolution</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Tim Tyler.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tomasello, M., Carpenter, M., Call, J., Behne, T., &amp; Moll, H. (2005). Understanding and sharing intentions: The origins of cultural cognition.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and brain sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">28</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(5), 675-690.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Yudkowsky, E. (2008A). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">37 ways words can be wrong. </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Available at <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/</a></span></span></span></span></span></span></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZYjewfy47zcMWrnxT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -5, "extendedScore": null, "score": 1.2475308076768227e-06, "legacy": true, "legacyId": "23122", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<div id=\"entry_t3_hto\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div><address><span style=\"color: #003300;\">Today's writings are shaded dark green, the rest was also in Part1.</span><br></address><address>This is a multi-purpose essay-on-the-making, it is being written aiming at the following goals 1) Mandatory essay writing at the end of a semester studying \"Cognitive Ethology: Culture in Human and Non-Human Animals\" 2) Drafting something that can later on be published in a journal that deals with cultural evolution, hopefully inclining people in the area to glance at future oriented research, i.e. FAI and global coordination 3) Publishing it in Lesswrong and 4) Ultimately <a href=\"/lw/373/how_to_save_the_world/\">Saving the World</a>, as everything should. If it's worth doing, it's worth doing in the way most likely to save the World. </address><address>Since many of <a href=\"/lw/g87/calibrating_against_undetectable_utilons_and_goal/\">my writings</a> are frequently too long for Lesswrong, I'll publish this in a sequence-like form made of self-contained chunks. My deadline is Sunday, so I'll probably post daily, editing/creating the new sessions based on previous commentary. <br></address>\n<p><br>Abstract: The study of cultural evolution has drawn much of its momentum from academic areas far removed from human and animal psychology, specially regarding the evolution of cooperation. Game theoretic results and parental investment theory come from economics, kin selection models from biology, and an ever growing amount of models describing the process of cultural evolution in general, and the evolution of altruism in particular come from mathematics. Even from Artificial Intelligence interest has been cast on how to create agents that can communicate, imitate and cooperate. In this article I begin to tackle the '<em>why?</em>' question. By trying to retrospectively make sense of the convergence of all these fields, I contend that further refinements in these fields <em>should</em> be directed towards understanding how to create environmental incentives fostering cooperation.</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #4e4e4e; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 18px; orphans: auto; text-align: -webkit-left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\"><em>We need systems that are wiser than we are. We need institutions and cultural norms that make us better than we tend to be. It seems to me that the greatest challenge we now face is to build them. - Sam Harris, 2013, The Power Of Bad Incentives</em><br></span></p>\n</blockquote>\n<p><strong id=\"1__Introduction\">1) Introduction</strong></p>\n<p><strong id=\"2__Cultures_evolve\">2) Cultures evolve</strong></p>\n<p>Culture is perhaps the most remarkable outcome of the evolutionary algorithm (Dennett, 1996) so far. It is the cradle of most things we consider <em>humane</em> - that is, typically human <em>and </em>valuable - and it surrounds our lives to the point that we may be thought of as creatures made of culture even more than creatures of bone and flesh (Hofstadter, 2007; Dennett, 1992). The appearance of our cultural complexity has relied on many associated capacities, among them:</p>\n<p>1) The ability to observe, be interested by, and go nearby an individual doing something interesting, an ability we share with norway rats, crows, and even lemurs (Galef &amp; Laland, 2005).</p>\n<p>2) Ability to learn from and scrounge the food of whoever knows how to get food, shared by capuchin monkeys (Ottoni et al, 2005).</p>\n<p>3) Ability to tolerate learners, to accept learners, and to socially learn, probably shared by animals as diverse as fish, finches and Fins (Galef &amp; Laland, 2005).</p>\n<p>4) Understanding and emulating other minds - Theory of Mind - empathizing, relating, perhaps re-framing an experience <em>as one's own</em>, shared by chimpanzees, dogs, and at least some cetaceans (Rendella &amp; Whitehead, 2001).</p>\n<p>5) Learning the program level description of the action of others, for which the evidence among other animals is controversial (but see Cantor &amp; Whitehead, 2013). And finally...</p>\n<p>6) Sharing intentions. Intricate understanding of how two minds can collaborate with complementary tasks to achieve a mutually agreed goal (Tomasello et al, 2005).</p>\n<p>Irrespective of definitional disputes around the <em>true meaning </em>of the word \"culture\" (which doesn't exist, see e.g. Pinker, 2007 pg115; Yudkowsky <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">2008A</a>), each of these is more cognitively complex than its predecessor, and even (1) is sufficient for intra-specific non-environmental, non-genetic behavioral variation, which I will call \"culture\" here, whoever it may harm.</p>\n<p>By transitivity, (2-6) allow the development of culture. It is interesting to notice that tool use, frequently but falsely cited as the hallmark of culture, is ubiquitously equiprobable in the animal kingdom. A graph showing, per biological family, which species shows tool use gives us a power law distribution, whose similarity with the universal prior will help in understanding that being from a family where a species uses tools tells us very little about a specie's own tool use (Michael Haslam, personal conversation).</p>\n<p>Once some of those abilities are available, and given an amount of environmental facilities, need, and randomness, cultures begin to form. Occasionally, so do more developed traditions. Be it by imitation, program level imitation, goal emulation or intention sharing, information is transmitted between agents giving rise to elements sufficient to constitute a primeval Darwinian soup. That is, entities form such that they exhibit 1)Variation 2)Heredity or replication 3)Differential fitness (Dennett, 1996). In light of the article <em>Five Misunderstandings About Cultural Evolution </em>(Henrich, Boyd &amp; Richerson, 2008)<em> </em>we can improve Dennett's conditions for the evolutionary algorithm as 1)Discrete or continuous variation 2)Heredity, replication, or less faithful replication plus content attractors 3)Differential fitness. Once this set of conditions is met, an evolutionary algorithm, or many, begin to carve their optimizing paws into whatever surpassed the threshold for long enough. Cultures, therefore, evolve.&nbsp;</p>\n<p>The intricacies of cultural evolution and mathematical and computational models of how cultures evolve have been the subject of much interdisciplinary research, for an extensive account of human culture see <em>Not By Genes Alone</em> (Richerson &amp; Boyd, 2005). For computational models of social evolution, there is work by Mesoudi, Novak, and others e.g<em>.</em> (Hauert et al, 2007). For mathematical models, the aptly named <em>Mathematical models of social evolution: A guide for the perplexed </em>by McElrath and Rob Boyd (2007) makes the textbook-style walk-through. For animal culture, see (Laland &amp; Galef, 2009).</p>\n<p>Cultural evolution satisfies David Deutsch's criterion for existence, it <em>kicks back</em>, it satisfies the evolutionary equivalent of the&nbsp; condition posed by the Quine-Putnam Indispensability argument in mathematics, i.e. it is a <em>sine qua non</em> condition for understanding how the World works nomologically. It is falsifiable to Popperian content, and it inflates the Worlds ontology a little, by inserting a new kind of \"replicator\", the meme. Contrary to what happened on the internet, the name 'meme' has lost much of it's appeal within cultural evolution theorists, and \"memetics\" is considered by some to refer only to the study of memes as monolithic atomic high fidelity replicators, which would make the theory obsolete. This has created the following conundrum: the name 'meme' remains by far the most well known one to speak of \"that which evolves culturally\" within, and specially outside, the specialist arena. Further, the niche occupied by the word 'meme' is so conceptually necessary within the area to communicate and explain that it is frequently put under scare quotes, or some other informal excuse. In fact, as argued by Tim Tyler - who frequently posts here - in the very sharp<em> Memetics</em> (2010), there are nearly no reasons to try to abandon the 'meme' meme, and nearly all reasons (practicality, Qwerty reasons, mnemonics) to keep it. To avoid contradicting the evidence ever since Dawkins first coined the term, I suggest we must redefine <em>Meme</em> as <em>an attractor in cultural evolution (dual-inheritance) whose development over time structurally mimics to a significant extent the discrete behavior of genes</em>, <em>frequently coinciding with the smallest unit of cultural replication.</em> The definition is long, but the idea is simple: Memes are not the best analogues of genes because they are discrete units that replicate just like genes, but because they are continuous conceptual clusters being attracted <em>to a point in conceptual space whose replication is just like that of genes</em>. Even more simply, memes are the mathematically closest things to genes in cultural evolution. So the suggestion here is for researchers of dual-inheritance and cultural evolution to take off the scare quotes of our memes and keep business as usual. <em>&nbsp; </em></p>\n<p>The evolutionary algorithm has created a new attractor-replicator, the meme, it didn't privilege with it any specific families in the biological trees and it ended up creating a process of cultural-genetic coevolution known as dual-inheritance. This process has been studied in ever more quantified ways by primatologists, behavioral ecologists, population biologists, anthropologists, ethologists, sociologists, neuroscientists and even philosophers. I've shown at least six distinct abilities which helped scaffold our astounding level of cultural intricacy, and some animals who share them with us. We will now take a look at the evolution of cooperation, collaboration, altruism, moral behavior, a sub-area of cultural evolution that saw an explosion of interest and research during the last decade, with publications (most from the last 4 years) such as <em>The Origins of Morality, Supercooperators, Good and Real, The Better Angels of Our Nature, Non-Zero, The Moral Animal, Primates and Philosophers</em>, <em>The Age of Empathy, Origins of Altruism and Cooperation, The Altruism Equation, Altruism in Humans, Cooperation and Its Evolution, Moral Tribes, The Expanding Circle, The Moral Landscape. </em></p>\n<p><em><br></em></p>\n<p><em> </em></p>\n<p><span style=\"color: #003300;\"><strong>3) Cooperation evolves</strong></span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">Despite the selfish nature of genes (Dawkins, 1999) and other units of Darwinian transmission (Jablonka &amp; Lamb, 2007), altruism at the individual level (cost to self for benefit to other) <em>can </em>and <em>does</em> arise because of several intertwined factors.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">1) Alleles (the molecular biologist word for what less-specialized areas call genes) under normal conditions optimize for there being more copies of themselves in the future. This happens regardless of whether it is that physical instantiation - also known as token - that is present in the future.&nbsp;</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">2) Copies of alleles are spread over space, individuals, groups, species and <em>time, </em>but they only care about the time dimension and the quantity dimension. In the long run alleles don't thrive if they are doing better than their neighbors, they thrive if they are doing better than the average allele. A token (instantiation) of an allele that codes for cancer, multiplying itself uncontrollably could, had he a mind, think he's doing great, but if the mutation that gave rise to it only happened in somatic cells (that do not go through the germ line), he'd be in for a surprise. One reason why biologists say natural selection is short-sighted.&nbsp;</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">3) The above reasoning applies exactly equally <em>and for the same reasons</em> to an allele that codes for individual-selfish behavior in a species in which more altruist groups tend to outlive more egotistic ones. The allele for individual-selfishness, and the selfish individual, may think they are doing great, comparing to their neighbors, when all of a sudden, with high probability, their group dies. Altruism wins in this case not because there is a new spooky unit of selection that reverses reductionism, and applies downward causation which originates in groups. Altruism thrives because the average long term fitness of each allele that coded for it was higher than that of genes that code for individual-selfish behavior. Group selection<sub>c</sub>&nbsp; - as well as superoganism selection, somatic cells selection, species selection and individual selection - only happens when <em>the selective forces operating on that level coincide </em>with the allele's fitness increasing in relation to all the competing alleles. (<a href=\"/lw/300/group_selection_update/\">Group selection<sub>c</sub></a> is selection for altruist genes at the group level, the only definition under which the entire discussion was dealing with a controversy <a href=\"/lw/nv/replace_the_symbol_with_the_substance/\">of substance</a> instead of talking past each other, as brilliantly explained <a href=\"/lw/300/group_selection_update/\">in this post by PhilGoetz, 2010</a>, please read the case study section in that post to get a more precise understanding than the above short definition). See also the excursus on what a fitness function is below.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">4) Completely independent from the reasons in (3), alleles, epigenetics, and learning can program individuals to be cooperative if they \"expect\" (consciously or not) the interaction with another individual, say, Malou, to: (a) Begin a cycle of reciprocation with Malou in the future whose benefit exceeds the current cost being paid; (b) Counterfactually increase their reputation with sufficiently many individuals that those will award more benefit than current cost; (c) Avoid being punished by third parties; (d) Conform to, or help enforce, by setting an example, social norms and rules upon which selection pressures act (Tomasello, 2005). A key notion in all these mechanisms based on this encoded \"expectation\" is that uncertainty must&nbsp; be present. In the absence of uncertainty, a state that <a href=\"/lw/mp/0_and_1_are_not_probabilities/\">doesn't exist</a> in nature, an agent in a prisoner dilemma like interaction would be required to defect instead of cooperating from round one, predicting the backwards-in-time cascade of defection from whichever was the last round of interaction, in which by definition cooperating is worse. The problems that in Lesswrong people are trying to solve using Timeless Decision Theory, Updateless Decision Theory, <a href=\"http://intelligence.org/files/RobustCooperation.pdf\">PrudentBot</a>, and other IQ140+ gimmicks, evolution solved by<em> inserting stupidity</em>! More precisely by embracing higher level uncertainty about how many future interactions will there be. Kissing, saying \"I love you\", becoming engaged, and getting married are all increasingly honest ways in which the computer program programmed by your alleles informs Malou that there will be more cooperation and less defection in the future.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">5) Finally, altruism only poses paradoxes of the \"Group Selection<sub>c</sub>\" kind when we are trying to explain <em>why a replicator that codes for Altruism emerged? And</em> we are trying to explain it <em>at that replicators level</em>. It is no mystery why a composition of the phenotypic effects of a gene (replicator) and two memes (attractor-replicators) in all individuals who posses the three of them makes them altruistic, if it does. Each gene and meme in that composition may be fending for itself, but as things turn out, they do make some really nice people (or bonobos) once their extended phenotypes are clustered within those people. If we trust Jablonka &amp; Lamb (2007), there are four streams of heredity flowing concomitantly: Genetic, Epigenetic, Behavioral and Symbolic. Some of the flowing hereditary entities are not even attractor-replicators (niche construction for instance), they don't exhibit replicator dynamics and any altruism that spreads through them requires no special explanation at all! </span></p>\n<p><span style=\"color: #003300;\">To the best of my knowledge, none of the 5 factors above, which all do play a role in the existence and maintenance of altruism, requires a revision of Neodarwinism of the Dawkins, Dennett, Trivers, Pinker sort. None of them challenges the validity of our models of replicator dynamics as replicator dynamics. None of them challenges the metaphysically fundamental notion of Darwinism as Universal Acid (Dennett,1996). None of them compromises the claim that everything in the universe that has complex design of which we are aware can be traced back to Darwinian mind-less processes operating, by and large, in replicator-like entities (Dennett, <em>opus cit</em>). None of them poses an obstacle to <a href=\"http://consc.net/papers/nature.html\">physicalist</a> <a href=\"http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29\">reductionism</a> - in this biology-ladden context being the claim that all macrophysical facts, including biological facts, are materially determined by the microphysical facts. </span></p>\n<p><span style=\"color: #003300;\">Cooperation evolves, and altruism evolves. They evolve for natural, non-mysterious reasons, and before any more shaking of the edifice of Darwinism is made, and it's constitutive reductionism or universal corrosive powers are contested, any counteracting evidence must be able to traverse undetectably by the far less demanding possibility of being explained by<em> any</em> of the factors above <em>or</em> a combination of them, <em>or</em> being simply the result of one of the many confusions clarified in the excursus below. Despite many people's attempts to look for Skyhooks that would cast away the all-too-natural demons of Neodarwinism and reductionism, things remain as they were before, Cranes all the way up. I will be listening attentively for a case of altruism found in the biological world or mathematical simulations based on it that can pierce through these many layers of epistemic explanatory ability, but I won't be holding my breadth. &nbsp; &nbsp; &nbsp; </span></p>\n<p><span style=\"color: #003300;\"><br></span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\"><strong>Excursus: What is a fitness function?</strong></span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">It is worth pointing out here not only <em>that</em> the altruism and group selection confusion happens, but showing <em>why</em> it does. And PhilGoetz <a href=\"/lw/300/group_selection_update/\">did half</a> of the explanatory job already. The other half is noticing that the fitness function is a <a href=\"/lw/ro/2place_and_1place_words/\">many-place function</a> (there is a newer and better post on Lesswrong explaining many-place functions/words, but I didn't find it in 12min, please point to it if you can). The complicated description of \"what the fitness function is\", in <a href=\"https://www.google.com.br/search?hl=pt-BR&amp;q=lewis+gramar#hl=pt-BR&amp;sclient=psy-ab&amp;q=%22i+promised+simplicity%22+%22I+deliver+functions+from%22&amp;oq=%22i+promised+simplicity%22+%22I+deliver+functions+from%22&amp;gs_l=serp.3...7985.25952.2.26469.60.52.7.0.0.0.290.11940.0j5j47.52.0...0.0...1c.1.18.psy-ab.vICz44fpMDU&amp;pbx=1&amp;bav=on.2,or.r_cp.r_qf.&amp;bvm=bv.48572450,d.dmQ&amp;fp=24bc1b15375a24a&amp;biw=1540&amp;bih=855\">David Lewis's manner of speaking,</a> would be that it is a function from things to functions from functions to functions. More understandably, with e.g. the specific \"thing\" being a token of an altruistic allele of kind \"Aallele\", call it \"Aallele<sub>334</sub>\":</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">Aallele<sub>344</sub>--<sup>1</sup>--&gt;((number of Aalleles--<sup>3</sup>--&gt;total number of alleles)--<sup>2</sup>--&gt;(amplitude configuration slice--<sup>4</sup>--&gt;simplest ordering))</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">Here arrow 4 is the function we call <em>time</em> from a timeless physics, quantum physics perspective. Just substitute the whole parenthesis for \"time\" instead if you haven't read the <a href=\"/lw/r5/the_quantum_physics_sequence/\">Quantum Physics sequence</a>. Arrow 3 is how good Aalleles are doing, i.e. how many of them there are in relation to the total number of competing alleles. Arrow 2 is how this relation between Aalleles and total varies over time. The fitness function is arrow 1, once you are given a specific token of<sub> </sub>an allele, it is the function that describes how well copies of that token do over time in relation to all the competing alleles. Needless to say, not many biologists are aware of that complex computation.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">The reason why the unexplained half of controversies happen is that the punctual fitness of an allele will appear very different when you factor it against the competing alleles of other cells, of other individuals,&nbsp; of other groups, or of other species. Fitness is what philosophers call an <em>externalist</em> concept, if you increase the amount of contextually relevant surroundings, the output number changes significantly. It will also appear very different when you factor it for final time T<sub>1</sub> or T<sub>2</sub>. The fitness of an allele coding for a species specific characteristic of T-Rex's large bodies will be very high if the final time is 65 million years ago, but negative if 64.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">I remember Feynman saying, I believe in <a href=\"http://www.youtube.com/watch?v=FXiOg5-l3fk\">this interview</a>, that it is amazing what the eye does. Surrounded in a 3d equivalent of an insect floating up and down in the 2d surface of a swimming pool, we manage to <a href=\"/intelligence.org/files/LOGI.pdf\u200e\">abstract away</a> all the waves going through the space between us and a seen object, and still capture information enough to locate it, interact with it, and admire it. It is as if the insect could tell only from his vertical oscillations how many children were in the pool, where they were located etc. The state of knowledge in many fields, adaptive fitness included, strikes me as similarly amazing. If this many-place function underlies what biologists should be talking about to avoid talking past each other, how can many of them be aware of only one or two of the many variables that should be input, and still be making good science? Or are they? <br>If you fail to see hidden variables, you can fall prey to anomalies like the <a href=\"/lw/3q3/simpsons_paradox/\">Simpson's paradox</a>, which is exactly the mistake described in <a href=\"/lw/300/group_selection_update/\">PhilGoetz's post</a> on group/species selection.</span></p>\n<span style=\"color: #003300;\"> </span>\n<p><span style=\"color: #003300;\">The function above also works for things other than alleles, like individuals with a characteristic, in which case it will be calculating the fitness of having that characteristic at the individual level.</span></p>\n<p>&nbsp;</p>\n<p><strong id=\"4__The_complexity_of_cultural_items_doesn_t_undermine_the_validity_of_mathematical_models_\">4) The complexity of cultural items doesn't undermine the validity of mathematical models.</strong></p>\n<p><strong> </strong></p>\n<p><strong id=\"_4_1__Cognitive_attractors_and_biases_substitute_for_memes_discreteness\">&nbsp;4.1) Cognitive attractors and biases substitute for memes discreteness</strong></p>\n<p>The math becomes equivalent.</p>\n<p><strong> </strong></p>\n<p><strong id=\"_4_2__Despite_the_Unilateralist_Curse_and_the_Tragedy_of_the_Commons__dyadic_interaction_models_help_us_understand_large_scale_cooperation\">&nbsp;4.2) Despite the Unilateralist Curse and the Tragedy of the Commons, dyadic interaction models help us understand large scale cooperation</strong></p>\n<p>Once we know these two failure modes, dyadic iterated (or reputation-sensitive) interaction is close enough.</p>\n<p><strong> </strong></p>\n<p><strong id=\"5__From_Monkeys_to_Apes_to_Humans_to_Transhumans_to_AIs__the_ranges_of_achievable_altruistic_skill_\">5) From Monkeys to Apes to Humans to Transhumans to AIs, the ranges of achievable altruistic skill.</strong></p>\n<p>Possible modes of being altruistic. Graph like <a href=\"http://www.posthumanism.com/space5.jpg\">Bostrom's</a>. Second and third order punishment and cooperation. Newcomb-like signaling problems within AI.</p>\n<p><strong> </strong></p>\n<p><strong id=\"6__Unfit_for_the_Future__the_need_for_greater_altruism_\">6) Unfit for the Future: the need for greater altruism.</strong></p>\n<p>We fail and will remain failing in Tragedy of the Commons problems unless we change our nature.</p>\n<p><strong> </strong></p>\n<p><strong id=\"7__From_Science__through_Philosophy__towards_Engineering__the_future_of_studies_of_altruism_\">7) From Science, through Philosophy, towards Engineering: the future of studies of altruism.</strong></p>\n<p>Philosophy: Existential Risk <a href=\"http://www.existential-risk.org/concept.html\">prevention through global coordination</a> and cooperation prior to technical maturity. Engineering Humans: creating enhancements and changing incentives. Engineering AI's: making them <a href=\"http://intelligence.org/files/RobustCooperation.pdf\">better</a> and <a href=\"https://www.youtube.com/watch?v=MwriJqBZyoM\">realer</a>.</p>\n<p><strong> </strong></p>\n<p><strong id=\"8__A_different_kind_of_Moral_Landscape\">8) A different kind of Moral Landscape</strong></p>\n<p>Like Sam Harris's one, except comparing not how much a society approaches <em>The Good Life (Moral Landscape pg15)</em>, but how much it fosters altruistic behavior.</p>\n<p><strong> </strong></p>\n<p><strong id=\"9__Conclusions\">9) Conclusions</strong></p>\n<p>Not yet.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr>\n<p>&nbsp;</p>\n<p>Bibliography (<sub>Only of the parts already written, obviously</sub>):</p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><span style=\"font-size: xx-small;\">Boyd, R., Gintis, H., Bowles, S., &amp; Richerson, P. J. (2003). <em>The evolution of altruistic punishment</em>. Proceedings of the National Academy of Sciences, 100(6), 3531-3535.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Cantor, M., &amp; Whitehead, H. (2013). The interplay between social networks and culture: theoretically and among whales and dolphins.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Philosophical Transactions of the Royal Society B: Biological Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">368</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(1618).</span></span></span></span></span></span><br><br><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><span style=\"font-size: xx-small;\">Dawkins, R. (1999). <em>The extended phenotype</em>: The long reach of the gene. Oxford University Press, USA.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1996). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Darwin's dangerous idea: Evolution and the meanings of life </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(No. 39). Simon &amp; Schuster.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Dennett, D. C. (1992). The self as a center of narrative gravity.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Self and consciousness: Multiple perspectives</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">.</span></span></span></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Galef Jr, B. G., &amp; Laland, K. N. (2005). Social learning in animals: empirical studies and theoretical models.&nbsp;</span>Bioscience<span style=\"font-style: normal;\">,&nbsp;</span>55<span style=\"font-style: normal;\">(6), 489-499.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Hauert, C., Traulsen, A., Brandt, H., Nowak, M. A., &amp; Sigmund, K. (2007). Via freedom to coercion: the emergence of costly punishment.&nbsp;</span>science<span style=\"font-style: normal;\">,&nbsp;</span>316<span style=\"font-style: normal;\">(5833), 1905-1907.</span></span></em></span></span></span></p>\n<p><span style=\"font-weight: normal;\"><span style=\"font-size: x-small;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><em><span style=\"color: #999999;\"><span style=\"font-style: normal;\">Henrich, J., Boyd, R., &amp; Richerson, P. J. (2008). Five misunderstandings about cultural evolution. </span>Human Nature<span style=\"font-style: normal;\">, </span>19<span style=\"font-style: normal;\">(2), 119-137.</span></span></em></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Hofstadter, D. R. (2007). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">I am a Strange Loop</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Basic Books</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\"><span style=\"font-size: xx-small;\">Jablonka, E., &amp; Lamb, M. J. (2007).<em> Precis of evolution in four dimensions.</em> Behavioral and Brain Sciences, 30(4), 353-364.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">McElreath, R., &amp; Boyd, R. (2007).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Mathematical models of social evolution: A guide for the perplexed</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Ottoni, E. B., de Resende, B. D., &amp; Izar, P. (2005). Watching the best nutcrackers: what capuchin monkeys (Cebus apella) know about others\u2019 tool-using skills.&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Animal cognition</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">8</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(4), 215-219.<br></span></span></span><br><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Persson, I., &amp; Savulescu, J. Unfit for the Future: The Need for Moral Enhancement Oxford: Oxford University Press, 2012 ISBN 978-0199653645 (HB)\u00a3 21.00. 160pp. On the brink of civil war, Abraham Lincoln stood on the steps of the US Capitol and appealed.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">PhilGoetz. (2010), <em>Group selection update</em>. Available at http://lesswrong.com/lw/300/group_selection_update/<br></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Pinker, S. (2007).&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">The stuff of thought: Language as a window into human nature</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Viking Adult.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Rendella, L., &amp; Whitehead, H. (2001). Culture in whales and dolphins.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and Brain Sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">24</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">, 309-382.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Richardson, P. J., &amp; Boyd, R. (2005). </span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Not by genes alone</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. University of Chicago Press.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tyler, T. (2011).&nbsp;</span></span></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><em><span style=\"font-weight: normal;\">Memetics: Memes and the Science of Cultural Evolution</span></em></span></span><span style=\"font-variant: normal;\"><span lang=\"en-US\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">. Tim Tyler.</span></span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Tomasello, M., Carpenter, M., Call, J., Behne, T., &amp; Moll, H. (2005). Understanding and sharing intentions: The origins of cultural cognition.</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">Behavioral and brain sciences</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">,&nbsp;</span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">28</span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">(5), 675-690.</span></span></span></span></span></span></p>\n<p><span style=\"color: #999999;\"><span style=\"font-family: arial,helvetica,sans-serif;\"><span style=\"font-size: x-small;\"><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Yudkowsky, E. (2008A). </span></span></span><span style=\"font-variant: normal;\"><em><span style=\"font-weight: normal;\">37 ways words can be wrong. </span></em></span><span style=\"font-variant: normal;\"><span style=\"font-style: normal;\"><span style=\"font-weight: normal;\">Available at <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/</a></span></span></span></span></span></span></p>\n</div>\n</div>\n</div>\n</div>", "sections": [{"title": "1) Introduction", "anchor": "1__Introduction", "level": 1}, {"title": "2) Cultures evolve", "anchor": "2__Cultures_evolve", "level": 1}, {"title": "4) The complexity of cultural items doesn't undermine the validity of mathematical models.", "anchor": "4__The_complexity_of_cultural_items_doesn_t_undermine_the_validity_of_mathematical_models_", "level": 1}, {"title": "\u00a04.1) Cognitive attractors and biases substitute for memes discreteness", "anchor": "_4_1__Cognitive_attractors_and_biases_substitute_for_memes_discreteness", "level": 1}, {"title": "\u00a04.2) Despite the Unilateralist Curse and the Tragedy of the Commons, dyadic interaction models help us understand large scale cooperation", "anchor": "_4_2__Despite_the_Unilateralist_Curse_and_the_Tragedy_of_the_Commons__dyadic_interaction_models_help_us_understand_large_scale_cooperation", "level": 1}, {"title": "5) From Monkeys to Apes to Humans to Transhumans to AIs, the ranges of achievable altruistic skill.", "anchor": "5__From_Monkeys_to_Apes_to_Humans_to_Transhumans_to_AIs__the_ranges_of_achievable_altruistic_skill_", "level": 1}, {"title": "6) Unfit for the Future: the need for greater altruism.", "anchor": "6__Unfit_for_the_Future__the_need_for_greater_altruism_", "level": 1}, {"title": "7) From Science, through Philosophy, towards Engineering: the future of studies of altruism.", "anchor": "7__From_Science__through_Philosophy__towards_Engineering__the_future_of_studies_of_altruism_", "level": 1}, {"title": "8) A different kind of Moral Landscape", "anchor": "8__A_different_kind_of_Moral_Landscape", "level": 1}, {"title": "9) Conclusions", "anchor": "9__Conclusions", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "4 comments"}], "headingsCount": 12}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TrmMcujGZt5JAtMGg", "GjXeKTxkYvZ5WfkFu", "FaJaCgqBKphrDzDSj", "ioWH9ERY3TTzRJFTD", "GKfPL6LQFgB49FEnv", "QGkYCwyC7wTDyt3yT", "eDpPnT7wdBwWPGvo5", "hc9Eg6erp6hk9bWhn", "7FJRnxbRtT7Sbzizs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T11:08:12.731Z", "modifiedAt": null, "url": null, "title": "Meetup : LW Vienna Meetup #4", "slug": "meetup-lw-vienna-meetup-4", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ratcourse", "createdAt": "2012-11-03T10:26:05.641Z", "isAdmin": false, "displayName": "Ratcourse"}, "userId": "qwnfbBpAcbxLT4JBr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6xKvH8853QaQ4bf32/meetup-lw-vienna-meetup-4", "pageUrlRelative": "/posts/6xKvH8853QaQ4bf32/meetup-lw-vienna-meetup-4", "linkUrl": "https://www.lesswrong.com/posts/6xKvH8853QaQ4bf32/meetup-lw-vienna-meetup-4", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20LW%20Vienna%20Meetup%20%234&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20LW%20Vienna%20Meetup%20%234%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6xKvH8853QaQ4bf32%2Fmeetup-lw-vienna-meetup-4%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20LW%20Vienna%20Meetup%20%234%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6xKvH8853QaQ4bf32%2Fmeetup-lw-vienna-meetup-4", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6xKvH8853QaQ4bf32%2Fmeetup-lw-vienna-meetup-4", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 59, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o8'>LW Vienna Meetup #4</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 July 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Universit\u00e4tsstra\u00dfe 7, 1010 Wien</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Rationality goes university take II! Meetup at the NIG, room 2G on the second floor, Universit\u00e4tsstra\u00dfe 7, 1010 Wien \nGunther Greindl on what constitutes evidence. Newcomers welcome. FB event: https://www.facebook.com/events/189961624499410/?ref=3</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o8'>LW Vienna Meetup #4</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6xKvH8853QaQ4bf32", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.247567634657576e-06, "legacy": true, "legacyId": "23128", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___LW_Vienna_Meetup__4\">Discussion article for the meetup : <a href=\"/meetups/o8\">LW Vienna Meetup #4</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 July 2013 03:00:00PM (+0200)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Universit\u00e4tsstra\u00dfe 7, 1010 Wien</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Rationality goes university take II! Meetup at the NIG, room 2G on the second floor, Universit\u00e4tsstra\u00dfe 7, 1010 Wien \nGunther Greindl on what constitutes evidence. Newcomers welcome. FB event: https://www.facebook.com/events/189961624499410/?ref=3</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___LW_Vienna_Meetup__41\">Discussion article for the meetup : <a href=\"/meetups/o8\">LW Vienna Meetup #4</a></h2>", "sections": [{"title": "Discussion article for the meetup : LW Vienna Meetup #4", "anchor": "Discussion_article_for_the_meetup___LW_Vienna_Meetup__4", "level": 1}, {"title": "Discussion article for the meetup : LW Vienna Meetup #4", "anchor": "Discussion_article_for_the_meetup___LW_Vienna_Meetup__41", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T12:17:56.737Z", "modifiedAt": null, "url": null, "title": "Vacancy at the Future of Humanity Institute: Academic Project Manager", "slug": "vacancy-at-the-future-of-humanity-institute-academic-project", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Sean_o_h", "createdAt": "2012-11-27T20:56:04.066Z", "isAdmin": false, "displayName": "Sean_o_h"}, "userId": "7ntNTAoctZqY9Nuwa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hGagTXWgYkdfhmm6t/vacancy-at-the-future-of-humanity-institute-academic-project", "pageUrlRelative": "/posts/hGagTXWgYkdfhmm6t/vacancy-at-the-future-of-humanity-institute-academic-project", "linkUrl": "https://www.lesswrong.com/posts/hGagTXWgYkdfhmm6t/vacancy-at-the-future-of-humanity-institute-academic-project", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vacancy%20at%20the%20Future%20of%20Humanity%20Institute%3A%20Academic%20Project%20Manager&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVacancy%20at%20the%20Future%20of%20Humanity%20Institute%3A%20Academic%20Project%20Manager%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhGagTXWgYkdfhmm6t%2Fvacancy-at-the-future-of-humanity-institute-academic-project%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vacancy%20at%20the%20Future%20of%20Humanity%20Institute%3A%20Academic%20Project%20Manager%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhGagTXWgYkdfhmm6t%2Fvacancy-at-the-future-of-humanity-institute-academic-project", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhGagTXWgYkdfhmm6t%2Fvacancy-at-the-future-of-humanity-institute-academic-project", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 599, "htmlBody": "<p class=\"MsoNormal\">The Future of Humanity Institute* recently secured funding for a new Research Collaboration with Amlin Insurance focusing on systemic risks associated with risk modelling. We're looking for someone with an academic background or interests and management/organisational abilities to coordinate and develop this project and area of research.</p>\n<p class=\"MsoNormal\"><strong>Who we need</strong></p>\n<p class=\"MsoNormal\">This is a unique opportunity to build a world-leading research programme. We&rsquo;re looking for someone who can not only manage this project, but who also has the drive and initiative to find new sources of funding, network with leading experts, and design future plans for the project. We&rsquo;re also looking for someone who understands and is motivated by the aims of the FHI; the post-holder will have the opportunity to contribute across the board to FHI projects, and may be a crucial part of the FHI&rsquo;s success going forward.</p>\n<p class=\"MsoNormal\">It&rsquo;s a two year position, but there will be the possibility of extension depending on the success of the project and the acquisition of further funding. We can sponsor a visa. All the details can be found <a href=\"http://www.fhi.ox.ac.uk/vacancy-academic-project-manager-at-the-future-of-humanity-institute/\">here</a>.</p>\n<p class=\"MsoNormal\"><strong>Why can you make a big difference in this role?</strong></p>\n<p class=\"MsoNormal\">I&rsquo;ve <a href=\"http://80000hours.org/blog/152-bringing-it-all-together-high-impact-research-management\">spoken to 80,000 hours</a> in the past about the impact a talented person can have in academic project management; this <a href=\"http://www.nature.com/naturejobs/science/articles/10.1038/nj7312-240a\">Nature article</a> also talks about the importance of this area of work. MIRI's recent successes are also in part due to the work of some excellent people with the right mix of research understanding and organisation-running ability.</p>\n<p class=\"MsoNormal\">While this is not a research post, your work will increase the success and impact of research done by each one of a team of top-tier academics, and will bring yet more high-quality researchers into the most important fields. This makes this position a way to achieve a huge amount of accumulative good. &nbsp;With a successful funding, development and media strategy, you can contribute to shaping the fields that the FHI is leading the world in.</p>\n<p class=\"MsoNormal\"><strong>More on the project</strong></p>\n<p class=\"MsoNormal\">Systemic risks concern the stability of an entire market, and are of great importance to managing large-scale risk. The very methods used to model these phenomena can themselves be a source of systemic risk, especially when they embody hidden assumptions that may not remain reliable in a fast-changing world. The project will focus on gaining a better understanding of systemic risks, particularly as they apply to catastropic risk modelling, and ways to avoid or mitigate such risks. Subtopics of interest are likely to include:</p>\n<ul>\n<li>Ways in which individually rational agents can misbehave when they become part of a larger network.</li>\n<li>Decision making under uncertainty.</li>\n<li>Cognitive biases that emerge when dealing with large risks, and when using the information pipelines used to model catastrophic events.</li>\n<li>How to model potential existential risks.</li>\n</ul>\n<p class=\"MsoNormal\">The current project research team are: Anders Sandberg, Stuart Armstrong and Nick Beckstead.</p>\n<p class=\"MsoNormal\"><strong>Closing date is 19th July</strong>.</p>\n<p class=\"MsoNormal\">For questions about the position please email me at sean.oheigeartaigh@philosophy.ox.ac.uk; Stuart Armstrong should also be able to answer questions. I'll try to answer as many as queries as I can, but I apologise in advance if I don't get to everyone - workload at present is very heavy. We'd be very grateful for any help in spreading the word to good people who might be interested. Thank you!</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\"><strong>*The Future of Humanity Institute</strong></p>\n<p class=\"MsoNormal\">The <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a> (Oxford) is a world-leading research centre looking at big-picture questions for human civilization.&nbsp; With the tools of mathematics, philosophy, and science, we explore the risks and opportunities that will arise from technological change, weigh ethical dilemmas, and evaluate global priorities.&nbsp; Our goal is to clarify the choices that will shape humanity&rsquo;s long-term future.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hGagTXWgYkdfhmm6t", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 22, "extendedScore": null, "score": 1.2476218128574884e-06, "legacy": true, "legacyId": "23129", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p class=\"MsoNormal\">The Future of Humanity Institute* recently secured funding for a new Research Collaboration with Amlin Insurance focusing on systemic risks associated with risk modelling. We're looking for someone with an academic background or interests and management/organisational abilities to coordinate and develop this project and area of research.</p>\n<p class=\"MsoNormal\"><strong id=\"Who_we_need\">Who we need</strong></p>\n<p class=\"MsoNormal\">This is a unique opportunity to build a world-leading research programme. We\u2019re looking for someone who can not only manage this project, but who also has the drive and initiative to find new sources of funding, network with leading experts, and design future plans for the project. We\u2019re also looking for someone who understands and is motivated by the aims of the FHI; the post-holder will have the opportunity to contribute across the board to FHI projects, and may be a crucial part of the FHI\u2019s success going forward.</p>\n<p class=\"MsoNormal\">It\u2019s a two year position, but there will be the possibility of extension depending on the success of the project and the acquisition of further funding. We can sponsor a visa. All the details can be found <a href=\"http://www.fhi.ox.ac.uk/vacancy-academic-project-manager-at-the-future-of-humanity-institute/\">here</a>.</p>\n<p class=\"MsoNormal\"><strong id=\"Why_can_you_make_a_big_difference_in_this_role_\">Why can you make a big difference in this role?</strong></p>\n<p class=\"MsoNormal\">I\u2019ve <a href=\"http://80000hours.org/blog/152-bringing-it-all-together-high-impact-research-management\">spoken to 80,000 hours</a> in the past about the impact a talented person can have in academic project management; this <a href=\"http://www.nature.com/naturejobs/science/articles/10.1038/nj7312-240a\">Nature article</a> also talks about the importance of this area of work. MIRI's recent successes are also in part due to the work of some excellent people with the right mix of research understanding and organisation-running ability.</p>\n<p class=\"MsoNormal\">While this is not a research post, your work will increase the success and impact of research done by each one of a team of top-tier academics, and will bring yet more high-quality researchers into the most important fields. This makes this position a way to achieve a huge amount of accumulative good. &nbsp;With a successful funding, development and media strategy, you can contribute to shaping the fields that the FHI is leading the world in.</p>\n<p class=\"MsoNormal\"><strong id=\"More_on_the_project\">More on the project</strong></p>\n<p class=\"MsoNormal\">Systemic risks concern the stability of an entire market, and are of great importance to managing large-scale risk. The very methods used to model these phenomena can themselves be a source of systemic risk, especially when they embody hidden assumptions that may not remain reliable in a fast-changing world. The project will focus on gaining a better understanding of systemic risks, particularly as they apply to catastropic risk modelling, and ways to avoid or mitigate such risks. Subtopics of interest are likely to include:</p>\n<ul>\n<li>Ways in which individually rational agents can misbehave when they become part of a larger network.</li>\n<li>Decision making under uncertainty.</li>\n<li>Cognitive biases that emerge when dealing with large risks, and when using the information pipelines used to model catastrophic events.</li>\n<li>How to model potential existential risks.</li>\n</ul>\n<p class=\"MsoNormal\">The current project research team are: Anders Sandberg, Stuart Armstrong and Nick Beckstead.</p>\n<p class=\"MsoNormal\"><strong>Closing date is 19th July</strong>.</p>\n<p class=\"MsoNormal\">For questions about the position please email me at sean.oheigeartaigh@philosophy.ox.ac.uk; Stuart Armstrong should also be able to answer questions. I'll try to answer as many as queries as I can, but I apologise in advance if I don't get to everyone - workload at present is very heavy. We'd be very grateful for any help in spreading the word to good people who might be interested. Thank you!</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\"><strong id=\"_The_Future_of_Humanity_Institute\">*The Future of Humanity Institute</strong></p>\n<p class=\"MsoNormal\">The <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a> (Oxford) is a world-leading research centre looking at big-picture questions for human civilization.&nbsp; With the tools of mathematics, philosophy, and science, we explore the risks and opportunities that will arise from technological change, weigh ethical dilemmas, and evaluate global priorities.&nbsp; Our goal is to clarify the choices that will shape humanity\u2019s long-term future.</p>", "sections": [{"title": "Who we need", "anchor": "Who_we_need", "level": 1}, {"title": "Why can you make a big difference in this role?", "anchor": "Why_can_you_make_a_big_difference_in_this_role_", "level": 1}, {"title": "More on the project", "anchor": "More_on_the_project", "level": 1}, {"title": "*The Future of Humanity Institute", "anchor": "_The_Future_of_Humanity_Institute", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T13:24:38.828Z", "modifiedAt": null, "url": null, "title": "Fractals and time management", "slug": "fractals-and-time-management", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:28.248Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "saph", "createdAt": "2011-07-09T08:53:07.800Z", "isAdmin": false, "displayName": "saph"}, "userId": "88eE6FAcgK9nsTzND", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C3hFuvyrMgPFBjjrx/fractals-and-time-management", "pageUrlRelative": "/posts/C3hFuvyrMgPFBjjrx/fractals-and-time-management", "linkUrl": "https://www.lesswrong.com/posts/C3hFuvyrMgPFBjjrx/fractals-and-time-management", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Fractals%20and%20time%20management&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFractals%20and%20time%20management%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC3hFuvyrMgPFBjjrx%2Ffractals-and-time-management%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Fractals%20and%20time%20management%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC3hFuvyrMgPFBjjrx%2Ffractals-and-time-management", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC3hFuvyrMgPFBjjrx%2Ffractals-and-time-management", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 518, "htmlBody": "<p>As you might know, fractal structures appear in a variety of natural situations and have found many technical applications (see&nbsp;<a title=\"Fractals\" href=\"http://en.wikipedia.org/wiki/Fractal\">Wikipedia</a>&nbsp;for more information and examples). In this short article I want to ask the question, whether it makes sense to structure various activities according to a 'fractal timetable'?</p>\n<h3>Cleaning rota</h3>\n<p>When you have to clean a flat or a house you probably you have seen a list like <a href=\"http://www.betterware.co.uk/blog/2012/04/17/cleaning-rota/\" target=\"_blank\">this</a> before. There are some tasks that one needs to do every day, others come along only once a week or once a month. Aside from those main cleaning tasks, there will be many small things you do several times during a day, like throwing something into the trash bin or washing your hands.</p>\n<p>If you analyse the structure of this behaviour, you will find that it looks similar to a one dimensional fractal (compare with the various layers in the construction of the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Cantor_set\" target=\"_blank\">Cantor set</a>, for example).</p>\n<h3>School Timetables</h3>\n<p>Most schools that I am familiar with use periodic arrangements for the teaching. You have a weekly timetable and at the same time every week you have the same subject for a whole year. This makes sense from the point of view of teacher and room allocation, but is this the best structure for optimal learning?</p>\n<p>My own experience suggests that the quality of my memory strongly depends on my understanding. If I take the time to understand everything, I will remember those things for years and can even reconstruct lost knowledge by using intuition and logical deduction. If I learned something poorly, on the other hand, I sometimes forget it completely in a matter of hours.</p>\n<p>Understanding is usually gained by a deep involvement with the topic for a longer period of time. I also find it much easier to learn something if I can focus on it for a certain period of time and examine the object/concept in detail without being disturbed by other matters.</p>\n<p>What if the best way of teaching school mathematics (for example) would be to have a 3 week long intense workshop once a year with some other 10 one day sessions allocated once a month and small homework problems evenly distributed throughout the year? The same could be done with the other subjects to fill the full school year.</p>\n<h3>Other Areas</h3>\n<p>Our motivation, health and available time fluctuate widely, but most jobs require a periodic commitment. This might be OK for mechanical jobs, but for professions with a substantial amount of creativity and cognitive demand one certainly can do better by playing around with the time/work distribution. (<a title=\"Stefan Sagmeister\" href=\"http://www.ted.com/talks/stefan_sagmeister_the_power_of_time_off.html\" target=\"_blank\">Here</a> is an interesting TED talk about a 'year off'.)</p>\n<p>Similar problems/opportunities arise in fitness, personal development and relationships.&nbsp;</p>\n<h3>Questions</h3>\n<p>I don't know, whether there are any existing studies on this topic. A superficial Google search didn't reveal anything interesting. I also would like to know, whether you had similar or contradictory experiences? Maybe I am an exception when it comes to this type of learning.</p>\n<p>Do you think that adding the mathematical model of a 'fractal' makes this approach more intuitive/useful or whether 'flexible time management' captures enough of the structure of the problem?</p>\n<p>Thanks!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C3hFuvyrMgPFBjjrx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": -1, "extendedScore": null, "score": 1.2476736393426834e-06, "legacy": true, "legacyId": "13286", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>As you might know, fractal structures appear in a variety of natural situations and have found many technical applications (see&nbsp;<a title=\"Fractals\" href=\"http://en.wikipedia.org/wiki/Fractal\">Wikipedia</a>&nbsp;for more information and examples). In this short article I want to ask the question, whether it makes sense to structure various activities according to a 'fractal timetable'?</p>\n<h3 id=\"Cleaning_rota\">Cleaning rota</h3>\n<p>When you have to clean a flat or a house you probably you have seen a list like <a href=\"http://www.betterware.co.uk/blog/2012/04/17/cleaning-rota/\" target=\"_blank\">this</a> before. There are some tasks that one needs to do every day, others come along only once a week or once a month. Aside from those main cleaning tasks, there will be many small things you do several times during a day, like throwing something into the trash bin or washing your hands.</p>\n<p>If you analyse the structure of this behaviour, you will find that it looks similar to a one dimensional fractal (compare with the various layers in the construction of the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Cantor_set\" target=\"_blank\">Cantor set</a>, for example).</p>\n<h3 id=\"School_Timetables\">School Timetables</h3>\n<p>Most schools that I am familiar with use periodic arrangements for the teaching. You have a weekly timetable and at the same time every week you have the same subject for a whole year. This makes sense from the point of view of teacher and room allocation, but is this the best structure for optimal learning?</p>\n<p>My own experience suggests that the quality of my memory strongly depends on my understanding. If I take the time to understand everything, I will remember those things for years and can even reconstruct lost knowledge by using intuition and logical deduction. If I learned something poorly, on the other hand, I sometimes forget it completely in a matter of hours.</p>\n<p>Understanding is usually gained by a deep involvement with the topic for a longer period of time. I also find it much easier to learn something if I can focus on it for a certain period of time and examine the object/concept in detail without being disturbed by other matters.</p>\n<p>What if the best way of teaching school mathematics (for example) would be to have a 3 week long intense workshop once a year with some other 10 one day sessions allocated once a month and small homework problems evenly distributed throughout the year? The same could be done with the other subjects to fill the full school year.</p>\n<h3 id=\"Other_Areas\">Other Areas</h3>\n<p>Our motivation, health and available time fluctuate widely, but most jobs require a periodic commitment. This might be OK for mechanical jobs, but for professions with a substantial amount of creativity and cognitive demand one certainly can do better by playing around with the time/work distribution. (<a title=\"Stefan Sagmeister\" href=\"http://www.ted.com/talks/stefan_sagmeister_the_power_of_time_off.html\" target=\"_blank\">Here</a> is an interesting TED talk about a 'year off'.)</p>\n<p>Similar problems/opportunities arise in fitness, personal development and relationships.&nbsp;</p>\n<h3 id=\"Questions\">Questions</h3>\n<p>I don't know, whether there are any existing studies on this topic. A superficial Google search didn't reveal anything interesting. I also would like to know, whether you had similar or contradictory experiences? Maybe I am an exception when it comes to this type of learning.</p>\n<p>Do you think that adding the mathematical model of a 'fractal' makes this approach more intuitive/useful or whether 'flexible time management' captures enough of the structure of the problem?</p>\n<p>Thanks!</p>", "sections": [{"title": "Cleaning rota", "anchor": "Cleaning_rota", "level": 1}, {"title": "School Timetables", "anchor": "School_Timetables", "level": 1}, {"title": "Other Areas", "anchor": "Other_Areas", "level": 1}, {"title": "Questions", "anchor": "Questions", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "5 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T15:35:02.675Z", "modifiedAt": null, "url": null, "title": "Weekly LW Meetups", "slug": "weekly-lw-meetups-114", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N9ycoenukgFKDutJs/weekly-lw-meetups-114", "pageUrlRelative": "/posts/N9ycoenukgFKDutJs/weekly-lw-meetups-114", "linkUrl": "https://www.lesswrong.com/posts/N9ycoenukgFKDutJs/weekly-lw-meetups-114", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Weekly%20LW%20Meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWeekly%20LW%20Meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN9ycoenukgFKDutJs%2Fweekly-lw-meetups-114%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Weekly%20LW%20Meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN9ycoenukgFKDutJs%2Fweekly-lw-meetups-114", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN9ycoenukgFKDutJs%2Fweekly-lw-meetups-114", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 476, "htmlBody": "<p><strong>This summary was posted to LW main on June 21st. The following week's summary is <a href=\"/lw/hui/new_lw_meetup_lyon/\">here</a>.</strong></p>\n<p>Irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a href=\"/meetups/nx\">Atlanta: Self-Hacking:&nbsp;<span class=\"date\">23 June 2013 06:00PM</span></a></li>\n<li><a href=\"/meetups/ng\">Bratislava Meetup IV.:&nbsp;<span class=\"date\">24 June 2013 06:00PM</span></a></li>\n<li><a href=\"/meetups/ns\">Brussels meetup with HEALES:&nbsp;<span class=\"date\">13 July 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/nn\">London Social - Exposure to Direct Sunlight - June 23rd:&nbsp;<span class=\"date\">23 June 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/nv\">[Moscow] How to use your brain:&nbsp;<span class=\"date\">23 June 2013 04:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">22 June 2019 01:30PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>, </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,&nbsp;</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N9ycoenukgFKDutJs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2477749680669177e-06, "legacy": true, "legacyId": "23034", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xovbarQtxZqvw9NJS", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T16:34:40.933Z", "modifiedAt": null, "url": null, "title": "Book: AKA Shakespeare (an extended Bayesian investigation)", "slug": "book-aka-shakespeare-an-extended-bayesian-investigation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:29.873Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xrBcCED78gsBMnFXy/book-aka-shakespeare-an-extended-bayesian-investigation", "pageUrlRelative": "/posts/xrBcCED78gsBMnFXy/book-aka-shakespeare-an-extended-bayesian-investigation", "linkUrl": "https://www.lesswrong.com/posts/xrBcCED78gsBMnFXy/book-aka-shakespeare-an-extended-bayesian-investigation", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Book%3A%20AKA%20Shakespeare%20(an%20extended%20Bayesian%20investigation)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABook%3A%20AKA%20Shakespeare%20(an%20extended%20Bayesian%20investigation)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxrBcCED78gsBMnFXy%2Fbook-aka-shakespeare-an-extended-bayesian-investigation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Book%3A%20AKA%20Shakespeare%20(an%20extended%20Bayesian%20investigation)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxrBcCED78gsBMnFXy%2Fbook-aka-shakespeare-an-extended-bayesian-investigation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxrBcCED78gsBMnFXy%2Fbook-aka-shakespeare-an-extended-bayesian-investigation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 627, "htmlBody": "<p><strong>Disclaimer:</strong> I have not read this book. I'm posting it in the expectation that others may enjoy it as much as I'm sure I would if I had time to read it myself.</p>\n<p><a href=\"http://amzn.com/0984261419\">This</a> looks interesting as an extended worked example of Bayesian reasoning (the \"scientific approach\" of the title).</p>\n<blockquote>\n<h1 class=\"parseasinTitle \" style=\"font-family: Arial, Helvetica, sans-serif; font-size: 1.7em; font-weight: normal; margin-bottom: 0px; margin-top: 0px;\"><span id=\"btAsinTitle\">AKA Shakespeare: A Scientific Approach to the Authorship Question</span></h1>\n<p><span style=\"font-family: verdana, arial, helvetica, sans-serif;\">The goal of AKA Shakespeare is to analyze the Shakespeare Authorship Question in such a way that you, Dear Reader, can review the evidence for yourself and come to your own conclusions. You will be presented with three candidates for the great playwright and poet whom we know as &ldquo;Shakespeare.&rdquo; He was either the gentleman from Stratford-upon-Avon (referred to as &ldquo;Stratford&rdquo;), Edward de Vere, Earl of Oxford (referred to as &ldquo;Oxford&rdquo;), or a vague &ldquo;somebody else&rdquo; (such as Christopher Marlowe, Henry Neville, etc., referred to as &ldquo;Ignotus&rdquo;). The book is built around 25 key questions. Concerning education, for instance, you are asked to infer Shakespeare's education level from his writings, and to compare that with the known (or more-or-less known, or speculated) education levels of Stratford, Oxford, and Ignotus. For each question, you are asked to express your opinions numerically. Rather than say &ldquo;I strongly believe &hellip;,&rdquo; you say, for instance, &ldquo;I give 10 to 1 odds that &hellip; You then enter your numbers in a chart in the book. Alternatively and preferably, you enter your numbers in the companion website aka-Shakespeare.com which contains a program, &ldquo;Prospero,&rdquo; who will process your entries and return your resulting conclusions, expressed as probabilities that Shakespeare was Stratford, or Oxford, or Ignotus. To accommodate a mix of information, debate, and speculation, AKA Shakespeare is written as a dialog involving four fictional characters who meet, drink, and talk in interesting locations&mdash;from Napa Valley to Big Sur&mdash;in Northern California. Beatrice, a professor of English literature, begins as a committed Stratfordian. Claudia, a detective-story writer, is skeptical. Her husband James (a once-successful engineer, now a less successful vintner) helps to identify the relevant questions. Martin is the scientist who develops and applies the necessary analytical procedures. (To see their portraits and biographies, open up aka-Shakespeare.com.) Beatrice and Claudia end up agreeing that the leading candidate is de Vere, with Ignotus second and Stratford a very distant third. Beatrice&rsquo;s entries lead to a final probability of 10&minus;13 (one chance in ten million million) that Shakespeare was the gentleman from Stratford-upon-Avon. Claudia&rsquo;s entries lead to an even smaller probability. James ends with the wry remark: &ldquo;We&mdash;in our smug presumed wisdom&mdash;wonder how any men or women could possibly have been so foolish as to believe that the Earth was flat. Maybe, in a hundred years&rsquo; time, people will wonder how otherwise sensible men and women could have believed that the works of Shakespeare were written by a butcher&rsquo;s apprentice from a small town in Warwickshire!&rdquo; You are encouraged to review the evidence for yourself. You may find that you agree with Beatrice, Claudia, and James. On the other hand, you may not.<br /></span><span style=\"font-family: verdana, arial, helvetica, sans-serif;\"><br /></span><a href=\"http://amzn.com/0984261419\">http://amzn.com/0984261419</a></p>\n</blockquote>\n<p>&nbsp;</p>\n<p><strong>Edited to add:</strong><br />There are many signs in the above block of text that this book is not up to Lesswrong standards. As <a href=\"/r/discussion/lw/huj/book_aka_shakespeare_an_extended_bayesian/98uh\">gwern suggests</a>, reading it should be done with an adversarial attitude.<br />I propose some more useful goals than finding someone for whom we can cheer loudly as a properly qualified member of our tribe: find worked examples that let you practice your art; find structured activities that will actually lead you to practice your art; try to critically assess arguments that use the tools we think powerful, then discuss your criticism on a forum like Lesswrong where your errors are likely to be discovered and your insights are likely to be rewarded (with tasty karma).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xrBcCED78gsBMnFXy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 0, "extendedScore": null, "score": 1.2478213158577058e-06, "legacy": true, "legacyId": "23131", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-28T21:10:30.007Z", "modifiedAt": null, "url": null, "title": "Emotional Basilisks", "slug": "emotional-basilisks", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:05.672Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "OrphanWilde", "createdAt": "2012-06-21T18:24:36.749Z", "isAdmin": false, "displayName": "OrphanWilde"}, "userId": "cdW87AS6fdK2sywL2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/faqYrJvk8LG6udh4S/emotional-basilisks", "pageUrlRelative": "/posts/faqYrJvk8LG6udh4S/emotional-basilisks", "linkUrl": "https://www.lesswrong.com/posts/faqYrJvk8LG6udh4S/emotional-basilisks", "postedAtFormatted": "Friday, June 28th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Emotional%20Basilisks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEmotional%20Basilisks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfaqYrJvk8LG6udh4S%2Femotional-basilisks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Emotional%20Basilisks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfaqYrJvk8LG6udh4S%2Femotional-basilisks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfaqYrJvk8LG6udh4S%2Femotional-basilisks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 292, "htmlBody": "<p>Suppose it is absolutely true that atheism has a negative impact on your happiness and lifespan. &nbsp;Suppose furthermore that you are the first person in your society of relatively happy theists who happened upon the idea of atheism, and moreover found absolute proof of its correctness, and quietly studied its effects on a small group of people kept isolated from the general population, and you discover that it has negative effects on happiness and lifespan. &nbsp;Suppose that it -does- free people from a considerable amount of time wasted - from your perspective as a newfound atheist - in theistic theater.</p>\n<p>Would you spread the idea?</p>\n<p>This is, in our theoretical society, the emotional equivalent of a nuclear weapon; the group you tested it on is now comparatively crippled with existentialism and doubt, and many are beginning to doubt that the continued existence of human beings is even a good thing. &nbsp;This is, for all intents and purposes, a basilisk, the mere knowledge of which causes its knower severe harm. &nbsp;Is it, in fact, a good idea to go around talking about this revolutionary new idea, which makes everybody who learns it slightly less happy? &nbsp;Would it be a -better- idea to form a secret society to go around talking to bright people likely to discover it themselves to try to keep this new idea quiet?</p>\n<p>(Please don't fight the hypothetical here. &nbsp;I know the evidence isn't nearly so perfect that atheism does in fact cause harm, as all the studies I've personally seen which suggest as much have some methodical flaws. &nbsp;This is merely a question of whether \"That which can be destroyed by the truth should be\" is, in fact, a useful position to take, in view of ideas which may actually be harmful.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "faqYrJvk8LG6udh4S", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": -8, "extendedScore": null, "score": -9e-06, "legacy": true, "legacyId": "23132", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-29T07:06:38.522Z", "modifiedAt": null, "url": null, "title": "How probable is Molecular Nanotech?", "slug": "how-probable-is-molecular-nanotech", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:39.429Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "leplen", "createdAt": "2012-11-11T22:41:09.575Z", "isAdmin": false, "displayName": "leplen"}, "userId": "cz84H76Bfm2puuBhp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZeDS9kCSzGwsxCKBW/how-probable-is-molecular-nanotech", "pageUrlRelative": "/posts/ZeDS9kCSzGwsxCKBW/how-probable-is-molecular-nanotech", "linkUrl": "https://www.lesswrong.com/posts/ZeDS9kCSzGwsxCKBW/how-probable-is-molecular-nanotech", "postedAtFormatted": "Saturday, June 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20probable%20is%20Molecular%20Nanotech%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20probable%20is%20Molecular%20Nanotech%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZeDS9kCSzGwsxCKBW%2Fhow-probable-is-molecular-nanotech%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20probable%20is%20Molecular%20Nanotech%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZeDS9kCSzGwsxCKBW%2Fhow-probable-is-molecular-nanotech", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZeDS9kCSzGwsxCKBW%2Fhow-probable-is-molecular-nanotech", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2507, "htmlBody": "<p>Circa a week ago I <a href=\"/r/discussion/lw/hs5/for_fai_is_molecular_nanotechnology_putting_our/\">posted</a> asking whether bringing up molecular nanotechnology(MNT) as a possible threat avenue for an unfriendly artificial intelligence made FAI research seem less credible because MNT seemed to me to be not obviously possible. I was told to some extent, to put up and address the science of MNT or shut up. &nbsp;A couple of people also expressed an interest in seeing a more fact and less PR oriented discussion, so I got the ball rolling and you all have no one to blame but yourselves. I should note before starting, that I do not personally have a strong opinion on whether Drexler-style MNT is possible. This isn't something I've researched previously, and I'm open to being convinced one way or the other. If MNT turns out to be likely at the end of this investigation, then hopefully this discussion can provide a good resource for LW/FAI on the topic for people like myself not yet convinced that MNT is the way of future. As far as I'm concerned, at this point all paths lead to victory.&nbsp;</p>\n<p>While&nbsp;<em>Nanosystems</em> was the canonical reference mentioned in the last conversation. I purchased it, then about 2/3rds of the way through this I figured Engines of Creation was giving me enough to work with and cancelled my order. If the science in Nanosystems is really much better than in EoC I can reorder it, but I figured we'd get started for free. 50 bucks is a lot of money to spend on an internet argument.</p>\n<p>Before I begin I would like to post the following disclaimers.</p>\n<p>1. I am not an expert in many of the claims that border on MNT. I did work at a Nanotechnology center for a year, but that experience was essentially nothing like what Drexler describes. More relevantly I am in the process of completing a Ph.D. in Physics, and my thesis work is on computational modeling of novel materials. I don't really like squishy things, so I'm very much out of my depth when it comes to discussions as to what ribosomes can and cannot accomplish, and I'll happily defer to other authorities on the more biological subjects. With that being said, several of my&nbsp;colleagues&nbsp;run MD simulations of protein folding all day every day, and if a biology issue is particularly important, I can shoot some emails around the department and try and get a more expert opinion.</p>\n<p>2. There are several difficulties in precisely addressing Drexler's arguments, because it's not always clear to me at least exactly what his arguments are. I've been going through Engines of Creation and several of his other works, and I'll present my best guess outline here. If other people would like to contribute specific claims about molecular nanotech, I'll be happy to add them to the list and do my best to address them.</p>\n<p>3. This discussion is intended to be scientific. As was pointed out previously, Drexler et al. have made many claims about time tables of when things might be invented. &nbsp;Judging the accuracy of these claims is difficult because of issues with definitions as mentioned in the previous paragraph. I'm not interested in having this discussion encompass Drexler's general prediction accuracy. Nature is the only authority I'm interested in consulting in this thread. If someone wants to make a Drexler's prediction accuracy thread, they're welcome to do so.</p>\n<p>4. If you have any questions about the science underlying anything I say, don't hesitate to ask. This is a fairly technical topic, and I'm happy to bring anyone up to speed on basic physics/chemistry terms and concepts.</p>\n<p><strong>Discussion</strong></p>\n<hr />\n<p>I'll begin by providing some background and highlighting why exactly I am not already convinced that MNT, and especially AI-assisted rapid MNT is the future, and then I'll try and address some specific claims made by Drexler in various publications.</p>\n<p><strong>Conservation of energy:</strong></p>\n<div>Feynman, and to some extent Drexler, spends an enormous amount of time addressing issues that we are familiar with from dealing with macroscopic pieces of equipment, such as how much space it takes to store things, how parts can wear out, etc. What is not mentioned in how we plan to power these Engines of Creation. Assembling nanotechnology is more than just getting atoms into the individual places you want them, it's a matter of very precise energetic control. The high resolution energy problem is equally as&nbsp;difficult&nbsp;as fine-grain control of atom positions, and this is further complicated by the fact that any energy delivery system you contrive for a nano-assembler is also going to impart momentum. In the macroscale world, your factory doesn't start sliding when you hook it up to the grid. At smaller sizes, that may not be true. It's very unclear in most of the discussions I read about these Nanofactories what's going to power them. What synthetic equivalent of ATP is going to allow us to out-compete the ribosome? What novel energy source is grey-goo going to have access to that will allow it break and reassemble the bonds necessary for nanofabrication?</div>\n<div><br /></div>\n<p><strong>Modelling is hard:</strong></p>\n<p>Solving the&nbsp;Schrodinger equation is essentially impossible. We can solve it more or less exactly for the Hydrogen atom, but things get very very difficult from there. This is because we don't have a simple solution for the <a href=\"http://en.wikipedia.org/wiki/Three-body_problem\">three-body problem</a>, much less the n-body problem. Approximately, the difficulty is that because each electron interacts with every other electron, you have a system where to determine the forces on electron 1, you need to know the position of electrons 2 through N, but the position of each of those electrons depends somewhat on electron 1. We have some tricks and approximations to get around this problem, but they're only justified empirically. The only way we know what approximations are good approximations is by testing them in experiments. Experiments are difficult and expensive, and if the AI is using MNT to gain infrastructure, then we can assume it doesn't already have the infrastructure to run its own physics lab.&nbsp;</p>\n<p><strong>A factory isn't the right analogy:</strong></p>\n<p>The discussion of nanotechnology seems to me to have an enormous emphasis on Assemblers, or nanofactories, but a factory doesn't run unless it has a steady supply of raw materials and energy resources both arriving at the correct time. The evocation of a factory calls to mind the rigid regularity of an assembly line, but the factory only works because it's situated in the larger, more chaotic world of the economy. Designing new nanofactories isn't a problem of building the factory, but a problem of designing an entire economy. There has to be a source of raw material, an energy source, and means of transporting material and energy from place to place. And, with a microscopic factory, Brownian motion may have moved the factory by the time the delivery van gets there. This fact makes the modelling problem orders of magnitude more difficult. Drexler makes a big deal about how his rigid positional world isn't like the chaotic world of the chemists, but it seems like the chaos is still there; building a factory doesn't get rid of the logistics issue.</p>\n<p><strong>Chaos</strong></p>\n<p>The reason we can't solve the n-body problem, and lots of other problems such as the <a href=\"http://en.wikipedia.org/wiki/Double_pendulum\">double pendulum</a>&nbsp;and the weather is because it turns out to be a rather unfortunate fact of nature that many systems have a very sensitive dependence on initial conditions. This means that ANY error, any unaccounted for variable, can perturb a system in dramatic ways. Since there will always be some error (at the bare minimum h/4&pi;) this means that our AI is going to have to do Monte Carlo simulations like the rest of us smucks and try to eliminate as many degrees of freedom as possible.</p>\n<p><strong>The laws of physics hold</strong></p>\n<p>I didn't think it would be necessary to mention this, but I believe that the laws of physics are pretty much the laws of physics we know right now. I would direct anyone who suggests that an AI has a shot at powering MNT with cold fusion, tachyons, or other physical phenomena not predicted by the standard model to <a href=\"/lw/ml/but_theres_still_a_chance_right/\">this post</a>. I am not saying there is no new no physics, but we understand quantum mechanics really well, and the Standard Model has been confirmed to enough decimal places that anyone who suggests something the Standard Model says can't happen is almost certainly wrong. Even if they have <a href=\"http://en.wikipedia.org/wiki/Faster-than-light#MINOS_experiment\">experimental evidence</a> that is supposed to 99.9999% percent correct.</p>\n<p>&nbsp;</p>\n<p><strong>Specific Claims</strong></p>\n<hr />\n<p>Drexler's claims about what we can do now with respect to materials science in general are true. This should be unsurprising. It is not particularly difficult to predict the past. Here are 6 claims he makes that we can't currently accomplish which I'll try and evaluate:</p>\n<ol>\n<li>Building \"gear-like\" nanostructures is possible (Toward Integrated Nanosystems)</li>\n<li>Predicting crystal structures from first principles is possible (Toward Integrated Nanosystems)</li>\n<li>Genetic engineering is a superior form of chemical synthesis to traditional chemical plants. (EoC 6)</li>\n<li>\"<em>Biochemical engineers, then, will construct new enzymes to assemble new patterns of atoms. For example, they might make an enzyme-like machine which will add carbon atoms to a small spot, layer on layer. If bonded correctly, the atoms will build up to form a fine, flexible diamond fiber having over fifty times as much strength as the same weight of aluminum</em>.\" (EoC 10)</li>\n<li>Proteins can make and break diamond bonds (EoC 11)</li>\n<li>Proteins are \"programmable\" (EoC 11)</li>\n</ol>\n<div>1. Maybe. This depends on definitions. We can build molecules that rotate, and indeed they occur naturally, but those are a long way from Drexler's proposals.&nbsp;I haven't run any simulations as to whether specific designs such as the molecular planetary gear he exhibits are actually stable. If anyone has an xyz file for one of those doodads I'll be happy to run a simulation. You might look at the <a href=\"https://www.youtube.com/watch?v=oSCX78-8-q0\">state of the art</a> and imagine that if we can make atomic flip books that molecular gears can't be too far off, but it's not really true. That video is more like molecular feet than molecular hands. We can push a molecule around on the floor, but we can't really do anything useful with it.</div>\n<p>2. True. This isn't true yet, but should be possible. I might even work on this after I graduate, if don't go hedge fund or into AI research.</p>\n<p>3. Not wrong, but misleading. The statement \"<em>Genetic engineers have now programmed bacteria to make proteins ranging from human growth hormone to rennin, an enzyme used in making cheese</em>.\" is true in the same sense that copying and pasting someone else's code constitutes programming. Splicing a gene into a plasmid is sweet, but genetic programming implies more control than we have. Similarly, the statement: <em>\"Whereas engineers running a chemical plant must work with vats of reacting chemicals (which often misarrange atoms and make noxious byproducts), engineers working with bacteria can make them absorb chemicals, carefully rearrange the atoms, and store a product or release it into the fluid around them</em>.\" implies that bacterial synthesis leads to better yields (false), that bacteria are careful(meaningless), and implies greater control over genetically modified E.Coli than we have.&nbsp;</p>\n<p>4a. False. Flexible diamond doesn't make any sense. Diamond is sp3 bonded carbon and those bonds are highly directional. They're not going to flex.. Metals are flexible because metallic bonds, unlike covalent bonds, don't confine the electrons in space. Whatever this purported carbon fiber is, it either won't be flexible, or it won't be diamond.</p>\n<p>4b. False. It isn't clear that this is even remotely possible. Enzymes don't work like this. Enzymes are catalysts for existing reactions. There is no existing reaction that results in a single carbon atom. That's an enormously energetically unfavorable state. Breaking a single carbon carbon double bond requires something like 636 kJ/mol (6.5eV) of energy. That's roughly equivalent to burning 30 units of ATP at the same time. How? How do you get all that energy into the right place at the right time? How does your enzyme manage to hold on to the carbons strongly enough to pull them apart?</p>\n<p>5. <em>\"A flexible, programmable protein machine will grasp a large molecule (the workpiece) while bringing a small molecule up against it in just the right place. Like an enzyme, it will then bond the molecules together. By bonding molecule after molecule to the workpiece, the machine will assemble a larger and larger structure while keeping complete control of how its atoms are arranged. This is the key ability that chemists have lacked.</em>\" I'm no biologist, but this isn't how proteins work. Proteins aren't Turing machines. You don't set the state and ignore them. The conformation of a protein depends intimately on its environment. The really difficult part here is that the thing it's holding, the nanopart you're trying to assemble is a big part of the protein's environment. Drexler complains around how proteins are no good because they're soft and squishy, but then he claims they're strong enough to assemble diamond and metal parts. But if the stiff nanopart that you're assembling has a dangling carbon bond waiting to filled then it's just going to cannibalize the squishy protein that's holding it. What can a protein held together by Van der Waals bonds do to a diamond? How can it control the shape it takes well enough to build a fiber?</p>\n<p>6. All of these tiny machines are repeatedly described as programmable, but that doesn't make any sense. What programs are they capable of accepting or executing? What set of instructions can a collection of 50 carbon atoms accept and execute? How are these instructions being delivered? This gets back to my factory vs. economy complaint. If nothing else, this seems an enormously sloppy use of language.</p>\n<p>&nbsp;</p>\n<p><strong>Some things that are possible</strong></p>\n<p>I think we have or will have the technology to build some interesting artificial inorganic structures in very small quantities, primarily using ultra-cold, ultra-high-vacuum laser traps. It's even possible that eventually we could create some functional objects this way, though I can't see any practical way to scale that production up.</p>\n<p>\"Nanorobots\" will be small pieces of metal or dieletric material that we manipulate with lasers or sophisticated magnetic fields, possibly attached to some sort of organic ligand. This isn't much of a prediction, we pretty much do this already. The nanoworld will continue to be statistical and messy.</p>\n<p>We will gain some inorganic control over organics like protein and DNA (though not organic over inorganic). This hasn't really been done yet that I'm aware of, but stronger bonds&gt;weaker bonds makes sense. I think there are people trying to read DNA/proteins by pushing the strands through tiny silicon windows. I feel like I heard a seminar along those lines, though I'm pretty sure I slept through it.</p>\n<p>&nbsp;</p>\n<p>That brings me through the first 12 pages of EoC or so. More to follow. Let me know if the links don't work or the formatting is terrible or I said something confusing. Also, please contribute any specific MNT claims you'd like evaluated, and any resources or publications you think are relevant. Thank you.</p>\n<p><strong>Bibliography</strong></p>\n<hr />\n<p><a href=\"http://xaonon.dyndns.org/misc/engines_of_creation.pdf\">Engines of Creation</a></p>\n<p><a href=\"http://e-drexler.com/d/06/00/NanosysDesign.pdf\">Toward Integrated Nanosystems</a></p>\n<p><a href=\"http://www.amazon.com/Molecular-Devices-Machines-Vincenzo-Balzani/dp/3527318003\">Molecular Devices and Machines</a>)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 2, "XJjvxWB68GYpts93N": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZeDS9kCSzGwsxCKBW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 56, "baseScore": 66, "extendedScore": null, "score": 0.00013208894321614022, "legacy": true, "legacyId": "23136", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 45, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Circa a week ago I <a href=\"/r/discussion/lw/hs5/for_fai_is_molecular_nanotechnology_putting_our/\">posted</a> asking whether bringing up molecular nanotechnology(MNT) as a possible threat avenue for an unfriendly artificial intelligence made FAI research seem less credible because MNT seemed to me to be not obviously possible. I was told to some extent, to put up and address the science of MNT or shut up. &nbsp;A couple of people also expressed an interest in seeing a more fact and less PR oriented discussion, so I got the ball rolling and you all have no one to blame but yourselves. I should note before starting, that I do not personally have a strong opinion on whether Drexler-style MNT is possible. This isn't something I've researched previously, and I'm open to being convinced one way or the other. If MNT turns out to be likely at the end of this investigation, then hopefully this discussion can provide a good resource for LW/FAI on the topic for people like myself not yet convinced that MNT is the way of future. As far as I'm concerned, at this point all paths lead to victory.&nbsp;</p>\n<p>While&nbsp;<em>Nanosystems</em> was the canonical reference mentioned in the last conversation. I purchased it, then about 2/3rds of the way through this I figured Engines of Creation was giving me enough to work with and cancelled my order. If the science in Nanosystems is really much better than in EoC I can reorder it, but I figured we'd get started for free. 50 bucks is a lot of money to spend on an internet argument.</p>\n<p>Before I begin I would like to post the following disclaimers.</p>\n<p>1. I am not an expert in many of the claims that border on MNT. I did work at a Nanotechnology center for a year, but that experience was essentially nothing like what Drexler describes. More relevantly I am in the process of completing a Ph.D. in Physics, and my thesis work is on computational modeling of novel materials. I don't really like squishy things, so I'm very much out of my depth when it comes to discussions as to what ribosomes can and cannot accomplish, and I'll happily defer to other authorities on the more biological subjects. With that being said, several of my&nbsp;colleagues&nbsp;run MD simulations of protein folding all day every day, and if a biology issue is particularly important, I can shoot some emails around the department and try and get a more expert opinion.</p>\n<p>2. There are several difficulties in precisely addressing Drexler's arguments, because it's not always clear to me at least exactly what his arguments are. I've been going through Engines of Creation and several of his other works, and I'll present my best guess outline here. If other people would like to contribute specific claims about molecular nanotech, I'll be happy to add them to the list and do my best to address them.</p>\n<p>3. This discussion is intended to be scientific. As was pointed out previously, Drexler et al. have made many claims about time tables of when things might be invented. &nbsp;Judging the accuracy of these claims is difficult because of issues with definitions as mentioned in the previous paragraph. I'm not interested in having this discussion encompass Drexler's general prediction accuracy. Nature is the only authority I'm interested in consulting in this thread. If someone wants to make a Drexler's prediction accuracy thread, they're welcome to do so.</p>\n<p>4. If you have any questions about the science underlying anything I say, don't hesitate to ask. This is a fairly technical topic, and I'm happy to bring anyone up to speed on basic physics/chemistry terms and concepts.</p>\n<p><strong id=\"Discussion\">Discussion</strong></p>\n<hr>\n<p>I'll begin by providing some background and highlighting why exactly I am not already convinced that MNT, and especially AI-assisted rapid MNT is the future, and then I'll try and address some specific claims made by Drexler in various publications.</p>\n<p><strong id=\"Conservation_of_energy_\">Conservation of energy:</strong></p>\n<div>Feynman, and to some extent Drexler, spends an enormous amount of time addressing issues that we are familiar with from dealing with macroscopic pieces of equipment, such as how much space it takes to store things, how parts can wear out, etc. What is not mentioned in how we plan to power these Engines of Creation. Assembling nanotechnology is more than just getting atoms into the individual places you want them, it's a matter of very precise energetic control. The high resolution energy problem is equally as&nbsp;difficult&nbsp;as fine-grain control of atom positions, and this is further complicated by the fact that any energy delivery system you contrive for a nano-assembler is also going to impart momentum. In the macroscale world, your factory doesn't start sliding when you hook it up to the grid. At smaller sizes, that may not be true. It's very unclear in most of the discussions I read about these Nanofactories what's going to power them. What synthetic equivalent of ATP is going to allow us to out-compete the ribosome? What novel energy source is grey-goo going to have access to that will allow it break and reassemble the bonds necessary for nanofabrication?</div>\n<div><br></div>\n<p><strong id=\"Modelling_is_hard_\">Modelling is hard:</strong></p>\n<p>Solving the&nbsp;Schrodinger equation is essentially impossible. We can solve it more or less exactly for the Hydrogen atom, but things get very very difficult from there. This is because we don't have a simple solution for the <a href=\"http://en.wikipedia.org/wiki/Three-body_problem\">three-body problem</a>, much less the n-body problem. Approximately, the difficulty is that because each electron interacts with every other electron, you have a system where to determine the forces on electron 1, you need to know the position of electrons 2 through N, but the position of each of those electrons depends somewhat on electron 1. We have some tricks and approximations to get around this problem, but they're only justified empirically. The only way we know what approximations are good approximations is by testing them in experiments. Experiments are difficult and expensive, and if the AI is using MNT to gain infrastructure, then we can assume it doesn't already have the infrastructure to run its own physics lab.&nbsp;</p>\n<p><strong id=\"A_factory_isn_t_the_right_analogy_\">A factory isn't the right analogy:</strong></p>\n<p>The discussion of nanotechnology seems to me to have an enormous emphasis on Assemblers, or nanofactories, but a factory doesn't run unless it has a steady supply of raw materials and energy resources both arriving at the correct time. The evocation of a factory calls to mind the rigid regularity of an assembly line, but the factory only works because it's situated in the larger, more chaotic world of the economy. Designing new nanofactories isn't a problem of building the factory, but a problem of designing an entire economy. There has to be a source of raw material, an energy source, and means of transporting material and energy from place to place. And, with a microscopic factory, Brownian motion may have moved the factory by the time the delivery van gets there. This fact makes the modelling problem orders of magnitude more difficult. Drexler makes a big deal about how his rigid positional world isn't like the chaotic world of the chemists, but it seems like the chaos is still there; building a factory doesn't get rid of the logistics issue.</p>\n<p><strong id=\"Chaos\">Chaos</strong></p>\n<p>The reason we can't solve the n-body problem, and lots of other problems such as the <a href=\"http://en.wikipedia.org/wiki/Double_pendulum\">double pendulum</a>&nbsp;and the weather is because it turns out to be a rather unfortunate fact of nature that many systems have a very sensitive dependence on initial conditions. This means that ANY error, any unaccounted for variable, can perturb a system in dramatic ways. Since there will always be some error (at the bare minimum h/4\u03c0) this means that our AI is going to have to do Monte Carlo simulations like the rest of us smucks and try to eliminate as many degrees of freedom as possible.</p>\n<p><strong id=\"The_laws_of_physics_hold\">The laws of physics hold</strong></p>\n<p>I didn't think it would be necessary to mention this, but I believe that the laws of physics are pretty much the laws of physics we know right now. I would direct anyone who suggests that an AI has a shot at powering MNT with cold fusion, tachyons, or other physical phenomena not predicted by the standard model to <a href=\"/lw/ml/but_theres_still_a_chance_right/\">this post</a>. I am not saying there is no new no physics, but we understand quantum mechanics really well, and the Standard Model has been confirmed to enough decimal places that anyone who suggests something the Standard Model says can't happen is almost certainly wrong. Even if they have <a href=\"http://en.wikipedia.org/wiki/Faster-than-light#MINOS_experiment\">experimental evidence</a> that is supposed to 99.9999% percent correct.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Specific_Claims\">Specific Claims</strong></p>\n<hr>\n<p>Drexler's claims about what we can do now with respect to materials science in general are true. This should be unsurprising. It is not particularly difficult to predict the past. Here are 6 claims he makes that we can't currently accomplish which I'll try and evaluate:</p>\n<ol>\n<li>Building \"gear-like\" nanostructures is possible (Toward Integrated Nanosystems)</li>\n<li>Predicting crystal structures from first principles is possible (Toward Integrated Nanosystems)</li>\n<li>Genetic engineering is a superior form of chemical synthesis to traditional chemical plants. (EoC 6)</li>\n<li>\"<em>Biochemical engineers, then, will construct new enzymes to assemble new patterns of atoms. For example, they might make an enzyme-like machine which will add carbon atoms to a small spot, layer on layer. If bonded correctly, the atoms will build up to form a fine, flexible diamond fiber having over fifty times as much strength as the same weight of aluminum</em>.\" (EoC 10)</li>\n<li>Proteins can make and break diamond bonds (EoC 11)</li>\n<li>Proteins are \"programmable\" (EoC 11)</li>\n</ol>\n<div>1. Maybe. This depends on definitions. We can build molecules that rotate, and indeed they occur naturally, but those are a long way from Drexler's proposals.&nbsp;I haven't run any simulations as to whether specific designs such as the molecular planetary gear he exhibits are actually stable. If anyone has an xyz file for one of those doodads I'll be happy to run a simulation. You might look at the <a href=\"https://www.youtube.com/watch?v=oSCX78-8-q0\">state of the art</a> and imagine that if we can make atomic flip books that molecular gears can't be too far off, but it's not really true. That video is more like molecular feet than molecular hands. We can push a molecule around on the floor, but we can't really do anything useful with it.</div>\n<p>2. True. This isn't true yet, but should be possible. I might even work on this after I graduate, if don't go hedge fund or into AI research.</p>\n<p>3. Not wrong, but misleading. The statement \"<em>Genetic engineers have now programmed bacteria to make proteins ranging from human growth hormone to rennin, an enzyme used in making cheese</em>.\" is true in the same sense that copying and pasting someone else's code constitutes programming. Splicing a gene into a plasmid is sweet, but genetic programming implies more control than we have. Similarly, the statement: <em>\"Whereas engineers running a chemical plant must work with vats of reacting chemicals (which often misarrange atoms and make noxious byproducts), engineers working with bacteria can make them absorb chemicals, carefully rearrange the atoms, and store a product or release it into the fluid around them</em>.\" implies that bacterial synthesis leads to better yields (false), that bacteria are careful(meaningless), and implies greater control over genetically modified E.Coli than we have.&nbsp;</p>\n<p>4a. False. Flexible diamond doesn't make any sense. Diamond is sp3 bonded carbon and those bonds are highly directional. They're not going to flex.. Metals are flexible because metallic bonds, unlike covalent bonds, don't confine the electrons in space. Whatever this purported carbon fiber is, it either won't be flexible, or it won't be diamond.</p>\n<p>4b. False. It isn't clear that this is even remotely possible. Enzymes don't work like this. Enzymes are catalysts for existing reactions. There is no existing reaction that results in a single carbon atom. That's an enormously energetically unfavorable state. Breaking a single carbon carbon double bond requires something like 636 kJ/mol (6.5eV) of energy. That's roughly equivalent to burning 30 units of ATP at the same time. How? How do you get all that energy into the right place at the right time? How does your enzyme manage to hold on to the carbons strongly enough to pull them apart?</p>\n<p>5. <em>\"A flexible, programmable protein machine will grasp a large molecule (the workpiece) while bringing a small molecule up against it in just the right place. Like an enzyme, it will then bond the molecules together. By bonding molecule after molecule to the workpiece, the machine will assemble a larger and larger structure while keeping complete control of how its atoms are arranged. This is the key ability that chemists have lacked.</em>\" I'm no biologist, but this isn't how proteins work. Proteins aren't Turing machines. You don't set the state and ignore them. The conformation of a protein depends intimately on its environment. The really difficult part here is that the thing it's holding, the nanopart you're trying to assemble is a big part of the protein's environment. Drexler complains around how proteins are no good because they're soft and squishy, but then he claims they're strong enough to assemble diamond and metal parts. But if the stiff nanopart that you're assembling has a dangling carbon bond waiting to filled then it's just going to cannibalize the squishy protein that's holding it. What can a protein held together by Van der Waals bonds do to a diamond? How can it control the shape it takes well enough to build a fiber?</p>\n<p>6. All of these tiny machines are repeatedly described as programmable, but that doesn't make any sense. What programs are they capable of accepting or executing? What set of instructions can a collection of 50 carbon atoms accept and execute? How are these instructions being delivered? This gets back to my factory vs. economy complaint. If nothing else, this seems an enormously sloppy use of language.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Some_things_that_are_possible\">Some things that are possible</strong></p>\n<p>I think we have or will have the technology to build some interesting artificial inorganic structures in very small quantities, primarily using ultra-cold, ultra-high-vacuum laser traps. It's even possible that eventually we could create some functional objects this way, though I can't see any practical way to scale that production up.</p>\n<p>\"Nanorobots\" will be small pieces of metal or dieletric material that we manipulate with lasers or sophisticated magnetic fields, possibly attached to some sort of organic ligand. This isn't much of a prediction, we pretty much do this already. The nanoworld will continue to be statistical and messy.</p>\n<p>We will gain some inorganic control over organics like protein and DNA (though not organic over inorganic). This hasn't really been done yet that I'm aware of, but stronger bonds&gt;weaker bonds makes sense. I think there are people trying to read DNA/proteins by pushing the strands through tiny silicon windows. I feel like I heard a seminar along those lines, though I'm pretty sure I slept through it.</p>\n<p>&nbsp;</p>\n<p>That brings me through the first 12 pages of EoC or so. More to follow. Let me know if the links don't work or the formatting is terrible or I said something confusing. Also, please contribute any specific MNT claims you'd like evaluated, and any resources or publications you think are relevant. Thank you.</p>\n<p><strong id=\"Bibliography\">Bibliography</strong></p>\n<hr>\n<p><a href=\"http://xaonon.dyndns.org/misc/engines_of_creation.pdf\">Engines of Creation</a></p>\n<p><a href=\"http://e-drexler.com/d/06/00/NanosysDesign.pdf\">Toward Integrated Nanosystems</a></p>\n<p><a href=\"http://www.amazon.com/Molecular-Devices-Machines-Vincenzo-Balzani/dp/3527318003\">Molecular Devices and Machines</a>)</p>", "sections": [{"title": "Discussion", "anchor": "Discussion", "level": 1}, {"title": "Conservation of energy:", "anchor": "Conservation_of_energy_", "level": 1}, {"title": "Modelling is hard:", "anchor": "Modelling_is_hard_", "level": 1}, {"title": "A factory isn't the right analogy:", "anchor": "A_factory_isn_t_the_right_analogy_", "level": 1}, {"title": "Chaos", "anchor": "Chaos", "level": 1}, {"title": "The laws of physics hold", "anchor": "The_laws_of_physics_hold", "level": 1}, {"title": "Specific Claims", "anchor": "Specific_Claims", "level": 1}, {"title": "Some things that are possible", "anchor": "Some_things_that_are_possible", "level": 1}, {"title": "Bibliography", "anchor": "Bibliography", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "56 comments"}], "headingsCount": 11}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9JKdnAakjCtvxTReJ", "q7Me34xvSG3Wm97As"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-29T23:36:06.042Z", "modifiedAt": null, "url": null, "title": "An attempt at a short no-prerequisite test for programming inclination", "slug": "an-attempt-at-a-short-no-prerequisite-test-for-programming", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:37.774Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ShardPhoenix", "createdAt": "2009-03-15T10:30:51.202Z", "isAdmin": false, "displayName": "ShardPhoenix"}, "userId": "yKRJEGkWmudHAihtv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gGMSWouCiPGAaxgWn/an-attempt-at-a-short-no-prerequisite-test-for-programming", "pageUrlRelative": "/posts/gGMSWouCiPGAaxgWn/an-attempt-at-a-short-no-prerequisite-test-for-programming", "linkUrl": "https://www.lesswrong.com/posts/gGMSWouCiPGAaxgWn/an-attempt-at-a-short-no-prerequisite-test-for-programming", "postedAtFormatted": "Saturday, June 29th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20attempt%20at%20a%20short%20no-prerequisite%20test%20for%20programming%20inclination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20attempt%20at%20a%20short%20no-prerequisite%20test%20for%20programming%20inclination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgGMSWouCiPGAaxgWn%2Fan-attempt-at-a-short-no-prerequisite-test-for-programming%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20attempt%20at%20a%20short%20no-prerequisite%20test%20for%20programming%20inclination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgGMSWouCiPGAaxgWn%2Fan-attempt-at-a-short-no-prerequisite-test-for-programming", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgGMSWouCiPGAaxgWn%2Fan-attempt-at-a-short-no-prerequisite-test-for-programming", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 635, "htmlBody": "<p>There has been previous discussion on LW on the topic of how to quickly determine if someone might be good at programming. This is relevant because this is currently a good career field that can be relatively easy to enter, and because programming-style thinking is often relevant to LW topics (eg decision theory). In light of this I've created the following test, which is based on my memory of a test from an interview process for a programming job. It attempts to test common low-level concepts from programming such as sequence, assignment, indirection, and recursion, in a way that doesn't require any previous programming experience (although previous experience will likely make it easier).</p>\n<p>This test is aimed at getting a quick clear positive, so the fact that someone does poorly on it doesn't mean they can't become a programmer (ie I'd guess it's likely to generate false negatives rather than false positives). This test is obviously lacking scientific validation, and is probably too short, but I'd like to start somewhere.</p>\n<p>I'd like to invite both programmers and non-programmers to take the test for comparison. It should only take about 5 minutes. If you do the test, please also take the short poll in the comments for feedback and calibration purposes, regardless of what result you got.</p>\n<p>-----&nbsp; Test begins below&nbsp; -----</p>\n<p>This is a 1-question algorithmic thinking exercise that should take less than 5 minutes.</p>\n<p>Pen and paper is required. There should be no prerequisites beyond basic arithmetic. <br /><br />First, write down the following sequence of numbered boxes. You will be writing numbers in some of the boxes more than once, so either use a pencil or make the boxes big enough to cross out and replace numbers.</p>\n<pre><p>&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp; 2&nbsp;&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp; 4&nbsp;&nbsp;&nbsp; 5&nbsp;&nbsp;&nbsp; 6&nbsp;&nbsp;&nbsp; 7&nbsp;&nbsp;&nbsp; 8\n</p><p>&nbsp;&nbsp; [&nbsp; ] [&nbsp; ] [&nbsp; ] [&nbsp; ] [&nbsp; ] [&nbsp; ] [&nbsp; ] [&nbsp; ]</p></pre>\n<p>Following is a sequence of numbered steps. Do the steps in the order they are numbered (unless instructed otherwise). Note that \"write a number in a box\" means \"cross out the previous number and write the new number\".</p>\n<p>1. Write 1 in box 3, 2 in box 6, 9 in box 4, 1 in box 5, 5 in box 8, and 0 in the remaining boxes.</p>\n<p>2. In box 4, write the sum of the number in box 3 and the number in box 5.</p>\n<p>3. In both boxes 2 and 5, write the the number in box 8 minus the number in box 6</p>\n<p>4. Write 1 in the box whose number is in box 3</p>\n<p>5. In box 3, write the sum of the number in box 3 and the number in box 4</p>\n<p>6. In the box whose number is in box 6, write the sum of the number that's in the box whose number is in box 4, and the number that's in box 5.</p>\n<p>7. Do step 2 again, then continue directly on to step 8.</p>\n<p>8. Do step 4 again, but this time with box 4 instead of box 3, then continue directly to step 9.</p>\n<p>9. The final result is the number that is in the box whose number is the number that is in the box whose number is equal to 2 plus the number that is in box 4. End of test.</p>\n<p>--------------</p>\n<p>Expected Results: <a href=\"http://pastebin.com/wA6xDxVb\">http://pastebin.com/wA6xDxVb</a></p>\n<p>Thanks for taking the test! Don't forget to answer the poll in the comments too.</p>\n<p>I'd also appreciate any feedback on the test, both if you think its going in the right direction or not and if you think there are specific improvements that could be made.</p>\n<p>edit: As some commenters have pointed out, there was a previous attempt at such a test that you may have heard of: http://www.eis.mdx.ac.uk/research/PhDArea/saeed/</p>\n<p>However, it seems that further investigation found that their test, while better than nothing, wasn't very accurate. The test given in this post takes a different approach.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gGMSWouCiPGAaxgWn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "23135", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-30T01:22:02.743Z", "modifiedAt": null, "url": null, "title": "Harry Potter and the Methods of Rationality discussion thread, part 19, chapter 88-89 ", "slug": "harry-potter-and-the-methods-of-rationality-discussion-1", "viewCount": null, "lastCommentedAt": "2017-06-17T04:24:07.832Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Pxiu5SG8gjhCh2jYd/harry-potter-and-the-methods-of-rationality-discussion-1", "pageUrlRelative": "/posts/Pxiu5SG8gjhCh2jYd/harry-potter-and-the-methods-of-rationality-discussion-1", "linkUrl": "https://www.lesswrong.com/posts/Pxiu5SG8gjhCh2jYd/harry-potter-and-the-methods-of-rationality-discussion-1", "postedAtFormatted": "Sunday, June 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2019%2C%20chapter%2088-89%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2019%2C%20chapter%2088-89%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPxiu5SG8gjhCh2jYd%2Fharry-potter-and-the-methods-of-rationality-discussion-1%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2019%2C%20chapter%2088-89%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPxiu5SG8gjhCh2jYd%2Fharry-potter-and-the-methods-of-rationality-discussion-1", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPxiu5SG8gjhCh2jYd%2Fharry-potter-and-the-methods-of-rationality-discussion-1", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 19px;\">This is a new thread to discuss Eliezer Yudkowsky&rsquo;s&nbsp;<em><a style=\"color: #8a8a8b;\" href=\"http://www.fanfiction.net/s/5782108/1/\">Harry Potter and the Methods of Rationality</a></em>&nbsp;and anything related to it. This thread is intended for discussing&nbsp;<a href=\"http://www.fanfiction.net/s/5782108/88/Harry-Potter-and-the-Methods-of-Rationality\"><span style=\"color: #8a8a8b;\">chapter</span></a> <a href=\"http://hpmor.com/chapter/88\">88-89</a>.&nbsp;<a href=\"/lw/g1q/harry_potter_and_the_methods_of_rationality/\"><span style=\"color: #8a8a8b;\">The previous thread</span></a>&nbsp;has passed 500 comments.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 19px;\">There is now a site dedicated to the story at&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/\">hpmor.com</a>, which is now the place to go to find the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/notes/\">authors notes</a>&nbsp;and all sorts of other goodies. AdeleneDawner has kept an&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://www.evernote.com/pub/adelenedawner/Eliezer\">archive of Author&rsquo;s Notes</a>.  (This goes up to the notes for chapter 76, and is now not updating. The  authors notes from chapter 77 onwards are on hpmor.com.)&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 19px;\">The first 5 discussion threads are on the main page under the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/tag/harry_potter/\">harry_potter tag</a>.&nbsp; Threads 6 and on (including this one) are in the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/tag/harry_potter/\">discussion section</a>&nbsp;using its separate tag system.&nbsp; Also:&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/2ab/harry_potter_and_the_methods_of_rationality\">1</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/2ie/harry_potter_and_the_methods_of_rationality\">2</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/2nm/harry_potter_and_the_methods_of_rationality\">3</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/2tr/harry_potter_and_the_methods_of_rationality\">4</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/30g/harry_potter_and_the_methods_of_rationality\">5</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/364/harry_potter_and_the_methods_of_rationality/\">6</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/3rb/harry_potter_and_the_methods_of_rationality/\">7</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/797/harry_potter_and_the_methods_of_rationality/\">8</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/7jd/harry_potter_and_the_methods_of_rationality\">9</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/ams/harry_potter_and_the_methods_of_rationality\">10</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/axe/harry_potter_and_the_methods_of_rationality/\">11</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/b5s/harry_potter_and_the_methods_of_rationality/\">12</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/b7s/harry_potter_and_the_methods_of_rationality/\">13</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/bfo/harry_potter_and_the_methods_of_rationality/\">14</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/bmx/harry_potter_and_the_methods_of_rationality/\">15</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/r/discussion/lw/bto/harry_potter_and_the_methods_of_rationality/\">16</a>, <a href=\"http://lesswrong.com/lw/fyv/harry_potter_and_the_methods_of_rationality/\">17</a>, <a href=\"/lw/g1q/harry_potter_and_the_methods_of_rationality/\">18</a>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 19px;\"><strong>Spoiler Warning</strong>:  this thread is full of spoilers. With few exceptions, spoilers for MOR  and canon are fair game to post, without warning or rot13.&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://lesswrong.com/lw/2tr/harry_potter_and_the_methods_of_rationality/2v1l\">More specifically</a>:</p>\n<blockquote style=\"font-family: Arial, Helvetica, sans-serif; text-align: justify; line-height: 19px;\">\n<p style=\"margin: 0px 0px 1em;\">You do not need to rot13 anything about  HP:MoR or the original Harry Potter series unless you are posting  insider information from Eliezer Yudkowsky which is not supposed to be  publicly available (which includes public statements by Eliezer that  have been retracted).</p>\n<p style=\"margin: 0px 0px 1em;\">If there is evidence for X in MOR and/or  canon then it&rsquo;s fine to post about X without rot13, even if you also  have heard privately from Eliezer that X is true. But you should not  post that &ldquo;Eliezer said X is true&rdquo; unless you use rot13.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yrg267i4a8EsgYAXp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Pxiu5SG8gjhCh2jYd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 18, "extendedScore": null, "score": 1.2493519761534721e-06, "legacy": true, "legacyId": "23138", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 963, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["35GjH7tDvNJWSHQ3H", "59rDBidWmmJTXL4Np", "xexS9nyzwRgP9sowp", "LzQcmBwAJBGyzrt6Z", "qKzeJvFWyPh5H2hwj", "nnnd4KRQxs6DYcehD", "y2Hszb4Dsm5FggnDC", "6ae2kq3JmKvL4YPgk", "zvXfBqp6TSriNkmbg", "WQ7XMjqvuRRj8nkpu", "LKFR5pBA3bBkERDxL", "8yEdpDpGgvDWHeodM", "K4JBpAxhvstdnNbeg", "xK6Pswbozev6pv4A6", "pBTcCB5uJTzADdMm4", "XN4WDRSPFo9iGEuk3", "QkhX5YeuYHzPW7Waz", "4sY9rqAqty8rHWGSW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-30T02:38:00.967Z", "modifiedAt": null, "url": null, "title": "Why one-box?", "slug": "why-one-box", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:57.627Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilosophyStudent", "createdAt": "2013-06-19T23:24:21.499Z", "isAdmin": false, "displayName": "PhilosophyStudent"}, "userId": "KYqEJXmR5EaCaW279", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ih2eMfnRz7hdTDHEm/why-one-box", "pageUrlRelative": "/posts/ih2eMfnRz7hdTDHEm/why-one-box", "linkUrl": "https://www.lesswrong.com/posts/ih2eMfnRz7hdTDHEm/why-one-box", "postedAtFormatted": "Sunday, June 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20one-box%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20one-box%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fih2eMfnRz7hdTDHEm%2Fwhy-one-box%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20one-box%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fih2eMfnRz7hdTDHEm%2Fwhy-one-box", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fih2eMfnRz7hdTDHEm%2Fwhy-one-box", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1031, "htmlBody": "<p><span style=\"color: #222222; font-family: arial;\">I have sympathy with both one-boxers and two-boxers in Newcomb's problem. Contrary to this, however, many people on Less Wrong seem to be staunch and confident one-boxers. So I'm turning to you guys to ask for help figuring out whether I should be a staunch one-boxer too. Below is an imaginary dialogue setting out my understanding of the arguments normally advanced on LW for one-boxing and I was hoping to get help filling in the details and extending this argument so that I (and anyone else who is uncertain about the issue) can develop an understanding of the strongest arguments for one-boxing.</span></p>\n<div style=\"color: #222222; font-family: arial;\">One-boxer: You should one-box because one-boxing wins (that is, a person that one-boxes ends up better off than a person that two-boxes). Not only does it seem clear that rationality should be about winning generally (that a rational agent should not be systematically outperformed by irrational agents) but Newcomb's problem is normally discussed within the context of instrumental rationality, which everyone agrees is about winning.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">Me: I get that and that's one of the main reasons I'm sympathetic to the one-boxing view but the two-boxers has a response to these concerns. The two-boxer agrees that rationality is about winning and they agree that winning means ending up with the most utility. The two-boxer should also agree that the rational <em>decision theory</em> to follow is one that will one-box on all future Newcomb's problems (those where the prediction has not yet occurred) and can also agree that the best <em>timeless agent type</em>&nbsp;is a one-boxing type. However, the two-boxer also claims that two-boxing is the rational <em>decision</em>.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">O: Sure, but why think they're right? After all, two-boxers don't win.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">M: Okay, those with a two-boxing <em>agent type</em> don't win but the two-boxer isn't talking about agent types. They're talking about decisions. So they are interested in what aspects of the agent's winning can be attributed to their decision and they say that we can attribute the agent's winning to their decision if this is caused by their decision. This strikes me as quite a reasonable way to apportion the credit for various parts of the winning. (Of course, it could be said that the two-boxer is right but they are playing a pointless game and should instead be interested in winning simpliciter rather than winning decisions. If this is the claim then the argument is dissolved and there is no disagreement. But I take it this is not the claim).</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">O: But this is a strange convoluted definition of winning. The agent ends up worse off than one-boxing agents so it must be a convoluted definition of winning that says that two-boxing is the winning decision.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">M: Hmm, maybe... But I'm worried that relevant distinctions aren't being made here (you've started talking about winning agents rather than winning decisions). The two-boxer relies on the same definition of winning as you and so agrees that the one-boxing agent is the winning agent. They just disagree about how to attribute winning to the agent's decisions (rather than to other features of the agent). And their way of doing this strikes me as quite a natural one. We credit the decision with the winning that it causes. Is this the source of my unwillingness to jump fully on board with your program? Do we simply disagree about the plausibility of this way of attributing winning to decisions?</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">Meta-comment (a): I don't know what to say here? Is this what's going on? Do people just intuitively feel that this is a crazy way to attribute winning to decisions? If so, can anyone suggest why I should adopt the one-boxer perspective on this?</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">O: But then the two-boxer has to rely on the claim that Newcomb's problem is \"unfair\" to explain why the two-boxing agent doesn't win. It seems absurd to say that a scenario like Newcomb's problem is unfair.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">M: Well, the two-boxing agent means something very particular by \"unfair\". They simply mean that in this case the winning agent doesn't correspond to the winning decision. Further, they can explain why this is the case without saying anything that strikes me as crazy. They simply say that Newcomb's problem is a case where the agent's winnings can't entirely be attributed to the agent's decision (ignoring a constant value). But if something else (the agent's type at time of prediction) also influences the agent's winning in this case, why should it be a surprise that the winning agent and the winning decision come apart? I'm not saying the two-boxer is right here but they don't seem to me to be obviously wrong either...</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">Meta-comment (b): Interested to know what response should be given here.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">O: Okay, let's try something else. The two-boxer focuses only on causal consequences but in doing so they simply ignore all the logical non-causal consequences of their decision algorithm outputting a certain decision. This is an ad hoc, unmotivated restriction.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">M: Ah hoc? I'm not sure I see why. Think about the problem with evidential decision theory. The proponent of EDT could say a similar thing (that the proponent of two-boxing ignores all the evidential implications of their decision). The two-boxer will respond that these implications just are not relevant to decision making. When we make decisions we are trying to bring about the best results, not get evidence for these results. Equally, they might say, we are trying to bring about the best results, not derive the best results in our logical calculations. Now I don't know what to make of the point/counter-point here but it doesn't seem to me that the one-boxing view is obviously correct here and I'm worried that we're again going to end up just trading intuitions (and I can see the force of both intuitions here).</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">Meta-comment: Again, I would love to know whether I've understood this argument and whether something can be said to convince me that the one-boxing view is the clear cut winner here.</div>\n<div style=\"color: #222222; font-family: arial;\"><br /></div>\n<div style=\"color: #222222; font-family: arial;\">End comments: That's my understanding of the primary argument advanced for one-boxing on LW. Are there other core arguments? How can these arguments be improved and extended?</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ih2eMfnRz7hdTDHEm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 10, "extendedScore": null, "score": 1.2494111497188457e-06, "legacy": true, "legacyId": "23139", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 98, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-30T19:01:55.912Z", "modifiedAt": null, "url": null, "title": "Meetup : S\u00e3o Paulo, Transhumanist Manifestation, Lesswrongers invited", "slug": "meetup-sao-paulo-transhumanist-manifestation-lesswrongers", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/82AJakaXfruPNZZj5/meetup-sao-paulo-transhumanist-manifestation-lesswrongers", "pageUrlRelative": "/posts/82AJakaXfruPNZZj5/meetup-sao-paulo-transhumanist-manifestation-lesswrongers", "linkUrl": "https://www.lesswrong.com/posts/82AJakaXfruPNZZj5/meetup-sao-paulo-transhumanist-manifestation-lesswrongers", "postedAtFormatted": "Sunday, June 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20S%C3%A3o%20Paulo%2C%20Transhumanist%20Manifestation%2C%20Lesswrongers%20invited&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20S%C3%A3o%20Paulo%2C%20Transhumanist%20Manifestation%2C%20Lesswrongers%20invited%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82AJakaXfruPNZZj5%2Fmeetup-sao-paulo-transhumanist-manifestation-lesswrongers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20S%C3%A3o%20Paulo%2C%20Transhumanist%20Manifestation%2C%20Lesswrongers%20invited%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82AJakaXfruPNZZj5%2Fmeetup-sao-paulo-transhumanist-manifestation-lesswrongers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F82AJakaXfruPNZZj5%2Fmeetup-sao-paulo-transhumanist-manifestation-lesswrongers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 439, "htmlBody": "<p>The Transhumanist community in Brazil nearly coincides with the \"read a few posts on Lesswrong\" community.</p>\n<p>So anyone nearby S&atilde;o Paulo is invited to join us in this event, to harness the let's take the streets climate around the country to talk about Transhumanism and have a picnic...&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It will be by far the biggest event with Lesswrong readers to take place in Brazil, if, say, 8 people show up out of 28 confirmed and 18 maybes...</p>\n<p><a href=\"https://www.facebook.com/events/583621724994218/?ref=notif&amp;notif_t=plan_user_joined\">https://www.facebook.com/events/583621724994218/?ref=notif&amp;notif_t=plan_user_joined</a></p>\n<p>Here is the description in portuguese for those who'd like to attend and have no facebook.&nbsp; Saturday, July 6. If anyone needs a translation to decide send me a private message or use google tradutor. <br /><br /><span style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\">Cansado das manifesta&ccedil;&otilde;es Contra tudo aquilo que voc&ecirc; &eacute; contra? Venha se manifestar A FAVOR de alguma coisa que voc&ecirc; &eacute; a favor, mas n&atilde;o sabia que tem nome!!<span class=\"Apple-converted-space\">&nbsp;</span></span><br style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\" /><br style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\" /><span style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\">Venha defender a import&acirc;ncia de modificar a condi&ccedil;&atilde;o humana usando tecnologia, o Transhumanismo.<span class=\"Apple-converted-space\">&nbsp;</span></span><br style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\" /><br style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\" /><span style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;\">Vamos nos aglomerar, com mentes abertas, instrumentos musicais e comes e bebes, na Pra&ccedil;a Alexandre Gusm&atilde;o, ao lado do Parque Trianon, fazer um grande Piquenique das 15:00 at&eacute; as 16:30 e subir em dire&ccedil;&atilde;o a Paulista, no v&atilde;o do MASP. A favor de...</span><br style=\"color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\" /><span class=\"text_exposed_show\" style=\"display: inline; color: #333333; font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 13.333333015441895px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 13.333333015441895px; orphans: auto; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\"><br />- A FAVOR do uso de tecnologia para tornar o ser humano mais cooperativo, altru&iacute;sta, moral, utiltarista, gentil do que j&aacute; &eacute;!<span class=\"Apple-converted-space\">&nbsp;</span><br />- A FAVOR de um programa de incentivo a pesquisa contra o envelhecimento (anti-ageing)<br />- A FAVOR de aprimoramentos cognitivos que permitam &agrave;s pessoas ser mais inteligentes, como o chocolate, o caf&eacute;, o Stavigile, e o Piracetam!<span class=\"Apple-converted-space\">&nbsp;</span><br />- A FAVOR de um interesse maior em &Eacute;tica no longo prazo, em particular a FAVOR de pesquisa e a&ccedil;&atilde;o pol&iacute;tica que vise evitar Riscos Existenciais, como guerra Nuclear, Intelig&ecirc;ncia Artificial N&atilde;o-amig&aacute;vel, Colapso Ambiental Global.<span class=\"Apple-converted-space\">&nbsp;</span><br />- A FAVOR de pensar quest&otilde;es pol&iacute;ticas quantitativamente, visando beneficiar o maior n&uacute;mero da maneira que gere mais benef&iacute;cios!<span class=\"Apple-converted-space\">&nbsp;</span><br />- A FAVOR da liberdade de escolher seu modelo familiar e de relacionamento, de abortar, de garantir aos indiv&iacute;duos o direito de intervir em seus corpos, mentes e vontades, independente de sua origem, orienta&ccedil;&atilde;o sexual, carga gen&eacute;tica, predisposi&ccedil;&atilde;o instintiva, afinidade pol&iacute;tica e classe social.<br />- A FAVOR de modular a si mesmo para sentir mais amor e felicidade, seja atrav&eacute;s de prolongar a Oxitocina de seu relacionamento de longo prazo, seja induzindo a produ&ccedil;&atilde;o direta de Serotonina!<span class=\"Apple-converted-space\">&nbsp;</span><br /><br />Venha nos encontrar na Pra&ccedil;a Alexandre Gusm&atilde;o, e vamos lutar A FAVOR daquilo que queremos juntos! Porque se voc&ecirc; n&atilde;o come&ccedil;ar a mudar e convidar &agrave; mudan&ccedil;a agora, quando acha que vai come&ccedil;ar?!!</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "82AJakaXfruPNZZj5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 1.2501779728653585e-06, "legacy": true, "legacyId": "23141", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-30T20:26:03.002Z", "modifiedAt": null, "url": null, "title": "[LINK] Cantor's theorem, the prisoner's dilemma, and the halting problem", "slug": "link-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:36.226Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/McXxpuL73PYsc5Fga/link-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting", "pageUrlRelative": "/posts/McXxpuL73PYsc5Fga/link-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting", "linkUrl": "https://www.lesswrong.com/posts/McXxpuL73PYsc5Fga/link-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting", "postedAtFormatted": "Sunday, June 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Cantor's%20theorem%2C%20the%20prisoner's%20dilemma%2C%20and%20the%20halting%20problem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Cantor's%20theorem%2C%20the%20prisoner's%20dilemma%2C%20and%20the%20halting%20problem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMcXxpuL73PYsc5Fga%2Flink-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Cantor's%20theorem%2C%20the%20prisoner's%20dilemma%2C%20and%20the%20halting%20problem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMcXxpuL73PYsc5Fga%2Flink-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMcXxpuL73PYsc5Fga%2Flink-cantor-s-theorem-the-prisoner-s-dilemma-and-the-halting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p>I wouldn't normally link to a <a href=\"http://qchu.wordpress.com/2013/06/30/cantors-theorem-the-prisoners-dilemma-and-the-halting-problem/\">post from my math blog</a> here, but it concerns a cute interpretation of Cantor's theorem that showed up when I was thinking about <a href=\"/lw/hmw/robust_cooperation_in_the_prisoners_dilemma/\">program equilibria</a> at the April MIRI workshop, so I thought it might be of interest here (e.g. if you're trying to persuade a mathematically inclined friend of yours to attend a future workshop). A short proof of the undecidability of the halting problem falls out as a bonus.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "McXxpuL73PYsc5Fga", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 22, "extendedScore": null, "score": 1.2502435696932923e-06, "legacy": true, "legacyId": "23142", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iQWk5jYeDg5ACCmpx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-06-30T22:57:02.361Z", "modifiedAt": null, "url": null, "title": "[LINKS] Killer Robots and Theories of Truth", "slug": "links-killer-robots-and-theories-of-truth", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:32.411Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fowlertm", "createdAt": "2012-01-07T20:35:26.490Z", "isAdmin": false, "displayName": "fowlertm"}, "userId": "gDAt4FezxH8dDr5EY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F5PSPwXMMXYBWKZKG/links-killer-robots-and-theories-of-truth", "pageUrlRelative": "/posts/F5PSPwXMMXYBWKZKG/links-killer-robots-and-theories-of-truth", "linkUrl": "https://www.lesswrong.com/posts/F5PSPwXMMXYBWKZKG/links-killer-robots-and-theories-of-truth", "postedAtFormatted": "Sunday, June 30th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINKS%5D%20Killer%20Robots%20and%20Theories%20of%20Truth&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINKS%5D%20Killer%20Robots%20and%20Theories%20of%20Truth%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF5PSPwXMMXYBWKZKG%2Flinks-killer-robots-and-theories-of-truth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINKS%5D%20Killer%20Robots%20and%20Theories%20of%20Truth%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF5PSPwXMMXYBWKZKG%2Flinks-killer-robots-and-theories-of-truth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF5PSPwXMMXYBWKZKG%2Flinks-killer-robots-and-theories-of-truth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 536, "htmlBody": "<p>Peter at the <a href=\"http://www.consciousentities.com/\">Conscious Entities</a> blog wrote an <a href=\"http://www.consciousentities.com/?p=1437\">essay</a>&nbsp;on the problems with using autonomous robots for combat, and attempts to articulate some general principles which allow them to be used ethically. &nbsp;He says:</p>\n<blockquote>\n<p>In essence I think there are four broad reasons why hypothetically we might think it right to be wary of killer robots: first, because they work well; second because in other ways they don&rsquo;t work well, third because they open up new scope for crime, and fourth because they might be inherently unethical.</p>\n</blockquote>\n<p>Unpacking this a little, autonomous robots will affect the characteristics of war and make it easier for many to carry out, can be expected to malfunction in especially complex and open-ended situations in <em>very</em>&nbsp;serious ways, might be re-purposed for crime, and because for various reasons they make the ethics surrounding war even <em>more</em>&nbsp;dubious. &nbsp;</p>\n<p>He even takes a stab at laying out restrictive principles which will help mitigate some of the danger in utilizing autonomous robots:</p>\n<blockquote>\n<p>P1. Killer Robots should not be produced or used in a way that allows them to fall into the hands of people who will use them unethically.</p>\n<p>P2. Killer Robots should not be used for any mission which you would not be prepared to assign to a human soldier if a human soldier were capable of executing it.</p>\n<p>P3. Killer Robots should not be used for any mission in unpredictable circumstances or where the application of background understanding may be required.</p>\n<p>P4. Killer Robots should not be equipped with capacities that go beyond the immediate mission; they should be subject to built-in time limits and capable of being shut down remotely.</p>\n</blockquote>\n<p>Though he is a non-expert in the field, I (also a non-expert) find his analysis capable and thorough, though I spotted some possible flaws. &nbsp;I mention it here at LessWrong because, while we may be decades away from superintelligent AI, work in AI risk and machine ethics is going to become especially important very soon as drones, robots, and other non-human combatants become more prevalent on battlefields all over the world.</p>\n<p>Switching gears a bit, Massimo Pigliucci of <a href=\"http://rationallyspeaking.blogspot.kr/\">Rationally Speaking</a> fame <a href=\"http://ieet.org/index.php/IEET/more/pigliucci?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+EthicalTechnology+Ethical+Technology#When:17:50:00Z\">lays</a>&nbsp;out some common theories of truth and problems facing each one. &nbsp;If you've never heard of Charles Sanders Pierce and wouldn't know a verificationist account of truth if it hit you in the face, Massimo's article could be a good place to start getting some familiarity. &nbsp;It seems relevant because there has been some <a href=\"http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners\">work on epistemology</a> in these parts recently. &nbsp;And, as Massimo says:</p>\n<blockquote>\n<p><span style=\"font-family: verdana, arial, sans-serif; font-size: 12px; line-height: 15.59375px;\">...it turns out that it is not exactly straightforward to claim that science makes progress toward the truth about the natural world, because it is not clear that we have a good theory of truth to rely on; moreover, there are different conceptions of truth, some of which likely represent the best we can do to justify our intuitive sense that science does indeed make progress, but others that may constitute a better basis to judge progress (understood in a different fashion) in other fields &mdash; such as mathematics, logic, and of course, philosophy.</span></p>\n</blockquote>\n<p><span style=\"font-family: verdana, arial, sans-serif; font-size: 12px; line-height: 15.59375px;\">This matters for anyone who wants to know how things are, but is even more urgent for one who would create a truth-seeking artificial mind. &nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F5PSPwXMMXYBWKZKG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": -6, "extendedScore": null, "score": 1.2503613290796244e-06, "legacy": true, "legacyId": "23145", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-01T04:40:08.242Z", "modifiedAt": null, "url": null, "title": "Dealing with Administrative Stress", "slug": "dealing-with-administrative-stress", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:37.750Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stabilizer", "createdAt": "2011-12-02T09:36:56.841Z", "isAdmin": false, "displayName": "Stabilizer"}, "userId": "Qa3pLZx3o2TApyfgq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sbaKQGRCg6yDJDqyv/dealing-with-administrative-stress", "pageUrlRelative": "/posts/sbaKQGRCg6yDJDqyv/dealing-with-administrative-stress", "linkUrl": "https://www.lesswrong.com/posts/sbaKQGRCg6yDJDqyv/dealing-with-administrative-stress", "postedAtFormatted": "Monday, July 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dealing%20with%20Administrative%20Stress&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADealing%20with%20Administrative%20Stress%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsbaKQGRCg6yDJDqyv%2Fdealing-with-administrative-stress%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dealing%20with%20Administrative%20Stress%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsbaKQGRCg6yDJDqyv%2Fdealing-with-administrative-stress", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsbaKQGRCg6yDJDqyv%2Fdealing-with-administrative-stress", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1006, "htmlBody": "<p>By Administrative Stress, I refer to the stress caused in dealing with filling forms, applications, talking to bureaucracies, and so on. This has caused me a lot of stress in the past and I've lost several opportunities because of my aversion in dealing with this. Over time I've become better at it. I still have a long way to go, but I've made progress. So here is a short list of strategies I use to overcome this stress/fear and I'm sharing in the hope that some people might find it useful. Feel free add your tips and strategies in the comments:</p>\n<p>1. If you can afford to <strong>pay someone else</strong> to do the work for you and someone else can indeed do it, then do so.&nbsp;</p>\n<p>2. <strong>Breathe</strong>. It's OK. Focus on your breathing. You can get over this. Keep telling yourself that you're stronger then some &nbsp;puny application forms. Take it one step at a time.</p>\n<p>3. <strong>Don't catastophize.</strong> Much of the fear comes from imagining situations where you missed one little detail and therefore lost a huge opportunity or lost a lot of money or got into trouble and so on. This is textbook <a href=\"http://psychcentral.com/lib/2007/what-is-catastrophizing/\">catastrophizing</a>. Tell yourself that millions of people do this kind of work everyday and that you are no worse than them. In fact, millions might even be filling out the exact form that you are filling out (in the case of taxes or visa applications). Anna Salamon mentions in the <a href=\"/lw/fc3/checklist_of_rationality_habits/\">Checklist of Rationality Habits</a>&nbsp;that she managed convince herself of the safety of the wire-guided fall at the Stratosphere Hotel in Las Vegas by imagining twice the population of her college doing the jump and surviving. Similarly, you can imagine maybe your entire city filling out the application and no one getting into significant trouble. Also, you can use simple mindfulness exercises to focus on the present.</p>\n<p>4. <strong>Use Checklists</strong>. I cannot overstate the importance of this. Write down every single thing you need to finish and process it one at a time. Write down the deadline at the head of your checklist and keep that date steady in mind.</p>\n<p>5.&nbsp;<strong>If you need to make appointments, make them early.</strong> I'm currently applying for a German visa. I kept postponing making a Visa appointment because I thought I'd get one easily, based on my experience of applying for a Canadian visa. But as it turns out I was wrong and now the appointment date is uncomfortably close to my date of travel. Making early appointments gives you a clear and comfortable deadline before which you need to finish things and also leaves you room for errors or delays you might encounter. In fact, if there are appointments necessary, they should be at the head of your checklist as well.</p>\n<p>6. <strong>If you feel certain about something or uncertain about something: check.</strong> If you are certain, make the belief pay rent. If you are uncertain, you have to vanquish the confusion. I once couldn't take the GRE exam because I felt certain that a particular form of ID (my drivers' license) was sufficient to take the test, but as it turned out, in my country only a national passport is valid. I lost a lot of money and time. So if you feel sure about something, be extra-sure.</p>\n<p>7. <strong>Don't take it personally.</strong> Bureaucracies aren't deliberately evil. They are impersonal. They exist and you have to deal with them. In the end, if you do not complete the requirements, you will lose. For example, a Chinese friend of mine considers it very demeaning that she has to apply for a Hong Kong visa in order to visit people in Hong Kong, even though Hong Kong is officially part of China. This has kept her from visiting people she loves who live in Hong Kong. I think in the end she is not winning.&nbsp;</p>\n<p>8. <strong>Be courteous.</strong> This is a no-brainer. When talking or sending emails to officials, secretaries and so forth, you can be persistent but always be courteous. Remember that the person you are talking to is not out to get you. He or she is simply doing their job.</p>\n<p>9. <strong>Bureaucracies can be flexible.</strong> Smaller the organization, more flexible they can be. For example, when I was applying to grad schools, all the schools had on their websites seemingly very tight deadlines by which I had to get all the application material in. One of the professors who was writing me recommendation letters was travelling and wouldn't write me a letter within the deadline for a few schools. This sent me into panic and I was considering not applying to these schools. But I emailed the application secretary and she was more than willing to extend the deadline for that recommendation letter. I sent the letter almost 2-3 weeks late and it was totally fine. So when in doubt, ask. If no dice, ask again. At the worst, you are going to get a polite no. What's wrong in trying.</p>\n<p>10. <strong>If you need to procure documents from secondary sources, do it early.</strong> Because in almost every procurement exercise, there're inevitable delays.&nbsp;</p>\n<p>11. <strong>Use friends. </strong>If you can get a friend who is doing/has done the same application as you are, then do it with him/her. This is how I always get my taxes done. I have a friend who actually enjoys figuring out the gory details of the American tax code. And he always knows the answer to confusing points.</p>\n<p>11a. If not, then if you can get a friend to simply sit with you when you're doing the application, then that helps a lot. You can chat, you can complain about the pain, you can talk about something in the application that is confusing you and so on.</p>\n<p>11b. Further, tell friends that you're doing this application and it needs to be done by so and so date. This means that people will bring it up in everyday conversation: \"How's that application going?\" and this creates social pressure to make sure that you are doing it.</p>\n<p>Please share your strategies in the comments!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sbaKQGRCg6yDJDqyv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 24, "extendedScore": null, "score": 1.250628990668529e-06, "legacy": true, "legacyId": "23148", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ttGbpJQ8shBi8hDhh"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-01T13:51:58.089Z", "modifiedAt": null, "url": null, "title": "Newbomb's parabox", "slug": "newbomb-s-parabox", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:33.439Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Locaha", "createdAt": "2012-12-26T10:59:43.142Z", "isAdmin": false, "displayName": "Locaha"}, "userId": "CnvnngECxgWgp5DQE", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gfkJEuysuyyqyLyRe/newbomb-s-parabox", "pageUrlRelative": "/posts/gfkJEuysuyyqyLyRe/newbomb-s-parabox", "linkUrl": "https://www.lesswrong.com/posts/gfkJEuysuyyqyLyRe/newbomb-s-parabox", "postedAtFormatted": "Monday, July 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Newbomb's%20parabox&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANewbomb's%20parabox%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgfkJEuysuyyqyLyRe%2Fnewbomb-s-parabox%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Newbomb's%20parabox%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgfkJEuysuyyqyLyRe%2Fnewbomb-s-parabox", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgfkJEuysuyyqyLyRe%2Fnewbomb-s-parabox", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 106, "htmlBody": "<p><em>Excuse the horrible terribad pun...</em></p>\n<p>&nbsp;</p>\n<p>An evil Omega has locked you in a box. Inside, there is a bomb and a button. Omega informs you that in an hour the bomb will explode, unless you do <strong>the opposite </strong>of what Omega predicted you will do. Namely, press the button if it predicted you won't or vice versa. In that case, the bomb won't explode and the box will open, letting you free.</p>\n<p>Your actions?</p>\n<p>&nbsp;</p>\n<p>PS. You have no chance to survive make your time.</p>\n<p>PPS. Quick! Omega predicted that in exactly 5 second from now, you will blink. Your actions?</p>\n<p>PPPS. Omega vs. Quantum Weather Butterfly. The battle of the Eon!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gfkJEuysuyyqyLyRe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": -12, "extendedScore": null, "score": -3.1e-05, "legacy": true, "legacyId": "23155", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-01T16:17:28.542Z", "modifiedAt": null, "url": null, "title": "[Link] Bets, Portfolios, and Belief Revelation", "slug": "link-bets-portfolios-and-belief-revelation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:32.525Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jayson_Virissimo", "createdAt": "2009-03-13T06:51:41.976Z", "isAdmin": false, "displayName": "Jayson_Virissimo"}, "userId": "zwzw5ALJYG47kDek8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yxuvvAg8Quqs6j8o6/link-bets-portfolios-and-belief-revelation", "pageUrlRelative": "/posts/yxuvvAg8Quqs6j8o6/link-bets-portfolios-and-belief-revelation", "linkUrl": "https://www.lesswrong.com/posts/yxuvvAg8Quqs6j8o6/link-bets-portfolios-and-belief-revelation", "postedAtFormatted": "Monday, July 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20Bets%2C%20Portfolios%2C%20and%20Belief%20Revelation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20Bets%2C%20Portfolios%2C%20and%20Belief%20Revelation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyxuvvAg8Quqs6j8o6%2Flink-bets-portfolios-and-belief-revelation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20Bets%2C%20Portfolios%2C%20and%20Belief%20Revelation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyxuvvAg8Quqs6j8o6%2Flink-bets-portfolios-and-belief-revelation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyxuvvAg8Quqs6j8o6%2Flink-bets-portfolios-and-belief-revelation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 180, "htmlBody": "<p>In a post today at <a href=\"http://econlog.econlib.org/\">EconLog</a>, <a href=\"http://en.wikipedia.org/wiki/Bryan_Caplan\">Bryan</a> defends the \"<span class=\"st\">a bet is a tax on bullshit</span>\" maxim contra \"portfolios reveal beliefs, bets reveal personality traits and public posturing\" (preferred by <a href=\"http://noahpinionblog.blogspot.com/\">Noah Smith</a> and <a href=\"http://en.wikipedia.org/wiki/Tyler_Cowen\">Tyler Cowen</a>).</p>\n<blockquote>\n<p><em>1. If portfolios really \"reveal beliefs,\" Tyler and Noah should be able  to look at a random person's portfolio and tell us everything he  believes.</em>&nbsp; Yet neither Tyler, Noah, nor anyone else can do this.&nbsp; They can't even deduce someone's <em>financial</em> beliefs from his portfolio, much less his beliefs about economic policy or the <a href=\"https://en.wikipedia.org/wiki/Fermi_paradox\">Fermi paradox</a>.&nbsp; Portfolios say something about beliefs, but every portfolio is consistent with a very wide range of views.</p>\n</blockquote>\n<blockquote>\n<p>2. <em>Most people's portfolios exhibit extreme inertia.</em>&nbsp; Even prominent Nobel prize-winning economists <a href=\"http://econlog.econlib.org/archives/2005/05/i_know_its_utte.html\">admit they follow simple rules of thumb</a> when they invest.&nbsp; So unless people's beliefs are carved in stone, how  could portfolios possibly reveal much about their beliefs?&nbsp; Tyler is a  case in point: He changes his mind a hundred times a day, but he follows  a simple financial strategy that hasn't varied in years.</p>\n</blockquote>\n<p>The full post can be found <a href=\"http://econlog.econlib.org/archives/2013/07/bets_portfolios.html\">here</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yxuvvAg8Quqs6j8o6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.2511733188205153e-06, "legacy": true, "legacyId": "23156", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-01T17:10:10.892Z", "modifiedAt": null, "url": null, "title": "Open Thread, July 1-15, 2013", "slug": "open-thread-july-1-15-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:50.009Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vFbeACxRb4YptwtwK/open-thread-july-1-15-2013", "pageUrlRelative": "/posts/vFbeACxRb4YptwtwK/open-thread-july-1-15-2013", "linkUrl": "https://www.lesswrong.com/posts/vFbeACxRb4YptwtwK/open-thread-july-1-15-2013", "postedAtFormatted": "Monday, July 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20July%201-15%2C%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20July%201-15%2C%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvFbeACxRb4YptwtwK%2Fopen-thread-july-1-15-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20July%201-15%2C%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvFbeACxRb4YptwtwK%2Fopen-thread-july-1-15-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvFbeACxRb4YptwtwK%2Fopen-thread-july-1-15-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 17, "htmlBody": "<div id=\"entry_t3_hpz\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">If it's worth saying, but not worth its own post (even in Discussion), then it goes here.</span></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vFbeACxRb4YptwtwK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.2512144769476458e-06, "legacy": true, "legacyId": "23158", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 345, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-01T20:08:40.764Z", "modifiedAt": null, "url": null, "title": "Meetup : West LA - Randomness: Why We Want It, How We Get It", "slug": "meetup-west-la-randomness-why-we-want-it-how-we-get-it", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:33.608Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Scott Garrabrant", "createdAt": "2017-09-22T02:21:16.385Z", "isAdmin": false, "displayName": "Scott Garrabrant"}, "userId": "hbQoLoK5tpmFAJGr4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ukLdoRN3cg7crcK79/meetup-west-la-randomness-why-we-want-it-how-we-get-it", "pageUrlRelative": "/posts/ukLdoRN3cg7crcK79/meetup-west-la-randomness-why-we-want-it-how-we-get-it", "linkUrl": "https://www.lesswrong.com/posts/ukLdoRN3cg7crcK79/meetup-west-la-randomness-why-we-want-it-how-we-get-it", "postedAtFormatted": "Monday, July 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20West%20LA%20-%20Randomness%3A%20Why%20We%20Want%20It%2C%20How%20We%20Get%20It&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20West%20LA%20-%20Randomness%3A%20Why%20We%20Want%20It%2C%20How%20We%20Get%20It%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FukLdoRN3cg7crcK79%2Fmeetup-west-la-randomness-why-we-want-it-how-we-get-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20West%20LA%20-%20Randomness%3A%20Why%20We%20Want%20It%2C%20How%20We%20Get%20It%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FukLdoRN3cg7crcK79%2Fmeetup-west-la-randomness-why-we-want-it-how-we-get-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FukLdoRN3cg7crcK79%2Fmeetup-west-la-randomness-why-we-want-it-how-we-get-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 263, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/o9'>West LA - Randomness: Why We Want It, How We Get It</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">03 July 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm Wednesday, July 3rd.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion:</strong> I will present many uses for random or pseudo-random numbers, both for algorithms and for humans. There will be applications to: Game Theory, Complexity Theory, Cryptography, and Fair Division. Then I will open the discussion to how we as humans can generate pseudo-random numbers. I encourage everyone to think about how they would attempt to generate an unpredictable string of random numbers, and share their results. (Imagine you are playing Rock-Paper-Scissors with an Omega-like AI which is very good at learning from patterns and predicting human behavior. How would you stop it from beating you.) Finally, there will probably be some philosophical discussion on the difference between randomness and pseudo-randomness, and whether or not randomness is achievable or even well defined.</p>\n\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n\n<p>There will be a probably whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes&#39; Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/o9'>West LA - Randomness: Why We Want It, How We Get It</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ukLdoRN3cg7crcK79", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 4, "extendedScore": null, "score": 1.2513538842824071e-06, "legacy": true, "legacyId": "23159", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___West_LA___Randomness__Why_We_Want_It__How_We_Get_It\">Discussion article for the meetup : <a href=\"/meetups/o9\">West LA - Randomness: Why We Want It, How We Get It</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">03 July 2013 07:00:00PM (-0700)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">10850 West Pico Blvd, Los Angeles, CA 90064</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p><strong>When:</strong> 7:00pm Wednesday, July 3rd.</p>\n\n<p><strong>Where:</strong> The Westside Tavern <em>in the upstairs Wine Bar</em> (all ages welcome), located inside the <a href=\"https://maps.google.com/maps?q=10850+West+Pico+Blvd,+Suite+312,+Los+Angeles,+CA+90064\" rel=\"nofollow\">Westside Pavillion</a> on the second floor, right by the movie theaters. The entrance sign says \"Lounge\".</p>\n\n<p><strong>Parking</strong> is free for 3 hours.</p>\n\n<p><strong>Discussion:</strong> I will present many uses for random or pseudo-random numbers, both for algorithms and for humans. There will be applications to: Game Theory, Complexity Theory, Cryptography, and Fair Division. Then I will open the discussion to how we as humans can generate pseudo-random numbers. I encourage everyone to think about how they would attempt to generate an unpredictable string of random numbers, and share their results. (Imagine you are playing Rock-Paper-Scissors with an Omega-like AI which is very good at learning from patterns and predicting human behavior. How would you stop it from beating you.) Finally, there will probably be some philosophical discussion on the difference between randomness and pseudo-randomness, and whether or not randomness is achievable or even well defined.</p>\n\n<p><em>No prior knowledge of or exposure to Less Wrong is necessary;</em> this will be generally accessible and useful to everyone who values thinking for themselves. There will be open general conversation until 7:30, and that's always a lot of good, fun, intelligent discussion!</p>\n\n<p>There will be a probably whiteboard with <a href=\"http://wiki.lesswrong.com/wiki/Bayes%27_theorem\">Bayes' Theorem</a> written on it.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___West_LA___Randomness__Why_We_Want_It__How_We_Get_It1\">Discussion article for the meetup : <a href=\"/meetups/o9\">West LA - Randomness: Why We Want It, How We Get It</a></h2>", "sections": [{"title": "Discussion article for the meetup : West LA - Randomness: Why We Want It, How We Get It", "anchor": "Discussion_article_for_the_meetup___West_LA___Randomness__Why_We_Want_It__How_We_Get_It", "level": 1}, {"title": "Discussion article for the meetup : West LA - Randomness: Why We Want It, How We Get It", "anchor": "Discussion_article_for_the_meetup___West_LA___Randomness__Why_We_Want_It__How_We_Get_It1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-01T23:12:09.197Z", "modifiedAt": null, "url": null, "title": "July 2013 Media Thread", "slug": "july-2013-media-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:55.750Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ievKb6gHs3v8Bqugt/july-2013-media-thread", "pageUrlRelative": "/posts/ievKb6gHs3v8Bqugt/july-2013-media-thread", "linkUrl": "https://www.lesswrong.com/posts/ievKb6gHs3v8Bqugt/july-2013-media-thread", "postedAtFormatted": "Monday, July 1st 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20July%202013%20Media%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJuly%202013%20Media%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FievKb6gHs3v8Bqugt%2Fjuly-2013-media-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=July%202013%20Media%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FievKb6gHs3v8Bqugt%2Fjuly-2013-media-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FievKb6gHs3v8Bqugt%2Fjuly-2013-media-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 185, "htmlBody": "<p>This is the monthly thread for posting media of various types that you've found that you enjoy. Post what you're reading, listening to, watching, and your opinion of it. Post recommendations to blogs. Post whatever media you feel like discussing! To see previous recommendations, check out the <a href=\"/r/discussion/tag/media_thread/\">older threads</a>.</p>\n<p>Rules:</p>\n<ul>\n<li>Please avoid downvoting recommendations just because you don't personally like the recommended material; remember that liking is a <a href=\"/lw/ro/2place_and_1place_words/\">two-place word</a>. If you can point out a specific flaw in a person's recommendation, consider posting a comment to that effect.</li>\n<li>If you want to post something that (you know) has been recommended before, but have another recommendation to add, please link to the original, so that the reader has both recommendations.</li>\n<li>Please use the comment trees for genres. There is a meta thread for comments about future threads.</li>\n<li>If you think there should be a thread for a particular genre of media, please post it to the Other Media thread for now, and add a poll to the Meta thread asking if it should be a thread every month.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ievKb6gHs3v8Bqugt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 1.2514972065432946e-06, "legacy": true, "legacyId": "23160", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 52, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-02T02:13:59.962Z", "modifiedAt": null, "url": null, "title": "Harry Potter and the Methods of Rationality discussion thread, part 20, chapter 90", "slug": "harry-potter-and-the-methods-of-rationality-discussion-5", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:28.297Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "palladias", "createdAt": "2012-04-03T13:45:53.766Z", "isAdmin": false, "displayName": "palladias"}, "userId": "Bv2LXWzZf96WGpqJ5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CEd85FLRbQWsbkrmf/harry-potter-and-the-methods-of-rationality-discussion-5", "pageUrlRelative": "/posts/CEd85FLRbQWsbkrmf/harry-potter-and-the-methods-of-rationality-discussion-5", "linkUrl": "https://www.lesswrong.com/posts/CEd85FLRbQWsbkrmf/harry-potter-and-the-methods-of-rationality-discussion-5", "postedAtFormatted": "Tuesday, July 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2020%2C%20chapter%2090&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2020%2C%20chapter%2090%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCEd85FLRbQWsbkrmf%2Fharry-potter-and-the-methods-of-rationality-discussion-5%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2020%2C%20chapter%2090%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCEd85FLRbQWsbkrmf%2Fharry-potter-and-the-methods-of-rationality-discussion-5", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCEd85FLRbQWsbkrmf%2Fharry-potter-and-the-methods-of-rationality-discussion-5", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 231, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">This is a new thread to discuss Eliezer Yudkowsky&rsquo;s&nbsp;<em><a style=\"color: #8a8a8b;\" href=\"http://www.fanfiction.net/s/5782108/1/\">Harry Potter and the Methods of Rationality</a></em>&nbsp;and anything related to it. This thread is intended for discussing <a href=\"http://www.fanfiction.net/s/5782108/90/\">chapter 90</a>.&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/huq/harry_potter_and_the_methods_of_rationality/\">The previous thread</a>&nbsp;has passed 750 comments.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">There is now a site dedicated to the story at&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/\">hpmor.com</a>, which is now the place to go to find the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/notes/\">authors notes</a>&nbsp;and all sorts of other goodies. AdeleneDawner has kept an&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://www.evernote.com/pub/adelenedawner/Eliezer\">archive of Author&rsquo;s Notes</a>. (This goes up to the notes for chapter 76, and is now not updating. The authors notes from chapter 77 onwards are on hpmor.com.)&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">The first 5 discussion threads are on the main page under the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/tag/harry_potter/\">harry_potter tag</a>.&nbsp; Threads 6 and on (including this one) are in the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/tag/harry_potter/\">discussion section</a>&nbsp;using its separate tag system.&nbsp; Also:&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2ab/harry_potter_and_the_methods_of_rationality\">1</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2ie/harry_potter_and_the_methods_of_rationality\">2</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2nm/harry_potter_and_the_methods_of_rationality\">3</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality\">4</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/30g/harry_potter_and_the_methods_of_rationality\">5</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/364/harry_potter_and_the_methods_of_rationality/\">6</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/3rb/harry_potter_and_the_methods_of_rationality/\">7</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/797/harry_potter_and_the_methods_of_rationality/\">8</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/7jd/harry_potter_and_the_methods_of_rationality\">9</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/ams/harry_potter_and_the_methods_of_rationality\">10</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/axe/harry_potter_and_the_methods_of_rationality/\">11</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/b5s/harry_potter_and_the_methods_of_rationality/\">12</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/b7s/harry_potter_and_the_methods_of_rationality/\">13</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bfo/harry_potter_and_the_methods_of_rationality/\">14</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bmx/harry_potter_and_the_methods_of_rationality/\">15</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bto/harry_potter_and_the_methods_of_rationality/\">16</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/fyv/harry_potter_and_the_methods_of_rationality/\">17</a>,<a style=\"color: #8a8a8b;\" href=\"/lw/g1q/harry_potter_and_the_methods_of_rationality/\">18</a>,<a href=\"/r/discussion/lw/huq/harry_potter_and_the_methods_of_rationality/\">19</a>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Spoiler Warning</strong>: this thread is full of spoilers. With few exceptions, spoilers for MOR and canon are fair game to post, without warning or rot13.&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality/2v1l\">More specifically</a>:</p>\n<blockquote style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\">You do not need to rot13 anything about HP:MoR or the original Harry Potter series unless you are posting insider information from Eliezer Yudkowsky which is not supposed to be publicly available (which includes public statements by Eliezer that have been retracted).</p>\n<p style=\"margin: 0px 0px 1em;\">If there is evidence for X in MOR and/or canon then it&rsquo;s fine to post about X without rot13, even if you also have heard privately from Eliezer that X is true. But you should not post that &ldquo;Eliezer said X is true&rdquo; unless you use rot13.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yrg267i4a8EsgYAXp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CEd85FLRbQWsbkrmf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 12, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "23164", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 618, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Pxiu5SG8gjhCh2jYd", "59rDBidWmmJTXL4Np", "xexS9nyzwRgP9sowp", "LzQcmBwAJBGyzrt6Z", "qKzeJvFWyPh5H2hwj", "nnnd4KRQxs6DYcehD", "y2Hszb4Dsm5FggnDC", "6ae2kq3JmKvL4YPgk", "zvXfBqp6TSriNkmbg", "WQ7XMjqvuRRj8nkpu", "LKFR5pBA3bBkERDxL", "8yEdpDpGgvDWHeodM", "K4JBpAxhvstdnNbeg", "xK6Pswbozev6pv4A6", "pBTcCB5uJTzADdMm4", "XN4WDRSPFo9iGEuk3", "QkhX5YeuYHzPW7Waz", "4sY9rqAqty8rHWGSW", "35GjH7tDvNJWSHQ3H"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-02T07:12:35.072Z", "modifiedAt": null, "url": null, "title": "Boston Megameetup July 13-14", "slug": "boston-megameetup-july-13-14", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:39.519Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ModusPonies", "createdAt": "2012-04-30T00:59:52.568Z", "isAdmin": false, "displayName": "ModusPonies"}, "userId": "9LEFaHEvri7Rrj8aM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XQbd2dZnk2PB3dPkj/boston-megameetup-july-13-14", "pageUrlRelative": "/posts/XQbd2dZnk2PB3dPkj/boston-megameetup-july-13-14", "linkUrl": "https://www.lesswrong.com/posts/XQbd2dZnk2PB3dPkj/boston-megameetup-july-13-14", "postedAtFormatted": "Tuesday, July 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Boston%20Megameetup%20July%2013-14&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABoston%20Megameetup%20July%2013-14%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQbd2dZnk2PB3dPkj%2Fboston-megameetup-july-13-14%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Boston%20Megameetup%20July%2013-14%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQbd2dZnk2PB3dPkj%2Fboston-megameetup-july-13-14", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXQbd2dZnk2PB3dPkj%2Fboston-megameetup-july-13-14", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p style=\"margin-bottom: 0in;\">On the weekend of July 13-14, Harvard High-Impact Philanthropy will be hosting a <a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/events/119327742/\">rationalist megameetup</a>. Everyone who can make the trip is strongly encouraged to come. We'll meet at the <a href=\"http://maps.google.com/maps?q=1+Oxford+Street,+Cambridge,+MA&amp;hl=en&amp;ll=42.376316,-71.115961&amp;spn=0.006388,0.007832&amp;sll=42.381206,-71.116358&amp;sspn=0.003194,0.003916&amp;hnear=1+Oxford+St,+Cambridge,+Middlesex,+Massachusetts+02138&amp;t=m&amp;z=17\">Harvard Science Center</a>&nbsp;in room B-10 at noon on both days. Crash space is available; comment or send me a PM to arrange. (I am supposed to say \"the megameetup is not sponsored by the Science Center or Harvard University.\") If you're planning to come, please RSVP in this thread or on our <a href=\"https://www.facebook.com/events/332132496919750\">facebook event page</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XQbd2dZnk2PB3dPkj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 8, "extendedScore": null, "score": 1.2518726371901447e-06, "legacy": true, "legacyId": "23168", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-02T14:51:26.529Z", "modifiedAt": null, "url": null, "title": "Meetup : Durham/RTLW General Discussion", "slug": "meetup-durham-rtlw-general-discussion", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/c7PE8HkpNcduTe8wi/meetup-durham-rtlw-general-discussion", "pageUrlRelative": "/posts/c7PE8HkpNcduTe8wi/meetup-durham-rtlw-general-discussion", "linkUrl": "https://www.lesswrong.com/posts/c7PE8HkpNcduTe8wi/meetup-durham-rtlw-general-discussion", "postedAtFormatted": "Tuesday, July 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Durham%2FRTLW%20General%20Discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Durham%2FRTLW%20General%20Discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc7PE8HkpNcduTe8wi%2Fmeetup-durham-rtlw-general-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Durham%2FRTLW%20General%20Discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc7PE8HkpNcduTe8wi%2Fmeetup-durham-rtlw-general-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc7PE8HkpNcduTe8wi%2Fmeetup-durham-rtlw-general-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 116, "htmlBody": "<h2>Discussion article for the meetup : Durham/RTLW&nbsp;<a href=\"/meetups/oa\">General Discussion</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">04 July 2013 07:30:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Cocoa Cinnamon, 420 W Geer St., Durham NC</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>This will be a fairly open meetup. Anyone who would like to can present, summarize, or simply offer for discussion an article (or just a concept) that has caught your interest recently, on Less Wrong or otherwise. We will divide our two hours into as many attendees as we have and experiment with timed and/or structured discussion.</p>\n<p>This is a great time to come back into the fold if you've been feeling left out by not having read the requisite articles (which, of course, you should never feel deterred by)!</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : Durham/RTLW&nbsp;<a href=\"/meetups/oa\">General Discussion</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "c7PE8HkpNcduTe8wi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1.2522313952838006e-06, "legacy": true, "legacyId": "23176", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_General_Discussion\">Discussion article for the meetup : Durham/RTLW&nbsp;<a href=\"/meetups/oa\">General Discussion</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">04 July 2013 07:30:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">Cocoa Cinnamon, 420 W Geer St., Durham NC</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>This will be a fairly open meetup. Anyone who would like to can present, summarize, or simply offer for discussion an article (or just a concept) that has caught your interest recently, on Less Wrong or otherwise. We will divide our two hours into as many attendees as we have and experiment with timed and/or structured discussion.</p>\n<p>This is a great time to come back into the fold if you've been feeling left out by not having read the requisite articles (which, of course, you should never feel deterred by)!</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Durham_RTLW_General_Discussion1\">Discussion article for the meetup : Durham/RTLW&nbsp;<a href=\"/meetups/oa\">General Discussion</a></h2>", "sections": [{"title": "Discussion article for the meetup : Durham/RTLW\u00a0General Discussion", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_General_Discussion", "level": 1}, {"title": "Discussion article for the meetup : Durham/RTLW\u00a0General Discussion", "anchor": "Discussion_article_for_the_meetup___Durham_RTLW_General_Discussion1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-02T16:21:59.219Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes July 2013", "slug": "rationality-quotes-july-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:28.032Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v4qto9hFREy8LjKhJ/rationality-quotes-july-2013", "pageUrlRelative": "/posts/v4qto9hFREy8LjKhJ/rationality-quotes-july-2013", "linkUrl": "https://www.lesswrong.com/posts/v4qto9hFREy8LjKhJ/rationality-quotes-july-2013", "postedAtFormatted": "Tuesday, July 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%20July%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%20July%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv4qto9hFREy8LjKhJ%2Frationality-quotes-july-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%20July%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv4qto9hFREy8LjKhJ%2Frationality-quotes-july-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv4qto9hFREy8LjKhJ%2Frationality-quotes-july-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 86, "htmlBody": "<div id=\"entry_t3_hlk\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>Another month has passed and here is a new rationality quotes thread. The usual rules are:</p>\n<ul>\n<li>Please post all quotes separately, so that they can be upvoted or downvoted separately. (If they are strongly related, reply to your own comments. If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote from Less Wrong itself, HPMoR, Eliezer Yudkowsky, or Robin Hanson.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v4qto9hFREy8LjKhJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "23157", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 429, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-02T16:38:45.766Z", "modifiedAt": null, "url": null, "title": "Seeking paid help for SPARC logistics", "slug": "seeking-paid-help-for-sparc-logistics", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qsbGaGM766hFfnCXQ/seeking-paid-help-for-sparc-logistics", "pageUrlRelative": "/posts/qsbGaGM766hFfnCXQ/seeking-paid-help-for-sparc-logistics", "linkUrl": "https://www.lesswrong.com/posts/qsbGaGM766hFfnCXQ/seeking-paid-help-for-sparc-logistics", "postedAtFormatted": "Tuesday, July 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seeking%20paid%20help%20for%20SPARC%20logistics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeeking%20paid%20help%20for%20SPARC%20logistics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqsbGaGM766hFfnCXQ%2Fseeking-paid-help-for-sparc-logistics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seeking%20paid%20help%20for%20SPARC%20logistics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqsbGaGM766hFfnCXQ%2Fseeking-paid-help-for-sparc-logistics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqsbGaGM766hFfnCXQ%2Fseeking-paid-help-for-sparc-logistics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 282, "htmlBody": "<p>&nbsp;</p>\n<p>This August CFAR is running the <a href=\"http://sparc2013.org\">Summer Program on Applied Rationality &amp; Cognition</a>, an academic high school summer program, and we are looking for a part-time, temporary logistics manager for the program. If you are interested in the role and live near Berkeley, CA, please fill out the short form <a href=\"https://docs.google.com/forms/d/1qzkZ9mlM7iX0ET7Hrg9J3NH1LA5AnstJaaGNAKjpyII/viewform\">here</a> with additional information.</p>\n<p>SPARC will be held at UC Berkeley from August 5 - August 17. The work is full time or more from August 3 - August 17, and about 10 hours per week between the start of the job and August 3. The participants are very talented high school math students.&nbsp;</p>\n<p>If you are interested in the work CFAR is doing or in SPARC in particular, this will be a great opportunity to see the work first hand, help out, and meet many of the people involved.</p>\n<p>Some examples of logistical tasks that you would help with:</p>\n<ul>\n<li>Ensure that facilities are prepared, help arrange housing, determine the schedule and coordinate with visiting instructors, and coordinate with UC Berkeley conference services</li>\n<li>Talk with students and parents in advance of the program, answer questions, give directions, etc.</li>\n<li>Acquire supplies for the program, print and distribute course materials and schedules</li>\n<li>Arrange liability insurance, medical histories, and releases.</li>\n</ul>\n<p>SPARC volunteers and instructors will be available to help with some tasks, especially during the program itself, but you would be the main staff responsible for logistics. We strongly prefer applicants who have experience organizing events and ensuring that they run smoothly. Applicants should be local and able to easily get to the UC Berkeley campus. (They should also be happy to interact with 16-18 year old students and their parents.)&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qsbGaGM766hFfnCXQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 17, "extendedScore": null, "score": 1.2523153302215683e-06, "legacy": true, "legacyId": "23177", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-02T16:39:03.792Z", "modifiedAt": null, "url": null, "title": "What are you working on? July 2013", "slug": "what-are-you-working-on-july-2013", "viewCount": null, "lastCommentedAt": "2017-06-17T04:21:02.293Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kMvjBoyQKBXPmNkBu/what-are-you-working-on-july-2013", "pageUrlRelative": "/posts/kMvjBoyQKBXPmNkBu/what-are-you-working-on-july-2013", "linkUrl": "https://www.lesswrong.com/posts/kMvjBoyQKBXPmNkBu/what-are-you-working-on-july-2013", "postedAtFormatted": "Tuesday, July 2nd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20you%20working%20on%3F%20July%202013&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20you%20working%20on%3F%20July%202013%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkMvjBoyQKBXPmNkBu%2Fwhat-are-you-working-on-july-2013%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20you%20working%20on%3F%20July%202013%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkMvjBoyQKBXPmNkBu%2Fwhat-are-you-working-on-july-2013", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkMvjBoyQKBXPmNkBu%2Fwhat-are-you-working-on-july-2013", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<div id=\"entry_t3_gkz\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>This is the supposedly-bimonthly-but-we-missed-April-and-June-2013 'What are you working On?' thread. Previous threads are&nbsp;<a href=\"/r/discussion/tag/waywo\">here</a>. So here's the question:</p>\n<p style=\"padding-left: 60px;\"><em>What are you working on?&nbsp;</em></p>\n<p>Here are some guidelines:</p>\n<ul>\n<li>Focus on projects that you have recently made progress on, not projects that you're thinking about doing but haven't started.</li>\n<li>Why this project and not others? Mention reasons why you're doing the project and/or why others should contribute to your project (if applicable).</li>\n<li>Talk about your goals for the project.</li>\n<li>Any kind of project is fair game: personal improvement, research project, art project, whatever.</li>\n<li>Link to your work if it's linkable.</li>\n</ul>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kMvjBoyQKBXPmNkBu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 15, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "23178", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 101, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-03T01:44:05.349Z", "modifiedAt": null, "url": null, "title": "Group Rationality Diary, July 1-15", "slug": "group-rationality-diary-july-1-15", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:07.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "therufs", "createdAt": "2012-09-08T16:55:46.272Z", "isAdmin": false, "displayName": "therufs"}, "userId": "GhiiAK49Arcg9DdGQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QXYsonygGQRc6fjJy/group-rationality-diary-july-1-15", "pageUrlRelative": "/posts/QXYsonygGQRc6fjJy/group-rationality-diary-july-1-15", "linkUrl": "https://www.lesswrong.com/posts/QXYsonygGQRc6fjJy/group-rationality-diary-july-1-15", "postedAtFormatted": "Wednesday, July 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Group%20Rationality%20Diary%2C%20July%201-15&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGroup%20Rationality%20Diary%2C%20July%201-15%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQXYsonygGQRc6fjJy%2Fgroup-rationality-diary-july-1-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Group%20Rationality%20Diary%2C%20July%201-15%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQXYsonygGQRc6fjJy%2Fgroup-rationality-diary-july-1-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQXYsonygGQRc6fjJy%2Fgroup-rationality-diary-july-1-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 220, "htmlBody": "<div id=\"entry_t3_hqf\" class=\"content clear\">\n<div class=\"md\">\n<div>\n<div>\n<p>T<span style=\"color: #333333;\">his is the public group instrumental rationality diary for July 1-15. <br /></span></p>\n<blockquote style=\"font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\"><span style=\"color: #333333;\">It's a place to record and chat about it if you have done, or are actively doing, things like:</span></p>\n<ul style=\"padding: 0px;\">\n<li>Established a useful new habit</li>\n<li>Obtained new evidence that made you change your mind about some belief</li>\n<li>Decided to behave in a different way in some set of situations</li>\n<li>Optimized some part of a common routine or cached behavior</li>\n<li>Consciously changed your emotions or affect with respect to something</li>\n<li>Consciously pursued new valuable information about something that could make a big difference in your life</li>\n<li>Learned something new about your beliefs, behavior, or life that surprised you</li>\n<li>Tried doing any of the above and&nbsp;failed</li>\n</ul>\n<p style=\"margin: 0px 0px 1em;\">Or anything else interesting which you want to share, so that other people can think about it, and perhaps be inspired to take action themselves. &nbsp;Try to include enough details so that everyone can use each other's experiences to learn about what tends to work out, and what doesn't tend to work out.</p>\n</blockquote>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\">Thanks to&nbsp;<a style=\"color: #8a8a8b;\" href=\"/user/therufs/submitted/r/discussion/lw/hg0/group_rationality_diary_may_1631/user/cata\">cata</a>&nbsp;for starting the Group Rationality Diary posts, and to commenters for participating!</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/r/therufs-drafts/lw/i05/group_rationality_diary_july_1531/\">Next diary</a> -- July 15-31</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"/lw/hqf/group_rationality_diary_june_130/\">Immediate past diary</a> -- June 1-30<a href=\"/lw/hqf/group_rationality_diary_june_130/\"><br /></a></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial,Helvetica,sans-serif; line-height: 19px; text-align: justify;\"><a href=\"http://wiki.lesswrong.com/wiki/Rationality_Diary\">Rationality Diaries archive</a></p>\n</div>\n</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QXYsonygGQRc6fjJy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 1.2527419813400954e-06, "legacy": true, "legacyId": "23182", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DTg6Y5x4MbgqEFAJr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-03T18:06:48.995Z", "modifiedAt": null, "url": null, "title": "Meetup : Atlanta: Intro to Meditation", "slug": "meetup-atlanta-intro-to-meditation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Nova_Division", "createdAt": "2011-03-14T15:21:15.124Z", "isAdmin": false, "displayName": "Nova_Division"}, "userId": "eFXLR4aNaxDBCDatT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7xwg28wWjLppCRwvF/meetup-atlanta-intro-to-meditation", "pageUrlRelative": "/posts/7xwg28wWjLppCRwvF/meetup-atlanta-intro-to-meditation", "linkUrl": "https://www.lesswrong.com/posts/7xwg28wWjLppCRwvF/meetup-atlanta-intro-to-meditation", "postedAtFormatted": "Wednesday, July 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Atlanta%3A%20Intro%20to%20Meditation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Atlanta%3A%20Intro%20to%20Meditation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7xwg28wWjLppCRwvF%2Fmeetup-atlanta-intro-to-meditation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Atlanta%3A%20Intro%20to%20Meditation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7xwg28wWjLppCRwvF%2Fmeetup-atlanta-intro-to-meditation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7xwg28wWjLppCRwvF%2Fmeetup-atlanta-intro-to-meditation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 102, "htmlBody": "<h2>Discussion article for the meetup : <a href=\"/meetups/ob\">Atlanta: Intro to Meditation</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">13 July 2013 06:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">TBA</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>This session will be an overview of meditation. What it is, it's benefits, types of practice, etc. Both experienced and novice Lesswrong meditation practitioners will be present to discuss their experiences and answer questions.</p>\n<p>These posts are of interest:</p>\n<p><a rel=\"nofollow\" href=\"/lw/hkt/two_weeks_of_meditation_can_reduce_mind_wandering/\">http://lesswrong.com/lw/hkt/two_weeks_of_meditation_can_reduce_mind_wandering/</a></p>\n<p><a rel=\"nofollow\" href=\"/lw/5h9/meditation_insight_and_rationality_part_1_of_3/\">http://lesswrong.com/lw/5h9/meditation_insight_and_rationality_part_1_of_3/</a></p>\n<p>After our discussion, we may do brief starting exercises to try out meditation in the group setting.</p>\n<p>No experience necessary, no reading required.</p>\n<p>As always, snacks and games and fun will be had by all!</p>\n<p>There will be cats! Lemme know if you're allergic.</p>\n</div>\n</div>\n<!-- .content -->\n<h2>Discussion article for the meetup : <a href=\"/meetups/ob\">Atlanta: Intro to Meditation</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7xwg28wWjLppCRwvF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2535114945160526e-06, "legacy": true, "legacyId": "23193", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Atlanta__Intro_to_Meditation\">Discussion article for the meetup : <a href=\"/meetups/ob\">Atlanta: Intro to Meditation</a></h2>\n<div class=\"meetup-meta\">\n<p><strong>WHEN:</strong> <span class=\"date\">13 July 2013 06:00:00PM (-0400)</span></p>\n<p><strong>WHERE:</strong> <span class=\"address\">TBA</span></p>\n</div>\n<!-- .meta -->\n<div class=\"content\">\n<div class=\"md\">\n<p>This session will be an overview of meditation. What it is, it's benefits, types of practice, etc. Both experienced and novice Lesswrong meditation practitioners will be present to discuss their experiences and answer questions.</p>\n<p>These posts are of interest:</p>\n<p><a rel=\"nofollow\" href=\"/lw/hkt/two_weeks_of_meditation_can_reduce_mind_wandering/\">http://lesswrong.com/lw/hkt/two_weeks_of_meditation_can_reduce_mind_wandering/</a></p>\n<p><a rel=\"nofollow\" href=\"/lw/5h9/meditation_insight_and_rationality_part_1_of_3/\">http://lesswrong.com/lw/5h9/meditation_insight_and_rationality_part_1_of_3/</a></p>\n<p>After our discussion, we may do brief starting exercises to try out meditation in the group setting.</p>\n<p>No experience necessary, no reading required.</p>\n<p>As always, snacks and games and fun will be had by all!</p>\n<p>There will be cats! Lemme know if you're allergic.</p>\n</div>\n</div>\n<!-- .content -->\n<h2 id=\"Discussion_article_for_the_meetup___Atlanta__Intro_to_Meditation1\">Discussion article for the meetup : <a href=\"/meetups/ob\">Atlanta: Intro to Meditation</a></h2>", "sections": [{"title": "Discussion article for the meetup : Atlanta: Intro to Meditation", "anchor": "Discussion_article_for_the_meetup___Atlanta__Intro_to_Meditation", "level": 1}, {"title": "Discussion article for the meetup : Atlanta: Intro to Meditation", "anchor": "Discussion_article_for_the_meetup___Atlanta__Intro_to_Meditation1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ekziTH4Jko7Q6v4tk", "QqSNFcGSZdnARx56E"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-03T18:40:11.888Z", "modifiedAt": null, "url": null, "title": "Progress on automated mathematical theorem proving?", "slug": "progress-on-automated-mathematical-theorem-proving", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:03.269Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uu9EAiFwoYg76AAEe/progress-on-automated-mathematical-theorem-proving", "pageUrlRelative": "/posts/uu9EAiFwoYg76AAEe/progress-on-automated-mathematical-theorem-proving", "linkUrl": "https://www.lesswrong.com/posts/uu9EAiFwoYg76AAEe/progress-on-automated-mathematical-theorem-proving", "postedAtFormatted": "Wednesday, July 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Progress%20on%20automated%20mathematical%20theorem%20proving%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProgress%20on%20automated%20mathematical%20theorem%20proving%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fuu9EAiFwoYg76AAEe%2Fprogress-on-automated-mathematical-theorem-proving%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Progress%20on%20automated%20mathematical%20theorem%20proving%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fuu9EAiFwoYg76AAEe%2Fprogress-on-automated-mathematical-theorem-proving", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fuu9EAiFwoYg76AAEe%2Fprogress-on-automated-mathematical-theorem-proving", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 442, "htmlBody": "<p>In a <a href=\"/lw/hmt/tiling_agents_for_selfmodifying_ai_opfai_2/99uz\">recent comment thread</a>&nbsp;I expressed skepticism as to whether there's been meaningful progress on general artificial intelligence.</p>\n<p>I hedged because of my lack of subject matter knowledge, but thinking it over, I realized that I do have relevant subject matter knowledge, coming from my background in pure math.</p>\n<p>In <a href=\"http://gowers.wordpress.com/2013/04/02/a-second-experiment-concerning-mathematical-writing/\">a blog post from April 2013</a>, Fields Medalist <a href=\"http://en.wikipedia.org/wiki/Timothy_Gowers\">Timothy Gowers</a> wrote:</p>\n<blockquote>\n<p>Over the last three years, I have been collaborating with Mohan Ganesalingam, a computer scientist, linguist and mathematician (and amazingly good at all three) on a project to write programs that can solve mathematical problems. We have recently produced our first program. It is rather rudimentary: the only problems it can solve are ones that mathematicians would describe as very routine and not requiring any ideas, and even within that class of problems there are considerable restrictions on what it can do; we plan to write more sophisticated programs in the future.</p>\n</blockquote>\n<p><strong>I don't know of any computer programs that have been able to prove theorems outside of the class \"very routine and not requiring any ideas,\" without human assistance (and without being heavily specialized to an individual theorem).</strong> I think that if such projects existed, Gowers would be aware of them and would likely have commented on them within his post.&nbsp;</p>\n<p>It's easy to give an algorithm that generates a proof of a mathematical theorem that's provable: choose a formal language with definitions and axioms, and for successive values of n, enumerate all sequences of mathematical deductions of length n, halting if the final line of a sequence is the statement of the the desired theorem. But the running time of this algorithm is exponential in the length of the proof, and the algorithm is infeasible to implement except for theorems with very short proofs.&nbsp;</p>\n<p><strong>It appears that the situation is not \"there are computer programs that are able to prove mathematical theorems, just not as yet as efficiently as humans,\" but rather \"computer programs are unable to prove any nontrivial theorems.\"</strong></p>\n<p>I'll highlight the <a href=\"http://en.wikipedia.org/wiki/Sylow_theorems\">Sylow theorems</a> from group theory as examples of nontrivial theorems. Their statements are simple, and their proofs are not very long, but they're ingenious, and involve substantive ideas. If somebody was able to write a program that's able to find proofs of the Sylow theorems, I would consider that to be strong evidence that there's been meaningful progress on general artificial intelligence. In absence of such examples, I have a strong prior against there having been meaningful progress on general artificial intelligence.</p>\n<p>I will update my views if I learn of the existence of such programs, or of programs that are capable of comparably impressive original research in domains outside of math.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"FJ3MGb684F88BoN2o": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uu9EAiFwoYg76AAEe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}], "voteCount": 18, "baseScore": 25, "extendedScore": null, "score": 7.5e-05, "legacy": true, "legacyId": "23179", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 65, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-03T19:19:59.616Z", "modifiedAt": null, "url": null, "title": "RIP Doug Engelbart", "slug": "rip-doug-engelbart", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:38.321Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9tgrBwwyMAcnzypnc/rip-doug-engelbart", "pageUrlRelative": "/posts/9tgrBwwyMAcnzypnc/rip-doug-engelbart", "linkUrl": "https://www.lesswrong.com/posts/9tgrBwwyMAcnzypnc/rip-doug-engelbart", "postedAtFormatted": "Wednesday, July 3rd 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20RIP%20Doug%20Engelbart&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARIP%20Doug%20Engelbart%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9tgrBwwyMAcnzypnc%2Frip-doug-engelbart%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=RIP%20Doug%20Engelbart%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9tgrBwwyMAcnzypnc%2Frip-doug-engelbart", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9tgrBwwyMAcnzypnc%2Frip-doug-engelbart", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 9, "htmlBody": "<p><a href=\"http://www.ietf.org/mail-archive/web/ietf/current/msg80472.html\">http://www.ietf.org/mail-archive/web/ietf/current/msg80472.html</a><br /><br />Prominently mentioned in<br /><a href=\"/lw/w8/engelbart_insufficiently_recursive/\">http://lesswrong.com/lw/w8/engelbart_insufficiently_recursive/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9tgrBwwyMAcnzypnc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 19, "extendedScore": null, "score": 1.2535688282615559e-06, "legacy": true, "legacyId": "23194", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NCb28Xdv7xDajtqtS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T04:35:51.582Z", "modifiedAt": null, "url": null, "title": "Meetup : Washington DC fun and games meetup", "slug": "meetup-washington-dc-fun-and-games-meetup-6", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rocurley", "createdAt": "2011-07-11T23:21:02.854Z", "isAdmin": false, "displayName": "rocurley"}, "userId": "zrzRGQu6QueyJGN5g", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/H2PCnhAFgp8vbeP2h/meetup-washington-dc-fun-and-games-meetup-6", "pageUrlRelative": "/posts/H2PCnhAFgp8vbeP2h/meetup-washington-dc-fun-and-games-meetup-6", "linkUrl": "https://www.lesswrong.com/posts/H2PCnhAFgp8vbeP2h/meetup-washington-dc-fun-and-games-meetup-6", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Washington%20DC%20fun%20and%20games%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Washington%20DC%20fun%20and%20games%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH2PCnhAFgp8vbeP2h%2Fmeetup-washington-dc-fun-and-games-meetup-6%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Washington%20DC%20fun%20and%20games%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH2PCnhAFgp8vbeP2h%2Fmeetup-washington-dc-fun-and-games-meetup-6", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FH2PCnhAFgp8vbeP2h%2Fmeetup-washington-dc-fun-and-games-meetup-6", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 47, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/oc'>Washington DC fun and games meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">07 July 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to have hang out and play games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/oc'>Washington DC fun and games meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "H2PCnhAFgp8vbeP2h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2540044982546969e-06, "legacy": true, "legacyId": "23196", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup\">Discussion article for the meetup : <a href=\"/meetups/oc\">Washington DC fun and games meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">07 July 2013 03:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">National Portrait Gallery, Washington, DC 20001, USA (courtyard)</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We'll be meeting to have hang out and play games.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup1\">Discussion article for the meetup : <a href=\"/meetups/oc\">Washington DC fun and games meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Washington DC fun and games meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup", "level": 1}, {"title": "Discussion article for the meetup : Washington DC fun and games meetup", "anchor": "Discussion_article_for_the_meetup___Washington_DC_fun_and_games_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T10:13:03.808Z", "modifiedAt": null, "url": null, "title": "Meetup : Melbourne Practical Rationality - July 5th", "slug": "meetup-melbourne-practical-rationality-july-5th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:37.505Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "BraydenM", "createdAt": "2013-06-10T09:17:31.294Z", "isAdmin": false, "displayName": "BraydenM"}, "userId": "KBZHqcMC6z2rPZkZK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/J6ErdcFHHxFhM6rQH/meetup-melbourne-practical-rationality-july-5th", "pageUrlRelative": "/posts/J6ErdcFHHxFhM6rQH/meetup-melbourne-practical-rationality-july-5th", "linkUrl": "https://www.lesswrong.com/posts/J6ErdcFHHxFhM6rQH/meetup-melbourne-practical-rationality-july-5th", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Melbourne%20Practical%20Rationality%20-%20July%205th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Melbourne%20Practical%20Rationality%20-%20July%205th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ6ErdcFHHxFhM6rQH%2Fmeetup-melbourne-practical-rationality-july-5th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Melbourne%20Practical%20Rationality%20-%20July%205th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ6ErdcFHHxFhM6rQH%2Fmeetup-melbourne-practical-rationality-july-5th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJ6ErdcFHHxFhM6rQH%2Fmeetup-melbourne-practical-rationality-july-5th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 314, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/od'>Melbourne Practical Rationality - July 5th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">05 July 2013 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">491 King St West Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Matt will be away for the July meetup, so I am taking charge of this month's Practical Rationality event at the newish venue (TrikeApps: Level 2, 491 King St West Melbourne) from 6:30pm to late.\nThe first structured activity for the evening will be a discussion of rationality outreach in Melbourne. The three topics up for investigation are:\n-Planning to run Less Wrong events that appeal to newcomers who have not read the sequences\n-Discussing what would be required to bring a CFAR workshop to Melbourne within the next 12 months\n-Starting a Melbourne Effective Altruist community\nYou can join a discussion about whichever of these you are most interested in. We will start with whichever one interests the first people to show up, and split when the group size increases.</p>\n\n<p>By the end of the discussion I hope for us to have obtained a clearer picture of the benefits of outreach, what events should look like, and how we can target high value potential members.</p>\n\n<p>Please consider which of the topics above you are interested in working on, and bring at least one idea along on the night.</p>\n\n<p>The second activity later in the evening will be Rationality Therapy, where you bring problems or doubts you are having to discuss in small groups, with the aim of generating solutions to specific issues in your life.</p>\n\n<p>We will be experimenting with a new incentive: making a takeaway order at 7:30pm for anyone who wants dinner. This will hopefully make it easier for you to come along early without having to worry about finding food beforehand.</p>\n\n<p>If you need to reach me, for example if you want to come earlier, you can contact me on 0407943917.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/od'>Melbourne Practical Rationality - July 5th</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "J6ErdcFHHxFhM6rQH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.25426891845059e-06, "legacy": true, "legacyId": "23198", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Practical_Rationality___July_5th\">Discussion article for the meetup : <a href=\"/meetups/od\">Melbourne Practical Rationality - July 5th</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">05 July 2013 06:30:00PM (+1000)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">491 King St West Melbourne</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Matt will be away for the July meetup, so I am taking charge of this month's Practical Rationality event at the newish venue (TrikeApps: Level 2, 491 King St West Melbourne) from 6:30pm to late.\nThe first structured activity for the evening will be a discussion of rationality outreach in Melbourne. The three topics up for investigation are:\n-Planning to run Less Wrong events that appeal to newcomers who have not read the sequences\n-Discussing what would be required to bring a CFAR workshop to Melbourne within the next 12 months\n-Starting a Melbourne Effective Altruist community\nYou can join a discussion about whichever of these you are most interested in. We will start with whichever one interests the first people to show up, and split when the group size increases.</p>\n\n<p>By the end of the discussion I hope for us to have obtained a clearer picture of the benefits of outreach, what events should look like, and how we can target high value potential members.</p>\n\n<p>Please consider which of the topics above you are interested in working on, and bring at least one idea along on the night.</p>\n\n<p>The second activity later in the evening will be Rationality Therapy, where you bring problems or doubts you are having to discuss in small groups, with the aim of generating solutions to specific issues in your life.</p>\n\n<p>We will be experimenting with a new incentive: making a takeaway order at 7:30pm for anyone who wants dinner. This will hopefully make it easier for you to come along early without having to worry about finding food beforehand.</p>\n\n<p>If you need to reach me, for example if you want to come earlier, you can contact me on 0407943917.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Melbourne_Practical_Rationality___July_5th1\">Discussion article for the meetup : <a href=\"/meetups/od\">Melbourne Practical Rationality - July 5th</a></h2>", "sections": [{"title": "Discussion article for the meetup : Melbourne Practical Rationality - July 5th", "anchor": "Discussion_article_for_the_meetup___Melbourne_Practical_Rationality___July_5th", "level": 1}, {"title": "Discussion article for the meetup : Melbourne Practical Rationality - July 5th", "anchor": "Discussion_article_for_the_meetup___Melbourne_Practical_Rationality___July_5th1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "1 comment"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T10:57:08.631Z", "modifiedAt": null, "url": null, "title": "New HPMOR Article(s)", "slug": "new-hpmor-article-s", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:35.430Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GfmMzYAC2tpbgDdwp/new-hpmor-article-s", "pageUrlRelative": "/posts/GfmMzYAC2tpbgDdwp/new-hpmor-article-s", "linkUrl": "https://www.lesswrong.com/posts/GfmMzYAC2tpbgDdwp/new-hpmor-article-s", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20HPMOR%20Article(s)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20HPMOR%20Article(s)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfmMzYAC2tpbgDdwp%2Fnew-hpmor-article-s%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20HPMOR%20Article(s)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfmMzYAC2tpbgDdwp%2Fnew-hpmor-article-s", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGfmMzYAC2tpbgDdwp%2Fnew-hpmor-article-s", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p>I was setting up the article for chapter 91 with the intent of doing one article for each new chapter because I don't like like dealing with long threads, but it occurred to me to ask whether people have a preference for one, two, or three threads.&nbsp;</p>\n<p>Someone else would have to consolidate multiple threads and it might not be possible to split a combined thread, so I'm checking first.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GfmMzYAC2tpbgDdwp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 2, "extendedScore": null, "score": 1.2543034915960987e-06, "legacy": true, "legacyId": "23200", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T11:49:07.263Z", "modifiedAt": null, "url": null, "title": "Harry Potter and the Methods of Rationality discussion thread, part 21, chapters 91 & 92", "slug": "harry-potter-and-the-methods-of-rationality-discussion-31", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:01.641Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CcnpbKuRaYMjpFmQq/harry-potter-and-the-methods-of-rationality-discussion-31", "pageUrlRelative": "/posts/CcnpbKuRaYMjpFmQq/harry-potter-and-the-methods-of-rationality-discussion-31", "linkUrl": "https://www.lesswrong.com/posts/CcnpbKuRaYMjpFmQq/harry-potter-and-the-methods-of-rationality-discussion-31", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2021%2C%20chapters%2091%20%26%2092&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2021%2C%20chapters%2091%20%26%2092%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcnpbKuRaYMjpFmQq%2Fharry-potter-and-the-methods-of-rationality-discussion-31%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2021%2C%20chapters%2091%20%26%2092%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcnpbKuRaYMjpFmQq%2Fharry-potter-and-the-methods-of-rationality-discussion-31", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCcnpbKuRaYMjpFmQq%2Fharry-potter-and-the-methods-of-rationality-discussion-31", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 233, "htmlBody": "<p>This is a new thread to discuss Eliezer Yudkowsky&rsquo;s&nbsp;<em><a style=\"color: #8a8a8b;\" href=\"http://www.fanfiction.net/s/5782108/1/\">Harry Potter and the Methods of Rationality</a></em>&nbsp;and anything related to it. This thread is intended for discussing <a href=\"http://www.fanfiction.net/s/5782108/90/\">chapters 91 &amp; 92</a>&nbsp;.&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/huq/harry_potter_and_the_methods_of_rationality/\">The previous thread</a>&nbsp;has passed 500 comments.&nbsp;</p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">There is now a site dedicated to the story at&nbsp;</span><a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/\">hpmor.com</a><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">, which is now the place to go to find the&nbsp;</span><a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/notes/\">authors notes</a><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">&nbsp;and all sorts of other goodies. AdeleneDawner has kept an&nbsp;</span><a style=\"color: #8a8a8b;\" href=\"http://www.evernote.com/pub/adelenedawner/Eliezer\">archive of Author&rsquo;s Notes</a><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">. (This goes up to the notes for chapter 76, and is now not updating. The authors notes from chapter 77 onwards are on hpmor.com.)&nbsp;</span></p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">The first 5 discussion threads are on the main page under the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/tag/harry_potter/\">harry_potter tag</a>.&nbsp; Threads 6 and on (including this one) are in the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/tag/harry_potter/\">discussion section</a>&nbsp;using its separate tag system.&nbsp; Also:&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2ab/harry_potter_and_the_methods_of_rationality\">1</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2ie/harry_potter_and_the_methods_of_rationality\">2</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2nm/harry_potter_and_the_methods_of_rationality\">3</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality\">4</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/30g/harry_potter_and_the_methods_of_rationality\">5</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/364/harry_potter_and_the_methods_of_rationality/\">6</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/3rb/harry_potter_and_the_methods_of_rationality/\">7</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/797/harry_potter_and_the_methods_of_rationality/\">8</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/7jd/harry_potter_and_the_methods_of_rationality\">9</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/ams/harry_potter_and_the_methods_of_rationality\">10</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/axe/harry_potter_and_the_methods_of_rationality/\">11</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/b5s/harry_potter_and_the_methods_of_rationality/\">12</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/b7s/harry_potter_and_the_methods_of_rationality/\">13</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bfo/harry_potter_and_the_methods_of_rationality/\">14</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bmx/harry_potter_and_the_methods_of_rationality/\">15</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bto/harry_potter_and_the_methods_of_rationality/\">16</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/fyv/harry_potter_and_the_methods_of_rationality/\">17</a>,<a style=\"color: #8a8a8b;\" href=\"/lw/g1q/harry_potter_and_the_methods_of_rationality/\">18</a>,<a href=\"/r/discussion/lw/huq/harry_potter_and_the_methods_of_rationality/\">19</a>,<a href=\"/r/discussion/lw/hvg/harry_potter_and_the_methods_of_rationality/\">20</a>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Spoiler Warning</strong>: this thread is full of spoilers. With few exceptions, spoilers for MOR and canon are fair game to post, without warning or rot13.&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality/2v1l\">More specifically</a>:</p>\n<blockquote style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\">You do not need to rot13 anything about HP:MoR or the original Harry Potter series unless you are posting insider information from Eliezer Yudkowsky which is not supposed to be publicly available (which includes public statements by Eliezer that have been retracted).</p>\n<p style=\"margin: 0px 0px 1em;\">If there is evidence for X in MOR and/or canon then it&rsquo;s fine to post about X without rot13, even if you also have heard privately from Eliezer that X is true. But you should not post that &ldquo;Eliezer said X is true&rdquo; unless you use rot13.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yrg267i4a8EsgYAXp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CcnpbKuRaYMjpFmQq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 1.2543442605472274e-06, "legacy": true, "legacyId": "23199", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 368, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Pxiu5SG8gjhCh2jYd", "59rDBidWmmJTXL4Np", "xexS9nyzwRgP9sowp", "LzQcmBwAJBGyzrt6Z", "qKzeJvFWyPh5H2hwj", "nnnd4KRQxs6DYcehD", "y2Hszb4Dsm5FggnDC", "6ae2kq3JmKvL4YPgk", "zvXfBqp6TSriNkmbg", "WQ7XMjqvuRRj8nkpu", "LKFR5pBA3bBkERDxL", "8yEdpDpGgvDWHeodM", "K4JBpAxhvstdnNbeg", "xK6Pswbozev6pv4A6", "pBTcCB5uJTzADdMm4", "XN4WDRSPFo9iGEuk3", "QkhX5YeuYHzPW7Waz", "4sY9rqAqty8rHWGSW", "35GjH7tDvNJWSHQ3H", "CEd85FLRbQWsbkrmf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T19:52:24.609Z", "modifiedAt": null, "url": null, "title": "[Link]: Anthropic shadow, or the dark dusk of disaster", "slug": "link-anthropic-shadow-or-the-dark-dusk-of-disaster", "viewCount": null, "lastCommentedAt": "2020-05-17T16:39:21.349Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XYYBCjAysLsGb5bDQ/link-anthropic-shadow-or-the-dark-dusk-of-disaster", "pageUrlRelative": "/posts/XYYBCjAysLsGb5bDQ/link-anthropic-shadow-or-the-dark-dusk-of-disaster", "linkUrl": "https://www.lesswrong.com/posts/XYYBCjAysLsGb5bDQ/link-anthropic-shadow-or-the-dark-dusk-of-disaster", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%3A%20Anthropic%20shadow%2C%20or%20the%20dark%20dusk%20of%20disaster&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%3A%20Anthropic%20shadow%2C%20or%20the%20dark%20dusk%20of%20disaster%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYYBCjAysLsGb5bDQ%2Flink-anthropic-shadow-or-the-dark-dusk-of-disaster%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%3A%20Anthropic%20shadow%2C%20or%20the%20dark%20dusk%20of%20disaster%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYYBCjAysLsGb5bDQ%2Flink-anthropic-shadow-or-the-dark-dusk-of-disaster", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXYYBCjAysLsGb5bDQ%2Flink-anthropic-shadow-or-the-dark-dusk-of-disaster", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 256, "htmlBody": "<p>From a <a href=\"http://www.nickbostrom.com/papers/anthropicshadow.pdf\">paper</a> by Milan M. \u0106irkovi\u0107, Anders Sandberg, and Nick Bostrom:</p>\n<blockquote>\n<p>We describe a signi\ufb01cant practical consequence of taking anthropic biases into account in deriving predictions for rare stochastic catastrophic events. The risks associated with catastrophes such as asteroidal/cometary impacts, supervolcanic episodes, and explosions of supernovae/gamma-ray bursts are based on their observed frequencies. As a result, the frequencies of catastrophes that destroy or are otherwise incompatible with the existence of observers are systematically underestimated. We describe the consequences of this anthropic bias for estimation of catastrophic risks, and suggest some directions for future work.</p>\n</blockquote>\n<p>There cannot have been a large disaster on Earth in the last millennia, or we wouldn't be around to see it. There can't have been a very large disaster on Earth in the last ten thousand years, or we wouldn't be around to see it. There can't have been a huge disaster on Earth in the last million years, or we wouldn't be around to see it. There can't have been a planet-destroying disaster on Earth... ever.</p>\n<p>Thus the fact that we exist precludes us seeing certain types of disasters in the historical record; as we get closer and closer to the present day, the magnitude of the disasters we can see goes down. These missing disasters form the \"anthropic shadow\", somewhat visible in the top right of this diagram:</p>\n<p><img src=\"http://images.lesswrong.com/t3_hw7_0.png\" alt=\"\" width=\"615\" height=\"347\" /></p>\n<p>Hence even though it looks like the risk is going down (the magnitude is diminishing as we approach the present), we can't rely on this being true: it could be a purely anthropic effect.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XYYBCjAysLsGb5bDQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 20, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "23191", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T19:54:16.922Z", "modifiedAt": null, "url": null, "title": "Caught in the glare of two anthropic shadows", "slug": "caught-in-the-glare-of-two-anthropic-shadows", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:44.422Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XwxHwyLtZkQi8jtgg/caught-in-the-glare-of-two-anthropic-shadows", "pageUrlRelative": "/posts/XwxHwyLtZkQi8jtgg/caught-in-the-glare-of-two-anthropic-shadows", "linkUrl": "https://www.lesswrong.com/posts/XwxHwyLtZkQi8jtgg/caught-in-the-glare-of-two-anthropic-shadows", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Caught%20in%20the%20glare%20of%20two%20anthropic%20shadows&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACaught%20in%20the%20glare%20of%20two%20anthropic%20shadows%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXwxHwyLtZkQi8jtgg%2Fcaught-in-the-glare-of-two-anthropic-shadows%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Caught%20in%20the%20glare%20of%20two%20anthropic%20shadows%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXwxHwyLtZkQi8jtgg%2Fcaught-in-the-glare-of-two-anthropic-shadows", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXwxHwyLtZkQi8jtgg%2Fcaught-in-the-glare-of-two-anthropic-shadows", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1069, "htmlBody": "<p><em>This article consists of original new research, so would not get published on Wikipedia!</em></p>\n<p>The <a href=\"/r/discussion/lw/hw7/link_anthropic_shadow_or_the_dark_dusk_of_disaster/\">previous post</a> introduced the concept of the anthropic shadow: the fact that certain large and devastating disasters cannot be observed in the historical record, because if they had happened, we wouldn't be around to observe them. This absence forms an &ldquo;anthropic shadow&rdquo;.</p>\n<p>But that was the result for a single category of disasters. What would happen if we consider two independent classes of disasters? Would we see a double shadow, or would one &lsquo;overshadow&rsquo; the other?</p>\n<p>To answer that question, we&rsquo;re going to have to analyse the anthropic shadow in more detail, and see that there are two separate components to it:</p>\n<ul>\n<li>The first is the <strong>standard </strong>effect: humanity cannot have developed a technological civilization, if there were large catastrophes in the recent past.</li>\n<li>The second effect is the <strong><em>lineage</em> </strong>effect: humanity cannot have developed a technological civilization, if there was another technological civilization in the recent past that survived to today (or at least, we couldn't have developed the way we did).</li>\n</ul>\n<p>To illustrate the difference between the two, consider the following model. Segment time into arbitrarily &ldquo;eras&rdquo;. In a given era, a large disaster may hit with probability q, or a small disaster may independently hit with probability q (hence with probability q<sup>2</sup>, there will be both a large and a small disaster). A small disaster will prevent a technological civilization from developing during that era; a large one will prevent such a civilization from developing in that era <em>or the next one</em>.</p>\n<p>If it is possible for a technological civilization to develop (no small disasters that era, no large ones in the preceding era, <em>and no previous civilization</em>), then one will do so with probability p. We will assume p constant: our model will only span a time frame where p is unchanging (maybe it's over the time period after the rise of big mammals?)<a id=\"more\"></a></p>\n<p>Assume a technological civilization develops during a given era (in which, of course, there is no disasters). Let _ denotes no disaster, \u2584 denotes a small disaster only, and \u2588 denotes a large disaster (with or without a small disaster as well). Then the possible past sequences that end in the current era (which is a _ by definition) can be divided into sequences that end in the following ways (the anthropic shadow is the first row):</p>\n<table style=\"color: #000000; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<th><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif; font-weight: normal; line-height: normal; text-align: start;\">\u2588 \u2584 _</span></th>\n<td style=\"font-size: 15px;\" align=\"center\">q<sup>2</sup>(1-q)</td>\n<td style=\"font-size: 15px;\" align=\"center\">q<sup>2</sup>(1-q)/&Omega;</td>\n</tr>\n<tr>\n<th><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif; font-weight: normal; line-height: normal; text-align: start;\">\u2588 _</span></th>\n<td style=\"font-size: 15px;\" align=\"center\">q</td>\n<td style=\"font-size: 15px;\" align=\"center\"><strong>0</strong></td>\n</tr>\n<tr>\n<th><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif; font-weight: normal; line-height: normal; text-align: start;\">\u2584 \u2584 _ or _ \u2584 _</span></th>\n<td style=\"font-size: 15px;\" align=\"center\">q(1-q)<sup>2</sup></td>\n<td style=\"font-size: 15px;\" align=\"center\">q(1-q)<sup>2</sup>/&Omega;</td>\n</tr>\n<tr>\n<th><span style=\"font-family: Verdana, Arial, Helvetica, sans-serif; font-weight: normal; line-height: normal; text-align: start;\">\u2588 _ ... _ or \u2584 _ ... _</span></th>\n<td style=\"font-size: 15px;\" align=\"center\">(1-q)<sup>2</sup></td>\n<td style=\"font-size: 15px;\" align=\"center\"><span style=\"font-size: 15px;\"><strong>(1-(1-q)<sup>2</sup>)*((1-q<sup>2</sup>)(1-p)/(1-(1-q<sup>2</sup>)(1-p)))</strong>/&Omega;</span></td>\n</tr>\n</tbody>\n</table>\n<p>The first column gives the probabilities of these various pasts, without any anthropic correction. The second column applies the anthropic correction, essentially changing some of the probabilities and then renormalising by &Omega;, which is the sum of the remaining probabilities, namely q<sup>2</sup>(1-q) + q(1-q)<sup>2</sup>&nbsp;+ (1-(1-q)<sup>2</sup>)*((1-q<sup>2</sup>)(1-p)/(1-(1-q<sup>2</sup>)(1-p))). Don&rsquo;t be impressed by the complexity of the formula: the ideas are key.</p>\n<p>The standard anthropic effect rules out the second row: we can&rsquo;t have large disasters in the previous era. The lineage effect reduces the probability of the fourth row: we have less chance of developing a technological civilization in this era, if there are many opportunities for a previous one to develop. Both these effects increase the relative probability of the first row, which is the anthropic shadow.</p>\n<p>The first thing to note is that the standard effect is very strong for high q. If q is very close to 1, then the third and fourth rows, being multiples of (1-q)<sup>2</sup>, are much less likely that the first row, which has a single power of (1-q). Hence an anthropic shadow is nearly certain.</p>\n<p>The <a href=\"/lw/hw8/caught_in_the_glare_of_two_anthropic_shadows/\">lineage</a> effect is weaker. Even if p=1, the only effect is to rule out the fourth row. The first and the third row remain as possibilities, with ratios of q<sup>2</sup>:q(1-q): hence we still need a reasonable q to get an anthropic shadow. If we break down the scale of the disaster into more than two components, and insist on a strict anthropic shadow (regularly diminishing disaster intensity), then the lineage effect becomes very weak indeed. If the data is poor, though, or if we allow approximate shadows (if for instance we consider the third row as an anthropic shadow: civilization appeared as soon after the small disaster as it could), then the lineage effect can be significant.</p>\n<p>What has this got to do with multiple disasters? If we look at meteor impacts and (non-meteor-caused) supervolcanoes, what should we expect to see? The simple rule is that the standard anthropic shadows of two classes of disasters combine (we see two anthropic shadows), while the lineage effect of the most devastating disaster dominates.</p>\n<p>How can we see this?</p>\n<p>Let&rsquo;s ignore the lineage effect for the moment, and let q and r be the probabilities for the two classes of disasters. Then instead of having four situations, as above, we have sixteen: four each for the disasters, independently. We can represent this by the following table:</p>\n<table style=\"color: #000000; font-family: Arial, Helvetica, sans-serif; font-size: small; line-height: 19px; text-align: justify;\" border=\"3\" align=\"center\">\n<tbody>\n<tr>\n<th><br /></th> <th style=\"text-align: start;\">q<sup>2</sup>(1-q)</th> <th style=\"text-align: start;\">q</th> <th>q(1-q)<sup>2</sup></th><th>(1-q)<sup>2</sup></th>\n</tr>\n<tr>\n<th>r<sup>2</sup>(1-r)</th>\n<td style=\"background-color:#FF0000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n</tr>\n<tr>\n<th>r</th>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n</tr>\n<tr>\n<th>r(1-r)<sup>2</sup></th>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n</tr>\n<tr>\n<th>(1-r)<sup>2</sup></th>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"background-color:#000000; font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n<td style=\"font-size: 15px;\" align=\"center\"><br /></td>\n</tr>\n</tbody>\n</table>\n<p>Then applying <strong>standard</strong> anthropic effects means removing the second row, then removing the second column (or vice versa), and then renormalising. The anthropic effect for the first class of disasters moves the probability of its anthropic shadows from q<sup>2</sup>(1-q) to q<sup>2</sup>. While the joint probability of the combined anthropic shadow (the top left box in red) is moved from q<sup>2</sup>(1-q)*r<sup>2</sup>(1-r) to q<sup>2</sup>*r<sup>2</sup>. The two shadows are independent.</p>\n<p>In contrast, the <strong>lineage</strong> effect rules out long series of disaster-free eras before our own era. If there is a possibility for a long series (q and r being low), then the lineage effect makes a big impact. But the likely number of disaster-free eras is determined by the highest of q and r. If q and r are both 1%, then we&rsquo;d expect something like 25 disaster-free eras in a row. If q is 10% and r is 1%, then we&rsquo;d expect something like 5 disaster-free eras in a row - the same as if r was zero, and we were facing a single disaster.</p>\n<p>So though the real-world data is probably too poor to conclude anything, the above result raises the possibility that we could estimate the lineage effect independently, by looking at the anthropic shadows of unrelated disasters - and thus get another way of calculating the probability of technological civilizations such as our own emerging.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XwxHwyLtZkQi8jtgg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 29, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "23192", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["XYYBCjAysLsGb5bDQ", "XwxHwyLtZkQi8jtgg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-04T23:34:15.548Z", "modifiedAt": null, "url": null, "title": "How I Became More Ambitious", "slug": "how-i-became-more-ambitious", "viewCount": null, "lastCommentedAt": "2017-06-17T04:29:33.311Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KJbQyFbXiiYDDWbaS/how-i-became-more-ambitious", "pageUrlRelative": "/posts/KJbQyFbXiiYDDWbaS/how-i-became-more-ambitious", "linkUrl": "https://www.lesswrong.com/posts/KJbQyFbXiiYDDWbaS/how-i-became-more-ambitious", "postedAtFormatted": "Thursday, July 4th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20I%20Became%20More%20Ambitious&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20I%20Became%20More%20Ambitious%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKJbQyFbXiiYDDWbaS%2Fhow-i-became-more-ambitious%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20I%20Became%20More%20Ambitious%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKJbQyFbXiiYDDWbaS%2Fhow-i-became-more-ambitious", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKJbQyFbXiiYDDWbaS%2Fhow-i-became-more-ambitious", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2273, "htmlBody": "<p>Follow-up to <a href=\"/lw/9j1/how_i_ended_up_nonambitious/\">How I Ended Up Non-Ambitious</a></p>\n<p>Living with yourself is a bit like having a preteen and watching them get taller; the changes happen so slowly that it's almost impossible to notice them, until you stumble across an old point of comparison and it becomes blindingly obvious. I hit that point a few days ago, while planning what I might want to talk about during an OkCupid date. My brain produced the following thought: \"well, if this topic comes up, it might sound like I'm trying to take over the world, and that's intimidating- Wait. What?\"</p>\n<p>I'm not trying to take over the world. It sounds like a lot of work, and not my comparative advantage. If it seemed necessary, I would point out the problems that needed solving and delegate them to CFAR alumni with more domain-specific expertise than me.</p>\n<p>However, I went back and reread the post linked at the beginning, and I no longer feel much kinship with that person. This is a change that happened maybe 25-50% deliberately, and the rest by drift, but I still changed my mind, so I will try to detail the particular changes, and what I think led to them. <a href=\"/lw/5sk/inferring_our_desires/\">Introspection is unreliable</a>, so I'll probably be at least 50% wrong, but what can you do?</p>\n<h2><strong>1. Idealism versus practicality</strong></h2>\n<p>I would still call myself practical, but I no longer think that this comes at the expense of idealism. Idealism is absolutely essential, if you want to have a world that changes because someone wanted it to, as opposed to just by drift. Lately in the rationalist/CFAR/LW community, there's been a lot of emphasis on <a href=\"/tag/agency/\">agency</a> and agentiness, which basically mean the ability to change the world and/or yourself deliberately, on purpose, through planned actions. This is hard. The first step is idealism-being able to imagine a state of affairs that is different and better. Then comes practicality, the part where you sit down and work hard and actually get something done.</p>\n<p>It's still true that idealism without practicality doesn't get much done, and practicality without idealism can get a lot done, but it matters what problems you're working on, too. Are you being <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">strategic</a>? Are you even thinking, at all, about whether your actions are helping to accomplish your goals? One of the big things I've learned, a year and a half and two CFAR workshops later, is how automatic and easy this lack of strategy really is.</p>\n<p>I had a limited sort of idealism in high school; I wanted to do work that was important and relevant; but I was lazy about it. I wanted someone to tell me what was important to be doing right now. Nursing seemed like an awesome solution. It still seems like a solution, but recently I've admitted to myself, with a painful twinge, that it might not be the best way for me, personally, to help the greatest number of people using my current and potential skill set. It's <a href=\"/lw/8j4/5second_level_case_study_value_of_information/\">worth spending a few minutes or hours</a> looking for interesting and important problems to work on.</p>\n<p>I don't think I had the mental vocabulary to think that thought a year and a half ago. Some of the change comes from having dated an economics student. Come to think of it, I expect some of his general ambition rubbed off on me, too. The rest of the change comes from hanging out with the effective altruism and similar communities.</p>\n<p>I'm still practical. I exercise, eat well, go to bed on time, work lots of hours, spend my money wisely, and maintain my social circle mostly on autopilot; it requires effort but not deliberate effort. I'm lucky to have this skill. But I no longer think it's a virtue over and above idealism. Practical idealists make the biggest difference, and they're pretty cool to hang out with. I want to be one when I grow up.</p>\n<h2><span style=\"mso-ansi-language: EN-US;\">2. Fear of failure</span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">Don't get me wrong. If there's one deep, gripping, soul-crushing terror in my life, one thing that gives me literal nightmares, it's failure. Making mistakes. Not being good enough. Et cetera. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">In the past few years, the main change has been admitting to myself that this terror doesn't make a lot of sense. First of all, it's completely miscalibrated. As Eliezer pointed out during a conversation on this, I don't fail at things very often. Far from being a success, this is likely a sign that the things I'm trying aren't nearly challenging enough. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">My threshold for what constitutes failure is also fairly low. I made a couple of embarrassing mistakes during my spring clinical. Some part of my brain is convinced that this equals <em>permanent </em>failure; I wasn't perfect during the placement, and I can't go back and change the past, thus I have failed. Forever. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I passed the clinical, wrote the provincial exam (results aren't in but I'm &gt;99% confident I passed) <span style=\"font-family: mceinline;\">(EDIT: Passed! YEAAHHH!!!)</span>, and I'm currently working in the intensive care unit, which has been my dream since I was about fifteen. The part of my brain that keeps telling me I failed permanently obviously isn't saying anything useful. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I think 'embarrassing' is a keyword here. The first thing I thought, on the several occasions that I made mistakes, was \"oh my god did I just kill someone... Phew, no, no harm done.\" The second thought was \"oh my god, my preceptor will think I'm stupid forever and she'll never respect me and no one wants me around, I'm not good enough...\" This line of thought never goes anywhere good. It says something about me, though, that \"I'm not good enough\" is very directly connected to people wanting me around, to belonging somewhere. For several personality-formative years of my life, people <em>didn't </em>want me around. Probably for good reason; my ten-year-old self was prickly and socially inept and miserable. I think a lot of my determination not to seek status comes from the \"uncool kids trying to be cool are pathetic\" meme that was so rampant when I was in sixth grade. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">Oh, and then there's the traumatic swim team experience. Somewhere, in a part of my brain where I don't go very often nowadays, there a bottomless whirlpool of powerless rage and despair around the phrase \"no matter how hard I try, I'll never be good enough.\" So when I make an embarrassing mistake, my ten-year-old self is screaming at me \"no wonder everyone hates you!\" and my fourteen-year-old self is sadly muttering that \"you know, maybe you just don't have enough natural talent,\" and none of it is at all useful. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">The thing about those phrases is that they refer to complex and value-laden concepts, in a way that makes them seem like innate attributes, &agrave; la <a href=\"/lw/hz/correspondence_bias/\">Fundamental Attribution Error</a>. \"Not good enough\" isn't a yes-or-no attribute of a person; it's a <a href=\"/lw/td/magical_categories/\">magical category</a> that only sounds simple because it's a three-word phrase. I've gotten somewhat better at propagating this to my emotional self. Slightly. It's a work in progress.</span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">During a conversation about this with <a href=\"http://annasalamon.com/\">Anna Salamon</a>, she noted that she likes to approach her own emotions and ask them what they want. It sounds weird, but it's helpful. \"Dear crushing sense of despair and unworthiness, what do you want? ...Oh, you're worried that you're going to end up an outcast from your tribe and starve to death in the wilderness because you accidentally gave an extra dose of digoxin? You want to signal remorse and regret and make sure everyone knows you're taking your failure seriously so that maybe they'll forgive you? Thank you for trying to protect me. But really, you don't need to worry about the starving-outcast thing. No one was harmed and no one is mad at you personally. Your friends and family couldn't care less. This mistake is data, but it's just as much data about the environment as it is about your attributes. These hand-copied medication records are the perfect medium for human error. Instead of signalling remorse, let's put some mental energy into getting rid of the environmental conditions that led to this mistake.\"</span></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Rejection_Therapy\">Rejection therapy</a> and having a general CoZE [Comfort Zone Expansion] mindset helped remove some of the sting of \"but I'll look stupid if I try something too hard and fail at it!\" I still worry about the pain of future embarrassment, but I'm more likely to point out to myself that it's not a valid objection and I should do X anyway. Making \"<a href=\"/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/\">I want to become stronger</a>\" an explicit motto is new to the last year and a half, too, and helps by giving me ammunition for why potential embarrassment isn't a reason not to do something.</p>\n<p>In conclusion: failure still sucks. I'm a perfectionist. But I failed in a lot of small ways during my <a href=\"/lw/gnv/learning_critical_thinking_a_personal_example/\">spring clinical</a>, and passed/got a job anyway, which seems to have helped me propagate to my emotional self that<em> it's okay to try hard things</em>, where I'm almost certain to make mistakes, because mistakes don't equal instant damnation and hatred from all of my friends.</p>\n<h2><span style=\"mso-ansi-language: EN-US;\"><strong>3. The morality of ambition</strong></span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">While I was in San Francisco a month ago, volunteering at the CFAR workshop and generally spending my time surrounded by smart, passionate, and ambitious people (thus convincing my emotional system that this is normal and okay), I had a conversation with Eliezer. He asked me to list ten areas in which I was above average. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">This was a lot more painful than it had any reason to be. After bouncing off various poorly-formed objections in my mind, I said to myself \"you know, having trouble admitting what you're good at doesn't make you virtuous.\" This was painful; losing a source of feeling-virtuous always is. But it was helpful. Yeah, talking all the time about how awesome you are at X, Y, Z makes you a bit of a bore. People might even avoid you (oh! the horror!). However, this doesn't mean that blocking even the<em> thought </em>of being above average makes you a good person. In fact, it's counterproductive. How are you supposed to know what problems you're capable of solving in the world if you can't be honest with yourself about your capabilities? </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">This conversation helped. (Even if some of the effect was \"high status person says X -&gt; I believe X,\" who cares? I endorsed myself changing my mind about this a year and a half ago. It's about time.)</span></p>\n<p><span style=\"mso-ansi-language: EN-US;\"><a href=\"http://hpmor.com/\">HPMOR</a> helped, too; specifically, the idea that there are four houses which have different positive qualities. Slytherins are demonized in canon, but in HPMOR their skills are recognized as essential. I can easily recognize the Ravenclaw and Hufflepuff and even the Gryffindor in myself, but not much of Slytherin. Having a word for the ambition-cunning-strategic concept cluster is helpful. I can ask myself \"now what would a Slytherin do with this information:?\" I can think thoughts that feel very un-virtuous. \"I'm young and prettier than average. What's a Slytherin way to use this... Oh, I suppose I can leverage it to get high-status men to pay attention to me long enough for me to explain the merits of an idea I have.\" This thought feels yuck, but the universe doesn't explode. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">Probably the biggest factor was going to the CFAR workshops in the first place. Not from any of the curriculum, particularly, although the mindset of goal factoring helped me to realize that the mental action of \"feeling unvirtuous for thinking in ambitious or calculating ways\" wasn't accomplishing anything I wanted. Mostly the change came from social normalization, from hanging out with people who talked openly about their strengths and weaknesses, and no one got shunned. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">[Silly plan for taking over the world: Arrange to meet high status-people and offer to give their children swimming lessons. Gain their trust. Proceed from there.]</span></p>\n<h2><span style=\"mso-ansi-language: EN-US;\"><strong>4. Laziness</strong></span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">Nope. Still lazy. If anything, akrasia and procrastination are more of a problem now that I'm trying to do harder things more deliberately. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I've been keeping written goals for about a year now. This means I actually notice when I don't accomplish them. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I use Remember the Milk as a GTD system, and some other productivity/organization software (rescuetime, Mint.com, etc). I finally switched to Gmail, where I can use Boomerang and other useful tools. My current openness to trying new organization methods is high. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">My general interest in <a href=\"/lw/5a5/no_seriously_just_try_it/\">trying things</a> is higher, mainly because I have lots of community-endorsed-warm-fuzzies positive affect around that phrase. I want to be someone who's open to new experiences; I've had enough new experiences to realize how exhilarating they can be.&nbsp;</span></p>\n<h2><span style=\"mso-ansi-language: EN-US;\"><strong>Conclusion</strong></span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">I now have a wider range of potentially high-value personal projects ongoing. I now have an explicit goal of being well-known for non-fiction writing, probably in a blog form, in the next five years. (Do I have enough interesting things to say to make this a reality? We'll see. Is this goal vague? Yes. Working on it. I used to reject goals if they weren't utterly concrete, but even vague goals are something to build on). </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I'm more explicit with myself about what I want from CFAR curriculum skills. (The general problem of critical thinking in nursing? Solvable! Why not?) </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I think I've finally admitted to myself that \"well, I'll just live in a cozy little house near my parents and work in the ICU and raise kids for the next forty years\" might not be particularly virtuous <em>or </em>fun. There are things I would prefer to be different in the world, even if I can only completely specify a few of them. There are exciting scary opportunities happening all the time. I'm lucky enough to belong to a community of people that can help me find them. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I don't have plans for much beyond the next year. But here's to the next decade being interesting!<br /></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"hrezrpGqXXdSe76ks": 3, "iP2X4jQNHMWHRNPne": 2, "irYLXtT9hkPXoZqhH": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KJbQyFbXiiYDDWbaS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 78, "baseScore": 117, "extendedScore": null, "score": 0.00028, "legacy": true, "legacyId": "23180", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 117, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Follow-up to <a href=\"/lw/9j1/how_i_ended_up_nonambitious/\">How I Ended Up Non-Ambitious</a></p>\n<p>Living with yourself is a bit like having a preteen and watching them get taller; the changes happen so slowly that it's almost impossible to notice them, until you stumble across an old point of comparison and it becomes blindingly obvious. I hit that point a few days ago, while planning what I might want to talk about during an OkCupid date. My brain produced the following thought: \"well, if this topic comes up, it might sound like I'm trying to take over the world, and that's intimidating- Wait. What?\"</p>\n<p>I'm not trying to take over the world. It sounds like a lot of work, and not my comparative advantage. If it seemed necessary, I would point out the problems that needed solving and delegate them to CFAR alumni with more domain-specific expertise than me.</p>\n<p>However, I went back and reread the post linked at the beginning, and I no longer feel much kinship with that person. This is a change that happened maybe 25-50% deliberately, and the rest by drift, but I still changed my mind, so I will try to detail the particular changes, and what I think led to them. <a href=\"/lw/5sk/inferring_our_desires/\">Introspection is unreliable</a>, so I'll probably be at least 50% wrong, but what can you do?</p>\n<h2 id=\"1__Idealism_versus_practicality\"><strong>1. Idealism versus practicality</strong></h2>\n<p>I would still call myself practical, but I no longer think that this comes at the expense of idealism. Idealism is absolutely essential, if you want to have a world that changes because someone wanted it to, as opposed to just by drift. Lately in the rationalist/CFAR/LW community, there's been a lot of emphasis on <a href=\"/tag/agency/\">agency</a> and agentiness, which basically mean the ability to change the world and/or yourself deliberately, on purpose, through planned actions. This is hard. The first step is idealism-being able to imagine a state of affairs that is different and better. Then comes practicality, the part where you sit down and work hard and actually get something done.</p>\n<p>It's still true that idealism without practicality doesn't get much done, and practicality without idealism can get a lot done, but it matters what problems you're working on, too. Are you being <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">strategic</a>? Are you even thinking, at all, about whether your actions are helping to accomplish your goals? One of the big things I've learned, a year and a half and two CFAR workshops later, is how automatic and easy this lack of strategy really is.</p>\n<p>I had a limited sort of idealism in high school; I wanted to do work that was important and relevant; but I was lazy about it. I wanted someone to tell me what was important to be doing right now. Nursing seemed like an awesome solution. It still seems like a solution, but recently I've admitted to myself, with a painful twinge, that it might not be the best way for me, personally, to help the greatest number of people using my current and potential skill set. It's <a href=\"/lw/8j4/5second_level_case_study_value_of_information/\">worth spending a few minutes or hours</a> looking for interesting and important problems to work on.</p>\n<p>I don't think I had the mental vocabulary to think that thought a year and a half ago. Some of the change comes from having dated an economics student. Come to think of it, I expect some of his general ambition rubbed off on me, too. The rest of the change comes from hanging out with the effective altruism and similar communities.</p>\n<p>I'm still practical. I exercise, eat well, go to bed on time, work lots of hours, spend my money wisely, and maintain my social circle mostly on autopilot; it requires effort but not deliberate effort. I'm lucky to have this skill. But I no longer think it's a virtue over and above idealism. Practical idealists make the biggest difference, and they're pretty cool to hang out with. I want to be one when I grow up.</p>\n<h2 id=\"2__Fear_of_failure\"><span style=\"mso-ansi-language: EN-US;\">2. Fear of failure</span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">Don't get me wrong. If there's one deep, gripping, soul-crushing terror in my life, one thing that gives me literal nightmares, it's failure. Making mistakes. Not being good enough. Et cetera. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">In the past few years, the main change has been admitting to myself that this terror doesn't make a lot of sense. First of all, it's completely miscalibrated. As Eliezer pointed out during a conversation on this, I don't fail at things very often. Far from being a success, this is likely a sign that the things I'm trying aren't nearly challenging enough. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">My threshold for what constitutes failure is also fairly low. I made a couple of embarrassing mistakes during my spring clinical. Some part of my brain is convinced that this equals <em>permanent </em>failure; I wasn't perfect during the placement, and I can't go back and change the past, thus I have failed. Forever. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I passed the clinical, wrote the provincial exam (results aren't in but I'm &gt;99% confident I passed) <span style=\"font-family: mceinline;\">(EDIT: Passed! YEAAHHH!!!)</span>, and I'm currently working in the intensive care unit, which has been my dream since I was about fifteen. The part of my brain that keeps telling me I failed permanently obviously isn't saying anything useful. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I think 'embarrassing' is a keyword here. The first thing I thought, on the several occasions that I made mistakes, was \"oh my god did I just kill someone... Phew, no, no harm done.\" The second thought was \"oh my god, my preceptor will think I'm stupid forever and she'll never respect me and no one wants me around, I'm not good enough...\" This line of thought never goes anywhere good. It says something about me, though, that \"I'm not good enough\" is very directly connected to people wanting me around, to belonging somewhere. For several personality-formative years of my life, people <em>didn't </em>want me around. Probably for good reason; my ten-year-old self was prickly and socially inept and miserable. I think a lot of my determination not to seek status comes from the \"uncool kids trying to be cool are pathetic\" meme that was so rampant when I was in sixth grade. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">Oh, and then there's the traumatic swim team experience. Somewhere, in a part of my brain where I don't go very often nowadays, there a bottomless whirlpool of powerless rage and despair around the phrase \"no matter how hard I try, I'll never be good enough.\" So when I make an embarrassing mistake, my ten-year-old self is screaming at me \"no wonder everyone hates you!\" and my fourteen-year-old self is sadly muttering that \"you know, maybe you just don't have enough natural talent,\" and none of it is at all useful. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">The thing about those phrases is that they refer to complex and value-laden concepts, in a way that makes them seem like innate attributes, \u00e0 la <a href=\"/lw/hz/correspondence_bias/\">Fundamental Attribution Error</a>. \"Not good enough\" isn't a yes-or-no attribute of a person; it's a <a href=\"/lw/td/magical_categories/\">magical category</a> that only sounds simple because it's a three-word phrase. I've gotten somewhat better at propagating this to my emotional self. Slightly. It's a work in progress.</span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">During a conversation about this with <a href=\"http://annasalamon.com/\">Anna Salamon</a>, she noted that she likes to approach her own emotions and ask them what they want. It sounds weird, but it's helpful. \"Dear crushing sense of despair and unworthiness, what do you want? ...Oh, you're worried that you're going to end up an outcast from your tribe and starve to death in the wilderness because you accidentally gave an extra dose of digoxin? You want to signal remorse and regret and make sure everyone knows you're taking your failure seriously so that maybe they'll forgive you? Thank you for trying to protect me. But really, you don't need to worry about the starving-outcast thing. No one was harmed and no one is mad at you personally. Your friends and family couldn't care less. This mistake is data, but it's just as much data about the environment as it is about your attributes. These hand-copied medication records are the perfect medium for human error. Instead of signalling remorse, let's put some mental energy into getting rid of the environmental conditions that led to this mistake.\"</span></p>\n<p><a href=\"http://en.wikipedia.org/wiki/Rejection_Therapy\">Rejection therapy</a> and having a general CoZE [Comfort Zone Expansion] mindset helped remove some of the sting of \"but I'll look stupid if I try something too hard and fail at it!\" I still worry about the pain of future embarrassment, but I'm more likely to point out to myself that it's not a valid objection and I should do X anyway. Making \"<a href=\"/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/\">I want to become stronger</a>\" an explicit motto is new to the last year and a half, too, and helps by giving me ammunition for why potential embarrassment isn't a reason not to do something.</p>\n<p>In conclusion: failure still sucks. I'm a perfectionist. But I failed in a lot of small ways during my <a href=\"/lw/gnv/learning_critical_thinking_a_personal_example/\">spring clinical</a>, and passed/got a job anyway, which seems to have helped me propagate to my emotional self that<em> it's okay to try hard things</em>, where I'm almost certain to make mistakes, because mistakes don't equal instant damnation and hatred from all of my friends.</p>\n<h2 id=\"3__The_morality_of_ambition\"><span style=\"mso-ansi-language: EN-US;\"><strong>3. The morality of ambition</strong></span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">While I was in San Francisco a month ago, volunteering at the CFAR workshop and generally spending my time surrounded by smart, passionate, and ambitious people (thus convincing my emotional system that this is normal and okay), I had a conversation with Eliezer. He asked me to list ten areas in which I was above average. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">This was a lot more painful than it had any reason to be. After bouncing off various poorly-formed objections in my mind, I said to myself \"you know, having trouble admitting what you're good at doesn't make you virtuous.\" This was painful; losing a source of feeling-virtuous always is. But it was helpful. Yeah, talking all the time about how awesome you are at X, Y, Z makes you a bit of a bore. People might even avoid you (oh! the horror!). However, this doesn't mean that blocking even the<em> thought </em>of being above average makes you a good person. In fact, it's counterproductive. How are you supposed to know what problems you're capable of solving in the world if you can't be honest with yourself about your capabilities? </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">This conversation helped. (Even if some of the effect was \"high status person says X -&gt; I believe X,\" who cares? I endorsed myself changing my mind about this a year and a half ago. It's about time.)</span></p>\n<p><span style=\"mso-ansi-language: EN-US;\"><a href=\"http://hpmor.com/\">HPMOR</a> helped, too; specifically, the idea that there are four houses which have different positive qualities. Slytherins are demonized in canon, but in HPMOR their skills are recognized as essential. I can easily recognize the Ravenclaw and Hufflepuff and even the Gryffindor in myself, but not much of Slytherin. Having a word for the ambition-cunning-strategic concept cluster is helpful. I can ask myself \"now what would a Slytherin do with this information:?\" I can think thoughts that feel very un-virtuous. \"I'm young and prettier than average. What's a Slytherin way to use this... Oh, I suppose I can leverage it to get high-status men to pay attention to me long enough for me to explain the merits of an idea I have.\" This thought feels yuck, but the universe doesn't explode. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">Probably the biggest factor was going to the CFAR workshops in the first place. Not from any of the curriculum, particularly, although the mindset of goal factoring helped me to realize that the mental action of \"feeling unvirtuous for thinking in ambitious or calculating ways\" wasn't accomplishing anything I wanted. Mostly the change came from social normalization, from hanging out with people who talked openly about their strengths and weaknesses, and no one got shunned. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">[Silly plan for taking over the world: Arrange to meet high status-people and offer to give their children swimming lessons. Gain their trust. Proceed from there.]</span></p>\n<h2 id=\"4__Laziness\"><span style=\"mso-ansi-language: EN-US;\"><strong>4. Laziness</strong></span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">Nope. Still lazy. If anything, akrasia and procrastination are more of a problem now that I'm trying to do harder things more deliberately. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I've been keeping written goals for about a year now. This means I actually notice when I don't accomplish them. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I use Remember the Milk as a GTD system, and some other productivity/organization software (rescuetime, Mint.com, etc). I finally switched to Gmail, where I can use Boomerang and other useful tools. My current openness to trying new organization methods is high. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">My general interest in <a href=\"/lw/5a5/no_seriously_just_try_it/\">trying things</a> is higher, mainly because I have lots of community-endorsed-warm-fuzzies positive affect around that phrase. I want to be someone who's open to new experiences; I've had enough new experiences to realize how exhilarating they can be.&nbsp;</span></p>\n<h2 id=\"Conclusion\"><span style=\"mso-ansi-language: EN-US;\"><strong>Conclusion</strong></span></h2>\n<p><span style=\"mso-ansi-language: EN-US;\">I now have a wider range of potentially high-value personal projects ongoing. I now have an explicit goal of being well-known for non-fiction writing, probably in a blog form, in the next five years. (Do I have enough interesting things to say to make this a reality? We'll see. Is this goal vague? Yes. Working on it. I used to reject goals if they weren't utterly concrete, but even vague goals are something to build on). </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I'm more explicit with myself about what I want from CFAR curriculum skills. (The general problem of critical thinking in nursing? Solvable! Why not?) </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I think I've finally admitted to myself that \"well, I'll just live in a cozy little house near my parents and work in the ICU and raise kids for the next forty years\" might not be particularly virtuous <em>or </em>fun. There are things I would prefer to be different in the world, even if I can only completely specify a few of them. There are exciting scary opportunities happening all the time. I'm lucky enough to belong to a community of people that can help me find them. </span></p>\n<p><span style=\"mso-ansi-language: EN-US;\">I don't have plans for much beyond the next year. But here's to the next decade being interesting!<br></span></p>", "sections": [{"title": "1. Idealism versus practicality", "anchor": "1__Idealism_versus_practicality", "level": 1}, {"title": "2. Fear of failure", "anchor": "2__Fear_of_failure", "level": 1}, {"title": "3. The morality of ambition", "anchor": "3__The_morality_of_ambition", "level": 1}, {"title": "4. Laziness", "anchor": "4__Laziness", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BFamedwSgRdGGKXQQ", "2G7AH92pHyj3nC32T", "PBRWb2Em5SNeWYwwB", "xDiqYyqeqPo92PojS", "DB6wbyrMugYMK5o6a", "PoDAyQMWEXBBBEJ5P", "DoLQN5ryZ9XkZjq5h", "pp62TwbtyFnTZe4Nb", "Zmfo388RA9oky3KYe"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T12:22:59.433Z", "modifiedAt": null, "url": null, "title": "A New Interpretation of the Marshmallow Test", "slug": "a-new-interpretation-of-the-marshmallow-test", "viewCount": null, "lastCommentedAt": "2021-06-05T11:25:15.947Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "elharo", "createdAt": "2012-12-28T14:11:02.335Z", "isAdmin": false, "displayName": "elharo"}, "userId": "cgJcCeZhdRnGtwMMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CHdsSaQGAvtkXBzmJ/a-new-interpretation-of-the-marshmallow-test", "pageUrlRelative": "/posts/CHdsSaQGAvtkXBzmJ/a-new-interpretation-of-the-marshmallow-test", "linkUrl": "https://www.lesswrong.com/posts/CHdsSaQGAvtkXBzmJ/a-new-interpretation-of-the-marshmallow-test", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20New%20Interpretation%20of%20the%20Marshmallow%20Test&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20New%20Interpretation%20of%20the%20Marshmallow%20Test%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCHdsSaQGAvtkXBzmJ%2Fa-new-interpretation-of-the-marshmallow-test%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20New%20Interpretation%20of%20the%20Marshmallow%20Test%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCHdsSaQGAvtkXBzmJ%2Fa-new-interpretation-of-the-marshmallow-test", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCHdsSaQGAvtkXBzmJ%2Fa-new-interpretation-of-the-marshmallow-test", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 563, "htmlBody": "<p>I've begun to notice a pattern with experiments in behavioral economics. An experiment produces a result that's counter-intuitive and surprising, and demonstrates that people don't behave as rationally as expected. Then, as time passes, other researchers contrive different versions of the experiment that show the experiment may not have been about what we thought it was about in the first place. For example, in the <a href=\"https://en.wikipedia.org/wiki/Dictator_game\">dictator game</a>, <span class=\"st\">Jeffrey<em> </em>Winking<em> </em>and<em> </em>Nicholas Mizer </span><a href=\"http://www.epjournal.net/blog/2013/05/are-all-dictator-game-results-artifacts/\">changed the experiment</a> so that the participants didn't know each other and the subjects didn't know they were in an experiment. With this simple adjustment that made the conditions of the game more realistic, the \"dictators\" switched from giving away a large portion of their unearned gains to giving away nothing. Now it's happened to the marshmallow test.</p>\n<p>In the original <a href=\"https://en.wikipedia.org/wiki/Stanford_marshmallow_experiment\">Stanford marshmallow experiment</a>, children were given one marshmallow. They could eat the marshmallow right away; or, if they waited fifteen minutes for the experimenter to return without eating the marshmallow, they'd get a second marshmallow. Even more interestingly, in follow-up studies two decades later, the children who waited longer for the second marshmallow, i.e. showed delayed gratification, had higher SAT scores, school performance, and even improved Body Mass Index. This is normally interpreted as indicating the importance of self-control and delayed gratification for life success.</p>\n<p>Not so fast.</p>\n<p>In a new variant of the experiment entitled (I kid you not) \"<a href=\"https://www.sciencedirect.com/science/article/pii/S0010027712001849\">Rational snacking</a>\", Celeste Kidd, Holly Palmeri, and Richard N. Aslin from the University of Rochester gave the children a similar test with an interesting twist.</p>\n<p>They assigned 28 children to two groups asked to perform art projects. Children in the first group each received half a container of used crayons, and were told that if they could wait, the researcher would bring them more and better art supplies. However, after two and a half minutes, the adult returned and told the child they had made a mistake, and there were no more art supplies so they'd have to use the original crayons.</p>\n<p>In part 2, the adult gave the child a single sticker and told the child that if they waited, the adult would bring them more stickers to use. Again the adult reneged.</p>\n<p>Children in the second group went through the same routine except this time the adult fulfilled their promises, bringing the children more and better art supplies and several large stickers.</p>\n<p>After these two events, the experimenters repeated the classic marshmallow test with both groups. The results demonstrated children were a lot more rational than we might have thought. Of the 14 children in group 1, who had been shown that the experimenters were unreliable adults, 13 of them ate the first marshmallow. 8 of the 14 children in the reliable adult group, waited out the fifteen minutes. On average children in unreliable group 1 waited only 3 minutes, and those in reliable group 2 waited 12 minutes.</p>\n<p>So maybe what the longitudinal studies show is that children who come from an environment where they have learned to be more trusting have better life outcomes. I make absolutely no claims as to which direction the arrow of causality may run, or whether it's pure correlation with other factors. For instance, maybe breastfeeding increases both trust and academic performance. But any way you interpret these results, the case for the importance and even the existence of innate self-control is looking a lot weaker.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"vg4LDxjdwHLotCm8w": 1, "Q55STnFh6gbSezRuR": 1, "ksdiAMKfgSyEeKMo6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CHdsSaQGAvtkXBzmJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 86, "baseScore": 117, "extendedScore": null, "score": 0.000311, "legacy": true, "legacyId": "23190", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 117, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T14:05:20.850Z", "modifiedAt": null, "url": null, "title": "Singleton: the risks and benefits of one world governments", "slug": "singleton-the-risks-and-benefits-of-one-world-governments", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:33.238Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4cD4dywgtX5pdxbHT/singleton-the-risks-and-benefits-of-one-world-governments", "pageUrlRelative": "/posts/4cD4dywgtX5pdxbHT/singleton-the-risks-and-benefits-of-one-world-governments", "linkUrl": "https://www.lesswrong.com/posts/4cD4dywgtX5pdxbHT/singleton-the-risks-and-benefits-of-one-world-governments", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singleton%3A%20the%20risks%20and%20benefits%20of%20one%20world%20governments&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingleton%3A%20the%20risks%20and%20benefits%20of%20one%20world%20governments%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4cD4dywgtX5pdxbHT%2Fsingleton-the-risks-and-benefits-of-one-world-governments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singleton%3A%20the%20risks%20and%20benefits%20of%20one%20world%20governments%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4cD4dywgtX5pdxbHT%2Fsingleton-the-risks-and-benefits-of-one-world-governments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4cD4dywgtX5pdxbHT%2Fsingleton-the-risks-and-benefits-of-one-world-governments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3587, "htmlBody": "<p><em>Many thanks to all those whose conversations have contributed to forming these ideas.</em></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">Will the singleton save us?</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">For most of the large existential risks that we deal with here, the situation would be improved with a single world government (a <a href=\"http://www.nickbostrom.com/fut/singleton.html\">singleton</a>), or at least greater global coordination. The risk of nuclear war would fade, pandemics would be met with a comprehensive global strategy rather than a mess of national priorities. Workable regulations for the technology risks - such as synthetic biology or AI &ndash; become at least conceivable. All in all, a great improvement in safety...</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">...with one important exception. A stable tyrannical one-world government, empowered by future mass surveillance, <a href=\"http://www.nickbostrom.com/existential/risks.html\">is itself an existential risk</a> (it might not destroy humanity, but it would &ldquo;permanently and drastically curtail its potential&rdquo;). So to decide whether to oppose or advocate for more global coordination, we need to see how likely such a despotic government could be.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This is the kind of research I would love to do if I had the time to develop the relevant domain skills. In the meantime, I&rsquo;ll just take all my thoughts on the subject and form them into a &ldquo;proto-research project plan&rdquo;, in the hopes that someone could make use of them in a real research project. Please contact me if you would want to do research on this, and would fancy a chat.</span></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">Defining &ldquo;acceptable&rdquo;</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">Before we can talk about the likelihood of a good outcome, we need to define what a good outcome actually is. For this analysis, I will take the definition that:</span></p>\n<ul>\n<li><span style=\"font-family: Verdana, sans-serif;\">A singleton regime is acceptable, if it is at least as good as any developed democratic government of today.<a id=\"more\"></a><br /></span></li>\n</ul>\n<p><span style=\"font-family: Verdana, sans-serif;\">This definition can be criticised for its conservatism, or its cowardice. Shouldn&rsquo;t we be aiming to <a href=\"/lw/8zs/just_another_day_in_utopia/\">do much better</a> than what we&rsquo;re doing now? What about the inefficiency of current governments, the huge opportunity costs? Is this not a disaster in itself?</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">As should be evident from some of my <a href=\"/lw/gmx/domesticating_reduced_impact_ais/\">previous</a> <a href=\"/lw/d8z/a_small_critique_of_total_utilitarianism/\">posts</a>, I don&rsquo;t see loss of efficiency as a huge problem, and I see the push towards efficiency (<a href=\"/lw/854/satisficers_want_to_become_maximisers/\">in certain circumstances</a>) as a huge risk. Others disagree, however, which is <em>why</em> I chose the above minimalist definition. There are many different moral and ethical systems out there, each having their own preferences for ideal governments and their own impressions as to how our current governments fall short. But the vast majority would agree that a democratic singleton would be better than a despotic one. So by choosing that definition, we elide a lot of the conflict over values and can spend most of our efforts on the probability of different outcomes.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">A related problem is the usual &ldquo;be careful what you wish for&rdquo;. Many people might passionately desire a libertarian or socialist paradise, only to be ultimately disappointed when it arrives. We thus have to worry about two probabilities - the probabilities of reaching X paradise, and the probability that X paradise will actually be paradisiacal. This is strictly harder. And it should be obvious that those pushing for X paradise are the least reliable at assessing whether it will work out; so investigating of specific outcomes should preferably be performed by people who have no interest in that outcome - but these would be hard to motivate to do so! Not to mention that there is a high risk of the whole debate collapsing into well-worn, passionate, but unresolvable current political conflicts.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">It should also be noted that a democratic singleton is likely to be no more than a transitional state, before the development of AI or other radical technologies, so this need not imply a loss of efficiency over the long term. Since the long term is even less predictable, and since most ethical systems care about the long term, we have another reason to lay aside their short-term differences.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">The last reason to avoid getting more specific, is that the problem is hard enough as it is. And specific details about the future trigger a whole host of biases that make reasoning less accurate (while often making it feel more accurate). Once you&rsquo;ve got a good grasp on the odds of acceptable democratic singleton vs tyranny, <em>then</em> you can start on (X paradise) vs not-(X paradise).</span></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">The lessons of history</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">History is the most obvious and important starting point. We&rsquo;ve had many tyrannies and democracies and transitions between them, so this is a rich vein to be mined for insights. But which ones?</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">We should immediately lay aside our experience with popular revolutions: a surveillance-empowered global tyranny should be stable to such changes. But there are many changes that didn&rsquo;t involve popular revolutions.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Very relevant are examples of democracies backsliding into tyranny (the Facist/Nazi takeovers, for instance, and many examples in South America or after decolonisation), despotic regimes improving themselves from the inside (USSR and China after the deaths of Stalin and Mao, the fall of Robespierre, Glasnost), and half-democracies evolving more towards full (the USA and especially the UK during the 19<sup>th</sup> century, many post-war European regimes). The causes of internal coups and their ultimate consequences may also be worth studying.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">These are big themes, and need to be analysed systematically, not with the intent of getting a scorecard (&ldquo;5-6 - democracies lose on points!&rdquo;), but to attempt to isolate the features that cause regimes to behave in certain ways. By eyeballing the examples available to me, my initial conclusions would be that dictatorships are not very stable systems of governments (<a href=\"/lw/hin/orwell_and_fictional_evidence_for_dictatorship/\">they should not be seen as attractors</a>), that the period after a dramatic or violent transition are particularly prone for regimes to get worse, and that after the first few generations of leaders, severe turns to the bad become unlikely. The potential for continual improvements in semi-democracies seems also quite impressive, but cultural factors are important. But this is a very informal picture, in need of systematisation.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Another approach is to take current trends in modern regimes, and see if history predicts whether they would extend. Greater centralisation of power seems a universal modern feature (countries gaining more power over regions/states, supranational organisations over countries - cities seem the only small political unit that endures well), and it would be interesting to get historian&rsquo;s perspective on the reasons for this. We can also try to assess the consequences of such centralisation: does this push towards or away from a bad outcome? We have to tread carefully here, as this enters into mind-killing current political debates, but centralisation has <em>not yet</em> caused the rise of tyrannical regimes (slippery slope arguments are separate, see later). We can similarly look at many other trends that affect governmental behaviour (these would be useful inputs to the models described in a later section).</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Another important study area is surveillance, contrasting high surveillance states (like the UK) with low surveillance ones (everywhere else ;-) and estimating the magnitude and direction of the effect of such surveillance on a country&rsquo;s regime. There is a lot of value loaded studies on surveillance, though, so one should always focus on the actual consequence of surveillance, rather than predicted ones. As I recall, surveillance - so far - seems to have had very little impact, neither the feared repression, nor the promised crime reduction.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">The future is not like the past, as a wise man once tautologised, and some features of a singleton will be quite unique. The most important is that it is, indeed, single: there will be no outside opponents, no competing regimes to act as rivals or safety valves. Would we have seen the increased democratisation of Britain in the 19<sup>th</sup> century without the existence of revolutionary France? Maybe it would have gone faster - or maybe it wouldn&rsquo;t have happened at all. Would the eastern block regimes have collapsed without the mass-exodus of their populations?</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Thus another strand of research is to look at how isolated societies change. There are a few examples - Tokugawa Japan being the most obvious, but some periods in Chinese history fit as well, as well as many other examples beyond my limited experience. There were times when the heart of the Roman Empire was functionally isolated from the outside world: the empire was neither expanding nor threatened, and the Roman citizens were convinced that nothing of value or worry lay outside the boundaries of their world. Isolated villages are other case studies, with the added advantage of approximating the &ldquo;ubiquitous surveillance&rdquo; of a future singleton.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">But none of those examples fit all that well. We don&rsquo;t have any good examples of large, isolated and recent democracies, which is what we would really want. So though we can gain some insights from studying isolated societies, we should hold those insights more weakly than those gained from the previous historical studies.</span></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">Wise and biased experts</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">In fact we should hold all these insights quite weakly. History and political science are, by necessity, very uncertain disciplines. Without access to strong versions of the scientific method, they cannot give us the certainty that we&rsquo;d need. Much of the insights in the field derive from expert opinion, and so we can (and must) use <a href=\"/psycnet.apa.org/journals/amp/64/6/515/&lrm;\">all</a> <a href=\"http://www.amazon.co.uk/Sources-Power-People-Make-Decisions/dp/0262611465\">the</a> <a href=\"/ruralgrocery.com/psych/cws/pdf/obhdp_paper91.PDF&lrm;\">insights</a> that we have about the reliability of such opinion. Expert disagreement is an important feature of many of these debates; we will need to use methods that allow us to resolve such disagreements, without presuming we know more than the experts or injecting our own biases into the debate. We would certainly need to increase our uncertainty in these areas, hopefully without losing the ability to draw conclusions.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\"><a href=\"http://press.princeton.edu/titles/7959.html\">Tetlock</a> has looked specifically into the reliability of expert political insight, and has concluded that it&rsquo;s not very good (though still better than <a href=\"/lw/e36/ai_timeline_predictions_are_we_getting_better/\">AI predictions</a>). His results further decompose to show that hedgehogs (who follow a single or small collection of ideas they know intimately) perform worse than foxes (who have many different ideas they follow weakly). We should aim to be like foxes, eschewing grand historical narratives, being open to being wrong, and trying to uncover multiple independent lines of evidence for important predictions. We should also pay attention to what subdisciplines seem more reliable than others.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Part of that discipline is consciously suppressing the influence of fictional narratives that have seeped into general consciousness (such as <a href=\"/lw/hin/orwell_and_fictional_evidence_for_dictatorship/\">1984</a>). If historians are not to be trusted with their predictions, writers are even less reliable. Political narratives are problematic as well. Life is generally better today than it was forty years ago. The state is also larger, and society is less equal. The narratives that a larger state/more inequality must lead to worse outcomes are therefore not <em>self-evidently</em> true. They may be true, but require further analysis. That means that the convincing-sounding <em>arguments</em> for either position are not enough: one needs to look at the evidence (while taking into account that informed, smart people disagree with us, and that we cannot simply dismiss their views without strong reasons to do so).</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">In fact, that might be the most important part of the historical approach: not necessarily giving firm probabilities, but awakening new possibilities. The fact that surveillance dictatorships might not be attractors was a revelation to me, and completely expanded my view of the potential future. Anyone investigating this further will similarly uncover strong preconceptions they didn&rsquo;t know they had.</span></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">The Future, modelled</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">What is often elided in Tetlock&rsquo;s work is that while foxes outperformed hedgehogs, some algorithms surpassed both of them. In cases of poor expert performance, algorithms and simple models <a href=\"http://www.amazon.co.uk/Thinking-Fast-Slow-Daniel-Kahneman/dp/0141033576\">can reach</a> surprisingly good results. Any future prediction that isn&rsquo;t purely qualitative is probably going to involve models, so the mastering the use and misuse of models is important for this research.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">At one end we have simple models, that explain a lot from a little. Some examples are the supply and demand curves in microeconomics, some of the simpler macroeconomic models, Moore&rsquo;s laws, and similar. These simple models have their place, but are critically dependent on the insights that go into them: if their assumptions are questioned, they fall apart. Standard economic models are example of highly successful models with questionable assumptions, but they have a lot of empirical evidence behind them (and still people are overconfident in their use). Nothing similar exists for political science models, and it&rsquo;s unlikely that a new researcher could produce such a model that has been overlooked until now.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Another weakness of simple models is that they are often &ldquo;attractor models&rdquo;. They point to a particular state being an equilibrium of certain factors, and predict that that state will be reached. But this is less useful: there is no timeline for how long it will take to reach that state, and we expect technology to radically change human social and political conditions, before any long-term equilibrium is reached. These models might still be useful for generating ideas, though.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">In my opinion, a better approach is to decompose the problem (always a <a href=\"/lw/e46/competence_in_experts_summary/\">wise idea</a> in areas of uncertainty) and construct smaller models for each component, that can be independently calibrated on the data and then combined. This approach has weaknesses as well, the main one being that through choices of decomposition and <a href=\"http://en.wikipedia.org/wiki/Overfitting\">overfitting</a>, we can end up with a model that says anything we want it to say: it could follow the model-maker&rsquo;s prejudices rather than anything else.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">We should certainly be alive to that risk, but I don&rsquo;t think giving up in despair is the correct answer. Instead we should do it, but <em>do it right</em>. Find ways of doing the decomposition honestly, calibrating the components independently, catching errors without massaging the data. We should get honest people trying to do a good job, but more importantly, we should establish procedures before the whole project start, to try and minimise bias and maximise accuracy. This also has the advantage that we can then say &ldquo;this is why our model is unbiased&rdquo;, rather than &ldquo;trust us, we did it in an unbiased way, because we're so good&rdquo;.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Apart from prediction, we can use these models to identify important features (what components seem to have the greatest influence on the outcome), vulnerability points (what small changes can make things dramatically worse) and which assumptions are the shakiest. A key point is to identify the enabling or dampening factors around slippery slopes. Politics is full of slippery slope arguments (the <a href=\"http://en.wikipedia.org/wiki/Official_Secrets_Act\">official secrets act</a> is the first step towards tyranny! Corporate media consolidation destroys democracy!) and it is vital to know whether such slippery slopes go all the way to the end, or can be countered by other trends, derailed or reinforced by technological or social changes.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This method complements rather than contrasts with the historical approach. Models with a causal structure (&ldquo;X causes Y for these reasons&rdquo;), that fit the data acceptably, are inherently superior to non-causal models, even if they fit the data better (this is because fitting data isn&rsquo;t hard with the amount of possible curves and methods we have available, and a causal model may be able to spot a change in the underlying dynamic). The historical approach can suggest the causal structures of the models, which are then fit to the historical data. The division into <a href=\"http://en.wikipedia.org/wiki/Training_set\">training</a> and <a href=\"http://en.wikipedia.org/wiki/Test_set\">test</a> sets should be maintained here; one useful method is to fit to certain countries, and then test on other countries. This gives an estimate of the inherent uncertainty in our models, and can suggest further factors of importance to investigate (though overfitting looms at this point).</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This cross-country approach can often resolve slippery slopes, as well: there will generally be countries that have stopped sliding down any particular slope (and sometimes countries that have slid all the way down), and we can use this to figure out the dampening factors. The most important question is rarely &ldquo;does X lead to Y&rdquo;, but &ldquo;in what circumstances does X lead to Y (and are those circumstances likely in the future)?&rdquo; As mentioned before, the UK has remained politically acceptable despite the explosion of CCTV cameras. It would be important to understand why, and if this would continue in the future.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">If the conditional models are well implemented, it would also allow us to estimate the effect of specific changes, caused by technology or exogenous shocks. For instance, what would happen if most of the legal profession was replaced by functional expert systems? Hopefully, we&rsquo;d be able to give a good guess.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This is all very abstract: what kind of submodels are we talking about here? Ideally we&rsquo;d want some things that tracks the flow of power in institutions and societies, the impact of new technologies and cultural trends, the resilience of certain systems to random shocks, and so on.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">These are just a few of the ideas that sprang immediately to mind: how income distribution interacts with political freedom; what kinds of legal rights are respected or denied in practice; how regimes go into, and come out of, periods of greater repression; when regimes possess the planning abilities and incentive to act in their own long term interests; what types of pressure can change regimes when everyone knows actual revolution is impossible; whether there&rsquo;s a quantification of relative political power that is predictive of government repression; how to model the resiliency of a chaotic democracy, up until the point the resiliency breaks; how control and corruption change under centralisation; how cultural trends and habits affect political power; the interplay between the legal profession and general freedom; will increased surveillance cause more repression or more toleration of marginal lifestyles; how much tradition adds to the stability of regimes; how political systems persuade those tempted to depose them to work within them instead; and much more.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Most of these will need to be further broken into subproblems. And this should of course start with a thorough literature review; there&rsquo;s no point reinventing the wheel, even if it is the <a href=\"http://refspace.com/quotes/d:1/Douglas_Adams/wheel\">wrong colour</a>.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Scenario analysis is sometimes mentioned in predictive context, allowing deep thinking about the consequences of certain specific changes. It&rsquo;s ludicrously inept at forging a general overall picture, but it can be used to suggest new ideas and breaking out of some preconceptions. In general, though, it seems to simply focus attention on a small number of factors, and obscure what's really going on.</span></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">The danger of (talking about) obvious improvements</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">There are many features that could - obviously or contentiously - improve the behaviour of any singleton world government. Complete transparency (not simply the government spying on its people, but the other way round), American-style freedom of speech, a more federated rather than centralised system, or the private ownership of guns: all of these have been suggested as important features to reduce the chance of governments growing tyrannical.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Who could object to the idea of (almost) complete transparency, for instance? How can you trust a government that operates in secrecy? Nevertheless, the research project should probably avoid tackling any of these issues. This is partially because of the political mind-killing aspect of it; the debate would soon degenerate.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">But the main reason to avoid these problems is because arguing about them is easy (and tempting), but it is hard to show that the result of the argument is relevant at all. We are wondering if pushing for a one world singleton is worth it, comparing the existential risk reduction we&rsquo;d get to the tyranny risk we&rsquo;d incur. In that case, we should only talk about complete transparency if we&rsquo;re willing to solve a question that&rsquo;s twice are hard!</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">How so? Well, complete transparency is only relevant if we can show <em>both</em> of the following:</span></p>\n<ol>\n<li><span style=\"font-family: Verdana, sans-serif;\">The risk of a completely transparent singleton becoming tyrannical is lower than the xrisk reduction benefit we get.</span></li>\n<li><span style=\"font-family: Verdana, sans-serif;\">The risk of a non-completely transparent singleton becoming tyrannical is higher that the xrisk reduction benefit we get.</span></li>\n</ol>\n<p><span style=\"font-family: Verdana, sans-serif;\">In other words, we can easily show that A is better than B; but we&rsquo;re trying to compare both with X, and A &gt; B tells us nothing about this. Worse, the distinction between A and B is only relevant if A &gt; X &gt; B (if not, then complete transparency isn</span><span style=\"font-family: Verdana, sans-serif;\">&rsquo;</span><span style=\"font-family: Verdana, sans-serif;\">t relevant to whether we push for a singleton). Do not confuse better and worse with good and bad...</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">And to those who might be tempted to argue that a singleton government without a certain feature is intrinsically worthless, and must be opposed at all costs: there are probably democratic countries across the world that lack that feature. Is life in all those countries so intolerable that you would gladly see humanity extinguished rather than live in such a regime? And if the answer is no, then we&rsquo;re back to discussing probabilities and <a href=\"http://www.goodreads.com/quotes/300099-churchill-madam-would-you-sleep-with-me-for-five-million\">relative tradeoffs</a>.</span></p>\n<h2><span style=\"font-family: Verdana, sans-serif;\">A usual conclusion</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">As usual, more research is needed (since this is a proto-research project, the opposite would have been somewhat surprising). I&rsquo;ve laid out what I think is a reasonable plan for tackling the singleton problem: defining a minimalist standard for an acceptable outcome, start with historical analysis and moving into model-building, trying to deal with all the relevant biases along the way, and avoiding exciting contentious issues that are not relevant to the main question. The Xrisk reduction from the singleton should be assessed separately.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">But I am not a social scientist, so this approach can and should be much improved. This is the area where those of a social science bent can help! We need you in the FHI/Less Wrong community. If you or a friend of yours are in that category, I encourage you to take my preliminary plan, ruthlessly trim, expand and discard it, and make it into something workable. And then, maybe, work on it!</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">The future is unwritten to our eyes; we need to lift the veil just enough to choose the course to follow.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4cD4dywgtX5pdxbHT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 2, "extendedScore": null, "score": 1.2555817080806081e-06, "legacy": true, "legacyId": "22532", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em>Many thanks to all those whose conversations have contributed to forming these ideas.</em></p>\n<h2 id=\"Will_the_singleton_save_us_\"><span style=\"font-family: Verdana, sans-serif;\">Will the singleton save us?</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">For most of the large existential risks that we deal with here, the situation would be improved with a single world government (a <a href=\"http://www.nickbostrom.com/fut/singleton.html\">singleton</a>), or at least greater global coordination. The risk of nuclear war would fade, pandemics would be met with a comprehensive global strategy rather than a mess of national priorities. Workable regulations for the technology risks - such as synthetic biology or AI \u2013 become at least conceivable. All in all, a great improvement in safety...</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">...with one important exception. A stable tyrannical one-world government, empowered by future mass surveillance, <a href=\"http://www.nickbostrom.com/existential/risks.html\">is itself an existential risk</a> (it might not destroy humanity, but it would \u201cpermanently and drastically curtail its potential\u201d). So to decide whether to oppose or advocate for more global coordination, we need to see how likely such a despotic government could be.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This is the kind of research I would love to do if I had the time to develop the relevant domain skills. In the meantime, I\u2019ll just take all my thoughts on the subject and form them into a \u201cproto-research project plan\u201d, in the hopes that someone could make use of them in a real research project. Please contact me if you would want to do research on this, and would fancy a chat.</span></p>\n<h2 id=\"Defining__acceptable_\"><span style=\"font-family: Verdana, sans-serif;\">Defining \u201cacceptable\u201d</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">Before we can talk about the likelihood of a good outcome, we need to define what a good outcome actually is. For this analysis, I will take the definition that:</span></p>\n<ul>\n<li><span style=\"font-family: Verdana, sans-serif;\">A singleton regime is acceptable, if it is at least as good as any developed democratic government of today.<a id=\"more\"></a><br></span></li>\n</ul>\n<p><span style=\"font-family: Verdana, sans-serif;\">This definition can be criticised for its conservatism, or its cowardice. Shouldn\u2019t we be aiming to <a href=\"/lw/8zs/just_another_day_in_utopia/\">do much better</a> than what we\u2019re doing now? What about the inefficiency of current governments, the huge opportunity costs? Is this not a disaster in itself?</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">As should be evident from some of my <a href=\"/lw/gmx/domesticating_reduced_impact_ais/\">previous</a> <a href=\"/lw/d8z/a_small_critique_of_total_utilitarianism/\">posts</a>, I don\u2019t see loss of efficiency as a huge problem, and I see the push towards efficiency (<a href=\"/lw/854/satisficers_want_to_become_maximisers/\">in certain circumstances</a>) as a huge risk. Others disagree, however, which is <em>why</em> I chose the above minimalist definition. There are many different moral and ethical systems out there, each having their own preferences for ideal governments and their own impressions as to how our current governments fall short. But the vast majority would agree that a democratic singleton would be better than a despotic one. So by choosing that definition, we elide a lot of the conflict over values and can spend most of our efforts on the probability of different outcomes.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">A related problem is the usual \u201cbe careful what you wish for\u201d. Many people might passionately desire a libertarian or socialist paradise, only to be ultimately disappointed when it arrives. We thus have to worry about two probabilities - the probabilities of reaching X paradise, and the probability that X paradise will actually be paradisiacal. This is strictly harder. And it should be obvious that those pushing for X paradise are the least reliable at assessing whether it will work out; so investigating of specific outcomes should preferably be performed by people who have no interest in that outcome - but these would be hard to motivate to do so! Not to mention that there is a high risk of the whole debate collapsing into well-worn, passionate, but unresolvable current political conflicts.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">It should also be noted that a democratic singleton is likely to be no more than a transitional state, before the development of AI or other radical technologies, so this need not imply a loss of efficiency over the long term. Since the long term is even less predictable, and since most ethical systems care about the long term, we have another reason to lay aside their short-term differences.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">The last reason to avoid getting more specific, is that the problem is hard enough as it is. And specific details about the future trigger a whole host of biases that make reasoning less accurate (while often making it feel more accurate). Once you\u2019ve got a good grasp on the odds of acceptable democratic singleton vs tyranny, <em>then</em> you can start on (X paradise) vs not-(X paradise).</span></p>\n<h2 id=\"The_lessons_of_history\"><span style=\"font-family: Verdana, sans-serif;\">The lessons of history</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">History is the most obvious and important starting point. We\u2019ve had many tyrannies and democracies and transitions between them, so this is a rich vein to be mined for insights. But which ones?</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">We should immediately lay aside our experience with popular revolutions: a surveillance-empowered global tyranny should be stable to such changes. But there are many changes that didn\u2019t involve popular revolutions.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Very relevant are examples of democracies backsliding into tyranny (the Facist/Nazi takeovers, for instance, and many examples in South America or after decolonisation), despotic regimes improving themselves from the inside (USSR and China after the deaths of Stalin and Mao, the fall of Robespierre, Glasnost), and half-democracies evolving more towards full (the USA and especially the UK during the 19<sup>th</sup> century, many post-war European regimes). The causes of internal coups and their ultimate consequences may also be worth studying.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">These are big themes, and need to be analysed systematically, not with the intent of getting a scorecard (\u201c5-6 - democracies lose on points!\u201d), but to attempt to isolate the features that cause regimes to behave in certain ways. By eyeballing the examples available to me, my initial conclusions would be that dictatorships are not very stable systems of governments (<a href=\"/lw/hin/orwell_and_fictional_evidence_for_dictatorship/\">they should not be seen as attractors</a>), that the period after a dramatic or violent transition are particularly prone for regimes to get worse, and that after the first few generations of leaders, severe turns to the bad become unlikely. The potential for continual improvements in semi-democracies seems also quite impressive, but cultural factors are important. But this is a very informal picture, in need of systematisation.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Another approach is to take current trends in modern regimes, and see if history predicts whether they would extend. Greater centralisation of power seems a universal modern feature (countries gaining more power over regions/states, supranational organisations over countries - cities seem the only small political unit that endures well), and it would be interesting to get historian\u2019s perspective on the reasons for this. We can also try to assess the consequences of such centralisation: does this push towards or away from a bad outcome? We have to tread carefully here, as this enters into mind-killing current political debates, but centralisation has <em>not yet</em> caused the rise of tyrannical regimes (slippery slope arguments are separate, see later). We can similarly look at many other trends that affect governmental behaviour (these would be useful inputs to the models described in a later section).</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Another important study area is surveillance, contrasting high surveillance states (like the UK) with low surveillance ones (everywhere else ;-) and estimating the magnitude and direction of the effect of such surveillance on a country\u2019s regime. There is a lot of value loaded studies on surveillance, though, so one should always focus on the actual consequence of surveillance, rather than predicted ones. As I recall, surveillance - so far - seems to have had very little impact, neither the feared repression, nor the promised crime reduction.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">The future is not like the past, as a wise man once tautologised, and some features of a singleton will be quite unique. The most important is that it is, indeed, single: there will be no outside opponents, no competing regimes to act as rivals or safety valves. Would we have seen the increased democratisation of Britain in the 19<sup>th</sup> century without the existence of revolutionary France? Maybe it would have gone faster - or maybe it wouldn\u2019t have happened at all. Would the eastern block regimes have collapsed without the mass-exodus of their populations?</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Thus another strand of research is to look at how isolated societies change. There are a few examples - Tokugawa Japan being the most obvious, but some periods in Chinese history fit as well, as well as many other examples beyond my limited experience. There were times when the heart of the Roman Empire was functionally isolated from the outside world: the empire was neither expanding nor threatened, and the Roman citizens were convinced that nothing of value or worry lay outside the boundaries of their world. Isolated villages are other case studies, with the added advantage of approximating the \u201cubiquitous surveillance\u201d of a future singleton.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">But none of those examples fit all that well. We don\u2019t have any good examples of large, isolated and recent democracies, which is what we would really want. So though we can gain some insights from studying isolated societies, we should hold those insights more weakly than those gained from the previous historical studies.</span></p>\n<h2 id=\"Wise_and_biased_experts\"><span style=\"font-family: Verdana, sans-serif;\">Wise and biased experts</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">In fact we should hold all these insights quite weakly. History and political science are, by necessity, very uncertain disciplines. Without access to strong versions of the scientific method, they cannot give us the certainty that we\u2019d need. Much of the insights in the field derive from expert opinion, and so we can (and must) use <a href=\"/psycnet.apa.org/journals/amp/64/6/515/\u200e\">all</a> <a href=\"http://www.amazon.co.uk/Sources-Power-People-Make-Decisions/dp/0262611465\">the</a> <a href=\"/ruralgrocery.com/psych/cws/pdf/obhdp_paper91.PDF\u200e\">insights</a> that we have about the reliability of such opinion. Expert disagreement is an important feature of many of these debates; we will need to use methods that allow us to resolve such disagreements, without presuming we know more than the experts or injecting our own biases into the debate. We would certainly need to increase our uncertainty in these areas, hopefully without losing the ability to draw conclusions.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\"><a href=\"http://press.princeton.edu/titles/7959.html\">Tetlock</a> has looked specifically into the reliability of expert political insight, and has concluded that it\u2019s not very good (though still better than <a href=\"/lw/e36/ai_timeline_predictions_are_we_getting_better/\">AI predictions</a>). His results further decompose to show that hedgehogs (who follow a single or small collection of ideas they know intimately) perform worse than foxes (who have many different ideas they follow weakly). We should aim to be like foxes, eschewing grand historical narratives, being open to being wrong, and trying to uncover multiple independent lines of evidence for important predictions. We should also pay attention to what subdisciplines seem more reliable than others.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Part of that discipline is consciously suppressing the influence of fictional narratives that have seeped into general consciousness (such as <a href=\"/lw/hin/orwell_and_fictional_evidence_for_dictatorship/\">1984</a>). If historians are not to be trusted with their predictions, writers are even less reliable. Political narratives are problematic as well. Life is generally better today than it was forty years ago. The state is also larger, and society is less equal. The narratives that a larger state/more inequality must lead to worse outcomes are therefore not <em>self-evidently</em> true. They may be true, but require further analysis. That means that the convincing-sounding <em>arguments</em> for either position are not enough: one needs to look at the evidence (while taking into account that informed, smart people disagree with us, and that we cannot simply dismiss their views without strong reasons to do so).</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">In fact, that might be the most important part of the historical approach: not necessarily giving firm probabilities, but awakening new possibilities. The fact that surveillance dictatorships might not be attractors was a revelation to me, and completely expanded my view of the potential future. Anyone investigating this further will similarly uncover strong preconceptions they didn\u2019t know they had.</span></p>\n<h2 id=\"The_Future__modelled\"><span style=\"font-family: Verdana, sans-serif;\">The Future, modelled</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">What is often elided in Tetlock\u2019s work is that while foxes outperformed hedgehogs, some algorithms surpassed both of them. In cases of poor expert performance, algorithms and simple models <a href=\"http://www.amazon.co.uk/Thinking-Fast-Slow-Daniel-Kahneman/dp/0141033576\">can reach</a> surprisingly good results. Any future prediction that isn\u2019t purely qualitative is probably going to involve models, so the mastering the use and misuse of models is important for this research.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">At one end we have simple models, that explain a lot from a little. Some examples are the supply and demand curves in microeconomics, some of the simpler macroeconomic models, Moore\u2019s laws, and similar. These simple models have their place, but are critically dependent on the insights that go into them: if their assumptions are questioned, they fall apart. Standard economic models are example of highly successful models with questionable assumptions, but they have a lot of empirical evidence behind them (and still people are overconfident in their use). Nothing similar exists for political science models, and it\u2019s unlikely that a new researcher could produce such a model that has been overlooked until now.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Another weakness of simple models is that they are often \u201cattractor models\u201d. They point to a particular state being an equilibrium of certain factors, and predict that that state will be reached. But this is less useful: there is no timeline for how long it will take to reach that state, and we expect technology to radically change human social and political conditions, before any long-term equilibrium is reached. These models might still be useful for generating ideas, though.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">In my opinion, a better approach is to decompose the problem (always a <a href=\"/lw/e46/competence_in_experts_summary/\">wise idea</a> in areas of uncertainty) and construct smaller models for each component, that can be independently calibrated on the data and then combined. This approach has weaknesses as well, the main one being that through choices of decomposition and <a href=\"http://en.wikipedia.org/wiki/Overfitting\">overfitting</a>, we can end up with a model that says anything we want it to say: it could follow the model-maker\u2019s prejudices rather than anything else.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">We should certainly be alive to that risk, but I don\u2019t think giving up in despair is the correct answer. Instead we should do it, but <em>do it right</em>. Find ways of doing the decomposition honestly, calibrating the components independently, catching errors without massaging the data. We should get honest people trying to do a good job, but more importantly, we should establish procedures before the whole project start, to try and minimise bias and maximise accuracy. This also has the advantage that we can then say \u201cthis is why our model is unbiased\u201d, rather than \u201ctrust us, we did it in an unbiased way, because we're so good\u201d.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Apart from prediction, we can use these models to identify important features (what components seem to have the greatest influence on the outcome), vulnerability points (what small changes can make things dramatically worse) and which assumptions are the shakiest. A key point is to identify the enabling or dampening factors around slippery slopes. Politics is full of slippery slope arguments (the <a href=\"http://en.wikipedia.org/wiki/Official_Secrets_Act\">official secrets act</a> is the first step towards tyranny! Corporate media consolidation destroys democracy!) and it is vital to know whether such slippery slopes go all the way to the end, or can be countered by other trends, derailed or reinforced by technological or social changes.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This method complements rather than contrasts with the historical approach. Models with a causal structure (\u201cX causes Y for these reasons\u201d), that fit the data acceptably, are inherently superior to non-causal models, even if they fit the data better (this is because fitting data isn\u2019t hard with the amount of possible curves and methods we have available, and a causal model may be able to spot a change in the underlying dynamic). The historical approach can suggest the causal structures of the models, which are then fit to the historical data. The division into <a href=\"http://en.wikipedia.org/wiki/Training_set\">training</a> and <a href=\"http://en.wikipedia.org/wiki/Test_set\">test</a> sets should be maintained here; one useful method is to fit to certain countries, and then test on other countries. This gives an estimate of the inherent uncertainty in our models, and can suggest further factors of importance to investigate (though overfitting looms at this point).</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This cross-country approach can often resolve slippery slopes, as well: there will generally be countries that have stopped sliding down any particular slope (and sometimes countries that have slid all the way down), and we can use this to figure out the dampening factors. The most important question is rarely \u201cdoes X lead to Y\u201d, but \u201cin what circumstances does X lead to Y (and are those circumstances likely in the future)?\u201d As mentioned before, the UK has remained politically acceptable despite the explosion of CCTV cameras. It would be important to understand why, and if this would continue in the future.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">If the conditional models are well implemented, it would also allow us to estimate the effect of specific changes, caused by technology or exogenous shocks. For instance, what would happen if most of the legal profession was replaced by functional expert systems? Hopefully, we\u2019d be able to give a good guess.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">This is all very abstract: what kind of submodels are we talking about here? Ideally we\u2019d want some things that tracks the flow of power in institutions and societies, the impact of new technologies and cultural trends, the resilience of certain systems to random shocks, and so on.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">These are just a few of the ideas that sprang immediately to mind: how income distribution interacts with political freedom; what kinds of legal rights are respected or denied in practice; how regimes go into, and come out of, periods of greater repression; when regimes possess the planning abilities and incentive to act in their own long term interests; what types of pressure can change regimes when everyone knows actual revolution is impossible; whether there\u2019s a quantification of relative political power that is predictive of government repression; how to model the resiliency of a chaotic democracy, up until the point the resiliency breaks; how control and corruption change under centralisation; how cultural trends and habits affect political power; the interplay between the legal profession and general freedom; will increased surveillance cause more repression or more toleration of marginal lifestyles; how much tradition adds to the stability of regimes; how political systems persuade those tempted to depose them to work within them instead; and much more.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Most of these will need to be further broken into subproblems. And this should of course start with a thorough literature review; there\u2019s no point reinventing the wheel, even if it is the <a href=\"http://refspace.com/quotes/d:1/Douglas_Adams/wheel\">wrong colour</a>.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Scenario analysis is sometimes mentioned in predictive context, allowing deep thinking about the consequences of certain specific changes. It\u2019s ludicrously inept at forging a general overall picture, but it can be used to suggest new ideas and breaking out of some preconceptions. In general, though, it seems to simply focus attention on a small number of factors, and obscure what's really going on.</span></p>\n<h2 id=\"The_danger_of__talking_about__obvious_improvements\"><span style=\"font-family: Verdana, sans-serif;\">The danger of (talking about) obvious improvements</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">There are many features that could - obviously or contentiously - improve the behaviour of any singleton world government. Complete transparency (not simply the government spying on its people, but the other way round), American-style freedom of speech, a more federated rather than centralised system, or the private ownership of guns: all of these have been suggested as important features to reduce the chance of governments growing tyrannical.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">Who could object to the idea of (almost) complete transparency, for instance? How can you trust a government that operates in secrecy? Nevertheless, the research project should probably avoid tackling any of these issues. This is partially because of the political mind-killing aspect of it; the debate would soon degenerate.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">But the main reason to avoid these problems is because arguing about them is easy (and tempting), but it is hard to show that the result of the argument is relevant at all. We are wondering if pushing for a one world singleton is worth it, comparing the existential risk reduction we\u2019d get to the tyranny risk we\u2019d incur. In that case, we should only talk about complete transparency if we\u2019re willing to solve a question that\u2019s twice are hard!</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">How so? Well, complete transparency is only relevant if we can show <em>both</em> of the following:</span></p>\n<ol>\n<li><span style=\"font-family: Verdana, sans-serif;\">The risk of a completely transparent singleton becoming tyrannical is lower than the xrisk reduction benefit we get.</span></li>\n<li><span style=\"font-family: Verdana, sans-serif;\">The risk of a non-completely transparent singleton becoming tyrannical is higher that the xrisk reduction benefit we get.</span></li>\n</ol>\n<p><span style=\"font-family: Verdana, sans-serif;\">In other words, we can easily show that A is better than B; but we\u2019re trying to compare both with X, and A &gt; B tells us nothing about this. Worse, the distinction between A and B is only relevant if A &gt; X &gt; B (if not, then complete transparency isn</span><span style=\"font-family: Verdana, sans-serif;\">\u2019</span><span style=\"font-family: Verdana, sans-serif;\">t relevant to whether we push for a singleton). Do not confuse better and worse with good and bad...</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">And to those who might be tempted to argue that a singleton government without a certain feature is intrinsically worthless, and must be opposed at all costs: there are probably democratic countries across the world that lack that feature. Is life in all those countries so intolerable that you would gladly see humanity extinguished rather than live in such a regime? And if the answer is no, then we\u2019re back to discussing probabilities and <a href=\"http://www.goodreads.com/quotes/300099-churchill-madam-would-you-sleep-with-me-for-five-million\">relative tradeoffs</a>.</span></p>\n<h2 id=\"A_usual_conclusion\"><span style=\"font-family: Verdana, sans-serif;\">A usual conclusion</span></h2>\n<p><span style=\"font-family: Verdana, sans-serif;\">As usual, more research is needed (since this is a proto-research project, the opposite would have been somewhat surprising). I\u2019ve laid out what I think is a reasonable plan for tackling the singleton problem: defining a minimalist standard for an acceptable outcome, start with historical analysis and moving into model-building, trying to deal with all the relevant biases along the way, and avoiding exciting contentious issues that are not relevant to the main question. The Xrisk reduction from the singleton should be assessed separately.</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">But I am not a social scientist, so this approach can and should be much improved. This is the area where those of a social science bent can help! We need you in the FHI/Less Wrong community. If you or a friend of yours are in that category, I encourage you to take my preliminary plan, ruthlessly trim, expand and discard it, and make it into something workable. And then, maybe, work on it!</span></p>\n<p><span style=\"font-family: Verdana, sans-serif;\">The future is unwritten to our eyes; we need to lift the veil just enough to choose the course to follow.</span></p>", "sections": [{"title": "Will the singleton save us?", "anchor": "Will_the_singleton_save_us_", "level": 1}, {"title": "Defining \u201cacceptable\u201d", "anchor": "Defining__acceptable_", "level": 1}, {"title": "The lessons of history", "anchor": "The_lessons_of_history", "level": 1}, {"title": "Wise and biased experts", "anchor": "Wise_and_biased_experts", "level": 1}, {"title": "The Future, modelled", "anchor": "The_Future__modelled", "level": 1}, {"title": "The danger of (talking about) obvious improvements", "anchor": "The_danger_of__talking_about__obvious_improvements", "level": 1}, {"title": "A usual conclusion", "anchor": "A_usual_conclusion", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "27 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["sMsvcdxbK2Xqx8EHr", "FdcxknHjeNH2MzrTj", "pyTuR4ZbLfqpS2oMh", "2qCxguXuZERZNKcNi", "73GboJqDCk6nBd2py", "47ci9ixyEbGKWENwR", "yrNW4ApXrpn2KMhxr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T15:29:25.286Z", "modifiedAt": null, "url": null, "title": "New LW Meetup: Lyon", "slug": "new-lw-meetup-lyon", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:34.166Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FrankAdamek", "createdAt": "2009-07-10T09:21:16.400Z", "isAdmin": false, "displayName": "FrankAdamek"}, "userId": "u4ciX8qr47d9EiSvD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xovbarQtxZqvw9NJS/new-lw-meetup-lyon", "pageUrlRelative": "/posts/xovbarQtxZqvw9NJS/new-lw-meetup-lyon", "linkUrl": "https://www.lesswrong.com/posts/xovbarQtxZqvw9NJS/new-lw-meetup-lyon", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20LW%20Meetup%3A%20Lyon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20LW%20Meetup%3A%20Lyon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxovbarQtxZqvw9NJS%2Fnew-lw-meetup-lyon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20LW%20Meetup%3A%20Lyon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxovbarQtxZqvw9NJS%2Fnew-lw-meetup-lyon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxovbarQtxZqvw9NJS%2Fnew-lw-meetup-lyon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 559, "htmlBody": "<p><strong>This summary was posted to LW Main on June 28th. The following week's summary is <a href=\"/lw/hwl/weekly_lw_meetups/\">here</a>.</strong></p>\n<p>New meetups (or meetups with a hiatus of more than a year) are happening in:</p>\n<ul>\n<li><a href=\"/meetups/o1\">[Lyon, France] LW Meetup in Lyon:&nbsp;<span class=\"date\">03 July 2013 06:00PM</span></a></li>\n</ul>\n<p>Other irregularly scheduled Less Wrong meetups are taking place in:</p>\n<ul>\n<li><a href=\"/meetups/ns\">Brussels meetup with HEALES:&nbsp;<span class=\"date\">13 July 2013 01:00PM</span></a></li>\n<li><a href=\"/meetups/o2\">Frankfurt meetup:&nbsp;<span class=\"date\">30 June 2013 04:30PM</span></a></li>\n<li><a href=\"/meetups/o5\">Israel LW meetup:&nbsp;<span class=\"date\">04 July 2013 07:00PM</span></a></li>\n<li><a href=\"/meetups/o3\">[Moscow] The Goals We Set:&nbsp;<span class=\"date\">07 July 2013 04:00PM</span></a></li>\n<li><a href=\"/meetups/o4\">[Munich] LW Munich Meetup in July:&nbsp;<span class=\"date\">06 July 2013 03:00PM</span></a></li>\n<li><a href=\"/meetups/ny\">San Francisco: Effective Altruism:&nbsp;<span class=\"date\">28 June 2013 07:54PM</span></a></li>\n<li><a href=\"/meetups/o8\">[Vienna] LW Vienna Meetup #4:&nbsp;<span class=\"date\">13 July 2013 03:00PM</span></a></li>\n</ul>\n<p>The remaining meetups take place in cities with regular scheduling, but involve a change in time or location, special meeting content, or simply a helpful reminder about the meetup:</p>\n<ul>\n<li><a href=\"/meetups/bx\">Austin, TX:&nbsp;<span class=\"date\">29 June 2019 01:30PM</span></a></li>\n<li><a href=\"/meetups/o6\">London Practical - Sunday 7th July:&nbsp;<span class=\"date\">07 July 2013 02:00PM</span></a></li>\n<li><a href=\"/meetups/o7\">Melbourne LW Outing: Astronomy evening in Eltham, Saturday 29th June, 5:30pm:&nbsp;<span class=\"date\">29 June 2013 05:30PM</span></a></li>\n<li><a href=\"/meetups/nz\">Melbourne LW Outing: Indoor Rock Climbing, Sunday June 30th:&nbsp;<span class=\"date\">30 June 2013 02:00PM</span></a></li>\n</ul>\n<p>Locations with regularly scheduled meetups:<strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Austin.2C_TX\">Austin</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berkeley\">Berkeley</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_MA\">Cambridge, MA</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Cambridge.2C_UK\">Cambridge UK</a>,</strong><strong> </strong><strong style=\"font-weight: bold;\"><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#London.2C_UK\">London</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Madison.2C_WI\">Madison WI</a></strong>,<strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Melbourne\">Melbourne</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Tortuga_.28in_Mountain_View.29\">Mountain View</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#New_York_City.2C_NY\">New York</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ohio\">Ohio</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Salt_Lake_City.2C_UT\">Salt Lake City</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Seattle.2C_WA\">Seattle</a>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Toronto\">Toronto</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vienna.2C_Austria\">Vienna</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Waterloo\"><strong>Waterloo</strong></a>, and <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">West Los Angeles</a></strong>. There's also a <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Online_Study_Hall\">24/7 online study hall</a> for coworking LWers.<a id=\"more\"></a></p>\n<p>If you'd like to talk with other LW-ers face to face, and there is no meetup in your area, consider starting your own meetup; <a href=\"/lw/43s/starting_a_lw_meetup_is_easy\">it's easy</a> (more resources <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_group_resources\">here</a>). Check one out, stretch your rationality skills, <a href=\"/lw/dm4/berkely_visit_report/\">build community</a>, and have fun!</p>\n<p>If you missed the deadline and wish to have your meetup featured, you can reach me on gmail at frank dot c dot adamek.</p>\n<p>In addition to the handy sidebar of upcoming meetups, a meetup overview will continue to be posted on the front page every Friday. These will be an attempt to collect information on all the meetups happening in the next weeks. The best way to get your meetup featured is still to use the Add New Meetup feature, but you'll now also have the benefit of having your meetup mentioned in a weekly overview. These overview posts will be moved to the discussion section when the new post goes up.</p>\n<p>Please note that for your meetup to appear in the weekly meetups feature, you need to post your meetup&nbsp;<em>before </em>the Friday before your meetup!</p>\n<p>If you check Less Wrong irregularly, consider subscribing to one or more city-specific mailing list in order to be notified when an irregular meetup is happening: <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Atlanta.2C_GA\">Atlanta</a>,</strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Berlin.2C_Germany\"><strong>Berlin</strong></a>,<strong style=\"font-weight: bold;\"> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Chicago.2C_IL\">Chicago</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Frankfurt.2C_Germany\">Frankfurt</a>,</strong> <strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Helsinki.2C_Finland\">Helsinki</a></strong><strong>,</strong><strong style=\"font-weight: bold;\"></strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Bay_Area.2C_CA\">Marin CA</a></strong><strong>,</strong><strong> </strong><strong><a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Ottawa\">Ottawa</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Pittsburgh.2C_PA\">Pittsburgh</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Portland.2C_OR\">Portland</a>,</strong><strong> <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California.2C_CA\">Southern California (Los Angeles/Orange County area)</a>,&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#St_Louis.2C_MO\">St. Louis</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Vancouver\">Vancouver</a>, </strong><a href=\"http://wiki.lesswrong.com/wiki/Meetup#Washington.2C_DC\"><strong>Washington, DC</strong></a>.</p>\n<p>Whether or not there's currently a meetup in your area, you can <a href=\"/lw/f9p/sign_up_to_be_notified_about_new_lw_meetups_in/\"><strong>sign up</strong></a> to be notified automatically of any future meetups. And if you're not interested in notifications you can still enter your approximate location, which will let meetup-starting heroes know that there's an interested LW population in their city!</p>\n<p>If your meetup has a mailing list that you'd like mentioned here, or has become regular and isn't listed as such, let me know!</p>\n<p>Want to help out the common good? If one of the meetups listed as regular has become inactive, let me know so we can present more accurate information to newcomers.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xovbarQtxZqvw9NJS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 1.25564777262959e-06, "legacy": true, "legacyId": "23130", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3PscmtNx4xRGAfwNa", "d28mWBMrFt8nwpXLp", "xQoMYN7ZKoKTA4NqP", "97WbQTb4Etch9mDuT"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T16:32:02.143Z", "modifiedAt": null, "url": null, "title": "Beeminding Sin", "slug": "beeminding-sin", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:59.126Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "f5v8QJsBuPMFKFqt7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/C72RP4QzLFQcMApgS/beeminding-sin", "pageUrlRelative": "/posts/C72RP4QzLFQcMApgS/beeminding-sin", "linkUrl": "https://www.lesswrong.com/posts/C72RP4QzLFQcMApgS/beeminding-sin", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Beeminding%20Sin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABeeminding%20Sin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC72RP4QzLFQcMApgS%2Fbeeminding-sin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Beeminding%20Sin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC72RP4QzLFQcMApgS%2Fbeeminding-sin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FC72RP4QzLFQcMApgS%2Fbeeminding-sin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 553, "htmlBody": "<p>(This is something that I originally posted to the CFAR Alumni list, and then fleshed out a bit and posted to the <a href=\"http://blog.beeminder.com/sin/\">Beeminder blog</a>. It has been well received and there have been suggestions that I post it here, so here it is.)</p>\n<p>For a long time I found that I was spending too much time on certain unproductive things and struggled with getting myself to do what I actually wanted to do with my time. The big break came one morning when I noticed that there was a very tight correlation between the things I wanted to stop doing and the traditional Christian concept of Sin.</p>\n<p>Once I noticed this, I went straight to the Wikipedia page for the <a href=\"https://en.wikipedia.org/wiki/Seven_deadly_sins\">Seven Deadly Sins</a>, and mapped them onto my own vices:</p>\n<p><strong>Lust</strong>: Porn, flirting, etc.</p>\n<p><strong>Gluttony</strong>: Junk food like cookies and chocolate.  I might add \"more than two bowls of spaghetti\" here; the stuff is just too easy to eat.</p>\n<p><strong>Sloth</strong>: Wasting time on stuff that isn't goal directed or self-improving. Being non-industrious. Failing to strive. Useless news/discussion websites, etc.</p>\n<p><strong>Wrath</strong>: Acting irrationally out of anger, pain, or frustration.  Chewing someone out, violence, slamming doors, etc.</p>\n<p><strong>Envy</strong>: Not reading, using, or appreciating someone else's work because solving a problem is caught up in my identity.</p>\n<p>I'm too much of a cheapskate to have trouble with material excess (<strong>Greed</strong>), and haven't been burned by <strong>Pride</strong> yet, so I wouldn't know what to avoid.  Maybe I'll figure these out soon.</p>\n<p>The nice thing about traditional concepts like Sin is that they come bundled with some guarantees of relative completeness for very little cognitive investment on my part. Someone has tested and developed this thing very extensively; even if it's not perfect, all I have to do is use it.  Further, concepts like Sin come with a rich aesthetic heritage that lends them some emotional weight and solidness that fresh concepts just don't have.  A culture that's been going for &gt;1500 years will leave behind some impressive artifacts.  We would be fools not to take advantage of them.</p>\n<p>While I figured all of this out, I had also been looking for a way to beemind my way out of these harmful behaviors.  I'd considered a number of schemes, but none were satisfactory. Armed with the concept of Sin, I had a comprehensive and reasonably clear-cut list of things to avoid. When I read how <a href=\"http://blog.beeminder.com/box/\">Bethany beeminds sugar-free days</a>, I knew exactly what I had to do.</p>\n<p>How it works is this: if I do something that I judge to be sinful, I <em>don't</em> get to report a Sin-Free Day to Beeminder, otherwise, I do.  I need 5 Sin-Free Days per week. Simple as that, and Sin is gone.  It's glorious.</p>\n<p>At work, we joke that the accountants are trying to kill us. They leave donuts and chocolate and cookies out for everyone, and we eat them, whether we like it or not. Well not anymore; it's just not worth it to eat that cookie when it means that I immediately fail the whole day, so I don't. The only reason I didn't eat like 20 tasty cookies today is because I beemind Sin.</p>\n<p>The traditional solution to akrasia and especially Sin is Willpower and self-loathing. As an akratic, I don't have Magical Free Will, but I don't have to hate myself either, because I have the next best thing: Beeminder!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "C72RP4QzLFQcMApgS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 21, "extendedScore": null, "score": 5e-05, "legacy": true, "legacyId": "23206", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 21, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T19:20:39.493Z", "modifiedAt": null, "url": null, "title": "Free ebook: Extraordinary Popular Delusions and the Madness of Crowds", "slug": "free-ebook-extraordinary-popular-delusions-and-the-madness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:36.327Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HkAxGsMe8gaFXXThf/free-ebook-extraordinary-popular-delusions-and-the-madness", "pageUrlRelative": "/posts/HkAxGsMe8gaFXXThf/free-ebook-extraordinary-popular-delusions-and-the-madness", "linkUrl": "https://www.lesswrong.com/posts/HkAxGsMe8gaFXXThf/free-ebook-extraordinary-popular-delusions-and-the-madness", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Free%20ebook%3A%20Extraordinary%20Popular%20Delusions%20and%20the%20Madness%20of%20Crowds&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFree%20ebook%3A%20Extraordinary%20Popular%20Delusions%20and%20the%20Madness%20of%20Crowds%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHkAxGsMe8gaFXXThf%2Ffree-ebook-extraordinary-popular-delusions-and-the-madness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Free%20ebook%3A%20Extraordinary%20Popular%20Delusions%20and%20the%20Madness%20of%20Crowds%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHkAxGsMe8gaFXXThf%2Ffree-ebook-extraordinary-popular-delusions-and-the-madness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHkAxGsMe8gaFXXThf%2Ffree-ebook-extraordinary-popular-delusions-and-the-madness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 37, "htmlBody": "<p>I don't know if this book is any good, but today, it's free:&nbsp;<a href=\"http://www.amazon.com/Extraordinary-Popular-Delusions-Illustrated-ebook/dp/B003I84MBO/\">Extraordinary Popular Delusions and the Madness of Crowds</a>. Some comments in the reviews indicate that this is only a small portion of the complete book.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HkAxGsMe8gaFXXThf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 1, "extendedScore": null, "score": 1.255829508179509e-06, "legacy": true, "legacyId": "23207", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T19:33:22.100Z", "modifiedAt": null, "url": null, "title": "[HPMOR][Possible Spoilers] Gedankenexperiment: Time Turner Meta-Informational Relativity", "slug": "hpmor-possible-spoilers-gedankenexperiment-time-turner-meta", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:09.296Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "stcredzero", "createdAt": "2009-04-21T15:21:47.268Z", "isAdmin": false, "displayName": "stcredzero"}, "userId": "Kmyowz5JmKN6oPpca", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/92JSuLFXmJdXj5rtK/hpmor-possible-spoilers-gedankenexperiment-time-turner-meta", "pageUrlRelative": "/posts/92JSuLFXmJdXj5rtK/hpmor-possible-spoilers-gedankenexperiment-time-turner-meta", "linkUrl": "https://www.lesswrong.com/posts/92JSuLFXmJdXj5rtK/hpmor-possible-spoilers-gedankenexperiment-time-turner-meta", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BHPMOR%5D%5BPossible%20Spoilers%5D%20Gedankenexperiment%3A%20Time%20Turner%20Meta-Informational%20Relativity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BHPMOR%5D%5BPossible%20Spoilers%5D%20Gedankenexperiment%3A%20Time%20Turner%20Meta-Informational%20Relativity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F92JSuLFXmJdXj5rtK%2Fhpmor-possible-spoilers-gedankenexperiment-time-turner-meta%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BHPMOR%5D%5BPossible%20Spoilers%5D%20Gedankenexperiment%3A%20Time%20Turner%20Meta-Informational%20Relativity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F92JSuLFXmJdXj5rtK%2Fhpmor-possible-spoilers-gedankenexperiment-time-turner-meta", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F92JSuLFXmJdXj5rtK%2Fhpmor-possible-spoilers-gedankenexperiment-time-turner-meta", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 608, "htmlBody": "<p>Some people have been asking the question about the 6-hour limit on time turners in <em>Harry Potter and the Methods of Rationality</em>. &nbsp;Apparently, if a character, let's say it's Amelia Bones, goes back in time N hours and relays a piece of information about the future to another character, say Dumbledore, then Dumbledore cannot go back in time more than (6-N) hours.</p>\n<p>The 6 hour limit is a useful rule to keep the HPMOR universe from becoming over-complicated with time travel, however several people have brought up the following objection. The claim is that Amelia Bones, by traveling back in time and saying that she has information she hasn't yet revealed, has already revealed information about the future in the form of Metadata: That the future still exists N hours in the future and that Amelia Bones was in it, etc. I will show, however, that this is not the case.&nbsp;</p>\n<p>Imagine that Amelia Bones has traveled back in time from 1 hour in the future, but she is confused about the time after having apparated across time zones and mistakenly tells Dumbledore that she has information for him from 4 hours in the future. Call this Scenario A. Now imagine that the same scenario happens, but that Amelia is not mistaken about the time. Call that Scenario B.&nbsp;</p>\n<p>The thing to note here, is that, from the informational point of view of Dumbledore, provided he doesn't have some additional side-channel information, Scenario A and Scenario B are <em>indistinguishable</em>. (In the same sense that being in an accelerating room is indistinguishable from being in a gravity field in General Relativity.) This is what I mean by \"time turner meta-informational relativity.\" Provided that the act of arriving at some time and place with a time turner doesn't itself leak information about how far in the future you arrived from, meta-information about the future is not the same as information. The time-space coordinate meta-information conveyed when Amelia Bones tells Dumbledore, \"I used a Time Turner and I have information about the future,\" is smeared out over the possible 6 hours. This tells us that meta-information cannot be the same as particular information about the future.&nbsp;</p>\n<p>Additional consequence: From this, we can hypothesize that *any* time-indeterminate information conveyed to the past will be \"smeared out\" over the possible range of times, and that further backwards-time travel is limited by the closest possible value. So, if Amelia came from 3 hours in the future and related a piece of information that leaves it ambiguous if she came from 1 to 5 hours in the future, Dumbledore should still be able to travel 5 hours into the past -- provided he is not also in possession of information that lets him narrow Amelia's possible departure time.&nbsp;</p>\n<p>Additional additional consequence: given the above is true, time turners can be used to empirically expose one's possession of such side information. I can imagine this being used for some clever deductive feat.&nbsp;</p>\n<p>EDIT: To address some confusion about indistinguishability: 1) This is in the context of a specific point in space-time. 2) A given piece of information can only distinguish Scenario A and Scenario B if it's plausibly consistent with Scenario A but not Scenario B, or vice versa. So the paths of single neutrinos or configurations of air molecules aren't going to be able to do this. However, if there was a leak in a canister of a gas (let's say helium) at the time of Scenario A (4 hours in the future) but not at Scenario B's time, then there would be additional data available in the form of an implausibly large number of helium atoms in Amelia Bone's clothes.&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "92JSuLFXmJdXj5rtK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 2, "extendedScore": null, "score": 1.2558394987599165e-06, "legacy": true, "legacyId": "23208", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-05T22:14:17.907Z", "modifiedAt": null, "url": null, "title": "Personal Library Management", "slug": "personal-library-management", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:37.479Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ritalin", "createdAt": "2012-05-01T18:00:25.863Z", "isAdmin": false, "displayName": "Ritalin"}, "userId": "ACGKS9W7iQQywxrWW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RuYmvK7Z9rq6xzJo5/personal-library-management", "pageUrlRelative": "/posts/RuYmvK7Z9rq6xzJo5/personal-library-management", "linkUrl": "https://www.lesswrong.com/posts/RuYmvK7Z9rq6xzJo5/personal-library-management", "postedAtFormatted": "Friday, July 5th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Personal%20Library%20Management&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APersonal%20Library%20Management%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRuYmvK7Z9rq6xzJo5%2Fpersonal-library-management%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Personal%20Library%20Management%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRuYmvK7Z9rq6xzJo5%2Fpersonal-library-management", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRuYmvK7Z9rq6xzJo5%2Fpersonal-library-management", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 241, "htmlBody": "<p>I've just finished my finals, and, after six years of college, I am faced with this fact: I have accumulated one heck of a lot of books, most of which I haven't read yet.</p>\n<p>An app, or at the very least an algorythm, on how to manage them, make a reading list, and go about reading them, is something I really wish for, but I have no idea how to approach this problem in a time-efficient, productive way, and I wouldn't want to reinvent the wheel.</p>\n<p>Do any of you have the same problem? What are your solutions?</p>\n<p>The main post will be gradually updated and amended as the discussion progresses.</p>\n<p>EDIT: For Mac Users, it appears that <a href=\"http://www.libib.com/\">Delicious Library</a> is a great solution. While looking for <a href=\"http://alternativeto.net/software/delicious-library/\">alternatives</a>, I found this web app, <a href=\"http://www.libib.com/\">libib</a>, which seems very promising.</p>\n<p>EDIT 2: I've spent most of the day cataloguing all of my stuff on libib, which is incredibly efficient... as long as the ISBN is readily-recognized. This doesn't work so well with rarer books and older books, but they're a small enough minority that I can delcare a <strong>smashing success</strong>.</p>\n<ol>\n<li>Step 1 was making a list of all available books. </li>\n<li>Step 2 is going to be applying the Universal Decimal System, </li>\n<li>Step 3 will be Establishing a </li>\n</ol>\n<blockquote>\n<ul>\n<li>Reading List and a</li>\n<li>List of What's Already Read and a</li>\n<li>List of What Will Probably Never Be Read</li>\n</ul>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RuYmvK7Z9rq6xzJo5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 10, "extendedScore": null, "score": 2.3e-05, "legacy": true, "legacyId": "23209", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-06T03:02:36.426Z", "modifiedAt": null, "url": null, "title": "Harry Potter and the Methods of Rationality discussion thread, part 22, chapter 93", "slug": "harry-potter-and-the-methods-of-rationality-discussion-26", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:01.055Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "daenerys", "createdAt": "2011-11-08T02:18:14.528Z", "isAdmin": false, "displayName": "daenerys"}, "userId": "KWkCEqaju3xRPA2ka", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/smKK6yrKBehxvQq5i/harry-potter-and-the-methods-of-rationality-discussion-26", "pageUrlRelative": "/posts/smKK6yrKBehxvQq5i/harry-potter-and-the-methods-of-rationality-discussion-26", "linkUrl": "https://www.lesswrong.com/posts/smKK6yrKBehxvQq5i/harry-potter-and-the-methods-of-rationality-discussion-26", "postedAtFormatted": "Saturday, July 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2022%2C%20chapter%2093&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2022%2C%20chapter%2093%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsmKK6yrKBehxvQq5i%2Fharry-potter-and-the-methods-of-rationality-discussion-26%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2022%2C%20chapter%2093%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsmKK6yrKBehxvQq5i%2Fharry-potter-and-the-methods-of-rationality-discussion-26", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsmKK6yrKBehxvQq5i%2Fharry-potter-and-the-methods-of-rationality-discussion-26", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 231, "htmlBody": "<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">This is a new thread to discuss Eliezer Yudkowsky&rsquo;s&nbsp;<em><a style=\"color: #8a8a8b;\" href=\"http://www.fanfiction.net/s/5782108/1/\">Harry Potter and the Methods of Rationality</a></em>&nbsp;and anything related to it. This thread is intended for discussing&nbsp;<a href=\"http://hpmor.com/chapter/93\">chapter 93</a>. <a href=\"/r/discussion/lw/hwf/harry_potter_and_the_methods_of_rationality/\">The previous thread&nbsp;</a>has passed 300 comments.&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">There is now a site dedicated to the story at&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/\">hpmor.com</a>, which is now the place to go to find the&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://hpmor.com/notes/\">authors notes</a>&nbsp;and all sorts of other goodies. AdeleneDawner has kept an&nbsp;<a style=\"color: #8a8a8b;\" href=\"http://www.evernote.com/pub/adelenedawner/Eliezer\">archive of Author&rsquo;s Notes</a>. (This goes up to the notes for chapter 76, and is now not updating. The authors notes from chapter 77 onwards are on hpmor.com.)&nbsp;</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">The first 5 discussion threads are on the main page under the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/tag/harry_potter/\">harry_potter tag</a>.&nbsp; Threads 6 and on (including this one) are in the&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/tag/harry_potter/\">discussion section</a>&nbsp;using its separate tag system.&nbsp; Also:&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2ab/harry_potter_and_the_methods_of_rationality\">1</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2ie/harry_potter_and_the_methods_of_rationality\">2</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2nm/harry_potter_and_the_methods_of_rationality\">3</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality\">4</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/30g/harry_potter_and_the_methods_of_rationality\">5</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/364/harry_potter_and_the_methods_of_rationality/\">6</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/3rb/harry_potter_and_the_methods_of_rationality/\">7</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/797/harry_potter_and_the_methods_of_rationality/\">8</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/7jd/harry_potter_and_the_methods_of_rationality\">9</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/ams/harry_potter_and_the_methods_of_rationality\">10</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/axe/harry_potter_and_the_methods_of_rationality/\">11</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/b5s/harry_potter_and_the_methods_of_rationality/\">12</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/b7s/harry_potter_and_the_methods_of_rationality/\">13</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bfo/harry_potter_and_the_methods_of_rationality/\">14</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bmx/harry_potter_and_the_methods_of_rationality/\">15</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/bto/harry_potter_and_the_methods_of_rationality/\">16</a>,&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/fyv/harry_potter_and_the_methods_of_rationality/\">17</a>,<a style=\"color: #8a8a8b;\" href=\"/lw/g1q/harry_potter_and_the_methods_of_rationality/\">18</a>,<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/huq/harry_potter_and_the_methods_of_rationality/\">19</a>,<a style=\"color: #8a8a8b;\" href=\"/r/discussion/lw/hvg/harry_potter_and_the_methods_of_rationality/\">20</a>.</p>\n<p style=\"margin: 0px 0px 1em; font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\"><strong>Spoiler Warning</strong>: this thread is full of spoilers. With few exceptions, spoilers for MOR and canon are fair game to post, without warning or rot13.&nbsp;<a style=\"color: #8a8a8b;\" href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality/2v1l\">More specifically</a>:</p>\n<blockquote style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px; text-align: justify;\">\n<p style=\"margin: 0px 0px 1em;\">You do not need to rot13 anything about HP:MoR or the original Harry Potter series unless you are posting insider information from Eliezer Yudkowsky which is not supposed to be publicly available (which includes public statements by Eliezer that have been retracted).</p>\n<p style=\"margin: 0px 0px 1em;\">If there is evidence for X in MOR and/or canon then it&rsquo;s fine to post about X without rot13, even if you also have heard privately from Eliezer that X is true. But you should not post that &ldquo;Eliezer said X is true&rdquo; unless you use rot13.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yrg267i4a8EsgYAXp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "smKK6yrKBehxvQq5i", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "23212", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 354, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CcnpbKuRaYMjpFmQq", "59rDBidWmmJTXL4Np", "xexS9nyzwRgP9sowp", "LzQcmBwAJBGyzrt6Z", "qKzeJvFWyPh5H2hwj", "nnnd4KRQxs6DYcehD", "y2Hszb4Dsm5FggnDC", "6ae2kq3JmKvL4YPgk", "zvXfBqp6TSriNkmbg", "WQ7XMjqvuRRj8nkpu", "LKFR5pBA3bBkERDxL", "8yEdpDpGgvDWHeodM", "K4JBpAxhvstdnNbeg", "xK6Pswbozev6pv4A6", "pBTcCB5uJTzADdMm4", "XN4WDRSPFo9iGEuk3", "QkhX5YeuYHzPW7Waz", "4sY9rqAqty8rHWGSW", "35GjH7tDvNJWSHQ3H", "Pxiu5SG8gjhCh2jYd", "CEd85FLRbQWsbkrmf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-06T15:05:47.350Z", "modifiedAt": null, "url": null, "title": "What's the name of this cognitive bias?", "slug": "what-s-the-name-of-this-cognitive-bias", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:57.524Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pete22", "createdAt": "2009-12-11T18:29:15.161Z", "isAdmin": false, "displayName": "pete22"}, "userId": "Evr4w9zQbxZJ8dnza", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7Dnnc4RMS5ctGBJNM/what-s-the-name-of-this-cognitive-bias", "pageUrlRelative": "/posts/7Dnnc4RMS5ctGBJNM/what-s-the-name-of-this-cognitive-bias", "linkUrl": "https://www.lesswrong.com/posts/7Dnnc4RMS5ctGBJNM/what-s-the-name-of-this-cognitive-bias", "postedAtFormatted": "Saturday, July 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What's%20the%20name%20of%20this%20cognitive%20bias%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat's%20the%20name%20of%20this%20cognitive%20bias%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Dnnc4RMS5ctGBJNM%2Fwhat-s-the-name-of-this-cognitive-bias%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What's%20the%20name%20of%20this%20cognitive%20bias%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Dnnc4RMS5ctGBJNM%2Fwhat-s-the-name-of-this-cognitive-bias", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Dnnc4RMS5ctGBJNM%2Fwhat-s-the-name-of-this-cognitive-bias", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 126, "htmlBody": "<p>Picture a circular road on a map. Let's say that my office is at twelve o'clock, my home is at five o'clock, and the post office is at three o'clock.</p>\n<p>Now, suppose I have to leave work, pick up a document at home, and take it to the post office to mail it. I know it's faster to walk clockwise home, passing the post office, and then return to it with the letter. But my gut preference is to go counterclockwise, either because of an aversion to retracing my steps, or because that route just ... feels \"cleaner\" or more efficient somehow, or ... I can't articulate it any better than that.</p>\n<p>Does anyone else share this intuition? Is it a manifestation of one or more known/studied effects?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7Dnnc4RMS5ctGBJNM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 14, "extendedScore": null, "score": 1.2567616671387486e-06, "legacy": true, "legacyId": "23221", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-06T16:01:20.723Z", "modifiedAt": null, "url": null, "title": "Prioritizing Happiness", "slug": "prioritizing-happiness", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:39.019Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jkaufman", "createdAt": "2010-11-04T21:42:19.863Z", "isAdmin": false, "displayName": "jefftk"}, "userId": "TtEoCrFeowCGb6rFK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/boP3Ae59AHhao8aPk/prioritizing-happiness", "pageUrlRelative": "/posts/boP3Ae59AHhao8aPk/prioritizing-happiness", "linkUrl": "https://www.lesswrong.com/posts/boP3Ae59AHhao8aPk/prioritizing-happiness", "postedAtFormatted": "Saturday, July 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Prioritizing%20Happiness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrioritizing%20Happiness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FboP3Ae59AHhao8aPk%2Fprioritizing-happiness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Prioritizing%20Happiness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FboP3Ae59AHhao8aPk%2Fprioritizing-happiness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FboP3Ae59AHhao8aPk%2Fprioritizing-happiness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 217, "htmlBody": "<p>When the limiting resource is money it's quite clear that we should prioritize the uses where it goes the farthest. If there are three organizations that can distribute antimalarial nets for $5/each, $50/each, and $500/each we should just give to the first one. Similarly, if I have $5 I could use it to have my electricity be generated by wind or I could use it to fund distribution of an additional antimalarial net. I can't spend that $5 on both, so I <a href=\"http://blog.givewell.org/2009/11/19/denying-the-choice/\">have to choose</a>, and I choose based on which I think will <a href=\"/lw/3gj/efficient_charity_do_unto_others/\">do more good with the money</a>.</p>\n<p>When the limiting resource is happiness, however, prioritization comes less naturally.   I could stop taking warm showers, take the bus instead of driving, <a href=\"http://www.jefftk.com/news/2010-07-06\">spend less</a> to donate more, go vegan, <a href=\"/lw/d4v\">donate a kidney</a>, not run fans in summer, or do any of a very large number of things to <a href=\"http://www.jefftk.com/news/2011-11-13\">make the world better at some cost to me</a>.  The more I do, the better, but the less happy I am.  If I chose options without looking at how they <a href=\"/lw/d97\">trade off my happiness against benefit to others</a> it would be like choosing what clothes to buy based on how much I would enjoy wearing them and not considering how much they cost.</p>\n<p><small><em>I also posted this <a href=\"http://www.jefftk.com/news/2013-07-06\">on my blog</a></em></small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "boP3Ae59AHhao8aPk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 0, "extendedScore": null, "score": 1.2568053946455762e-06, "legacy": true, "legacyId": "23222", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["pC47ZTsPNAkjavkXs", "wzdjAmeoPRmBE8v8o", "xjufPJmEsN7d9dmkf"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-06T19:56:54.641Z", "modifiedAt": null, "url": null, "title": "Optimizing Workouts for Intellectual Performance", "slug": "optimizing-workouts-for-intellectual-performance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:33.146Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ritalin", "createdAt": "2012-05-01T18:00:25.863Z", "isAdmin": false, "displayName": "Ritalin"}, "userId": "ACGKS9W7iQQywxrWW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CLZs22gNSxtcJo7a5/optimizing-workouts-for-intellectual-performance", "pageUrlRelative": "/posts/CLZs22gNSxtcJo7a5/optimizing-workouts-for-intellectual-performance", "linkUrl": "https://www.lesswrong.com/posts/CLZs22gNSxtcJo7a5/optimizing-workouts-for-intellectual-performance", "postedAtFormatted": "Saturday, July 6th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Optimizing%20Workouts%20for%20Intellectual%20Performance&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOptimizing%20Workouts%20for%20Intellectual%20Performance%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCLZs22gNSxtcJo7a5%2Foptimizing-workouts-for-intellectual-performance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Optimizing%20Workouts%20for%20Intellectual%20Performance%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCLZs22gNSxtcJo7a5%2Foptimizing-workouts-for-intellectual-performance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCLZs22gNSxtcJo7a5%2Foptimizing-workouts-for-intellectual-performance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 481, "htmlBody": "<p>So this year I've stopped working out, and my grades have improved drastically, but at the cost of losing muscle mass and gaining fat, and becoming physically slower and lazier just as I became faster and more active intellectually. One effect I especially noticed was the disappearance of <a title=\"Swarzenegger Cums All The Time\" href=\"http://www.youtube.com/watch?v=8sHvWYAzIRo\">that perpetual state of happiness/satisfaction</a> that comes from frequent physical exertion, which I think had a tendency to get in the way of a feeling of urgency regarding studies; why bother with tiresome and frustrating intellectual exercise when physical exercise yielded results and pleasure/satisfaction much more easily and reliably?</p>\n<p>Anyway, this got me thinking: \"I need to figure out a training that is optimized for intellectual performance. Aspects that might be interesting to work on would be:</p>\n<ul>\n<li>getting as much blood (oxygen, nutrients) as possible to the brain, whenever needed.</li>\n<li>minimizing the amount of other tissue (including muscle in excess of what is strictly needed for a comfortable daily life, and digestive organs in excess of what is needed to get the nutrients from the food).</li>\n<li>optimizing the diet in order to feed the brain according to its needs while avoiding dietetical imbalances that would result in damage of some sort or another (too much sugar can damage the pancreas, too much protein and the kidneys can suffer, etc.)</li>\n<li>something that is easy and quick to implement and follow, relatively inexpensive and straightforward; the idea is to save as much time, resources and energy as possible for the needs of studying/working.</li>\n</ul>\n<p>These ideas I'm throwing around from a position of extreme ignorance. I've tried hiring nutritionists, but their diets were optimized for bodybuilding, not for intellectual efficacy, and were incredibly troublesome to follow. These involved about five to eight meals a day, large amounts of meat or meat substitutes, which is <em>expensive</em> to sustain, and me in a perpetual state of either hunger or digestive lethargy, plus permanent muscular soreness from the training regime that goes with it... and then there's the <em>supplements</em>.</p>\n<p>So, yeah, I'm no gwern, but I'd love to figure out a diet that allows me to work at maximum efficacy. Other concerns, such as feeling strong or looking attractive or even dancing well, are quite far behind in priority. How should I go about this? How about you lads and ladies? What's your experience with dieting/working-out? More importantly, what does the research say?</p>\n<p>P.S. I tried to read \"Good Calories Bad Calories\", but I never managed to finish it: it spent so much time attacking the current paradygm that I grew tired of waiting for it to actually list and summarize its recommendations. If anyone here finished reading that and drew out the conclusions, I'd love to hear them.</p>\n<p>P.P.S. The main post will update as the discussion advances; once enough <em>proper</em> information is gathered, a top level post might emerge.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CLZs22gNSxtcJo7a5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 16, "extendedScore": null, "score": 1.2569908346751359e-06, "legacy": true, "legacyId": "23223", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-07T08:08:40.580Z", "modifiedAt": null, "url": null, "title": "Meetup : Helsinki LW meetup", "slug": "meetup-helsinki-lw-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:29.090Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "morrel", "createdAt": "2013-07-04T17:36:44.083Z", "isAdmin": false, "displayName": "morrel"}, "userId": "Xdtoje5pFmqC2CY6y", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2JEert5zDuGvgCyy4/meetup-helsinki-lw-meetup", "pageUrlRelative": "/posts/2JEert5zDuGvgCyy4/meetup-helsinki-lw-meetup", "linkUrl": "https://www.lesswrong.com/posts/2JEert5zDuGvgCyy4/meetup-helsinki-lw-meetup", "postedAtFormatted": "Sunday, July 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Helsinki%20LW%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Helsinki%20LW%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JEert5zDuGvgCyy4%2Fmeetup-helsinki-lw-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Helsinki%20LW%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JEert5zDuGvgCyy4%2Fmeetup-helsinki-lw-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2JEert5zDuGvgCyy4%2Fmeetup-helsinki-lw-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 129, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/oe'>Helsinki LW meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">20 July 2013 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Hakasalmenpuisto</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We\u2019re having a meetup! Thanks to Kaj and Cat for organizing the previous meetup, where we had more than a dozen people. This time we\u2019ll have a less formal meetup to get to know each other better, and to plan future meetups. We\u2019ll also have a good chance to practice applied rationality, as one LWer has volunteered to let us help in deciding the direction of his studies.</p>\n\n<p>To find us, look for someone wearing a pink elephant hat. We\u2019ll be sitting in the park between the Opera house and Finlandia hall. If it rains, we\u2019ll meet in Kaisla. You can also join our <a href=\"https://www.facebook.com/groups/404894356287927/\" rel=\"nofollow\">Facebook group</a>.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/oe'>Helsinki LW meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2JEert5zDuGvgCyy4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2575671989223709e-06, "legacy": true, "legacyId": "23225", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Helsinki_LW_meetup\">Discussion article for the meetup : <a href=\"/meetups/oe\">Helsinki LW meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">20 July 2013 02:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Hakasalmenpuisto</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>We\u2019re having a meetup! Thanks to Kaj and Cat for organizing the previous meetup, where we had more than a dozen people. This time we\u2019ll have a less formal meetup to get to know each other better, and to plan future meetups. We\u2019ll also have a good chance to practice applied rationality, as one LWer has volunteered to let us help in deciding the direction of his studies.</p>\n\n<p>To find us, look for someone wearing a pink elephant hat. We\u2019ll be sitting in the park between the Opera house and Finlandia hall. If it rains, we\u2019ll meet in Kaisla. You can also join our <a href=\"https://www.facebook.com/groups/404894356287927/\" rel=\"nofollow\">Facebook group</a>.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Helsinki_LW_meetup1\">Discussion article for the meetup : <a href=\"/meetups/oe\">Helsinki LW meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Helsinki LW meetup", "anchor": "Discussion_article_for_the_meetup___Helsinki_LW_meetup", "level": 1}, {"title": "Discussion article for the meetup : Helsinki LW meetup", "anchor": "Discussion_article_for_the_meetup___Helsinki_LW_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "9 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-07T09:53:38.749Z", "modifiedAt": null, "url": null, "title": "On-line conference for LW readers and meet up members", "slug": "on-line-conference-for-lw-readers-and-meet-up-members", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:02.947Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KC8PymMeZbayfpg4P/on-line-conference-for-lw-readers-and-meet-up-members", "pageUrlRelative": "/posts/KC8PymMeZbayfpg4P/on-line-conference-for-lw-readers-and-meet-up-members", "linkUrl": "https://www.lesswrong.com/posts/KC8PymMeZbayfpg4P/on-line-conference-for-lw-readers-and-meet-up-members", "postedAtFormatted": "Sunday, July 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On-line%20conference%20for%20LW%20readers%20and%20meet%20up%20members&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn-line%20conference%20for%20LW%20readers%20and%20meet%20up%20members%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKC8PymMeZbayfpg4P%2Fon-line-conference-for-lw-readers-and-meet-up-members%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On-line%20conference%20for%20LW%20readers%20and%20meet%20up%20members%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKC8PymMeZbayfpg4P%2Fon-line-conference-for-lw-readers-and-meet-up-members", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKC8PymMeZbayfpg4P%2Fon-line-conference-for-lw-readers-and-meet-up-members", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 108, "htmlBody": "<p>I would like to consolidate LW members in a new way. I believe we can organize an on-line gathering in some form, for example as a set of chat rooms to discuss different topics in the real time. This event can be announced in advance to help everyone to arrange plans. I hope the discussion can be more intense and productive than in chats that open for prolonged periods of time. And comparing to the lesswrong.com this event should give some feeling of a real conversation, which I can not get while posting articles and comments here.</p>\n<p>If you have any additions, ideas and proposals please let me know.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KC8PymMeZbayfpg4P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 1.2576499148873202e-06, "legacy": true, "legacyId": "23226", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-07T18:27:39.809Z", "modifiedAt": null, "url": null, "title": "A Gamification Of Education: a modest proposal based on the Universal Decimal Classification  and RPG skill trees", "slug": "a-gamification-of-education-a-modest-proposal-based-on-the", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:06.457Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ritalin", "createdAt": "2012-05-01T18:00:25.863Z", "isAdmin": false, "displayName": "Ritalin"}, "userId": "ACGKS9W7iQQywxrWW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pqcMyeALASb4d7KE8/a-gamification-of-education-a-modest-proposal-based-on-the", "pageUrlRelative": "/posts/pqcMyeALASb4d7KE8/a-gamification-of-education-a-modest-proposal-based-on-the", "linkUrl": "https://www.lesswrong.com/posts/pqcMyeALASb4d7KE8/a-gamification-of-education-a-modest-proposal-based-on-the", "postedAtFormatted": "Sunday, July 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20Gamification%20Of%20Education%3A%20a%20modest%20proposal%20based%20on%20the%20Universal%20Decimal%20Classification%20%20and%20RPG%20skill%20trees&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20Gamification%20Of%20Education%3A%20a%20modest%20proposal%20based%20on%20the%20Universal%20Decimal%20Classification%20%20and%20RPG%20skill%20trees%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqcMyeALASb4d7KE8%2Fa-gamification-of-education-a-modest-proposal-based-on-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20Gamification%20Of%20Education%3A%20a%20modest%20proposal%20based%20on%20the%20Universal%20Decimal%20Classification%20%20and%20RPG%20skill%20trees%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqcMyeALASb4d7KE8%2Fa-gamification-of-education-a-modest-proposal-based-on-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqcMyeALASb4d7KE8%2Fa-gamification-of-education-a-modest-proposal-based-on-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1908, "htmlBody": "<p>While <a href=\"/lw/hwp/personaly_library_management/\">making the inventory of my personal library</a> and applying the <a href=\"http://www.udcc.org/udcsummary/php/index.php?lang=en\">Universal Decimal System</a> to its classification, I found myself discovering a systematized classification of fields of knowledge, nested and organized and intricate, many of which I didn't even know existed. I couldn't help but compare how information was therein classified, and how it was imparted to me in engineering school. I also thought about how, often, software engineers and computer scientists were mostly self-thought, with even college mostly consisting of \"here's a problem: go forth and figure out a way to solve it\". This made me wonder whether another way of certified and certifiable education couldn't be achieved, and a couple of ideas sort of came to me.</p>\n<p>It's pretty nebulous in my mind so far, but the crux of the concept would be a <strong>modular structure of education</strong>, where the academic institution essentially established what information precisely you need from each module, and <em>lets you <strong>get on</strong> with the activity of <strong>learning</strong></em>, with <strong>periodic exams</strong> that you can sign up for, which will certify your level and area of proficiency in each module.</p>\n<p>A <strong>recommended tree of learning</strong> can be established, but it should be possible to not take every intermediate test, if passing the final test proves that you've passed all the others behind it (this would allow people coming from different academic systems to certify their knowledge quickly and easily, thus avoiding the classic \"Doctor in Physics from Former Soviet Union, current Taxi Driver in New York\" scenario).</p>\n<p>Thus, a <strong>universal standard</strong> of <strong>how much you have proven to know about what topics can be established</strong>.</p>\n<p>Employers would then be free to request <strong>profiles</strong> in the format of such a tree. It need not be a binary \"you need to have done all these courses and only these courses to work for us\", they could be free to <strong>write their utility function</strong> for this or that job <strong>however they would see fit</strong>, with <strong>whichever weights and restrictions</strong> they would need.</p>\n<p>Students and other learners would be <strong>free</strong> to <strong>advance in whichever tree they required</strong>, depending on what <strong>kind of profile</strong> they want to end up with at what <strong>age or point in time</strong>. One would determine what to learn based on <strong>statistical studies</strong> of what elements are, by and large, most <strong>desired by employers</strong> of/<strong>predictors</strong> of professional <strong>success</strong> in a certain field you want to work in.</p>\n<p>One would find, for example, that mastering the peculiar field of railway engineering is great to be a proficient railway engineer, but also that having studied, say, things involved with people skills (from rhetoric to psychology to management), correlates positively with success in that field.</p>\n<p>Conversely, a painter may find that learning about statistics, market predictions, web design, or cognitive biases correlates with a more successful career (whether it be on terms of income, or in terms of copies sold, or of public exposure... each one may optimize <em>their own</em> learning according to <em>their own</em> criteria).</p>\n<p>One might even be able to <strong>calculate </strong>whether such <strong>complimentary education</strong> is <strong>actually worth their time</strong>, and <strong>which</strong> of them are <strong>the most cost-efficient</strong>.</p>\n<p>I would predict that such a system would help society overall optimize how many people know what skills, and facilitate the learning of new skills and the updating of old ones for everyone, thus reducing structural unemployment, and preventing pigeonholing and other forms of professional arthritis.</p>\n<p>I would even dare to predict that, given the vague, statistical, cluster-ish nature of this system, people would be encouraged to learn quite a lot more, and on a quite wider range of fields, than they do now, when one must jump through a great many hoops and endure a great many constraints in space and time and coin to get access to some types of educations (and to the acknowledgement of their acquisition thereof).</p>\n<p>Acquiring access to the actual sources of knowledge, a <strong>library</strong> (virtual or otherwise),<strong> lectures </strong>(virtual or otherwise), and so on, would be a private matter, up to the learner:</p>\n<ul>\n<li>some of them <strong>already have the knowledge</strong> and just need to get it <strong>certified</strong>, </li>\n<li>others can actually <strong>buy the books</strong> they want/need, especially if keeping them around as reference will be useful to them in the future, </li>\n<li>others can <strong>subscribe</strong> to one or many <strong>libraries</strong>, of the on-site sort or by correspondence</li>\n<li>others can <strong>buy</strong> access to pre-recorded <strong>lectures</strong>, <strong>peruse</strong> lectures that are available <strong>for free</strong>, or <strong>enroll</strong> in academic <strong>institutions</strong> whose ostensible purpose is to <strong>give lectures</strong> and/or otherwise guide students through learning, more or less closely</li>\n<li>the same applies to <strong>finding study groups</strong> with whom you can work on a topic together: I can easily imagine <strong>dedicated social networks</strong> could be created for that purpose, helping people pair up with each other based on mutual distance, predicted personal affinity, mutual goals, backgrounds, and so on. Who knows what amazing research teams might be borne of the intellectual equivalent of <a href=\"http://www.okcupid.com\">OK!Cupid</a>.</li>\n</ul>\n<p>A thing that I would like very much about this system is that it would free up the <em>strange conflicts of interest</em> that hamper the function of traditional educational institutions.</p>\n<p>W<em>hen the ones who teach you are also the ones who grade you</em>, the effort they invest in you can feel like a zero-sum game, especially if they are only allowed to let a <em>percentag</em>e of you pass.</p>\n<p><em>When the ones who teach you have priorities other than teach</em> (usually research, but some teachers are also involved in administrative functions, or even private interests completely outside of the university's ivory tower<sup>1</sup>), this can and often does reduce the energy and dedication they can/will allocate to the actual function of teaching, as opposed to the others.</p>\n<p>By separating these functions, and the contradictory incentives they provide, the organizations performing them are free to <strong>optimize</strong> for each:&nbsp;</p>\n<ul>\n<li><strong>Testing</strong> is optimized for <strong>predicting current and future competence in a subject</strong>: the testers whose tests are the most reliable have more employers requiring their certificates, and thus more people requesting that they test them</li>\n<li><strong>Teaching</strong> is optimized for <strong>getting the knowledge through</strong> whatever the heck the students want, whether it be to succeed at the tests or to simply master the subject (I don't know much game theory, but I'd naively guess that the spontaneous equilibrium between the teaching and testing institutions would lead to both goals becoming identical).</li>\n<li><strong>Researching</strong> is optimized for <strong>research</strong> (researchers are not teachers. dang it, those are very different skill-sets!). However researchers and other experts get to have a pretty big say in what the tests test for and how, because their involvement makes the tests more trustworthy for employers, and because they, too, are employers.</li>\n<li>And of course entire <strong>meta-institutions</strong> can spring from this, whose role is to statistically verify, over the long term, <br /> \n<ul>\n<li>how <strong>good</strong> a <strong>predictor</strong> of <strong>professional success</strong> in this or that field is <strong>passing</strong> the corresponding <strong>test</strong>, and </li>\n<li>how good a predictor of <strong>passing the test</strong> is to be <strong>taught</strong> by this or that <strong>teaching institution</strong>.</li>\n<li>how good a predictor of <strong>the test being reliable</strong> is the <strong>input</strong> of these or those <strong>researchers and experts</strong></li>\n</ul>\n</li>\n<li>It occurs to me now that, if one wished to be really nitpicky about who watches the watchmen, I suspect that there would be institutions testing the reliability of those meta-institutions, and so on and so forth... When does it stop? How to avoid vested interests and little cheats and manipulations pulling an academic equivalent of the AAA certification of sub-prime junk debt in 2008?</li>\n</ul>\n<p>Another discrepancy I'd like to see solved is the difference between the official time it is supposed to take to obtain this or that degree, to learn this or that subject, and the actual statistical distribution of that time. Nowadays, a degree that's supposed to take you five years ends up taking up eight or ten years of your life. You find yourself having to go through the most difficult subjects again and again, because they are explained in an extremely rushed way, the materials crammed into a pre-formatted time. Other subjects are so exceedingly easy and thinly-spread that you find that going to class is a waste of time, and that you're better off preparing for it one week before finals. Now, after having written all of the above, my mind is quite spent, and I don't feel capable of either anticipating the effect of my proposed idea on this particular, nor of offering any solutions. Nevertheless, I wish to draw attention to this, so I'm leaving this paragraph in until I can amend it to something more useful/promising.</p>\n<p>I hereby submit this idea to the LW community for screening and sound-boarding. I apologize in advance for your time, just in case this idea appears to be flawed enough to be unsalvageable. If you deem the concept good but flawed, we could perhaps work on ironing those kinks together. If, afterwards, this seems to you like a good enough idea to implement, know that good proposals are a dime a dozen; if there is any interest in seeing something like this happen, we can need to move on to proprely understanding the current state of secondary/superior/higher education, and figuring out of what incentives/powers/leverages are needed to actually get it implemented.</p>\n<p>&nbsp;</p>\n<hr />\n<hr />\n<p>&nbsp;</p>\n<p><sup>1</sup>By ivory tower I simply mean the protected environment where professors teach, researchers research, and students study, with multiple buffers between it and the ebb and flow of political, economical, and social turmoil. No value judgement is intended.</p>\n<p>&nbsp;</p>\n<hr />\n<p>&nbsp;</p>\n<p>EDIT: And now I look upon the title of this article and realize that, though I had comparisons to games in mind, I never got around to writing them down. My inspirations here were mostly <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/TechTree\">Civilization's Research Trees</a>, <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/Main/SkillScoresAndPerks?from=Main.SkillTree\">RPG Skill Scores and Perks</a>, and, in particular, <a href=\"http://tvtropes.org/pmwiki/pmwiki.php/VideoGame/TheElderScrollsVSkyrim\">Skyrim</a>'s skills and perks tree.</p>\n<p>Basically, your level at whatever skill improves by studying and by practising it rather than merely by levelling up, and, when you need to perform a task that's outside your profile, you can go and learn it without having to commit to a class. Knowing the right combination of skills at the right level lets you unlock perks or access previously-unavailable skills and applications. What I like the most about it is that there's a lot of freedom to learn what you want and be who you want to be according to your own tastes and wishes, but, overall, it sounds sensible and is relatively well-balanced. And of course there's the fact that it allows you to keep a careful tally of how good you are at what things, and the sense of accomplishment is so motivating and encouraging!</p>\n<p>Speaking of which, several netwroks and consoles' <a href=\"http://tvtropes.org/pmwiki/discussion.php?id=ol7jwc8t6o5lv4vh7i0uzsco\">Achievement systems</a> also strike me as motivators for keeping track of what one has achieved so far, to look back and be able to say \"I've come a long way\" (in an effect similar to that of gratitude journals), and also to accomplish a task and have this immediate and universal acknowledgement that <em>you did it</em> dammit (and, for those who care about that kind of thing, the chance to rub it the face of those who <em>haven't</em>).</p>\n<p>I would think our educational systems could benefit from this kind of modularity and from this ability to keep track of things in a systematic way. What do you guys think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pqcMyeALASb4d7KE8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 18, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "23227", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 80, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RuYmvK7Z9rq6xzJo5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-07T21:30:34.459Z", "modifiedAt": null, "url": null, "title": "Home Economics", "slug": "home-economics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:34.038Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Ritalin", "createdAt": "2012-05-01T18:00:25.863Z", "isAdmin": false, "displayName": "Ritalin"}, "userId": "ACGKS9W7iQQywxrWW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zyMvJ325DSqaspfNH/home-economics", "pageUrlRelative": "/posts/zyMvJ325DSqaspfNH/home-economics", "linkUrl": "https://www.lesswrong.com/posts/zyMvJ325DSqaspfNH/home-economics", "postedAtFormatted": "Sunday, July 7th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Home%20Economics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHome%20Economics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzyMvJ325DSqaspfNH%2Fhome-economics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Home%20Economics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzyMvJ325DSqaspfNH%2Fhome-economics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzyMvJ325DSqaspfNH%2Fhome-economics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 417, "htmlBody": "<p>As I <a href=\"/lw/hwp/personaly_library_management/\">inventoried my personal library</a> and classified it using the<a href=\"http://www.udcc.org/udcsummary/php/index.php?lang=en\"> Universal Decimal System</a>, I found out about lots of fields of knowledge I was only dimly aware of or didn't even know existed<sup>1</sup>, and one of those that piqued my curiosity was home economics, domestic science and housekeeping (field 64). I was kinda bluffed, actually; I always thought of home economics as that thing that shows up in American high school sitcoms, that elective \"for girls\" where people get to cook stuff on campus. Now I find that it fully occupies one of The Tens of the UDC! I finally realized it; this is Serious Business!</p>\n<p>I thought of the permanently shoddy state of my bank account, of all the money I had spent in books (no less than 215 physical books, and then there's Kindle!), fancy gadgets (were those Marshall headphones really necessary? What about that sandwich-maker?), fancy food (even though I always seem to end up \"cooking\" the same boring, unbalanced crap), unnecessary or excessive heating and air conditioning, and so on and so forth.</p>\n<p>I've come to realize how much I had underestimated this field, the duty towards oneself of taking care of one's house, and the advantages of so doing. I want to catch up in terms of planning my budget and my cleaning and my cooking and my buying furniture and appliances and so on and so for. I suppose I could figure it out by myself, but why reinvent the wheel?</p>\n<p>So I thought to myself: asking your mates at LW has had awesome results when it came to getting your library in order, why don't you ask them about Home Economics? They probably actually went to those courses in High School, or have otherwise taken an interest just to optimize their homes! I mean, their literal livelihoods and well-beings are at stake, so why wouldn't they<sup>2</sup>?</p>\n<p>So, yeah, if you guys know which reference books to start with, or have any practical recommendations in terms of resources or bibliography, and the handling thereof, I'd love to hear it. Who knows, maybe a good top level post may come of it?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<hr />\n<p><sup>1</sup>This triggered my imagination on a completely unrelated topic:<a href=\"/lw/hx7/a_gamification_of_education_a_modest_proposal/\"> a gamified education system in the style of an RPG skill tree</a>.</p>\n<p>&nbsp;</p>\n<p><sup>2</sup>My Inner Critic obligingly suggested \"Arkasia and, given the demographic, a compounded disdain for manual labor, pedestrian and materialistic concerns, and girly stuff. Why else didn't <em>you?</em>\" I told it to step aside and go have a swim in the North Atlantic.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zyMvJ325DSqaspfNH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 19, "extendedScore": null, "score": 5.9e-05, "legacy": true, "legacyId": "23228", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RuYmvK7Z9rq6xzJo5", "pqcMyeALASb4d7KE8"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T04:30:31.764Z", "modifiedAt": null, "url": null, "title": "Estimating the kolmogorov complexity of the known laws of physics?", "slug": "estimating-the-kolmogorov-complexity-of-the-known-laws-of", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:39.694Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Strilanc", "createdAt": "2012-07-25T07:36:05.321Z", "isAdmin": false, "displayName": "Strilanc"}, "userId": "nBwAhG4QXmGpxLB2F", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zsNrcax53C4xR9esg/estimating-the-kolmogorov-complexity-of-the-known-laws-of", "pageUrlRelative": "/posts/zsNrcax53C4xR9esg/estimating-the-kolmogorov-complexity-of-the-known-laws-of", "linkUrl": "https://www.lesswrong.com/posts/zsNrcax53C4xR9esg/estimating-the-kolmogorov-complexity-of-the-known-laws-of", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Estimating%20the%20kolmogorov%20complexity%20of%20the%20known%20laws%20of%20physics%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEstimating%20the%20kolmogorov%20complexity%20of%20the%20known%20laws%20of%20physics%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzsNrcax53C4xR9esg%2Festimating-the-kolmogorov-complexity-of-the-known-laws-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Estimating%20the%20kolmogorov%20complexity%20of%20the%20known%20laws%20of%20physics%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzsNrcax53C4xR9esg%2Festimating-the-kolmogorov-complexity-of-the-known-laws-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzsNrcax53C4xR9esg%2Festimating-the-kolmogorov-complexity-of-the-known-laws-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 275, "htmlBody": "<p>In the post <a href=\"/lw/vh/complexity_and_intelligence/\">Complexity and Intelligence</a>, Eliezer says that the <a href=\"http://en.wikipedia.org/wiki/Kolmogorov_complexity\">Kolmogorov Complexity</a> (length of shortest equivalent computer program) of the laws of physics is about 500 bits:</p>\n<blockquote>\n<p>Suppose you ran a Turing machine with unlimited tape, so that, starting from our laws of physics, it simulated our whole universe - not just the region of space we see around us, but all regions of space and all quantum branches. [...]</p>\n<p>Then the \"Kolmogorov complexity\" of that entire universe [...] would be 500 bits, or whatever the size of the true laws of physics when written out as equations on a sheet of paper.</p>\n</blockquote>\n<p>Where did this 500 come from?</p>\n<p>I googled around for estimates on the Kolmogorov Complexity of the laws of physics, but didn't find anything. Certainly nothing as concrete as 500.</p>\n<p>I <a href=\"http://physics.stackexchange.com/questions/65005/estimating-the-kolmogorov-complexity-of-the-standard-model\">asked about it on the physics stack exchange</a>, but haven't received any answers as of yet.</p>\n<p>I considered estimating it myself, but doing that well involves significant time investment. I'd need to learn the standard model well enough to write a computer program that simulated it (however inefficiently or intractably, it's the program length that matters not it's time or memory performance).</p>\n<p>Based on my experience programming, I'm sure it wouldn't take a million bits. Probably less than ten thousand. The demo scene does some <a href=\"https://www.youtube.com/watch?v=AWcbj7ksqwE\">pretty amazing things with 4096 bits</a>. But 500 sounds like a teeny tiny amount to mention off hand for fitting the constants, the forces, the particles, and the mathematical framework for doing things like differential equations. The fundamental constants alone are going to consume ~20-30 bits each.</p>\n<p>Does anyone have a reference, or even a more worked-through example of an estimate?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb25c": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zsNrcax53C4xR9esg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 17, "extendedScore": null, "score": 4.4e-05, "legacy": true, "legacyId": "23232", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["rELc88PvDkhetQzqx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T05:16:48.460Z", "modifiedAt": null, "url": null, "title": "Evidential Decision Theory, Selection Bias, and Reference Classes", "slug": "evidential-decision-theory-selection-bias-and-reference", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:03.053Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Qiaochu_Yuan", "createdAt": "2012-11-24T08:36:50.547Z", "isAdmin": false, "displayName": "Qiaochu_Yuan"}, "userId": "qgFX9ZhzPCkcduZyB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fWKGXSZ3uXxLKAxvm/evidential-decision-theory-selection-bias-and-reference", "pageUrlRelative": "/posts/fWKGXSZ3uXxLKAxvm/evidential-decision-theory-selection-bias-and-reference", "linkUrl": "https://www.lesswrong.com/posts/fWKGXSZ3uXxLKAxvm/evidential-decision-theory-selection-bias-and-reference", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Evidential%20Decision%20Theory%2C%20Selection%20Bias%2C%20and%20Reference%20Classes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEvidential%20Decision%20Theory%2C%20Selection%20Bias%2C%20and%20Reference%20Classes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfWKGXSZ3uXxLKAxvm%2Fevidential-decision-theory-selection-bias-and-reference%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Evidential%20Decision%20Theory%2C%20Selection%20Bias%2C%20and%20Reference%20Classes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfWKGXSZ3uXxLKAxvm%2Fevidential-decision-theory-selection-bias-and-reference", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfWKGXSZ3uXxLKAxvm%2Fevidential-decision-theory-selection-bias-and-reference", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1714, "htmlBody": "<p><strong>See also:</strong> <a href=\"/lw/3pf/does_evidential_decision_theory_really_fail/\">Does Evidential Decision Theory really fail Solomon's Problem?</a>, <a href=\"/lw/e7e/whats_wrong_with_evidential_decision_theory/\">What's Wrong with Evidential Decision Theory?</a></p>\n<p>It seems to me that the examples usually given of decision problems where EDT makes the wrong decisions are really examples of performing Bayesian updates incorrectly. The basic problem seems to be that naive EDT ignores a <em>selection bias</em>&nbsp;when it assumes that an agent that has just performed an action should be treated as a random sample from the population of all agents who have performed that action. Said another way, naive EDT agents make some unjustified assumptions about what <em>reference classes</em>&nbsp;they should put themselves into when considering counterfactuals. A more sophisticated Bayesian agent should make neither of these mistakes, and correcting them should not in principle require moving beyond EDT but just becoming less naive in applying it.&nbsp;</p>\n<p><a href=\"http://www.smbc-comics.com/index.php?db=comics&amp;id=3020\"><img style=\"float:right\" src=\"http://www.smbc-comics.com/comics/20130625.png\" alt=\"\" width=\"40%\" /></a></p>\n<h3>Elaboration</h3>\n<p>Recall that an EDT agent attempts to maximize conditional expected utility. The main criticism of EDT is that naively computing conditional probabilities leads to the conclusion that you should perform actions which <em>are good news</em>&nbsp;upon learning that they happened, as opposed to actions which <em>cause&nbsp;good outcomes</em>&nbsp;(what CDT attempts to do instead). For a concrete example of the difference, let's take the <a href=\"http://wiki.lesswrong.com/wiki/Smoking_lesion\">smoking lesion</a> problem:</p>\n<blockquote>\n<p>Smoking is strongly correlated with lung cancer, but in the world of the Smoker's Lesion this correlation is understood to be the result of a common cause: a genetic lesion that tends to cause both smoking and cancer. Once we fix the presence or absence of the lesion, there is no additional correlation between smoking and cancer.</p>\n<p>Suppose you prefer smoking without cancer to not smoking without cancer, and prefer smoking with cancer to not smoking with cancer. Should you smoke?</p>\n</blockquote>\n<p>In the smoking lesion problem, smoking is bad news, but it doesn't cause a bad outcome: learning that someone smokes, in the absence of further information, increases your posterior probability that they have the lesion and therefore cancer, but choosing to smoke cannot in fact alter whether you have the lesion / cancer or not. Naive EDT recommends not smoking, but naive CDT recommends smoking, and in this case it seems that naive CDT's recommendation is correct and naive EDT's recommendation is not.&nbsp;</p>\n<p>The naive EDT agent's reasoning process involves considering the following counterfactual: \"if I observe myself smoking, that increases my posterior probability that I have the lesion and therefore cancer, and that would be bad. Therefore I will not smoke.\" But it seems to me that in this counterfactual, the naive EDT agent -- who smokes and then glumly concludes that there is an increased probability that they have cancer -- is performing a Bayesian update incorrectly, and that the incorrectness of this Bayesian update, rather than any fundamental problem with making decisions based on conditional probabilities, is what causes the naive EDT agent to perform poorly.&nbsp;</p>\n<p>Here are some other examples of this kind of Bayesian update, all of which seem obviously incorrect to me. They lead to silly decisions because they are silly updates.&nbsp;</p>\n<ul>\n<li>\"If I observe myself throwing away expensive things, that increases my posterior probability that I am rich and can afford to throw away expensive things, and that would be good. Therefore I will throw away expensive things.\" (This example requires that you have some uncertainty about your finances -- perhaps you never check your bank statement and never ask your boss what your salary is.)</li>\n<li>\"If I observe myself not showering, that increases my posterior probability that I am clean and do not need to shower, and that would be good. Therefore I will not shower.\" (This example requires that you have some uncertainty about how clean you are -- perhaps you don't have a sense of smell or a mirror.)</li>\n<li>\"If I observe myself playing video games, that increases my posterior probability that I don't have any work to do, and that would be good. Therefore I will play video games.\" (This example requires that you have some uncertainty about how much work you have to do -- perhaps you write this information down and then forget it.)&nbsp;</li>\n</ul>\n<h3>Selection Bias</h3>\n<p>Earlier I said that <em>in the absence of further information</em>, learning that someone smokes increases your posterior probability that they have the lesion and therefore cancer in the smoking lesion problem. But when a naive EDT agent is deciding what to do, they <em>have</em>&nbsp;further information: in the counterfactual where they're smoking, they know that they're smoking because they're in a counterfactual about what would happen if they smoked (or something like that). This information should <a href=\"http://wiki.lesswrong.com/wiki/Screening_off\">screen off</a> inferences about other possible causes of smoking, which is perhaps clearer in the bulleted examples above. If you consider what would happen if you threw away expensive things, you know that you're doing so because you're considering what would happen if you threw away expensive things and not because you're rich.&nbsp;</p>\n<p>Failure to take this information into account is a kind of selection bias: a naive EDT agent considering the counterfactual where they perform some action treats itself as a random sample from the population of similar agents who have performed such actions, but it is not in fact such a random sample! The sampling procedure, which consists of actually performing an action, is undoubtedly biased.&nbsp;</p>\n<h3>Reference Classes</h3>\n<p>Another way to think about the above situation is that a naive EDT agent chooses inappropriate reference classes: when an agent performs an action, the appropriate reference class is not all other agents who have performed that action. It's unclear to me exactly what it is, but at the very least it's something like \"other sufficiently similar agents who have performed that action under sufficiently similar circumstances.\"&nbsp;</p>\n<p>This is actually very easy to see in the smoker's lesion problem because of the following observation (which I think I found in Eliezer's old <a href=\"http://intelligence.org/files/TDT.pdf\">TDT writeup</a>): suppose the world of the smoker's legion is populated entirely with naive EDT agents who do not know whether or not they have the lesion. Then the above argument suggests that none of them will choose to smoke. But if that's the case, then where does the correlation between the lesion and smoking come from? Any agents who smoke are either not naive EDT agents or know whether they have the lesion. In either case, that makes them inappropriate members of the reference class any reasonable Bayesian agent should be using.</p>\n<p>Furthermore, if the naive EDT agents collectively decide to become slightly less naive and restrict their reference class to each other, they now find that smoking no longer gives any information about whether they have the lesion or not! This is a kind of reflective inconsistency: the naive recommendation not to smoke in the smoker's lesion problem has the property that, if adopted by a population of naive EDT agents, it breaks the correlations upon which the recommendation is based.&nbsp;</p>\n<h3>The Tickle Defense</h3>\n<p>As it happens, there is a standard counterargument in the decision theory literature to the claim that EDT recommends not smoking in the smoking lesion problem. It is known as the \"tickle defense,\" and runs as follows: in the smoking lesion problem, what an EDT agent should be updating on is not the action of smoking but an internal desire, or \"tickle,\" prompting it to smoke, and once the presence or absence of such a tickle has been updated on it screens off any information gained by updating on the act of smoking or not smoking. So EDT + Tickles smokes on the smoking lesion problem. (Note that this prescription <em>also</em> has the effect of breaking the correlation claimed in the setup of the smoking lesion problem among a population of EDT + Tickles agents who don't know whether hey have the lesion or not. So maybe there's just something wrong with the smoking lesion problem.)&nbsp;</p>\n<p>The tickle defense is good in that it encourages ignoring less information than naive EDT, but it strikes me as a patch covering up part of a more general problem, namely the problem of how to choose appropriate reference classes when performing Bayesian updates (or something like that). So I don't find it a satisfactory rescuing of EDT. It doesn't help that there's a more sophisticated version known as the \"meta-tickle defense\" that recommends two-boxing on Newcomb's problem.</p>\n<h3>Sophisticated EDT?</h3>\n<p>What does a more sophisticated version of EDT, taking the above observations into account, look like? I don't know. I suspect that it looks like some version of TDT / UDT, where TDT corresponds to something like trying to update on \"being the kind of agent who outputs this action in this situation\" and UDT corresponds to something more mysterious that I haven't been able to find a good explanation of yet, but I haven't thought about this much. If someone else has, let me know.</p>\n<p>Here are some vague thoughts. First, I think <a href=\"/lw/e7e/whats_wrong_with_evidential_decision_theory/79g1\">this comment</a> by Stuart_Armstrong is right on the money:</p>\n<blockquote>\n<p>I've found that, in practice, most versions of EDT are underspecified, and people use their intuitions to fill the gaps in one direction or the other.</p>\n</blockquote>\n<p>A \"true\" EDT agent needs to update on all the evidence they've ever observed, and it's very unclear to me how to do this in practice. So it seems that it's difficult to claim with much certainty that EDT will or will not do a particular thing in a particular situation.</p>\n<p>CDT-via-causal-networks and TDT-via-causal-networks seem like reasonable candidates for more sophisticated versions of EDT in that they formalize the intuition above about screening off possible causes of a particular action. TDT seems like it better captures this intuition in that it better attempts to update on the cause of an action in a hypothetical about that action (the cause being that TDT outputs that action). My intuition here is that it should be possible to see causal networks as arising naturally out of Bayesian considerations, although I haven't thought about this much either.&nbsp;</p>\n<p>AIXI might be another candidate. Unfortunately, AIXI can't handle the smoking lesion problem because it models itself as separate from the environment, whereas a key point in the smoking lesion problem is that an agent in the world of the smoking lesion has some uncertainty about its innards, regarded as part of its environment. Fully specifying sophisticated EDT might involve finding a version of AIXI that models itself as part of its environment.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 1, "MAp6Ft8b3s7kJdrQ9": 1, "3uE2pXvbcnS9nnZRE": 1, "5f5c37ee1b5cdee568cfb28f": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fWKGXSZ3uXxLKAxvm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 33, "extendedScore": null, "score": 0.000117, "legacy": true, "legacyId": "23210", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><strong>See also:</strong> <a href=\"/lw/3pf/does_evidential_decision_theory_really_fail/\">Does Evidential Decision Theory really fail Solomon's Problem?</a>, <a href=\"/lw/e7e/whats_wrong_with_evidential_decision_theory/\">What's Wrong with Evidential Decision Theory?</a></p>\n<p>It seems to me that the examples usually given of decision problems where EDT makes the wrong decisions are really examples of performing Bayesian updates incorrectly. The basic problem seems to be that naive EDT ignores a <em>selection bias</em>&nbsp;when it assumes that an agent that has just performed an action should be treated as a random sample from the population of all agents who have performed that action. Said another way, naive EDT agents make some unjustified assumptions about what <em>reference classes</em>&nbsp;they should put themselves into when considering counterfactuals. A more sophisticated Bayesian agent should make neither of these mistakes, and correcting them should not in principle require moving beyond EDT but just becoming less naive in applying it.&nbsp;</p>\n<p><a href=\"http://www.smbc-comics.com/index.php?db=comics&amp;id=3020\"><img style=\"float:right\" src=\"http://www.smbc-comics.com/comics/20130625.png\" alt=\"\" width=\"40%\"></a></p>\n<h3 id=\"Elaboration\">Elaboration</h3>\n<p>Recall that an EDT agent attempts to maximize conditional expected utility. The main criticism of EDT is that naively computing conditional probabilities leads to the conclusion that you should perform actions which <em>are good news</em>&nbsp;upon learning that they happened, as opposed to actions which <em>cause&nbsp;good outcomes</em>&nbsp;(what CDT attempts to do instead). For a concrete example of the difference, let's take the <a href=\"http://wiki.lesswrong.com/wiki/Smoking_lesion\">smoking lesion</a> problem:</p>\n<blockquote>\n<p>Smoking is strongly correlated with lung cancer, but in the world of the Smoker's Lesion this correlation is understood to be the result of a common cause: a genetic lesion that tends to cause both smoking and cancer. Once we fix the presence or absence of the lesion, there is no additional correlation between smoking and cancer.</p>\n<p>Suppose you prefer smoking without cancer to not smoking without cancer, and prefer smoking with cancer to not smoking with cancer. Should you smoke?</p>\n</blockquote>\n<p>In the smoking lesion problem, smoking is bad news, but it doesn't cause a bad outcome: learning that someone smokes, in the absence of further information, increases your posterior probability that they have the lesion and therefore cancer, but choosing to smoke cannot in fact alter whether you have the lesion / cancer or not. Naive EDT recommends not smoking, but naive CDT recommends smoking, and in this case it seems that naive CDT's recommendation is correct and naive EDT's recommendation is not.&nbsp;</p>\n<p>The naive EDT agent's reasoning process involves considering the following counterfactual: \"if I observe myself smoking, that increases my posterior probability that I have the lesion and therefore cancer, and that would be bad. Therefore I will not smoke.\" But it seems to me that in this counterfactual, the naive EDT agent -- who smokes and then glumly concludes that there is an increased probability that they have cancer -- is performing a Bayesian update incorrectly, and that the incorrectness of this Bayesian update, rather than any fundamental problem with making decisions based on conditional probabilities, is what causes the naive EDT agent to perform poorly.&nbsp;</p>\n<p>Here are some other examples of this kind of Bayesian update, all of which seem obviously incorrect to me. They lead to silly decisions because they are silly updates.&nbsp;</p>\n<ul>\n<li>\"If I observe myself throwing away expensive things, that increases my posterior probability that I am rich and can afford to throw away expensive things, and that would be good. Therefore I will throw away expensive things.\" (This example requires that you have some uncertainty about your finances -- perhaps you never check your bank statement and never ask your boss what your salary is.)</li>\n<li>\"If I observe myself not showering, that increases my posterior probability that I am clean and do not need to shower, and that would be good. Therefore I will not shower.\" (This example requires that you have some uncertainty about how clean you are -- perhaps you don't have a sense of smell or a mirror.)</li>\n<li>\"If I observe myself playing video games, that increases my posterior probability that I don't have any work to do, and that would be good. Therefore I will play video games.\" (This example requires that you have some uncertainty about how much work you have to do -- perhaps you write this information down and then forget it.)&nbsp;</li>\n</ul>\n<h3 id=\"Selection_Bias\">Selection Bias</h3>\n<p>Earlier I said that <em>in the absence of further information</em>, learning that someone smokes increases your posterior probability that they have the lesion and therefore cancer in the smoking lesion problem. But when a naive EDT agent is deciding what to do, they <em>have</em>&nbsp;further information: in the counterfactual where they're smoking, they know that they're smoking because they're in a counterfactual about what would happen if they smoked (or something like that). This information should <a href=\"http://wiki.lesswrong.com/wiki/Screening_off\">screen off</a> inferences about other possible causes of smoking, which is perhaps clearer in the bulleted examples above. If you consider what would happen if you threw away expensive things, you know that you're doing so because you're considering what would happen if you threw away expensive things and not because you're rich.&nbsp;</p>\n<p>Failure to take this information into account is a kind of selection bias: a naive EDT agent considering the counterfactual where they perform some action treats itself as a random sample from the population of similar agents who have performed such actions, but it is not in fact such a random sample! The sampling procedure, which consists of actually performing an action, is undoubtedly biased.&nbsp;</p>\n<h3 id=\"Reference_Classes\">Reference Classes</h3>\n<p>Another way to think about the above situation is that a naive EDT agent chooses inappropriate reference classes: when an agent performs an action, the appropriate reference class is not all other agents who have performed that action. It's unclear to me exactly what it is, but at the very least it's something like \"other sufficiently similar agents who have performed that action under sufficiently similar circumstances.\"&nbsp;</p>\n<p>This is actually very easy to see in the smoker's lesion problem because of the following observation (which I think I found in Eliezer's old <a href=\"http://intelligence.org/files/TDT.pdf\">TDT writeup</a>): suppose the world of the smoker's legion is populated entirely with naive EDT agents who do not know whether or not they have the lesion. Then the above argument suggests that none of them will choose to smoke. But if that's the case, then where does the correlation between the lesion and smoking come from? Any agents who smoke are either not naive EDT agents or know whether they have the lesion. In either case, that makes them inappropriate members of the reference class any reasonable Bayesian agent should be using.</p>\n<p>Furthermore, if the naive EDT agents collectively decide to become slightly less naive and restrict their reference class to each other, they now find that smoking no longer gives any information about whether they have the lesion or not! This is a kind of reflective inconsistency: the naive recommendation not to smoke in the smoker's lesion problem has the property that, if adopted by a population of naive EDT agents, it breaks the correlations upon which the recommendation is based.&nbsp;</p>\n<h3 id=\"The_Tickle_Defense\">The Tickle Defense</h3>\n<p>As it happens, there is a standard counterargument in the decision theory literature to the claim that EDT recommends not smoking in the smoking lesion problem. It is known as the \"tickle defense,\" and runs as follows: in the smoking lesion problem, what an EDT agent should be updating on is not the action of smoking but an internal desire, or \"tickle,\" prompting it to smoke, and once the presence or absence of such a tickle has been updated on it screens off any information gained by updating on the act of smoking or not smoking. So EDT + Tickles smokes on the smoking lesion problem. (Note that this prescription <em>also</em> has the effect of breaking the correlation claimed in the setup of the smoking lesion problem among a population of EDT + Tickles agents who don't know whether hey have the lesion or not. So maybe there's just something wrong with the smoking lesion problem.)&nbsp;</p>\n<p>The tickle defense is good in that it encourages ignoring less information than naive EDT, but it strikes me as a patch covering up part of a more general problem, namely the problem of how to choose appropriate reference classes when performing Bayesian updates (or something like that). So I don't find it a satisfactory rescuing of EDT. It doesn't help that there's a more sophisticated version known as the \"meta-tickle defense\" that recommends two-boxing on Newcomb's problem.</p>\n<h3 id=\"Sophisticated_EDT_\">Sophisticated EDT?</h3>\n<p>What does a more sophisticated version of EDT, taking the above observations into account, look like? I don't know. I suspect that it looks like some version of TDT / UDT, where TDT corresponds to something like trying to update on \"being the kind of agent who outputs this action in this situation\" and UDT corresponds to something more mysterious that I haven't been able to find a good explanation of yet, but I haven't thought about this much. If someone else has, let me know.</p>\n<p>Here are some vague thoughts. First, I think <a href=\"/lw/e7e/whats_wrong_with_evidential_decision_theory/79g1\">this comment</a> by Stuart_Armstrong is right on the money:</p>\n<blockquote>\n<p>I've found that, in practice, most versions of EDT are underspecified, and people use their intuitions to fill the gaps in one direction or the other.</p>\n</blockquote>\n<p>A \"true\" EDT agent needs to update on all the evidence they've ever observed, and it's very unclear to me how to do this in practice. So it seems that it's difficult to claim with much certainty that EDT will or will not do a particular thing in a particular situation.</p>\n<p>CDT-via-causal-networks and TDT-via-causal-networks seem like reasonable candidates for more sophisticated versions of EDT in that they formalize the intuition above about screening off possible causes of a particular action. TDT seems like it better captures this intuition in that it better attempts to update on the cause of an action in a hypothetical about that action (the cause being that TDT outputs that action). My intuition here is that it should be possible to see causal networks as arising naturally out of Bayesian considerations, although I haven't thought about this much either.&nbsp;</p>\n<p>AIXI might be another candidate. Unfortunately, AIXI can't handle the smoking lesion problem because it models itself as separate from the environment, whereas a key point in the smoking lesion problem is that an agent in the world of the smoking lesion has some uncertainty about its innards, regarded as part of its environment. Fully specifying sophisticated EDT might involve finding a version of AIXI that models itself as part of its environment.&nbsp;</p>", "sections": [{"title": "Elaboration", "anchor": "Elaboration", "level": 1}, {"title": "Selection Bias", "anchor": "Selection_Bias", "level": 1}, {"title": "Reference Classes", "anchor": "Reference_Classes", "level": 1}, {"title": "The Tickle Defense", "anchor": "The_Tickle_Defense", "level": 1}, {"title": "Sophisticated EDT?", "anchor": "Sophisticated_EDT_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "128 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 128, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3z8xxvSib8LQuhFaa", "RtPC6cmKLftbLSn6n"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T08:44:17.283Z", "modifiedAt": null, "url": null, "title": "Meetup : [Moscow] Weekday meet up", "slug": "meetup-moscow-weekday-meet-up", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yuu", "createdAt": "2012-04-04T16:48:49.513Z", "isAdmin": false, "displayName": "Yuu"}, "userId": "MBtCqzM7BePuwToxX", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DeNNHWJ5aDrXmuiv6/meetup-moscow-weekday-meet-up", "pageUrlRelative": "/posts/DeNNHWJ5aDrXmuiv6/meetup-moscow-weekday-meet-up", "linkUrl": "https://www.lesswrong.com/posts/DeNNHWJ5aDrXmuiv6/meetup-moscow-weekday-meet-up", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20%5BMoscow%5D%20Weekday%20meet%20up&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20%5BMoscow%5D%20Weekday%20meet%20up%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDeNNHWJ5aDrXmuiv6%2Fmeetup-moscow-weekday-meet-up%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20%5BMoscow%5D%20Weekday%20meet%20up%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDeNNHWJ5aDrXmuiv6%2Fmeetup-moscow-weekday-meet-up", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDeNNHWJ5aDrXmuiv6%2Fmeetup-moscow-weekday-meet-up", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/of'>[Moscow] Weekday meet up</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">11 July 2013 07:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">Russia, Moscow, naberezhnaya Luzhnetskaya 2/4 \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 17</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is another meet up on weekdays. If you are going for the first time, please fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to register for the gathering.</p>\n\n<p>You need metal door with number 17 (building number) near it. Enter and follow white labels \u201cNe\u00faron\u201d or \u201cApplied rationality\u201d until you will get to office 444. You can also wait near this door, we will check it several times. We will start at 19:00, so please come in advance. Meetup will take 2-2.5 hours.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Applied rationality exercises.</p></li>\n<li><p>Prediction markets.</p></li>\n</ul>\n\n<p>You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html?utm_source=lesswrong.com&amp;utm_medium=meet_up_announcement&amp;utm_term=20130711_meet_up+weekday&amp;utm_content=20130711_meet_up&amp;utm_campaign=moscow_meet_ups\">here, in Russian</a>, now with more photos.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/of'>[Moscow] Weekday meet up</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DeNNHWJ5aDrXmuiv6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 1.2587308652995097e-06, "legacy": true, "legacyId": "23235", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup____Moscow__Weekday_meet_up\">Discussion article for the meetup : <a href=\"/meetups/of\">[Moscow] Weekday meet up</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">11 July 2013 07:00:00PM (+0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">Russia, Moscow, naberezhnaya Luzhnetskaya 2/4 \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 17</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>This is another meet up on weekdays. If you are going for the first time, please fill <a href=\"https://docs.google.com/spreadsheet/viewform?formkey=dHY4Qy1WOTUtc1ZLU21ORjh1VEtCa3c6MA\" rel=\"nofollow\">this one minute form</a> (in Russian), to register for the gathering.</p>\n\n<p>You need metal door with number 17 (building number) near it. Enter and follow white labels \u201cNe\u00faron\u201d or \u201cApplied rationality\u201d until you will get to office 444. You can also wait near this door, we will check it several times. We will start at 19:00, so please come in advance. Meetup will take 2-2.5 hours.</p>\n\n<p>Main topics:</p>\n\n<ul>\n<li><p>Applied rationality exercises.</p></li>\n<li><p>Prediction markets.</p></li>\n</ul>\n\n<p>You can also use personal messages here, or drop a message at lw@lesswrong.ru to contact me for any reason.</p>\n\n<p>Reports from previous sessions can be found <a href=\"http://lesswrong.ru/forum/index.php/topic,71.0.html?utm_source=lesswrong.com&amp;utm_medium=meet_up_announcement&amp;utm_term=20130711_meet_up+weekday&amp;utm_content=20130711_meet_up&amp;utm_campaign=moscow_meet_ups\">here, in Russian</a>, now with more photos.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup____Moscow__Weekday_meet_up1\">Discussion article for the meetup : <a href=\"/meetups/of\">[Moscow] Weekday meet up</a></h2>", "sections": [{"title": "Discussion article for the meetup : [Moscow] Weekday meet up", "anchor": "Discussion_article_for_the_meetup____Moscow__Weekday_meet_up", "level": 1}, {"title": "Discussion article for the meetup : [Moscow] Weekday meet up", "anchor": "Discussion_article_for_the_meetup____Moscow__Weekday_meet_up1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T12:04:37.740Z", "modifiedAt": null, "url": null, "title": "Harry Potter and the Methods of Rationality discussion thread, part 23, chapter 94 ", "slug": "harry-potter-and-the-methods-of-rationality-discussion-8", "viewCount": null, "lastCommentedAt": "2017-06-17T04:18:01.828Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "elharo", "createdAt": "2012-12-28T14:11:02.335Z", "isAdmin": false, "displayName": "elharo"}, "userId": "cgJcCeZhdRnGtwMMR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bMxxf7Wtic298LcNx/harry-potter-and-the-methods-of-rationality-discussion-8", "pageUrlRelative": "/posts/bMxxf7Wtic298LcNx/harry-potter-and-the-methods-of-rationality-discussion-8", "linkUrl": "https://www.lesswrong.com/posts/bMxxf7Wtic298LcNx/harry-potter-and-the-methods-of-rationality-discussion-8", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2023%2C%20chapter%2094%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2023%2C%20chapter%2094%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbMxxf7Wtic298LcNx%2Fharry-potter-and-the-methods-of-rationality-discussion-8%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20discussion%20thread%2C%20part%2023%2C%20chapter%2094%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbMxxf7Wtic298LcNx%2Fharry-potter-and-the-methods-of-rationality-discussion-8", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbMxxf7Wtic298LcNx%2Fharry-potter-and-the-methods-of-rationality-discussion-8", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 252, "htmlBody": "<p>This is a new thread to discuss Eliezer Yudkowsky&rsquo;s&nbsp;<em><a href=\"http://www.fanfiction.net/s/5782108/1/\">Harry Potter and the Methods of Rationality</a></em>&nbsp;and anything related to it. This thread is intended for discussing&nbsp;<a href=\"http://hpmor.com/chapter/94\">chapter 94</a>. <a href=\"/r/discussion/lw/hws/harry_potter_and_the_methods_of_rationality/\">The previous thread&nbsp;</a>has passed 200 comments.&nbsp;</p>\n<p>There is now a site dedicated to the story at&nbsp;<a href=\"http://hpmor.com/\">hpmor.com</a>, which is now the place to go to find the&nbsp;<a href=\"http://hpmor.com/notes/\">authors notes</a>&nbsp;and all sorts of other goodies. AdeleneDawner has kept an&nbsp;<a href=\"http://www.evernote.com/pub/adelenedawner/Eliezer\">archive of Author&rsquo;s Notes</a>. (This goes up to the notes for chapter 76, and is now not updating. The authors notes from chapter 77 onwards are on hpmor.com.)&nbsp;</p>\n<p>The first 5 discussion threads are on the main page under the&nbsp;<a href=\"/tag/harry_potter/\">harry_potter tag</a>.&nbsp; Threads 6 and on (including this one) are in the&nbsp;<a href=\"/r/discussion/tag/harry_potter/\">discussion section</a>&nbsp;using its separate tag system. Also:&nbsp;<a href=\"/lw/2ab/harry_potter_and_the_methods_of_rationality\">1</a>,&nbsp; <a href=\"/lw/2ie/harry_potter_and_the_methods_of_rationality\">2</a>,&nbsp; <a href=\"/lw/2nm/harry_potter_and_the_methods_of_rationality\">3</a>,&nbsp; <a href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality\">4</a>,&nbsp; <a href=\"/lw/30g/harry_potter_and_the_methods_of_rationality\">5</a>,&nbsp; <a href=\"/r/discussion/lw/364/harry_potter_and_the_methods_of_rationality/\">6</a>,&nbsp; <a href=\"/r/discussion/lw/3rb/harry_potter_and_the_methods_of_rationality/\">7</a>,&nbsp; <a href=\"/lw/797/harry_potter_and_the_methods_of_rationality/\">8</a>,&nbsp; <a href=\"/lw/7jd/harry_potter_and_the_methods_of_rationality\">9</a>,&nbsp; <a href=\"/lw/ams/harry_potter_and_the_methods_of_rationality\">10</a>,&nbsp; <a href=\"/lw/axe/harry_potter_and_the_methods_of_rationality/\">11</a>,&nbsp; <a href=\"/r/discussion/lw/b5s/harry_potter_and_the_methods_of_rationality/\">12</a>,&nbsp; <a href=\"/r/discussion/lw/b7s/harry_potter_and_the_methods_of_rationality/\">13</a>,&nbsp; <a href=\"/r/discussion/lw/bfo/harry_potter_and_the_methods_of_rationality/\">14</a>,&nbsp; <a href=\"/r/discussion/lw/bmx/harry_potter_and_the_methods_of_rationality/\">15</a>,&nbsp; <a href=\"/r/discussion/lw/bto/harry_potter_and_the_methods_of_rationality/\">16</a>,&nbsp; <a href=\"/lw/fyv/harry_potter_and_the_methods_of_rationality/\">17</a>,&nbsp; <a href=\"/lw/g1q/harry_potter_and_the_methods_of_rationality/\">18</a>,&nbsp; <a href=\"/r/discussion/lw/huq/harry_potter_and_the_methods_of_rationality/\">19</a>,&nbsp; <a href=\"/r/discussion/lw/hvg/harry_potter_and_the_methods_of_rationality/\">20</a>,&nbsp; <a href=\"/r/discussion/lw/hwf/harry_potter_and_the_methods_of_rationality/\">21</a>,&nbsp; <a href=\"/r/discussion/lw/hws/harry_potter_and_the_methods_of_rationality/\">22</a>.</p>\n<p><strong>Spoiler Warning</strong>: this thread is full of spoilers. With few exceptions, spoilers for MOR and canon are fair game to post, without warning or rot13.&nbsp;<a href=\"/lw/2tr/harry_potter_and_the_methods_of_rationality/2v1l\">More specifically</a>:</p>\n<blockquote>\n<p>You do not need to rot13 anything about HP:MoR or the original Harry Potter series unless you are posting insider information from Eliezer Yudkowsky which is not supposed to be publicly available (which includes public statements by Eliezer that have been retracted).</p>\n<p>If there is evidence for X in MOR and/or canon then it&rsquo;s fine to post about X without rot13, even if you also have heard privately from Eliezer that X is true. But you should not post that &ldquo;Eliezer said X is true&rdquo; unless you use rot13.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yrg267i4a8EsgYAXp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bMxxf7Wtic298LcNx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 1.2588890009300645e-06, "legacy": true, "legacyId": "23236", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 344, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["smKK6yrKBehxvQq5i", "59rDBidWmmJTXL4Np", "xexS9nyzwRgP9sowp", "LzQcmBwAJBGyzrt6Z", "qKzeJvFWyPh5H2hwj", "nnnd4KRQxs6DYcehD", "y2Hszb4Dsm5FggnDC", "6ae2kq3JmKvL4YPgk", "zvXfBqp6TSriNkmbg", "WQ7XMjqvuRRj8nkpu", "LKFR5pBA3bBkERDxL", "8yEdpDpGgvDWHeodM", "K4JBpAxhvstdnNbeg", "xK6Pswbozev6pv4A6", "pBTcCB5uJTzADdMm4", "XN4WDRSPFo9iGEuk3", "QkhX5YeuYHzPW7Waz", "4sY9rqAqty8rHWGSW", "35GjH7tDvNJWSHQ3H", "Pxiu5SG8gjhCh2jYd", "CEd85FLRbQWsbkrmf", "CcnpbKuRaYMjpFmQq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T14:33:50.800Z", "modifiedAt": null, "url": null, "title": "Responses to Catastrophic AGI Risk: A Survey", "slug": "responses-to-catastrophic-agi-risk-a-survey", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:39.664Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EAp3AQJv8dzTqAdKW/responses-to-catastrophic-agi-risk-a-survey", "pageUrlRelative": "/posts/EAp3AQJv8dzTqAdKW/responses-to-catastrophic-agi-risk-a-survey", "linkUrl": "https://www.lesswrong.com/posts/EAp3AQJv8dzTqAdKW/responses-to-catastrophic-agi-risk-a-survey", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Responses%20to%20Catastrophic%20AGI%20Risk%3A%20A%20Survey&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AResponses%20to%20Catastrophic%20AGI%20Risk%3A%20A%20Survey%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEAp3AQJv8dzTqAdKW%2Fresponses-to-catastrophic-agi-risk-a-survey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Responses%20to%20Catastrophic%20AGI%20Risk%3A%20A%20Survey%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEAp3AQJv8dzTqAdKW%2Fresponses-to-catastrophic-agi-risk-a-survey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEAp3AQJv8dzTqAdKW%2Fresponses-to-catastrophic-agi-risk-a-survey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<p>A great many Less Wrongers gave feedback on earlier drafts of \"Responses to Catastrophic AGI Risk: A Survey,\" which has now been <a href=\"http://intelligence.org/2013/07/08/responses-to-catastrophic-agi-risk-a-survey/\">released</a>. This is the preferred discussion page for the paper.</p>\n<p>The report, co-authored by past MIRI researcher Kaj Sotala and University of Louisville&rsquo;s Roman Yampolskiy, is a summary of the extant literature (250+ references) on AGI risk, and can serve either as a guide for researchers or as an introduction for the uninitiated.</p>\n<p>Here is the abstract:</p>\n<blockquote>\n<p>Many researchers have argued that humanity will create artificial general intelligence (AGI) within the next twenty to one hundred years. It has been suggested that AGI may pose a catastrophic risk to humanity. After summarizing the arguments for why AGI may pose such a risk, we survey the field&rsquo;s proposed responses to AGI risk. We consider societal proposals, proposals for external constraints on AGI behaviors, and proposals for creating AGIs that are safe due to their internal design.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ZFrgTgzwEfStg26JL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EAp3AQJv8dzTqAdKW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 17, "extendedScore": null, "score": 1.2590068061369109e-06, "legacy": true, "legacyId": "23238", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T16:22:57.508Z", "modifiedAt": null, "url": null, "title": "Meetup : Zagreb LW meetup", "slug": "meetup-zagreb-lw-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:52.598Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "morrel", "createdAt": "2013-07-04T17:36:44.083Z", "isAdmin": false, "displayName": "morrel"}, "userId": "Xdtoje5pFmqC2CY6y", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HqqtdMjQxyGkZmKXq/meetup-zagreb-lw-meetup", "pageUrlRelative": "/posts/HqqtdMjQxyGkZmKXq/meetup-zagreb-lw-meetup", "linkUrl": "https://www.lesswrong.com/posts/HqqtdMjQxyGkZmKXq/meetup-zagreb-lw-meetup", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Zagreb%20LW%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Zagreb%20LW%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHqqtdMjQxyGkZmKXq%2Fmeetup-zagreb-lw-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Zagreb%20LW%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHqqtdMjQxyGkZmKXq%2Fmeetup-zagreb-lw-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHqqtdMjQxyGkZmKXq%2Fmeetup-zagreb-lw-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/og'>Zagreb LW meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">13 July 2013 03:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\"> CAFFE BAR KOLDING, Ulica Petra Berislavi\u0107a 8, 10000, Zagreb, Kroatia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I\u2019m visiting Zagreb, and I would really enjoy meeting any LWers there. There are definitely some Croatian readers here, so let\u2019s have a meetup and see how many show up!</p>\n\n<p>I\u2019m going to spend at least two hours sitting in <a href=\"http://www.kolding.hr/caffe/\" rel=\"nofollow\">Kolding</a> waiting for you. To find me, look for a sign that says \"LW\". You\u2019re completely welcome regardless of how long you\u2019ve been reading Less Wrong. If enough people show up, we can plan more meetups and I can tell you inspiring tales of Finnish meetups!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/og'>Zagreb LW meetup</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HqqtdMjQxyGkZmKXq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1.2590929606535207e-06, "legacy": true, "legacyId": "23240", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Zagreb_LW_meetup\">Discussion article for the meetup : <a href=\"/meetups/og\">Zagreb LW meetup</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">13 July 2013 03:00:00PM (+0300)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\"> CAFFE BAR KOLDING, Ulica Petra Berislavi\u0107a 8, 10000, Zagreb, Kroatia</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>I\u2019m visiting Zagreb, and I would really enjoy meeting any LWers there. There are definitely some Croatian readers here, so let\u2019s have a meetup and see how many show up!</p>\n\n<p>I\u2019m going to spend at least two hours sitting in <a href=\"http://www.kolding.hr/caffe/\" rel=\"nofollow\">Kolding</a> waiting for you. To find me, look for a sign that says \"LW\". You\u2019re completely welcome regardless of how long you\u2019ve been reading Less Wrong. If enough people show up, we can plan more meetups and I can tell you inspiring tales of Finnish meetups!</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Zagreb_LW_meetup1\">Discussion article for the meetup : <a href=\"/meetups/og\">Zagreb LW meetup</a></h2>", "sections": [{"title": "Discussion article for the meetup : Zagreb LW meetup", "anchor": "Discussion_article_for_the_meetup___Zagreb_LW_meetup", "level": 1}, {"title": "Discussion article for the meetup : Zagreb LW meetup", "anchor": "Discussion_article_for_the_meetup___Zagreb_LW_meetup1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "3 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-08T21:44:42.052Z", "modifiedAt": null, "url": null, "title": "Strategic Bestseller: Taking the Blog Path (4HS002)", "slug": "strategic-bestseller-taking-the-blog-path-4hs002", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:38.801Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Neotenic", "createdAt": "2013-03-04T02:28:23.403Z", "isAdmin": false, "displayName": "Neotenic"}, "userId": "qMgZoftatigAeMMhL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/vGZQXgEpPqwp6HecX/strategic-bestseller-taking-the-blog-path-4hs002", "pageUrlRelative": "/posts/vGZQXgEpPqwp6HecX/strategic-bestseller-taking-the-blog-path-4hs002", "linkUrl": "https://www.lesswrong.com/posts/vGZQXgEpPqwp6HecX/strategic-bestseller-taking-the-blog-path-4hs002", "postedAtFormatted": "Monday, July 8th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Strategic%20Bestseller%3A%20Taking%20the%20Blog%20Path%20(4HS002)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStrategic%20Bestseller%3A%20Taking%20the%20Blog%20Path%20(4HS002)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvGZQXgEpPqwp6HecX%2Fstrategic-bestseller-taking-the-blog-path-4hs002%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Strategic%20Bestseller%3A%20Taking%20the%20Blog%20Path%20(4HS002)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvGZQXgEpPqwp6HecX%2Fstrategic-bestseller-taking-the-blog-path-4hs002", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FvGZQXgEpPqwp6HecX%2Fstrategic-bestseller-taking-the-blog-path-4hs002", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1515, "htmlBody": "<blockquote><address>\"The scariest moment is just before you start\"</address><address>\"I think timid writers like the passive voice for the same reason timid lovers like passive<br />partners. The passive voice is safe.\"</address><address> - Stephen King</address><address><br /></address></blockquote>\n<address>Follow-up to: <a href=\"/lw/hoq/how_can_i_strategically_write_a_complex/\">How can I strategically write a complex bestseller? </a><br /></address>\n<h5>2:27 PM, Mexico City, 08 July 2013</h5>\n<p><strong>The Blog Path and the Time Dimension</strong></p>\n<p>Robin Hanson recently said that writing a book feels lonelier than writing blog posts. Blog posts have many features that books will never have. Not only the obvious ones such as instantaneous gratification, being able to complete a chunk of work in one sitting, and being able to <em>show</em> you are actually doing something, not just claiming you are. Blogs also partition time in a way that makes a primate brain comfortable, both from the reader's and the writer's perspective. But in my case the most important feature of blogs is that <em>generate and test</em> and <em>trial and error</em> are easy to do.&nbsp; So after my first post here, and weeks solving many of the surrounding problems that could impede me from moving forward, I decided to go through the beaten track and blog my way into a bestseller.</p>\n<p><span style=\"color: #000000;\"><br /></span></p>\n<p><strong>The Challenges Theme</strong></p>\n<p>The theme of the blog is self challenges, and it envisions the public that enjoys Saturday Morning Breakfast Cereal, with a side of A J Jacobs. It begins by the <a href=\"http://fourhourscience.com/2013/07/08/first-challenge-stop-learning-start-doing/\">#50: Stop Learning, Start Doing.<br /></a></p>\n<blockquote>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\">This is the first post, so let&rsquo;s cut to the chase: In this blog we&rsquo;ll be going through a series of 50 challenges. Whatever you want to do, let&rsquo;s do this together. You like A. J. Jacobs and Tim Ferriss? That&rsquo;s a good start. You want to deal with your big picture question too? On top of that you like Science and Philosophy? You&rsquo;ve come to the right place, but don&rsquo;t take a seat yet, this is not a place to rest your gaze and get your warm fuzzy feeling inside by making a comment. This is a place to do.</p>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\"><strong style=\"border: 0px; font-family: inherit; font-size: 14px; font-style: inherit; font-weight: bold; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear;\">All you&rsquo;ll need prior to reading this blog is linked below:</strong></p>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\">You want to be one of the few<span class=\"Apple-converted-space\">&nbsp;</span><a style=\"border: 0px; font-family: inherit; font-size: 14px; font-style: inherit; font-weight: inherit; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #265e15; text-decoration: none; -webkit-transition: all 0.3s linear;\" title=\"You don't want to be submissive? Then also don't be authoritarian! \" href=\"http://www.edge.org/response-detail/23876\">Self-Actualizers</a><span class=\"Apple-converted-space\">&nbsp;</span>out there? This won&rsquo;t be any easy, and though we&rsquo;ll make the journey together, no one besides you can do it for you.</p>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\">But before we start, there are Six things you need to know, and they&rsquo;re gonna hurt like few things you&nbsp;<span class=\"Apple-converted-space\"><a href=\"http://fourhourscience.com/2013/07/08/first-challenge-stop-learning-start-doing/\">(... and it continues from here)</a></span></p>\n</blockquote>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\"><strong><span style=\"color: #000000;\"><br />Previous LW Post Comments</span> <a href=\"/lw/hoq/how_can_i_strategically_write_a_complex/#comments\">(ordered by upvotes)</a>:</strong></p>\n<p>Omid said that if writing is like music, being a bestseller is mostly about lu<span style=\"color: #000000;\">ck. Partially (0.5) I concur, but it seems to me that randomness in music interest is mostly dominated by <a href=\"http://www.hirhome.com/academic/hen%26gil.pdf\">prestige considerations</a> from separate domains.</span></p>\n<p><span style=\"color: #000000;\"><span style=\"color: #000000;\">Trevor Blake told his story and made clear that only writing is writing, talking about it, or even what I'm doing here, writing about it, isn't it. That seemed like an important downward spiral to keep track of. It explains why these LW posts will be less frequent than I thought before.</span></span></p>\n<p><span style=\"color: #000000;\"><span style=\"color: #000000;\"><span style=\"color: #000000;\">Gwern and Pjeby had a long discussion about book stats and likelihoods of making bestselling lists. It is clear that it is very hard. But it made me feel it is less hard than I thought before. </span></span></span></p>\n<p><span style=\"color: #000000;\">ChristianKI asked the words per day question. I'll respond by saying that I read+write more than six hours a day, which is Stephen King's suggested time in his \"On Writing\"</span></p>\n<p><span style=\"color: #000000;\">Michaelos and Qiaochu_Yuan suggested a mixed nagging strategy, getting someone close to me to nag me about writing while <em>also </em>beeminding it. This seems very important. Beeminder is set, and feel free to nag me in private messages if you are reading this far from the date it was written. I'll get a friend whom I see a lot, and a sexy lady, and an authority figure, to nag me every once in a while. So whether I'm feeling gregarious, romantically infatuated or seeking validation, there will always be a chance that writing is the emotionally correct thing to do.</span></p>\n<p>Finally, and of course there will never be time to respond to every comment here, though there might in the blog itself: Viliam_Bur devised \"on the fly\" a strategy, which nicely coincides with what I'm doing, except in that outlining the book is something I'll do after a few blog posts, now that this new \"blog post\" element entered the book agenda. Viliam also mentioned humans love reading stories, and the blogs next post will be one of my stories.</p>\n<p>&nbsp;</p>\n<p><strong>Getting informed about what does and doesn't work</strong></p>\n<p>Last post I said this post would contain a few things, among them \"(d) Gather that information\" in Salamon's list of strategic things to do in a project pursuit. From the information I got uptill now, including comments, posts in LW and asking authors by email, things that influence selling odds in non-fiction in a good way are, in no particular order:</p>\n<p>1) Being famous<br />2) Writing a lot<br />3) Luck<br />4) Being a professor in a prestigious university<br />5) Passion<br />6) A wide circle of influence<br />7) Having a 1000 true fans, who'll buy your stuff because it is yours <br />8) Knowing your Grammar, and when to ignore it<br />9) Ignoring 80% of the criticism you receive <br />(those would be the \"If I can't have it, so can't you\" kind of critics, or just naturally spiteful individuals)<br />10) Paying five times more attention to the remaining 20%<br />11) If your reader says your writing is confusing, it is, by definition, confusing <br />12) Dealing with topics in a way that interests many, but focusing on your idealized one reader<br />13) Understand that lacking the level of obsession and resources used to promote The Four Hour Workweek, the journey could be as long as writing three or four books before making it big, or five hundred blog posts. It helps that I'm riding the four hour brand.<br />15) Using your strengths however you can <br />In my case I intend to use my \"sure, naked dancing in public citing horoscopes sounds ok to me\" strength, and also however many stories of unbelievable days this lack of embarrassment has given me. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Next LW&nbsp; Post</strong></p>\n<p>Before the next LW post I intend to copy Svi's idea of <a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/\">using TDT for a personal hacking</a> experience, and also do the same thing with other unusual ideas that pop up in LW frequently. Instead of taking advice from something in LW that is specifically about strategic thinking, which I'm already doing with<em> Great Courses</em> lectures+Salamon's post, I'll just try to see how to administer things like TDT, Everett, Timeless Physics, AIXI, Newcomb, Iterated Prisoner Dilemma and PrudentBot into effective writing - &iquest;or should I call it effective bestselling now that I know writing itself is but the tip of the iceberg?. I have no idea how to do that transposition, but when last here I exposed my goals, and now it doesn't seem that embarrassing to do it anymore.&nbsp;</p>\n<p>Last, I ask a favor with a story:</p>\n<p><em>There is a one domain I never felt like learning more about. Seeking for truth is a noble goal, but some truths are <a href=\"http://www.nickbostrom.com/information-hazards.pdf&lrm;\">information hazards</a>, and I always had the impression that music, for me, was a dark terrain. It feels like the more I know - from almost nothing - about music, about structure, math, chords, composition, harmony, style, it all boils down to \"unweaving the rainbow\" in Dawkins' parlance. It detracts from the experience. Going to a music show for me is a torture, for the last thing I want to associate music with is a bunch of humans making coordinated physical motions in complex devices that cause the air to oscillate. I want music to be what makes my eyes teary when a Myiazaki's character finally saves the forgotten forest from the mountain spirit. Music should be a memoir of my grandma bringing me as a child to bed while Vivaldi's Spring surrounded the bed. By the same token, there are many details of people's lives we are better off unaware of, and in the case of a blogger, or a writer, you frequently just don't want to know the details, how easy or hard it was for her to write, or how long does she usually take in the shower. Most people are not hardcore epistemic rationalists, and I'd prefer that those didn't find any link, mention or pointer from the blog comments to the LW posts about it. Perhaps not so much in this community, but mystery is, and will <a href=\"/lw/xo/justified_expectation_of_pleasant_surprises/\">forever remain</a>, an important component in excitement and interest.&nbsp; &nbsp; &nbsp;&nbsp; </em></p>\n<p>I'll finish off as I did before, by mentioning what this is all about: I don't know which LW posts contain the most compact, memorable or effective techniques for winning at being strategic, but I'm hoping by the end of this process the territory is better mapped for those who'd like to follow suit. Or point and laugh.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "vGZQXgEpPqwp6HecX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 1.2593470688053928e-06, "legacy": true, "legacyId": "23242", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote><address>\"The scariest moment is just before you start\"</address><address>\"I think timid writers like the passive voice for the same reason timid lovers like passive<br>partners. The passive voice is safe.\"</address><address> - Stephen King</address><address><br></address></blockquote>\n<address>Follow-up to: <a href=\"/lw/hoq/how_can_i_strategically_write_a_complex/\">How can I strategically write a complex bestseller? </a><br></address>\n<h5>2:27 PM, Mexico City, 08 July 2013</h5>\n<p><strong id=\"The_Blog_Path_and_the_Time_Dimension\">The Blog Path and the Time Dimension</strong></p>\n<p>Robin Hanson recently said that writing a book feels lonelier than writing blog posts. Blog posts have many features that books will never have. Not only the obvious ones such as instantaneous gratification, being able to complete a chunk of work in one sitting, and being able to <em>show</em> you are actually doing something, not just claiming you are. Blogs also partition time in a way that makes a primate brain comfortable, both from the reader's and the writer's perspective. But in my case the most important feature of blogs is that <em>generate and test</em> and <em>trial and error</em> are easy to do.&nbsp; So after my first post here, and weeks solving many of the surrounding problems that could impede me from moving forward, I decided to go through the beaten track and blog my way into a bestseller.</p>\n<p><span style=\"color: #000000;\"><br></span></p>\n<p><strong id=\"The_Challenges_Theme\">The Challenges Theme</strong></p>\n<p>The theme of the blog is self challenges, and it envisions the public that enjoys Saturday Morning Breakfast Cereal, with a side of A J Jacobs. It begins by the <a href=\"http://fourhourscience.com/2013/07/08/first-challenge-stop-learning-start-doing/\">#50: Stop Learning, Start Doing.<br></a></p>\n<blockquote>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\">This is the first post, so let\u2019s cut to the chase: In this blog we\u2019ll be going through a series of 50 challenges. Whatever you want to do, let\u2019s do this together. You like A. J. Jacobs and Tim Ferriss? That\u2019s a good start. You want to deal with your big picture question too? On top of that you like Science and Philosophy? You\u2019ve come to the right place, but don\u2019t take a seat yet, this is not a place to rest your gaze and get your warm fuzzy feeling inside by making a comment. This is a place to do.</p>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\"><strong style=\"border: 0px; font-family: inherit; font-size: 14px; font-style: inherit; font-weight: bold; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear;\" id=\"All_you_ll_need_prior_to_reading_this_blog_is_linked_below_\">All you\u2019ll need prior to reading this blog is linked below:</strong></p>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\">You want to be one of the few<span class=\"Apple-converted-space\">&nbsp;</span><a style=\"border: 0px; font-family: inherit; font-size: 14px; font-style: inherit; font-weight: inherit; margin: 0px; outline: 0px; padding: 0px; vertical-align: baseline; color: #265e15; text-decoration: none; -webkit-transition: all 0.3s linear;\" title=\"You don't want to be submissive? Then also don't be authoritarian! \" href=\"http://www.edge.org/response-detail/23876\">Self-Actualizers</a><span class=\"Apple-converted-space\">&nbsp;</span>out there? This won\u2019t be any easy, and though we\u2019ll make the journey together, no one besides you can do it for you.</p>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\">But before we start, there are Six things you need to know, and they\u2019re gonna hurt like few things you&nbsp;<span class=\"Apple-converted-space\"><a href=\"http://fourhourscience.com/2013/07/08/first-challenge-stop-learning-start-doing/\">(... and it continues from here)</a></span></p>\n</blockquote>\n<p style=\"border: 0px; font-family: 'Open Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; font-style: normal; font-weight: normal; margin: 0px 0px 1.5em; outline: 0px; padding: 0px; vertical-align: baseline; -webkit-transition: opacity 0.3s linear; color: #444444; font-variant: normal; letter-spacing: normal; line-height: 23px; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-size-adjust: auto; -webkit-text-stroke-width: 0px; background-color: #ffffff;\"><strong id=\"Previous_LW_Post_Comments__ordered_by_upvotes__\"><span style=\"color: #000000;\"><br>Previous LW Post Comments</span> <a href=\"/lw/hoq/how_can_i_strategically_write_a_complex/#comments\">(ordered by upvotes)</a>:</strong></p>\n<p>Omid said that if writing is like music, being a bestseller is mostly about lu<span style=\"color: #000000;\">ck. Partially (0.5) I concur, but it seems to me that randomness in music interest is mostly dominated by <a href=\"http://www.hirhome.com/academic/hen%26gil.pdf\">prestige considerations</a> from separate domains.</span></p>\n<p><span style=\"color: #000000;\"><span style=\"color: #000000;\">Trevor Blake told his story and made clear that only writing is writing, talking about it, or even what I'm doing here, writing about it, isn't it. That seemed like an important downward spiral to keep track of. It explains why these LW posts will be less frequent than I thought before.</span></span></p>\n<p><span style=\"color: #000000;\"><span style=\"color: #000000;\"><span style=\"color: #000000;\">Gwern and Pjeby had a long discussion about book stats and likelihoods of making bestselling lists. It is clear that it is very hard. But it made me feel it is less hard than I thought before. </span></span></span></p>\n<p><span style=\"color: #000000;\">ChristianKI asked the words per day question. I'll respond by saying that I read+write more than six hours a day, which is Stephen King's suggested time in his \"On Writing\"</span></p>\n<p><span style=\"color: #000000;\">Michaelos and Qiaochu_Yuan suggested a mixed nagging strategy, getting someone close to me to nag me about writing while <em>also </em>beeminding it. This seems very important. Beeminder is set, and feel free to nag me in private messages if you are reading this far from the date it was written. I'll get a friend whom I see a lot, and a sexy lady, and an authority figure, to nag me every once in a while. So whether I'm feeling gregarious, romantically infatuated or seeking validation, there will always be a chance that writing is the emotionally correct thing to do.</span></p>\n<p>Finally, and of course there will never be time to respond to every comment here, though there might in the blog itself: Viliam_Bur devised \"on the fly\" a strategy, which nicely coincides with what I'm doing, except in that outlining the book is something I'll do after a few blog posts, now that this new \"blog post\" element entered the book agenda. Viliam also mentioned humans love reading stories, and the blogs next post will be one of my stories.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Getting_informed_about_what_does_and_doesn_t_work\">Getting informed about what does and doesn't work</strong></p>\n<p>Last post I said this post would contain a few things, among them \"(d) Gather that information\" in Salamon's list of strategic things to do in a project pursuit. From the information I got uptill now, including comments, posts in LW and asking authors by email, things that influence selling odds in non-fiction in a good way are, in no particular order:</p>\n<p>1) Being famous<br>2) Writing a lot<br>3) Luck<br>4) Being a professor in a prestigious university<br>5) Passion<br>6) A wide circle of influence<br>7) Having a 1000 true fans, who'll buy your stuff because it is yours <br>8) Knowing your Grammar, and when to ignore it<br>9) Ignoring 80% of the criticism you receive <br>(those would be the \"If I can't have it, so can't you\" kind of critics, or just naturally spiteful individuals)<br>10) Paying five times more attention to the remaining 20%<br>11) If your reader says your writing is confusing, it is, by definition, confusing <br>12) Dealing with topics in a way that interests many, but focusing on your idealized one reader<br>13) Understand that lacking the level of obsession and resources used to promote The Four Hour Workweek, the journey could be as long as writing three or four books before making it big, or five hundred blog posts. It helps that I'm riding the four hour brand.<br>15) Using your strengths however you can <br>In my case I intend to use my \"sure, naked dancing in public citing horoscopes sounds ok to me\" strength, and also however many stories of unbelievable days this lack of embarrassment has given me. &nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"Next_LW__Post\">Next LW&nbsp; Post</strong></p>\n<p>Before the next LW post I intend to copy Svi's idea of <a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/\">using TDT for a personal hacking</a> experience, and also do the same thing with other unusual ideas that pop up in LW frequently. Instead of taking advice from something in LW that is specifically about strategic thinking, which I'm already doing with<em> Great Courses</em> lectures+Salamon's post, I'll just try to see how to administer things like TDT, Everett, Timeless Physics, AIXI, Newcomb, Iterated Prisoner Dilemma and PrudentBot into effective writing - \u00bfor should I call it effective bestselling now that I know writing itself is but the tip of the iceberg?. I have no idea how to do that transposition, but when last here I exposed my goals, and now it doesn't seem that embarrassing to do it anymore.&nbsp;</p>\n<p>Last, I ask a favor with a story:</p>\n<p><em>There is a one domain I never felt like learning more about. Seeking for truth is a noble goal, but some truths are <a href=\"http://www.nickbostrom.com/information-hazards.pdf\u200e\">information hazards</a>, and I always had the impression that music, for me, was a dark terrain. It feels like the more I know - from almost nothing - about music, about structure, math, chords, composition, harmony, style, it all boils down to \"unweaving the rainbow\" in Dawkins' parlance. It detracts from the experience. Going to a music show for me is a torture, for the last thing I want to associate music with is a bunch of humans making coordinated physical motions in complex devices that cause the air to oscillate. I want music to be what makes my eyes teary when a Myiazaki's character finally saves the forgotten forest from the mountain spirit. Music should be a memoir of my grandma bringing me as a child to bed while Vivaldi's Spring surrounded the bed. By the same token, there are many details of people's lives we are better off unaware of, and in the case of a blogger, or a writer, you frequently just don't want to know the details, how easy or hard it was for her to write, or how long does she usually take in the shower. Most people are not hardcore epistemic rationalists, and I'd prefer that those didn't find any link, mention or pointer from the blog comments to the LW posts about it. Perhaps not so much in this community, but mystery is, and will <a href=\"/lw/xo/justified_expectation_of_pleasant_surprises/\">forever remain</a>, an important component in excitement and interest.&nbsp; &nbsp; &nbsp;&nbsp; </em></p>\n<p>I'll finish off as I did before, by mentioning what this is all about: I don't know which LW posts contain the most compact, memorable or effective techniques for winning at being strategic, but I'm hoping by the end of this process the territory is better mapped for those who'd like to follow suit. Or point and laugh.</p>", "sections": [{"title": "The Blog Path and the Time Dimension", "anchor": "The_Blog_Path_and_the_Time_Dimension", "level": 1}, {"title": "The Challenges Theme", "anchor": "The_Challenges_Theme", "level": 1}, {"title": "All you\u2019ll need prior to reading this blog is linked below:", "anchor": "All_you_ll_need_prior_to_reading_this_blog_is_linked_below_", "level": 1}, {"title": "Previous LW Post Comments (ordered by upvotes):", "anchor": "Previous_LW_Post_Comments__ordered_by_upvotes__", "level": 1}, {"title": "Getting informed about what does and doesn't work", "anchor": "Getting_informed_about_what_does_and_doesn_t_work", "level": 1}, {"title": "Next LW\u00a0 Post", "anchor": "Next_LW__Post", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "2 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["dGkAL4PbihR2CvRfA", "scwoBEju75C45W5n3", "DGXvLNpiSYBeQ6TLW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T00:59:40.963Z", "modifiedAt": null, "url": null, "title": "Four Focus Areas of Effective Altruism", "slug": "four-focus-areas-of-effective-altruism", "viewCount": null, "lastCommentedAt": "2017-06-17T04:28:07.777Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JmmA2Mf5GrY9D6nQD/four-focus-areas-of-effective-altruism", "pageUrlRelative": "/posts/JmmA2Mf5GrY9D6nQD/four-focus-areas-of-effective-altruism", "linkUrl": "https://www.lesswrong.com/posts/JmmA2Mf5GrY9D6nQD/four-focus-areas-of-effective-altruism", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Four%20Focus%20Areas%20of%20Effective%20Altruism&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFour%20Focus%20Areas%20of%20Effective%20Altruism%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmmA2Mf5GrY9D6nQD%2Ffour-focus-areas-of-effective-altruism%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Four%20Focus%20Areas%20of%20Effective%20Altruism%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmmA2Mf5GrY9D6nQD%2Ffour-focus-areas-of-effective-altruism", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJmmA2Mf5GrY9D6nQD%2Ffour-focus-areas-of-effective-altruism", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1456, "htmlBody": "<p><img style=\"float: right; padding: 10px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2013/07/effective-altruism-small.jpg\" alt=\"\" />It was a pleasure to see all major strands of the <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">effective altruism movement</a> gathered in one place at last week's <a href=\"http://www.effectivealtruismsummit.com/\">Effective Altruism Summit</a>.</p>\n<p>Representatives from&nbsp;<a href=\"http://www.givewell.org/\">GiveWell</a>, <a href=\"http://www.thelifeyoucansave.org/\">The Life You Can Save</a>, <a href=\"http://80000hours.org/\">80,000 Hours</a>, <a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a>, <a href=\"http://www.effectiveanimalactivism.org/\">Effective Animal Altruism</a>,&nbsp;<a href=\"http://www.leverageresearch.org/\">Leverage Research</a>, the <a href=\"http://www.thehighimpactnetwork.org/\">Center for Applied Rationality</a>, and the <a href=\"http://intelligence.org/\">Machine Intelligence Research Institute</a> either attended or gave presentations.&nbsp;My thanks to Leverage Research&nbsp;for organizing and hosting the event!</p>\n<p>What do all these groups have in common? As <a href=\"http://en.wikipedia.org/wiki/Peter_Singer\">Peter Singer</a> said in&nbsp;<a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">his TED talk</a>, effective altruism \"combines both the heart and the head.\" The heart motivates us to be empathic and altruistic toward others, while the head can \"make sure that what [we] do is effective and well-directed,\" so that altruists can do not just&nbsp;<em>some</em> good but&nbsp;<em>as much good as possible</em>.</p>\n<p>Effective altruists (EAs) tend to:</p>\n<ol>\n<li><span style=\"line-height: 13px;\"><strong>Be globally altruistic</strong>:&nbsp;</span><span style=\"line-height: 13px;\">EAs care about people equally, regardless of location. Typically, the most cost-effective altruistic cause won't happen to be in one's home country.</span></li>\n<li><strong>Value consequences</strong>: EAs tend to value causes according to their consequences, whether those consequences are happiness, health, justice, fairness and/or other values.</li>\n<li><strong>Try to do as much good as possible</strong>: EAs don't just want to do <em>some</em> good; they want to do (roughly)&nbsp;<em>as much good as possible</em>. As such, they hope to devote their altruistic resources (time, money, energy, attention) to unusually cost-effective causes. (This <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">doesn't</a> necessarily mean that EAs think \"explicit\" cost effectiveness calculations are the best <em>method for&nbsp;figuring out</em> which causes are likely to do the most good.)</li>\n<li><strong>Think scientifically and quantitatively</strong>: EAs tend to be analytic, scientific, and quantitative when trying to figure out which causes <em>actually</em> do the most good.</li>\n<li><strong>Be willing to make significant life changes to be more effectively altruistic</strong>: As a result of their efforts to be more effective in their altruism, EAs often (1) change which charities they support financially, (2) change careers, (3) spend significant chunks of time investigating which causes are most cost-effective according to their values, or (4) make other significant life changes.</li>\n</ol>\n<p>Despite these similarities, EAs are a diverse bunch, and they focus their efforts on a variety of causes.</p>\n<p>Below are four popular focus areas of effective altruism, ordered roughly by how large and visible they appear to be at the moment. Many EAs work on several of these focus areas at once, due to uncertainty about both facts and values.</p>\n<p>Though labels and categories <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">have</a> <a href=\"http://www.paulgraham.com/identity.html\">their</a> <a href=\"http://www.psychologytoday.com/blog/alternative-truths/201005/why-its-dangerous-label-people\">dangers</a>, they can also enable <a href=\"http://en.wikipedia.org/wiki/Chunking_(psychology)\">chunking</a>, which has benefits for memory, learning, and communication. There are many other ways we might categorize the efforts of today's EAs; this is only one categorization.</p>\n<h4><a id=\"more\"></a><br /></h4>\n<h4>Focus Area 1: Poverty Reduction</h4>\n<p>Here, \"poverty reduction\" is meant in a broad sense that includes (e.g.) economic benefit, better health, and better education.</p>\n<p>Major organizations in this focus area include:</p>\n<ul>\n<li><a href=\"http://www.givewell.org/\">GiveWell</a>&nbsp;is home to the most rigorous research on charitable causes, especially poverty reduction and global health. Their current charity recommendations are the <a href=\"http://www.againstmalaria.com/\">Against Malaria Foundation</a>, <a href=\"http://www.givedirectly.org/\">GiveDirectly</a>, and the <a href=\"http://www3.imperial.ac.uk/schisto\">Schistosomiasis Control Initiative</a>. (Note that GiveWell also does quite a bit of \"meta effective altruism\"; see below.)</li>\n<li><a href=\"http://www.goodventures.org/\">Good Ventures</a>&nbsp;works closely with GiveWell.</li>\n<li><a href=\"http://www.thelifeyoucansave.org/\">The Life You Can Save</a>&nbsp;(TLYCS), named after Peter Singer's <a href=\"http://www.amazon.com/The-Life-You-Can-Save/dp/0812981561/\">book</a> on effective altruism, encourages people to pledge a fraction of their income to effective charities. TLYCS currently recommends GiveWell's recommended charities and <a href=\"http://www.thelifeyoucansave.org/WheretoDonate.aspx\">several others</a>.</li>\n<li><a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a>&nbsp;(GWWC) does some charity evaluation and also encourages people to pledge 10% of their income effective charities. GWWC currently recommends two of GiveWell's recommended charities and <a href=\"http://www.givingwhatwecan.org/where-to-give/recommended-charities\">two others</a>.</li>\n<li><a href=\"http://www.aidgrade.org/\">AidGrade</a> evaluates the cost effectiveness of poverty reduction causes, with less of a focus on individual organizations.</li>\n</ul>\n<p>In addition, some well-endowed foundations seem to have \"one foot\" in effective poverty reduction. For example, the <a href=\"http://www.gatesfoundation.org/\">Bill &amp; Melinda Gates Foundation</a> has funded many of the most cost-effective causes in the developing world (e.g. vaccinations),&nbsp;although it also funds less cost-effective-seeming interventions in the developed world.</p>\n<p>In the future, poverty reduction EAs might&nbsp;also focus on economic, political, or research-infrastructure changes that might achieve poverty reduction, global health, and educational improvements more&nbsp;indirectly, as when&nbsp;<a href=\"http://en.wikipedia.org/wiki/Chinese_economic_reform\">Chinese economic reforms</a>&nbsp;lifted hundreds of millions out of poverty. Though it is generally easier to evaluate the cost-effectiveness of direct efforts than that of indirect efforts, some groups (e.g. <a href=\"http://blog.givewell.org/2013/05/30/refining-the-goals-of-givewell-labs/\">GiveWell Labs</a>&nbsp;and&nbsp;<a href=\"http://www.vannevargroup.org/\">The Vannevar Group</a>) are beginning to evaluate the likely cost-effectiveness of these causes. &nbsp;</p>\n<h4><br /></h4>\n<h4>Focus Area 2: Meta Effective Altruism</h4>\n<p>Meta effective altruists focus less on specific causes and more on \"meta\" activities such as raising awareness of the importance of evidence-based altruism, helping EAs reach their potential, and doing research to help EAs decide which focus areas they should contribute to.</p>\n<p>Organizations in this focus area include:</p>\n<ul>\n<li><a href=\"http://80000hours.org/\">80,000 Hours</a>&nbsp;highlights the importance of helping the world effectively through one's career. They also offer personal counseling to help EAs choose a career and a set of causes to support.</li>\n<li>Explicitly, the&nbsp;<a href=\"http://rationality.org/\">Center for Applied Rationality</a>&nbsp;(CFAR) just trains people in rationality skills. But&nbsp;<em>de facto</em>&nbsp;they are especially focused on the application of rational thought to the practice of altruism, and are deeply embedded in the effective altruism community.</li>\n<li><a href=\"http://www.leverageresearch.org/\">Leverage Research</a> focuses on growing and empowering the EA movement, e.g. by running <a href=\"http://www.effectivealtruismsummit.com/\">Effective Altruism Summit</a>, by organizing the <a href=\"http://www.thehighimpactnetwork.org/\">THINK</a> student group network, and by searching for \"mind hacks\" (like the <a href=\"http://en.wikipedia.org/wiki/Method_of_loci\">memory palace</a>) that can make EAs more effective.</li>\n</ul>\n<p>Other people and organizations contribute to meta effective altruism, too. Paul Christiano examines effective altruism from a high level at <a href=\"http://rationalaltruist.com/\">Rational Altruist</a>. GiveWell and others often write about the <a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/\">ethics</a> and <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">epistemology</a> of effective altruism in addition to focusing on their chosen causes. And, of course, most EA organizations spend&nbsp;<em>some</em> resources growing the EA movement. &nbsp;</p>\n<h4><br /></h4>\n<h4>Focus Area 3: The Long-Term Future</h4>\n<p>Many EAs value future people roughly as much as currently-living people, and think that nearly all potential value is found in the well-being of the astronomical numbers of people who could populate the long-term future (<a href=\"http://intelligence.org/files/AstronomicalWaste.pdf\">Bostrom 2003</a>; <a href=\"https://sites.google.com/site/nbeckstead/research/Beckstead%2C%20Nick--On%20the%20Overwhelming%20Importance%20of%20Shaping%20the%20Far%20Future.pdf\">Beckstead 2013</a>). Future-focused EAs aim to somewhat-directly&nbsp;capture these \"astronomical benefits\" of the long-term future, e.g. via explicit efforts to <a href=\"http://www.existential-risk.org/concept.pdf\">reduce existential risk</a>.</p>\n<p>Organizations in this focus area include:</p>\n<ul>\n<li><span style=\"line-height: 13px;\">The <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a> at Oxford University is the primary hub of research on <a href=\"http://www.existential-risk.org/concept.pdf\">existential risk mitigation</a> within the effective altruism movement. (<a href=\"http://cser.org/\">CSER</a> may join it soon, if it gets funding.)</span></li>\n<li>The <a href=\"http://intelligence.org/\">Machine Intelligence Research Institute</a>&nbsp;focuses on doing the research needed for humanity to one day build <a href=\"http://en.wikipedia.org/wiki/Friendly_artificial_intelligence\">Friendly AI</a> that could make astronomical numbers of future people enormously better off. It also runs the <a href=\"/\">Less Wrong</a> group blog and forum, where much of today's EA analysis and discussion occurs.</li>\n</ul>\n<p>Other groups study particular existential risks (among other things), though perhaps not explicitly from the view of effective altruism. For example, NASA has spent time <a href=\"http://www.givewell.org/shallow/asteroid-detection\">identifying nearby asteroids</a> that could be an existential threat, and many organizations (e.g. <a href=\"http://gcrinstitute.org/\">GCRI</a>) study worst-case scenarios for climate change or nuclear warfare that <em>might</em> result in human extinction but are more likely to result in \"merely catastrophic\" damage.</p>\n<p>Some EAs (e.g.&nbsp;<a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">Holden Karnofsky</a>,&nbsp;<a href=\"http://rationalaltruist.com/2013/06/03/my-outlook/\">Paul Christiano</a>) have argued that even if nearly all value lies in the long-term future, focusing on nearer-term goals (e.g. effective poverty reduction or meta effective altruism) may be more likely to realize that value than more direct efforts.</p>\n<p>&nbsp;</p>\n<h4>Focus Area 4: Animal Suffering</h4>\n<p>Effective animal altruists are focused on reducing animal suffering in cost-effective ways. After all, animals vastly outnumber humans, and growing numbers of scientists <a href=\"http://en.wikipedia.org/wiki/Animal_consciousness#Cambridge_Declaration_on_Consciousness\">believe</a> that many animals <a href=\"http://en.wikipedia.org/wiki/Animal_consciousness\">consciously experience</a> pleasure and suffering.</p>\n<p>The only organization of this type so far (that I know of) is <a href=\"http://www.effectiveanimalactivism.org/\">Effective Animal Activism</a>, which currently recommends supporting <a href=\"http://thehumaneleague.com/\">The Humane League</a> and <a href=\"http://www.veganoutreach.org/\">Vegan Outreach</a>.</p>\n<p><em>Edit</em>: There is now also <a href=\"http://www.animal-ethics.org/\">Animal Ethics, Inc</a>.</p>\n<p>Major inspirations for those in this focus area include <a href=\"http://en.wikipedia.org/wiki/Peter_Singer\">Peter Singer</a>, <a href=\"http://en.wikipedia.org/wiki/David_Pearce_(philosopher)\">David Pearce</a>, and <a href=\"http://utilitarian-essays.com/\">Brian Tomasik</a>. &nbsp;</p>\n<h4><br /></h4>\n<h4>Other focus areas</h4>\n<p>I could perhaps have listed \"effective environmental altruism\" as focus area 5. The environmental movement <em>in general</em>&nbsp;is large and well-known, but I'm not aware of many effective altruists who take environmentalism to be the most important cause for them to work on, after closely investigating the above focus areas. In contrast, the groups and people named above&nbsp;tend to have influenced each other, and have considered all these focus areas explicitly. For this reason, I've left \"effective environmental altruism\" off the list, though perhaps a popular focus on effective environmental altruism could arise in the future.</p>\n<p>Other focus areas could later come to prominence, too.</p>\n<h4><br /></h4>\n<h4>Working together</h4>\n<p>I was pleased to see the EAs from different strands of the EA movement cooperating and learning from each other at the Effective Altruism Summit. Cooperation is crucial for growing the EA movement, so I hope that even if it&rsquo;s <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">not always easy</a>, EAs will \"go out of their way\" to cooperate and work together, no matter which focus areas they&rsquo;re sympathetic to.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Q9ASuEEoJWxT3RLMT": 2, "qAvbtzdG2A2RBn7in": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JmmA2Mf5GrY9D6nQD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 48, "baseScore": 67, "extendedScore": null, "score": 0.000185, "legacy": true, "legacyId": "23224", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 67, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><img style=\"float: right; padding: 10px;\" src=\"http://commonsenseatheism.com/wp-content/uploads/2013/07/effective-altruism-small.jpg\" alt=\"\">It was a pleasure to see all major strands of the <a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">effective altruism movement</a> gathered in one place at last week's <a href=\"http://www.effectivealtruismsummit.com/\">Effective Altruism Summit</a>.</p>\n<p>Representatives from&nbsp;<a href=\"http://www.givewell.org/\">GiveWell</a>, <a href=\"http://www.thelifeyoucansave.org/\">The Life You Can Save</a>, <a href=\"http://80000hours.org/\">80,000 Hours</a>, <a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a>, <a href=\"http://www.effectiveanimalactivism.org/\">Effective Animal Altruism</a>,&nbsp;<a href=\"http://www.leverageresearch.org/\">Leverage Research</a>, the <a href=\"http://www.thehighimpactnetwork.org/\">Center for Applied Rationality</a>, and the <a href=\"http://intelligence.org/\">Machine Intelligence Research Institute</a> either attended or gave presentations.&nbsp;My thanks to Leverage Research&nbsp;for organizing and hosting the event!</p>\n<p>What do all these groups have in common? As <a href=\"http://en.wikipedia.org/wiki/Peter_Singer\">Peter Singer</a> said in&nbsp;<a href=\"http://www.ted.com/talks/peter_singer_the_why_and_how_of_effective_altruism.html\">his TED talk</a>, effective altruism \"combines both the heart and the head.\" The heart motivates us to be empathic and altruistic toward others, while the head can \"make sure that what [we] do is effective and well-directed,\" so that altruists can do not just&nbsp;<em>some</em> good but&nbsp;<em>as much good as possible</em>.</p>\n<p>Effective altruists (EAs) tend to:</p>\n<ol>\n<li><span style=\"line-height: 13px;\"><strong>Be globally altruistic</strong>:&nbsp;</span><span style=\"line-height: 13px;\">EAs care about people equally, regardless of location. Typically, the most cost-effective altruistic cause won't happen to be in one's home country.</span></li>\n<li><strong>Value consequences</strong>: EAs tend to value causes according to their consequences, whether those consequences are happiness, health, justice, fairness and/or other values.</li>\n<li><strong>Try to do as much good as possible</strong>: EAs don't just want to do <em>some</em> good; they want to do (roughly)&nbsp;<em>as much good as possible</em>. As such, they hope to devote their altruistic resources (time, money, energy, attention) to unusually cost-effective causes. (This <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">doesn't</a> necessarily mean that EAs think \"explicit\" cost effectiveness calculations are the best <em>method for&nbsp;figuring out</em> which causes are likely to do the most good.)</li>\n<li><strong>Think scientifically and quantitatively</strong>: EAs tend to be analytic, scientific, and quantitative when trying to figure out which causes <em>actually</em> do the most good.</li>\n<li><strong>Be willing to make significant life changes to be more effectively altruistic</strong>: As a result of their efforts to be more effective in their altruism, EAs often (1) change which charities they support financially, (2) change careers, (3) spend significant chunks of time investigating which causes are most cost-effective according to their values, or (4) make other significant life changes.</li>\n</ol>\n<p>Despite these similarities, EAs are a diverse bunch, and they focus their efforts on a variety of causes.</p>\n<p>Below are four popular focus areas of effective altruism, ordered roughly by how large and visible they appear to be at the moment. Many EAs work on several of these focus areas at once, due to uncertainty about both facts and values.</p>\n<p>Though labels and categories <a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">have</a> <a href=\"http://www.paulgraham.com/identity.html\">their</a> <a href=\"http://www.psychologytoday.com/blog/alternative-truths/201005/why-its-dangerous-label-people\">dangers</a>, they can also enable <a href=\"http://en.wikipedia.org/wiki/Chunking_(psychology)\">chunking</a>, which has benefits for memory, learning, and communication. There are many other ways we might categorize the efforts of today's EAs; this is only one categorization.</p>\n<h4><a id=\"more\"></a><br></h4>\n<h4 id=\"Focus_Area_1__Poverty_Reduction\">Focus Area 1: Poverty Reduction</h4>\n<p>Here, \"poverty reduction\" is meant in a broad sense that includes (e.g.) economic benefit, better health, and better education.</p>\n<p>Major organizations in this focus area include:</p>\n<ul>\n<li><a href=\"http://www.givewell.org/\">GiveWell</a>&nbsp;is home to the most rigorous research on charitable causes, especially poverty reduction and global health. Their current charity recommendations are the <a href=\"http://www.againstmalaria.com/\">Against Malaria Foundation</a>, <a href=\"http://www.givedirectly.org/\">GiveDirectly</a>, and the <a href=\"http://www3.imperial.ac.uk/schisto\">Schistosomiasis Control Initiative</a>. (Note that GiveWell also does quite a bit of \"meta effective altruism\"; see below.)</li>\n<li><a href=\"http://www.goodventures.org/\">Good Ventures</a>&nbsp;works closely with GiveWell.</li>\n<li><a href=\"http://www.thelifeyoucansave.org/\">The Life You Can Save</a>&nbsp;(TLYCS), named after Peter Singer's <a href=\"http://www.amazon.com/The-Life-You-Can-Save/dp/0812981561/\">book</a> on effective altruism, encourages people to pledge a fraction of their income to effective charities. TLYCS currently recommends GiveWell's recommended charities and <a href=\"http://www.thelifeyoucansave.org/WheretoDonate.aspx\">several others</a>.</li>\n<li><a href=\"http://www.givingwhatwecan.org/\">Giving What We Can</a>&nbsp;(GWWC) does some charity evaluation and also encourages people to pledge 10% of their income effective charities. GWWC currently recommends two of GiveWell's recommended charities and <a href=\"http://www.givingwhatwecan.org/where-to-give/recommended-charities\">two others</a>.</li>\n<li><a href=\"http://www.aidgrade.org/\">AidGrade</a> evaluates the cost effectiveness of poverty reduction causes, with less of a focus on individual organizations.</li>\n</ul>\n<p>In addition, some well-endowed foundations seem to have \"one foot\" in effective poverty reduction. For example, the <a href=\"http://www.gatesfoundation.org/\">Bill &amp; Melinda Gates Foundation</a> has funded many of the most cost-effective causes in the developing world (e.g. vaccinations),&nbsp;although it also funds less cost-effective-seeming interventions in the developed world.</p>\n<p>In the future, poverty reduction EAs might&nbsp;also focus on economic, political, or research-infrastructure changes that might achieve poverty reduction, global health, and educational improvements more&nbsp;indirectly, as when&nbsp;<a href=\"http://en.wikipedia.org/wiki/Chinese_economic_reform\">Chinese economic reforms</a>&nbsp;lifted hundreds of millions out of poverty. Though it is generally easier to evaluate the cost-effectiveness of direct efforts than that of indirect efforts, some groups (e.g. <a href=\"http://blog.givewell.org/2013/05/30/refining-the-goals-of-givewell-labs/\">GiveWell Labs</a>&nbsp;and&nbsp;<a href=\"http://www.vannevargroup.org/\">The Vannevar Group</a>) are beginning to evaluate the likely cost-effectiveness of these causes. &nbsp;</p>\n<h4><br></h4>\n<h4 id=\"Focus_Area_2__Meta_Effective_Altruism\">Focus Area 2: Meta Effective Altruism</h4>\n<p>Meta effective altruists focus less on specific causes and more on \"meta\" activities such as raising awareness of the importance of evidence-based altruism, helping EAs reach their potential, and doing research to help EAs decide which focus areas they should contribute to.</p>\n<p>Organizations in this focus area include:</p>\n<ul>\n<li><a href=\"http://80000hours.org/\">80,000 Hours</a>&nbsp;highlights the importance of helping the world effectively through one's career. They also offer personal counseling to help EAs choose a career and a set of causes to support.</li>\n<li>Explicitly, the&nbsp;<a href=\"http://rationality.org/\">Center for Applied Rationality</a>&nbsp;(CFAR) just trains people in rationality skills. But&nbsp;<em>de facto</em>&nbsp;they are especially focused on the application of rational thought to the practice of altruism, and are deeply embedded in the effective altruism community.</li>\n<li><a href=\"http://www.leverageresearch.org/\">Leverage Research</a> focuses on growing and empowering the EA movement, e.g. by running <a href=\"http://www.effectivealtruismsummit.com/\">Effective Altruism Summit</a>, by organizing the <a href=\"http://www.thehighimpactnetwork.org/\">THINK</a> student group network, and by searching for \"mind hacks\" (like the <a href=\"http://en.wikipedia.org/wiki/Method_of_loci\">memory palace</a>) that can make EAs more effective.</li>\n</ul>\n<p>Other people and organizations contribute to meta effective altruism, too. Paul Christiano examines effective altruism from a high level at <a href=\"http://rationalaltruist.com/\">Rational Altruist</a>. GiveWell and others often write about the <a href=\"http://blog.givewell.org/2013/06/11/the-moral-case-for-giving-doesnt-rely-on-questionable-quantitative-estimates/\">ethics</a> and <a href=\"http://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/\">epistemology</a> of effective altruism in addition to focusing on their chosen causes. And, of course, most EA organizations spend&nbsp;<em>some</em> resources growing the EA movement. &nbsp;</p>\n<h4><br></h4>\n<h4 id=\"Focus_Area_3__The_Long_Term_Future\">Focus Area 3: The Long-Term Future</h4>\n<p>Many EAs value future people roughly as much as currently-living people, and think that nearly all potential value is found in the well-being of the astronomical numbers of people who could populate the long-term future (<a href=\"http://intelligence.org/files/AstronomicalWaste.pdf\">Bostrom 2003</a>; <a href=\"https://sites.google.com/site/nbeckstead/research/Beckstead%2C%20Nick--On%20the%20Overwhelming%20Importance%20of%20Shaping%20the%20Far%20Future.pdf\">Beckstead 2013</a>). Future-focused EAs aim to somewhat-directly&nbsp;capture these \"astronomical benefits\" of the long-term future, e.g. via explicit efforts to <a href=\"http://www.existential-risk.org/concept.pdf\">reduce existential risk</a>.</p>\n<p>Organizations in this focus area include:</p>\n<ul>\n<li><span style=\"line-height: 13px;\">The <a href=\"http://www.fhi.ox.ac.uk/\">Future of Humanity Institute</a> at Oxford University is the primary hub of research on <a href=\"http://www.existential-risk.org/concept.pdf\">existential risk mitigation</a> within the effective altruism movement. (<a href=\"http://cser.org/\">CSER</a> may join it soon, if it gets funding.)</span></li>\n<li>The <a href=\"http://intelligence.org/\">Machine Intelligence Research Institute</a>&nbsp;focuses on doing the research needed for humanity to one day build <a href=\"http://en.wikipedia.org/wiki/Friendly_artificial_intelligence\">Friendly AI</a> that could make astronomical numbers of future people enormously better off. It also runs the <a href=\"/\">Less Wrong</a> group blog and forum, where much of today's EA analysis and discussion occurs.</li>\n</ul>\n<p>Other groups study particular existential risks (among other things), though perhaps not explicitly from the view of effective altruism. For example, NASA has spent time <a href=\"http://www.givewell.org/shallow/asteroid-detection\">identifying nearby asteroids</a> that could be an existential threat, and many organizations (e.g. <a href=\"http://gcrinstitute.org/\">GCRI</a>) study worst-case scenarios for climate change or nuclear warfare that <em>might</em> result in human extinction but are more likely to result in \"merely catastrophic\" damage.</p>\n<p>Some EAs (e.g.&nbsp;<a href=\"http://blog.givewell.org/2013/05/15/flow-through-effects/\">Holden Karnofsky</a>,&nbsp;<a href=\"http://rationalaltruist.com/2013/06/03/my-outlook/\">Paul Christiano</a>) have argued that even if nearly all value lies in the long-term future, focusing on nearer-term goals (e.g. effective poverty reduction or meta effective altruism) may be more likely to realize that value than more direct efforts.</p>\n<p>&nbsp;</p>\n<h4 id=\"Focus_Area_4__Animal_Suffering\">Focus Area 4: Animal Suffering</h4>\n<p>Effective animal altruists are focused on reducing animal suffering in cost-effective ways. After all, animals vastly outnumber humans, and growing numbers of scientists <a href=\"http://en.wikipedia.org/wiki/Animal_consciousness#Cambridge_Declaration_on_Consciousness\">believe</a> that many animals <a href=\"http://en.wikipedia.org/wiki/Animal_consciousness\">consciously experience</a> pleasure and suffering.</p>\n<p>The only organization of this type so far (that I know of) is <a href=\"http://www.effectiveanimalactivism.org/\">Effective Animal Activism</a>, which currently recommends supporting <a href=\"http://thehumaneleague.com/\">The Humane League</a> and <a href=\"http://www.veganoutreach.org/\">Vegan Outreach</a>.</p>\n<p><em>Edit</em>: There is now also <a href=\"http://www.animal-ethics.org/\">Animal Ethics, Inc</a>.</p>\n<p>Major inspirations for those in this focus area include <a href=\"http://en.wikipedia.org/wiki/Peter_Singer\">Peter Singer</a>, <a href=\"http://en.wikipedia.org/wiki/David_Pearce_(philosopher)\">David Pearce</a>, and <a href=\"http://utilitarian-essays.com/\">Brian Tomasik</a>. &nbsp;</p>\n<h4><br></h4>\n<h4 id=\"Other_focus_areas\">Other focus areas</h4>\n<p>I could perhaps have listed \"effective environmental altruism\" as focus area 5. The environmental movement <em>in general</em>&nbsp;is large and well-known, but I'm not aware of many effective altruists who take environmentalism to be the most important cause for them to work on, after closely investigating the above focus areas. In contrast, the groups and people named above&nbsp;tend to have influenced each other, and have considered all these focus areas explicitly. For this reason, I've left \"effective environmental altruism\" off the list, though perhaps a popular focus on effective environmental altruism could arise in the future.</p>\n<p>Other focus areas could later come to prominence, too.</p>\n<h4><br></h4>\n<h4 id=\"Working_together\">Working together</h4>\n<p>I was pleased to see the EAs from different strands of the EA movement cooperating and learning from each other at the Effective Altruism Summit. Cooperation is crucial for growing the EA movement, so I hope that even if it\u2019s <a href=\"/lw/3h/why_our_kind_cant_cooperate/\">not always easy</a>, EAs will \"go out of their way\" to cooperate and work together, no matter which focus areas they\u2019re sympathetic to.</p>", "sections": [{"title": "Focus Area 1: Poverty Reduction", "anchor": "Focus_Area_1__Poverty_Reduction", "level": 1}, {"title": "Focus Area 2: Meta Effective Altruism", "anchor": "Focus_Area_2__Meta_Effective_Altruism", "level": 1}, {"title": "Focus Area 3: The Long-Term Future", "anchor": "Focus_Area_3__The_Long_Term_Future", "level": 1}, {"title": "Focus Area 4: Animal Suffering", "anchor": "Focus_Area_4__Animal_Suffering", "level": 1}, {"title": "Other focus areas", "anchor": "Other_focus_areas", "level": 1}, {"title": "Working together", "anchor": "Working_together", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "57 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FaJaCgqBKphrDzDSj", "7FzD7pNm9X68Gp5ZC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T10:46:25.548Z", "modifiedAt": null, "url": null, "title": "My Take on a Decision Theory", "slug": "my-take-on-a-decision-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:58.945Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ygert", "createdAt": "2012-01-18T18:04:35.691Z", "isAdmin": false, "displayName": "ygert"}, "userId": "mk5TmNSNxju4GEBrS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bxGpzD7diqHvKEiNH/my-take-on-a-decision-theory", "pageUrlRelative": "/posts/bxGpzD7diqHvKEiNH/my-take-on-a-decision-theory", "linkUrl": "https://www.lesswrong.com/posts/bxGpzD7diqHvKEiNH/my-take-on-a-decision-theory", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20Take%20on%20a%20Decision%20Theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20Take%20on%20a%20Decision%20Theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbxGpzD7diqHvKEiNH%2Fmy-take-on-a-decision-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20Take%20on%20a%20Decision%20Theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbxGpzD7diqHvKEiNH%2Fmy-take-on-a-decision-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FbxGpzD7diqHvKEiNH%2Fmy-take-on-a-decision-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1368, "htmlBody": "<p>Finding a good decision theory is hard. Previous attempts, such as Timeless Decision Theory, work, it seems, in providing a stable, effective decision theory, but are mathematically complicated. Simpler theories, like CDT or EDT, are much more intuitive, but have deep flaws. They fail at certain problems, and thus violate the maxim that rational agents should <em>win</em>. This makes them imperfect.</p>\n<p>But it seems to me that there is a relatively simple fix one could make to them, in the style of TDT, to extend their power considerably. Here I will show an implementation of such an extension of CDT, that wins on the problems that classic CDT fails on. It quite possibly could turn out that this is not as powerful as TDT, but it is a significant step in that direction, starting only from the naivest of decision theories. It also could turn out that this is nothing more than a reformulation of TDT or a lesser version thereof. In that case, this still has some value as a simpler formulation, easier to understand. Because as it stands, TDT seems like a far cry from a trivial extension of the basic, intuitive decision theories, as this hopes to be.</p>\n<p>We will start by remarking that when CDT (or EDT) tries to figure out the expected value or a action or outcome, the naive way which it does so drops crucial information, which is what TDT manages to preserve. As such, I will try to calculate a CDT with this information not dropped. This information is, for CDT, the fact that Omega has simulated you and figured out what you are going to do. Why does a CDT agent automatically assume that it is the \"real\" one, so to speak? This trivial tweak seems powerful. I will, for the purpose of this post, call this tweaked version of CDT \"Simulationist Causal Decision Theory\", or SCDT for short.</p>\n<p>Let's run this tweaked version though Newcomb's problem. Let Alice be a SCDT agent. Before the problem begins, as is standard in Newcomb's problem, Omega looks at Alice and calculates what choice Alice will make in the game. Without to much loss of generality, we can assume that Omega directly simulates Alice, and runs the simulation through the a simulation of the game, in order make the determination of what choice Alice will make. In other formulations of Newcomb's problem, Omega figures in out some other way what Alice will do, say by doing a formal analysis of her source code, but that seems intuitively&nbsp;equivalent. This <em>is</em> a possible flaw, but if the different versions of Newcomb's problem are equivalent (as they seem to be) this point evaporates, and so we will put it aside for now, and continue.</p>\n<p>We will call the simulated agent SimAlice. SimAlice does not know, of course, that she is being simulated, and is an exact copy of Alice in all respects. In particular, she also uses the same SCDT thought processes as Alice, and she has the same utility function as Alice.</p>\n<p>So, Alice (or SimAlice, she doesn't know which one she is) is presented with the game. She reasons thusly:</p>\n<blockquote>\n<p>There are two possible cases: Either I am Alice or I am SimAlice.&nbsp;</p>\n<ul>\n<li>If I am Alice: Choosing both boxes will always get me exactly $1000 more then choosing just one. Regardless of whether or not there is $1,000,000 in box 2, by choosing box 1 as well, I am getting an extra $1000. (Note that this is exactly the same reasoning standard CDT uses!)</li>\n<li>If I am SimAlice: Then \"I\" don't actually get any money in this game, regardless of what I choose. But my goal is not SimAlice getting money it is is Alice getting money, by the simple fact that this is what Alice wants, and we assumed above that SimAlice uses the same utility function as Alice.And depending what I choose now, that will affect the way Omega sets up the boxes, and so affects the amount of money Alice will get. Specifically, if I one box, Omega will put an extra&nbsp;$1,000,000 in box 2, and so Alice will get an extra&nbsp;$1,000,000, no matter what she chooses. (Because in both the choices Alice could make (taking either box 2 or boxes 1&amp;2), she takes box 2, and so will wind up with a bonus&nbsp;$1,000,000 above what she would get if box 2 was empty, which is what would happen if SimAlice didn't two box.)</li>\n</ul>\n<div>So, as I don't know whether I am Alice or SimAlice, and as there is one of each, there is a 0.5 probability of me being either one, so by the law of total expectation,</div>\n<div>E[money|I one box]=0.5 * E[money|(I one box)&amp;(I am Alice)] + 0.5 * E[money|(I one box)&amp;(I am SimAlice)]</div>\n<div>So my expected return off one boxing (above what I would get by two boxing) is 0.5 * -$1000 + 0.5 * $1,000,000 = $450,000, which is positive, so I should one box.</div>\n</blockquote>\n<div><br /></div>\n<div>As you can see, just by acknowledging the rules of the game, by admitting that Omega has the power to simulate her (as the rules of Newcomb's problem insist), she will one box. This is unlike a CDT agent, which would ignore Omega's power to simulate her (or otherwise figure out what she will do), and say \"Hey, what's in the boxes is fixed, and my choice does not affect it\". That is only valid reasoning if you know you are the \"original\" agent, and Alice herself uses that reasoning, but only in the case where she is assuming she is the \"original\". She takes care, unlike a CDT agent, to multiply the conditional expected value by the chance of the condition occurring.</div>\n<div><br /></div>\n<div>This is not only limited to Newcomb's problem. Let's take a look at Parfit's Hitchhiker, another scenario CDT has trouble with. There are again two identical agents making decisions: The \"real\" Alice, as soon as she gets home; and the \"Alice-after-she-gets-home-as simulated-by-the-driver-offering-her-a-ride, which I will again call SimAlice for short.</div>\n<div><br /></div>\n<div>Conditional on an agent being Alice and not SimAlice, paying the driver loses that agent her $100 and gains her nothing compared to refusing to pay. Conditional on an agent being SimAlice and not Alice, agreeing to pay the driver loses her nothing (as she, being a simulation, cannot give the driver <em>real</em>&nbsp;money), and gains her a trip out of the desert, and so her life. So, again, the law of total expectation gives us that the expected value of paying the driver (considering you don't know which you are), is 0.5 * -$100 + 0.5 * (Value of Alice's life). This gives us that Alice should pay if and only if she values her life at more than $100, which is, once again, the correct answer.</div>\n<div><br /></div>\n<div>So, to sum up, we found that SCDT can not only solve Newcomb's problem, which standard CDT cannot, but also solve Parfit's Hitchhiker, which neither CDT nor EDT can do. It does so at almost no cost in complexity compared to CDT, unlike, say, TDT, which is rather more complex. In fact, I kind of think that it is entirely possible that this SCDT is nothing more than a special case of something similar to TDT. But even if it is, it is a very nice, simple, and relatively easy to understand special case, and so may deserve a look for that alone.</div>\n<div><br /></div>\n<div>There are still open problems for SCDT. If, rather than a simulation, you are analysed in a more direct way, should that change anything? What if, in Newcomb's problem, Omega simulates many simulations of you in parallel? Should that change the weights you place on the expected values? This ties in deeply with the&nbsp;<a href=\"/lw/1hg/the_moral_status_of_independent_identical_copies/\">philosophical problem</a> of how you assign measure to identical, independent agents. I can not give a simple answer, and a simple answer to those questions is needed before SCDT is complete. But, if we can figure out the answer to these questions, or otherwise bypass them, we have a trivial extrapolation of CDT, the naivest decision theory, which solves correctly most or all of the problems that trip up CDT. That seems quite worthwhile.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bxGpzD7diqHvKEiNH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 4, "extendedScore": null, "score": 1.2599648435273335e-06, "legacy": true, "legacyId": "23237", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["DNyMJmLf5o26seqvX"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T14:50:34.654Z", "modifiedAt": null, "url": null, "title": "HPMoR the Youtube Series! But in need of advice", "slug": "hpmor-the-youtube-series-but-in-need-of-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:03.150Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "wobster109", "createdAt": "2011-03-23T00:20:05.950Z", "isAdmin": false, "displayName": "wobster109"}, "userId": "ACBZi6NBz3rarqbY9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WajNXQCsrXtqes8ys/hpmor-the-youtube-series-but-in-need-of-advice", "pageUrlRelative": "/posts/WajNXQCsrXtqes8ys/hpmor-the-youtube-series-but-in-need-of-advice", "linkUrl": "https://www.lesswrong.com/posts/WajNXQCsrXtqes8ys/hpmor-the-youtube-series-but-in-need-of-advice", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20HPMoR%20the%20Youtube%20Series!%20But%20in%20need%20of%20advice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHPMoR%20the%20Youtube%20Series!%20But%20in%20need%20of%20advice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWajNXQCsrXtqes8ys%2Fhpmor-the-youtube-series-but-in-need-of-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=HPMoR%20the%20Youtube%20Series!%20But%20in%20need%20of%20advice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWajNXQCsrXtqes8ys%2Fhpmor-the-youtube-series-but-in-need-of-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWajNXQCsrXtqes8ys%2Fhpmor-the-youtube-series-but-in-need-of-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 79, "htmlBody": "<p>Hi Less Wrong! I was wondering if you have experience with video editing? I want to record footage and a soundtrack, and then overlay them on each other, and I'll also need to be able to do special effects, such as to float someone in the air. Is there a video editing program that you'd recommend?</p>\n<p>&nbsp;</p>\n<p>Edit - Please let me know if you'd like to act in it and are able to get to Madison, WI on weekends :)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WajNXQCsrXtqes8ys", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": -1, "extendedScore": null, "score": 1.2601578995865107e-06, "legacy": true, "legacyId": "23255", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T16:01:03.363Z", "modifiedAt": null, "url": null, "title": "[LINK] Analysis of why excluding hostile people is worth it", "slug": "link-analysis-of-why-excluding-hostile-people-is-worth-it", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:57.630Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/bj2NQC9zKYBcka7ha/link-analysis-of-why-excluding-hostile-people-is-worth-it", "pageUrlRelative": "/posts/bj2NQC9zKYBcka7ha/link-analysis-of-why-excluding-hostile-people-is-worth-it", "linkUrl": "https://www.lesswrong.com/posts/bj2NQC9zKYBcka7ha/link-analysis-of-why-excluding-hostile-people-is-worth-it", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Analysis%20of%20why%20excluding%20hostile%20people%20is%20worth%20it&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Analysis%20of%20why%20excluding%20hostile%20people%20is%20worth%20it%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbj2NQC9zKYBcka7ha%2Flink-analysis-of-why-excluding-hostile-people-is-worth-it%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Analysis%20of%20why%20excluding%20hostile%20people%20is%20worth%20it%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbj2NQC9zKYBcka7ha%2Flink-analysis-of-why-excluding-hostile-people-is-worth-it", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fbj2NQC9zKYBcka7ha%2Flink-analysis-of-why-excluding-hostile-people-is-worth-it", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 75, "htmlBody": "<p><a href=\"http://blip.tv/tech-love-live/osb09-donnie-berkholz-assholes-are-killing-your-project-2464449\">http://blip.tv/tech-love-live/osb09-donnie-berkholz-assholes-are-killing-your-project-2464449</a></p>\n<p>This is specifically about why it's important to get assholes out of open source projects, but it applies in general. It includes an analysis of the social cost of keeping people around who frequently make other people unhappy, and in particular a way to balance the social costs (distraction, people doing much less work or leaving, useful volunteers not joining, assholes recruiting other assholes, etc.) of assholes against the useful work some of them do.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "bj2NQC9zKYBcka7ha", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 16, "extendedScore": null, "score": 1.2602136381621492e-06, "legacy": true, "legacyId": "23256", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T18:00:12.460Z", "modifiedAt": null, "url": null, "title": "Gauging interest for a Zurich, Switzerland meetup group", "slug": "gauging-interest-for-a-zurich-switzerland-meetup-group", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:29.826Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "roland", "createdAt": "2009-02-27T23:03:47.279Z", "isAdmin": false, "displayName": "roland"}, "userId": "p2C9rpg32LHrGwer8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w92NE87AZsyafvJAc/gauging-interest-for-a-zurich-switzerland-meetup-group", "pageUrlRelative": "/posts/w92NE87AZsyafvJAc/gauging-interest-for-a-zurich-switzerland-meetup-group", "linkUrl": "https://www.lesswrong.com/posts/w92NE87AZsyafvJAc/gauging-interest-for-a-zurich-switzerland-meetup-group", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Gauging%20interest%20for%20a%20Zurich%2C%20Switzerland%20meetup%20group&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGauging%20interest%20for%20a%20Zurich%2C%20Switzerland%20meetup%20group%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw92NE87AZsyafvJAc%2Fgauging-interest-for-a-zurich-switzerland-meetup-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Gauging%20interest%20for%20a%20Zurich%2C%20Switzerland%20meetup%20group%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw92NE87AZsyafvJAc%2Fgauging-interest-for-a-zurich-switzerland-meetup-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw92NE87AZsyafvJAc%2Fgauging-interest-for-a-zurich-switzerland-meetup-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 61, "htmlBody": "<p>Who would be interested in meeting? Please reply to this thread or msg me in private.</p>\n<p>Thanks!</p>\n<p>Edit: There doesnt seem to be enough people willing to meet so Im not planning anything at the moment. But if you happen to be in Zurich and want to meet a fellow LWer just msg me in private and we can go for a talk/drink.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w92NE87AZsyafvJAc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 3, "extendedScore": null, "score": 1.2603078802630427e-06, "legacy": true, "legacyId": "23258", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T18:07:25.823Z", "modifiedAt": null, "url": null, "title": "Where Are We the Weakest?", "slug": "where-are-we-the-weakest", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:01.482Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DiscyD3rp", "createdAt": "2013-06-27T02:39:53.113Z", "isAdmin": false, "displayName": "DiscyD3rp"}, "userId": "jG6joP7TmaHXQjQZz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ReTtchuBD7CxYuHNT/where-are-we-the-weakest", "pageUrlRelative": "/posts/ReTtchuBD7CxYuHNT/where-are-we-the-weakest", "linkUrl": "https://www.lesswrong.com/posts/ReTtchuBD7CxYuHNT/where-are-we-the-weakest", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Where%20Are%20We%20the%20Weakest%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhere%20Are%20We%20the%20Weakest%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FReTtchuBD7CxYuHNT%2Fwhere-are-we-the-weakest%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Where%20Are%20We%20the%20Weakest%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FReTtchuBD7CxYuHNT%2Fwhere-are-we-the-weakest", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FReTtchuBD7CxYuHNT%2Fwhere-are-we-the-weakest", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 179, "htmlBody": "<p>As rationalists, we should be able to consistently and accurately make predictions that enable us to act effectively.</p>\n<p>As humans, we don't. At least not perfectly.</p>\n<p>We need to improve. Many of us have, or at least believe we have. However, it's a notably <em>hacked</em>&nbsp;improvement. <a href=\"http://predictionbook.com/\">PredictionBook</a>&nbsp;is an excellent source of feedback on how well we're doing, but there's more detailed information that isn't easily available that I think could be incredibly useful. Questions I would like to see answered are:</p>\n<ul>\n<li>What <em>kinds</em> of predictions are we the least successful at predicting? (weakest calibration, smallest accuracy)</li>\n<li>What <em>kinds</em> of predictions have the most low-hanging fruit? What's the easiest to improve on <em>right now?</em></li>\n<li><em><span style=\"font-style: normal;\">What&nbsp;<em>kinds</em>&nbsp;of predictions are the&nbsp;<em>most useful</em>&nbsp;to us? (accurately predicting a close friend's behavior&gt;predicting obscure political decision)</span></em></li>\n<li>Where <em>aren't</em> we making quantitative predictions? Where does our behavior involve predictions that are underrepresented on PredictionBook?</li>\n</ul>\n<div>Before we are <em>able</em> to improve as a community, we need to know <em>where</em> to improve. I'd love to hear suggestions on&nbsp;how<em> </em>to answer these questions in the comments.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ReTtchuBD7CxYuHNT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 1.2603135934204611e-06, "legacy": true, "legacyId": "23257", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T18:22:49.318Z", "modifiedAt": null, "url": null, "title": "\"Can we know what to do about AI?\": An Introduction", "slug": "can-we-know-what-to-do-about-ai-an-introduction", "viewCount": null, "lastCommentedAt": "2017-06-17T04:15:02.769Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JonahSinick", "createdAt": "2012-06-23T04:40:16.600Z", "isAdmin": false, "displayName": "JonahS"}, "userId": "NjJPzTdMQkX5ZeQaK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/t7gKX9Av5zggsQsYr/can-we-know-what-to-do-about-ai-an-introduction", "pageUrlRelative": "/posts/t7gKX9Av5zggsQsYr/can-we-know-what-to-do-about-ai-an-introduction", "linkUrl": "https://www.lesswrong.com/posts/t7gKX9Av5zggsQsYr/can-we-know-what-to-do-about-ai-an-introduction", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Can%20we%20know%20what%20to%20do%20about%20AI%3F%22%3A%20An%20Introduction&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Can%20we%20know%20what%20to%20do%20about%20AI%3F%22%3A%20An%20Introduction%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft7gKX9Av5zggsQsYr%2Fcan-we-know-what-to-do-about-ai-an-introduction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Can%20we%20know%20what%20to%20do%20about%20AI%3F%22%3A%20An%20Introduction%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft7gKX9Av5zggsQsYr%2Fcan-we-know-what-to-do-about-ai-an-introduction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft7gKX9Av5zggsQsYr%2Fcan-we-know-what-to-do-about-ai-an-introduction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 556, "htmlBody": "<div style=\"font-family: arial;\">\n<div style=\"font-family: Verdana, Arial, Helvetica, sans-serif;\">\n<p>I'm currently working on a research project for MIRI, and I would welcome feedback on my research as I proceed. In this post, I describe the project.</p>\n<p><a id=\"more\"></a></p>\n<p>As a part of an effort to&nbsp;<a href=\"/lw/85h/better_disagreement/\" target=\"_blank\">steel-man</a>&nbsp;objections to MIRI's mission, MIRI Executive Director Luke Muehlhauser has asked me to develop the following objection:</p>\n<blockquote>\n<p>\"Even if AI is somewhat likely to arrive during the latter half of this century, how on earth can we know what to do about it&nbsp;<em>now</em>, so far in advance?\"</p>\n</blockquote>\n<p>In Luke's initial email to me, he wrote:</p>\n<blockquote>\n<p>I think there are plausibly&nbsp;<a href=\"/lw/hmb/many_weak_arguments_vs_one_relatively_strong/\" target=\"_blank\">many weak arguments</a>&nbsp;and historical examples suggesting that P: \"it's very hard to nudge specific distant events in a positive direction through highly targeted actions or policies undertaken today.\" Targeted actions might have no lasting effect, or they might completely miss their mark, or they might backfire.</p>\n<p>If P is true, this would weigh against the view that a highly targeted intervention today (e.g. Yudkowsky's Friendly AI math research) is likely to positively affect the future creation of AI, and might instead weigh in favor of the view that all we can do about&nbsp;<a href=\"http://en.wikipedia.org/wiki/Strong_AI#Artificial_General_Intelligence_research\" target=\"_blank\">AGI</a>&nbsp;from this distance is to engage in broad interventions likely to improve our odds of wisely handling future crises in general &mdash; e.g. improving decision-making institutions, spreading rationality, etc.</p>\n<p>I'm interested in abstract arguments for P, but I'm even more interested in historical data. What can we learn from seemingly analogous cases, and are those cases analogous in the relevant ways? What sorts of&nbsp;<a href=\"http://www.amazon.com/Unmaking-West-What-If-Scenarios-Rewrite/dp/0472031430/\" target=\"_blank\">counterfactual history</a>&nbsp;can we do to clarify our picture?</p>\n</blockquote>\n<p>Luke and I brainstormed a list of potential historical examples of people predicting the future 10+ years out, and using the predictions to inform their actions. We came up with the following potential examples, which I've listed in chronological order by approximate year:</p>\n<ul>\n<li>1896: Svante Arrhenius's&nbsp;<a href=\"http://en.wikipedia.org/wiki/Svante_Arrhenius#Greenhouse_effect\" target=\"_blank\">prediction of anthropogenic climate change</a>.</li>\n<li>1935: Leo Szilard's ~1935&nbsp;<a href=\"http://www.cccoe.k12.ca.us/abomb/popups/patent.htm\" target=\"_blank\">attempts to&nbsp;keep his patent of the atomic bomb secret from Germany</a>.</li>\n<li>1950-1980: Efforts to win the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Cold_War\" target=\"_blank\">Cold War</a>&nbsp;decades later, such as increasing education for gifted children.</li>\n<li>1960: Norbert Weiner&nbsp;<a href=\"http://www.itu.dk/people/cmmm/Wiener.pdf\" target=\"_blank\">highlighting the dangers of artificial intelligence</a>.</li>\n<li>1972: The circle of ideas and actions around the&nbsp;<a href=\"http://en.wikipedia.org/wiki/The_Limits_to_Growth\" target=\"_blank\">The Limits to Growth</a>, a book about the consequences of unchecked population growth and economic growth.</li>\n<li>1975: The&nbsp;<a href=\"http://en.wikipedia.org/wiki/WASH-1400\" target=\"_blank\">WASH-1400 reactor safety study</a>, which attempted to assess the risks associated with nuclear reactors.&nbsp;</li>\n<li>1975: The&nbsp;<a href=\"http://en.wikipedia.org/wiki/Asilomar_Conference_on_Recombinant_DNA\" target=\"_blank\">Asilomar Conference on Recombinant DNA</a>, which set up guidelines to ensure the safety of recombinant DNA technology.</li>\n<li>1978: China's&nbsp;<a href=\"https://en.wikipedia.org/wiki/One-child_policy\" target=\"_blank\">one-child policy</a>&nbsp;to reduce population growth.</li>\n<li>1980: The&nbsp;<a href=\"http://www.givewell.org/files/conversations/Lant%20Pritchet%2006-18-12%20final%20for%20upload.pdf\" target=\"_blank\">Ford Foundation setting up a policy think</a>&nbsp;in India that helped India recover from&nbsp;<a href=\"http://en.wikipedia.org/wiki/1991_India_economic_crisis\" target=\"_blank\">its 1991 financial crisis</a>&nbsp;</li>\n<li>1988:&nbsp;<a href=\"http://www.ipcc.ch/organization/organization_history.shtml\" target=\"_blank\">Early climate change mitigation efforts</a></li>\n<li>1992+:&nbsp;<a href=\"http://en.wikipedia.org/wiki/Asteroid_impact_avoidance#History_of_government_mandates\" target=\"_blank\">Asteroid strike deflection efforts</a>&nbsp;</li>\n<li>???: Possible deliberate long term efforts to produce revolutionary scientific technologies.</li>\n<li>????: Long term computer security research</li>\n</ul>\n<div>In addition, we selected</div>\n<div>\n<ul>\n<li><a href=\"http://www.amazon.com/The-Signal-Noise-Many-Predictions/dp/159420411X\" target=\"_blank\">The Signal and the Noise: Why So Many Predictions Fail &mdash; but Some Don't</a>&nbsp;by Nate Silver</li>\n<li><a href=\"http://www.amazon.com/books/dp/0691128715\" target=\"_blank\">Expert Political Judgment: How Good Is It? How Can We Know?</a>&nbsp;by Philip Tetlock</li>\n</ul>\n<div>as background reading.</div>\n</div>\n<div><br /></div>\n<div>I would greatly appreciate any ideas from the Less Wrong community concerning potential historical examples and relevant background reading.</div>\n<div><br /></div>\n<div>Over the coming weeks, I'll be making a series of discussion board posts on Less Wrong reporting on my findings, and linking these posts here.</div>\n</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "t7gKX9Av5zggsQsYr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 28, "extendedScore": null, "score": 6.1e-05, "legacy": true, "legacyId": "23252", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 69, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FhH8m5n8qGSSHsAgG", "9W9P2snxu5Px746LD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-09T20:50:43.753Z", "modifiedAt": null, "url": null, "title": "Prisoner's dilemma tournament results", "slug": "prisoner-s-dilemma-tournament-results-0", "viewCount": null, "lastCommentedAt": "2018-02-02T16:03:03.186Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QP7Ne4KXKytj4Krkx/prisoner-s-dilemma-tournament-results-0", "pageUrlRelative": "/posts/QP7Ne4KXKytj4Krkx/prisoner-s-dilemma-tournament-results-0", "linkUrl": "https://www.lesswrong.com/posts/QP7Ne4KXKytj4Krkx/prisoner-s-dilemma-tournament-results-0", "postedAtFormatted": "Tuesday, July 9th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Prisoner's%20dilemma%20tournament%20results&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APrisoner's%20dilemma%20tournament%20results%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQP7Ne4KXKytj4Krkx%2Fprisoner-s-dilemma-tournament-results-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Prisoner's%20dilemma%20tournament%20results%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQP7Ne4KXKytj4Krkx%2Fprisoner-s-dilemma-tournament-results-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQP7Ne4KXKytj4Krkx%2Fprisoner-s-dilemma-tournament-results-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 258, "htmlBody": "<p>The <a href=\"/lw/hmx/prisoners_dilemma_with_visible_source_code/\">prisoner's dilemma tournament</a> is over. There were a total of 21 entries. The winner is Margaret Sy, with a total of 39 points. 2nd and 3rd place go to rpglover64 and THE BLACK KNIGHT, with scores of 38 and 36 points respectively. There were some fairly intricate strategies in the tournament, but all three of these top scorers submitted programs that completely ignored the source code of the other player and acted randomly, with the winner having a bias towards defecting.</p>\n<p>You can download a chart describing the outcomes <a href=\"http://alex.mennen.org/results.xls\">here</a>, and the source codes for the entries can be downloaded <a href=\"http://alex.mennen.org/PDTournament.zip\">here</a>.</p>\n<p>I represented each submission with a single letter while running the tournament. Here is a directory of the entries, along with their scores: (some people gave me a term to refer to the player by, while others gave me a term to refer to the program. I went with whatever they gave me, and if they gave me both, I put the player first and then the program)</p>\n<p>A: rpglover64 (38)<br />B: Watson Ladd (27)<br />c: THE BLACK KNIGHT (36)<br />D: skepsci (24)<br />E: Devin Bayer (30)<br />F: Billy, Mimic-- (27)<br />G: itaibn (34)<br />H: CooperateBot (24)<br />I: Sean Nolan (28)<br />J: oaz (26)<br />K: selbram (34)<br />L: Alexei (25)<br />M: LEmma (25)<br />N: BloodyShrimp (34)<br />O: caa (32)<br />P: nshepperd (25)<br />Q: Margaret Sy (39)<br />R: So8res, NateBot (33)<br />S: Quinn (33)<br />T: HonoreDB (23)<br />U: SlappedTogetherAtTheLastMinuteBot (20)</p>\n<div><br /></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"be2Mh2bddQ6ZaBcti": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QP7Ne4KXKytj4Krkx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 49, "extendedScore": null, "score": 1.2604427747289284e-06, "legacy": true, "legacyId": "23254", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 32, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 124, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["BY8kvyuLzMZJkwTHL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-10T01:34:36.397Z", "modifiedAt": null, "url": null, "title": "Can we make Drake-like Fermi estimates of expected distance to the next planet with primitive, sentient or self-improving life?", "slug": "can-we-make-drake-like-fermi-estimates-of-expected-distance", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:58.759Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "chaosmage", "createdAt": "2012-04-27T12:21:32.969Z", "isAdmin": false, "displayName": "chaosmage"}, "userId": "onF6sJLEXsAkjx9Ki", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EJzgGEMFmLzdscag9/can-we-make-drake-like-fermi-estimates-of-expected-distance", "pageUrlRelative": "/posts/EJzgGEMFmLzdscag9/can-we-make-drake-like-fermi-estimates-of-expected-distance", "linkUrl": "https://www.lesswrong.com/posts/EJzgGEMFmLzdscag9/can-we-make-drake-like-fermi-estimates-of-expected-distance", "postedAtFormatted": "Wednesday, July 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Can%20we%20make%20Drake-like%20Fermi%20estimates%20of%20expected%20distance%20to%20the%20next%20planet%20with%20primitive%2C%20sentient%20or%20self-improving%20life%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACan%20we%20make%20Drake-like%20Fermi%20estimates%20of%20expected%20distance%20to%20the%20next%20planet%20with%20primitive%2C%20sentient%20or%20self-improving%20life%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEJzgGEMFmLzdscag9%2Fcan-we-make-drake-like-fermi-estimates-of-expected-distance%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Can%20we%20make%20Drake-like%20Fermi%20estimates%20of%20expected%20distance%20to%20the%20next%20planet%20with%20primitive%2C%20sentient%20or%20self-improving%20life%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEJzgGEMFmLzdscag9%2Fcan-we-make-drake-like-fermi-estimates-of-expected-distance", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEJzgGEMFmLzdscag9%2Fcan-we-make-drake-like-fermi-estimates-of-expected-distance", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 312, "htmlBody": "<p>I expect everyone here has an opinion on the <a href=\"http://en.wikipedia.org/wiki/Drake_equation\">Drake Equation</a>. (Comment if I'm wrong.) And that's because it is an easy story to remember and spread. Never mind its glaring inadequacy or the symbols it uses: it gives you a number of alien civilizations and somehow that sticks. I'd like to see if a science meme with similar properties could be created to carry a transhumanist payload. So. Could you convince a random person of the following three points if you wanted to?</p>\n<ul>\n<li>We're getting increasingly confident estimates on the number and distribution of planets in our galaxy.</li>\n<li>The other factors in the Drake equation have been discussed a lot - they remain guesses till we find something, but at least they aren't going to change a lot until we do.</li>\n<li>So we should be able to estimate, very roughly and while mumbling about priors, an expected distance to the next planetary body with primitive life, with sentient life or with self-improving life (i.e. something like AIs that can exponentially grow that biosphere's cognitive capacity).</li>\n</ul>\n<p>I think you could. And if you do, and if you can give a number of light-years, regardless of how much you emphasize the low confidence, aliens will suddenly seem more real to that random person. And so will, if not full transhumanism, at least some vague notion that intelligence must grow much like life does. I think that could reach a lot of people.</p>\n<p>(If anybody complains that the expectation of some Singularity-like development is ideological: no, it is a reasonable guess based on the current evidence, much like Drake's expectation of every technological civilization's eventual self-destruction was reasonable in his Cold War era.)</p>\n<p>The brain I'm typing this from knows too little math or astronomy to do this locally, so I'm throwing out the idea. Anyone care to play with this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EJzgGEMFmLzdscag9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": -1, "extendedScore": null, "score": 1.2606673983166374e-06, "legacy": true, "legacyId": "23259", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-10T02:34:15.521Z", "modifiedAt": null, "url": null, "title": "Meetup : Buffalo LW - Biased Boardgaming", "slug": "meetup-buffalo-lw-biased-boardgaming", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "StonesOnCanvas", "createdAt": "2012-06-28T17:32:49.237Z", "isAdmin": false, "displayName": "StonesOnCanvas"}, "userId": "FAfkKGH6E8BLmXW4M", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rTkRmSAemSAqxdnEp/meetup-buffalo-lw-biased-boardgaming", "pageUrlRelative": "/posts/rTkRmSAemSAqxdnEp/meetup-buffalo-lw-biased-boardgaming", "linkUrl": "https://www.lesswrong.com/posts/rTkRmSAemSAqxdnEp/meetup-buffalo-lw-biased-boardgaming", "postedAtFormatted": "Wednesday, July 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20%3A%20Buffalo%20LW%20-%20Biased%20Boardgaming&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20%3A%20Buffalo%20LW%20-%20Biased%20Boardgaming%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrTkRmSAemSAqxdnEp%2Fmeetup-buffalo-lw-biased-boardgaming%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20%3A%20Buffalo%20LW%20-%20Biased%20Boardgaming%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrTkRmSAemSAqxdnEp%2Fmeetup-buffalo-lw-biased-boardgaming", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrTkRmSAemSAqxdnEp%2Fmeetup-buffalo-lw-biased-boardgaming", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 173, "htmlBody": "<h2>Discussion article for the meetup : <a href='/meetups/oh'>Buffalo LW - Biased Boardgaming</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong>&#32;\n\t\t    \t<span class=\"date\">18 July 2013 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong>&#32;\n\t\t    \t<span class=\"address\">121 Wanda Ave. Cheektowaga, NY 14211</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Buffalo-area Less Wrong meetups on the first Sunday and Third Thursday of every month. Join us on Meetup: <a href=\"http://www.meetup.com/Less-Wrong-Buffalo/\" rel=\"nofollow\">http://www.meetup.com/Less-Wrong-Buffalo/</a>\nHey Everyone,\nSo, instead of doing a doodle poll to figure out a good day for a game night, I figured we could have a game night for our next meetup. We'll order some pizza for everyone. This time we will try playing with biases (each player draws a bias at random from a deck, and plays their turn with that bias. If someone is unsure how to play the bias he/she can ask the group for future reference and draw another one instead. If we think we know what bias someone drew we can try guessing it). See you all there!\nP.S. This meetup starts an hour earlier than our normal Thursday meetups and will be held at our house.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2>Discussion article for the meetup : <a href='/meetups/oh'>Buffalo LW - Biased Boardgaming</a></h2>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rTkRmSAemSAqxdnEp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "23261", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": {"html": "<h2 id=\"Discussion_article_for_the_meetup___Buffalo_LW___Biased_Boardgaming\">Discussion article for the meetup : <a href=\"/meetups/oh\">Buffalo LW - Biased Boardgaming</a></h2>\n\t\t  <div class=\"meetup-meta\">\n\t\t\t\t<p>\n\t\t    \t<strong>WHEN:</strong> \n\t\t    \t<span class=\"date\">18 July 2013 06:00:00PM (-0400)</span><br>\n\t\t\t\t</p>\n\t\t\t\t<p>\n\t\t    \t<strong>WHERE:</strong> \n\t\t    \t<span class=\"address\">121 Wanda Ave. Cheektowaga, NY 14211</span>\n\t\t\t\t</p>\n\t\t  </div><!-- .meta -->\n\t\t  <div id=\"\" class=\"content\">\n\t\t    <div class=\"md\"><p>Buffalo-area Less Wrong meetups on the first Sunday and Third Thursday of every month. Join us on Meetup: <a href=\"http://www.meetup.com/Less-Wrong-Buffalo/\" rel=\"nofollow\">http://www.meetup.com/Less-Wrong-Buffalo/</a>\nHey Everyone,\nSo, instead of doing a doodle poll to figure out a good day for a game night, I figured we could have a game night for our next meetup. We'll order some pizza for everyone. This time we will try playing with biases (each player draws a bias at random from a deck, and plays their turn with that bias. If someone is unsure how to play the bias he/she can ask the group for future reference and draw another one instead. If we think we know what bias someone drew we can try guessing it). See you all there!\nP.S. This meetup starts an hour earlier than our normal Thursday meetups and will be held at our house.</p></div>\n\t\t  </div><!-- .content -->\n\t\t<h2 id=\"Discussion_article_for_the_meetup___Buffalo_LW___Biased_Boardgaming1\">Discussion article for the meetup : <a href=\"/meetups/oh\">Buffalo LW - Biased Boardgaming</a></h2>", "sections": [{"title": "Discussion article for the meetup : Buffalo LW - Biased Boardgaming", "anchor": "Discussion_article_for_the_meetup___Buffalo_LW___Biased_Boardgaming", "level": 1}, {"title": "Discussion article for the meetup : Buffalo LW - Biased Boardgaming", "anchor": "Discussion_article_for_the_meetup___Buffalo_LW___Biased_Boardgaming1", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "No comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-10T11:05:49.235Z", "modifiedAt": null, "url": null, "title": "[LINK] XKCD Comic #1236, Seashells and Bayes' Theorem", "slug": "link-xkcd-comic-1236-seashells-and-bayes-theorem", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:57.280Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Petruchio", "createdAt": "2012-09-20T21:52:44.002Z", "isAdmin": false, "displayName": "Petruchio"}, "userId": "Sq97ckSEEWbQ6AxC9", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gkzRkBT5ePrEJxtdG/link-xkcd-comic-1236-seashells-and-bayes-theorem", "pageUrlRelative": "/posts/gkzRkBT5ePrEJxtdG/link-xkcd-comic-1236-seashells-and-bayes-theorem", "linkUrl": "https://www.lesswrong.com/posts/gkzRkBT5ePrEJxtdG/link-xkcd-comic-1236-seashells-and-bayes-theorem", "postedAtFormatted": "Wednesday, July 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20XKCD%20Comic%20%231236%2C%20Seashells%20and%20Bayes'%20Theorem&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20XKCD%20Comic%20%231236%2C%20Seashells%20and%20Bayes'%20Theorem%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgkzRkBT5ePrEJxtdG%2Flink-xkcd-comic-1236-seashells-and-bayes-theorem%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20XKCD%20Comic%20%231236%2C%20Seashells%20and%20Bayes'%20Theorem%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgkzRkBT5ePrEJxtdG%2Flink-xkcd-comic-1236-seashells-and-bayes-theorem", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgkzRkBT5ePrEJxtdG%2Flink-xkcd-comic-1236-seashells-and-bayes-theorem", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 9, "htmlBody": "<p>A fun comic about seashells and Bayes' Theorem. <a href=\"http://xkcd.com/1236/\">http://xkcd.com/1236/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gkzRkBT5ePrEJxtdG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": -11, "extendedScore": null, "score": 1.261119597147307e-06, "legacy": true, "legacyId": "23271", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-10T11:23:31.177Z", "modifiedAt": null, "url": null, "title": "Help please! Making a good choice between two jobs", "slug": "help-please-making-a-good-choice-between-two-jobs", "viewCount": null, "lastCommentedAt": "2017-06-17T04:22:33.778Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cjb230", "createdAt": "2012-02-18T11:33:49.197Z", "isAdmin": false, "displayName": "cjb230"}, "userId": "C3cGzow6RPjG48e54", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3bH8v5yRSQvNJrnX9/help-please-making-a-good-choice-between-two-jobs", "pageUrlRelative": "/posts/3bH8v5yRSQvNJrnX9/help-please-making-a-good-choice-between-two-jobs", "linkUrl": "https://www.lesswrong.com/posts/3bH8v5yRSQvNJrnX9/help-please-making-a-good-choice-between-two-jobs", "postedAtFormatted": "Wednesday, July 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%20please!%20Making%20a%20good%20choice%20between%20two%20jobs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%20please!%20Making%20a%20good%20choice%20between%20two%20jobs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3bH8v5yRSQvNJrnX9%2Fhelp-please-making-a-good-choice-between-two-jobs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%20please!%20Making%20a%20good%20choice%20between%20two%20jobs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3bH8v5yRSQvNJrnX9%2Fhelp-please-making-a-good-choice-between-two-jobs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3bH8v5yRSQvNJrnX9%2Fhelp-please-making-a-good-choice-between-two-jobs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 469, "htmlBody": "<p>After about three months of unemployment, today I have been told I will receive two different job offers. Obviously I want to make a decision that maximises my utility, but there are some difficult-to-quantify factors involved. Can anyone suggest a useful or clarifying perspective on the choice? What questions should I be asking myself?</p>\n<p>As background, I'm a 36-year old male techie based in the UK. What I would really like to do is build my own startup, or join a startup that I think has good prospects. However, having done that twice, and nearly bankrupted myself twice, I need to get a financial cushion under myself before trying again. For the sake of my CV, I think I need to stay in my next role for at least 18 months. After that, I hope to be able to try something entrepreneurial again, but I want to stay employable in technology as a financial safeguard.&nbsp;</p>\n<p>One job is in London, and will certainly pay more. I have many friends there, and a social network I can get back in to straight away. The pool of women I am interested in dating is much bigger there. The job itself will allow me to improve my skills, but probably not broaden them; there are very skilled people there that I can learn from. With this job, I fear being bored, and getting more and more specialised in a skill that is getting less popular.</p>\n<p>The other job is in Glasgow. It will pay less, probably by about &pound;15k. The cost of living difference, after tax, will probably be bigger than this - I expect I will have more money in my pocket with this job than with the London job. I only know two people living in Glasgow, so I will need to make new friends and get a new social life. Dating prospects are probably less good, but I don't know by how much. The job itself looks more interesting, and I can broaden my skills. The job market I am in will probably be more open to me after I take this job. With this job, I fear getting depressed due to isolation, and also the long-term effect of accepting a pay cut - if I worked in London again later, would I be able to negotiate my salary back up?</p>\n<p>Cost aside, London is a better location. It has more of everything I am interested in (including a LW meetup group!). Location and pay aside, the job in Glasgow is better. I expect it will be more interesting, and will make it less likely that I'll be unemployed in the future.</p>\n<p>I don't know how to weight these factors up properly. What mistakes in judgement do I need to avoid? What approaches can I take to make the decision easier to make correctly?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3bH8v5yRSQvNJrnX9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 3, "extendedScore": null, "score": 1.2611336130797483e-06, "legacy": true, "legacyId": "23272", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-10T13:38:57.443Z", "modifiedAt": null, "url": null, "title": "The failure of counter-arguments argument", "slug": "the-failure-of-counter-arguments-argument", "viewCount": null, "lastCommentedAt": "2017-06-17T04:12:58.519Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/emwNATBCiYWkqejjf/the-failure-of-counter-arguments-argument", "pageUrlRelative": "/posts/emwNATBCiYWkqejjf/the-failure-of-counter-arguments-argument", "linkUrl": "https://www.lesswrong.com/posts/emwNATBCiYWkqejjf/the-failure-of-counter-arguments-argument", "postedAtFormatted": "Wednesday, July 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20failure%20of%20counter-arguments%20argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20failure%20of%20counter-arguments%20argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FemwNATBCiYWkqejjf%2Fthe-failure-of-counter-arguments-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20failure%20of%20counter-arguments%20argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FemwNATBCiYWkqejjf%2Fthe-failure-of-counter-arguments-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FemwNATBCiYWkqejjf%2Fthe-failure-of-counter-arguments-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 553, "htmlBody": "<p>Suppose you read a convincing-seeming argument by Karl Marx, and get swept up in the beauty of the rhetoric and clarity of the exposition. Or maybe a creationist argument carries you away with its elegance and power. Or maybe you've read <a href=\"http://yudkowsky.net/singularity/ai-risk\">Eliezer's take on AI risk</a>, and, again, it seems pretty convincing.</p>\n<p>How could you know if these arguments are sound? Ok, you could whack the creationist argument with the scientific method, and Karl Marx with the verdict of history, but what would you do if neither was available (as they aren't available when currently assessing the AI risk argument)? Even if you're pretty smart, there's no guarantee that you haven't missed a subtle logical flaw, a dubious premise or two, or haven't got caught up in the rhetoric.</p>\n<p>One thing should make you believe the argument more strongly: and that's if the argument has been repeatedly criticised, and the criticisms have failed to puncture it. Unless you have the time to become an expert yourself, this is the best way to evaluate arguments where evidence isn't available or conclusive. After all, opposite experts presumably know the subject intimately, and are motivated to identify and illuminate the argument's weaknesses.</p>\n<p>If counter-arguments seem incisive, pointing out serious flaws, or if the main argument is being continually patched to defend it against criticisms - well, this is strong evidence that main argument is flawed. Conversely, if the counter-arguments continually fail, then this is good evidence that the main argument is sound. Not logical evidence - a failure to find a disproof doesn't establish a proposition - but good Bayesian evidence.</p>\n<p>In fact, the failure of counter-arguments is much stronger evidence than whatever is in the argument itself. If you can't find a flaw, that just means <em>you</em> can't find a flaw. If counter-arguments fail, that means many smart and knowledgeable people have thought deeply about the argument - and haven't found a flaw.</p>\n<p>And as far as I can tell, critics have constantly failed to counter the AI risk argument. To pick just one example, Holden recently provided a <a href=\"/lw/cbs/thoughts_on_the_singularity_institute_si/\">cogent critique</a> of the value of MIRI's focus on AI risk reduction. Eliezer wrote a <a href=\"/lw/cze/reply_to_holden_on_tool_ai/\">response</a> to it (I wrote&nbsp;<a href=\"/lw/cfd/tools_versus_agents/\">one</a> as well). The core of Eliezer's and my response wasn't anything new; they were mainly a rehash of what had been said before, with a different emphasis.</p>\n<p>And most responses to critics of the AI risk argument take this form. Thinking for a short while, one can rephrase essentially the same argument, with a change in emphasis to take down the criticism. After a few examples, it becomes quite easy, a kind of paint-by-numbers process of showing that the ideas the critic has assumed, do not actually make the AI safe.</p>\n<p>You may not agree with my assessment of the critiques, but if you do, then you should adjust your belief in AI risk upwards. There's a kind of \"<a href=\"/lw/ii/conservation_of_expected_evidence/\">conservation of expected evidence</a>\" here: if the critiques had succeeded, you'd have reduced the probability of AI risk, so their failure must push you in the opposite direction.</p>\n<p>In my opinion, the strength of the AI risk argument derives 30% from the actual argument, and 70% from the failure of counter-arguments. This would be higher, but we haven't yet seen the most prominent people in the AI community take a really good swing at it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "emwNATBCiYWkqejjf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 26, "extendedScore": null, "score": 1.2612408759790835e-06, "legacy": true, "legacyId": "23173", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["6SGqkCgHuNr7d4yJm", "sizjfDgCgAsuLJQmm", "nAwTGhgrdxE85Bjmg", "jiBFC7DcCrZjGmZnJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2013-07-10T13:47:33.114Z", "modifiedAt": null, "url": null, "title": "Against easy superintelligence: the unforeseen friction argument", "slug": "against-easy-superintelligence-the-unforeseen-friction", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:00.462Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Stuart_Armstrong", "createdAt": "2009-03-26T10:25:39.189Z", "isAdmin": false, "displayName": "Stuart_Armstrong"}, "userId": "uCfjEXpnchoqDWNoL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rPBoLRxSJ88jrthEJ/against-easy-superintelligence-the-unforeseen-friction", "pageUrlRelative": "/posts/rPBoLRxSJ88jrthEJ/against-easy-superintelligence-the-unforeseen-friction", "linkUrl": "https://www.lesswrong.com/posts/rPBoLRxSJ88jrthEJ/against-easy-superintelligence-the-unforeseen-friction", "postedAtFormatted": "Wednesday, July 10th 2013", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Against%20easy%20superintelligence%3A%20the%20unforeseen%20friction%20argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAgainst%20easy%20superintelligence%3A%20the%20unforeseen%20friction%20argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPBoLRxSJ88jrthEJ%2Fagainst-easy-superintelligence-the-unforeseen-friction%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Against%20easy%20superintelligence%3A%20the%20unforeseen%20friction%20argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPBoLRxSJ88jrthEJ%2Fagainst-easy-superintelligence-the-unforeseen-friction", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrPBoLRxSJ88jrthEJ%2Fagainst-easy-superintelligence-the-unforeseen-friction", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1559, "htmlBody": "<p>In 1932, Stanley Baldwin, prime minister of the largest empire the world had ever seen, proclaimed that \"<a href=\"http://en.wikipedia.org/wiki/The_bomber_will_always_get_through\">The bomber will always get through</a>\". Backed up by most of the professional military opinion of the time, by the experience of the first world war, and by reasonable extrapolations and arguments, he laid out a vision of the future where the unstoppable heavy bomber would utterly devastate countries if a war started. Deterrence - building more bombers yourself to threaten complete retaliation - seemed the only counter.</p>\n<p>And yet, things <a href=\"http://en.wikipedia.org/wiki/Battle_of_Britain\">didn't turn out</a> <a href=\"http://en.wikipedia.org/wiki/Strategic_bombing_during_World_War_II\">that way</a>. Against all past trends, the light fighter plane surpassed the heavily armed bomber in aerial combat, the development of radar changed the strategic balance, and cities and industry proved much more resilient to bombing than anyone had a right to suspect.</p>\n<p>Could anyone have predicted these changes ahead of time? Most probably, no. All of these ran counter to what was known and understood, (and radar was a completely new and unexpected development). What could and should have been predicted, though, was that <em>something</em> would happen to weaken the impact of the all-conquering bomber. The extreme predictions would be unrealistic; frictions, technological changes, changes in military doctrine and hidden, unknown factors, would undermine them.</p>\n<p>This is what I call the \"generalised friction\" argument. Simple predictive models, based on strong models or current understanding, will likely not succeed as well as expected: there will likely be delays, obstacles, and unexpected difficulties along the way.</p>\n<p>I am, of course, thinking of AI predictions here, specifically of the Omohundro-Yudkowsky model of AI <a href=\"/lw/we/recursive_selfimprovement/\">recursive self-improvements</a> that rapidly reach great power, with convergent instrumental goals that make the AI into a <a href=\"http://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/\">power-hungry expected utility maximiser</a>. This model I see as the \"supply and demand curve\" of AI prediction: too simple to be true in the form described.</p>\n<p>But the supply and demand curves are generally approximately true, especially over the long term. So this isn't an argument that the Omohundro-Yudkowsky model is wrong, but that it will likely not happen as flawlessly as described. Ultimately, the \"bomber will always get through\" turned out to be true: but only in the form of the ICBM. If you take the old arguments and replace \"bomber\" with \"ICBM\", you end with strong and accurate predictions. So \"the AI may not foom in the manner and on the timescales described\" is not saying \"the AI won't foom\".</p>\n<p>Also, it should be emphasised that this argument is strictly about our predictive ability, and does not say anything about the capacity or difficulty of AI per se.<a id=\"more\"></a></p>\n<h2>Why frictions?</h2>\n<p>An analogy often used for AI is that of the <a href=\"/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">nuclear chain reaction</a>: here is a perfect example of a recursive improvement, as the chain reaction grows and grows indefinitely. Scepticism about the chain reaction was unjustified, though experts were far too willing to rule it out ahead of time, based on unsound heuristics.</p>\n<p>In contrast, many examples of simple models were slowed or derailed by events. The examples that came immediately to mind, for me, were the bomber example, the failure of expansion into space after the first moon landing, and the failure of early AI predictions. To be fair, there are also examples of unanticipated success, often in economic policy, but even in <a href=\"http://en.wikipedia.org/wiki/G.I._Bill\">government</a><a href=\"http://en.wikipedia.org/wiki/Clean_Air_Act_1956\"> interventions</a>. But generally, dramatic predictions fail, either by being wrong or by being too optimistic on the timeline. Why is this?</p>\n<h2>Beware the opposition</h2>\n<p>One reason that predictions fail is because they underestimate human opposition. The bomber fleets may have seemed invincible, but that didn't take into account that large number of smart people were working away to try and counter them. The solution turned out to be improved fighters and radar; but even without knowing that, it should have been obvious <em>some</em> new methods or technologies were going to be invented or developed. Since the strength of the bomber depended on a certain strategic landscape, it should have been seen that deliberate attempts to modify that landscape would likely result in a reduction of the bomber's efficacy.</p>\n<p>Opposition is much harder to <a href=\"http://en.wikipedia.org/wiki/Game_theory\">model</a>, especially in such a wide area as modern warfare and technology. Still, theorisers should realised that there would have been some opposition, and that, historically, ways have been found to counter most weapons, in ways that were not obvious at the time of the weapon's creation. It is easier to change the strategic landscape than to preserve it, so anything that depends on the current strategic landscape will most likely be blunted by human effort.</p>\n<p>This kind of friction is less relevant to AI (though see the last section), and not relevant at all to the chain reaction example: there are no fiendish atoms plotting how to fight against human efforts to disintegrate then.</p>\n<h2>If noise is expected, expect reduced impact</h2>\n<p>The second, more general, friction argument, is just a rephrasing of the truism that things are rarely as easy as they seem. This is related to \"<a href=\"http://link.springer.com/article/10.1007%2Fs11023-012-9276-0\">the first step fallacy</a>\", the argument that just because we can start climbing a hill, doesn't mean we can reach the sky.</p>\n<p>Another way of phrasing it is in terms of entropy or noise: adding noise to a process rarely improves it, and almost always makes it worse. Here the \"noise\" is all the unforeseen and unpredictable details that we didn't model, didn't (couldn't) account for, but that would have their bearing on our prediction. These details <em>may</em> make our prediction more certain or faster, but they are unlikely to do so.</p>\n<p>The sci-fi authors of 1960 didn't expect that we would give up on space: they saw the first steps into space, and extrapolated to space stations and martian colonies. But this was a fragile model, dependent on continued investment in space exploration, and assuming there would be no setbacks. But changes in government investment and unexpected setbacks were not unheard of: indeed, they were practically certain, and would have messed up any simplistic model.</p>\n<p>Let us return to chain reactions. Imagine that an alien had appeared and told us that our theory of fission was very wrong, that there were completely new and unexpected phenomena that happened at these energies that we hadn't yet modelled. Would this have increased or decreased the likelihood of a chain reaction? This feels like it can only decrease it: the chain reaction depended on a feedback loop, and random changes are more likely to break the loop than reinforce it. Now imagine that the first chain reaction suffered not from an incomplete theory, but from very sloppy experimental proceeding: now we're nearly certain we won't see the chain reaction, as this kind of noise degraded very strongly towards the status quo.</p>\n<p>So why then, were the doubters wrong to claim that the chain reaction wouldn't work? Because we were pretty certain at the time that these noises wouldn't materialise. We didn't only have a theory that said we should expect to see a chain reaction, barring unexpected phenomena; we had a well-tested theory that said we should not expect to see unexpected phenomena. We had an anti-noise theory: any behaviour that potentially broke the chain reaction would have been a great surprise. Assuming a minimum of competence of the experimenters (a supposition backed up by history), success was the most likely outcome.</p>\n<p>Contrast that with AI predictions: here, we expect noise. We expect AI to be different from our current models, we expect developments to go in unpredictable directions, we expect to see problems that are not evident from our current vantage point. All this noise is likely to press against our current model, increasing its uncertainty, extending its timeline. Even if our theory was much more developed that it is now, even if we thought about it for a thousand years and had accounted for every eventuality <em>we could think of</em>, if we expect that there is still noise, we should caveat our prediction.</p>\n<h2>Who cares?</h2>\n<p>Right, so we may be justified in increasing our uncertainty about the impact of AI foom, and in questioning the timeline. But what difference does it make in practice? Even with all the caveats, there is still a worryingly high probability of a fast, deadly foom, well worth putting all our efforts into preventing. And slow, deadly fooms aren't much better, either! So how is the argument relevant?</p>\n<p>It becomes relevant in accessing the relative worth of different interventions. For instance, one way of containing an AI would be to build a community of fast uploads around it: with the uploads matching the AI in reasoning speed, they have a higher chance of controlling it. Or we could try and build capacity for adaptation at a later date: if the AIs have a slow takeoff, it might be better to equip the people of the time with the tools to contain it (since they will have a much better understanding of the situation), rather than do it all ahead of time. Or we could try and build Oracles or&nbsp;<a href=\"/lw/gmx/domesticating_reduced_impact_ais/\">reduced impact AIs</a>, hoping that we haven't left out anything important.</p>\n<p>All these interventions share a common feature: they are stupid to attempt in the case of a strong, fast foom. They have practically no chance of working, and are just a waste of time and effort. If, however, we increase the chances of weaker, slower fooms, then they start to seem more attractive - possibly worth putting some effort into, in case the friendly AI approach doesn't bear fruits in time.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"pGqRLe9bFDX2G2kXY": 1, "8daMDi9NEShyLqxth": 1, "sYm3HiWcfZvrGu3ui": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rPBoLRxSJ88jrthEJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 39, "extendedScore": null, "score": 0.000113, "legacy": true, "legacyId": "23172", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 25, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In 1932, Stanley Baldwin, prime minister of the largest empire the world had ever seen, proclaimed that \"<a href=\"http://en.wikipedia.org/wiki/The_bomber_will_always_get_through\">The bomber will always get through</a>\". Backed up by most of the professional military opinion of the time, by the experience of the first world war, and by reasonable extrapolations and arguments, he laid out a vision of the future where the unstoppable heavy bomber would utterly devastate countries if a war started. Deterrence - building more bombers yourself to threaten complete retaliation - seemed the only counter.</p>\n<p>And yet, things <a href=\"http://en.wikipedia.org/wiki/Battle_of_Britain\">didn't turn out</a> <a href=\"http://en.wikipedia.org/wiki/Strategic_bombing_during_World_War_II\">that way</a>. Against all past trends, the light fighter plane surpassed the heavily armed bomber in aerial combat, the development of radar changed the strategic balance, and cities and industry proved much more resilient to bombing than anyone had a right to suspect.</p>\n<p>Could anyone have predicted these changes ahead of time? Most probably, no. All of these ran counter to what was known and understood, (and radar was a completely new and unexpected development). What could and should have been predicted, though, was that <em>something</em> would happen to weaken the impact of the all-conquering bomber. The extreme predictions would be unrealistic; frictions, technological changes, changes in military doctrine and hidden, unknown factors, would undermine them.</p>\n<p>This is what I call the \"generalised friction\" argument. Simple predictive models, based on strong models or current understanding, will likely not succeed as well as expected: there will likely be delays, obstacles, and unexpected difficulties along the way.</p>\n<p>I am, of course, thinking of AI predictions here, specifically of the Omohundro-Yudkowsky model of AI <a href=\"/lw/we/recursive_selfimprovement/\">recursive self-improvements</a> that rapidly reach great power, with convergent instrumental goals that make the AI into a <a href=\"http://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/\">power-hungry expected utility maximiser</a>. This model I see as the \"supply and demand curve\" of AI prediction: too simple to be true in the form described.</p>\n<p>But the supply and demand curves are generally approximately true, especially over the long term. So this isn't an argument that the Omohundro-Yudkowsky model is wrong, but that it will likely not happen as flawlessly as described. Ultimately, the \"bomber will always get through\" turned out to be true: but only in the form of the ICBM. If you take the old arguments and replace \"bomber\" with \"ICBM\", you end with strong and accurate predictions. So \"the AI may not foom in the manner and on the timescales described\" is not saying \"the AI won't foom\".</p>\n<p>Also, it should be emphasised that this argument is strictly about our predictive ability, and does not say anything about the capacity or difficulty of AI per se.<a id=\"more\"></a></p>\n<h2 id=\"Why_frictions_\">Why frictions?</h2>\n<p>An analogy often used for AI is that of the <a href=\"/lw/h8m/being_halfrational_about_pascals_wager_is_even/\">nuclear chain reaction</a>: here is a perfect example of a recursive improvement, as the chain reaction grows and grows indefinitely. Scepticism about the chain reaction was unjustified, though experts were far too willing to rule it out ahead of time, based on unsound heuristics.</p>\n<p>In contrast, many examples of simple models were slowed or derailed by events. The examples that came immediately to mind, for me, were the bomber example, the failure of expansion into space after the first moon landing, and the failure of early AI predictions. To be fair, there are also examples of unanticipated success, often in economic policy, but even in <a href=\"http://en.wikipedia.org/wiki/G.I._Bill\">government</a><a href=\"http://en.wikipedia.org/wiki/Clean_Air_Act_1956\"> interventions</a>. But generally, dramatic predictions fail, either by being wrong or by being too optimistic on the timeline. Why is this?</p>\n<h2 id=\"Beware_the_opposition\">Beware the opposition</h2>\n<p>One reason that predictions fail is because they underestimate human opposition. The bomber fleets may have seemed invincible, but that didn't take into account that large number of smart people were working away to try and counter them. The solution turned out to be improved fighters and radar; but even without knowing that, it should have been obvious <em>some</em> new methods or technologies were going to be invented or developed. Since the strength of the bomber depended on a certain strategic landscape, it should have been seen that deliberate attempts to modify that landscape would likely result in a reduction of the bomber's efficacy.</p>\n<p>Opposition is much harder to <a href=\"http://en.wikipedia.org/wiki/Game_theory\">model</a>, especially in such a wide area as modern warfare and technology. Still, theorisers should realised that there would have been some opposition, and that, historically, ways have been found to counter most weapons, in ways that were not obvious at the time of the weapon's creation. It is easier to change the strategic landscape than to preserve it, so anything that depends on the current strategic landscape will most likely be blunted by human effort.</p>\n<p>This kind of friction is less relevant to AI (though see the last section), and not relevant at all to the chain reaction example: there are no fiendish atoms plotting how to fight against human efforts to disintegrate then.</p>\n<h2 id=\"If_noise_is_expected__expect_reduced_impact\">If noise is expected, expect reduced impact</h2>\n<p>The second, more general, friction argument, is just a rephrasing of the truism that things are rarely as easy as they seem. This is related to \"<a href=\"http://link.springer.com/article/10.1007%2Fs11023-012-9276-0\">the first step fallacy</a>\", the argument that just because we can start climbing a hill, doesn't mean we can reach the sky.</p>\n<p>Another way of phrasing it is in terms of entropy or noise: adding noise to a process rarely improves it, and almost always makes it worse. Here the \"noise\" is all the unforeseen and unpredictable details that we didn't model, didn't (couldn't) account for, but that would have their bearing on our prediction. These details <em>may</em> make our prediction more certain or faster, but they are unlikely to do so.</p>\n<p>The sci-fi authors of 1960 didn't expect that we would give up on space: they saw the first steps into space, and extrapolated to space stations and martian colonies. But this was a fragile model, dependent on continued investment in space exploration, and assuming there would be no setbacks. But changes in government investment and unexpected setbacks were not unheard of: indeed, they were practically certain, and would have messed up any simplistic model.</p>\n<p>Let us return to chain reactions. Imagine that an alien had appeared and told us that our theory of fission was very wrong, that there were completely new and unexpected phenomena that happened at these energies that we hadn't yet modelled. Would this have increased or decreased the likelihood of a chain reaction? This feels like it can only decrease it: the chain reaction depended on a feedback loop, and random changes are more likely to break the loop than reinforce it. Now imagine that the first chain reaction suffered not from an incomplete theory, but from very sloppy experimental proceeding: now we're nearly certain we won't see the chain reaction, as this kind of noise degraded very strongly towards the status quo.</p>\n<p>So why then, were the doubters wrong to claim that the chain reaction wouldn't work? Because we were pretty certain at the time that these noises wouldn't materialise. We didn't only have a theory that said we should expect to see a chain reaction, barring unexpected phenomena; we had a well-tested theory that said we should not expect to see unexpected phenomena. We had an anti-noise theory: any behaviour that potentially broke the chain reaction would have been a great surprise. Assuming a minimum of competence of the experimenters (a supposition backed up by history), success was the most likely outcome.</p>\n<p>Contrast that with AI predictions: here, we expect noise. We expect AI to be different from our current models, we expect developments to go in unpredictable directions, we expect to see problems that are not evident from our current vantage point. All this noise is likely to press against our current model, increasing its uncertainty, extending its timeline. Even if our theory was much more developed that it is now, even if we thought about it for a thousand years and had accounted for every eventuality <em>we could think of</em>, if we expect that there is still noise, we should caveat our prediction.</p>\n<h2 id=\"Who_cares_\">Who cares?</h2>\n<p>Right, so we may be justified in increasing our uncertainty about the impact of AI foom, and in questioning the timeline. But what difference does it make in practice? Even with all the caveats, there is still a worryingly high probability of a fast, deadly foom, well worth putting all our efforts into preventing. And slow, deadly fooms aren't much better, either! So how is the argument relevant?</p>\n<p>It becomes relevant in accessing the relative worth of different interventions. For instance, one way of containing an AI would be to build a community of fast uploads around it: with the uploads matching the AI in reasoning speed, they have a higher chance of controlling it. Or we could try and build capacity for adaptation at a later date: if the AIs have a slow takeoff, it might be better to equip the people of the time with the tools to contain it (since they will have a much better understanding of the situation), rather than do it all ahead of time. Or we could try and build Oracles or&nbsp;<a href=\"/lw/gmx/domesticating_reduced_impact_ais/\">reduced impact AIs</a>, hoping that we haven't left out anything important.</p>\n<p>All these interventions share a common feature: they are stupid to attempt in the case of a strong, fast foom. They have practically no chance of working, and are just a waste of time and effort. If, however, we increase the chances of weaker, slower fooms, then they start to seem more attractive - possibly worth putting some effort into, in case the friendly AI approach doesn't bear fruits in time.</p>", "sections": [{"title": "Why frictions?", "anchor": "Why_frictions_", "level": 1}, {"title": "Beware the opposition", "anchor": "Beware_the_opposition", "level": 1}, {"title": "If noise is expected, expect reduced impact", "anchor": "If_noise_is_expected__expect_reduced_impact", "level": 1}, {"title": "Who cares?", "anchor": "Who_cares_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 48, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["JBadX7rwdcRFzGuju", "ebiCeBHr7At8Yyq9R", "FdcxknHjeNH2MzrTj"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}