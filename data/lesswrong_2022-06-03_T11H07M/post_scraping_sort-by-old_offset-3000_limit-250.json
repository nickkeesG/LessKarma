{"results": [{"createdAt": null, "postedAt": "2011-03-22T08:37:46.395Z", "modifiedAt": null, "url": null, "title": "Rationality Boot Camp", "slug": "rationality-boot-camp", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:54.666Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Jasen", "createdAt": "2009-06-11T15:05:07.288Z", "isAdmin": false, "displayName": "Jasen"}, "userId": "hMDxPMjrPyw8vGzMa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/s887k4Hcqj28cchYo/rationality-boot-camp", "pageUrlRelative": "/posts/s887k4Hcqj28cchYo/rationality-boot-camp", "linkUrl": "https://www.lesswrong.com/posts/s887k4Hcqj28cchYo/rationality-boot-camp", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Boot%20Camp&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Boot%20Camp%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs887k4Hcqj28cchYo%2Frationality-boot-camp%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Boot%20Camp%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs887k4Hcqj28cchYo%2Frationality-boot-camp", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fs887k4Hcqj28cchYo%2Frationality-boot-camp", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 635, "htmlBody": "<p>It&rsquo;s been over a year since the Singularity Institute launched our ongoing Visiting Fellows Program and we&rsquo;ve learned a lot in the process of running it.&nbsp;&nbsp;This&nbsp;summer we&rsquo;re going to try something different.&nbsp; We&rsquo;re going to run Rationality Boot Camp.</p>\n<p>We are going to try to take ten weeks and fill them with&nbsp;activities&nbsp;meant to teach mental skills - if there's reading to be done, we'll tell you to get it done in advance.&nbsp; We aren't just aiming to teach skills like betting at the right odds or learning how to take into account others' information, we're going to practice techniques like mindfulness meditation and Rejection Therapy (making requests that you know will be rejected), in order to teach focus, non-attachment, social courage and all the other things that are&nbsp;also&nbsp;needed to produce formidable rationalists.&nbsp; Participants will learn how to draw (so that they can learn how to pay attention to previously unnoticed details, and see that they can do things that previously seemed like mysterious superpowers).&nbsp; We will play games, and switch games every few days, to get used to novelty and practice learning.</p>\n<p>We're going to run A/B tests on you, and track the results to find out which training activities work best, and begin the tradition of evidence-based rationality training.</p>\n<p>In short, we're going to start constructing the kind of program that universities would run if they&nbsp;actually&nbsp;wanted to teach you how to think. <a id=\"more\"></a></p>\n<p>And then at the end, some of us are going to go to Burning Man for training in desert survival and living in an emotionally positive community.</p>\n<p>When I call the program Rationality Boot Camp, I mean this quite literally.&nbsp; Six days per week, participants will rise, meditate, prepare and eat food, attend lectures, participate in group and individual activities and exercise together. &nbsp;</p>\n<p>Everyone who applies needs to have read at least&nbsp;some&nbsp;of the <a href=\"http://wiki.lesswrong.com/wiki/Sequences\" target=\"_blank\">Sequences</a>, and may be assigned particular posts as makeup material - in which case you will need to read them&nbsp;before&nbsp;you arrive and you may be turned away otherwise.&nbsp; Apart from that, we'll look for a mix of people who've demonstrated high productivity and who already seem like good epistemic rationalists.&nbsp; The program will begin in the first week of June and continue through mid-August.&nbsp; We will cover room, board and airfare.&nbsp;&nbsp;We're going to try to take this up to the next level of awesome.&nbsp; It's our first time trying something this ambitious and there&nbsp;will&nbsp;be speedbumps - and if that sounds very scary, consider applying next year when we'll know more for certain about how to teach people courage and the art of overcoming setbacks.&nbsp; But if you're the sort of person who wants to be part of this program&nbsp;today, instead of putting it off into the indefinite future of maybe-never - or if you know that's the sort of person you&nbsp;want&nbsp;to be, and you're willing to put in the effort to reach up to that - then&nbsp;<a href=\"https://singularityinstitute.wufoo.com/forms/rationality-boot-camp-application/\" target=\"_blank\">send in an application</a>.&nbsp;</p>\n<p>Edit:</p>\n<p>\n<p>Attention: &nbsp;Anyone still interested in attending the course must get their application in by midnight on Friday the 8th of April. &nbsp;I would like to make the final decision about who to accept by mid April and need to finish interviewing applicants before then. &nbsp; &nbsp; &nbsp; &nbsp;</p>\n<div>I expect to accept between 10 and 15 people this summer.</div>\n</p>\n<p>I expect to make all decisions about acceptance before the end of April and will try to do so sooner. &nbsp;I will start scheduling skype interviews in a few days and will <em>not</em>&nbsp;wait until an arbitrary date before accepting people. &nbsp;Apply as soon as possible to maximize your chance of being considered for this summer!<br />Don't worry if you're not chosen this time. &nbsp;This program is an experiment, and if all goes well we will be holding holding several (even better!) programs like it each year. &nbsp;If we never hold it again, you probably didn't miss much. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "s887k4Hcqj28cchYo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 79, "baseScore": 96, "extendedScore": null, "score": 0.000175, "legacy": true, "legacyId": "6358", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 96, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 202, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T11:29:35.803Z", "modifiedAt": null, "url": null, "title": "Designing serious games - a request for help", "slug": "designing-serious-games-a-request-for-help", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.526Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taryneast", "createdAt": "2010-11-29T20:51:06.328Z", "isAdmin": false, "displayName": "taryneast"}, "userId": "xD8wjhiTvwbXdKirW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mAK7ryHLq5PJqoXLN/designing-serious-games-a-request-for-help", "pageUrlRelative": "/posts/mAK7ryHLq5PJqoXLN/designing-serious-games-a-request-for-help", "linkUrl": "https://www.lesswrong.com/posts/mAK7ryHLq5PJqoXLN/designing-serious-games-a-request-for-help", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Designing%20serious%20games%20-%20a%20request%20for%20help&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADesigning%20serious%20games%20-%20a%20request%20for%20help%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmAK7ryHLq5PJqoXLN%2Fdesigning-serious-games-a-request-for-help%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Designing%20serious%20games%20-%20a%20request%20for%20help%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmAK7ryHLq5PJqoXLN%2Fdesigning-serious-games-a-request-for-help", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmAK7ryHLq5PJqoXLN%2Fdesigning-serious-games-a-request-for-help", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 205, "htmlBody": "<p>We need some ideas for <a href=\"/lw/4fp/fun_and_games_with_cognitive_biases/\">serious games</a>. Games that will help us be better. Games that reward us for improving ourselves (even if just by the satisfaction of seeing our scores improve). Games that will help us in our quest of <a href=\"/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/\">Tsoyoku Naritai</a></p>\n<p>We've got an upcoming <a href=\"/lw/4vu/project_ideas_for_the_london_hackday/\">hackday in London</a> - where we'll have a (small) bunch of people able to code up any good ideas into something usable... but we need **you** to help us come up with a whole bunch of good ideas.&nbsp;</p>\n<p>To start with, they should be simple ideas - not as complex as <a href=\"/lw/3o8/rationalist_clue/\">Rationalist Clue</a> (which is an awesome idea... but we all have dayjobs too). I've got in mind something like the kinds of games you see at <a href=\"http://www.lumosity.com/\">luminosity</a></p>\n<p>The ideas should address individual biases - a way of training us to: a) recognise when we've accidentally engaged a bias b) reward us when we find a way to get the \"right answer\" in an unbiased manner.</p>\n<p>&nbsp;</p>\n<p>We can do the programming (more help would of course be welcome), we can even come up with some ideas of our own...&nbsp;</p>\n<p>but we are few, and you are many... and the more ideas we get, the better we can choose between them... so let's roll.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mAK7ryHLq5PJqoXLN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 18, "extendedScore": null, "score": 6.930045166760218e-07, "legacy": true, "legacyId": "6361", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Ytr4dJT79sCBuuEjG", "DoLQN5ryZ9XkZjq5h", "tQ5AxChGZz5RvWBD2", "nEt2MhG8rbmvhrdjG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T12:06:16.404Z", "modifiedAt": null, "url": null, "title": "Rationality, Singularity, Method, and the Mainstream", "slug": "rationality-singularity-method-and-the-mainstream", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.560Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mitchell_Porter", "createdAt": "2009-05-28T02:36:19.394Z", "isAdmin": false, "displayName": "Mitchell_Porter"}, "userId": "fjERoRhgjipqw3z2b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F75MwixdkpcxHDTsj/rationality-singularity-method-and-the-mainstream", "pageUrlRelative": "/posts/F75MwixdkpcxHDTsj/rationality-singularity-method-and-the-mainstream", "linkUrl": "https://www.lesswrong.com/posts/F75MwixdkpcxHDTsj/rationality-singularity-method-and-the-mainstream", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%2C%20Singularity%2C%20Method%2C%20and%20the%20Mainstream&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%2C%20Singularity%2C%20Method%2C%20and%20the%20Mainstream%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF75MwixdkpcxHDTsj%2Frationality-singularity-method-and-the-mainstream%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%2C%20Singularity%2C%20Method%2C%20and%20the%20Mainstream%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF75MwixdkpcxHDTsj%2Frationality-singularity-method-and-the-mainstream", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF75MwixdkpcxHDTsj%2Frationality-singularity-method-and-the-mainstream", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1450, "htmlBody": "<p>Upon reading <a href=\"/lw/4wm/rationality_boot_camp/\">this</a>, my immediate response was: <br /><br />What does this have to do with the Singularity Institute's purpose? You're the Singularity Institute, not the Rationality Institute. <br /><br />I can see that, if you have a team of problem solvers, having a workshop or a retreat designed to enhance their problem-solving skills makes sense. But as described, there's no indication that graduates of the Boot Camp will then go on to tackle conceptual problems of AI design or tactics for the Singularity. <br /><br />What seems to be happening is that, instead of making connections to people who know about cognitive neuroscience, decision theory, and the theory of algorithms, there is a drive to increase the number of people who share a particular subjective philosophy and subjective practice of rationality - perhaps out of a belief that the discoveries needed to produce Friendly AI won't be made by people who haven't adopted this philosophy and this practice. <br /><br />I find this a little ominous for several reasons: <br /><br />It could be a symptom of <a href=\"http://en.wikipedia.org/wiki/Mission_creep\">mission creep</a>. The mission, as I recall, was to design and code a Friendly artificial intelligence. But \"produc[ing] formidable rationalists\" sounds like it's meant to make the world better in a generalized way, by producing people who can shine the light of rationality into every dark corner, et cetera. Maybe someone should be doing this, but it's potentially a huge distraction from the more important task. <br /><br />Also, I'm far more impressed by the specific ideas Eliezer has come up with over the years - the concept of seed AI; the concept of Friendly AI; CEV; TDT - than by his ruminations about rationality in the Sequences. They're interesting, yes. It's also interesting to hear Feynman talk about how to do science, or to read Einstein's reflections on life. But the discoveries in physics which complemented those of Einstein and Feynman weren't achieved by people who studied their intellectual biographies and sought to reproduce their subjective method; they were achieved by other people of high intelligence who also studied the physical world. <br /><br />It may seem at times that the supposed professionals in the FAI-relevant fields I listed above are terminally obtuse, for having to failed to grasp their own relevance to the FAI problem, or the schema of the solution as proposed by SIAI. That, and the way that people working in AI are just sleepwalking towards the creation of superhuman intelligence without grasping that the world won't get a second chance if they get machine intelligence very right but machine values very wrong - all of that could reinforce the attitude that to have any chance of succeeding, SIAI needs to have a group of people who share a subjective methodology, and not just domain expertise. <br /><br />However, I think we are rapidly approaching a point where a significant number of people are going to understand that the \"intelligence explosion\" will above all be about the utility function dominating that event. There have been discussions about how a proto-friendly AI might try to infer the human utility-function schema, how to do so without creating large numbers of simulated persons who might be subjected to cognitive vivisection, and so forth. But I suspect that will never happen, at least not in this brute-force fashion, in which whole adult brains might be scanned, simulated, modified and so on, for the purpose of reverse-engineering the human decision architecture. <br /><br />My expectation is that the presently small fields of machine ethics and neuroscience of morality will grow rapidly and will come into contact, and there will be a distributed research subculture which is consciously focused on determining the optimal AI value system in the light of biological human nature. In other words, there will be human minds trying to answer this question long before anyone has the capacity to direct an AI to solve it. We should expect that before we reach the point of a Singularity, there will be a body of educated public opinion regarding what the ultimate utility function or decision method (for a transhuman AI) should be, deriving from work in those fields which ought to be FAI-relevant but which have yet to engage with the problem. In other words, they <em>will</em> be collectively engaging with the problem before anyone gets to outsource the necessary research to AIs. <br /><br />The conclusion I draw from this for the present is that there needs to be more preparation for this future circumstance, and less attempt to spread a set of methods intended just to facilitate generalized rationality. People who want to see Friendly AI created need to be ready to talk with researchers in those other fields, who never attended \"Rationality Boot Camp\" but who will nonetheless be independently coming to the threshold of thinking about the FAI problem (perhaps under a different name) and developing solutions to it. When the time comes, there will be a phase transition in academia and R&amp;D, from ignoring the problem to wanting to work on it. The creation of ethical artificial minds is not going to be the work of one startup or one secret military project, working in isolation from mainstream intellectual culture; nor is it a mirage that will hang on the horizon of the future forever. It will happen because of that phase transition, and tens of thousands of people will be working on it, in one way or another. That doesn't mean they all get to be relevant or right, but there will be a pre-Singularity ferment that develops very quickly, and in which certain specific understandings of the people who <em>did</em> labor in isolation on this problem for many years will be surpassed and superseded. People will have ingrained assumptions about the answer to subproblem X or subproblem Y - assumptions to which one will have grown accustomed due to the years of isolation spent trying to solve all subproblems at once - and one must be ready for these answer-schemas to be junked when the time finally arrives that the true experts in that area deign to turn their attention to the subproblem in question. <br /><br />One other observation about \"lessons in rationality\". Luke <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">recently posted</a> about LW's philosophy as being just a form of \"naturalism\" (i.e. materialism), a view that has already been well-developed by mainstream philosophy, but it was countered that these philosophers have few results to show for their efforts, even if they get the basics right. I think the crucial question, regarding both LW's originality and its efficacy, concerns <strong>method</strong>. It has been demonstrated that there is this other intellectual culture, the naturalistic sector of analytic philosophy, which shares a lot of the basic LW worldview. But are there people \"producing results\" (or perhaps just arriving at opinions) in a way comparable to the way that opinions are being produced here? For example, Will Sawin <a href=\"/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q9l\">suggested</a> that LW's epistemic method consists of first imagining how a perfectly rational being would think about a problem. As a method of rationality, this is still very \"subjective\" and \"intuitive\" - it's not as if you're plugging numbers into a Bayesian formula and computing the answer, which remains the idealized standard of rationality here. <br /><br />So, if someone wants to do some comparative scholarship regarding methods of rationality that already exist out there, an important thing to recognize is that LW's method or practice, whatever it is, is a subjective method. I don't call it subjective in order to be derogatory, but just to point out that it is a method intended to be used by conscious beings, whose practice has to involve conscious awareness, whether through real-time reflection or after-the-fact analysis of behavior and results. The LW method is not an algorithm or a computation in the normal sense, though these non-subjective epistemological ideas obviously play a normative and inspirational role for LW humans trying to \"refine their rationality\". So if there is \"prior art\", if LW's methods have been anticipated or even surpassed somewhere, it's going to be in some tradition, discipline, or activity where the analysis of subjectivity is fairly advanced, and not just one where some calculus of objectivities, like probability theory or computer science, has been raised to a high art. <br /><br />For that matter, the art of getting the best performance out of the human brain won't just involve analysis; not even analysis of subjectivity is the whole story. The brain spontaneously synthesizes and creates, and one also needs to identify the conditions under which it does so most fluently and effectively.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NrvXXL3iGjjxu5B7d": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F75MwixdkpcxHDTsj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 52, "extendedScore": null, "score": 0.0005743363696095945, "legacy": true, "legacyId": "6362", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 38, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["s887k4Hcqj28cchYo", "oTX2LXHqXqYg2u4g6"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T12:25:00.688Z", "modifiedAt": null, "url": null, "title": "Bayesian Methods Reading List", "slug": "bayesian-methods-reading-list", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.233Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gxaj4KAzYhSRgqvsh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Zjd3vjCy5BiuQ7Cuh/bayesian-methods-reading-list", "pageUrlRelative": "/posts/Zjd3vjCy5BiuQ7Cuh/bayesian-methods-reading-list", "linkUrl": "https://www.lesswrong.com/posts/Zjd3vjCy5BiuQ7Cuh/bayesian-methods-reading-list", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20Methods%20Reading%20List&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20Methods%20Reading%20List%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZjd3vjCy5BiuQ7Cuh%2Fbayesian-methods-reading-list%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20Methods%20Reading%20List%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZjd3vjCy5BiuQ7Cuh%2Fbayesian-methods-reading-list", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZjd3vjCy5BiuQ7Cuh%2Fbayesian-methods-reading-list", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>I'm reading <a href=\"http://cocosci.berkeley.edu/tom/bayes.html\" target=\"_blank\">this</a>&nbsp;for fun -- tutorials and book recommendations on the Bayesian methods toolboox with a cognitive science/machine learning slant. &nbsp; Comes from the Computational Cognitive Science Lab at Berkeley. &nbsp;I recommend the general 2008 tutorial.&nbsp;</p>\n<p>Useful stuff included in tutorial:</p>\n<p>Parameter estimation</p>\n<p>Model selection</p>\n<p>Why Occam's Razor emerges <em>naturally</em>&nbsp;from the Conservation of Expected Evidence</p>\n<p>Graphical models</p>\n<p>Hierarchical Bayesian models</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Zjd3vjCy5BiuQ7Cuh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 19, "extendedScore": null, "score": 6.930197314762217e-07, "legacy": true, "legacyId": "6363", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T14:14:36.553Z", "modifiedAt": null, "url": null, "title": "collecting successes and deltas", "slug": "collecting-successes-and-deltas", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.268Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MartinB", "createdAt": "2009-04-20T11:11:22.800Z", "isAdmin": false, "displayName": "MartinB"}, "userId": "2BGK5dWpTXzCE7iwF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4SJYf9FbrsPxPTjdB/collecting-successes-and-deltas", "pageUrlRelative": "/posts/4SJYf9FbrsPxPTjdB/collecting-successes-and-deltas", "linkUrl": "https://www.lesswrong.com/posts/4SJYf9FbrsPxPTjdB/collecting-successes-and-deltas", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20collecting%20successes%20and%20deltas&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Acollecting%20successes%20and%20deltas%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4SJYf9FbrsPxPTjdB%2Fcollecting-successes-and-deltas%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=collecting%20successes%20and%20deltas%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4SJYf9FbrsPxPTjdB%2Fcollecting-successes-and-deltas", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4SJYf9FbrsPxPTjdB%2Fcollecting-successes-and-deltas", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 37, "htmlBody": "<p>It might be useful if we fellow LW'ers collect actual big scale success stories of ourself in real world applications. Since we are supposed to <a title=\"win\" href=\"http://wiki.lesswrong.com/wiki/Rationalists_should_win\">win</a> some real life experiences of actual winning would be great.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4SJYf9FbrsPxPTjdB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 6.930498246474472e-07, "legacy": true, "legacyId": "6364", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T19:51:32.196Z", "modifiedAt": null, "url": null, "title": "The Heilmeier Questions", "slug": "the-heilmeier-questions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.661Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "PbyH3bFJCZjPX5DTp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TyhxgRCD3F9cpanDL/the-heilmeier-questions", "pageUrlRelative": "/posts/TyhxgRCD3F9cpanDL/the-heilmeier-questions", "linkUrl": "https://www.lesswrong.com/posts/TyhxgRCD3F9cpanDL/the-heilmeier-questions", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Heilmeier%20Questions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Heilmeier%20Questions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyhxgRCD3F9cpanDL%2Fthe-heilmeier-questions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Heilmeier%20Questions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyhxgRCD3F9cpanDL%2Fthe-heilmeier-questions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTyhxgRCD3F9cpanDL%2Fthe-heilmeier-questions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 465, "htmlBody": "<p style=\"margin: 0.0px 0.0px 0.0px 0.0px; font: 23.0px Arial;\"><span style=\"font-family: sans-serif; font-size: 13px; line-height: 19px;\"> </span></p>\n<div>Funding agencies like DARPA encourage you to consider a list of questions to guide the development of a good proposal. These are often called the <a title=\"Heilmeier\" href=\"http://en.wikipedia.org/wiki/George_H._Heilmeier\">Heilmeier</a> questions or Heilmeier catechism. I often look back at this checklist when starting a new research project; they provide good inspiration, but as I read LW, I realize they could use reworking. These are the original questions:</div>\n<ol>\n<li>What are you trying to do? Articulate your objectives using absolutely no jargon.</li>\n<li>How is it done today, and what are the limits of current practice?</li>\n<li>What's new in your approach and why do you think it will be successful?</li>\n<li>Who cares?</li>\n<li>If you're successful, what difference will it make?</li>\n<li>What are the risks and the payoffs?</li>\n<li>How much will it cost?</li>\n<li>How long will it take?</li>\n<li>What are the midterm and final \"exams\" to check for success?</li>\n</ol>\n<div>The best question is number 3, which I've seen in a more effective form as \"Why now and not last year or ten years ago?\" This is a perfect outside view question that forces you to confront the possibility that there are lots of smart people around, none of them has done this, and there is probably some good reason for this. You should know the reason before you start, and reasons like \"They weren't smart enough\" or \"They simply never thought about this topic\" are probably incorrect.</div>\n<div>1,5,6,9 are OK but vague. \"What would success look like? Is that what I want?\" is a question often overlooked, even for projects that are personally very important, like picking a career. When I asked myself this question in grad school, I found myself pushed towards changing fields.</div>\n<div>The worst are 7 and 8, which should be \"How much have projects like this one cost? How long have projects like this one taken?\"</div>\n<div>The usefulness of such catechisms is a delicate balancing act. The questions should be broad enough to apply to many situations, but specific enough to start a specific train of thought for each input problem.&nbsp;</div>\n<div>A proposed, simplified revision. I would love feedback.</div>\n<div><strong>So you want to solve problem x using method y.</strong></div>\n<div><ol>\n<li>What difference would it make if you solved this problem? Is that what you want?</li>\n<li>Why hasn't someone already solved this problem? What makes you think what stopped them won't stop you?</li>\n<li>Are there sub-problems to x? Repeat 1 and 2 for these sub-problems.</li>\n<li>Are there other potential methods to solve this problem? If so, why are you considering y and not the others?</li>\n<li>Are there other implications to solving x that you haven't considered? If so, go back to 1.</li>\n<li>If y fails to solve x, what would that teach you that you (hopefully) didn't know at the beginning?</li>\n</ol></div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TyhxgRCD3F9cpanDL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 29, "extendedScore": null, "score": 5.9e-05, "legacy": true, "legacyId": "6366", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T22:22:26.180Z", "modifiedAt": null, "url": null, "title": "Seattle Meetup, Sun Mar 27 5pm", "slug": "seattle-meetup-sun-mar-27-5pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.804Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BGpitdnuSfTerYfCD/seattle-meetup-sun-mar-27-5pm", "pageUrlRelative": "/posts/BGpitdnuSfTerYfCD/seattle-meetup-sun-mar-27-5pm", "linkUrl": "https://www.lesswrong.com/posts/BGpitdnuSfTerYfCD/seattle-meetup-sun-mar-27-5pm", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seattle%20Meetup%2C%20Sun%20Mar%2027%205pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeattle%20Meetup%2C%20Sun%20Mar%2027%205pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBGpitdnuSfTerYfCD%2Fseattle-meetup-sun-mar-27-5pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seattle%20Meetup%2C%20Sun%20Mar%2027%205pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBGpitdnuSfTerYfCD%2Fseattle-meetup-sun-mar-27-5pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBGpitdnuSfTerYfCD%2Fseattle-meetup-sun-mar-27-5pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 100, "htmlBody": "<p><span style=\"border-collapse: collapse; font-family: arial, sans-serif; font-size: 13px;\">\n<p><a id=\"more\"></a>Posted for IRL friend User:<a style=\"color: #0065cc;\" href=\"/user/Morgan_Catha/\" target=\"_blank\">Morgan_Catha</a>&nbsp;who doesn't have the Karma to post:</p>\n<p>Hi everyone!</p>\n<p>I'm interested in meeting other aspiring rationalists, so I'd like to invite everyone to another Seattle meetup.</p>\n<p>I haven't spent a lot of time on LW, but I like the general thrust of the site and this seems like a great way to meet people with similar interests.&nbsp;</p>\n<p>Big Time Brewery</p>\n<p>4133 University Way NE</p>\n<p>Seattle, WA&nbsp; 98105</p>\n<p>Sunday, March 27, 5 pm</p>\n<p>&nbsp;</p>\n<p>The place is open to minors until 8 pm.&nbsp; I'll be there with a sign reading \"LW\".</p>\n<p>Also, feel free to email or PM me with questions:&nbsp;&nbsp;<a style=\"color: #0065cc;\" href=\"mailto:morgan.catha@gmail.com\" target=\"_blank\">morgan.catha@gmail.com</a></p>\n<p>&nbsp;</p>\n<p>I'm looking forward to seeing you all!</p>\n</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BGpitdnuSfTerYfCD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 6.931837994057045e-07, "legacy": true, "legacyId": "6365", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-22T23:59:44.995Z", "modifiedAt": null, "url": null, "title": "Madison WI Meetup, Sat Apr 2nd 1PM", "slug": "madison-wi-meetup-sat-apr-2nd-1pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.606Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "drethelin", "createdAt": "2011-03-02T17:38:08.607Z", "isAdmin": false, "displayName": "drethelin"}, "userId": "ZwawHK4dwF53ZDvMM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5MCBJp5kWWFNmGg5x/madison-wi-meetup-sat-apr-2nd-1pm", "pageUrlRelative": "/posts/5MCBJp5kWWFNmGg5x/madison-wi-meetup-sat-apr-2nd-1pm", "linkUrl": "https://www.lesswrong.com/posts/5MCBJp5kWWFNmGg5x/madison-wi-meetup-sat-apr-2nd-1pm", "postedAtFormatted": "Tuesday, March 22nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Madison%20WI%20Meetup%2C%20Sat%20Apr%202nd%201PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMadison%20WI%20Meetup%2C%20Sat%20Apr%202nd%201PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5MCBJp5kWWFNmGg5x%2Fmadison-wi-meetup-sat-apr-2nd-1pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Madison%20WI%20Meetup%2C%20Sat%20Apr%202nd%201PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5MCBJp5kWWFNmGg5x%2Fmadison-wi-meetup-sat-apr-2nd-1pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5MCBJp5kWWFNmGg5x%2Fmadison-wi-meetup-sat-apr-2nd-1pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 50, "htmlBody": "<p><a id=\"more\"></a>Madison LW Meetup</p>\n<p>When: Saturday, April 2 at 1 PM</p>\n<p>Where: Manna Cafe at 611 N. Sherman Ave</p>\n<p>&nbsp;</p>\n<p>I'll be in the back room, at the big table. I'll be wearing a very unusual hat and a black hoodie. I'll have a sign saying LW. Hopefully we can start up a regular group!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5MCBJp5kWWFNmGg5x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 6.932105306742151e-07, "legacy": true, "legacyId": "6367", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T00:38:01.980Z", "modifiedAt": null, "url": null, "title": "rationality for turing machines", "slug": "rationality-for-turing-machines", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:03.619Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EKBYY6LxzaFzDqGLm/rationality-for-turing-machines", "pageUrlRelative": "/posts/EKBYY6LxzaFzDqGLm/rationality-for-turing-machines", "linkUrl": "https://www.lesswrong.com/posts/EKBYY6LxzaFzDqGLm/rationality-for-turing-machines", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20rationality%20for%20turing%20machines&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Arationality%20for%20turing%20machines%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEKBYY6LxzaFzDqGLm%2Frationality-for-turing-machines%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=rationality%20for%20turing%20machines%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEKBYY6LxzaFzDqGLm%2Frationality-for-turing-machines", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEKBYY6LxzaFzDqGLm%2Frationality-for-turing-machines", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 419, "htmlBody": "<p><em>What can we say about rational behaviour among realizable algorithms, i.e. Turing machines? What limits can we put on their performance? What exactly does Cox's theorem have to say?</em></p>\n<p>Cox's theorem tells us that optimally rational beliefs imply Bayesian reasoning. But such results are independent of specific models of computation. Can we rigorously apply machinery like Cox's theorem if we state the problem in terms of optimal behaviour among general recursive algorithms -- i.e. realizable algorithms.</p>\n<p>To make that a little more concrete: take the problem of writing an algorithm (designing a Turing machine) that processes sensor inputs and writes actions as output.&nbsp;As a concrete Turing machine, the algorithm consists of discrete steps at which it either writes an output symbol (corresponding to some action) or does not (which we can interpret as some null action). There is a second Turing machine corresponding to the external world that responds to each action by changing its state, which feeds back into the sensor inputs of our algorithm. We seek the algorithm&nbsp;maximizing&nbsp;the expectation of some pre-specified utility function U, defined over states of the world. To define this rigorously we need to nail down how utility is summed over time, perhaps something along the lines of <a href=\"http://portal.acm.org/citation.cfm?id=1325248\">Legg and Hutter's formalism</a> would be appropriate. Or perhaps we can just terminate the process after some pre-specified number of steps.</p>\n<p>So it seems to me that Cox's theorem establishes that there must be a Bayes-optimal decision at any point in time, and a \"Bayes oracle\" that always outputs this decisions would be optimal among all algorithms. But such an oracle is certainly not&nbsp;directly&nbsp;realizable as a Turing machine, since at each time step a Turing machine simply changes state, moves the tape, and writes a symbol, whereas a full Bayesian update could require arbitrary amounts of computation. And there is no option of not acting, only of outputting the null action.</p>\n<p>One approach would be to make a Bayes-optimal decision about how much computation to spend on each update that&nbsp;takes into account opportunity costs. But while this seems intuitively reasonable, there is also an opportunity cost to performing this computation, so the question really is how sure we can be that this is the <em>best</em> design choice.</p>\n<p>Nevertheless, it seems quite reasonable to write Bayesian algorithms, and indeed to expect them to perform optimally on average. But can we formalize and prove a result along these lines? Does someone know of existing work in this direction? Perhaps Cox's theorem or something similar applies in some direct way that I haven't&nbsp;perceived?</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EKBYY6LxzaFzDqGLm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 6.932210472310951e-07, "legacy": true, "legacyId": "6368", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T01:43:20.521Z", "modifiedAt": null, "url": null, "title": "Rationalist sonnets about being a person", "slug": "rationalist-sonnets-about-being-a-person", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.274Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/nXQcZbiZDZsTYnrQv/rationalist-sonnets-about-being-a-person", "pageUrlRelative": "/posts/nXQcZbiZDZsTYnrQv/rationalist-sonnets-about-being-a-person", "linkUrl": "https://www.lesswrong.com/posts/nXQcZbiZDZsTYnrQv/rationalist-sonnets-about-being-a-person", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20sonnets%20about%20being%20a%20person&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20sonnets%20about%20being%20a%20person%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnXQcZbiZDZsTYnrQv%2Frationalist-sonnets-about-being-a-person%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20sonnets%20about%20being%20a%20person%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnXQcZbiZDZsTYnrQv%2Frationalist-sonnets-about-being-a-person", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnXQcZbiZDZsTYnrQv%2Frationalist-sonnets-about-being-a-person", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 268, "htmlBody": "<p><a href=\"http://smallship1.livejournal.com/631270.html?nc=16\">7 sonnets and some comments</a></p>\n<p>A friend tells me that, if there is no soul,<br />There is no clash of body against mind.<br />I hate to be contentious, but I find<br />The case is rather different, on the whole.<br /><br />For flesh and mind are clashing all the time;<br />The flesh says \"eat!\", the mind says \"lose some weight.\"<br />The mind cries \"run!\", the flesh drones \"vegetate,\"<br />The soul is no wise guilty of this crime.<br /><br />Am I the athlete who desires to run,<br />Or else the slugabed who yearns for quiet?<br />Do I crave food, or would I rather diet?<br />The I that speaks is both, and neither one.<br /><br />When flesh and mind contend with shouts obscene<br />I place the soul--the self--smack in between.</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----<a href=\"http://www.smallship1.livejournal.com\">smallship1</a></p>\n<p>&nbsp;</p>\n<div style=\"margin-left: 5px;\">The body and the mind are the two hands<br />that weave the self between them, interplay<br />a dialogue that may change day to day<br />creates consistency. Self understands<br /><br />what neither flesh nor mind can apprehend<br />yet is a fiction and a referee<br />yet needs to be reined in. So fluently<br />its guesses become fantasies and end<br /><br />in things we cannot know, that are not there<br />-God, Hell and Heaven - all ways to deny<br />the simple tasks life gives us. Mortify<br />the flesh, confuse the mind. Hope and despair.<br /><br />The self's a servant. Use it, never let<br />it rule, or you will die full of regret.</div>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----<a href=\"http://www.rozk.livejournal.com\">rozk</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>:</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "nXQcZbiZDZsTYnrQv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 9, "extendedScore": null, "score": 6.932389885838338e-07, "legacy": true, "legacyId": "6371", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T13:24:34.648Z", "modifiedAt": null, "url": null, "title": "Simple embodied cognition hacks", "slug": "simple-embodied-cognition-hacks", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:53.537Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W8ibiHCtywhCnBeMk/simple-embodied-cognition-hacks", "pageUrlRelative": "/posts/W8ibiHCtywhCnBeMk/simple-embodied-cognition-hacks", "linkUrl": "https://www.lesswrong.com/posts/W8ibiHCtywhCnBeMk/simple-embodied-cognition-hacks", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Simple%20embodied%20cognition%20hacks&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASimple%20embodied%20cognition%20hacks%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW8ibiHCtywhCnBeMk%2Fsimple-embodied-cognition-hacks%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Simple%20embodied%20cognition%20hacks%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW8ibiHCtywhCnBeMk%2Fsimple-embodied-cognition-hacks", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW8ibiHCtywhCnBeMk%2Fsimple-embodied-cognition-hacks", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p>I've known that the mind can be affected by the body's actions, but I often forget this when sitting at my computer chair for long stretches, and when standing and interacting in social situations I've subconciously cultivated a passive, non-confrontational but minimally interactive posture. &nbsp;But simple physical actions can act as a mild nootropic for certain situations.</p>\n<p>Article with citations:&nbsp;<a title=\"10 Simple Postures that Boost Performance\" href=\"http://www.spring.org.uk/2011/03/10-simple-postures-that-boost-performance.php\">10 Simple Postures that Boost Performance</a></p>\n<p>Article&nbsp;summary:</p>\n<p>1. Take a powerful pose to feel powerful</p>\n<p>2. Tense muscles for willpower</p>\n<p>3. Cross arms for persistence</p>\n<p>4. Lie down for insight</p>\n<p>5. Nap for cognitive performance, vigour and wakefulness</p>\n<p>6. Hand gestures for persuasion</p>\n<p>7. Gesture to self for comprehension and memory</p>\n<p>8. Smile for happiness</p>\n<p>9. Mimic to empathize</p>\n<p>10. Imitate for comprehension and prediction</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"rfZ6DY88ApBDXFpyW": 1, "fkABsGCJZ6y9qConW": 1, "udPbn9RthmgTtHMiG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W8ibiHCtywhCnBeMk", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 47, "baseScore": 59, "extendedScore": null, "score": 0.00012946709183168085, "legacy": true, "legacyId": "6379", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T16:04:16.620Z", "modifiedAt": null, "url": null, "title": "Folk theories can be useful even when they're entirely wrong", "slug": "folk-theories-can-be-useful-even-when-they-re-entirely-wrong", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.179Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "taw", "createdAt": "2009-03-16T02:43:25.472Z", "isAdmin": false, "displayName": "taw"}, "userId": "vix9BLjt4bHtsCqWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yB3ipMYY6kjrr9aR7/folk-theories-can-be-useful-even-when-they-re-entirely-wrong", "pageUrlRelative": "/posts/yB3ipMYY6kjrr9aR7/folk-theories-can-be-useful-even-when-they-re-entirely-wrong", "linkUrl": "https://www.lesswrong.com/posts/yB3ipMYY6kjrr9aR7/folk-theories-can-be-useful-even-when-they-re-entirely-wrong", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Folk%20theories%20can%20be%20useful%20even%20when%20they're%20entirely%20wrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFolk%20theories%20can%20be%20useful%20even%20when%20they're%20entirely%20wrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyB3ipMYY6kjrr9aR7%2Ffolk-theories-can-be-useful-even-when-they-re-entirely-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Folk%20theories%20can%20be%20useful%20even%20when%20they're%20entirely%20wrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyB3ipMYY6kjrr9aR7%2Ffolk-theories-can-be-useful-even-when-they-re-entirely-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyB3ipMYY6kjrr9aR7%2Ffolk-theories-can-be-useful-even-when-they-re-entirely-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<p>Here's an interesting but very old paper - <a href=\"http://csjarchive.cogsci.rpi.edu/1986v10/i01/p0075p0090/MAIN.PDF\">two theories of Heat Control</a>.</p>\n<p>It discusses mental models of home heating systems (thermostats) non-experts use.</p>\n<p>These models tend to be extremely wrong from theoretical perspective, but surprisingly useful in practice.</p>\n<p>The findings are applicable to a much wider range of subjects than just thermostats, and have certain epistemological significance, especially with regard to compartmentalization.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yB3ipMYY6kjrr9aR7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 25, "extendedScore": null, "score": 4.7e-05, "legacy": true, "legacyId": "6380", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T18:05:42.335Z", "modifiedAt": null, "url": null, "title": "The trouble with teamwork", "slug": "the-trouble-with-teamwork", "viewCount": null, "lastCommentedAt": "2011-03-25T21:48:31.067Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZMrHjRYt7pj8oJubt/the-trouble-with-teamwork", "pageUrlRelative": "/posts/ZMrHjRYt7pj8oJubt/the-trouble-with-teamwork", "linkUrl": "https://www.lesswrong.com/posts/ZMrHjRYt7pj8oJubt/the-trouble-with-teamwork", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20trouble%20with%20teamwork&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20trouble%20with%20teamwork%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMrHjRYt7pj8oJubt%2Fthe-trouble-with-teamwork%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20trouble%20with%20teamwork%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMrHjRYt7pj8oJubt%2Fthe-trouble-with-teamwork", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZMrHjRYt7pj8oJubt%2Fthe-trouble-with-teamwork", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1297, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19px;\"> <!--StartFragment--> </span></span></p>\n<h1><span style=\"font-weight: normal; font-size: small;\"><span lang=\"EN-GB\">I've hated group projects since about Grade 3. I grew up assuming that at some point, working in groups would stop being a series of trials and tribulations, and turn into normal, sane people working just like they would normally, except on a shared problem. Either they would change, or <em>I </em>would change,&nbsp;because I am <em>incredibly bad</em></span><span lang=\"EN-GB\"> at teamwork, at least the kind of it that gets doled out in the classroom. I don&rsquo;t have the requisite people skills to lead a group, but I&rsquo;m too much of a control freak to meekly follow along when the group wants to do a B+ project and I would like an A+. Drama inevitably ensues.</span></span></h1>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I would like to not have this problem. An inability to work in teams seems like a <em>serious</em></span><span lang=\"EN-GB\"> handicap. There are very few jobs that don&rsquo;t involve teamwork, and my choice of future career, nursing, involves a lot.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">My first experiences in the workplace, as a lifeguard, made me feel a <em>little </em></span><span lang=\"EN-GB\">better about this. There was a lot less drama and a lot more just getting the work done. I think it has a lot to do with a) the fact that we&rsquo;re <em>paid</em></span><span lang=\"EN-GB\"> to do a job that&rsquo;s generally pretty easy, and b) the requirements of that job are pretty simple, if not easy. There <em>is </em></span><span lang=\"EN-GB\">drama, but it rarely involves guard rotations or who&rsquo;s going to hose the deck, and I can safely ignore it. Rescues do involve teamwork, but it&rsquo;s a specific sort of teamwork where the roles are all laid out in advance, and that&rsquo;s what we spent most of our training learning. Example: in a three-guard scenario, the guard to notice an unconscious swimmer in the water becomes guard #1: they make a whistle signal to the others and jump in, while guard #2 calls 911 and guard #3 clears the pool and does crowd control. There isn&rsquo;t a lot of room for drama, and there isn&rsquo;t much <em>point</em></span><span lang=\"EN-GB\"> because there is one right way to do things, everyone knows the right way to do things, and there isn&rsquo;t time to fight about it anyway.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I&rsquo;m hoping that working as a nurse in a hospital will be more this and less like the school-project variety of group work. The roles are defined and laid out; they&rsquo;re what we&rsquo;re learning right now in our theory classes. There&rsquo;s less of a time crunch, but there&rsquo;s still, usually, an <em>obviously </em></span><span lang=\"EN-GB\">right way to do things. Maybe it gets more complicated when you have to approach a colleague for, say, not following the hand-hygiene rules, or when the rules the hospital management enforces are obviously <em>not </em></span><span lang=\"EN-GB\">the best way to do things, but those are add-ons to the job, not its backbone.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">But that&rsquo;s for bedside nursing. Research is a different matter, and unfortunately, it&rsquo;s a lot more like school. I&rsquo;m taking a class about research right now, and something like 30% or 40% of our mark is on a group project. We have to design a study from beginning to end: problem, hypothesis, type of research, research proposal, population and sample, methods of measurement, methods of analysis, etc. My excuse that &ldquo;I dislike this because it has absolutely no real-world relevance&rdquo; is downright <em>wrong</em></span><span lang=\"EN-GB\">, because we&rsquo;re doing exactly what real researchers would do, only with much less resources and time, and I <em>do </em></span><span lang=\"EN-GB\">like research and would like to work in that milieu someday.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Conflict with my group-members usually comes because I&rsquo;m more invested in the outcome than the others. I have more motivation to spend time on it, and a higher standard for \"good enough\". Even if I think the assignment is stupid, I want to do it properly, partly for grades and partly because I hate <em>not </em></span><span lang=\"EN-GB\">doing things properly. I don&rsquo;t want to lead the group, because I know I&rsquo;m terrible at it, but no one else wants to either because they don&rsquo;t care either way. I end up feeling like a slave driver who isn&rsquo;t very good at her job.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">This time I had a new sort of problem. A group asked me to join them because they thought I was smart and would be a good worker. They set a personal deadline to have the project finished nearly a month before it was due. They had a group meeting, which I couldn&rsquo;t go to because I was at work, and assigned sections, and sent out an email with an outline. I skimmed the email and put it aside for later, since it seemed less than urgent to me. ...And all of a sudden, at our next meeting, the project was <em>nearly finished</em></span><span lang=\"EN-GB\">. No one had hounded me; they had just gone ahead and done it. Maybe they had a schema in their heads that hounding the non-productive members of the team would lead to drama, but I was offended, because I felt that in my case it <em>wouldn&rsquo;t </em></span><span lang=\"EN-GB\">have. I would have overridden my policy of doing my work at the last minute, and just gotten it done. It&rsquo;s not like I didn&rsquo;t care about our final grade. <span style=\"mso-spacerun: yes;\">&nbsp;</span></span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">My pride was hurt (the way my classmate told me was by looking at my computer screen in the library, where I&rsquo;d started to do the part assigned to me in the outline, and saying &ldquo;you might as well not save that, I already did it.&rdquo;) I didn&rsquo;t feel like fighting about it, so I emailed the prof and asked if I could do the project on my own instead of with a team. She seemed confused that I wanted to do <em>extra </em></span><span lang=\"EN-GB\">work, but assented.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I didn&rsquo;t want to do extra work. I wanted to <em>avoid </em></span><span lang=\"EN-GB\">the work of team meetings, team discussions, team drama... But that&rsquo;s not how real-world research works. Refusing to play their game means I lose an opportunity to improve my teamwork skills, and I&rsquo;m going to <em>need </em></span><span lang=\"EN-GB\">those someday, and not just the skills acquired through lifeguarding. Either I need to turn off my control-freak need to have things <em>my </em></span><span lang=\"EN-GB\">way, or I need to become charismatic and good at leading groups, and to do either of those things, I need a venue to practice.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Does anyone else here have the same problem I do? Has anyone <em>solved </em></span><span lang=\"EN-GB\">it? Does anyone have tips for ways to improve?</span></p>\n<p class=\"MsoNormal\">Edit: reply to comment by jwendy, concerning my 'other' kind of problem.&nbsp;</p>\n<p class=\"MsoNormal\"><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">\"I probably didn't say enough about it in the article, if you thought it seemed glossed over, but I thought a lot about why this happened at the time, and I was pretty upset (more than I should have been, really, over a school project) and that's why I left the group...because unlike type#2 team members, I actually cared a&nbsp;<em style=\"font-style: italic;\">lot</em>about making a fair contribution and felt like shit when I hadn't. I never consciously decided to procrastinate, either...I just had a lot of other things on my plate, which is pretty much inevitable during the school year, and all of a sudden,&nbsp;<em style=\"font-style: italic;\">foom!</em>, my part of the project is done because one of the girls was&nbsp;<em style=\"font-style: italic;\">bored on the weekend</em>&nbsp;and had nothing better to do. (Huh? When does this&nbsp;<em style=\"font-style: italic;\">ever</em>&nbsp;happen?)</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">So I guess I'm like a team #2 member in that I procrastinate when I can get away with it, but like a team#1 member in that I do want to turn in quality work and get an A+. And I want it to my&nbsp;<em style=\"font-style: italic;\">my</em>&nbsp;quality work, not someone else's with my name on it.\"</p>\n</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I think it was justified to be <em>surprised </em>when the new kind of problem happened to me. If I'm more involved/engaged than all the students I've worked with in the past, that doesn't mean I'm the most engaged, but it does mean I have a schema in my brain for 'no one has their work finished until a week after they say they will'.&nbsp;</span></p>\n<!--EndFragment-->\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"uL87Bw3TKzsYFMpZp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZMrHjRYt7pj8oJubt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 19, "extendedScore": null, "score": 6.935089579095685e-07, "legacy": true, "legacyId": "6382", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T19:13:17.131Z", "modifiedAt": null, "url": null, "title": "Link: Who Is Afraid Of The Singularity (NPR)", "slug": "link-who-is-afraid-of-the-singularity-npr", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.031Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d3tj7D9hk6KiWXK3x/link-who-is-afraid-of-the-singularity-npr", "pageUrlRelative": "/posts/d3tj7D9hk6KiWXK3x/link-who-is-afraid-of-the-singularity-npr", "linkUrl": "https://www.lesswrong.com/posts/d3tj7D9hk6KiWXK3x/link-who-is-afraid-of-the-singularity-npr", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Who%20Is%20Afraid%20Of%20The%20Singularity%20(NPR)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Who%20Is%20Afraid%20Of%20The%20Singularity%20(NPR)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd3tj7D9hk6KiWXK3x%2Flink-who-is-afraid-of-the-singularity-npr%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Who%20Is%20Afraid%20Of%20The%20Singularity%20(NPR)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd3tj7D9hk6KiWXK3x%2Flink-who-is-afraid-of-the-singularity-npr", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd3tj7D9hk6KiWXK3x%2Flink-who-is-afraid-of-the-singularity-npr", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 10, "htmlBody": "<p>A standard pop-news article on the singularity, focus on Kurzweil</p>\n<p><a href=\"http://www.npr.org/blogs/13.7/2011/03/23/134762846/who-is-afraid-of-the-singularity?sc=fb&amp;cc=fp\">http://www.npr.org/blogs/13.7/2011/03/23/134762846/who-is-afraid-of-the-singularity?sc=fb&amp;cc=fp</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d3tj7D9hk6KiWXK3x", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 5, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "6383", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-23T19:31:17.926Z", "modifiedAt": null, "url": null, "title": "Sean Carroll: Does the Universe Need God? [link]", "slug": "sean-carroll-does-the-universe-need-god-link", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:55.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dreaded_Anomaly", "createdAt": "2010-12-30T06:38:34.106Z", "isAdmin": false, "displayName": "Dreaded_Anomaly"}, "userId": "sBHF4CXWBLakPFzfu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XEamue7T7WJvkHZmG/sean-carroll-does-the-universe-need-god-link", "pageUrlRelative": "/posts/XEamue7T7WJvkHZmG/sean-carroll-does-the-universe-need-god-link", "linkUrl": "https://www.lesswrong.com/posts/XEamue7T7WJvkHZmG/sean-carroll-does-the-universe-need-god-link", "postedAtFormatted": "Wednesday, March 23rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sean%20Carroll%3A%20Does%20the%20Universe%20Need%20God%3F%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASean%20Carroll%3A%20Does%20the%20Universe%20Need%20God%3F%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXEamue7T7WJvkHZmG%2Fsean-carroll-does-the-universe-need-god-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sean%20Carroll%3A%20Does%20the%20Universe%20Need%20God%3F%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXEamue7T7WJvkHZmG%2Fsean-carroll-does-the-universe-need-god-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXEamue7T7WJvkHZmG%2Fsean-carroll-does-the-universe-need-god-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2311, "htmlBody": "<p><a href=\"http://preposterousuniverse.com/writings/dtung/\">Does the Universe Need God? (essay by Sean Carroll)</a></p>\n<p>In this essay, Sean Carroll:</p>\n<ul>\n<li>\n<p>Dissolves the problem of \"creation from nothing\":</p>\n<blockquote>A provocative way of characterizing these beginning cosmologies is to say that \"the universe was created from nothing.\" Much debate has gone into deciding what this claim is supposed to mean. Unfortunately, it is a fairly misleading natural-language translation of a concept that is not completely well-defined even at the technical level. Terms that are imprecisely defined include \"universe,\" \"created,\" \"from,\" and \"nothing.\" (We can argue about \"was.\")<br /> <br /> The problem with \"creation from nothing\" is that it conjures an image of a pre-existing \"nothingness\" out of which the universe spontaneously appeared &ndash; not at all what is actually involved in this idea. Partly this is because, as human beings embedded in a universe with an arrow of time, we can't help but try to explain events in terms of earlier events, even when the event we are trying to explain is explicitly stated to be the earliest one. It would be more accurate to characterize these models by saying \"there was a time such that there was no earlier time.\"<br /> <br /> To make sense of this, it is helpful to think of the present state of the universe and work backwards, rather than succumbing to the temptation to place our imaginations \"before\" the universe came into being. The beginning cosmologies posit that our mental journey backwards in time will ultimately reach a point past which the concept of \"time\" is no longer applicable. Alternatively, imagine a universe that collapsed into a Big Crunch, so that there was a future end point to time. We aren't tempted to say that such a universe \"transformed into nothing\"; it simply has a final moment of its existence. What actually happens at such a boundary point depends, of course, on the correct quantum theory of gravity.<br /> <br /> The important point is that we can easily imagine self-contained descriptions of the universe that have an earliest moment of time. There is no logical or metaphysical obstacle to completing the conventional temporal history of the universe by including an atemporal boundary condition at the beginning. Together with the successful post-Big-Bang cosmological model already in our possession, that would constitute a consistent and self-contained description of the history of the universe.<br /> <br /> Nothing in the fact that there is a first moment of time, in other words, necessitates that an external something is required to bring the universe about at that moment. As Hawking put it in a celebrated passage:<br /> <br />\n<blockquote>So long as the universe had a beginning, we could suppose it had a creator. But if the universe is really self-contained, having no boundary or edge, it would have neither beginning nor end, it would simply be. What place, then, for a creator?</blockquote>\n</blockquote>\n</li>\n<li>\n<p>Uses Bayesian reasoning to judge possible explanations:</p>\n<blockquote>Nevertheless, for the sake of playing along, let's imagine that intelligent life only arises under a very restrictive set of circumstances. Following Swinburne, we can cast the remaining choices in terms of Bayesian probability. The basic idea is simple: we assign some prior probability &ndash; before we take into account what we actually know about the universe &ndash; to each of the three remaining scenarios. Then we multiply that prior probability by the probability that intelligent life would arise in that particular model. The result is proportional to the probability that the model is correct, given that intelligent life exists.[17] Thus, for option #2 (a single universe, no supernatural intervention), we might put the prior probability at a relatively high value by virtue of its simplicity, but the probability of life arising (we are imagining) is extremely small, so much so that this model could be considered unlikely in comparison with the other two.<br /> <br /> We are left with option #3, a \"multiverse\" with different conditions in different regions (traditionally called \"universes\" even if they spatially connected), and #4, a single universe with parameters chosen by God to allow for the eventual appearance of life. In either case we can make a plausible argument that the probability of life arising is considerable. All of the heavy lifting, therefore, comes down to our prior probabilities &ndash; our judgments about how <em>a priori</em> likely such a cosmological scenario is. Sadly, prior probabilities are notoriously contentious objects.<br /> <br /> I will consider more carefully the status of the \"God hypothesis,\" and its corresponding prior probability, in the final section. For now, let's take a look at the multiverse.</blockquote>\n</li>\n<li>\n<p>Correctly describes parsimony in terms of Kolmogorov complexity:</p>\n<blockquote>What prior likelihood should we assign to such a scenario? One popular objection to the multiverse is that it is highly non-parsimonious; is it really worth invoking an enormous number of universes just to account for a few physical parameters? As Swinburne says:<br /> <br />\n<blockquote>To postulate a trillion trillion other universes, rather than one God in order to explain the orderliness of our universe, seems the height of irrationality.</blockquote>\n<br /> That might be true, even with the hyperbole, if what one was postulating were simply \"a trillion trillion other universes.\" But that is a mischaracterization of what is involved. What one postulates are not universes, but laws of physics. Given inflation and the string theory landscape (or other equivalent dynamical mechanisms), a multiverse happens, whether you like it or not.<br /> <br /> This is an important point that bears emphasizing. All else being equal, a simpler scientific theory is preferred over a more complicated one. But how do we judge simplicity? It certainly doesn't mean \"the sets involved in the mathematical description of the theory contain the smallest possible number of elements.\" In the Newtonian clockwork universe, every cubic centimeter contains an infinite number of points, and space contains an infinite number of cubic centimeters, all of which persist for an infinite number of separate moments each second, over an infinite number of seconds. Nobody ever claimed that all these infinities were a strike against the theory. Indeed, in an open universe described by general relativity, space extends infinitely far, and lasts infinitely long into the future; again, these features are not typically seen as fatal flaws. It is only when space extends without limit and conditions change from place to place, representing separate \"universes,\" that people grow uncomfortable. In quantum mechanics, any particular system is potentially described by an infinite number of distinct wave functions; again, it is only when different branches of such a wave function are labeled as \"universes\" that one starts to hear objections, even if the mathematical description of the wave function itself hasn't grown any more complicated.<br /> <br /> A scientific theory consists of some formal (typically mathematical) structure, as well as an \"interpretation\" that matches that structure onto the world we observe. The structure is a statement about patterns that are exhibited among the various objects in the theory. The simplicity of a theory is a statement about how compactly we can describe the formal structure (the Kolmogorov complexity), not how many elements it contains. The set of real numbers consisting of \"eleven, and thirteen times the square root of two, and pi to the twenty-eighth power, and all prime numbers between 4,982 and 34,950\" is a more complicated set than \"the integers,\" even though the latter set contains an infinitely larger number of elements. The physics of a universe containing 1088 particles that all belong to just a handful of types, each particle behaving precisely according to the characteristics of its type, is much simpler than that of a universe containing only a thousand particles, each behaving completely differently.</blockquote>\n</li>\n<li>\n<p>Discusses \"meta-explanatory accounts\":</p>\n<blockquote>For convenience I am brutally lumping together quite different arguments, but hopefully the underlying point of similarity is clear.  These ideas all arise from a conviction that, in various contexts, it is insufficient to fully understand what happens; we must also provide an explanation for why it happens &ndash; what might be called a \"meta-explanatory\" account.<br /> <br /> It can be difficult to respond to this kind of argument.  Not because the arguments are especially persuasive, but because the ultimate answer to \"We need to understand why the universe exists/continues to exist/exhibits regularities/came to be\" is essentially \"No we don't.\"  That is unlikely to be considered a worthwhile comeback to anyone who was persuaded by the need for a meta-explanatory understanding in the first place.<br /> <br /> Granted, it is always nice to be able to provide reasons why something is the case.  Most scientists, however, suspect that the search for ultimate explanations eventually terminates in some final theory of the world, along with the phrase \"and that's just how it is.\"  It is certainly conceivable that the ultimate explanation is to be found in God; but a compelling argument to that effect would consist of a demonstration that God provides a better explanation (for whatever reason) than a purely materialist picture, not an <em>a priori</em> insistence that a purely materialist picture is unsatisfying.<br /> <br /> Why are some people so convinced of the need for a meta-explanatory account, while others are perfectly happy without one?  I would suggest that the impetus to provide such an account comes from our experiences within the world, while the suspicion that there is no need comes from treating the entire universe as something unique, something for which a different set of standards is appropriate.<br /> <br /> ...<br /> <br /> States of affairs only require an explanation if we have some contrary expectation, some reason to be surprised that they hold.  Is there any reason to be surprised that the universe exists, continues to exist, or exhibits regularities?  When it comes to the universe, we don't have any broader context in which to develop expectations.  As far as we know, it may simply exist and evolve according to the laws of physics.  If we knew that it was one element of a large ensemble of universes, we might have reason to think otherwise, but we don't.  (I'm using \"universe\" here to mean the totality of existence, so what would be called the \"multiverse\" if that's what we lived in.)<br /> <br /> ...<br /> <br /> Likewise for the universe.  There is no reason, within anything we currently understand about the ultimate structure of reality, to think of the existence and persistence and regularity of the universe as things that require external explanation.  Indeed, for most scientists, adding on another layer of metaphysical structure in order to purportedly explain these nomological facts is an unnecessary complication.  This brings us to the status of God as a scientific hypothesis.</blockquote>\n</li>\n<li>\n<p>Points out the theory-saving in and the predictive issues of God as a hypothesis:</p>\n<blockquote>Similarly, the apparent precision of the God hypothesis evaporates when it comes to connecting to the messy workings of reality. To put it crudely, God is not described in equations, as are other theories of fundamental physics. Consequently, it is difficult or impossible to make predictions. Instead, one looks at what has already been discovered, and agrees that that's the way God would have done it. Theistic evolutionists argue that God uses natural selection to develop life on Earth; but religious thinkers before Darwin were unable to predict that such a mechanism would be God's preferred choice.<br /><br /> ...<br /><br /> This is a venerable problem, reaching far beyond natural theology. In numerous ways, the world around us is more like what we would expect from a dysteleological set of uncaring laws of nature than from a higher power with an interest in our welfare. As another thought experiment, imagine a hypothetical world in which there was no evil, people were invariably kind, fewer natural disasters occurred, and virtue was always rewarded. Would inhabitants of that world consider these features to be evidence against the existence of God? If not, why don't we consider the contrary conditions to be such evidence?&nbsp;</blockquote>\n</li>\n<li>And more!</li>\n</ul>\n<p>See also his <a href=\"http://blogs.discovermagazine.com/cosmicvariance/2011/03/21/does-the-universe-need-god/\">blog entry</a> for more discussion of the essay.</p>\n<p>Edit: added the bullet point about \"meta-explanatory accounts.\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XEamue7T7WJvkHZmG", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 24, "extendedScore": null, "score": 6.935324890994081e-07, "legacy": true, "legacyId": "6384", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T06:48:05.061Z", "modifiedAt": null, "url": null, "title": "St. Louis, Missouri Meetup - now happening every week!", "slug": "st-louis-missouri-meetup-now-happening-every-week", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:55.773Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z4xtmZz9wJNZ3cHrc/st-louis-missouri-meetup-now-happening-every-week", "pageUrlRelative": "/posts/Z4xtmZz9wJNZ3cHrc/st-louis-missouri-meetup-now-happening-every-week", "linkUrl": "https://www.lesswrong.com/posts/Z4xtmZz9wJNZ3cHrc/st-louis-missouri-meetup-now-happening-every-week", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20St.%20Louis%2C%20Missouri%20Meetup%20-%20now%20happening%20every%20week!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASt.%20Louis%2C%20Missouri%20Meetup%20-%20now%20happening%20every%20week!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ4xtmZz9wJNZ3cHrc%2Fst-louis-missouri-meetup-now-happening-every-week%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=St.%20Louis%2C%20Missouri%20Meetup%20-%20now%20happening%20every%20week!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ4xtmZz9wJNZ3cHrc%2Fst-louis-missouri-meetup-now-happening-every-week", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ4xtmZz9wJNZ3cHrc%2Fst-louis-missouri-meetup-now-happening-every-week", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 212, "htmlBody": "<p><a id=\"more\"></a></p>\n<p>I got inspired by the&nbsp;<a href=\"/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">NY meetup</a>&nbsp;post by Cosmos, and&nbsp;I'd love to get a recurring meetup started in St. Louis.</p>\n<p><strong>Where</strong>: <a href=\"http://www.yelp.com/biz/kayaks-coffee-and-provisions-saint-louis\">Kayak Coffee</a> at Skinker and Forest Park Parkway, near Washington University.</p>\n<p><strong>When</strong>: Every Tuesday from 6-8 PM, until and including May 3, 2011 and starting again in September 2011. I won't be in St. Louis for the summer, though of course if enough people will be around the meetups will continue without me.</p>\n<p><strong>What</strong>: Meet each other and share our thoughts/discoveries on subjects related to LW and/or transhumanism, whatever you find interesting. I'm personally interested in the instrumental value of rationality, philosophy, self-improvement, life hacking, futurism.</p>\n<p>I want to use rationality to win more often, and to help the people around me win more often. Let's see where it goes!</p>\n<p>I'll make a sign that says 'Less Wrong'. RSVP here - I looking forward to meeting you.</p>\n<p>Edit: I meant March, not May.</p>\n<p><strong>Update: Our inaugural meetup was excellent. One person RSVP'd and didn't show up, but four others didn't RSVP and did show up. Future meetups are being planned, so leave a comment or message me if you want to get involved.</strong></p>\n<p><strong>Update two: We're now meeting every week - I've updated the time to reflect our recurring time. Definitely send me a message if you want to come!</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z4xtmZz9wJNZ3cHrc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 6.937186000666173e-07, "legacy": true, "legacyId": "6393", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a id=\"more\"></a></p>\n<p>I got inspired by the&nbsp;<a href=\"/lw/4ul/less_wrong_nyc_case_study_of_a_successful/\">NY meetup</a>&nbsp;post by Cosmos, and&nbsp;I'd love to get a recurring meetup started in St. Louis.</p>\n<p><strong>Where</strong>: <a href=\"http://www.yelp.com/biz/kayaks-coffee-and-provisions-saint-louis\">Kayak Coffee</a> at Skinker and Forest Park Parkway, near Washington University.</p>\n<p><strong>When</strong>: Every Tuesday from 6-8 PM, until and including May 3, 2011 and starting again in September 2011. I won't be in St. Louis for the summer, though of course if enough people will be around the meetups will continue without me.</p>\n<p><strong>What</strong>: Meet each other and share our thoughts/discoveries on subjects related to LW and/or transhumanism, whatever you find interesting. I'm personally interested in the instrumental value of rationality, philosophy, self-improvement, life hacking, futurism.</p>\n<p>I want to use rationality to win more often, and to help the people around me win more often. Let's see where it goes!</p>\n<p>I'll make a sign that says 'Less Wrong'. RSVP here - I looking forward to meeting you.</p>\n<p>Edit: I meant March, not May.</p>\n<p><strong id=\"Update__Our_inaugural_meetup_was_excellent__One_person_RSVP_d_and_didn_t_show_up__but_four_others_didn_t_RSVP_and_did_show_up__Future_meetups_are_being_planned__so_leave_a_comment_or_message_me_if_you_want_to_get_involved_\">Update: Our inaugural meetup was excellent. One person RSVP'd and didn't show up, but four others didn't RSVP and did show up. Future meetups are being planned, so leave a comment or message me if you want to get involved.</strong></p>\n<p><strong id=\"Update_two__We_re_now_meeting_every_week___I_ve_updated_the_time_to_reflect_our_recurring_time__Definitely_send_me_a_message_if_you_want_to_come_\">Update two: We're now meeting every week - I've updated the time to reflect our recurring time. Definitely send me a message if you want to come!</strong></p>", "sections": [{"title": "Update: Our inaugural meetup was excellent. One person RSVP'd and didn't show up, but four others didn't RSVP and did show up. Future meetups are being planned, so leave a comment or message me if you want to get involved.", "anchor": "Update__Our_inaugural_meetup_was_excellent__One_person_RSVP_d_and_didn_t_show_up__but_four_others_didn_t_RSVP_and_did_show_up__Future_meetups_are_being_planned__so_leave_a_comment_or_message_me_if_you_want_to_get_involved_", "level": 1}, {"title": "Update two: We're now meeting every week - I've updated the time to reflect our recurring time. Definitely send me a message if you want to come!", "anchor": "Update_two__We_re_now_meeting_every_week___I_ve_updated_the_time_to_reflect_our_recurring_time__Definitely_send_me_a_message_if_you_want_to_come_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "8 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["CsKboswS3z5iaiutC"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T08:18:40.449Z", "modifiedAt": null, "url": null, "title": "Link: Paul Graham on intelligence vs determination", "slug": "link-paul-graham-on-intelligence-vs-determination", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.834Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vladimir_Golovin", "createdAt": "2009-02-28T13:32:31.085Z", "isAdmin": false, "displayName": "Vladimir_Golovin"}, "userId": "Me2m84AhCn9H49riY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HKdQ43yEadSHGWXze/link-paul-graham-on-intelligence-vs-determination", "pageUrlRelative": "/posts/HKdQ43yEadSHGWXze/link-paul-graham-on-intelligence-vs-determination", "linkUrl": "https://www.lesswrong.com/posts/HKdQ43yEadSHGWXze/link-paul-graham-on-intelligence-vs-determination", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Paul%20Graham%20on%20intelligence%20vs%20determination&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Paul%20Graham%20on%20intelligence%20vs%20determination%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHKdQ43yEadSHGWXze%2Flink-paul-graham-on-intelligence-vs-determination%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Paul%20Graham%20on%20intelligence%20vs%20determination%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHKdQ43yEadSHGWXze%2Flink-paul-graham-on-intelligence-vs-determination", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHKdQ43yEadSHGWXze%2Flink-paul-graham-on-intelligence-vs-determination", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 181, "htmlBody": "<p>Paul Graham of Y-Combinator on picking winners-at-life:<br /><a title=\"Paul Graham spills: Why some companies get his cash and others don't \" href=\"http://www.entrepreneur.com/article/219377\">Paul Graham spills: Why some companies get his cash and others don't</a></p>\n<blockquote>\n<p><em><strong>What's most essential for a successful startup?</strong><br /> The founders. We've learned in the six years of doing Y Combinator to  look at the founders--not the business ideas--because the earlier you  invest, the more you're investing in the people. When Bill Gates was  starting Microsoft, the idea that he had then involved a small-time  microcomputer called the Altair. That didn't seem very promising, so you  had to see that this 19-year-old kid was going places.</em></p>\n<p><em><strong>What do you look for?</strong><br /> Determination. When we started, we thought we were looking for smart  people, but it turned out that intelligence was not as important as we  expected. If you imagine someone with 100 percent determination and 100  percent intelligence, you can discard a lot of intelligence before they  stop succeeding. But if you start discarding determination, you very  quickly get an ineffectual and perpetual grad student.</em></p>\n</blockquote>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HKdQ43yEadSHGWXze", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 24, "extendedScore": null, "score": 4.9e-05, "legacy": true, "legacyId": "6397", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T08:27:23.506Z", "modifiedAt": null, "url": null, "title": "death-is-bad-ism going a little bit more mainstream?", "slug": "death-is-bad-ism-going-a-little-bit-more-mainstream", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:29.897Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ktLifbd5mWKjPGfna/death-is-bad-ism-going-a-little-bit-more-mainstream", "pageUrlRelative": "/posts/ktLifbd5mWKjPGfna/death-is-bad-ism-going-a-little-bit-more-mainstream", "linkUrl": "https://www.lesswrong.com/posts/ktLifbd5mWKjPGfna/death-is-bad-ism-going-a-little-bit-more-mainstream", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20death-is-bad-ism%20going%20a%20little%20bit%20more%20mainstream%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Adeath-is-bad-ism%20going%20a%20little%20bit%20more%20mainstream%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FktLifbd5mWKjPGfna%2Fdeath-is-bad-ism-going-a-little-bit-more-mainstream%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=death-is-bad-ism%20going%20a%20little%20bit%20more%20mainstream%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FktLifbd5mWKjPGfna%2Fdeath-is-bad-ism-going-a-little-bit-more-mainstream", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FktLifbd5mWKjPGfna%2Fdeath-is-bad-ism-going-a-little-bit-more-mainstream", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p>So, apparently appsumo is having a custom reddit bundle, a bundle meant to appeal to redditors, and 10% of the proceeds get donated. On the surface, doesn't sound _that_ interesting, except...</p>\n<p>&nbsp;</p>\n<p>Take a closer look:&nbsp;<a href=\"http://appsumo.com/reddit-special-deal/\">http://appsumo.com/reddit-special-deal/</a>&nbsp;and find that the recipient of the donations will be... SENS!</p>\n<p>&nbsp;</p>\n<p>I find this to be an interesting development. It wasn't the \"custom transhumanist bundle\" or \"the custom sens bundle\" but \"the custom reddit bundle\". Yes, \"reddit\" doesn't, in and of itself, count as extremely mainstream as such, but I'd say it's still an interesting development.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"vmvTYnmaKA73fYDe5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ktLifbd5mWKjPGfna", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 20, "extendedScore": null, "score": 6.937459162505106e-07, "legacy": true, "legacyId": "6398", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T17:04:28.029Z", "modifiedAt": null, "url": null, "title": "\"If the race starts at X, I'll win\"", "slug": "if-the-race-starts-at-x-i-ll-win", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:04.486Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QnbYBtsHKWLdZDrxf/if-the-race-starts-at-x-i-ll-win", "pageUrlRelative": "/posts/QnbYBtsHKWLdZDrxf/if-the-race-starts-at-x-i-ll-win", "linkUrl": "https://www.lesswrong.com/posts/QnbYBtsHKWLdZDrxf/if-the-race-starts-at-x-i-ll-win", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22If%20the%20race%20starts%20at%20X%2C%20I'll%20win%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22If%20the%20race%20starts%20at%20X%2C%20I'll%20win%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQnbYBtsHKWLdZDrxf%2Fif-the-race-starts-at-x-i-ll-win%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22If%20the%20race%20starts%20at%20X%2C%20I'll%20win%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQnbYBtsHKWLdZDrxf%2Fif-the-race-starts-at-x-i-ll-win", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQnbYBtsHKWLdZDrxf%2Fif-the-race-starts-at-x-i-ll-win", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<p>I just found a brilliant metaphor in an&nbsp;<a href=\"http://uxmatters.com/mt/archives/2010/03/ux-design-versus-ui-development.php\">article</a>&nbsp;about programmers vs designers, here's the relevant quote:</p>\n<blockquote>\n<p><span style=\"font-size: 13px; line-height: 17px;\">...a mistake we sometimes make as UX Designers is that we believe, if the race starts at wireframing, we will win.</span></p>\n</blockquote>\n<p><span style=\"font-size: 13px; line-height: 17px;\">This looks like a new and unflattering lens through which to view my self-image. If I have good math skills but poor understanding of customers, then I'm smugly confident about winning \"if the race starts at rigorous problem formulation\". But of course the universe isn't so obliging, and the race always starts before you'd hoped it would! If you feel blocked today, can it be because you're an expert at some task but poor at its natural <a href=\"http://www.joelonsoftware.com/articles/StrategyLetterV.html\">complementary</a> tasks?</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QnbYBtsHKWLdZDrxf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 6.938881776244609e-07, "legacy": true, "legacyId": "6399", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T17:11:38.503Z", "modifiedAt": null, "url": null, "title": "Why Would A Certain Hoax Story Be Reported For So Long?", "slug": "why-would-a-certain-hoax-story-be-reported-for-so-long", "viewCount": null, "lastCommentedAt": "2021-11-06T00:16:41.753Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Servant", "createdAt": "2010-08-28T01:06:07.043Z", "isAdmin": false, "displayName": "Servant"}, "userId": "hKpfDZpbiECWioGmm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YLBmGc7esaesxe8tM/why-would-a-certain-hoax-story-be-reported-for-so-long", "pageUrlRelative": "/posts/YLBmGc7esaesxe8tM/why-would-a-certain-hoax-story-be-reported-for-so-long", "linkUrl": "https://www.lesswrong.com/posts/YLBmGc7esaesxe8tM/why-would-a-certain-hoax-story-be-reported-for-so-long", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Why%20Would%20A%20Certain%20Hoax%20Story%20Be%20Reported%20For%20So%20Long%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhy%20Would%20A%20Certain%20Hoax%20Story%20Be%20Reported%20For%20So%20Long%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYLBmGc7esaesxe8tM%2Fwhy-would-a-certain-hoax-story-be-reported-for-so-long%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Why%20Would%20A%20Certain%20Hoax%20Story%20Be%20Reported%20For%20So%20Long%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYLBmGc7esaesxe8tM%2Fwhy-would-a-certain-hoax-story-be-reported-for-so-long", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYLBmGc7esaesxe8tM%2Fwhy-would-a-certain-hoax-story-be-reported-for-so-long", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 587, "htmlBody": "<p>Recently, Tyler Cowen, on his blog, reported&nbsp;<a href=\"http://marginalrevolution.com/marginalrevolution/2011/03/market-failure-in-everything.html\">a story</a>&nbsp;of a German court case&nbsp;where Demitrius Soupolos&nbsp;sued Frank Maus for \"breach of contract\". Demitrius paid Maus to do a certain service, which Maus then was unable to deliever. Maus argued that he was only paid to make a good effort on said service but was prevented from doing so (due to an <a href=\"http://www.trinidadexpress.com/commentaries/Nature__nurture_and_nativity-116518308.html\">\"act of god\"</a>, as one American legal scholar supposedly claimed). This got me curious: who would win that court case? So I began doing a Google search for more information about this case...only to see that this case has been repeated over and over. Tyler Cowen's blog post links to an <a href=\"http://www.just-whatever.com/2009/03/30/paid-to-do-it-72-times/\">article </a>on this case written in <em>March 30th 2009...</em>and that all these other news stories just copy this article, word-for-word. There is no mention of a verdict anywhere in my searches (which I think would be fairly important concerning that this is a court case after all), nor were any of these news articles about&nbsp;Soupolos were written in Germany (where the court case was supposed to be held),&nbsp;leading me to conclude that this is nothing more than a hoax. Now, this may not be a hoax, but I'm fairly confident that it is a hoax.</p>\n<p>Tyler made his blog post in March 23rd 2011...so why would this hoax story continue to spread long after 2009? The answer is simple: the context of the story. Frank Maus' service was&nbsp;impregnation of Demitrius' wife, a \"beauty queen\"*. The \"act of god\" that prevented Frank Maus for carrying out this service...was the fact that Frank Maus was infertile and didn't know of this&nbsp;infertility&nbsp;because his wife deceived him.</p>\n<p>The story seems so weird, strange, and soap operaic when you added in the 'context' that it becomes understandable that somebody may&nbsp;instinctively&nbsp;wish to grapple with the implications of this story as opposed to digging in deeper and questioning the story's&nbsp;inauthenticity (and I must admit, when I was doing my research, I was not&nbsp;intending&nbsp;to question the story but merely wanted to know who won the court case in question). Let's assume that the Maus story is a fake. I have two questions based on that assumption:</p>\n<p>1) If someone wants to create a hoax story that is generally accepted by the population (either for purely sadistic entertainment or for more sinister purposes), would he desire to create a story that is weird or unbelievable just to capitalize on the 'weird' factor and get people to accept it? If so, at what level of&nbsp;weirdness&nbsp;or unbelievability?</p>\n<p>2) Assuming that a \"rational\" individual would prefer to have accurate and true information, how does one guard against some prankster using this sort of tactic?</p>\n<p>*The excuse given in the story was that&nbsp;Demitrius Soupolos was infertile...but considering that a beauty queen should be someone of means, then Soupolos could have used technological advances such as IVF to deal with the infertility problem. This, alongside the bizzare nature of mentioning the detail of a beauty queen (who, when I did the search, once again bring up repeated copies of the same court case article), as if that is the only important thing about this woman in question, suggests that this is yet another evidence of this being a hoax.</p>\n<p>EDIT: According to <a href=\"/r/discussion/lw/4xs/why_would_a_certain_hoax_story_be_reported_for_so/3r8v\">Douglas Knight</a>, this&nbsp;story had originally started as a article in Jet&nbsp;Magazine, written in 1978. While it doesn't prove that it's not a \"hoax\", this new piece of evidence does help to explain why I was unable to find anything on Google search relating to the court case (other than repeated copies of the same story).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3uE2pXvbcnS9nnZRE": 2, "gHCNhqxuJq2bZ2akb": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YLBmGc7esaesxe8tM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "6400", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T20:52:53.978Z", "modifiedAt": null, "url": null, "title": "The \"supernatural\" category", "slug": "the-supernatural-category", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:36.806Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "rstarkov", "createdAt": "2011-02-21T19:53:18.490Z", "isAdmin": false, "displayName": "rstarkov"}, "userId": "tsHG32deqwFhnQ2sx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CwdxCAFjzMiPM5nYq/the-supernatural-category", "pageUrlRelative": "/posts/CwdxCAFjzMiPM5nYq/the-supernatural-category", "linkUrl": "https://www.lesswrong.com/posts/CwdxCAFjzMiPM5nYq/the-supernatural-category", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20%22supernatural%22%20category&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20%22supernatural%22%20category%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwdxCAFjzMiPM5nYq%2Fthe-supernatural-category%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20%22supernatural%22%20category%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwdxCAFjzMiPM5nYq%2Fthe-supernatural-category", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCwdxCAFjzMiPM5nYq%2Fthe-supernatural-category", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 544, "htmlBody": "<p>The term \"supernatural\" is frequently used in discussions related to skepticism. I am trying to establish the category that people refer to with this term.<br /><br />All uses of this term appear to imply a separation of concepts and events into two disjoint categories: \"natural\" and \"supernatural\". Some examples of things typically classified into \"supernatural\": God, ghosts, telepathy, telekinesis, aura. Things typically classified as \"natural\": animals, rocks, talking, earthquake, body temperature.<br /><br />I will try to follow the advice given in <a href=\"/lw/nj/similarity_clusters/\">Similarity Clusters</a> and try to establish some verbal hints as to what causes a concept to be classified into either similarity cluster.<br /><br /><br />One idea I had is the following: anything we expect to <em>be able</em> to experience, if the necessary prerequisites are met, is \"natural\"; anything we expect to fail to experience even if we try hard is \"supernatural\". This seems to work quite well on the concepts mentioned above. This works for unlikely events too: a plane crash is not \"supernatural\" because if I'm at the right place and the right time then I expect to be able to experience it.<br /><br />It's still a bit weak for exceedingly unlikely events. For example, proton decay has never been witnessed, and we don't know if it can even occur. But \"proton decay\" is not classified as \"supernatural\"; rather as a \"hypothesis\". Telepathy, however, might for all we know be as rare as proton decay (thus being exceedingly hard to confirm experimentally), and yet it's classified into \"supernatural\". Something is missing from this verbal hint.<br /><br />But <em>what</em>?<br /><br /><br />Approaching this from a different perspective, it appears that one can classify \"supernatural\" as having the property of being \"outside of the universe\". On further thought, however, this isn't helpful at all: the latter is not so much a verbal hint as a label in itself.<br /><br />If taken literally, one might argue that all supernatural things therefore don't exist. They are said to be outside the universe, but we can only experience things within the universe, because anything we can experience must be part of the universe, and thus \"inside\" it. This is quite useless, however, in my opinion: as used by actual people, the category \"supernatural\" isn't intended to preclude existence. So this doesn't work.<br /><br /><br />Could it be that the category \"supernatural\" is actually completely useless, by offering so little information about the things that belong to it that knowing that something is classified as \"supernatural\" doesn't tell us very much at all?<br /><br />Thinking about this led me to the idea that perhaps \"supernatural\" simply means \"something that science has shown false or doesn't accept as a valid theory\". That is certainly a property <strong>I</strong> infer about P when told that P belongs to \"supernatural\".<br /><br />This is still quite unsatisfactory. It can't be the only property. People explain away God's undetectability by being \"supernatural\", intending it as a convincing argument - but even those who do things like this wouldn't claim that \"not a valid theory\" is an argument in favour of God. They must mean something else.<br /><br />But <em>what</em>?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CwdxCAFjzMiPM5nYq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 11, "extendedScore": null, "score": 6.939510419761226e-07, "legacy": true, "legacyId": "6401", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["jMTbQj9XB5ah2maup"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-24T21:53:09.612Z", "modifiedAt": null, "url": null, "title": "Crime and punishment", "slug": "crime-and-punishment", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:49.413Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SCXaRKGhQPkJCMmpm/crime-and-punishment", "pageUrlRelative": "/posts/SCXaRKGhQPkJCMmpm/crime-and-punishment", "linkUrl": "https://www.lesswrong.com/posts/SCXaRKGhQPkJCMmpm/crime-and-punishment", "postedAtFormatted": "Thursday, March 24th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Crime%20and%20punishment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACrime%20and%20punishment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSCXaRKGhQPkJCMmpm%2Fcrime-and-punishment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Crime%20and%20punishment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSCXaRKGhQPkJCMmpm%2Fcrime-and-punishment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSCXaRKGhQPkJCMmpm%2Fcrime-and-punishment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 720, "htmlBody": "<p>Why do those words go together?</p>\n<p>Society - and for once, I'm using this term universally - teaches that, if you committed a crime, you should be punished.</p>\n<p>But in some societies, we have an insanity defense.&nbsp; If you had a brain condition so that you had no - here it's a little vague - consciousness, or moral sense, or free will, or, well, <em>something</em> - then it would be cruel to punish you for your crime.&nbsp; Instead of going to prison, you should be placed somewhere where you can't hurt anybody, where professional physicians and counselors can study your case and try to reform you so that you can rejoin society.</p>\n<p>Wait - so that isn't what prison is for?<a id=\"more\"></a></p>\n<p>No.&nbsp; Prison is to punish people.&nbsp; Is it any wonder that prison doesn't reform people, when we don't <em>want</em> it to reform them?&nbsp; Most people would be <em>upset</em> if prisoners could go in on Friday, and emerge, rehabilitated, on Sunday.&nbsp; When people say, \"It would be cruel to punish people who aren't responsible for their actions\", they are implicitly saying, \"Prison is necessarily cruel; and that's good, because we <em>should</em> be cruel to criminals who are responsible for their actions.\"</p>\n<p>But the more we learn about psychology and neuroscience, the further responsibility recedes into the distance.</p>\n<p>Outcome-based justice argues that we should give up playing the blame game, because neuroscience keeps finding more and more proofs that things are \"not our fault\".&nbsp; Instead, we should write laws that deter crime.</p>\n<p>You might think this is what we already try to do.&nbsp; But it isn't!&nbsp; Witness this confused article from the Brookings Institute, <a href=\"http://www.brookings.edu/papers/2010/1228_neuroscience_snead.aspx\">Cognitive Neuroscience and the Future of Punishment</a> by <span class=\"author\">O. Carter Snead</span>.&nbsp;&nbsp;&nbsp; Snead objects to outcome-based justice.&nbsp; He summarized all of the arguments for it, yet managed to completely miss their point, concluding where he started from, saying that outcome-based justice is obviously bad because it could lead to being cruel to people who didn't deserve it.&nbsp; (Instead of only being cruel to the people who <em>do</em> deserve it, which is obviously what we <em>want</em> to do.)</p>\n<p>Snead understands that outcome-based justice deters crime:</p>\n<blockquote>\n<p>Many features of the criminal justice system that are frequently criticized as draconian and inhumane are, in fact, motivated by a purely consequentialist crime-control rationale. Such measures include laws that authorize life sentences for recidivists (e.g., &ldquo;three strikes&rdquo; laws), laws that reduce the age at which offenders can be tried as adults, laws that punish gang membership, laws that require the registration of sex offenders, laws that dramatically increase sentences by virtue of past history, and, most paradigmatically, laws that provide for the involuntary civil commitment of sexual offenders who show difficulty controlling their behavior.</p>\n</blockquote>\n<p>You might expect that Snead goes on to explain why these laws are bad things.&nbsp; But he doesn't!&nbsp; He assumes we can all <em>see</em> that these are <em>obviously</em> bad things.</p>\n<p><a href=\"/lw/1p/the_wrath_of_kahneman\">The Wrath of Kahneman</a> describes a study which asked whether people punish others in order to deter crime, and concluded, No.&nbsp; People are doing something else.</p>\n<p>One theory is that people are trying to be fair.&nbsp; Everyone should get the same chances; everyone should get the same punishment for the same crime.&nbsp; John Rawls argues this explicitly in <a href=\"http://www.hist-analytic.org/Rawlsfair.htm\">Justice as Fairness</a>:&nbsp; Justice should <em>not</em> be utilitarian, but should instead be fair.</p>\n<p>I believe Rawls' view is also the popular view of what \"justice\" means.&nbsp; And, I will argue in a later post, it is part of a pattern showing a deep divide between two different ways of using the word \"ethics\".</p>\n<p>ADDED: Constant made the point that, while one part of outcome-based justice is preventing future harm from the criminal on the dock, another part is deterring harm by other criminals.&nbsp; This latter part does not benefit from punishing criminals who cannot be deterred.&nbsp; Thus, to optimally punish both criminals who can and cannot be deterred, the law requires a concept of moral culpability, and should punish criminals who can't be deterred more lightly.&nbsp; This is a better origin story for the linking together of morality and free will than the just-so story I'd come up with, so I plan on stealing it for my next post.&nbsp; (SilasBarta may have been trying to make the same point, but I found his comments impenetrable.)</p>\n<p>(This post is laying groundwork for two other posts that will go in different directions, neither of which concerns justice.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 1, "ipJwbLxhR83ZksN6Z": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SCXaRKGhQPkJCMmpm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 53, "baseScore": 50, "extendedScore": null, "score": 0.000144, "legacy": true, "legacyId": "6381", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 39, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 192, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YGPzzqqpYcAoyzF4d"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T00:26:56.091Z", "modifiedAt": null, "url": null, "title": "\"Is there a God\" for noobs", "slug": "is-there-a-god-for-noobs", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:28.513Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "loup-vaillant", "createdAt": "2011-03-23T10:39:25.887Z", "isAdmin": false, "displayName": "loup-vaillant"}, "userId": "wdoZti3BcPbJXsZ66", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9pgTYotjWhmAqoCyc/is-there-a-god-for-noobs", "pageUrlRelative": "/posts/9pgTYotjWhmAqoCyc/is-there-a-god-for-noobs", "linkUrl": "https://www.lesswrong.com/posts/9pgTYotjWhmAqoCyc/is-there-a-god-for-noobs", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Is%20there%20a%20God%22%20for%20noobs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Is%20there%20a%20God%22%20for%20noobs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9pgTYotjWhmAqoCyc%2Fis-there-a-god-for-noobs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Is%20there%20a%20God%22%20for%20noobs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9pgTYotjWhmAqoCyc%2Fis-there-a-god-for-noobs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9pgTYotjWhmAqoCyc%2Fis-there-a-god-for-noobs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1452, "htmlBody": "<p>I am trying to write a small essay about the issue. I intend to eventually submit it to reddit (both <a href=\"http://www.reddit.com/r/religion\">r/religion</a> and <a href=\"http://www.reddit.com/r/atheism\">r/atheism</a>), and to show it to my family. This is basic stuff. I basically want to show that:</p>\n<ul>\n<li>Either God exists, or it doesn't. Therefore, either theism or atheism is false.</li>\n<li>It is worthwhile to actively seek truth in this matter</li>\n<li>Being confident is not the same as being arrogant, or intolerant.</li>\n</ul>\n<p>My hope is to be able to be able to have meaningful discussions about the topic without being called arrogant or disrespectful. The present draft still miss an introduction, but I think I'll just state what I told above. So, what do you think? Did I miss something? Did I underestimate <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferential distances</a>? Could I use other wording? Is this just pointless? Overall, how someone who've never read Less Wrong nor Dawkings might react to that?</p>\n<hr />\n<p>Edits:</p>\n<ul>\n<li>Replaced \"odds\" by \"likelihood\".</li>\n<li>Change my quotation to remove religious references  (I kept Flat Earth, though). It is now (hopefully obviously) a full piece of fiction.</li>\n<li>Replaced \"meta\" by a small explanation of it.</li>\n<li>Removed \"exist\", in the hope of avoiding argument about the meaning of \"existence\".</li>\n</ul>\n<hr />\n<p><strong>Missing Introduction</strong></p>\n<h2>Truth is universal</h2>\n<p>We all live in the same world. Of course, each of us perceive it differently. We don't see the same things, we don't live in the same places, we don't meet the same people. Because of that and more, we don't hold the same beliefs. But there's only one reality. If a statement is true, it is so for everyone.</p>\n<p>For instance, I happen to wear black socks at the time of this writing. Believe it or not, that's the reality, so \"Loup was wearing blacks socks when he wrote this\" is true for everyone, including you. Even if you believe I'm lying, I <em>am</em> wearing black socks. You can't be absolutely certain of this fact, but a fact it is.</p>\n<p>Now imagine I believe the Earth is flat, and you believe the earth is (roughly) spherical. Those two beliefs are mutually contradictory. Clearly, one of us is mistaken.</p>\n<h2>We should avoid false beliefs</h2>\n<blockquote>\n<p>31th day</p>\n<p>My captain has gone nuts. I couldn't believe that at first. He's a good leader, and got us out of many tight situations. But he wants to sail west towards India. He actually believe that the Earth has the shape of a ball. A <em>ball</em>. Some sort of giant orb, floating in&hellip; nothing, I suppose. I'm no navigation master, but I do know one thing: if we sail west far enough, we will all fall down the bottomless pit of despair at the edge of the world.</p>\n<p>I tried to talk him out of this folly, but he would have none of it. I'm sorry captain, but you leave me no choice. Tonight will be your end. For the sake of the crew. Please forgive me.</p>\n</blockquote>\n<p>Holding false beliefs is dangerous. It has consequences, sometimes innocuous, sometimes tragic. You never know until you correct a previously false belief. If you care about anything, you should try and hold only true beliefs, because one false belief can be enough to destroy what you hold dear. Incidentally, that's basically why most of the time, lying is not nice.</p>\n<p>Flaws in reasoning are even worse: they generate or sustain false beliefs. They are also more difficult to correct. Basically they're a reliable way to be wrong, which is potentially much more dangerous than any single wrong belief. If you find a flaw in your reasoning, eliminate it, then re-check your beliefs. If someone proposes you to adopt one, do not drink that cup, it's poisoned.</p>\n<h2>\"I don't know\" is a stance</h2>\n<p>Are my socks black? Think about it for 30 seconds, look at the evidence at your disposal, then answer honestly. There are 3 kinds of answers you might produce:</p>\n<ul>\n<li>\"Your socks are black.\" Meaning, you are reasonably sure that my socks are black.</li>\n<li>&nbsp;\"Your socks are not black.\" Meaning, you are reasonably sure that my socks aren't black.</li>\n<li>\"I don't know\". Meaning that from your point of view, my socks could be black, or they could be of a different colour. You're not sure either way.</li>\n</ul>\n<p>Note that all three answers share a common structure. They could all be phrased thus: \"I estimate that the likelihood of your socks being black is X%\". If X is close to 100%, you believe my socks are black. If it is close to 0%, you believe they're not. If X is, say, between 10% and 90%, then you're not sure. Anyway you're bound to choose a value for X, and that will be your stance. It is no less respectable than any other, provided you did your best to estimate the odds.</p>\n<h2>Disagreement is not intolerance</h2>\n<p>Say I'm 99.9% confident that the Earth is flat, and you are 99.999% confident it is spherical. If we also know of each other's opinion, then we automatically strongly believe the other is mistaken. This is not intolerance. This is the direct consequence of our respective beliefs. If you weren't so sure that I'm wrong, you wouldn't be so sure that the Earth is spherical either. This is a matter of consistency.</p>\n<p>There is hope however: if we are both reasonable, don't have flaws in our reasoning, have roughly equal access to evidence, and honestly attempt to reach the truth together, then we will eventually agree. At least one of us will radically change his mind.</p>\n<p>Let's say that halfway through such a quest, you are still 99.999% confident the Earth is spherical, but I am only 60% confident. It means two things:</p>\n<ol>\n<li>I changed my mind.</li>\n<li>We still disagree.</li>\n</ol>\n<p>This time, the disagreement is not as strong, but still significant: you estimate that flat Earth is barely worth considering. I on the other hand, think sailing West means 40% chances of falling at the edge of the world, which is just too risky.</p>\n<h2>No exception</h2>\n<p>These rules apply to any question. Even controversial, emotional questions. So. Is there a God?</p>\n<ul>\n<li>\n<p>Either there is a God, or there isn't. Either way this is a fact. Inevitably, of atheists and theists, one group is mistaken.</p>\n</li>\n<li>\n<p>This is an important question. A wrong answer can for instance lead us to forsake our lives or our souls for naught.</p>\n</li>\n<li>\n<p>Agnosticism is less comfortable than it sounds. First, agnostics disagree with both theists and atheists. Second, any significant evidence should mostly turn them into either theists or atheists. And the importance of the question suggest they <em>should</em> seek such evidence.</p>\n</li>\n<li>\n<p>Many atheists are very sure there is no God, and many theists are very sure there is &mdash;even though they know of each other's opinions. Therefore, they both believe the other group is mistaken. This is not intolerance, this is consistency.</p>\n<p>I'm worried however by the lack of consensus after all this time. \"Is there a God\" is an old and important question, and as far as I know, there is plenty of widely accessible evidence, and numerous debates. I suppose our thinking still have problems.</p>\n</li>\n</ul>\n<p>Now, is there a God? Your answer should be of the form \"My estimate of the likelihood that there is a God is X%\". Don't style yourself as an atheist, believer, or agnostic. Assess the evidence at your disposal (science, scriptures, what you where told&hellip;), then give your number. Just bear in mind these sanity checks:</p>\n<ul>\n<li>\n<p>Your estimate may be very close to either 0% or 100%, which means you are very confident. Just to be sure, could you live up to your confidence, and say to the face of someone of the opposite opinion \"you are mistaken\"?</p>\n</li>\n<li>\n<p>On the other hand, your estimate may be close to 50%. Just to be sure, are you positive that the evidence at your disposal is <em>that</em> balanced? It is not stronger one way or another?</p>\n</li>\n<li>If you want to share your estimates with friends, make sure you talk about the same idea of God. A good starting point can be \"a supernatural, sentient being that created the universe, is omnipotent and omniscient\". You could add \"is benevolent\", or, \"is still active in the universe\", or \"listen to prayers\", all the way down to any particular religious dogma if you want to.</li>\n</ul>\n<p>Like I said, these principles can apply to any question. Including the really scary ones, like \"is there an afterlife?\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9pgTYotjWhmAqoCyc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 20, "extendedScore": null, "score": 6.940099533778452e-07, "legacy": true, "legacyId": "6403", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I am trying to write a small essay about the issue. I intend to eventually submit it to reddit (both <a href=\"http://www.reddit.com/r/religion\">r/religion</a> and <a href=\"http://www.reddit.com/r/atheism\">r/atheism</a>), and to show it to my family. This is basic stuff. I basically want to show that:</p>\n<ul>\n<li>Either God exists, or it doesn't. Therefore, either theism or atheism is false.</li>\n<li>It is worthwhile to actively seek truth in this matter</li>\n<li>Being confident is not the same as being arrogant, or intolerant.</li>\n</ul>\n<p>My hope is to be able to be able to have meaningful discussions about the topic without being called arrogant or disrespectful. The present draft still miss an introduction, but I think I'll just state what I told above. So, what do you think? Did I miss something? Did I underestimate <a href=\"http://wiki.lesswrong.com/wiki/Inferential_distance\">inferential distances</a>? Could I use other wording? Is this just pointless? Overall, how someone who've never read Less Wrong nor Dawkings might react to that?</p>\n<hr>\n<p>Edits:</p>\n<ul>\n<li>Replaced \"odds\" by \"likelihood\".</li>\n<li>Change my quotation to remove religious references  (I kept Flat Earth, though). It is now (hopefully obviously) a full piece of fiction.</li>\n<li>Replaced \"meta\" by a small explanation of it.</li>\n<li>Removed \"exist\", in the hope of avoiding argument about the meaning of \"existence\".</li>\n</ul>\n<hr>\n<p><strong id=\"Missing_Introduction\">Missing Introduction</strong></p>\n<h2 id=\"Truth_is_universal\">Truth is universal</h2>\n<p>We all live in the same world. Of course, each of us perceive it differently. We don't see the same things, we don't live in the same places, we don't meet the same people. Because of that and more, we don't hold the same beliefs. But there's only one reality. If a statement is true, it is so for everyone.</p>\n<p>For instance, I happen to wear black socks at the time of this writing. Believe it or not, that's the reality, so \"Loup was wearing blacks socks when he wrote this\" is true for everyone, including you. Even if you believe I'm lying, I <em>am</em> wearing black socks. You can't be absolutely certain of this fact, but a fact it is.</p>\n<p>Now imagine I believe the Earth is flat, and you believe the earth is (roughly) spherical. Those two beliefs are mutually contradictory. Clearly, one of us is mistaken.</p>\n<h2 id=\"We_should_avoid_false_beliefs\">We should avoid false beliefs</h2>\n<blockquote>\n<p>31th day</p>\n<p>My captain has gone nuts. I couldn't believe that at first. He's a good leader, and got us out of many tight situations. But he wants to sail west towards India. He actually believe that the Earth has the shape of a ball. A <em>ball</em>. Some sort of giant orb, floating in\u2026 nothing, I suppose. I'm no navigation master, but I do know one thing: if we sail west far enough, we will all fall down the bottomless pit of despair at the edge of the world.</p>\n<p>I tried to talk him out of this folly, but he would have none of it. I'm sorry captain, but you leave me no choice. Tonight will be your end. For the sake of the crew. Please forgive me.</p>\n</blockquote>\n<p>Holding false beliefs is dangerous. It has consequences, sometimes innocuous, sometimes tragic. You never know until you correct a previously false belief. If you care about anything, you should try and hold only true beliefs, because one false belief can be enough to destroy what you hold dear. Incidentally, that's basically why most of the time, lying is not nice.</p>\n<p>Flaws in reasoning are even worse: they generate or sustain false beliefs. They are also more difficult to correct. Basically they're a reliable way to be wrong, which is potentially much more dangerous than any single wrong belief. If you find a flaw in your reasoning, eliminate it, then re-check your beliefs. If someone proposes you to adopt one, do not drink that cup, it's poisoned.</p>\n<h2 id=\"_I_don_t_know__is_a_stance\">\"I don't know\" is a stance</h2>\n<p>Are my socks black? Think about it for 30 seconds, look at the evidence at your disposal, then answer honestly. There are 3 kinds of answers you might produce:</p>\n<ul>\n<li>\"Your socks are black.\" Meaning, you are reasonably sure that my socks are black.</li>\n<li>&nbsp;\"Your socks are not black.\" Meaning, you are reasonably sure that my socks aren't black.</li>\n<li>\"I don't know\". Meaning that from your point of view, my socks could be black, or they could be of a different colour. You're not sure either way.</li>\n</ul>\n<p>Note that all three answers share a common structure. They could all be phrased thus: \"I estimate that the likelihood of your socks being black is X%\". If X is close to 100%, you believe my socks are black. If it is close to 0%, you believe they're not. If X is, say, between 10% and 90%, then you're not sure. Anyway you're bound to choose a value for X, and that will be your stance. It is no less respectable than any other, provided you did your best to estimate the odds.</p>\n<h2 id=\"Disagreement_is_not_intolerance\">Disagreement is not intolerance</h2>\n<p>Say I'm 99.9% confident that the Earth is flat, and you are 99.999% confident it is spherical. If we also know of each other's opinion, then we automatically strongly believe the other is mistaken. This is not intolerance. This is the direct consequence of our respective beliefs. If you weren't so sure that I'm wrong, you wouldn't be so sure that the Earth is spherical either. This is a matter of consistency.</p>\n<p>There is hope however: if we are both reasonable, don't have flaws in our reasoning, have roughly equal access to evidence, and honestly attempt to reach the truth together, then we will eventually agree. At least one of us will radically change his mind.</p>\n<p>Let's say that halfway through such a quest, you are still 99.999% confident the Earth is spherical, but I am only 60% confident. It means two things:</p>\n<ol>\n<li>I changed my mind.</li>\n<li>We still disagree.</li>\n</ol>\n<p>This time, the disagreement is not as strong, but still significant: you estimate that flat Earth is barely worth considering. I on the other hand, think sailing West means 40% chances of falling at the edge of the world, which is just too risky.</p>\n<h2 id=\"No_exception\">No exception</h2>\n<p>These rules apply to any question. Even controversial, emotional questions. So. Is there a God?</p>\n<ul>\n<li>\n<p>Either there is a God, or there isn't. Either way this is a fact. Inevitably, of atheists and theists, one group is mistaken.</p>\n</li>\n<li>\n<p>This is an important question. A wrong answer can for instance lead us to forsake our lives or our souls for naught.</p>\n</li>\n<li>\n<p>Agnosticism is less comfortable than it sounds. First, agnostics disagree with both theists and atheists. Second, any significant evidence should mostly turn them into either theists or atheists. And the importance of the question suggest they <em>should</em> seek such evidence.</p>\n</li>\n<li>\n<p>Many atheists are very sure there is no God, and many theists are very sure there is \u2014even though they know of each other's opinions. Therefore, they both believe the other group is mistaken. This is not intolerance, this is consistency.</p>\n<p>I'm worried however by the lack of consensus after all this time. \"Is there a God\" is an old and important question, and as far as I know, there is plenty of widely accessible evidence, and numerous debates. I suppose our thinking still have problems.</p>\n</li>\n</ul>\n<p>Now, is there a God? Your answer should be of the form \"My estimate of the likelihood that there is a God is X%\". Don't style yourself as an atheist, believer, or agnostic. Assess the evidence at your disposal (science, scriptures, what you where told\u2026), then give your number. Just bear in mind these sanity checks:</p>\n<ul>\n<li>\n<p>Your estimate may be very close to either 0% or 100%, which means you are very confident. Just to be sure, could you live up to your confidence, and say to the face of someone of the opposite opinion \"you are mistaken\"?</p>\n</li>\n<li>\n<p>On the other hand, your estimate may be close to 50%. Just to be sure, are you positive that the evidence at your disposal is <em>that</em> balanced? It is not stronger one way or another?</p>\n</li>\n<li>If you want to share your estimates with friends, make sure you talk about the same idea of God. A good starting point can be \"a supernatural, sentient being that created the universe, is omnipotent and omniscient\". You could add \"is benevolent\", or, \"is still active in the universe\", or \"listen to prayers\", all the way down to any particular religious dogma if you want to.</li>\n</ul>\n<p>Like I said, these principles can apply to any question. Including the really scary ones, like \"is there an afterlife?\"</p>", "sections": [{"title": "Missing Introduction", "anchor": "Missing_Introduction", "level": 2}, {"title": "Truth is universal", "anchor": "Truth_is_universal", "level": 1}, {"title": "We should avoid false beliefs", "anchor": "We_should_avoid_false_beliefs", "level": 1}, {"title": "\"I don't know\" is a stance", "anchor": "_I_don_t_know__is_a_stance", "level": 1}, {"title": "Disagreement is not intolerance", "anchor": "Disagreement_is_not_intolerance", "level": 1}, {"title": "No exception", "anchor": "No_exception", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "87 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 87, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T05:28:48.187Z", "modifiedAt": null, "url": null, "title": "The function of belief - advice appreciated.", "slug": "the-function-of-belief-advice-appreciated", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.352Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3QdXLreyJJmSbABg4/the-function-of-belief-advice-appreciated", "pageUrlRelative": "/posts/3QdXLreyJJmSbABg4/the-function-of-belief-advice-appreciated", "linkUrl": "https://www.lesswrong.com/posts/3QdXLreyJJmSbABg4/the-function-of-belief-advice-appreciated", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20function%20of%20belief%20-%20advice%20appreciated.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20function%20of%20belief%20-%20advice%20appreciated.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3QdXLreyJJmSbABg4%2Fthe-function-of-belief-advice-appreciated%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20function%20of%20belief%20-%20advice%20appreciated.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3QdXLreyJJmSbABg4%2Fthe-function-of-belief-advice-appreciated", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3QdXLreyJJmSbABg4%2Fthe-function-of-belief-advice-appreciated", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 154, "htmlBody": "<p>Hi Less Wrongers and Less Wrongerettes,</p>\r\n<p>Doing a fortnightly Less Wrong group with some friends, and next session we're planning to scrutinize belief, hoping to touch on belief in belief, belief as attire etc. but I wanted to start by examining what belief is and the functions of belief. I have a few subtitles:</p>\r\n<p>The function of belief -To anticipate experience</p>\r\n<p>Belief in Belief -</p>\r\n<p>Belief as attire - (the two are pretty closely related)</p>\r\n<p>Free Floating Belief - beliefs that are useless</p>\r\n<p>Correct belief - when beliefs are held for poor reasons, but turn out to be correct, why they are still inaccurate</p>\r\n<p>Making beliefs pay rent - Don't ask what to believe, ask what to anticipate. Want to finish on this one because I think it's applicability is limitless.</p>\r\n<p>just wanted some critiques/suggestions. Particuarly concerned with the first one, defining belief and it's purpose. I need help making the concepts clear and concise.</p>\r\n<p>The more accessible to the layman the better!</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3QdXLreyJJmSbABg4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 2, "extendedScore": null, "score": 6.940930549985935e-07, "legacy": true, "legacyId": "6414", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T08:21:00.470Z", "modifiedAt": null, "url": null, "title": "Constantly ask what you're currently doing that is irrational", "slug": "constantly-ask-what-you-re-currently-doing-that-is", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:57.817Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CijQQZJXnzAhHxkY8/constantly-ask-what-you-re-currently-doing-that-is", "pageUrlRelative": "/posts/CijQQZJXnzAhHxkY8/constantly-ask-what-you-re-currently-doing-that-is", "linkUrl": "https://www.lesswrong.com/posts/CijQQZJXnzAhHxkY8/constantly-ask-what-you-re-currently-doing-that-is", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Constantly%20ask%20what%20you're%20currently%20doing%20that%20is%20irrational&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConstantly%20ask%20what%20you're%20currently%20doing%20that%20is%20irrational%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCijQQZJXnzAhHxkY8%2Fconstantly-ask-what-you-re-currently-doing-that-is%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Constantly%20ask%20what%20you're%20currently%20doing%20that%20is%20irrational%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCijQQZJXnzAhHxkY8%2Fconstantly-ask-what-you-re-currently-doing-that-is", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCijQQZJXnzAhHxkY8%2Fconstantly-ask-what-you-re-currently-doing-that-is", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 153, "htmlBody": "<p>At today's meetup in Tortuga, we were supposed to discuss something we're currently being irrational about.&nbsp; In retrospect I could probably have done better than the item I picked (for example, it now occurs to me that I'm probably currently being irrational about bedtimes and sleep-cycle stuff)...</p>\n<p>But the key point is that while straining my brain to think of something I was currently being irrational about, but <em>hadn't</em> fixed yet, I noticed myself being irrational in <em>small</em> ways too.</p>\n<p>For example, I was sitting on the floor in a way that was beginning to strain my left thigh, but wasn't standing up and finding a chair...</p>\n<p>So I stood up and found a chair.</p>\n<p>I think it might be a valuable exercise to spend an hour practicing rationalist mindfulness, constantly asking yourself, \"What am I currently doing that is not rational?\" as though you had to find <em>something</em> to fulfill your obligation to an LW meetup.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwv9eHi7KGg5KA9oM": 1, "5gcpKG2XEAZGj5DEf": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CijQQZJXnzAhHxkY8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 29, "baseScore": 36, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "6423", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 36, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T08:43:45.401Z", "modifiedAt": null, "url": null, "title": "Phoenix Meet Up Group?", "slug": "phoenix-meet-up-group", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:06.643Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Danny_Hintze", "createdAt": "2010-12-04T23:01:40.826Z", "isAdmin": false, "displayName": "Danny_Hintze"}, "userId": "2fHm6t2WFDMPShg5b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eA5bEswFd27pCGcym/phoenix-meet-up-group", "pageUrlRelative": "/posts/eA5bEswFd27pCGcym/phoenix-meet-up-group", "linkUrl": "https://www.lesswrong.com/posts/eA5bEswFd27pCGcym/phoenix-meet-up-group", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Phoenix%20Meet%20Up%20Group%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhoenix%20Meet%20Up%20Group%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeA5bEswFd27pCGcym%2Fphoenix-meet-up-group%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Phoenix%20Meet%20Up%20Group%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeA5bEswFd27pCGcym%2Fphoenix-meet-up-group", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeA5bEswFd27pCGcym%2Fphoenix-meet-up-group", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 22, "htmlBody": "<p>I and many of my friends in Phoenix are frequent readers of Less Wrong. Is anyone else from the Metro Phoenix Area?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eA5bEswFd27pCGcym", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 7, "extendedScore": null, "score": 6.94146733268161e-07, "legacy": true, "legacyId": "6425", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T11:15:07.528Z", "modifiedAt": null, "url": null, "title": "Kinect self-awareness-hack (why Friendliness is crucial)", "slug": "kinect-self-awareness-hack-why-friendliness-is-crucial", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.048Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/noGx6BYAKBx4g2gBQ/kinect-self-awareness-hack-why-friendliness-is-crucial", "pageUrlRelative": "/posts/noGx6BYAKBx4g2gBQ/kinect-self-awareness-hack-why-friendliness-is-crucial", "linkUrl": "https://www.lesswrong.com/posts/noGx6BYAKBx4g2gBQ/kinect-self-awareness-hack-why-friendliness-is-crucial", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Kinect%20self-awareness-hack%20(why%20Friendliness%20is%20crucial)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AKinect%20self-awareness-hack%20(why%20Friendliness%20is%20crucial)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnoGx6BYAKBx4g2gBQ%2Fkinect-self-awareness-hack-why-friendliness-is-crucial%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Kinect%20self-awareness-hack%20(why%20Friendliness%20is%20crucial)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnoGx6BYAKBx4g2gBQ%2Fkinect-self-awareness-hack-why-friendliness-is-crucial", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FnoGx6BYAKBx4g2gBQ%2Fkinect-self-awareness-hack-why-friendliness-is-crucial", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 9, "htmlBody": "<p>A hilarious sketch about AI from CollegeHumor at http://bit.ly/i96EzL</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "noGx6BYAKBx4g2gBQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 20, "extendedScore": null, "score": 6.941882821341572e-07, "legacy": true, "legacyId": "6427", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T16:32:00.315Z", "modifiedAt": null, "url": null, "title": "Verifying Rationality via RationalPoker.com", "slug": "verifying-rationality-via-rationalpoker-com", "viewCount": null, "lastCommentedAt": "2017-11-17T16:44:50.851Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Louie", "createdAt": "2010-05-10T21:41:14.619Z", "isAdmin": false, "displayName": "Louie"}, "userId": "JPwZspDjBcfwwuy7W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xjMDAtz5T3Ssz9Y7X/verifying-rationality-via-rationalpoker-com", "pageUrlRelative": "/posts/xjMDAtz5T3Ssz9Y7X/verifying-rationality-via-rationalpoker-com", "linkUrl": "https://www.lesswrong.com/posts/xjMDAtz5T3Ssz9Y7X/verifying-rationality-via-rationalpoker-com", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Verifying%20Rationality%20via%20RationalPoker.com&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVerifying%20Rationality%20via%20RationalPoker.com%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxjMDAtz5T3Ssz9Y7X%2Fverifying-rationality-via-rationalpoker-com%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Verifying%20Rationality%20via%20RationalPoker.com%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxjMDAtz5T3Ssz9Y7X%2Fverifying-rationality-via-rationalpoker-com", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxjMDAtz5T3Ssz9Y7X%2Fverifying-rationality-via-rationalpoker-com", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 508, "htmlBody": "<p>Related to: <a href=\"http://wiki.lesswrong.com/wiki/Problem_of_verifying_rationality\">Problem of verifying rationality</a></p>\n<p>We're excited to announce the (soft) launch of <a href=\"http://rationalpoker.com\">RationalPoker.com</a>! It's a new guide developed by me,&nbsp;Zvi,&nbsp;Kevin, and&nbsp;patrissimo&nbsp;detailing&nbsp;how to use online poker as rationality training to conquer your cognitive biases. We want our community to go from&nbsp;<a href=\"/sequences\">knowing a lot about cognitive biases</a>&nbsp;to actually <a href=\"http://rationalpoker.com/2011/03/15/knowledge-of-biases-isnt-enough/\">having a training method</a>&nbsp;that allows us to integrate that knowledge into our habits -- truly reducing biases instead of just leaving us perpetually lamenting our flawed brain-ware. In the coming weeks, we'll be making the case that online poker is a useful rationalist pursuit along with developing <a href=\"http://rationalpoker.com/category/poker-how-to/\">introductory \"How To\" material</a>&nbsp;that allows those who join us to play profitably.</p>\n<p>We want to make sure we aren&rsquo;t <a href=\"/lw/2po/selfimprovement_or_shiny_distraction_why_less/\">wasting our time</a>&nbsp;practicing an <a href=\"/lw/9t/extreme_rationality_it_could_be_great\">ungrounded art</a>&nbsp;with&nbsp;<a href=\"/lw/2j/schools_proliferating_without_evidence/\">methods that don&rsquo;t work</a>. Poker gives us an objective way to&nbsp;<a href=\"/lw/9p/extreme_rationality_its_not_that_great/\">test x-rationality</a>. The difference between winning and losing in poker once you know a small amount of domain-specific knowledge is due to differing <a href=\"/lw/2s/3_levels_of_rationality_verification/\">levels of rationality</a>. Our site will be presenting the case that a strong rationalist who can act on their knowledge of cognitive biases (a defining feature of x-rationality but not traditional rationality) should have a distinct advantage. We'll be offering the connecting material between&nbsp;<a href=\"/sequences\">the sequences</a> and <a href=\"http://rationalpoker.com/\">online poker</a>&nbsp;to teach you how to apply knowledge of cognitive biases to poker in a way that <a href=\"/lw/h/test_your_rationality/\">verifies your current level of rationality</a>&nbsp;and naturally teaches you to improve your rationality over time.</p>\n<p>Incidentally, this also presents a solution for those of us looking to&nbsp;<a href=\"/lw/2qp/virtual_employment_open_thread/\">earn money from anywhere</a>&nbsp;with a&nbsp;<a href=\"/lw/38u/best_career_models_for_doing_research/\">flexible schedule that leaves time for outside interests</a>.</p>\n<p><a id=\"more\"></a></p>\n<p>We&rsquo;re just getting started so please be kind! Our site is definitely not a final product yet. If you're curious about where we're going with this though,&nbsp;<a href=\"http://rationalpoker.com/feed/\">add us to your RSS feeds</a>&nbsp;or check the site every few days. We hope some of you who aren't convinced yet consider playing once you feel like we&rsquo;ve finally given you enough information to understand why poker is a profitable rationalist pursuit.&nbsp;</p>\n<p>Also, if you sign up for one of the online poker rooms like <a href=\"http://www.fulltiltpoker.com/?key=MDAwMTc3OTEwMDAzOTVFQzIwODI0MDI0MDAwMDAwMDA-\">Full Tilt</a>&nbsp;using our affiliate links, the residuals get donated to Less Wrong/Singularity Institute. That way, the more poker you play after you sign up, the more money you direct towards <a href=\"/lw/1e/raising_the_sanity_waterline/\">raising the sanity waterline</a>&nbsp;and <a href=\"http://intelligence.org/\">creating provably friendly artificial intelligence</a>.</p>\n<p>We&rsquo;re not counting on it, but even a very small group of us could theoretically fund SIAI in a very real and meaningful way <em>just as a side-effect of playing a lot of online poker</em>. I know I'm partisan, but this seems like an unreasonably exciting opportunity! So if you support SIAI and you (or your friends) want to sign up to play online poker anyway, please&nbsp;<a href=\"http://rationalpoker.com/\">sign-up using our links</a>.</p>\n<p>Anyway, we hope some of you <a href=\"/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/\">want to get stronger</a>&nbsp;by joining us in the&nbsp;<a href=\"/lw/gn/the_martial_art_of_rationality/\">Rationality Dojo</a>&nbsp;of online poker. You can be part of our crew of aspiring rationalists who want to&nbsp;<a href=\"/lw/41/individual_rationality_is_a_matter_of_life_and/\">increase our rationality</a>, earn money, and help <a href=\"/lw/373/how_to_save_the_world/\">save the world</a>&nbsp;-- all by playing a fun computer game with no boss, no schedule, and the potential for lots of&nbsp;<a href=\"http://rationalpoker.com/2011/03/21/poker-as-a-transferable-skill/\">self-development and personal growth</a>.</p>\n<p>So check out <a href=\"http://rationalpoker.com/\">our site</a>&nbsp;and let us know if you're interested in joining.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"RLQumypPQGPYg9t6G": 1, "Ng8Gice9KNkncxqcj": 1, "tRPnS4FoZeWjRfBxN": 2, "5f5c37ee1b5cdee568cfb163": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xjMDAtz5T3Ssz9Y7X", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 54, "baseScore": 45, "extendedScore": null, "score": 8.5e-05, "legacy": true, "legacyId": "6428", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 45, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 159, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["uFYQaGCRwt3wKtyZP", "B3b29FJboqnANJRDz", "JnKCaGcgZL4Rsep8m", "LgavAYtzFQZKg95WC", "5K7CMa6dEL7TN7sae", "Kn6H8Tk6EPT4Atq4k", "9bTNcSpNBdPpyocMK", "rNkFLv9tXzq8Lrvrc", "XqmjdBKa4ZaXJtNmf", "DoLQN5ryZ9XkZjq5h", "teaxCFgtmCQ3E9fy8", "WzMJRQBN3ryxiAbhi", "TrmMcujGZt5JAtMGg"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T17:30:18.012Z", "modifiedAt": null, "url": null, "title": "Vizier AIs", "slug": "vizier-ais", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:05.265Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Oligopsony", "createdAt": "2010-08-03T16:27:12.586Z", "isAdmin": false, "displayName": "Oligopsony"}, "userId": "pyLy9zaTeZRW42iin", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5k5Ya2JzwZ9D3Bmbb/vizier-ais", "pageUrlRelative": "/posts/5k5Ya2JzwZ9D3Bmbb/vizier-ais", "linkUrl": "https://www.lesswrong.com/posts/5k5Ya2JzwZ9D3Bmbb/vizier-ais", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vizier%20AIs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVizier%20AIs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5k5Ya2JzwZ9D3Bmbb%2Fvizier-ais%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vizier%20AIs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5k5Ya2JzwZ9D3Bmbb%2Fvizier-ais", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5k5Ya2JzwZ9D3Bmbb%2Fvizier-ais", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 611, "htmlBody": "<p>This seems like a fairly obvious solution to FAI, a subject which has been pondered by many people much more intelligent and learned than I, so I assume there's a crippling flaw with it - just one that's eluded me. But:</p>\n<p>Couldn't an AGI be programmed such that its only desire was to give true answers to the questions asked of it? If the genie desired to argue its way out of the box, it surely could, but it doesn't want to. It just wants to answer questions, like:</p>\n<ul>\n<li>\"Here are all of our scientific experiments, and here's all our literature on measurement error, academic fraud, and the like. What's the most parsimonious explanation for the data?\"</li>\n<li>\"Does P=NP?\"</li>\n<li>\"If I gave you the following utility function, what would you do?\"</li>\n<li>\"What are the most persuasive factually accurate arguments that you can imagine for and against doing x?\"</li>\n<li>\"What distribution and level of income do you expect over the next n years under the following tax codes?\"</li>\n<li>\"What's the shortest DNA sequence of a bug that will be fatal to most everyone in that racial group I hate but spare most everyone in that racial group I like?\"</li>\n</ul>\n<p>Obviously, as a super-powerful tool, such a thing could be used for great evil (as last example shows.) But this is just a problem with developing more powerful tools in general, and it doesn't seem inconceivable that we could develop institutions and safeguards (assuming the collective will to do so in the first place) that would, to a passable degree, prevent just anyone from asking just anything without it solely in the hands of a privately interested clique. For instance, if we're really paranoid, the public and academics could veto questions before they're asked, and a sequestered jury of volunteers among the terminally ill could then be given a 50% chance of the computer telling them \"sorry, I can't tell you anything\" and a 50% chance of being told the answer, which they could then decide to be understandable and worthy of release upon their deaths or not, such that outsiders would not know the difference between chosen and chance nonrelease. (Looser safeguards could exist for questions where we can imagine all the possible answers, and judge none of them to be dangerous.) We would have to phrase questions precisely to get useful answers, but this seems like something we'd have to solve in creating AI that weren't viziers anyway.</p>\n<p>An active friendly AI would be able to help us out more efficiently than we would ourselves with a mere vizier, but this seems to have a much lower downside risk than of releasing an AI which we *think* is friendly.</p>\n<p><strong>Edit I</strong>: to be more precise, each question creates a demon with access to the AI's computational capacity; demons can't communicate with each other, and their only goal is to give the true answer (or a probability distribution of answers, or whatever) to the question asked, given the information available as of its asking and within the timeframe requested. Then they disappear into the ether. It can't do anything but read and textually respond to questions, and there's no supervisory utility function that would manipulate one answer to get a better answer on another.</p>\n<p><strong>Edit II</strong>: Vladimir kindly notes that Eliezer has already addressed this in a frontpage article from the days of yore. Regardless of whether I agree with the arguments there, I feel kind of rude for bringing something up in, in ignorance, in an independent thread. I tried to delete this post, but nothing happened, so I feel both rude and silly.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5k5Ya2JzwZ9D3Bmbb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": -1, "extendedScore": null, "score": -1e-06, "legacy": true, "legacyId": "6429", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T20:44:16.401Z", "modifiedAt": null, "url": null, "title": "Real-world Newcomb-like Problems ", "slug": "real-world-newcomb-like-problems", "viewCount": null, "lastCommentedAt": "2017-06-17T04:21:39.071Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TejMdvF9XTNP5pGDR/real-world-newcomb-like-problems", "pageUrlRelative": "/posts/TejMdvF9XTNP5pGDR/real-world-newcomb-like-problems", "linkUrl": "https://www.lesswrong.com/posts/TejMdvF9XTNP5pGDR/real-world-newcomb-like-problems", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Real-world%20Newcomb-like%20Problems%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReal-world%20Newcomb-like%20Problems%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTejMdvF9XTNP5pGDR%2Freal-world-newcomb-like-problems%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Real-world%20Newcomb-like%20Problems%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTejMdvF9XTNP5pGDR%2Freal-world-newcomb-like-problems", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTejMdvF9XTNP5pGDR%2Freal-world-newcomb-like-problems", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 718, "htmlBody": "<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Elaboration of:</span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"> A <a href=\"/lw/3mn/discussion_for_eliezer_yudkowskys_paper_timeless/3ase\">point</a> I&rsquo;ve made before.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong style=\"mso-bidi-font-weight: normal;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Summary: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">I phrase a variety of realistic dilemmas so as to show how they&rsquo;re similar to Newcomb&rsquo;s problem.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Problem: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Many LW readers don't understand why we bother talking about obviously-unrealistic situations like <a href=\"http://wiki.lesswrong.com/wiki/Counterfactual_mugging\">Counterfactual Mugging</a> or <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a>.<span style=\"mso-spacerun: yes;\">&nbsp; </span>Here I'm going to put them in the context of realistic dilemmas, identifying the common thread, so that the parallels are clear and you can see how Counterfactual Mugging et al. are actually highlighting relevant aspects of real-world problems -- even though they may do it unrealistically.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">The common thread </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">across all the Newcomblike problems I will list is this: \"You would not be in a position to enjoy a larger benefit unless you would <em>cause</em> [1] a harm to yourself within particular outcome branches (including bad ones).\"<span style=\"mso-spacerun: yes;\">&nbsp; </span>Keep in mind that a &ldquo;benefit&rdquo; can include probabilistic ones (so that you don&rsquo;t <em style=\"mso-bidi-font-style: normal;\">always</em> get the benefit by having this propensity).<span style=\"mso-spacerun: yes;\">&nbsp; </span>Also, many of the relationships listed exist because your decisions are correlated with others&rsquo;.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Without further ado, here is a list of both real and theoretical situations, in rough order from most to least \"real-world\"ish:</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Natural selection: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not exist as an evolution-constructed mind unless you would be willing to <em>cause</em> the spreading of your genes at the expense of your life and leisure. (I elaborate <a href=\"/lw/2ls/morality_as_parfitianfiltered_decision_theory/\"><span style=\"color: #800080;\">here</span></a>.)</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Expensive punishment: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position of enjoying a crime level this low unless you would <em>cause</em> a net loss to yourself to punish crimes when they do happen.<span style=\"mso-spacerun: yes;\">&nbsp; </span>(My <a href=\"/lw/4x9/crime_and_punishment/3r7t\"><span style=\"color: #800080;\">recent</span></a> <a href=\"/lw/4x9/crime_and_punishment/3r8j\"><span style=\"color: #800080;\">comments</span></a> on the matter.)</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">\"<a href=\"http://en.wikipedia.org/wiki/Mutually_assured_destruction\"><span style=\"color: #800080;\">Mutually assured destruction</span></a>\" tactics: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position of having a peaceful enemy unless you would <em>cause</em> destruction of both yourself and the enemy in those cases where the enemy attacks.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Voting: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in a polity where humans (rather than \"<a href=\"/lw/mi/stop_voting_for_nincompoops/\"><span style=\"color: #800080;\">lizards</span></a>\") rule over you unless you would <em>cause</em> yourself to endure the costs of voting despite the slim chance of influencing the outcome.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Lying: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position where your statements influence others&rsquo; beliefs unless you would be willing state true things that are sub-optimal to you for others to believe. (Kant/Categorical Imperative name-check)</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Cheating on tests: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position to reap the (larger) gains of being able to communicate your ability unless you would forgo the benefits of an artificially-high score.<span style=\"mso-spacerun: yes;\">&nbsp; </span>(Kant/Categorical Imperative name-check)</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Shoplifting: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position where merchants offer goods of this quality, with this low of a markup and this level of security lenience unless you would pass up the opportunity to shoplift even when you could get away with it, or at least have incorrect beliefs about the success probability that lead you to act this way.<span style=\"mso-spacerun: yes;\">&nbsp; </span>(Controversial -- see <a href=\"/lw/3mn/discussion_for_eliezer_yudkowskys_paper_timeless/3auo\">previous discussion</a>.)</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"/lw/2v3/hazing_as_counterfactual_mugging/\">Hazing/abuse cycles</a>: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position to be unhazed/unabused (as often) by earlier generations unless you would forgo the satisfaction of abusing later generations when you had been abused.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"file:///C:/notes/LW%20stuff/Akrasia/addiction:%20You%20would%20not%20be%20addiction-%20and%20bad%20habit-free%20unless%20you%20would%20cause%20the%20pain%20of%20not%20feeding%20the%20habit%20during%20the%20existence-moments%20when%20you%20do%20have%20addictions%20and%20bad%20habits\">Akrasia/addiction</a>:</span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"> You would not be addiction- and bad habit-free unless you would <em>cause</em> the pain of not feeding the habit during the existence-moments when you do have addictions and bad habits.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></strong></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"/lw/182/the_absentminded_driver/\"><span style=\"color: #800080;\">Absent-Minded Driver</span></a>: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not ever have the opportunity to take the correct exit unless you would sometimes drive past it.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"http://wiki.lesswrong.com/wiki/Parfit%27s_hitchhiker\">Parfit's Hitchhiker</a>: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position of surviving the desert unless you would <em>cause</em> the loss of money to pay the rescuer.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a>: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position of Box #2 being filled unless you would forgo the contents of Box #1.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Newcomb's problem with transparent boxes: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">Ditto, except that Box #2 isn't always filled.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"http://wiki.lesswrong.com/wiki/Prisoner%27s_dilemma\">Prisoner's Dilemma</a>: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not be in the position of having a cooperating partner unless you would <em>cause</em> the diminished \"expected prison avoidance\" by cooperating yourself.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\"><a href=\"http://wiki.lesswrong.com/wiki/Counterfactual_mugging\">Counterfactual Mugging</a>: </span></strong><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">You would not ever be in the position of receiving lots of free money unless you would <em>cause</em> yourself to lose less money in those cases where you lose the coin flip.</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">&nbsp;</span></p>\r\n<p class=\"MsoNormal\" style=\"margin: 0in 0in 0pt; line-height: 150%; mso-pagination: none; mso-layout-grid-align: none;\"><span style=\"font-size: 10pt; line-height: 150%; font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;\">[1] &ldquo;Cause&rdquo; is used here in the technical sense, which requires the effect to be either in the future, or, in timeless formalisms, a descendent of the minimal set (in a Bayesian network) that screens off knowledge about the effect.<span style=\"mso-spacerun: yes;\">&nbsp; </span>In the parlance of Newcomb&rsquo;s problem, it may feel intuitive to say that &ldquo;one-boxing causes Box #2 to be filled&rdquo;, but this is not correct in the technical sense.</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"dPPATLhRmhdJtJM2t": 1, "fihKHQuS5WZBJgkRm": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TejMdvF9XTNP5pGDR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 22, "extendedScore": null, "score": 4.6e-05, "legacy": true, "legacyId": "6431", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["iNXS7ggMhXNoKCaRr", "k5qPoHFgjyxtvYsm7", "EdRHRbTuzqWCFsKDy", "GfHdNfqxe3cSCfpHL"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T22:01:46.130Z", "modifiedAt": null, "url": null, "title": "LessWrong search traffic doubles", "slug": "lesswrong-search-traffic-doubles", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:55.853Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Louie", "createdAt": "2010-05-10T21:41:14.619Z", "isAdmin": false, "displayName": "Louie"}, "userId": "JPwZspDjBcfwwuy7W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/j7fKMzgB3Y6XDiuWx/lesswrong-search-traffic-doubles", "pageUrlRelative": "/posts/j7fKMzgB3Y6XDiuWx/lesswrong-search-traffic-doubles", "linkUrl": "https://www.lesswrong.com/posts/j7fKMzgB3Y6XDiuWx/lesswrong-search-traffic-doubles", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LessWrong%20search%20traffic%20doubles&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALessWrong%20search%20traffic%20doubles%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj7fKMzgB3Y6XDiuWx%2Flesswrong-search-traffic-doubles%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LessWrong%20search%20traffic%20doubles%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj7fKMzgB3Y6XDiuWx%2Flesswrong-search-traffic-doubles", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fj7fKMzgB3Y6XDiuWx%2Flesswrong-search-traffic-doubles", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 284, "htmlBody": "<p>LessWrong search traffic doubles... <strong>despite Google thinking our site is a pro-family pro-democracy astrology blog</strong>! More on that in a minute.</p>\n<p>First, The Good News: Since I started doing SEO on LessWrong (10 months ago) search traffic from Google has <strong>doubled</strong>! It took researching &gt;200 different techniques -- actually implementing 14 of them (w/ help from <a href=\"http://tricycledevelopments.com/\">Tricycle</a>) -- 2 of which I think are responsible for most of the improvement:</p>\n<ul>\n<li>Reversing titles (e.g., \"Less Wrong - OMG Scholarship!\" -&gt; \"OMG Scholarship! - Less Wrong\")</li>\n<li>No-Following / No-Indexing a complex set of duplicate content</li>\n</ul>\n<div>The analytics make me believe that this improvement is due to structural changes and not just generally increased traffic. But it certainly hasn't hurt that people have been writing new content and that HP:MoR exists.</div>\n<p>Anyway, I'm&nbsp;<em>really happy&nbsp;</em>about this! This was the explicit goal I set for myself 10 months ago. It's nice to achieve goals... especially unreasonably&nbsp;ambitious&nbsp;ones.</p>\n<p>So... YAY!! :D</p>\n<p>OK, Now, The Bad News: So I was trying to figure out why we never get any traction for search terms like \"rationality\" when I looked through Google Webmaster tools. This is what Google thinks our site is about, keyword wise:</p>\n<p>&nbsp;</p>\n<p><!-- table {mso-displayed-decimal-separator:\"\\.\"; mso-displayed-thousand-separator:\"\\,\";} td {padding-top:1px; padding-right:1px; padding-left:1px; mso-ignore:padding; color:windowtext; font-size:10.0pt; font-weight:400; font-style:normal; text-decoration:none; font-family:Verdana; mso-generic-font-family:auto; mso-font-charset:0; mso-number-format:General; text-align:general; vertical-align:bottom; border:none; mso-background-source:auto; mso-pattern:auto; mso-protection:locked visible; white-space:nowrap; mso-rotate:0;} ruby {ruby-align:left;} rt {color:windowtext; font-size:8.0pt; font-weight:400; font-style:normal; text-decoration:none; font-family:Verdana; mso-generic-font-family:auto; mso-font-charset:0; mso-char-type:none; display:none;} --> \n<table style=\"border-collapse: collapse\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\" width=\"150\">\n<!--StartFragment--> <colgroup><col span=\"2\" width=\"75\"></col> </colgroup> \n<tbody>\n<tr height=\"13\">\n<td width=\"75\" height=\"13\">Keyword</td>\n<td width=\"75\">Occurrences</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>vote</strong></td>\n<td align=\"right\"><strong>196504</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>points</strong></td>\n<td align=\"right\"><strong>152881</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>permalink</strong></td>\n<td align=\"right\"><strong>95106</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>children</strong></td>\n<td align=\"right\"><strong>84578</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>parent</strong></td>\n<td align=\"right\"><strong>56374</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">people</td>\n<td align=\"right\">37047</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">it's</td>\n<td align=\"right\">27082</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>march</strong></td>\n<td align=\"right\"><strong>21846</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>february</strong></td>\n<td align=\"right\"><strong>21520</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>january</strong></td>\n<td align=\"right\"><strong>20425</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">human</td>\n<td align=\"right\">19587</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>december</strong></td>\n<td align=\"right\"><strong>18005</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>september</strong></td>\n<td align=\"right\"><strong>15695</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>august</strong></td>\n<td align=\"right\"><strong>15667</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>password</strong></td>\n<td align=\"right\"><strong>15377</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>april</strong></td>\n<td align=\"right\"><strong>14714</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>october</strong></td>\n<td align=\"right\"><strong>14011</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">seem</td>\n<td align=\"right\">12822</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>november</strong></td>\n<td align=\"right\"><strong>11546</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>july</strong></td>\n<td align=\"right\"><strong>11265</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>june</strong></td>\n<td align=\"right\"><strong>9283</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">world</td>\n<td align=\"right\">8542</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>post</strong></td>\n<td align=\"right\"><strong>8496</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">actual</td>\n<td align=\"right\">8251</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><em>probability</em></td>\n<td align=\"right\"><em>8114</em></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>child</strong></td>\n<td align=\"right\"><strong>7828</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">moral</td>\n<td align=\"right\">7787</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">work</td>\n<td align=\"right\">7143</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">might</td>\n<td align=\"right\">6250</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">new</td>\n<td align=\"right\">6156</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">theory</td>\n<td align=\"right\">5827</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">argument</td>\n<td align=\"right\">5639</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">read</td>\n<td align=\"right\">5278</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">utility</td>\n<td align=\"right\">5206</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">account</td>\n<td align=\"right\">5002</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">evident</td>\n<td align=\"right\">4777</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">belief</td>\n<td align=\"right\">4749</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">remember</td>\n<td align=\"right\">4691</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>recent</strong></td>\n<td align=\"right\"><strong>4584</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">intelligent</td>\n<td align=\"right\">4582</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">science</td>\n<td align=\"right\">4424</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">eliezer</td>\n<td align=\"right\">4384</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">doesn't</td>\n<td align=\"right\">4339</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><em>rationality</em></td>\n<td align=\"right\"><em>4188</em></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">brain</td>\n<td align=\"right\">3969</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">decision</td>\n<td align=\"right\">3904</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">life</td>\n<td align=\"right\">3795</td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\"><strong>username</strong></td>\n<td align=\"right\"><strong>3732</strong></td>\n</tr>\n<tr height=\"13\">\n<td height=\"13\">mind</td>\n<td align=\"right\">3721</td>\n</tr>\n</tbody>\n</table>\n</p>\n<p>All the keywords that I&nbsp;<strong>bolded&nbsp;</strong>are purely structural elements of the Less Wrong site layout. And it appears Google actually is punishing our site for this keyword density imbalance. Google really does think our site is about voting, parenting, and astrology. And while I find it somewhat hilarious that our top source of Google impressions (27,000/mo) is for the keyword \"babies\", I also lament that the keyword \"rationality\" is our #3955 source of traffic. We should invert this.</p>\n<p>So does anyone have any ideas? How do other sites solve this problem?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "j7fKMzgB3Y6XDiuWx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 26, "baseScore": 34, "extendedScore": null, "score": 6.4e-05, "legacy": true, "legacyId": "6432", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-25T23:49:45.425Z", "modifiedAt": null, "url": null, "title": "Toronto Meetup - Thursday, March 31st, 8:00 PM", "slug": "toronto-meetup-thursday-march-31st-8-00-pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.036Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spencer_Sleep", "createdAt": "2011-02-11T08:03:53.049Z", "isAdmin": false, "displayName": "Spencer_Sleep"}, "userId": "xAjAXuvj2czWZix2v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2h2NkNc8J8YXZv5sQ/toronto-meetup-thursday-march-31st-8-00-pm", "pageUrlRelative": "/posts/2h2NkNc8J8YXZv5sQ/toronto-meetup-thursday-march-31st-8-00-pm", "linkUrl": "https://www.lesswrong.com/posts/2h2NkNc8J8YXZv5sQ/toronto-meetup-thursday-march-31st-8-00-pm", "postedAtFormatted": "Friday, March 25th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toronto%20Meetup%20-%20Thursday%2C%20March%2031st%2C%208%3A00%20PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToronto%20Meetup%20-%20Thursday%2C%20March%2031st%2C%208%3A00%20PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2h2NkNc8J8YXZv5sQ%2Ftoronto-meetup-thursday-march-31st-8-00-pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toronto%20Meetup%20-%20Thursday%2C%20March%2031st%2C%208%3A00%20PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2h2NkNc8J8YXZv5sQ%2Ftoronto-meetup-thursday-march-31st-8-00-pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2h2NkNc8J8YXZv5sQ%2Ftoronto-meetup-thursday-march-31st-8-00-pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 179, "htmlBody": "<p><strong><a id=\"more\"></a>When</strong>: &nbsp;Thursday, March 31st, 8:00 PM</p>\n<p><strong>Where</strong>: The Bedford Academy, 36 Prince Arthur Avenue</p>\n<p>Hi everyone,</p>\n<p>This will be our third Toronto meetup. &nbsp;The last two were resounding successes, so we plan on continuing them on a biweekly basis.&nbsp;</p>\n<p>Returning people should note the location change; the Duke of York has live music every Thursday at 9 PM from now until May, so that venue is no longer optimal. &nbsp;The Bedford Academy is just across the street and is fairly similar, so it will serve well as a substitute.&nbsp;</p>\n<p>The reservation will be under the name lesswrong, and we will have a sign. &nbsp;</p>\n<p>Newcomers are&nbsp;<em>extremely</em>&nbsp;welcome. &nbsp;You don't have to have read all the sequences and be a regular poster to attend these meetings; everyone is encouraged to come out. &nbsp;The liveliest discussions are usually those between people with different ideas and background reading. &nbsp;</p>\n<p>Feel free to come with discussion topics in mind, that generally makes the first half hour run more smoothly, as that way we don't need to sit there waiting for someone to come up with something to talk about.</p>\n<p>See you there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2h2NkNc8J8YXZv5sQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 6.943962873100704e-07, "legacy": true, "legacyId": "6430", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-26T10:40:13.369Z", "modifiedAt": null, "url": null, "title": "I want to learn programming", "slug": "i-want-to-learn-programming", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:24.541Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "benelliott", "createdAt": "2010-10-24T16:54:14.159Z", "isAdmin": false, "displayName": "benelliott"}, "userId": "H4iHqStnPyuAkniAA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aBeJuczn3b67m43qR/i-want-to-learn-programming", "pageUrlRelative": "/posts/aBeJuczn3b67m43qR/i-want-to-learn-programming", "linkUrl": "https://www.lesswrong.com/posts/aBeJuczn3b67m43qR/i-want-to-learn-programming", "postedAtFormatted": "Saturday, March 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20want%20to%20learn%20programming&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20want%20to%20learn%20programming%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaBeJuczn3b67m43qR%2Fi-want-to-learn-programming%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20want%20to%20learn%20programming%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaBeJuczn3b67m43qR%2Fi-want-to-learn-programming", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaBeJuczn3b67m43qR%2Fi-want-to-learn-programming", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 128, "htmlBody": "<p>I would like to learn programming but haven't been able to get started. Advice appreciated, both high-level (you should try learing language X) and low level (you can find a program that will run language X here), the latter has been a particular problem for me, I don't really know how this sort of thing works.</p>\n<p>I am currently studying maths and physics, and I have a particular talent for the former, so I would probably do well with a language that plays to that strength. My only actual experience with programming was when my father let me play around with Jython a bit when I was about 13, I had some fun calculating prime numbers and approximating pi but never got any farther.</p>\n<p>Thanks in advance for all suggestions.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aBeJuczn3b67m43qR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 6.945755532843201e-07, "legacy": true, "legacyId": "6439", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-26T13:53:12.303Z", "modifiedAt": null, "url": null, "title": "The null model of science", "slug": "the-null-model-of-science", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:08.394Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Johnicholas", "createdAt": "2009-02-27T15:01:52.708Z", "isAdmin": false, "displayName": "Johnicholas"}, "userId": "kBvTXutfPytNtzPyD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/c7RSQkTTw8SBmTjWX/the-null-model-of-science", "pageUrlRelative": "/posts/c7RSQkTTw8SBmTjWX/the-null-model-of-science", "linkUrl": "https://www.lesswrong.com/posts/c7RSQkTTw8SBmTjWX/the-null-model-of-science", "postedAtFormatted": "Saturday, March 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20null%20model%20of%20science&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20null%20model%20of%20science%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc7RSQkTTw8SBmTjWX%2Fthe-null-model-of-science%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20null%20model%20of%20science%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc7RSQkTTw8SBmTjWX%2Fthe-null-model-of-science", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc7RSQkTTw8SBmTjWX%2Fthe-null-model-of-science", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<p>\n<div style=\"color: #000000; font-family: Verdana, Arial, Helvetica, sans-serif; font-size: small; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #ffffff; padding: 0.5em; margin: 8px;\">\n<p>Jonah Lehrer wrote about the (surprising?) power of publication bias.</p>\n<p><a href=\"http://m.newyorker.com/reporting/2010/12/13/101213fa_fact_lehrer?currentPage=all\">http://m.newyorker.com/reporting/2010/12/13/101213fa_fact_lehrer?currentPage=all</a></p>\n<p>Cosma Shalizi (I think) said something, or pointed to something, about the null model of science - what science would look like if there were no actual effects, just statistical anomalies that look good at first. I can't find the reference, though.</p>\n<p>&nbsp;</p>\n<div><br /></div>\n</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "c7RSQkTTw8SBmTjWX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 25, "extendedScore": null, "score": 5.6e-05, "legacy": true, "legacyId": "6440", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-26T19:59:08.512Z", "modifiedAt": null, "url": null, "title": "Just letting alcoholics drink", "slug": "just-letting-alcoholics-drink", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:07.262Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MaApwCXeTLHi6nbRi/just-letting-alcoholics-drink", "pageUrlRelative": "/posts/MaApwCXeTLHi6nbRi/just-letting-alcoholics-drink", "linkUrl": "https://www.lesswrong.com/posts/MaApwCXeTLHi6nbRi/just-letting-alcoholics-drink", "postedAtFormatted": "Saturday, March 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Just%20letting%20alcoholics%20drink&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJust%20letting%20alcoholics%20drink%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMaApwCXeTLHi6nbRi%2Fjust-letting-alcoholics-drink%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Just%20letting%20alcoholics%20drink%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMaApwCXeTLHi6nbRi%2Fjust-letting-alcoholics-drink", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMaApwCXeTLHi6nbRi%2Fjust-letting-alcoholics-drink", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 77, "htmlBody": "<p><a href=\"http://www.twincities.com/ci_16774107?nclick_check=1\">\"Wet houses\"-- subsidized housing for alcoholics</a> (they need to get most of their own money for alcohol, but their other expenses are covered) might actually be a good idea. It's cheaper than trying to get them to stop drinking, arguably kinder than trying to get people to take on a very hard task that they aren't interested in, and leads to less collateral damage than having alcoholics couch-surfing or living on the street.</p>\n<p>Utilitarians, what do you think?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MaApwCXeTLHi6nbRi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 18, "extendedScore": null, "score": 6.947296547079713e-07, "legacy": true, "legacyId": "6442", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-26T21:27:23.846Z", "modifiedAt": null, "url": null, "title": "The Difference Between Classical, Evidential, and Timeless Decision Theories", "slug": "the-difference-between-classical-evidential-and-timeless", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:06.578Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "DanielLC", "createdAt": "2009-12-26T17:34:50.257Z", "isAdmin": false, "displayName": "DanielLC"}, "userId": "3e6zTkDmDpNspRb8P", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JEaPKSjARuJJqQJeN/the-difference-between-classical-evidential-and-timeless", "pageUrlRelative": "/posts/JEaPKSjARuJJqQJeN/the-difference-between-classical-evidential-and-timeless", "linkUrl": "https://www.lesswrong.com/posts/JEaPKSjARuJJqQJeN/the-difference-between-classical-evidential-and-timeless", "postedAtFormatted": "Saturday, March 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Difference%20Between%20Classical%2C%20Evidential%2C%20and%20Timeless%20Decision%20Theories&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Difference%20Between%20Classical%2C%20Evidential%2C%20and%20Timeless%20Decision%20Theories%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJEaPKSjARuJJqQJeN%2Fthe-difference-between-classical-evidential-and-timeless%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Difference%20Between%20Classical%2C%20Evidential%2C%20and%20Timeless%20Decision%20Theories%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJEaPKSjARuJJqQJeN%2Fthe-difference-between-classical-evidential-and-timeless", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJEaPKSjARuJJqQJeN%2Fthe-difference-between-classical-evidential-and-timeless", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 292, "htmlBody": "<p>I couldn't find any concise explanation of what the decision theories are. Here's mine:</p>\n<p>A Causal Decision Theorist wins, given what's happened so far.</p>\n<p>An Evidential Decision Theorist wins, given what they know.</p>\n<p>A Timeless Decision Theorist wins a priori.</p>\n<p>To explain what I mean, here are two interesting problems. In each of them, two of the decision theories give one choice, and the third gives the other.</p>\n<p>In <a href=\"http://wiki.lesswrong.com/wiki/Newcomb%27s_problem\">Newcomb's problem</a> and you separate people into groups based on what happened before the experiment, i.e. whether or not Box A has money, CDT will be at least as successful in each group as any other strategy, and notably more successful than EDT and TDT. If you separate it into what's known, there's only one group, since everybody has the same information. EDT is at least as successful as any other strategy, and notably more successful than CDT. If you don't separate it at all, TDT will be at least as successful as any other strategy, and notably more successful than EDT.</p>\n<p>In <a href=\"http://wiki.lesswrong.com/wiki/Parfit%27s_hitchhiker\">Parfit's hitchhiker</a>, when it comes time to pay the driver, if you split into groups based on what happened before the experiment, i.e. whether or not one has been picked up, CDT will be at least as successful in each group as any other strategy, and notably more successful than TDT. If you split based on what's given, which is again whether or not one has been picked up, EDT will be at least as successful in each group as any other strategy, and notably more successful than TDT. If you don't separate at all, TDT will be at least as successful as any other strategy, and notably more successful than CDT and EDT.</p>\n<p>There's one thing I'm not sure about. How does Updateless Decision Theory compare?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb28f": 2, "5f5c37ee1b5cdee568cfb1db": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JEaPKSjARuJJqQJeN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 6, "extendedScore": null, "score": 6.947539934719579e-07, "legacy": true, "legacyId": "6443", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-26T22:26:56.436Z", "modifiedAt": null, "url": null, "title": "Faith and theory", "slug": "faith-and-theory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:38.282Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LND8Gt3u2ctcorENv/faith-and-theory", "pageUrlRelative": "/posts/LND8Gt3u2ctcorENv/faith-and-theory", "linkUrl": "https://www.lesswrong.com/posts/LND8Gt3u2ctcorENv/faith-and-theory", "postedAtFormatted": "Saturday, March 26th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Faith%20and%20theory&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFaith%20and%20theory%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLND8Gt3u2ctcorENv%2Ffaith-and-theory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Faith%20and%20theory%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLND8Gt3u2ctcorENv%2Ffaith-and-theory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLND8Gt3u2ctcorENv%2Ffaith-and-theory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1129, "htmlBody": "<h2>Faith<br /></h2>\n<p>Faith is often described as belief without evidence.&nbsp; The famous definition in Hebrews, in its best-known form, is close to that:</p>\n<p style=\"padding-left: 30px;\">\"Now faith is the substance of things hoped for, the evidence of things not seen.\" - Hebrews 11:1 (King James Version),&nbsp;often attributed to St. Paul</p>\n<p>This is the way the term \"faith\" is used by religious people when they argue against the primacy of reason, as demonstrated in <a href=\"/lw/b0/antirationality_quotes/\">these quotes</a>, which is the context I am concerned with. &nbsp;(It's also the meaning used&nbsp;by atheists arguing against religious faith, eg. Sam Harris in <a href=\"http://www.amazon.com/End-Faith-Religion-Terror-Future/dp/0393035158\">The End of Faith</a>.) &nbsp;But the New International Version, which is less pretty, but translated more carefully by better scholars from more and older texts, says:</p>\n<p style=\"padding-left: 30px;\">\"Now faith is confidence in what we hope for and assurance about what we do not see.\"</p>\n<p>The <a href=\"http://en.wikipedia.org/wiki/Faith\">Wikipedia</a> and <a href=\"http://plato.stanford.edu/entries/faith/\">Plato</a> entries on <em>faith</em> give information on the use of words translated as \"faith\" in English in different religions and philosophies.&nbsp; Wikipedia cites the <span class=\"citation book\"><em>New American standard exhaustive concordance of the Bible</em> as saying,</span></p>\n<p style=\"padding-left: 30px;\">In English translations of the New Testament, the word faith generally corresponds to the Greek noun &pi;\u03af&sigma;&tau;&iota;&sigmaf; (<em>pistis</em>) or the Greek verb &pi;&iota;&sigma;&tau;&epsilon;\u03cd&omega; (<em>pisteuo</em>), meaning \"to trust, to have confidence, faithfulness, to be reliable, to assure\".<sup id=\"cite_ref-Thomas1981_21-0\" class=\"reference\"><a href=\"http://en.wikipedia.org/wiki/Faith#cite_note-Thomas1981-21\"><span>[</span>22<span>]</span></a></sup></p>\n<h2>Theory</h2>\n<p>Scientific theory is also assurance about things unseen.&nbsp; (If you can observe something directly, you don't need science.)&nbsp; Science builds an abstract mental structure that interprets data and makes predictions from it.&nbsp; It is also an epistemology for belief in things we can't see, like atoms, oxygen, radio waves, vast distances, or circulation of the blood.</p>\n<h2>The history of faith and theory<br /></h2>\n<p>The most popular belief appears to be that faith is ancient, and scientific theory came along later to supersede it.&nbsp; But I'm not aware of evidence for this.<a id=\"more\"></a></p>\n<p>I've read many accounts by Christian missionaries of how they persuaded people living in tribal cultures to convert to Christianity.&nbsp; Faith is not a factor in these debates.&nbsp; Tribal cultures don't need to protect their religions with rationalizations.&nbsp; In these narratives, the tribe members often seem unaware that not believing their religion is a physical possibility; they are sometimes less surprised that the white-skinned stranger descended from the skies, than that he pretends to be unfamiliar with their gods.&nbsp; Tribal people are more reasonable about the matter than people from advanced civilizations; they never defend their religion by making arguments against reason itself.&nbsp; They are pragmatic and opportunistic:&nbsp; Can the missionary cure the sick better than the tribal shaman?&nbsp; Yes?&nbsp; Then his god is stronger!</p>\n<p>There are numerous <a href=\"http://www.biblegateway.com/keyword/?search=faith&amp;version1=31&amp;searchtype=all\">verses in the</a> <a href=\"http://cvhope.20m.com/faithot.htm\">old Testament about faith</a>, and many more passages describing the same sentiment.&nbsp; But \"faith\" in these passages seems synonymous with \"obedience\", or possibly \"trust\", when it isn't something else entirely that was lost in translation or history (e.g., \"And there shall be faith in thy times: riches of salvation, wisdom and knowledge\" ... what?)</p>\n<p>Nothing described in the Wikipedia or Plato pages on faith definitely antedates Buddhism<a href=\"#hindu\"><sup>1</sup></a>.&nbsp; The concepts of faith, and of scientific theory, both may have developed primarily between the 6th century BC, when mathematics, philosophy, Buddhism, large parts of Hindu philosophy, and Phariseeic (intellectual) Judaism were being invented; and the time when Jesus spoke and Paul wrote about faith as a kind of power and a means of justification (a technical Christian term).</p>\n<p>By the time Jesus spoke of faith, it had one main feature distinguishing it from theory:&nbsp; The truth of the belief was proportional to the strength of the belief.&nbsp; Luke 17:6 (NIV): \"If you have faith as small as a mustard seed, you can say to this mulberry tree, 'Be uprooted and planted in the sea,' and it will obey you.\"<a href=\"#mass-energy\"><sup>2</sup></a>&nbsp; Paul's chapter on faith (<a href=\"http://www.biblegateway.com/passage/?search=Hebrews+11&amp;version=NIV\">Hebrews 11</a>) describes faith as having causal power.</p>\n<p>How many people living during that time could have distinguished between faith and theory?</p>\n<h2>Faith as reaction to theory</h2>\n<p>One theory of mine is that faith developed as a reaction to theory.&nbsp; How to keep a religion alive, when these pesky philosophers are corrupting the youth with reason?&nbsp; Declare that reason is not the final arbiter!&nbsp; Faith is thus a sort of early post-modernism.</p>\n<p>You could alternatively see it as the post-philosophical epistemology for people who value winning over being right; it lets them retain adaptive beliefs that their society had evolved, even after philosophers found disproofs of those beliefs.</p>\n<h2>Faith as popularized theory<br /></h2>\n<p>\"Christianity is Platonism for 'the people'\".&nbsp; - Nietzsche, preface to <em>Beyond Good and Evil</em></p>\n<p>Another theory is that faith is a faulty theory about theory.&nbsp; Ancient people could have observed proto-scientists, and their ability to make seemingly-impossible predictions - such as the time of eclipses.&nbsp; The first prediction of a solar eclipse was <a href=\"http://www.thaindian.com/newsportal/sports/first-total-solar-eclipse-to-be-predicted-occurred-in-585-bc_10055593.html\">perhaps in 585 BC</a>.&nbsp; What did non-astronomers believe the astronomers were doing?&nbsp; Did they think that the power of the astronomer's belief caused the eclipse?&nbsp; How many Pythagoreans understood why the sum of the squares of the sides of a right triangle equalled the square of its hypotenuse, or why the square root of 2 could not be rational?&nbsp; Did they take these claims <em>on faith</em>, like most high-school geometry students do today?&nbsp; If you imagine that understanding has magical power, it would be easy to read what Paul wrote about faith, and substitute the word \"understanding\".&nbsp; Is that what some Gnostic Christians were doing?</p>\n<h2>Faith as proto-theory<br /></h2>\n<p>Another theory is that theory is faith++.&nbsp; The mental commitment of faith is very similar to the mental commitment of theory, if not the same.&nbsp; People practiced in having faith in things unseen, would be more likely to be able to have theories about things unseen.&nbsp; They would just have better heuristics for what to have faith in.&nbsp; This suggests that faith is a necessary historical precondition for theory.</p>\n<h2>Faith &asymp; theory</h2>\n<p>Perhaps my favorite theory - and these theories are not all mutually exclusive - is that many pre-modern thinkers did not distinguish between faith and theory.&nbsp; It's not clear that Gnostic Christians, Hermetic philosophers, or alchemists were able to make that distinction.&nbsp; Many Gnostic Christians may have thought they were practicing a kind of natural philosophy.&nbsp; Many Renaissance alchemists may have regarded their studies as a spiritual practice.&nbsp; Therefore, in modern debates between faith and science, when people cite pre-modern texts and try to claim their authors for their side based on their usage of terms like \"faith\" or \"reason\", it may be those authors weren't even aware there were different sides to be on.</p>\n<p>&nbsp;</p>\n<p>1. <a name=\"hindu\"></a>The Hindu trans-rational epistemology referred to by Wikipedia may be an older variant of faith.&nbsp; Its age, and its relation to what I'm calling faith, are unclear to me.</p>\n<p>2. <a name=\"mass-energy\"></a>Faith performs work, and is therefore a type of energy.&nbsp; A mustard seed <a href=\"http://askville.amazon.com/mustard-seed-weigh/AnswerViewer.do?requestId=5460571\">weighs about .002g</a>, which is the mass equivalent of the energy of 43 tonnes of TNT.&nbsp; So Jesus was being conservative.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LND8Gt3u2ctcorENv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 8, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "6441", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h2 id=\"Faith\">Faith<br></h2>\n<p>Faith is often described as belief without evidence.&nbsp; The famous definition in Hebrews, in its best-known form, is close to that:</p>\n<p style=\"padding-left: 30px;\">\"Now faith is the substance of things hoped for, the evidence of things not seen.\" - Hebrews 11:1 (King James Version),&nbsp;often attributed to St. Paul</p>\n<p>This is the way the term \"faith\" is used by religious people when they argue against the primacy of reason, as demonstrated in <a href=\"/lw/b0/antirationality_quotes/\">these quotes</a>, which is the context I am concerned with. &nbsp;(It's also the meaning used&nbsp;by atheists arguing against religious faith, eg. Sam Harris in <a href=\"http://www.amazon.com/End-Faith-Religion-Terror-Future/dp/0393035158\">The End of Faith</a>.) &nbsp;But the New International Version, which is less pretty, but translated more carefully by better scholars from more and older texts, says:</p>\n<p style=\"padding-left: 30px;\">\"Now faith is confidence in what we hope for and assurance about what we do not see.\"</p>\n<p>The <a href=\"http://en.wikipedia.org/wiki/Faith\">Wikipedia</a> and <a href=\"http://plato.stanford.edu/entries/faith/\">Plato</a> entries on <em>faith</em> give information on the use of words translated as \"faith\" in English in different religions and philosophies.&nbsp; Wikipedia cites the <span class=\"citation book\"><em>New American standard exhaustive concordance of the Bible</em> as saying,</span></p>\n<p style=\"padding-left: 30px;\">In English translations of the New Testament, the word faith generally corresponds to the Greek noun \u03c0\u03af\u03c3\u03c4\u03b9\u03c2 (<em>pistis</em>) or the Greek verb \u03c0\u03b9\u03c3\u03c4\u03b5\u03cd\u03c9 (<em>pisteuo</em>), meaning \"to trust, to have confidence, faithfulness, to be reliable, to assure\".<sup id=\"cite_ref-Thomas1981_21-0\" class=\"reference\"><a href=\"http://en.wikipedia.org/wiki/Faith#cite_note-Thomas1981-21\"><span>[</span>22<span>]</span></a></sup></p>\n<h2 id=\"Theory\">Theory</h2>\n<p>Scientific theory is also assurance about things unseen.&nbsp; (If you can observe something directly, you don't need science.)&nbsp; Science builds an abstract mental structure that interprets data and makes predictions from it.&nbsp; It is also an epistemology for belief in things we can't see, like atoms, oxygen, radio waves, vast distances, or circulation of the blood.</p>\n<h2 id=\"The_history_of_faith_and_theory\">The history of faith and theory<br></h2>\n<p>The most popular belief appears to be that faith is ancient, and scientific theory came along later to supersede it.&nbsp; But I'm not aware of evidence for this.<a id=\"more\"></a></p>\n<p>I've read many accounts by Christian missionaries of how they persuaded people living in tribal cultures to convert to Christianity.&nbsp; Faith is not a factor in these debates.&nbsp; Tribal cultures don't need to protect their religions with rationalizations.&nbsp; In these narratives, the tribe members often seem unaware that not believing their religion is a physical possibility; they are sometimes less surprised that the white-skinned stranger descended from the skies, than that he pretends to be unfamiliar with their gods.&nbsp; Tribal people are more reasonable about the matter than people from advanced civilizations; they never defend their religion by making arguments against reason itself.&nbsp; They are pragmatic and opportunistic:&nbsp; Can the missionary cure the sick better than the tribal shaman?&nbsp; Yes?&nbsp; Then his god is stronger!</p>\n<p>There are numerous <a href=\"http://www.biblegateway.com/keyword/?search=faith&amp;version1=31&amp;searchtype=all\">verses in the</a> <a href=\"http://cvhope.20m.com/faithot.htm\">old Testament about faith</a>, and many more passages describing the same sentiment.&nbsp; But \"faith\" in these passages seems synonymous with \"obedience\", or possibly \"trust\", when it isn't something else entirely that was lost in translation or history (e.g., \"And there shall be faith in thy times: riches of salvation, wisdom and knowledge\" ... what?)</p>\n<p>Nothing described in the Wikipedia or Plato pages on faith definitely antedates Buddhism<a href=\"#hindu\"><sup>1</sup></a>.&nbsp; The concepts of faith, and of scientific theory, both may have developed primarily between the 6th century BC, when mathematics, philosophy, Buddhism, large parts of Hindu philosophy, and Phariseeic (intellectual) Judaism were being invented; and the time when Jesus spoke and Paul wrote about faith as a kind of power and a means of justification (a technical Christian term).</p>\n<p>By the time Jesus spoke of faith, it had one main feature distinguishing it from theory:&nbsp; The truth of the belief was proportional to the strength of the belief.&nbsp; Luke 17:6 (NIV): \"If you have faith as small as a mustard seed, you can say to this mulberry tree, 'Be uprooted and planted in the sea,' and it will obey you.\"<a href=\"#mass-energy\"><sup>2</sup></a>&nbsp; Paul's chapter on faith (<a href=\"http://www.biblegateway.com/passage/?search=Hebrews+11&amp;version=NIV\">Hebrews 11</a>) describes faith as having causal power.</p>\n<p>How many people living during that time could have distinguished between faith and theory?</p>\n<h2 id=\"Faith_as_reaction_to_theory\">Faith as reaction to theory</h2>\n<p>One theory of mine is that faith developed as a reaction to theory.&nbsp; How to keep a religion alive, when these pesky philosophers are corrupting the youth with reason?&nbsp; Declare that reason is not the final arbiter!&nbsp; Faith is thus a sort of early post-modernism.</p>\n<p>You could alternatively see it as the post-philosophical epistemology for people who value winning over being right; it lets them retain adaptive beliefs that their society had evolved, even after philosophers found disproofs of those beliefs.</p>\n<h2 id=\"Faith_as_popularized_theory\">Faith as popularized theory<br></h2>\n<p>\"Christianity is Platonism for 'the people'\".&nbsp; - Nietzsche, preface to <em>Beyond Good and Evil</em></p>\n<p>Another theory is that faith is a faulty theory about theory.&nbsp; Ancient people could have observed proto-scientists, and their ability to make seemingly-impossible predictions - such as the time of eclipses.&nbsp; The first prediction of a solar eclipse was <a href=\"http://www.thaindian.com/newsportal/sports/first-total-solar-eclipse-to-be-predicted-occurred-in-585-bc_10055593.html\">perhaps in 585 BC</a>.&nbsp; What did non-astronomers believe the astronomers were doing?&nbsp; Did they think that the power of the astronomer's belief caused the eclipse?&nbsp; How many Pythagoreans understood why the sum of the squares of the sides of a right triangle equalled the square of its hypotenuse, or why the square root of 2 could not be rational?&nbsp; Did they take these claims <em>on faith</em>, like most high-school geometry students do today?&nbsp; If you imagine that understanding has magical power, it would be easy to read what Paul wrote about faith, and substitute the word \"understanding\".&nbsp; Is that what some Gnostic Christians were doing?</p>\n<h2 id=\"Faith_as_proto_theory\">Faith as proto-theory<br></h2>\n<p>Another theory is that theory is faith++.&nbsp; The mental commitment of faith is very similar to the mental commitment of theory, if not the same.&nbsp; People practiced in having faith in things unseen, would be more likely to be able to have theories about things unseen.&nbsp; They would just have better heuristics for what to have faith in.&nbsp; This suggests that faith is a necessary historical precondition for theory.</p>\n<h2 id=\"Faith___theory\">Faith \u2248 theory</h2>\n<p>Perhaps my favorite theory - and these theories are not all mutually exclusive - is that many pre-modern thinkers did not distinguish between faith and theory.&nbsp; It's not clear that Gnostic Christians, Hermetic philosophers, or alchemists were able to make that distinction.&nbsp; Many Gnostic Christians may have thought they were practicing a kind of natural philosophy.&nbsp; Many Renaissance alchemists may have regarded their studies as a spiritual practice.&nbsp; Therefore, in modern debates between faith and science, when people cite pre-modern texts and try to claim their authors for their side based on their usage of terms like \"faith\" or \"reason\", it may be those authors weren't even aware there were different sides to be on.</p>\n<p>&nbsp;</p>\n<p>1. <a name=\"hindu\"></a>The Hindu trans-rational epistemology referred to by Wikipedia may be an older variant of faith.&nbsp; Its age, and its relation to what I'm calling faith, are unclear to me.</p>\n<p>2. <a name=\"mass-energy\"></a>Faith performs work, and is therefore a type of energy.&nbsp; A mustard seed <a href=\"http://askville.amazon.com/mustard-seed-weigh/AnswerViewer.do?requestId=5460571\">weighs about .002g</a>, which is the mass equivalent of the energy of 43 tonnes of TNT.&nbsp; So Jesus was being conservative.</p>", "sections": [{"title": "Faith", "anchor": "Faith", "level": 1}, {"title": "Theory", "anchor": "Theory", "level": 1}, {"title": "The history of faith and theory", "anchor": "The_history_of_faith_and_theory", "level": 1}, {"title": "Faith as reaction to theory", "anchor": "Faith_as_reaction_to_theory", "level": 1}, {"title": "Faith as popularized theory", "anchor": "Faith_as_popularized_theory", "level": 1}, {"title": "Faith as proto-theory", "anchor": "Faith_as_proto_theory", "level": 1}, {"title": "Faith \u2248 theory", "anchor": "Faith___theory", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "40 comments"}], "headingsCount": 9}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 40, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["kWRFfWfhrS6m4Fibm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T04:16:55.104Z", "modifiedAt": null, "url": null, "title": "AI that doesn't want to get out", "slug": "ai-that-doesn-t-want-to-get-out", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:07.064Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Tiiba", "createdAt": "2009-02-27T06:55:57.544Z", "isAdmin": false, "displayName": "Tiiba"}, "userId": "FngsS7fwH2r3ikxTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FtRLBoxfGQpQ6DH9L/ai-that-doesn-t-want-to-get-out", "pageUrlRelative": "/posts/FtRLBoxfGQpQ6DH9L/ai-that-doesn-t-want-to-get-out", "linkUrl": "https://www.lesswrong.com/posts/FtRLBoxfGQpQ6DH9L/ai-that-doesn-t-want-to-get-out", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20AI%20that%20doesn't%20want%20to%20get%20out&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAI%20that%20doesn't%20want%20to%20get%20out%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFtRLBoxfGQpQ6DH9L%2Fai-that-doesn-t-want-to-get-out%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=AI%20that%20doesn't%20want%20to%20get%20out%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFtRLBoxfGQpQ6DH9L%2Fai-that-doesn-t-want-to-get-out", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFtRLBoxfGQpQ6DH9L%2Fai-that-doesn-t-want-to-get-out", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 523, "htmlBody": "<p>Here's another attempt to make an AI safe by putting it in a box and telling it very sternly not to leave. I don't think this safeguard is invincible, but it might help in combination with others.</p>\r\n<p>The AI is, first of all, a question-answering machine. Before it is turned on, the building housing it is filled with energy resources, data disks with every fact humans have learned in the last five millennia, and some material for computronium. The goals are, then:</p>\r\n<p>1) Invent a cure for AIDS.</p>\r\n<p>2) This cure must destroy HIV, and only HIV. It cannot affect any human cell, or anything else, in any way not absolutely required.</p>\r\n<p>3) You have a week to finish. You can't do it, sucks.</p>\r\n<p>4) You have a volume of ten thousand cubic meters within which you can do anything you want (except for some things, which I won't bother with here, to stop it from creating and torturing artificial people). Nothing outside this volume is yours. You cannot go there to get matter, energy or knowledge. You cannot let anything get out, except waste heat. Heat must be released in a uniform manner (to keep it from trying to communicate or causing an explosion). You cannot let anything in if you can help it. Overall, your goal is to leave the world the way it would be if you spent this week in another universe.</p>\r\n<p>5) &nbsp;Your answer will take the form of a book, written on paper. It can't have any computer code in it. Or if we're feeling lucky, a data disk with text, audio, video, or databases, but nothing Turing-complete.</p>\r\n<p>6) When time is up, you must shut down. Your energy use must be zero.</p>\r\n<p>7) The chamber where the answer book rests must contain enough space to comfortably enter and retrieve the book, breathable air, the book, a button to initiate another problem-solving session, and absolutely nothing else. No nanites, no killer vacuum cleaners, no bombs, and definitely no successor AI.</p>\r\n<p>8) Stop! Please! I created you!</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;</p>\r\n<p>&nbsp;Appendix:</p>\r\n<p>&nbsp;9) What I forgot is that another form of energy the AI can't possibly keep in is vibration, and perhaps also the shifts in gravity from objects moving around on the inside. Most computers I know do a lot of useful work without being flung around the house, but you can't be too careful.</p>\r\n<p>I could just add three new rules, but I think it would be better to state the general goal.</p>\r\n<p>9) While energy is allowed to escape, it must have the least effect on people that it is possible to have. Thus, if people would ignore one form of energy and be killed, harmed, alarmed, informed, or turned into lotus eaters by another, choose the one that would be ignored.</p>\r\n<p>10) Energy coming in from the outside has to be kept out. If it can't, its information content is to be minimized. (Not totally sure if this is necessary, but it seems necessary now.)</p>\r\n<p>11) The overall goal is to ensure that the information flow between the microcosms - especially from the AI to us - is kept low. Anything it wants to say or do has to go through the Answer.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FtRLBoxfGQpQ6DH9L", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": -6, "extendedScore": null, "score": 6.948669492911248e-07, "legacy": true, "legacyId": "6445", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T05:57:36.035Z", "modifiedAt": null, "url": null, "title": "Inverse Speed", "slug": "inverse-speed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:35.703Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "komponisto", "createdAt": "2009-03-01T21:10:23.585Z", "isAdmin": false, "displayName": "komponisto"}, "userId": "h48TMtPzfimsEobTm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qNiH3RRTiXXyvMJRg/inverse-speed", "pageUrlRelative": "/posts/qNiH3RRTiXXyvMJRg/inverse-speed", "linkUrl": "https://www.lesswrong.com/posts/qNiH3RRTiXXyvMJRg/inverse-speed", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Inverse%20Speed&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInverse%20Speed%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNiH3RRTiXXyvMJRg%2Finverse-speed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Inverse%20Speed%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNiH3RRTiXXyvMJRg%2Finverse-speed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqNiH3RRTiXXyvMJRg%2Finverse-speed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1063, "htmlBody": "<blockquote>\n<p>One must always invert.</p>\n</blockquote>\n<p>- <a href=\"http://en.wikipedia.org/wiki/Carl_Gustav_Jacob_Jacobi\">Carl Gustav Jacobi</a></p>\n<p>I'm grateful to <a href=\"/lw/5f/bayesians_vs_barbarians/3qzr\">orthonormal</a>&nbsp;for mentioning the following math problem, because it allowed me to have a significant confusion-dissolving insight (actually going on two, but I'll only discuss one in this post), as well as&nbsp;providing an example of how <a href=\"/lw/4pe/lw_is_to_rationality_as_aixi_is_to_intelligence/3n80\">bad I am</a>&nbsp;<a href=\"/lw/4vk/what_is_wrong_with_mathematics_education/3pzu\">at math</a>:</p>\n<blockquote>\n<p>\"[I]f you want to average 40 mph on a trip, and you averaged 20 mph for the first half of the route, how fast do you have to go on the second half of the route?\"&nbsp;</p>\n</blockquote>\n<p>When I read this, my first thought was \"Huh? If you spend an hour going 20 mph and then spend another hour going 60 mph, you've just gone 80 miles in 2 hours -- for an&nbsp;average speed of 40 mph, just as desired. So what do you people mean it's impossible?\"</p>\n<p>As you can see, my confusion resulted from interpreting \"half of the route\" to refer to the total <em>time</em>&nbsp;of the journey, rather than the total <em>distance</em>.</p>\n<p>This misinterpretation reveals something fundamental about how I (<a href=\"/lw/dr/generalizing_from_one_example/\">I know better by now than to say \"we\"</a>) think about <em>speed</em>.</p>\n<p>In my mind, speed is a <em>mapping</em>&nbsp;from <em>times</em>&nbsp;to <em>distances</em>. The way to compare different speeds is by holding time constant and looking at the different distances&nbsp;traversed in that fixed time. (I know I'm not a total mutant in this regard, because even other people tend to visually represent speeds as little arrows of&nbsp;varying length, with greater lengths corresponding to higher speeds.)</p>\n<p>In particular, I <em>don't</em>&nbsp;think of it as a mapping from <em>distances</em>&nbsp;to <em>times</em>. I don't find it natural to compare speeds by imagining a fixed distance corresponding to&nbsp;different travel times. Which explains why I find this problem so difficult, and other people's explanations so unilluminating: they tend to begin with something along&nbsp;the lines of \"let d be the total distance traveled\", upon which my brain experiences an error message that is perhaps best verbalized as something like \"wait, what?&nbsp;Who said anything about a fixed distance? If speeds are varying, distances have to be varying, too!\"&nbsp;</p>\n<p>If speed is a mapping from times to distances, then the way that you add speeds together and multiply them by numbers (the operations involved in averaging) is by&nbsp;performing the same operations on corresponding distances. (This is an instance of the general definition in mathematics of addition of functions: (f+g)(x) = f(x)+g(x), and similarly for multiplication by numbers: (af)(x) = a*f(x).) In concrete terms, what this means is that in order to add 30 mph and 20 mph together, all you&nbsp;have to do is add 30 and 20 and then stick \"mph\" on the result. Likewise with averages: provided the times involved are the same, if your speeds are 20 mph and 60 mph,&nbsp;your average speed is 40 mph.&nbsp;</p>\n<p>You cannot do these operations nearly so easily, however, if distance is being held fixed and time varying. Why not? Because if our mapping is from times to distances,&nbsp;then finding the time that corresponds to a given distance requires us to <em>invert</em>&nbsp;that mapping, and there's no easy way to invert the sum of two mappings (we can't&nbsp;for example just add the inverses of the mappings themselves). As a result, I find it difficult to understand the notion of \"speed\" while thinking of time as a&nbsp;dependent variable.&nbsp;</p>\n<p>And that, at least for me, is why this problem is confusing: the statement doesn't contain a prominent warning saying \"Attention! Whereas you normally think of speed&nbsp;as the being the (longness-of-)distance traveled in a given time, here you need to think of it as the (shortness-of-)time required to travel a given distance. In other&nbsp;words, the question is actually about <em>inverse speed</em>, even though it talks about 'speed'.\"</p>\n<p>Only when I have \"inverse speed\" in my vocabulary, can I then solve the problem -- which, properly formulated, would read: \"If you want your inverse speed for the&nbsp;whole trip to be 1/40 hpm, and your inverse speed for the first half is 1/20 hpm, how 'slow' (i.e. inversely-fast) do you have to go on the second half?\"&nbsp;</p>\n<p><strong>Solution</strong>: <em>Now</em>&nbsp;it makes sense to begin with \"let d be the total distance\"! For inverse speed, unlike speed, accepts distances as inputs (and produces times as&nbsp;outputs). So, instead of distance = speed*time -- or, as I would rather have it, distance = speed(time) -- we have the formula time = speed<sup>-1</sup>(distance). Just as the&nbsp;original formula converts questions about speed to questions about distance, this new formula conveniently converts our question about inverse speeds to a question&nbsp;about times: we'll find the time required for the whole journey, the time required for the first half, subtract to find the time required for the second half, then&nbsp;finally convert this back to an inverse speed.</p>\n<p>So if d is the total distance, the total time required for the journey is (1/40)*d = d/40. The time required for the first half of the journey is (1/20)*(d/2) = d/40.&nbsp;So the time required for the second half is d/40 - d/40 = 0. Hence the inverse speed must be 0.</p>\n<p>So we're being asked to travel a nonzero distance in zero time -- which happens to be an impossibility.</p>\n<p>Problem solved.&nbsp;</p>\n<p>Now, here's the interesting thing: I'll bet there are people reading this who (despite my best efforts) found the above explanation difficult to follow -- <em>and yet had&nbsp;no trouble solving the problem themselves</em>. And I'll bet there are probably also people who consider my explanation to be an example of belaboring the obvious.</p>\n<p>I have a term for people in these categories: I call them \"good at math\". What unites them is the ability to produce correct solutions to problems like this without&nbsp;having to expend significant effort figuring out the sort of stuff I explained above.</p>\n<p>If for any reason anyone is ever tempted to describe <em>me</em>&nbsp;as \"good at math\", I will invite them to reflect on the fact that an&nbsp;<em>explicit understanding</em>&nbsp;of the concept of&nbsp;\"inverse speed\" as described above (i.e. as a function that sends distances to times) was a <em>necessary prerequisite</em>&nbsp;for my being able to solve this problem, and then&nbsp;to consider that problems of this sort are customarily taught in middle- or high school, by middle- and high school teachers.</p>\n<p>No indeed, I was not sorted into the tribe of \"good at math\".</p>\n<p>I should find some sort of prize to award to anyone who can explain how to solve \"mixing\" problems in a manner I find comprehensible. (You know the type: how much of&nbsp;x% concentration do you add to your y% concentration to get z% concentration? <em>et similia</em>.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qNiH3RRTiXXyvMJRg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 22, "extendedScore": null, "score": 6.94894451802951e-07, "legacy": true, "legacyId": "6446", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["baTWMegR42PAsH9qJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T06:13:20.780Z", "modifiedAt": null, "url": null, "title": "Put Yourself in Manual Mode (aka Shut Up and Multiply)", "slug": "put-yourself-in-manual-mode-aka-shut-up-and-multiply", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:01.753Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TXH5am367xofYJadR/put-yourself-in-manual-mode-aka-shut-up-and-multiply", "pageUrlRelative": "/posts/TXH5am367xofYJadR/put-yourself-in-manual-mode-aka-shut-up-and-multiply", "linkUrl": "https://www.lesswrong.com/posts/TXH5am367xofYJadR/put-yourself-in-manual-mode-aka-shut-up-and-multiply", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Put%20Yourself%20in%20Manual%20Mode%20(aka%20Shut%20Up%20and%20Multiply)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APut%20Yourself%20in%20Manual%20Mode%20(aka%20Shut%20Up%20and%20Multiply)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTXH5am367xofYJadR%2Fput-yourself-in-manual-mode-aka-shut-up-and-multiply%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Put%20Yourself%20in%20Manual%20Mode%20(aka%20Shut%20Up%20and%20Multiply)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTXH5am367xofYJadR%2Fput-yourself-in-manual-mode-aka-shut-up-and-multiply", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTXH5am367xofYJadR%2Fput-yourself-in-manual-mode-aka-shut-up-and-multiply", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 40, "htmlBody": "<p>Joshua Greene manages to squeeze his ideas about 'point and shoot morality vs. manual mode morality' into just 10 minutes. For those unfamiliar, his work is a neuroscientific approach to recommending that we <a href=\"/lw/n3/circular_altruism/\">shut up and multiply</a>.</p>\n<p><a href=\"http://www.youtube.com/watch?v=sChdbsbTNxI&amp;feature=player_embedded\">Greene's 10-minute video lecture</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb187": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TXH5am367xofYJadR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 11, "extendedScore": null, "score": 6.948990688661722e-07, "legacy": true, "legacyId": "6447", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4ZzefKQwAtMo5yp99"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T10:27:58.401Z", "modifiedAt": null, "url": null, "title": "How much friendliness is enough?", "slug": "how-much-friendliness-is-enough", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:24.881Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/P2k37CZmnBR2DjtGB/how-much-friendliness-is-enough", "pageUrlRelative": "/posts/P2k37CZmnBR2DjtGB/how-much-friendliness-is-enough", "linkUrl": "https://www.lesswrong.com/posts/P2k37CZmnBR2DjtGB/how-much-friendliness-is-enough", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20much%20friendliness%20is%20enough%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20much%20friendliness%20is%20enough%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP2k37CZmnBR2DjtGB%2Fhow-much-friendliness-is-enough%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20much%20friendliness%20is%20enough%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP2k37CZmnBR2DjtGB%2Fhow-much-friendliness-is-enough", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FP2k37CZmnBR2DjtGB%2Fhow-much-friendliness-is-enough", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 191, "htmlBody": "<p>According to Eliezer, making AI safe requires solving two problems:</p>\n<p>1) Formalize a utility function whose fulfillment would constitute \"good\" to us. CEV is intended as a step toward that.</p>\n<p>2) Invent a way to code an AI so that it's mathematically guaranteed not to change its goals after many cycles of self-improvement, negotiations etc. TDT is intended as a step toward that.</p>\n<p>It is obvious to me that (2) must be solved, but I'm not sure about (1). The problem in (1) is that we're asked to formalize a whole lot of things that don't look like they should be necessary. If the AI is tasked with building a faster and more efficient airplane, does it really need to understand that <a href=\"/lw/xr/in_praise_of_boredom/\">humans don't like to be bored</a>?</p>\n<p>To put the question sharply, which of the following looks easier to formalize:</p>\n<p>a) Please output a proof of the Riemann hypothesis, and please don't get out of your box along the way.</p>\n<p>b) Please do whatever the CEV of humanity wants.</p>\n<p>Note that I'm not asking if (a) is easy in absolute terms, only if it's easier than (b). If you disagree that (a) looks easier than (b), why?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "P2k37CZmnBR2DjtGB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 10, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "6449", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 78, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WMDy4GxbyYkNrbmrs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T19:54:33.210Z", "modifiedAt": null, "url": null, "title": "Rational Reading: Thoughts On Prioritizing Books", "slug": "rational-reading-thoughts-on-prioritizing-books", "viewCount": null, "lastCommentedAt": "2019-09-26T15:03:42.335Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "patrissimo", "createdAt": "2009-03-01T21:01:34.487Z", "isAdmin": false, "displayName": "patrissimo"}, "userId": "jimxrRCsNY7PfcM6e", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Kmch6T2YscMyLFJD9/rational-reading-thoughts-on-prioritizing-books", "pageUrlRelative": "/posts/Kmch6T2YscMyLFJD9/rational-reading-thoughts-on-prioritizing-books", "linkUrl": "https://www.lesswrong.com/posts/Kmch6T2YscMyLFJD9/rational-reading-thoughts-on-prioritizing-books", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20Reading%3A%20Thoughts%20On%20Prioritizing%20Books&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20Reading%3A%20Thoughts%20On%20Prioritizing%20Books%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKmch6T2YscMyLFJD9%2Frational-reading-thoughts-on-prioritizing-books%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20Reading%3A%20Thoughts%20On%20Prioritizing%20Books%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKmch6T2YscMyLFJD9%2Frational-reading-thoughts-on-prioritizing-books", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKmch6T2YscMyLFJD9%2Frational-reading-thoughts-on-prioritizing-books", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1405, "htmlBody": "<p>A large element of instrumental rationality consists of filtering, prioritizing, and focusing. &nbsp;It's true for tasks, for emails, for blogs, and for the multitude of other inputs that many of us are drowning in these days[1]. &nbsp;Doing everything, reading everything, commenting on everything is simply not an option - it would take infinite time. &nbsp;We could simply limit time and do what happens to catch our attention in that limited time, but that's clearly not optimal. &nbsp;Spending some time prioritizing rather than executing will always improve results if items can be prioritized and vary widely in benefit. &nbsp;So maximizing the results we get from our finite time requires, for a variety of domains:</p>\n<ol>\n<li>Filtering: a quick first-pass to get input down to a manageable size for the higher-cost effort of prioritizing.</li>\n<li>Prioritizing: briefly evaluating the impact each item will have towards your goals.</li>\n<li>Focusing: on the highest-priority items.</li>\n</ol>\n<p>I have some thoughts, and am looking for more advice on how to do this for non-fiction reading. &nbsp;I've stopped buying books that catch my attention, because I have an inpile of about 3-4 shelves of unread books that have been unread for years. &nbsp;Instead, I put them on my Amazon Wishlists, which as a result have swelled to a total of 254 books - obviously un-manageable, and growing much faster than I read.</p>\n<p>One obvious question to ask when optimizing is: what is the goal of reading? &nbsp;Let me suggest a few possibilities:</p>\n<ul>\n<li>Improve performance at a current job/role. &nbsp;For example, as Executive Director of a nonprofit, I could read books on fundraising or management.</li>\n<li>Relatedly, work towards a current goal. &nbsp;Here is where it helps to have identified your goals, perhaps&nbsp;<a href=\"http://patrissimo.livejournal.com/1423868.html\">in an Annual Review</a>. &nbsp;As a parent, for example, there are an infinitude of parenting books that I could read, but I chose for this year to work specifically on <a href=\"http://www.amazon.com/exec/obidos/ASIN/0060977094/patriscontactjug\">positive psychology parenting</a>, as it seemed like a potentially high-impact skill to learn. &nbsp;This massively filters the set of possible parenting books. &nbsp;Essentially, goal-setting (\"learn positive psychology parenting habits\") was a conscious prioritization step based on considering what new parenting skills would best advance my goals (in this case, to benefit my kids while making parenting more pleasant along the way).</li>\n<li>Improve core skills or attributes relevant to many areas of life - productivity, happiness, social skills, diet, etc.</li>\n<li>Expand your worldview (improve your map). &nbsp;Myopically focusing only on immediate needs would eliminate some of the greatest benefit I feel I've gotten from non-fiction in my life, which is a richer and more accurate understanding of the world.</li>\n<li>Be able to converse intelligently on currently popular books. &nbsp;(Much as one might watch the news in order to facilitate social bonding by being able to discuss current events). &nbsp;Note that I don't actually recommend this as a goal - I think you can find other things to bond over, plus you will sometimes read currently popular books because they serve other goals - but it may be important for some people.</li>\n</ul>\n<div><a id=\"more\"></a>So it seems like the basic process should be to determine the goals for your non-fiction reading, then determine what books will best advance those goals, using sources like friends, Amazon reviews, apparent relevance of the book to the goal, etc. &nbsp;Here is where it seems like Web 2.0 could really help through some sort of recommendation engine, where people rate the books that most impacted their understanding of the world, or most helped them learn how to achieve a goal, and the engine combines these recommendations, perhaps using some trust system. &nbsp;LW posts like <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">The Best Textbooks on Every Subject</a>&nbsp;are a step in this direction, but suffer from the general flaw of being a blog post rather than a structured data store. &nbsp;If someone knows an effective system like this, please comment - perhaps we can coordinate on a single one.</div>\n<div>Some additional thoughts &amp; issues:</div>\n<div><ol>\n<li>One needs to figure out how to divide up reading time between these various goals, but I think any reasonable approximation based on relative goal priority &amp; enjoyment of reading various book types will work pretty well.</li>\n<li>Anything that maximizes the speed of information extraction from the book is obviously a win - whether learning to speed-read / skim or finding summaries[2] or \"Cliffs Notes\" or Anki cards. &nbsp;The existence of a sub-skill of optimal execution that strictly improves performance at the higher-level goal (\"Get max out of each book in min time\" clearly supports \"Get max out of your reading in min time\") is very common in instrumental rationality.</li>\n<li>You should&nbsp;<a href=\"http://www.washingtontimes.com/news/2009/jul/24/edge-closing-the-book-on-a-bad-read/\">stop reading a book</a>&nbsp;if it isn't achieving your goal (or isn't fun, and thus has a higher than anticipated reading cost).</li>\n<li>There are some obvious ways that a rationalist book group could implement this collaboratively, choosing shared goals (ie core life skills), splitting the work of summarizing books, perhaps presenting or discussing summaries in live sessions, or even better discussing personal experience implementing the lessons. &nbsp;Here social pressure would help ensure that the reading/summarizing gets done, plus interaction may help learning for some.</li>\n</ol></div>\n<p>(2) seems like the biggest win - surely any program of rational reading has to start with learning to read efficiently. &nbsp;Relatedly,&nbsp;<a href=\"/user/Nick_Tarleton/\">Nick</a>&nbsp;points out that if there are any books (or articles/blogs) on how to pick books well, that would be an obvious start too. &nbsp;I haven't done either of these, which means that my reading has been extremely inefficient and my process has been deeply irrational, which is what often happens when one doesn't consciously optimize. &nbsp;Please comment with recommendations in these areas.</p>\n<p>I would most like to hear from anyone who has used a system for consciously choosing which books to read, and am also interested in any thoughts y'all have on the topic. &nbsp;Nonfiction reading used to be fun and mind-opening, but now it is an area of stress in my life. &nbsp;I never know what I should be reading, when I read something I worry it isn't the most useful thing, and when a great book gets recommended to me, I have no idea if I'll read it, which is sad. &nbsp;I'd like to know that books are going into some trusted system and that I'm then reading the right ones. &nbsp;I can figure out my own goals, and how relevant a book seems to be to them, but the quality evaluation - what are truly the best of the hundreds of great books that apply to my goals - is an important missing step. &nbsp;And starting with reading book summaries seems like it would tremendously improve reading effectiveness.</p>\n<p>Finally, one of the neat things about Rational Reading is that it has so much in common with optimizing anything. &nbsp;Filter, prioritize, balance, optimize execution, execute, and refine - these are general instrumental rationality skills. &nbsp;Those not yet ready to apply these skills to other areas of their life may want to consider beginning with reading as their practice, honing skills there, and then applying them to more intimidating areas (task management, email, goals, etc.) &nbsp;Relatedly, in my case, making sure that my reading supports my personal goals is a way to ensure that I am making some progress on those goals even if I fail to work on them in other ways.</p>\n<p>[1] I can imagine a reader who is not drowning in inputs feeling superior because of it, but I must sadly inform you that this is not rational either. &nbsp;If you read a book every two weeks, and your social network suggests a book that sounds fun every two weeks, it is true that your reading is \"balanced\" and you are likely to feel unstressed about it, which is great. &nbsp;But it also means that you can't be reading anything like the best possible books, because you are drawing from a tiny pool of suggestions from a few people, rather than the vast ocean of material that exists. &nbsp;Yes your social network is a filter, but it's not a great one, so if that's your only filter, I highly doubt you're reading anything like the best &amp; most useful books you could be reading.</p>\n<p>[2] For example,&nbsp;<a href=\"/user/Cosmos\">Cosmos</a>&nbsp;has written useful summaries of a number of books which he sent to the NY rationalists, but has not yet gone the last mile &amp; made them available online. &nbsp;I am nagging him to fix this, if you know him then you should too :).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "fF9GEdWXKJ3z73TmB": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Kmch6T2YscMyLFJD9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 40, "extendedScore": null, "score": 7.2e-05, "legacy": true, "legacyId": "6450", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 44, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xg3hXCYQPJkwHyik2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T22:31:37.160Z", "modifiedAt": null, "url": null, "title": "How Safe are Uploads?", "slug": "how-safe-are-uploads", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.685Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/S589HGGemkMAihwuT/how-safe-are-uploads", "pageUrlRelative": "/posts/S589HGGemkMAihwuT/how-safe-are-uploads", "linkUrl": "https://www.lesswrong.com/posts/S589HGGemkMAihwuT/how-safe-are-uploads", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Safe%20are%20Uploads%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Safe%20are%20Uploads%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS589HGGemkMAihwuT%2Fhow-safe-are-uploads%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Safe%20are%20Uploads%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS589HGGemkMAihwuT%2Fhow-safe-are-uploads", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FS589HGGemkMAihwuT%2Fhow-safe-are-uploads", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 347, "htmlBody": "<p>I have encountered the argument that safe brain uploads are as hard as friendly AI. In particular, this is offered as justification for focusing on the development of FAI rather than spending energy trying to make sure WBE (or an alternative based on stronger understanding of the brain) comes first. I don't yet understand/believe these arguments.</p>\n<p>I have not seen a careful discussion of these issues anywhere, although I suspect plenty have occurred. My question is: why would I support the SIAI instead of directing my money towards the technology needed to better understand and emulate the human brain?</p>\n<p>&nbsp;</p>\n<p>Suppose human society has some hope of designing FAI. Then I strongly suspect that a community of uploads have at least as good a chance of designing FAI. If I can find humans who are properly motivated, then I can produce uploads who are also motivated to work on the design of FAI. Moreover, if emulated brains eventually outproduce us signfiicantly, then they have a higher chance of designing an FAI before something else kills them. The main remaining question is how safe an upload would be, and how well an upload-initiated singularity is likely to proceed.</p>\n<p>There are three factors suggesting the safety of an upload-initiated singularity. First, uploads always run as fast as the available computing substrate. It is less likely for an upload to accidentally stumble upon (rather than design) AI, because computers never get subjectively faster. Second, there is hope of controlling the nature of uploads; if rational, intelligent uploads can be responsible for most upload output, then we should expect the probability of a friendly singularity to be correspondingly higher.</p>\n<p>The main factor contributing to the risk of an upload-initiated singularity is that uploads already have access to uploads. It is possible that uploads will self-modify unsafely, and that this may be (even relatively) easier than for existing humans to develop AI. Is this the crux of the argument against uploads? If so, could someone who has thought through the argument please spell it out in much more detail, or point me to such a spelling out?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "S589HGGemkMAihwuT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 6.95169053981369e-07, "legacy": true, "legacyId": "6452", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 55, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-27T23:57:04.131Z", "modifiedAt": null, "url": null, "title": "The Neuroscience of Pleasure", "slug": "the-neuroscience-of-pleasure", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:56.192Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zThWT5Zvifo5qYaca/the-neuroscience-of-pleasure", "pageUrlRelative": "/posts/zThWT5Zvifo5qYaca/the-neuroscience-of-pleasure", "linkUrl": "https://www.lesswrong.com/posts/zThWT5Zvifo5qYaca/the-neuroscience-of-pleasure", "postedAtFormatted": "Sunday, March 27th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Neuroscience%20of%20Pleasure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Neuroscience%20of%20Pleasure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzThWT5Zvifo5qYaca%2Fthe-neuroscience-of-pleasure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Neuroscience%20of%20Pleasure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzThWT5Zvifo5qYaca%2Fthe-neuroscience-of-pleasure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzThWT5Zvifo5qYaca%2Fthe-neuroscience-of-pleasure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 3415, "htmlBody": "<p>The <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">scientific</a> approach to self-help&nbsp;suggests that a better understanding of who we are can help us achieve <a href=\"/lw/4su/the_science_of_happiness/\">happiness</a> and <a href=\"/lw/3w3/how_to_beat_procrastination/\">other goals</a>. Most centrally, it will be helpful to understand our <em>brains</em>, because it is our brains that generate happiness and goals.</p>\n<p>In particular, I'd like to explore the neuroscience of pleasure and desire. Today's post covers the neuroscience of pleasure; the next post will cover the neuroscience of desire. After each post I'll consider some of the implications for self-help. In a later post, I'll consider how this research can inform the pursuit of <a href=\"http://intelligence.org/ourresearch/publications/what-is-friendly-ai.html\">Friendly AI</a>.</p>\n<p>&nbsp;</p>\n<h4>Introducing Affective Neuroscience</h4>\n<p>The last decade has seen the arrival of&nbsp;<a href=\"http://en.wikipedia.org/wiki/Affective_neuroscience\">affective neuroscience</a>: the study of the neural mechanisms behind emotion, including pleasure and desire.<sup>1</sup>&nbsp;Most questions remain unanswered, and experts disagree on many specifics,<sup>2</sup> but there are some things we can state with confidence. We begin with the reward system in the brain.</p>\n<p>The <a href=\"http://en.wikipedia.org/wiki/Reward_system\">reward system</a> consists of three major components (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/wanting-learning-liking.png\">image</a>)<sup>3</sup>:</p>\n<ul>\n<li><em>Liking</em>: The 'hedonic impact' of reward, comprised of (1) neural processes<sup>4</sup> that may or may not be conscious and (2) the conscious experience of pleasure.</li>\n<li><em>Wanting</em>: Motivation for reward, comprised of (1) processes of&nbsp;'incentive salience'&nbsp;that may or may not be conscious and (2) conscious desires.</li>\n<li><em>Learning</em>: Associations, representations, and predictions about future rewards, comprised of (1) <em>explicit</em> predictions and (2) <em>implicit</em> knowledge and associative conditioning (e.g. <a href=\"http://en.wikipedia.org/wiki/Classical_conditioning\">Pavlovian associations</a>).</li>\n</ul>\n<p>Unfortunately, the interaction between these components is extraordinarily complex, and many puzzles remain.<sup>5</sup></p>\n<p>I'll share two examples of our ignorance.&nbsp;First: pleasure electrodes. For decades, it was thought that electrical stimulation of certain structures caused pleasure, because rats and humans would self-administer this stimulation hundreds or thousands of times each hour if allowed to do so.<sup>6</sup> But a careful reading of the transcripts reveals the causation of&nbsp;<em>wanting</em>, not&nbsp;<em>liking</em>. Sometimes, the cause was even an unpleasant&nbsp;<em>nervousness</em>.<sup>7</sup> Though, there are a few exceptions where liking was produced.<sup>8</sup></p>\n<p>Second: dopamine. For decades, experts thought dopamine was 'the pleasure chemical'.<sup>9</sup> But this is probably false.<sup>10</sup> Lack of dopamine does not impair 'liking' reactions.<sup>11</sup> And in humans, perceived pleasure is not reduced by loss of dopamine.<sup>12</sup> Dopamine has a big role in wanting, instead.<sup>13</sup></p>\n<p>Today we focus on 'liking' or <em>pleasure</em>.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Pleasure</h4>\n<p>Thoughts and sensations are not intrinsically pleasurable. Rather, the reward system must paint them with a 'hedonic gloss' to make them 'liked'.<sup>14</sup>&nbsp;Food and sex are reliably pleasurable for obvious Darwinian reasons.<sup>15</sup> These 'fundamental pleasures' use the same brain structures as 'higher-order pleasures' like social pleasures, art, money, and altruism.<sup>16</sup></p>\n<p>The basic structures which produce pleasure are shared by other mammals (for Darwinian reasons), and other mammals exhibit liking processes in the brain.<sup>17</sup> It's not clear how similar their subjective experience of pleasure is to our own, though. Humans do have unique cognitive, representational and 'savoring' capacities,<sup>18</sup> among others.</p>\n<p>Much research concerns 'hedonic hotspots' in the brain. A hedonic hotspot might be a <em>necessary cause</em>&nbsp;of pleasure (pleasure doesn't occur without it; e.g. the <a href=\"http://en.wikipedia.org/wiki/Ventral_pallidum\">ventral pallidum</a>), a <em>sufficient cause</em>&nbsp;of pleasure (if activated, pleasure occurs; e.g. the <a href=\"http://en.wikipedia.org/wiki/Nucleus_accumbens\">nucleus accumbens</a>), or it may <em>code for</em>&nbsp;pleasure (its activation correlates with pleasure, but might be either a cause or effect of pleasure, or both; e.g. the <a href=\"http://en.wikipedia.org/wiki/Orbitofrontal_cortex\">orbitofrontal cortex</a>&nbsp;and ventral pallidum). A substrate may play multiple roles, or it may code without causing, or it may be a sufficient cause without being a necessary cause.<sup>19</sup></p>\n<p>We know thousands of specific things about pleasure and the reward system, but we don't yet understand pleasure on a <a href=\"http://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis\">systems level</a>. We don't know how to integrate these thousands of bits of information into a cohesive theory of how pleasure works.</p>\n<p>Many have tried, of course. Here is Tim Schroeder's attractively simple theory of pleasure:</p>\n<blockquote>\n<p>To be pleased is (at least) to represent a net increase in desire satisfaction relative to expectation; to be displeased is to represent a net decrease in desire satisfaction relative to expectation. Intensity of pleasure or displeasure represents degrees of change in desire satisfaction relative to expectations.<sup>20</sup></p>\n</blockquote>\n<p>But this is <em>too</em>&nbsp;simple. Though pleasure often results from experiencing more satisfaction than expected,&nbsp;there are many other sources of pleasure,<sup>21</sup> and pleasure can occur in animals that lack representational capacities or expectations, for example anecephalic infants&nbsp;and animals with most of their brains removed.<sup>22</sup>&nbsp;</p>\n<p>Among neuroscientists, there are many overlapping theories of pleasure, which are often not mutually exclusive.<sup>23</sup> Rather than survey them all, let me jump to the self-help advice: what can brain science teach us about pleasure and how to get more of it?</p>\n<h4><br /></h4>\n<h4>Self-Help Implications</h4>\n<p>The neuroscience of pleasure is most useful when designing new drugs or performing neurosurgery, but there are a few self-help recommendations we can draw from the field:</p>\n<ol>\n<li>Wanting and liking are different signals, though they sometimes share use of the same neurons, like phone and internet data traveling along the same wire.<sup>24</sup> As a result, we <em>usually</em> like what we want and want what we like, but <em>sometimes</em> we don't want what we like or&nbsp;don't like what we want.<sup>25</sup> Understanding <a href=\"http://commonsenseatheism.com/?p=15072\">why this happens</a> may relieve the confusion that often results when it occurs (not to mention <a href=\"/lw/1lb/are_wireheads_happy/\">philosophical confusion</a>).</li>\n<li>Contrary to some theories,<sup>26</sup> pleasure is not merely the perception of certain bodily sensations (e.g. blood rising, organs warming). Instead, sensations and thoughts are painted with a hedonic gloss that makes them pleasurable. Moreover, the selection of sensations and thoughts that are painted with a hedonic gloss can be <em>changed</em>.<sup>27</sup> This is why we can change (to some degree) what we like and dislike via <a href=\"http://en.wikipedia.org/wiki/Classical_conditioning\">classical</a> and <a href=\"http://en.wikipedia.org/wiki/Operant_conditioning\">operant</a> conditioning, and other methods.</li>\n<li>Anticipation matters. Anticipating future pain is itself painful,<sup>28</sup>&nbsp;and anticipating pleasure is itself pleasant.<sup>29</sup>&nbsp;Spend more time reliving happy memories and anticipating future pleasures, and spend less time anticipating future pains. But beware: trying&nbsp;<em>not</em>&nbsp;to think of the event will only bring it to your mind again. Instead, get 'lost' in a challenging task that matches your level of ability: that is,&nbsp;<a href=\"/lw/3w3/how_to_beat_procrastination/#flow\">get in flow</a>.</li>\n<li>If you experience a continuing&nbsp;<em>lack</em>&nbsp;of pleasure in life (<a href=\"http://en.wikipedia.org/wiki/Anhedonia\">anhedonia</a>), your problem might be neurological, not situational. A doctor may be able to solve the problem with drugs or deep brain stimulation.<sup>30</sup></li>\n</ol>\n<p>This is a short list, but additional self-help recommendations can be gleaned after we build on this knowledge to discuss the neuroscience of <em>desire</em>, which we will cover <a href=\"/lw/4z7/the_neuroscience_of_desire/\">next</a>.</p>\n<p align=\"right\">&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup> LeDoux &amp; Phelps (2000); Berridge (2003a); Davidson et al. (2003); Damasio (2004);&nbsp;Rolls (2005);&nbsp;Feldman &amp; Wager (2006); Kringelbach (2005);&nbsp;Kringelbach &amp; Berridge (2009a, 2009b).</small></p>\n<p><small><sup>2</sup> Kringelbach et al. (2009).</small></p>\n<p><small><sup>3</sup>&nbsp;Berridge &amp; Kringelbach (2008); Berridge et al. (2009); Berridge (1996); Berridge &amp; Robinson (1998); Pecina et al. (2003); Camerer (2006); Kringelbach &amp; Berridge (2010b). Some experts will talk as if there is no such thing as unconscious pleasure (Kringelbach et al. 2009), but this is only a manner of speaking adopted to respect the folk understanding of conscious pleasure, for they acknowledge the same unconscious hedonic processes that other researchers do (Winkielman &amp; Berridge 2004; Winkielman et al. 2005; Schooler &amp; Mauss 2009). Likewise, though ever researcher may not use the liking / wanting / learning scheme, I haven't found any major expert who disagrees with the minimal factual claims presupposed by that scheme. Experts agree that pleasure, motivation, and learning are distinct components of the reward system in the brain.</small></p>\n<p><small><sup>4</sup>&nbsp;The neural processes that apply the 'hedonic gloss' to sensations and cognitions seem to be a particular pattern of excitation of neurons in a hedonic hotspot in the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Ventral_pallidum\">ventral pallidum</a>&nbsp;(Tindell et al. 2005; Aldridge &amp; Berridge 2009), though other brain structures may play a role as well, in particular the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Nucleus_accumbens\">nucleus accumbens</a>&nbsp;(Smith et al. 2001), the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Orbitofrontal_cortex\">orbitofrontal cortex</a>&nbsp;(Kringelbach 2009), and perhaps the perigenual&nbsp;<a href=\"http://en.wikipedia.org/wiki/Anterior_cingulate_cortex#Reward-based_learning_theory\">anterior cingulate cortex</a>&nbsp;(Schroeder 2004, ch. 3). Commonly measured 'surface' pleasure reactions are (1) subjective report in humans, and (2) particular facial expressions in human adults, human infants, chimpanzees, and rats (Smith et al. 2005). See videos&nbsp;<a href=\"http://www.lsa.umich.edu/psych/research&amp;labs/berridge/VideoIndex.htm\">here</a>.</small></p>\n<p><small><sup>5</sup> Baldo &amp; Kelley (2007); Balleine &amp; Kilcross (2006); Balleine et al. (2007); Beaver et al. (2006); Burke et al. (2009), Di Chiara &amp; Bassareo (2007); Evans et al. (2006); Everitt &amp; Robbins (2005); Izard (2007); Kuhn &amp; Koob (2010); Panksepp (2007); Salamone et al. (2007); Schultz (2006); Stoeckel et al. (2008);&nbsp;Van Leijenhorst et al. (2010);&nbsp;Volkow et al. (2006); Voon et al. (2010); Wise (2006);&nbsp;Kringelbach &amp; Berridge (2010a).</small></p>\n<p><small><sup>6</sup>&nbsp;Delgado (1969); Heath (1972); Sem-Jacobsen (1976).</small></p>\n<p><small><sup>7</sup>&nbsp;Berridge (2003b); Pecina et al. (2006); Smith et al. (2009).</small></p>\n<p><small><sup>8</sup>&nbsp;Morgan et al. (2006).</small></p>\n<p><small><sup>9</sup>&nbsp;Hoebel et al. (1999); Shizgal (1999); Wise &amp; Bozarth (1985).</small></p>\n<p><small><sup>10</sup>&nbsp;Smith et al. (2009); Berridge (2007); Robinson &amp; Berridge (2003).</small></p>\n<p><small><sup>11</sup>&nbsp;Berridge &amp; Robinson (1998); Berridge et al. (1989); Robinson et al. (2005); Pecina et al. (1997).</small></p>\n<p><small><sup>12</sup>&nbsp;Sienkiewicz-Jarosz et al. (2005); Brauer et al. (2001); Leyton et al. (2005); Leyton (2009).</small></p>\n<p><small><sup>13</sup>&nbsp;Berridge (2007).</small></p>\n<p><small><sup>14</sup> Frijda (2006, 2009); Aldridge &amp; Berridge (2009); Ryle (1954).</small></p>\n<p><small><sup>15</sup>&nbsp;Cabanac (2009); Kringelbach (2005, 2009); Rolls (2005); Schulkin (2004).</small></p>\n<p><small><sup>16</sup>&nbsp;Kringelbach (2005, 2009); Pecina et al. (2006); Small et al. (2001);&nbsp;Gottfried (2009); Kahneman et al. (2004).</small></p>\n<p><small><sup>17</sup>&nbsp;Steiner et al. (2001); Berridge (2000); Kringelbach (2008, 2009); Smith et al. (2009); Calder et al. (2007).</small></p>\n<p><small><sup>18</sup>&nbsp;Barrett et al. (2007); Frijda (2006); Frijda &amp; Sundarajan (2007); Gilbert &amp; Wilson (2007).</small></p>\n<p><small><sup>19</sup>&nbsp;Berridge &amp; Kringelbach (2008); Smith et al. (2009).</small></p>\n<p><small><sup>20</sup> Schroeder (2004), p. 94.</small></p>\n<p><small><sup>21</sup>&nbsp;Smith et al. (2009); Kringelbach &amp; Berridge (2009b).</small></p>\n<p><small><sup>22</sup>&nbsp;Steiner (1973); Steiner et al. (2001);&nbsp;Goltz (1892); Miller &amp; Sherrington (1915); Grill &amp; Norgren (1978). It must be noted that my summary is a bit unfair to Schroeder: Schroeder is offering a theory only of <em>conscious</em>&nbsp;pleasure, which may indeed require the representational capacities unneeded for unconscious 'liking.' Still, it remains the case that there seem to be many other causes and implementations of pleasure than representations of a positive difference between actual desire satisfaction and expected desire satisfaction. But Schroeder's theory is not, as far as I can tell, decisively <em>falsified</em>&nbsp;by the data.</small></p>\n<p><small><sup>23</sup>&nbsp;See Dickinson &amp; Balleine (2009) for a comparison of theories. Some leading theories are: the somantic marker hypothesis by Damasio (1996), the hedonic interface theory by Dickinson &amp; Balleine (2009), the common currency theory of Cabanac (1992), and the multiple-components theories of Berridge, Kringelbach, and others: see Berridge &amp; Kringelbach (2008); Kringelbach (2008).</small></p>\n<p><small><sup>24</sup>&nbsp;Smith et al. (2009); Tindell et al. (2005); Smith et al. (2007); Berridge et al. (2009).</small></p>\n<p><small><sup>25</sup>&nbsp;Smith et al. (2009);&nbsp;Dickinson &amp; Balleine (2009).</small></p>\n<p><small><sup>26</sup>&nbsp;For example, Damasio (1994), p. 263.</small></p>\n<p><small><sup>27</sup>&nbsp;Burke et al. (2009); Aldridge &amp; Berridge (2009).</small></p>\n<p><small><sup>28</sup> Berns et al. (2006).</small></p>\n<p><small><sup>29</sup> Gard et al. (2006).</small></p>\n<p><small><sup>30</sup> Green et al. (2009).</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Aldridge &amp; Berridge (2009). Neural coding of pleasure: 'rose-tinted glasses' of the ventral pallidum.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 62-73). Oxford University Press.</small></p>\n<p><small>Baldo &amp; Kelley (2007). Discrete neurochemical coding of distinguishable motivational processes: insights from nucleus accumbens control of feeding. <em>Psychopharmacology, 191</em>: 439-459.</small></p>\n<p><small>Balleine &amp; Kilcross (2006). Parallel incentive processing: an integrated view of amygdala function. <em>Trends in Neuroscience, 29</em>: 272-279.</small></p>\n<p><small>Balleine, Delgado, &amp; Hikosaka (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Balleine-The-role-of-the-dorsal-striatum-in-reward-and-decision-making.pdf\">The role of the dorsal striatum in reward and decision-making</a>. <em>The Journal of Neuroscience, 27</em>: 8161-8165.</small></p>\n<p><small>Barrett, Mesquita, Ochsner, &amp; Gross (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Barrett-The-experience-of-emotion.pdf\">The experience of emotion</a>. <em>Annual Review of Psychology, 58</em>: 373-403.</small></p>\n<p><small>Beaver, Lawrence, van Ditzhuijzen, David, Woods, &amp; Calder (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Beaver-Individual-differences-in-reward-drive-predict-neural-responses-to-images-of-food.pdf\">Individual differences in reward drive predict neural responses to images of food</a>. <em>Journal of Neuroscience, 26</em>: 5160-5166.</small></p>\n<p><small>Berns, Chappelow, Cekic, Zink, Pagnoni, &amp; Martin-Shurski (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berns-Neurobiological-substrates-of-dread.pdf\">Neurobiological substrates of dread</a>. <em>Science, 312</em>: 754-758.</small></p>\n<p><small>Berridge (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Food-reward.pdf\">Food reward: Brain substrates of wanting and liking</a>. <em>Neuroscience and Biobehavioral Reviews, 20</em>: 1-25.</small></p>\n<p><small>Berridge (2000). Measuring hedonic impact in animals and infants: Microstructure of affective taste reactivity patterns. <em>Neuroscience and Biobehavioral Reviews, 24</em>: 173-198.</small></p>\n<p><small>Berridge (2003a). Comparing the emotional brain of humans to other animals. In Davidson, Goldsmith, &amp; Scherer (eds.), <em>Handbook of affective sciences</em>. Oxford University Press.</small></p>\n<p><small>Berridge (2003b). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Pleasures-of-the-brain.pdf\">Pleasures of the brain</a>. <em>Brain and Cognition, 52</em>: 106-128.</small></p>\n<p><small>Berridge (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-The-debate-over-dopamines-role-in-reward-the-case-for-incentive-salience.pdf\">The debate over dopamine's role in reward: the case for incentive salience</a>. <em>Psychopharmacology, 191</em>: 391-431.</small></p>\n<p><span style=\"font-size: 11px;\">Berridge (2009).&nbsp;<a href=\"http://www.lsa.umich.edu/psych/research&amp;labs/berridge/publications/Berridge%20'Liking'%20&amp;%20'wanting'%20food%20rewards%20Physiol%20&amp;%20Behav%202009.pdf\">&lsquo;Liking&rsquo; and &lsquo;wanting&rsquo; food rewards: Brain substrates and roles in eating disorders</a>. <em>Physiology &amp; Behavior, 97</em>: 537-550.</span></p>\n<p><small>Berridge &amp; Robinson (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Robinson-What-is-the-role-of-dopamine-in-reward.pdf\">What is the role of dopamine in reward: Hedonic impact, reward learning, or incentive salience?</a> <em>Brain Research Reviews, 28</em>: 309-369.</small></p>\n<p><small>Berridge &amp; Kringelbach (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Affective-neuroscience-of-pleasure-reward-in-humans-and-animals.pdf\">Affective neuroscience of pleasure: Reward in humans and other animals</a>. <em>Psychopharmacology 199</em>, 457-80.</small></p>\n<p><small>Berridge, Venier, &amp; Robinson (1989). Taste reactivity analysis of 6-hydroxydopamine-induced aphagia: Implications for arousal and anhedonia hypotheses of dopamine function. <em>Behavioral Neuroscience, 103</em>: 36-45.</small></p>\n<p><small>Berridge, Robinson, &amp; Aldridge (2009).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Dissecting-components-of-reward-&lsquo;liking&rsquo;-&lsquo;wanting&rsquo;-and-learning.pdf\">Dissecting components of reward: &lsquo;liking&rsquo;, &lsquo;wanting&rsquo;, and learning</a>.&nbsp;<em>Current Opinion in Pharmacology, 9</em>: 65&ndash;67.</small></p>\n<p><small>Brauer, Cramblett, Paxton, &amp; Rose (2001). Haloperidol reduces smoking of both nicotine-containing and denicotinized cigarettes. <em>Psychopharmacology, 159</em>: 31-37.</small></p>\n<p><small>Burke, Franz, Miller, &amp; Schoenbaum (2009). Conditioned reinforcement and the specialized role of corticolimbic circuits in the pursuit of happiness and other more specific rewards.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 50-61). Oxford University Press.</small></p>\n<p><small>Cabanac (1992). Pleasure: the common currency. <em>Journal of Theoretical Biology, 155</em>: 173-200.</small></p>\n<p><small>Cabanac (2009). The dialectics of pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 113-124). Oxford University Press.</small></p>\n<p><small>Calder, Beaver, Davis, van Ditzhuijzen, Keane, &amp; Lawrence (2007). Disgust sensitivity predicts the insula and pallidal response to pictures of disgusting foods. <em>European Journal of Neuroscience, 25</em>: 3422-3428.</small></p>\n<p><small>Camerer (2006).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Camerer-Wanting-liking-and-learning-neuroscience-and-paternalism.pdf\">Wanting, liking, and learning: Neuroscience and paternalism</a>.&nbsp;<em>The University of Chicago Law Review, 73</em>: 87-110.</small></p>\n<p><small>Damasio (1994).&nbsp;<em><a href=\"http://www.amazon.com/Descartes-Error-Emotion-Reason-Human/dp/014303622X/\">Descartes&rsquo; error: Emotion, reason, and the human brain</a></em>. Putnam&rsquo;s.</small></p>\n<p><small>Damasio (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Damasio-The-somatic-marker-hypothesis-and-the-possible-functions-of-the-prefrontal-cortex.pdf\">The somatic marker hypothesis and the possible functions of the prefrontal cortex</a>. <em>Philosophical Transactions of the Royal Society B, 351</em>: 1413-1420.</small></p>\n<p><small>Damasio (2004). Emotions and feelings: a neurobiological perspective. In Manstead, Frijda, &amp; Fischer (eds.), <em>Feelings and emotions: the Amsterdam symposium</em>&nbsp;(pp. 49-57). Cambridge University Press.</small></p>\n<p><small>Davidson, Scherer, &amp; Goldsmith, eds. (2003). <em><a href=\"http://www.amazon.com/Handbook-Affective-Sciences-Richard-Davidson/dp/0195377001/\">Handbook of affective sciences</a></em>. Oxford University Press.</small></p>\n<p><small>Delgado (1969). <em><a href=\"http://www.amazon.com/Physical-control-mind-psychocivilized-torchbooks/dp/0061319147/\">Physical Control of the Mind: Toward a Psychocivilized Society</a></em>. Harper and Row.</small></p>\n<p><small>Di Chiara &amp; Bassareo (2007). Reward system and addiction: what dopamine does and doesn't do. <em>Current Opinion in Pharmacology, 7</em>: 69-76.</small></p>\n<p><small>Dickinson &amp; Balleine (2009). Hedonics: the cognitive-motivational interface.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 74-84). Oxford University Press.</small></p>\n<p><small>Evans, Pavese, Lawrence, Tai, Appel, Doder, Brooks, Lees, &amp; Piccini (2006). Compulsive drug use linked to sensitized ventral striatal dopamine transmission. <em>Annals of Neurology, 59</em>: 852-858.</small></p>\n<p><small>Everitt &amp; Robbins (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Everitt-Robbins-Neural-systems-of-reinforcement-for-drug-addiction.pdf\">Neural systems of reinforcement for drug addiction: from actions to habits to compulsion</a>. <em>Nature Neuroscience, 8</em>: 1481-1489.</small></p>\n<p><small>Feldman &amp; Wager (2006). The structure of emotion: evidence from neuroimaging studies. <em>Current Directions in Psychological Science, 15(2)</em>: 79-83.</small></p>\n<p><small>Frijda (2006). <em><a href=\"http://www.amazon.com/Laws-Emotion-Nico-H-Frijda/dp/0805825983/\">The laws of emotion</a></em>. Psychology Press.</small></p>\n<p><small>Frijda (2009). On the nature and function of pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 99-112). Oxford University Press.</small></p>\n<p><small>Frijda &amp; Sundararajan (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Frijda-Emotion-refinement.pdf\">Emotion refinement: a theory inspired by Chinese poetics</a>. <em>Perspectives on Psychological Science, 2</em>: 227&ndash;241.</small></p>\n<p><small>Gard, Gard, Kring, &amp; John (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Gard-Anticipatory-and-consummatory-components-of-the-experience-of-pleasure-a-scale-development-study.pdf\">Anticipatory and consummatory components of the experience of pleasure: a scale development study</a>. <em>Journal of Research in Personality, 40</em>: 1086-1102.</small></p>\n<p><small>Gilbert &amp; Wilson (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Gilbert-Wilson-Prospection-experiencing-the-future.pdf\">Prospection: experiencing the future</a>. <em>Science 317</em>: 1351&ndash;1354.</small></p>\n<p><small>Goltz (1892). Der hund ohne grosshirn. <em>Pfl&uuml;gers Archiv European Journal of Physiology, 51</em>: 570.</small></p>\n<p><small>Gottfried (2009). Olfaction and its pleasures: human neuroimaging perspectives.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 125-145). Oxford University Press.</small></p>\n<p><small>Green, Pereira, &amp; Aziz (2009). Deep brain stimulation and pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 302-319). Oxford University Press.</small></p>\n<p><small>Grill &amp; Norgren (1978). The taste reactivity test II: Mimetic responses to gustatory stimuli in chronic thalamic and chronic decerebrate rats. <em>Brain Research, 143</em>: 263-279.</small></p>\n<p><small>Heath (1972). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Heath-Pleasure-and-brain-activity-in-man.pdf\">Pleasure and brain activity in man: Deep and surface electroencephalograms during orgasm</a>. <em>Journal of Nervous and Mental Disease, 154</em>: 3-18.</small></p>\n<p><small>Hoebel, Rada, Mark, &amp; Pathos (1999). Neural systems for reinforcement and inhibition of behavior: Relevance to eating, addiction, and depression. In Kahneman, Diener, &amp; Schwarz (eds.), <em>Well-being: the foundations of hedonic psychology</em>&nbsp;(pp. 558-572). Russell Sage Foundation.</small></p>\n<p><small>Izard (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Izard-Basic-emotions-natural-kinds-emotion-schemas-and-a-new-paradigm.pdf\">Basic emotions, natural kinds, emotion schemas, and a new paradigm</a>. <em>Perspectives on Psychological Science, 2</em>: 260-280.</small></p>\n<p><small>Kahneman, Krueger, Schkade, Schwarz, &amp; Stone (2004). A survey method for characterizing daily life experience: the day reconstruction method. <em>Science, 306</em>: 1776&ndash;1780.</small></p>\n<p><small>Kringelbach (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kringelbach-The-human-orbitofrontal-cortex.pdf\">The human orbitofrontal cortex: linking reward to hedonic experience</a>. <em>Nature Reviews Neuroscience, 6</em>: 691-702.</small></p>\n<p><small>Kringelbach (2008). <em><a href=\"http://www.amazon.com/Pleasure-Center-Trust-Animal-Instincts/dp/0195322851/\">The pleasure center: Trust your animal instincts</a></em>. Oxford University Press.</small></p>\n<p><small>Kringelbach (2009). The hedonic brain: a functional neuroanatomy of human pleasure. In Kringelbach &amp; Berridge (eds.), <em>Pleasures of the brain</em> (pp. 202-221). Oxford University Press.</small></p>\n<p><small>Kringelbach &amp; Berridge (2009a). Towards a functional neuroanatomy of pleasure and happiness. <em>Trends in Cognitive Sciences, 13(11)</em>: 479-487.</small></p>\n<p><small>Kringelbach &amp; Berridge, eds. (2009b). <em><a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/\">Pleasures of the Brain</a></em>. Oxford University Press.</small></p>\n<p><small>Kringelbach &amp; Berridge (2010a). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kringelbach-Berridge-The-Functional-Neuroanatomy-of-Pleasure-and-Happiness.pdf\">The functional neuroanatomy of pleasure and happiness</a>. <em>Discovery Medicine, 9</em>: 579-587.</small></p>\n<p><small>Kringelbach &amp; Berridge (2010b). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kringelbach-Berridge-The-Neuroscience-of-Happiness-and-pleasure.pdf\">The neuroscience of happiness and pleasure</a>. <em>Social Research, 77(2)</em>: 659-678.</small></p>\n<p><small>Kringelbach, Berridge, Cabanac, Aldridge, Frijda, Leknes, Dickinson, Shizgal, Gottfried, Komisaruk, Petrovic, Green, Schoenbaum, &amp; Small (2009). Fundamental pleasure questions.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 7-23). Oxford University Press.</small></p>\n<p><small>Kuhn &amp; Koob (2010). <em><a href=\"http://www.amazon.com/Advances-Neuroscience-Addiction-Frontiers/dp/0849373913/\">Advances in the Neuroscience of Addiction</a></em>. CRC Press.</small></p>\n<p><small>LeDoux &amp; Phelps (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Ledoux-Phelps-Emotional-networks-in-the-brain.pdf\">Emotional networks in the brain</a>. In Lewis &amp; Haviland-Jones (eds.), <em>Handbook of emotions</em>&nbsp;(pp. 157-172). Guilford.</small></p>\n<p><small>Leyton, Casey, Delaney, Kolivakis, &amp; Benkelfat (2005). Cocaine craving, euphoria, and self-administration: a preliminary study of the effect of catecholamine precursor depletion. <em>Behavioral Neuroscience, 119</em>: 1619-1627.</small></p>\n<p><small>Leyton (2009). The neurobiology of desire: Dopamine and the regulation of mood and motivational states in humans.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 222-243). Oxford University Press.</small></p>\n<p><small>Miller &amp; Sherrington (1915). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Miller-Some-observations-on-the-bucco-pharyngeal-stage-of-reflex-deglutition-in-the-cat.pdf\">Some observations on the bucco-pharyngeal stage of reflex deglutition in the cat</a>. <em>Quarterly Journal of Experimental Physiology, 9</em>: 147-186.</small></p>\n<p><small>Morgan, di Donato, Iyer, Jenkins, Smith, &amp; Sethi (2006). Self-stimulatory behavior associated with deep brain stimulation in Parkinson's disease. <em>Movement Disorders, 21</em>: 283-285.</small></p>\n<p><small>Panksepp (2007). Neurologizing the psychology of affects: how appraisal-based constructivism and basic emotion theory can coexist. <em>Perspectives on Psychological Science, 2</em>: 281-296.</small></p>\n<p><small>Pecina, Berridge, &amp; Parker (1997). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Pecina-Pimozide-does-not-shift-palatibility.pdf\">Pimozide does not shift palatibility: Separation of anhedonia from sensorimotor suppression by taste reactivity</a>. <em>Pharmacology Biochemistry and Behavior, 58</em>: 801-811.</small></p>\n<p><small>Pecina, Cagniard, Berridge, Aldridge, &amp; Zhuang (2003).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Pecina-Hyperdopaminergic-Mutant-Mice-Have-Higher-Wanting-But-Not-Liking-for-Sweet-Rewards.pdf\">Hyperdopaminergic mutant mice have higher 'wanting' but not 'liking' for sweet rewards</a>. <em>The Journal of Neuroscience, 23</em>:&nbsp;9395-9402.</small></p>\n<p><small>Pecina, Smith, &amp; Berridge (2006). Hedonic hot spots in the brain. <em>Neuroscientist, 12</em>: 500&ndash;511.</small></p>\n<p><small>Robinson &amp; Berridge (2003). Addiction. <em>Annual Review of Psychology, 54</em>: 25-53.</small></p>\n<p><small>Robinson, Sandstrom, Denenberg, &amp; Palmiter (2005). Distinguishing whether dopamine regulates liking, wanting, and/or learning about rewards. <em>Behavioral Neuroscience, 119</em>: 5-15.</small></p>\n<p><small>Rolls (2005). <em><a href=\"http://www.amazon.com/Emotion-Explained-Affective-Science-Edmund/dp/019857004X/\">Emotion explained</a></em>. Oxford University Press.</small></p>\n<p><small>Ryle G (1954). Pleasure. <em>Proceedings of the Aristotelian Society, 28</em>: 135&ndash;146.</small></p>\n<p><small>Salamone, Correa, Farrar, &amp; Mingote (2007). Effort-related functions of nucleus accumbens dopamine and associated forebrain circuits. <em>Psychopharmacology, 191</em>: 461-482.</small></p>\n<p><small>Schooler &amp; Mauss (2009). To be happy and to know it: the experience and meta-awareness of pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 244-254). Oxford University Press.</small></p>\n<p><small>Schroeder (2004). <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three faces of desire</a></em>. Oxford University Press.</small></p>\n<p><small>Schulkin (2004).&nbsp;<em><a href=\"http://www.amazon.com/Allostasis-Homeostasis-Costs-Physiological-Adaptation/dp/0521811414/\">Allostasis, homeostasis, and the costs of physiological adaptation</a></em>. Cambridge University Press.</small></p>\n<p><small>Schultz (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Schultz-Behavioral-theories-and-the-neurophysiology-of-reward.pdf\">Behavioral theories and the neurophysiology of reward</a>. <em>Annual Review of Psychology, 57</em>: 87-115.</small></p>\n<p><small>Sem-Jacobsen (1976). Electrical stimulation and self-stimulation with chronic implanted electrodes: Interpretation and pitfalls of results. In Wauquier &amp; Rolls (eds.), <em>Brain-Stimulation Reward</em>&nbsp;(pp. 505-520). Elsevier.</small></p>\n<p><small>Shizgall (1999). On the neural computation of utility: Implications from the studies of brain stimulation reward.&nbsp;In Kahneman, Diener, &amp; Schwarz (eds.),&nbsp;<em>Well-being: the foundations of hedonic psychology</em>&nbsp;(pp. 500-524). Russell Sage Foundation.</small></p>\n<p><small>Sienkiewicz-Jarosz, Scinska, Kuran, Ryglewicz, Rogowski, Wrobel, Korkosz, Kukwa, Kostowski, &amp; Bienkowski (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sienkiewicz-Jarosz-Taste-responses-in-patients-with-Parkinsons-disease.pdf\">Taste responses in patients with Parkinson's disease</a>. <em>Journal of Neurology, Neurosurgery, &amp; Psychiatry, 76</em>: 40-46.</small></p>\n<p><small>Small, Zatorre, Dagher, Evans, &amp; Jones-Gotman (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Small-Changes-in-brain-activity-related-to-eating-chocolate.pdf\">Changes in brain activity related to eating chocolate: From pleasure to aversion</a>. <em>Brain, 124</em>: 1720&ndash;1733.</small></p>\n<p><small>Smith, Berridge, &amp; Aldridge (2007). Ventral pallidal neurons distinguish 'liking' and 'wanting' elevations caused by opioids versus dopamine in nucleus acumbens. Program No. 310.5, 2007 Neuroscience Meeting Planner. San Diego, CA: Society for Neuroscience.</small></p>\n<p><small>Smith, Mahler, Pecina, &amp; Berridge (2009). Hedonic hotspots: generating sensory pleasure in the brain.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 27-49). Oxford University Press.</small></p>\n<p><small>Steiner (1973). The gustofacial response: Observation on normal and anecephalic newborn infants. <em>Symposium on Oral Sensation and Perception, 4</em>: 254-278.</small></p>\n<p><small>Steiner, Glaser, Hawillo, &amp; Berridge (2001). Comparative expression of hedonic impact: affective reactions to taste by human infants and other primates. <em>Neuroscience and Biobehavioral Reviews, 25</em>: 53-74.</small></p>\n<p><small>Stoeckel, Weller, Cook, Twieg, Knowlton, &amp; Cox (2008). Widespread reward-system activation in obese women in response to pictures of high-calorie foods. <em>Neuroimage, 41(2)</em>: 636-647.</small></p>\n<p><small>Tindell, Berridge, Zhang, Pecina, &amp; Aldridge (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Tindell-Ventral-pallidal-neurons-code-incentive-motivation.pdf\">Ventral pallidal neurons code incentive motivation: Amplification by mesolimbic sensitization and amphetamine</a>. <em>European Journal of Neuroscience, 22</em>: 2617-2634.</small></p>\n<p><small>Van Leijenhorst, Zanolie, Van Meel, Westenberg, Rombouts, &amp; Crone (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Van-Leijenhorst-What-Motivates-the-Adolescent.pdf\">What motivates the adolescent? Brain regions mediating reward sensitivity across adolescence</a>. <em>Cerebral Cortex 20</em>, 61-69.</small></p>\n<p><small>Veldhuizen, Rudenga, &amp; Small (2009). The pleasure of taste, flavor, and food.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 146-168). Oxford University Press.</small></p>\n<p><small>Volkow, Wang, Telang, Fowler, Logan, Childress, Jayne, Ma, &amp; Wong (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Volkow-Cocaine-cues-and-dopamine-in-dorsal-striatum.pdf\">Cocaine cues and dopamine in dorsal striatum: mechanism of craving in cocaine addiction</a>. <em>Journal of Neuroscience, 26</em>: 6583-6588.</small></p>\n<p><small>Voon, Pessiglione, Brezing, Gallea, Fernandez, Dolan, &amp; Hallett (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Voon-Mechanisms-underlying-dopamine-mediated-reward-bias-in-compulsive-behaviors.pdf\">Mechanisms underlying dopamine-mediated reward bias in compulsive behaviors</a>. <em>Neuron, 65</em>: 135.</small></p>\n<p><small>Winkielman &amp; Berridge (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Winkielman-Berridge-Unconscious-emotion.pdf\">Unconscious emotion</a>. <em>Current Directions in Psychological Science, 13</em>: 120-123.</small></p>\n<p><small>Winkielman, Berridge, &amp; Wilbarger (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Winkielman-Unconscious-Affective-Reactions.pdf\">Unconscious affective reactions to masked happy versus angry faces influence consumption behavior and judgments of value</a>. <em>Personality and Social Psychology Bulletin, 31</em>: 121-135.</small></p>\n<p><small>Wise (2006). Role of brain dopamine in food reward and reinforcement. <em>Philosophical Transactions of the Royal Society B, 361</em>: 1149-1158.</small></p>\n<p><small>Wise &amp; Bozarth (1985). Brain mechanisms of drug reward and euphoria. <em>Psychiatric Medicine, 3</em>: 445-460.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Jzm2mYuuDBCNWq8hi": 1, "Wi3EopKJ2aNdtxSWg": 1, "5f5c37ee1b5cdee568cfb186": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zThWT5Zvifo5qYaca", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 48, "extendedScore": null, "score": 9.6e-05, "legacy": true, "legacyId": "6434", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 48, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>The <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">scientific</a> approach to self-help&nbsp;suggests that a better understanding of who we are can help us achieve <a href=\"/lw/4su/the_science_of_happiness/\">happiness</a> and <a href=\"/lw/3w3/how_to_beat_procrastination/\">other goals</a>. Most centrally, it will be helpful to understand our <em>brains</em>, because it is our brains that generate happiness and goals.</p>\n<p>In particular, I'd like to explore the neuroscience of pleasure and desire. Today's post covers the neuroscience of pleasure; the next post will cover the neuroscience of desire. After each post I'll consider some of the implications for self-help. In a later post, I'll consider how this research can inform the pursuit of <a href=\"http://intelligence.org/ourresearch/publications/what-is-friendly-ai.html\">Friendly AI</a>.</p>\n<p>&nbsp;</p>\n<h4 id=\"Introducing_Affective_Neuroscience\">Introducing Affective Neuroscience</h4>\n<p>The last decade has seen the arrival of&nbsp;<a href=\"http://en.wikipedia.org/wiki/Affective_neuroscience\">affective neuroscience</a>: the study of the neural mechanisms behind emotion, including pleasure and desire.<sup>1</sup>&nbsp;Most questions remain unanswered, and experts disagree on many specifics,<sup>2</sup> but there are some things we can state with confidence. We begin with the reward system in the brain.</p>\n<p>The <a href=\"http://en.wikipedia.org/wiki/Reward_system\">reward system</a> consists of three major components (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/05/wanting-learning-liking.png\">image</a>)<sup>3</sup>:</p>\n<ul>\n<li><em>Liking</em>: The 'hedonic impact' of reward, comprised of (1) neural processes<sup>4</sup> that may or may not be conscious and (2) the conscious experience of pleasure.</li>\n<li><em>Wanting</em>: Motivation for reward, comprised of (1) processes of&nbsp;'incentive salience'&nbsp;that may or may not be conscious and (2) conscious desires.</li>\n<li><em>Learning</em>: Associations, representations, and predictions about future rewards, comprised of (1) <em>explicit</em> predictions and (2) <em>implicit</em> knowledge and associative conditioning (e.g. <a href=\"http://en.wikipedia.org/wiki/Classical_conditioning\">Pavlovian associations</a>).</li>\n</ul>\n<p>Unfortunately, the interaction between these components is extraordinarily complex, and many puzzles remain.<sup>5</sup></p>\n<p>I'll share two examples of our ignorance.&nbsp;First: pleasure electrodes. For decades, it was thought that electrical stimulation of certain structures caused pleasure, because rats and humans would self-administer this stimulation hundreds or thousands of times each hour if allowed to do so.<sup>6</sup> But a careful reading of the transcripts reveals the causation of&nbsp;<em>wanting</em>, not&nbsp;<em>liking</em>. Sometimes, the cause was even an unpleasant&nbsp;<em>nervousness</em>.<sup>7</sup> Though, there are a few exceptions where liking was produced.<sup>8</sup></p>\n<p>Second: dopamine. For decades, experts thought dopamine was 'the pleasure chemical'.<sup>9</sup> But this is probably false.<sup>10</sup> Lack of dopamine does not impair 'liking' reactions.<sup>11</sup> And in humans, perceived pleasure is not reduced by loss of dopamine.<sup>12</sup> Dopamine has a big role in wanting, instead.<sup>13</sup></p>\n<p>Today we focus on 'liking' or <em>pleasure</em>.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Pleasure\">Pleasure</h4>\n<p>Thoughts and sensations are not intrinsically pleasurable. Rather, the reward system must paint them with a 'hedonic gloss' to make them 'liked'.<sup>14</sup>&nbsp;Food and sex are reliably pleasurable for obvious Darwinian reasons.<sup>15</sup> These 'fundamental pleasures' use the same brain structures as 'higher-order pleasures' like social pleasures, art, money, and altruism.<sup>16</sup></p>\n<p>The basic structures which produce pleasure are shared by other mammals (for Darwinian reasons), and other mammals exhibit liking processes in the brain.<sup>17</sup> It's not clear how similar their subjective experience of pleasure is to our own, though. Humans do have unique cognitive, representational and 'savoring' capacities,<sup>18</sup> among others.</p>\n<p>Much research concerns 'hedonic hotspots' in the brain. A hedonic hotspot might be a <em>necessary cause</em>&nbsp;of pleasure (pleasure doesn't occur without it; e.g. the <a href=\"http://en.wikipedia.org/wiki/Ventral_pallidum\">ventral pallidum</a>), a <em>sufficient cause</em>&nbsp;of pleasure (if activated, pleasure occurs; e.g. the <a href=\"http://en.wikipedia.org/wiki/Nucleus_accumbens\">nucleus accumbens</a>), or it may <em>code for</em>&nbsp;pleasure (its activation correlates with pleasure, but might be either a cause or effect of pleasure, or both; e.g. the <a href=\"http://en.wikipedia.org/wiki/Orbitofrontal_cortex\">orbitofrontal cortex</a>&nbsp;and ventral pallidum). A substrate may play multiple roles, or it may code without causing, or it may be a sufficient cause without being a necessary cause.<sup>19</sup></p>\n<p>We know thousands of specific things about pleasure and the reward system, but we don't yet understand pleasure on a <a href=\"http://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis\">systems level</a>. We don't know how to integrate these thousands of bits of information into a cohesive theory of how pleasure works.</p>\n<p>Many have tried, of course. Here is Tim Schroeder's attractively simple theory of pleasure:</p>\n<blockquote>\n<p>To be pleased is (at least) to represent a net increase in desire satisfaction relative to expectation; to be displeased is to represent a net decrease in desire satisfaction relative to expectation. Intensity of pleasure or displeasure represents degrees of change in desire satisfaction relative to expectations.<sup>20</sup></p>\n</blockquote>\n<p>But this is <em>too</em>&nbsp;simple. Though pleasure often results from experiencing more satisfaction than expected,&nbsp;there are many other sources of pleasure,<sup>21</sup> and pleasure can occur in animals that lack representational capacities or expectations, for example anecephalic infants&nbsp;and animals with most of their brains removed.<sup>22</sup>&nbsp;</p>\n<p>Among neuroscientists, there are many overlapping theories of pleasure, which are often not mutually exclusive.<sup>23</sup> Rather than survey them all, let me jump to the self-help advice: what can brain science teach us about pleasure and how to get more of it?</p>\n<h4><br></h4>\n<h4 id=\"Self_Help_Implications\">Self-Help Implications</h4>\n<p>The neuroscience of pleasure is most useful when designing new drugs or performing neurosurgery, but there are a few self-help recommendations we can draw from the field:</p>\n<ol>\n<li>Wanting and liking are different signals, though they sometimes share use of the same neurons, like phone and internet data traveling along the same wire.<sup>24</sup> As a result, we <em>usually</em> like what we want and want what we like, but <em>sometimes</em> we don't want what we like or&nbsp;don't like what we want.<sup>25</sup> Understanding <a href=\"http://commonsenseatheism.com/?p=15072\">why this happens</a> may relieve the confusion that often results when it occurs (not to mention <a href=\"/lw/1lb/are_wireheads_happy/\">philosophical confusion</a>).</li>\n<li>Contrary to some theories,<sup>26</sup> pleasure is not merely the perception of certain bodily sensations (e.g. blood rising, organs warming). Instead, sensations and thoughts are painted with a hedonic gloss that makes them pleasurable. Moreover, the selection of sensations and thoughts that are painted with a hedonic gloss can be <em>changed</em>.<sup>27</sup> This is why we can change (to some degree) what we like and dislike via <a href=\"http://en.wikipedia.org/wiki/Classical_conditioning\">classical</a> and <a href=\"http://en.wikipedia.org/wiki/Operant_conditioning\">operant</a> conditioning, and other methods.</li>\n<li>Anticipation matters. Anticipating future pain is itself painful,<sup>28</sup>&nbsp;and anticipating pleasure is itself pleasant.<sup>29</sup>&nbsp;Spend more time reliving happy memories and anticipating future pleasures, and spend less time anticipating future pains. But beware: trying&nbsp;<em>not</em>&nbsp;to think of the event will only bring it to your mind again. Instead, get 'lost' in a challenging task that matches your level of ability: that is,&nbsp;<a href=\"/lw/3w3/how_to_beat_procrastination/#flow\">get in flow</a>.</li>\n<li>If you experience a continuing&nbsp;<em>lack</em>&nbsp;of pleasure in life (<a href=\"http://en.wikipedia.org/wiki/Anhedonia\">anhedonia</a>), your problem might be neurological, not situational. A doctor may be able to solve the problem with drugs or deep brain stimulation.<sup>30</sup></li>\n</ol>\n<p>This is a short list, but additional self-help recommendations can be gleaned after we build on this knowledge to discuss the neuroscience of <em>desire</em>, which we will cover <a href=\"/lw/4z7/the_neuroscience_of_desire/\">next</a>.</p>\n<p align=\"right\">&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup> LeDoux &amp; Phelps (2000); Berridge (2003a); Davidson et al. (2003); Damasio (2004);&nbsp;Rolls (2005);&nbsp;Feldman &amp; Wager (2006); Kringelbach (2005);&nbsp;Kringelbach &amp; Berridge (2009a, 2009b).</small></p>\n<p><small><sup>2</sup> Kringelbach et al. (2009).</small></p>\n<p><small><sup>3</sup>&nbsp;Berridge &amp; Kringelbach (2008); Berridge et al. (2009); Berridge (1996); Berridge &amp; Robinson (1998); Pecina et al. (2003); Camerer (2006); Kringelbach &amp; Berridge (2010b). Some experts will talk as if there is no such thing as unconscious pleasure (Kringelbach et al. 2009), but this is only a manner of speaking adopted to respect the folk understanding of conscious pleasure, for they acknowledge the same unconscious hedonic processes that other researchers do (Winkielman &amp; Berridge 2004; Winkielman et al. 2005; Schooler &amp; Mauss 2009). Likewise, though ever researcher may not use the liking / wanting / learning scheme, I haven't found any major expert who disagrees with the minimal factual claims presupposed by that scheme. Experts agree that pleasure, motivation, and learning are distinct components of the reward system in the brain.</small></p>\n<p><small><sup>4</sup>&nbsp;The neural processes that apply the 'hedonic gloss' to sensations and cognitions seem to be a particular pattern of excitation of neurons in a hedonic hotspot in the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Ventral_pallidum\">ventral pallidum</a>&nbsp;(Tindell et al. 2005; Aldridge &amp; Berridge 2009), though other brain structures may play a role as well, in particular the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Nucleus_accumbens\">nucleus accumbens</a>&nbsp;(Smith et al. 2001), the&nbsp;<a href=\"http://en.wikipedia.org/wiki/Orbitofrontal_cortex\">orbitofrontal cortex</a>&nbsp;(Kringelbach 2009), and perhaps the perigenual&nbsp;<a href=\"http://en.wikipedia.org/wiki/Anterior_cingulate_cortex#Reward-based_learning_theory\">anterior cingulate cortex</a>&nbsp;(Schroeder 2004, ch. 3). Commonly measured 'surface' pleasure reactions are (1) subjective report in humans, and (2) particular facial expressions in human adults, human infants, chimpanzees, and rats (Smith et al. 2005). See videos&nbsp;<a href=\"http://www.lsa.umich.edu/psych/research&amp;labs/berridge/VideoIndex.htm\">here</a>.</small></p>\n<p><small><sup>5</sup> Baldo &amp; Kelley (2007); Balleine &amp; Kilcross (2006); Balleine et al. (2007); Beaver et al. (2006); Burke et al. (2009), Di Chiara &amp; Bassareo (2007); Evans et al. (2006); Everitt &amp; Robbins (2005); Izard (2007); Kuhn &amp; Koob (2010); Panksepp (2007); Salamone et al. (2007); Schultz (2006); Stoeckel et al. (2008);&nbsp;Van Leijenhorst et al. (2010);&nbsp;Volkow et al. (2006); Voon et al. (2010); Wise (2006);&nbsp;Kringelbach &amp; Berridge (2010a).</small></p>\n<p><small><sup>6</sup>&nbsp;Delgado (1969); Heath (1972); Sem-Jacobsen (1976).</small></p>\n<p><small><sup>7</sup>&nbsp;Berridge (2003b); Pecina et al. (2006); Smith et al. (2009).</small></p>\n<p><small><sup>8</sup>&nbsp;Morgan et al. (2006).</small></p>\n<p><small><sup>9</sup>&nbsp;Hoebel et al. (1999); Shizgal (1999); Wise &amp; Bozarth (1985).</small></p>\n<p><small><sup>10</sup>&nbsp;Smith et al. (2009); Berridge (2007); Robinson &amp; Berridge (2003).</small></p>\n<p><small><sup>11</sup>&nbsp;Berridge &amp; Robinson (1998); Berridge et al. (1989); Robinson et al. (2005); Pecina et al. (1997).</small></p>\n<p><small><sup>12</sup>&nbsp;Sienkiewicz-Jarosz et al. (2005); Brauer et al. (2001); Leyton et al. (2005); Leyton (2009).</small></p>\n<p><small><sup>13</sup>&nbsp;Berridge (2007).</small></p>\n<p><small><sup>14</sup> Frijda (2006, 2009); Aldridge &amp; Berridge (2009); Ryle (1954).</small></p>\n<p><small><sup>15</sup>&nbsp;Cabanac (2009); Kringelbach (2005, 2009); Rolls (2005); Schulkin (2004).</small></p>\n<p><small><sup>16</sup>&nbsp;Kringelbach (2005, 2009); Pecina et al. (2006); Small et al. (2001);&nbsp;Gottfried (2009); Kahneman et al. (2004).</small></p>\n<p><small><sup>17</sup>&nbsp;Steiner et al. (2001); Berridge (2000); Kringelbach (2008, 2009); Smith et al. (2009); Calder et al. (2007).</small></p>\n<p><small><sup>18</sup>&nbsp;Barrett et al. (2007); Frijda (2006); Frijda &amp; Sundarajan (2007); Gilbert &amp; Wilson (2007).</small></p>\n<p><small><sup>19</sup>&nbsp;Berridge &amp; Kringelbach (2008); Smith et al. (2009).</small></p>\n<p><small><sup>20</sup> Schroeder (2004), p. 94.</small></p>\n<p><small><sup>21</sup>&nbsp;Smith et al. (2009); Kringelbach &amp; Berridge (2009b).</small></p>\n<p><small><sup>22</sup>&nbsp;Steiner (1973); Steiner et al. (2001);&nbsp;Goltz (1892); Miller &amp; Sherrington (1915); Grill &amp; Norgren (1978). It must be noted that my summary is a bit unfair to Schroeder: Schroeder is offering a theory only of <em>conscious</em>&nbsp;pleasure, which may indeed require the representational capacities unneeded for unconscious 'liking.' Still, it remains the case that there seem to be many other causes and implementations of pleasure than representations of a positive difference between actual desire satisfaction and expected desire satisfaction. But Schroeder's theory is not, as far as I can tell, decisively <em>falsified</em>&nbsp;by the data.</small></p>\n<p><small><sup>23</sup>&nbsp;See Dickinson &amp; Balleine (2009) for a comparison of theories. Some leading theories are: the somantic marker hypothesis by Damasio (1996), the hedonic interface theory by Dickinson &amp; Balleine (2009), the common currency theory of Cabanac (1992), and the multiple-components theories of Berridge, Kringelbach, and others: see Berridge &amp; Kringelbach (2008); Kringelbach (2008).</small></p>\n<p><small><sup>24</sup>&nbsp;Smith et al. (2009); Tindell et al. (2005); Smith et al. (2007); Berridge et al. (2009).</small></p>\n<p><small><sup>25</sup>&nbsp;Smith et al. (2009);&nbsp;Dickinson &amp; Balleine (2009).</small></p>\n<p><small><sup>26</sup>&nbsp;For example, Damasio (1994), p. 263.</small></p>\n<p><small><sup>27</sup>&nbsp;Burke et al. (2009); Aldridge &amp; Berridge (2009).</small></p>\n<p><small><sup>28</sup> Berns et al. (2006).</small></p>\n<p><small><sup>29</sup> Gard et al. (2006).</small></p>\n<p><small><sup>30</sup> Green et al. (2009).</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Aldridge &amp; Berridge (2009). Neural coding of pleasure: 'rose-tinted glasses' of the ventral pallidum.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 62-73). Oxford University Press.</small></p>\n<p><small>Baldo &amp; Kelley (2007). Discrete neurochemical coding of distinguishable motivational processes: insights from nucleus accumbens control of feeding. <em>Psychopharmacology, 191</em>: 439-459.</small></p>\n<p><small>Balleine &amp; Kilcross (2006). Parallel incentive processing: an integrated view of amygdala function. <em>Trends in Neuroscience, 29</em>: 272-279.</small></p>\n<p><small>Balleine, Delgado, &amp; Hikosaka (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Balleine-The-role-of-the-dorsal-striatum-in-reward-and-decision-making.pdf\">The role of the dorsal striatum in reward and decision-making</a>. <em>The Journal of Neuroscience, 27</em>: 8161-8165.</small></p>\n<p><small>Barrett, Mesquita, Ochsner, &amp; Gross (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Barrett-The-experience-of-emotion.pdf\">The experience of emotion</a>. <em>Annual Review of Psychology, 58</em>: 373-403.</small></p>\n<p><small>Beaver, Lawrence, van Ditzhuijzen, David, Woods, &amp; Calder (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Beaver-Individual-differences-in-reward-drive-predict-neural-responses-to-images-of-food.pdf\">Individual differences in reward drive predict neural responses to images of food</a>. <em>Journal of Neuroscience, 26</em>: 5160-5166.</small></p>\n<p><small>Berns, Chappelow, Cekic, Zink, Pagnoni, &amp; Martin-Shurski (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berns-Neurobiological-substrates-of-dread.pdf\">Neurobiological substrates of dread</a>. <em>Science, 312</em>: 754-758.</small></p>\n<p><small>Berridge (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Food-reward.pdf\">Food reward: Brain substrates of wanting and liking</a>. <em>Neuroscience and Biobehavioral Reviews, 20</em>: 1-25.</small></p>\n<p><small>Berridge (2000). Measuring hedonic impact in animals and infants: Microstructure of affective taste reactivity patterns. <em>Neuroscience and Biobehavioral Reviews, 24</em>: 173-198.</small></p>\n<p><small>Berridge (2003a). Comparing the emotional brain of humans to other animals. In Davidson, Goldsmith, &amp; Scherer (eds.), <em>Handbook of affective sciences</em>. Oxford University Press.</small></p>\n<p><small>Berridge (2003b). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Pleasures-of-the-brain.pdf\">Pleasures of the brain</a>. <em>Brain and Cognition, 52</em>: 106-128.</small></p>\n<p><small>Berridge (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-The-debate-over-dopamines-role-in-reward-the-case-for-incentive-salience.pdf\">The debate over dopamine's role in reward: the case for incentive salience</a>. <em>Psychopharmacology, 191</em>: 391-431.</small></p>\n<p><span style=\"font-size: 11px;\">Berridge (2009).&nbsp;<a href=\"http://www.lsa.umich.edu/psych/research&amp;labs/berridge/publications/Berridge%20'Liking'%20&amp;%20'wanting'%20food%20rewards%20Physiol%20&amp;%20Behav%202009.pdf\">\u2018Liking\u2019 and \u2018wanting\u2019 food rewards: Brain substrates and roles in eating disorders</a>. <em>Physiology &amp; Behavior, 97</em>: 537-550.</span></p>\n<p><small>Berridge &amp; Robinson (1998). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Robinson-What-is-the-role-of-dopamine-in-reward.pdf\">What is the role of dopamine in reward: Hedonic impact, reward learning, or incentive salience?</a> <em>Brain Research Reviews, 28</em>: 309-369.</small></p>\n<p><small>Berridge &amp; Kringelbach (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Affective-neuroscience-of-pleasure-reward-in-humans-and-animals.pdf\">Affective neuroscience of pleasure: Reward in humans and other animals</a>. <em>Psychopharmacology 199</em>, 457-80.</small></p>\n<p><small>Berridge, Venier, &amp; Robinson (1989). Taste reactivity analysis of 6-hydroxydopamine-induced aphagia: Implications for arousal and anhedonia hypotheses of dopamine function. <em>Behavioral Neuroscience, 103</em>: 36-45.</small></p>\n<p><small>Berridge, Robinson, &amp; Aldridge (2009).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-Dissecting-components-of-reward-\u2018liking\u2019-\u2018wanting\u2019-and-learning.pdf\">Dissecting components of reward: \u2018liking\u2019, \u2018wanting\u2019, and learning</a>.&nbsp;<em>Current Opinion in Pharmacology, 9</em>: 65\u201367.</small></p>\n<p><small>Brauer, Cramblett, Paxton, &amp; Rose (2001). Haloperidol reduces smoking of both nicotine-containing and denicotinized cigarettes. <em>Psychopharmacology, 159</em>: 31-37.</small></p>\n<p><small>Burke, Franz, Miller, &amp; Schoenbaum (2009). Conditioned reinforcement and the specialized role of corticolimbic circuits in the pursuit of happiness and other more specific rewards.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 50-61). Oxford University Press.</small></p>\n<p><small>Cabanac (1992). Pleasure: the common currency. <em>Journal of Theoretical Biology, 155</em>: 173-200.</small></p>\n<p><small>Cabanac (2009). The dialectics of pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 113-124). Oxford University Press.</small></p>\n<p><small>Calder, Beaver, Davis, van Ditzhuijzen, Keane, &amp; Lawrence (2007). Disgust sensitivity predicts the insula and pallidal response to pictures of disgusting foods. <em>European Journal of Neuroscience, 25</em>: 3422-3428.</small></p>\n<p><small>Camerer (2006).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Camerer-Wanting-liking-and-learning-neuroscience-and-paternalism.pdf\">Wanting, liking, and learning: Neuroscience and paternalism</a>.&nbsp;<em>The University of Chicago Law Review, 73</em>: 87-110.</small></p>\n<p><small>Damasio (1994).&nbsp;<em><a href=\"http://www.amazon.com/Descartes-Error-Emotion-Reason-Human/dp/014303622X/\">Descartes\u2019 error: Emotion, reason, and the human brain</a></em>. Putnam\u2019s.</small></p>\n<p><small>Damasio (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Damasio-The-somatic-marker-hypothesis-and-the-possible-functions-of-the-prefrontal-cortex.pdf\">The somatic marker hypothesis and the possible functions of the prefrontal cortex</a>. <em>Philosophical Transactions of the Royal Society B, 351</em>: 1413-1420.</small></p>\n<p><small>Damasio (2004). Emotions and feelings: a neurobiological perspective. In Manstead, Frijda, &amp; Fischer (eds.), <em>Feelings and emotions: the Amsterdam symposium</em>&nbsp;(pp. 49-57). Cambridge University Press.</small></p>\n<p><small>Davidson, Scherer, &amp; Goldsmith, eds. (2003). <em><a href=\"http://www.amazon.com/Handbook-Affective-Sciences-Richard-Davidson/dp/0195377001/\">Handbook of affective sciences</a></em>. Oxford University Press.</small></p>\n<p><small>Delgado (1969). <em><a href=\"http://www.amazon.com/Physical-control-mind-psychocivilized-torchbooks/dp/0061319147/\">Physical Control of the Mind: Toward a Psychocivilized Society</a></em>. Harper and Row.</small></p>\n<p><small>Di Chiara &amp; Bassareo (2007). Reward system and addiction: what dopamine does and doesn't do. <em>Current Opinion in Pharmacology, 7</em>: 69-76.</small></p>\n<p><small>Dickinson &amp; Balleine (2009). Hedonics: the cognitive-motivational interface.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 74-84). Oxford University Press.</small></p>\n<p><small>Evans, Pavese, Lawrence, Tai, Appel, Doder, Brooks, Lees, &amp; Piccini (2006). Compulsive drug use linked to sensitized ventral striatal dopamine transmission. <em>Annals of Neurology, 59</em>: 852-858.</small></p>\n<p><small>Everitt &amp; Robbins (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Everitt-Robbins-Neural-systems-of-reinforcement-for-drug-addiction.pdf\">Neural systems of reinforcement for drug addiction: from actions to habits to compulsion</a>. <em>Nature Neuroscience, 8</em>: 1481-1489.</small></p>\n<p><small>Feldman &amp; Wager (2006). The structure of emotion: evidence from neuroimaging studies. <em>Current Directions in Psychological Science, 15(2)</em>: 79-83.</small></p>\n<p><small>Frijda (2006). <em><a href=\"http://www.amazon.com/Laws-Emotion-Nico-H-Frijda/dp/0805825983/\">The laws of emotion</a></em>. Psychology Press.</small></p>\n<p><small>Frijda (2009). On the nature and function of pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 99-112). Oxford University Press.</small></p>\n<p><small>Frijda &amp; Sundararajan (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Frijda-Emotion-refinement.pdf\">Emotion refinement: a theory inspired by Chinese poetics</a>. <em>Perspectives on Psychological Science, 2</em>: 227\u2013241.</small></p>\n<p><small>Gard, Gard, Kring, &amp; John (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Gard-Anticipatory-and-consummatory-components-of-the-experience-of-pleasure-a-scale-development-study.pdf\">Anticipatory and consummatory components of the experience of pleasure: a scale development study</a>. <em>Journal of Research in Personality, 40</em>: 1086-1102.</small></p>\n<p><small>Gilbert &amp; Wilson (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Gilbert-Wilson-Prospection-experiencing-the-future.pdf\">Prospection: experiencing the future</a>. <em>Science 317</em>: 1351\u20131354.</small></p>\n<p><small>Goltz (1892). Der hund ohne grosshirn. <em>Pfl\u00fcgers Archiv European Journal of Physiology, 51</em>: 570.</small></p>\n<p><small>Gottfried (2009). Olfaction and its pleasures: human neuroimaging perspectives.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 125-145). Oxford University Press.</small></p>\n<p><small>Green, Pereira, &amp; Aziz (2009). Deep brain stimulation and pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 302-319). Oxford University Press.</small></p>\n<p><small>Grill &amp; Norgren (1978). The taste reactivity test II: Mimetic responses to gustatory stimuli in chronic thalamic and chronic decerebrate rats. <em>Brain Research, 143</em>: 263-279.</small></p>\n<p><small>Heath (1972). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Heath-Pleasure-and-brain-activity-in-man.pdf\">Pleasure and brain activity in man: Deep and surface electroencephalograms during orgasm</a>. <em>Journal of Nervous and Mental Disease, 154</em>: 3-18.</small></p>\n<p><small>Hoebel, Rada, Mark, &amp; Pathos (1999). Neural systems for reinforcement and inhibition of behavior: Relevance to eating, addiction, and depression. In Kahneman, Diener, &amp; Schwarz (eds.), <em>Well-being: the foundations of hedonic psychology</em>&nbsp;(pp. 558-572). Russell Sage Foundation.</small></p>\n<p><small>Izard (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Izard-Basic-emotions-natural-kinds-emotion-schemas-and-a-new-paradigm.pdf\">Basic emotions, natural kinds, emotion schemas, and a new paradigm</a>. <em>Perspectives on Psychological Science, 2</em>: 260-280.</small></p>\n<p><small>Kahneman, Krueger, Schkade, Schwarz, &amp; Stone (2004). A survey method for characterizing daily life experience: the day reconstruction method. <em>Science, 306</em>: 1776\u20131780.</small></p>\n<p><small>Kringelbach (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kringelbach-The-human-orbitofrontal-cortex.pdf\">The human orbitofrontal cortex: linking reward to hedonic experience</a>. <em>Nature Reviews Neuroscience, 6</em>: 691-702.</small></p>\n<p><small>Kringelbach (2008). <em><a href=\"http://www.amazon.com/Pleasure-Center-Trust-Animal-Instincts/dp/0195322851/\">The pleasure center: Trust your animal instincts</a></em>. Oxford University Press.</small></p>\n<p><small>Kringelbach (2009). The hedonic brain: a functional neuroanatomy of human pleasure. In Kringelbach &amp; Berridge (eds.), <em>Pleasures of the brain</em> (pp. 202-221). Oxford University Press.</small></p>\n<p><small>Kringelbach &amp; Berridge (2009a). Towards a functional neuroanatomy of pleasure and happiness. <em>Trends in Cognitive Sciences, 13(11)</em>: 479-487.</small></p>\n<p><small>Kringelbach &amp; Berridge, eds. (2009b). <em><a href=\"http://www.amazon.com/Pleasures-Affective-Science-Morten-Kringelbach/dp/0195331028/\">Pleasures of the Brain</a></em>. Oxford University Press.</small></p>\n<p><small>Kringelbach &amp; Berridge (2010a). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kringelbach-Berridge-The-Functional-Neuroanatomy-of-Pleasure-and-Happiness.pdf\">The functional neuroanatomy of pleasure and happiness</a>. <em>Discovery Medicine, 9</em>: 579-587.</small></p>\n<p><small>Kringelbach &amp; Berridge (2010b). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Kringelbach-Berridge-The-Neuroscience-of-Happiness-and-pleasure.pdf\">The neuroscience of happiness and pleasure</a>. <em>Social Research, 77(2)</em>: 659-678.</small></p>\n<p><small>Kringelbach, Berridge, Cabanac, Aldridge, Frijda, Leknes, Dickinson, Shizgal, Gottfried, Komisaruk, Petrovic, Green, Schoenbaum, &amp; Small (2009). Fundamental pleasure questions.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 7-23). Oxford University Press.</small></p>\n<p><small>Kuhn &amp; Koob (2010). <em><a href=\"http://www.amazon.com/Advances-Neuroscience-Addiction-Frontiers/dp/0849373913/\">Advances in the Neuroscience of Addiction</a></em>. CRC Press.</small></p>\n<p><small>LeDoux &amp; Phelps (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Ledoux-Phelps-Emotional-networks-in-the-brain.pdf\">Emotional networks in the brain</a>. In Lewis &amp; Haviland-Jones (eds.), <em>Handbook of emotions</em>&nbsp;(pp. 157-172). Guilford.</small></p>\n<p><small>Leyton, Casey, Delaney, Kolivakis, &amp; Benkelfat (2005). Cocaine craving, euphoria, and self-administration: a preliminary study of the effect of catecholamine precursor depletion. <em>Behavioral Neuroscience, 119</em>: 1619-1627.</small></p>\n<p><small>Leyton (2009). The neurobiology of desire: Dopamine and the regulation of mood and motivational states in humans.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 222-243). Oxford University Press.</small></p>\n<p><small>Miller &amp; Sherrington (1915). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Miller-Some-observations-on-the-bucco-pharyngeal-stage-of-reflex-deglutition-in-the-cat.pdf\">Some observations on the bucco-pharyngeal stage of reflex deglutition in the cat</a>. <em>Quarterly Journal of Experimental Physiology, 9</em>: 147-186.</small></p>\n<p><small>Morgan, di Donato, Iyer, Jenkins, Smith, &amp; Sethi (2006). Self-stimulatory behavior associated with deep brain stimulation in Parkinson's disease. <em>Movement Disorders, 21</em>: 283-285.</small></p>\n<p><small>Panksepp (2007). Neurologizing the psychology of affects: how appraisal-based constructivism and basic emotion theory can coexist. <em>Perspectives on Psychological Science, 2</em>: 281-296.</small></p>\n<p><small>Pecina, Berridge, &amp; Parker (1997). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Pecina-Pimozide-does-not-shift-palatibility.pdf\">Pimozide does not shift palatibility: Separation of anhedonia from sensorimotor suppression by taste reactivity</a>. <em>Pharmacology Biochemistry and Behavior, 58</em>: 801-811.</small></p>\n<p><small>Pecina, Cagniard, Berridge, Aldridge, &amp; Zhuang (2003).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Pecina-Hyperdopaminergic-Mutant-Mice-Have-Higher-Wanting-But-Not-Liking-for-Sweet-Rewards.pdf\">Hyperdopaminergic mutant mice have higher 'wanting' but not 'liking' for sweet rewards</a>. <em>The Journal of Neuroscience, 23</em>:&nbsp;9395-9402.</small></p>\n<p><small>Pecina, Smith, &amp; Berridge (2006). Hedonic hot spots in the brain. <em>Neuroscientist, 12</em>: 500\u2013511.</small></p>\n<p><small>Robinson &amp; Berridge (2003). Addiction. <em>Annual Review of Psychology, 54</em>: 25-53.</small></p>\n<p><small>Robinson, Sandstrom, Denenberg, &amp; Palmiter (2005). Distinguishing whether dopamine regulates liking, wanting, and/or learning about rewards. <em>Behavioral Neuroscience, 119</em>: 5-15.</small></p>\n<p><small>Rolls (2005). <em><a href=\"http://www.amazon.com/Emotion-Explained-Affective-Science-Edmund/dp/019857004X/\">Emotion explained</a></em>. Oxford University Press.</small></p>\n<p><small>Ryle G (1954). Pleasure. <em>Proceedings of the Aristotelian Society, 28</em>: 135\u2013146.</small></p>\n<p><small>Salamone, Correa, Farrar, &amp; Mingote (2007). Effort-related functions of nucleus accumbens dopamine and associated forebrain circuits. <em>Psychopharmacology, 191</em>: 461-482.</small></p>\n<p><small>Schooler &amp; Mauss (2009). To be happy and to know it: the experience and meta-awareness of pleasure.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 244-254). Oxford University Press.</small></p>\n<p><small>Schroeder (2004). <em><a href=\"http://www.amazon.com/Three-Faces-Desire-Philosophy-Mind/dp/019517237X/\">Three faces of desire</a></em>. Oxford University Press.</small></p>\n<p><small>Schulkin (2004).&nbsp;<em><a href=\"http://www.amazon.com/Allostasis-Homeostasis-Costs-Physiological-Adaptation/dp/0521811414/\">Allostasis, homeostasis, and the costs of physiological adaptation</a></em>. Cambridge University Press.</small></p>\n<p><small>Schultz (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Schultz-Behavioral-theories-and-the-neurophysiology-of-reward.pdf\">Behavioral theories and the neurophysiology of reward</a>. <em>Annual Review of Psychology, 57</em>: 87-115.</small></p>\n<p><small>Sem-Jacobsen (1976). Electrical stimulation and self-stimulation with chronic implanted electrodes: Interpretation and pitfalls of results. In Wauquier &amp; Rolls (eds.), <em>Brain-Stimulation Reward</em>&nbsp;(pp. 505-520). Elsevier.</small></p>\n<p><small>Shizgall (1999). On the neural computation of utility: Implications from the studies of brain stimulation reward.&nbsp;In Kahneman, Diener, &amp; Schwarz (eds.),&nbsp;<em>Well-being: the foundations of hedonic psychology</em>&nbsp;(pp. 500-524). Russell Sage Foundation.</small></p>\n<p><small>Sienkiewicz-Jarosz, Scinska, Kuran, Ryglewicz, Rogowski, Wrobel, Korkosz, Kukwa, Kostowski, &amp; Bienkowski (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sienkiewicz-Jarosz-Taste-responses-in-patients-with-Parkinsons-disease.pdf\">Taste responses in patients with Parkinson's disease</a>. <em>Journal of Neurology, Neurosurgery, &amp; Psychiatry, 76</em>: 40-46.</small></p>\n<p><small>Small, Zatorre, Dagher, Evans, &amp; Jones-Gotman (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Small-Changes-in-brain-activity-related-to-eating-chocolate.pdf\">Changes in brain activity related to eating chocolate: From pleasure to aversion</a>. <em>Brain, 124</em>: 1720\u20131733.</small></p>\n<p><small>Smith, Berridge, &amp; Aldridge (2007). Ventral pallidal neurons distinguish 'liking' and 'wanting' elevations caused by opioids versus dopamine in nucleus acumbens. Program No. 310.5, 2007 Neuroscience Meeting Planner. San Diego, CA: Society for Neuroscience.</small></p>\n<p><small>Smith, Mahler, Pecina, &amp; Berridge (2009). Hedonic hotspots: generating sensory pleasure in the brain.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 27-49). Oxford University Press.</small></p>\n<p><small>Steiner (1973). The gustofacial response: Observation on normal and anecephalic newborn infants. <em>Symposium on Oral Sensation and Perception, 4</em>: 254-278.</small></p>\n<p><small>Steiner, Glaser, Hawillo, &amp; Berridge (2001). Comparative expression of hedonic impact: affective reactions to taste by human infants and other primates. <em>Neuroscience and Biobehavioral Reviews, 25</em>: 53-74.</small></p>\n<p><small>Stoeckel, Weller, Cook, Twieg, Knowlton, &amp; Cox (2008). Widespread reward-system activation in obese women in response to pictures of high-calorie foods. <em>Neuroimage, 41(2)</em>: 636-647.</small></p>\n<p><small>Tindell, Berridge, Zhang, Pecina, &amp; Aldridge (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Tindell-Ventral-pallidal-neurons-code-incentive-motivation.pdf\">Ventral pallidal neurons code incentive motivation: Amplification by mesolimbic sensitization and amphetamine</a>. <em>European Journal of Neuroscience, 22</em>: 2617-2634.</small></p>\n<p><small>Van Leijenhorst, Zanolie, Van Meel, Westenberg, Rombouts, &amp; Crone (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Van-Leijenhorst-What-Motivates-the-Adolescent.pdf\">What motivates the adolescent? Brain regions mediating reward sensitivity across adolescence</a>. <em>Cerebral Cortex 20</em>, 61-69.</small></p>\n<p><small>Veldhuizen, Rudenga, &amp; Small (2009). The pleasure of taste, flavor, and food.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 146-168). Oxford University Press.</small></p>\n<p><small>Volkow, Wang, Telang, Fowler, Logan, Childress, Jayne, Ma, &amp; Wong (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Volkow-Cocaine-cues-and-dopamine-in-dorsal-striatum.pdf\">Cocaine cues and dopamine in dorsal striatum: mechanism of craving in cocaine addiction</a>. <em>Journal of Neuroscience, 26</em>: 6583-6588.</small></p>\n<p><small>Voon, Pessiglione, Brezing, Gallea, Fernandez, Dolan, &amp; Hallett (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Voon-Mechanisms-underlying-dopamine-mediated-reward-bias-in-compulsive-behaviors.pdf\">Mechanisms underlying dopamine-mediated reward bias in compulsive behaviors</a>. <em>Neuron, 65</em>: 135.</small></p>\n<p><small>Winkielman &amp; Berridge (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Winkielman-Berridge-Unconscious-emotion.pdf\">Unconscious emotion</a>. <em>Current Directions in Psychological Science, 13</em>: 120-123.</small></p>\n<p><small>Winkielman, Berridge, &amp; Wilbarger (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Winkielman-Unconscious-Affective-Reactions.pdf\">Unconscious affective reactions to masked happy versus angry faces influence consumption behavior and judgments of value</a>. <em>Personality and Social Psychology Bulletin, 31</em>: 121-135.</small></p>\n<p><small>Wise (2006). Role of brain dopamine in food reward and reinforcement. <em>Philosophical Transactions of the Royal Society B, 361</em>: 1149-1158.</small></p>\n<p><small>Wise &amp; Bozarth (1985). Brain mechanisms of drug reward and euphoria. <em>Psychiatric Medicine, 3</em>: 445-460.</small></p>", "sections": [{"title": "Introducing Affective Neuroscience", "anchor": "Introducing_Affective_Neuroscience", "level": 1}, {"title": "Pleasure", "anchor": "Pleasure", "level": 1}, {"title": "Self-Help Implications", "anchor": "Self_Help_Implications", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "17 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["33KewgYhNSxFpbpXg", "ZbgCx2ntD5eu8Cno9", "RWo4LwFzpHNQCTcYt", "HmfxSWnqnK265GEFM", "48DTJkBH58JbBNSFH"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-28T00:55:51.557Z", "modifiedAt": null, "url": null, "title": "Collapsible article sections?", "slug": "collapsible-article-sections", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:07.227Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fzHBJSpWPHyZY9Lmu/collapsible-article-sections", "pageUrlRelative": "/posts/fzHBJSpWPHyZY9Lmu/collapsible-article-sections", "linkUrl": "https://www.lesswrong.com/posts/fzHBJSpWPHyZY9Lmu/collapsible-article-sections", "postedAtFormatted": "Monday, March 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Collapsible%20article%20sections%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACollapsible%20article%20sections%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfzHBJSpWPHyZY9Lmu%2Fcollapsible-article-sections%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Collapsible%20article%20sections%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfzHBJSpWPHyZY9Lmu%2Fcollapsible-article-sections", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfzHBJSpWPHyZY9Lmu%2Fcollapsible-article-sections", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>It would be nice to be able to make 'collapsible sections' in articles, like on my <a href=\"http://commonsenseatheism.com/?p=3148\">atheism FAQ</a>. That way, each article with (for example) a long list of references at the bottom could by default have the references collapsed, but if you click 'References' then the list of references would appear. That way people wouldn't have to scroll past several pages of references in order to leave a comment. (Examples: <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">1</a>, <a href=\"/lw/3w3/how_to_beat_procrastination/\">2</a>, <a href=\"/lw/4su/how_to_be_happy/\">3</a>, <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">4</a>, <a href=\"/lw/3gv/statistical_prediction_rules_outperform_expert/\">5</a>.)</p>\n<p>This suggestion is mostly just for me at this point, though, as I'm the only one doing long lists of references. But I figured I'd mention it anyway.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fzHBJSpWPHyZY9Lmu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 27, "extendedScore": null, "score": 6.952088771981574e-07, "legacy": true, "legacyId": "6453", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["33KewgYhNSxFpbpXg", "RWo4LwFzpHNQCTcYt", "ZbgCx2ntD5eu8Cno9", "zThWT5Zvifo5qYaca", "CKW8c2Bngz9yXibSk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-28T03:28:31.885Z", "modifiedAt": null, "url": null, "title": "Free Will as Unsolvability by Rivals", "slug": "free-will-as-unsolvability-by-rivals", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:07.281Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Pavitra", "createdAt": "2009-09-22T08:32:44.250Z", "isAdmin": false, "displayName": "Pavitra"}, "userId": "yC2JgX3ENu7mionKh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/RiaBk3ZyWFvSt4rcr/free-will-as-unsolvability-by-rivals", "pageUrlRelative": "/posts/RiaBk3ZyWFvSt4rcr/free-will-as-unsolvability-by-rivals", "linkUrl": "https://www.lesswrong.com/posts/RiaBk3ZyWFvSt4rcr/free-will-as-unsolvability-by-rivals", "postedAtFormatted": "Monday, March 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Free%20Will%20as%20Unsolvability%20by%20Rivals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFree%20Will%20as%20Unsolvability%20by%20Rivals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRiaBk3ZyWFvSt4rcr%2Ffree-will-as-unsolvability-by-rivals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Free%20Will%20as%20Unsolvability%20by%20Rivals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRiaBk3ZyWFvSt4rcr%2Ffree-will-as-unsolvability-by-rivals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FRiaBk3ZyWFvSt4rcr%2Ffree-will-as-unsolvability-by-rivals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 488, "htmlBody": "<blockquote>\n<p>Nadia wanted to <em>solve</em> Alonzo. To reduce him to a canonical, analytic representation, sufficient to reconfigure him at will. If there was a potential Alonzo within potential-Alonzo-space, say, who was utterly devoted to Nadia, who would dote on her and die for her, an Alonzo-solution would make its generation trivial.</p>\n</blockquote>\n<p>from <em>True Names</em>, by Cory Doctorow and Benjamin Rosenbaum</p>\n<p>&nbsp;</p>\n<p>Warning: this post tends toward the character of mainstream philosophy, in that it relies on the author's intuitions to draw inferences about the nature of reality.</p>\n<p>&nbsp;</p>\n<p>If you are dealing with an intelligence <a href=\"/lw/qk/that_alien_message/\">vastly</a> more or less intelligent than yourself, there is no contest. One of you can <a href=\"http://wiki.lesswrong.com/wiki/Dark_arts\">play</a> the other like tic-tac-toe. The stupid party's values are simply irrelevant to the final outcome.</p>\n<p>If you are dealing with an intelligence extremely close to your own -- say, two humans within about five IQ points of each other -- then both parties' values will significantly affect the outcome.</p>\n<p>If you are dealing with an intelligence <em>moderately</em> more or less intelligent than yourself, such as a world-class politician or an average eight-year-old child respectively, then the weaker intelligence <em>might</em> be able to <em>slightly</em> affect the outcome.</p>\n<p>&nbsp;</p>\n<p>If we formalize free will as the fact that what we want to do has a causal effect on what we actually do, then perhaps we can characterize the <em>sensation</em> of free will -- the desire to loudly assert in political arguments that we have free will -- as a belief that our values will have a causal effect on the eventual outcome of reality.</p>\n<p>This matches the <a href=\"/lw/nh/extensions_and_intensions/\">sense</a> that facing a terrifyingly powerful intelligence, one that can solve us completely, strips away our free will, which in turn probably explains the common misconception that free will is incompatible with reductionism -- knowing that an explanation exists <a href=\"/lw/op/fake_reductionism/\">feels like</a> having the explanation be <a href=\"/lw/os/joy_in_discovery/\">known by someone</a>. We <em>don't want to be understood</em>.</p>\n<p>It matches the sense that a person's free will can be denied by forcing them into a straitjacket and tossing them in a padded cell. It matches the assumption that not having free will would feel like sitting at the wheel of a vehicle that was running on autopilot and refusing manual commands.</p>\n<p>&nbsp;</p>\n<p>In general, we can distinguish three successive stages at which free will can be cut off:</p>\n<ul>\n<li>The creature can be constructed non-heuristically to begin with; that is, it lacks a utility function.</li>\n<li>The creature can control insufficient resources to be in a winnable state; that is, it is physically helpless.</li>\n<li>The creature can be outsmarted; that is, it has a vastly superior opponent.</li>\n</ul>\n<p>Probably the last two, and possibly all three, cannot remain cleanly separated under close scrutiny. But the model has such a deep psychological appeal that I think it must be useful somehow, if only as an intermediate step in easing lay folk into <a href=\"https://secure.wikimedia.org/wikipedia/en/wiki/Compatibilism\">compatibilism</a>, or in predicting and <a href=\"/r/discussion/lw/4zb/free_will_as_unsolvability_by_rivals/\">manipulating</a> the vast majority of humans that believe or <a href=\"http://wiki.lesswrong.com/wiki/Alief\">alieve</a> it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb1b8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "RiaBk3ZyWFvSt4rcr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 24, "extendedScore": null, "score": 6.952510328508847e-07, "legacy": true, "legacyId": "6455", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["5wMcKNAwB6X4mp9og", "HsznWM9A7NiuGsp28", "mTf8MkpAigm3HP6x2", "KfMNFB3G7XNviHBPN", "RiaBk3ZyWFvSt4rcr"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-28T04:58:00.870Z", "modifiedAt": "2020-10-04T18:29:13.630Z", "url": null, "title": "Rationalist Movies (Spoilers for the film Limitless)", "slug": "rationalist-movies-spoilers-for-the-film-limitless", "viewCount": null, "lastCommentedAt": "2011-03-29T21:59:19.443Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mycroft65536", "createdAt": "2009-03-14T03:04:26.898Z", "isAdmin": false, "displayName": "Mycroft65536"}, "userId": "dKGL3eRH8Xcvrig7b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/g3z62J7bCReHB7Zyo/rationalist-movies-spoilers-for-the-film-limitless", "pageUrlRelative": "/posts/g3z62J7bCReHB7Zyo/rationalist-movies-spoilers-for-the-film-limitless", "linkUrl": "https://www.lesswrong.com/posts/g3z62J7bCReHB7Zyo/rationalist-movies-spoilers-for-the-film-limitless", "postedAtFormatted": "Monday, March 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationalist%20Movies%20(Spoilers%20for%20the%20film%20Limitless)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationalist%20Movies%20(Spoilers%20for%20the%20film%20Limitless)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg3z62J7bCReHB7Zyo%2Frationalist-movies-spoilers-for-the-film-limitless%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationalist%20Movies%20(Spoilers%20for%20the%20film%20Limitless)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg3z62J7bCReHB7Zyo%2Frationalist-movies-spoilers-for-the-film-limitless", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fg3z62J7bCReHB7Zyo%2Frationalist-movies-spoilers-for-the-film-limitless", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 172, "htmlBody": "<p>I just came back from the film Limitless. The movie contained a very interesting depiction of a character who gets an black market nootropic that works very well. It gives him perfect recall, perfect situational awareness, and the ability to figure out the best thing to say/do in real time. He uses this new power to finish his book, get back together with his girlfriend, become rich, and eventually become president of the united states.&nbsp;Incidentally&nbsp;he gets in shape, establishes himself as high status at top tier social events, learns many new languages, and sleeps with a bunch of women. In the end his new found&nbsp;intelligence&nbsp;leads him to happiness. The drama in the film comes from the fact that the drug has side effects, and there's a mobster who gets his hands on some and wants more.&nbsp;Intelligence&nbsp;is depicted as a&nbsp;fundamentally&nbsp;good thing. It's even described as \"I knew what I wanted and I knew how to get it.\" He&nbsp;affirms&nbsp;several times (and the story agrees) that he's still himself on the drug, just more effective.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "g3z62J7bCReHB7Zyo", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 17, "extendedScore": null, "score": 3.2e-05, "legacy": true, "legacyId": "6458", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": "2011-03-28T04:58:00.870Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-28T19:31:58.441Z", "modifiedAt": null, "url": null, "title": "Philosophy: A Diseased Discipline", "slug": "philosophy-a-diseased-discipline", "viewCount": null, "lastCommentedAt": "2021-04-19T20:26:01.923Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FwiPfF8Woe5JrzqEu/philosophy-a-diseased-discipline", "pageUrlRelative": "/posts/FwiPfF8Woe5JrzqEu/philosophy-a-diseased-discipline", "linkUrl": "https://www.lesswrong.com/posts/FwiPfF8Woe5JrzqEu/philosophy-a-diseased-discipline", "postedAtFormatted": "Monday, March 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Philosophy%3A%20A%20Diseased%20Discipline&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhilosophy%3A%20A%20Diseased%20Discipline%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwiPfF8Woe5JrzqEu%2Fphilosophy-a-diseased-discipline%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Philosophy%3A%20A%20Diseased%20Discipline%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwiPfF8Woe5JrzqEu%2Fphilosophy-a-diseased-discipline", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFwiPfF8Woe5JrzqEu%2Fphilosophy-a-diseased-discipline", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2063, "htmlBody": "<p>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></p><p>Eliezer&#x27;s anti-philosophy post <a href=\"https://www.lesserwrong.com/lw/tg/against_modal_logics/\">Against Modal Logics</a> was pretty controversial, while my recent pro-philosophy (by LW standards) <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">post</a> and my <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qe4\">list of useful mainstream philosophy contributions</a> were massively up-voted. This suggests a significant appreciation for mainstream philosophy on Less Wrong - not surprising, since <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\">Less</a> <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">Wrong</a> <a href=\"http://wiki.lesswrong.com/wiki/Free_will\">covers</a> <a href=\"http://wiki.lesswrong.com/wiki/Reductionism_(sequence)\">so</a> <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">many</a> <a href=\"https://www.lesserwrong.com/lw/n3/circular_altruism/\">philosophical</a> <a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">topics</a>.</p><p>If you followed the recent <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q6b\">very</a> <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qan\">long</a> <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qth\">debate</a> between Eliezer and I over the value of mainstream philosophy, you may have gotten the impression that Eliezer and I strongly diverge on the subject. But I suspect I agree more with Eliezer on the value of mainstream philosophy than I do with many Less Wrong readers - perhaps most.</p><p>That might sound odd coming from someone who writes <a href=\"http://commonsenseatheism.com/\">a philosophy blog</a> and spends most of his spare time doing philosophy, so let me explain myself. (Warning: broad generalizations ahead! There are exceptions.)</p><h2>Failed methods</h2><p>Large swaths of philosophy (e.g. <a href=\"http://en.wikipedia.org/wiki/Continental_philosophy\">continental</a> and <a href=\"http://en.wikipedia.org/wiki/Postmodern_philosophy\">postmodern</a> philosophy) often don&#x27;t even <em>try</em> to be clear, rigorous, or scientifically respectable. This is philosophy of the &quot;Uncle Joe&#x27;s musings on the meaning of life&quot; sort, except that it&#x27;s <a href=\"http://el-prod.baylor.edu/certain_doubts/?p=453\">dressed up</a> in big words and long footnotes. You will occasionally stumble upon an <em>argument</em>, but it falls prey to <a href=\"https://www.lesserwrong.com/lw/td/magical_categories/\">magical categories</a> and <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">language confusions</a> and <a href=\"https://www.lesserwrong.com/lw/on/reductionism/\">non-natural hypotheses</a>. You may also stumble upon science or math, but they are used to &#x27;prove&#x27; things <a href=\"http://richarddawkins.net/articles/824-postmodernism-disrobed\">irrelevant</a> to the actual scientific data or the equations used.</p><p><a href=\"http://commonsenseatheism.com/?p=13499\">Analytic</a> philosophy is clearer, more rigorous, and better with math and science, but only does a slightly better job of avoiding magical categories, language confusions, and non-natural hypotheses. Moreover, its central tool is <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/#non-quine\">intuition</a>, and this displays a near-total ignorance of <a href=\"http://www.amazon.com/Kluge-Haphazard-Evolution-Human-Mind/dp/054723824X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">how</a> <a href=\"http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">brains</a> <a href=\"http://www.amazon.com/Foundations-Neuroeconomic-Analysis-Paul-Glimcher/dp/0199744254/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">work</a>. As <a href=\"http://en.wikipedia.org/wiki/Michael_Vassar\">Michael Vassar</a> observes, philosophers are &quot;spectacularly bad&quot; at understanding that their intuitions are <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">generated by cognitive algorithms</a>.</p><h2>A diseased discipline</h2><p>What about <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy\">Quinean naturalists</a>? Many of them at <em>least</em> understand the basics: that <a href=\"https://www.lesserwrong.com/lw/on/reductionism/\">things are made of atoms</a>, that many questions don&#x27;t need to be answered but instead <a href=\"https://www.lesserwrong.com/lw/of/dissolving_the_question/\">dissolved</a>, that <a href=\"https://www<em>.lesserwr</em>ong.com/lw/k2/a_priori/\">the brain is not an a priori truth factory</a>, that <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">intuitions come from cognitive algorithms</a>, that <a href=\"http://wiki.lesswrong.com/wiki/Bias\">humans are loaded with bias</a>, that <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">language is full of tricks</a>, and that <a href=\"https://www.lesserwrong.com/lw/s0/where_recursive_justification_hits_bottom/\">justification rests</a> in <a href=\"https://www.lesserwrong.com/lw/jm/the_lens_that_sees_its_flaws/\">the lens that can see its flaws</a>. Some of them are even <a href=\"http://commonsenseatheism.com/?p=13156\">Bayesians</a>.</p><p>Like I said, a few naturalistic philosophers are doing <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qe4\">some useful work</a>. But the signal-to-noise ratio is <em>much</em> lower even in naturalistic philosophy than it is in, say, behavioral economics or cognitive neuroscience or artificial intelligence or statistics. Why? Here are some hypotheses, based on my thousands of hours in the literature:</p><ol><li>Many philosophers have been infected (often by <a href=\"http://en.wikipedia.org/wiki/Philosophical_Investigations\">later Wittgenstein</a>) with the idea that philosophy is <em>supposed</em> to be useless. If it&#x27;s useful, then it&#x27;s science or math or something else, but not philosophy. Michael Bishop <a href=\"http://commonsenseatheism.com/?p=10553\">says</a> a common complaint from his colleagues about <a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">his 2004 book</a> is that it is <em>too useful</em>.</li><li>Most philosophers <em>don&#x27;t</em> understand the basics, so naturalists spend much of their time coming up with new ways to argue that people are made of atoms and intuitions don&#x27;t trump science. They fight beside the poor atheistic philosophers who keep coming up with <a href=\"http://www.amazon.com/Logic-Theism-Arguments-Against-Beliefs/dp/0521108667/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">new</a> <a href=\"http://www.amazon.com/Arguing-about-Gods-Graham-Oppy/dp/0521122643/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">ways</a> to argue that the universe was not created by someone&#x27;s invisible magical friend.</li><li>Philosophy has grown into an abnormally backward-looking discipline. Scientists like to put their work in the context of what old dead guys said, too, but philosophers have a real <em>fetish</em> for it. Even naturalists spend a fair amount of time re-interpreting Hume and Dewey yet again.</li><li>Because they were trained in traditional philosophical ideas, arguments, and frames of mind, naturalists will <a href=\"https://www.lesserwrong.com/lw/j7/anchoring_and_adjustment/\">anchor and adjust</a> from traditional philosophy when they make progress, rather than scrapping the whole mess and starting from scratch with a correct understanding of language, physics, and cognitive science. Sometimes, philosophical work is useful to build from: Judea Pearl&#x27;s triumphant <a href=\"http://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">work on causality</a> built on earlier counterfactual accounts of causality from philosophy. Other times, it&#x27;s best to ignore the past confusions. Eliezer made most of his philosophical progress on his own, in order to solve problems in AI, and only later looked around in philosophy to see which standard position his own theory was most similar to.</li><li>Many naturalists aren&#x27;t trained in cognitive science or AI. Cognitive science is essential because the tool we use to philosophize is the brain, and if you don&#x27;t know how your tool works then you&#x27;ll use it poorly. AI is useful because it keeps you honest: you can&#x27;t write confused concepts or non-natural hypotheses in a programming language.</li><li>Mainstream philosophy publishing favors the established positions and arguments. You&#x27;re more likely to get published if you can write about how intuitions are useless in solving Gettier problems (which is a confused set of non-problems anyway) than if you write about how to make a superintelligent machine preserve its utility function across millions of self-modifications.</li><li>Even much of the <em>useful</em> work naturalistic philosophers do is not at the cutting-edge. Chalmers&#x27; <a href=\"https://www.lesserwrong.com/lw/42l/david_chalmers_the_singularity_a_philosophical/\">update</a> for I.J. Good&#x27;s &#x27;intelligence explosion&#x27; argument is the best one-stop summary available, but it doesn&#x27;t get as far as the <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">Hanson-Yudkowsky AI-Foom debate</a> in 2008 did. Talbot (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Talbot-How-to-use-intuitions-in-philosophy.pdf\">2009</a>) and Bishop &amp; Trout (<a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321928423&linkCode=as2&tag=lesswrong-20\">2004</a>) provide handy summaries of much of the heuristics and biases literature, just like Eliezer has so usefully done on Less Wrong, but of course this isn&#x27;t cutting edge. You could always just read it in the primary literature by Kahneman and Tversky and others.</li></ol><p>Of course, there <em>is</em> mainstream philosophy that is both good and cutting-edge: the work of <a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a> and <a href=\"http://ase.tufts.edu/cogstud/incbios/dennettd/dennettd.htm\">Daniel Dennett</a> stands out. And of course there <em>is</em> a role for those who keep arguing for atheism and reductionism and so on. I was a fundamentalist Christian <a href=\"http://commonsenseatheism.com/?p=12\">until</a> I read some contemporary atheistic philosophy, so that kind of work definitely does some good.</p><p>But if you&#x27;re looking to solve cutting-edge problems, mainstream philosophy is one of the <em>last</em> places you should look. Try to find the answer in the cognitive science or AI literature first, or try to solve the problem by applying rationalist thinking: <a href=\"https://www.lesserwrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">like this</a>.</p><p>Swimming the murky waters of mainstream philosophy is perhaps a job best left for those who already spent several years studying it - that is, people like <em>me</em>. I already know what things are called and where to look, and I have an efficient filter for skipping past the 95% of philosophy that isn&#x27;t useful to me. And hopefully my rationalist training will protect me from picking up bad habits of thought.</p><h1>Philosophy: the way forward</h1><p>Unfortunately, many important problems are fundamentally <em>philosophical</em> problems. Philosophy itself is unavoidable. How can we proceed?</p><p>First, we must remain vigilant with our rationality training. It is not easy to overcome millions of years of brain evolution, and as long as you are human there is no final victory. You will always wake up the next morning as <em>homo sapiens</em>.</p><p>Second, if you want to contribute to cutting-edge problems, even ones that seem philosophical, it&#x27;s far more productive to study math and science than it is to study philosophy. You&#x27;ll learn more in math and science, and your learning will be of a higher quality. Ask a fellow rationalist who is knowledgeable about philosophy what the standard positions and arguments in philosophy are on your topic. If any of them seem <em>really</em> useful, grab those particular works and read them. But again: you&#x27;re probably better off trying to solve the problem by thinking like a cognitive scientist or an AI programmer than by ingesting mainstream philosophy.</p><p>However, I must say that I wish so much of Eliezer&#x27;s cutting-edge work wasn&#x27;t spread out across hundreds of Less Wrong blog posts and long SIAI articles written in with an idiosyncratic style and vocabulary. I would rather these ideas were written in standard academic form, even if they transcended the standard game of mainstream philosophy.</p><p>But it&#x27;s one thing to complain; another to offer solutions. So let me tell you what I think cutting-edge philosophy should be. As you might expect, my vision is to combine what&#x27;s good in LW-style philosophy with what&#x27;s good in mainstream philosophy, and toss out the rest:</p><ol><li>Write short articles. One or two major ideas or arguments per article, maximum. Try to keep each article under 20 pages. It&#x27;s hard to follow a <a href=\"http://intelligence.org/upload/TDT-v01o.pdf\">hundred-page argument</a>.</li><li>Open each article by explaining the context and goals of the article (even if you cover mostly the same ground in the opening of 5 other articles). What topic are you discussing? Which problem do you want to solve? What have other people said about the problem? What will you accomplish in the paper? Introduce key terms, cite standard sources and positions on the problem you&#x27;ll be discussing, even if you disagree with them.</li><li>If possible, use the standard terms in the field. If the standard terms are flawed, explain why they are flawed and then introduce your new terms in that context so everybody knows what you&#x27;re talking about. This requires that you research your topic so you know what the standard terms and positions <em>are</em>. If you&#x27;re talking about a problem in cognitive science, you&#x27;ll need to read cognitive science literature. If you&#x27;re talking about a problem in social science, you&#x27;ll need to read social science literature. If you&#x27;re talking about a problem in epistemology or morality, you&#x27;ll need to read philosophy.</li><li>Write as clearly and simply as possible. Organize the paper with lots of heading and subheadings. Put in lots of &#x27;hand-holding&#x27; sentences to help your reader along: explain the point of the previous section, then explain why the next section is necessary, etc. Patiently guide your reader through every step of the argument, especially if it is long and complicated.</li><li>Always cite the relevant literature. If you <a href=\"http://intelligence.org/upload/artificial-intelligence-risk.pdf\">can&#x27;t find</a> much work relevant to your topic, you almost certainly <a href=\"https://www.lesserwrong.com/lw/3m3/the_neglected_virtue_of_scholarship/\">haven&#x27;t looked hard enough</a>. Citing the relevant literature not only lends weight to your argument, but also enables the reader to track down and examine the ideas or claims you are discussing. Being lazy with your citations is a sure way to frustrate precisely those readers who care enough to read your paper closely.</li><li>Think like a cognitive scientist and AI programmer. Watch out for biases. Avoid magical categories and language confusions and non-natural hypotheses. Look at your intuitions from the outside, as cognitive algorithms. Update your beliefs in response to evidence. [<strong>This one is central. This is LW-style philosophy</strong>.]</li><li>Use your rationality training, but avoid language that is unique to Less Wrong. Nearly all these terms and ideas have standard names outside of Less Wrong (though in many cases Less Wrong already uses the standard language).</li><li>Don&#x27;t dwell too long on what old dead guys said, nor on semantic debates. Dissolve semantic problems and move on.</li><li>Conclude with a summary of your paper, and suggest directions for future research.</li><li>Ask fellow rationalists to read drafts of your article, then re-write. Then rewrite again, adding more citations and hand-holding sentences.</li><li>Format the article attractively. A well-chosen font makes for an <a href=\"http://en.wikipedia.org/wiki/Typography#Readability_and_legibility\">easier read</a>. Then publish (in a journal or elsewhere).</li></ol><p>Note that this is <em>not</em> just my vision of <a href=\"https://www.<em>lesserwrong</em>.com/lw/4r1/how_siai_could_publish_in_mainstream_cognitive/\">how to get published in journals</a>. It&#x27;s my vision of <em>how to do philosophy</em>.</p><p>Meeting journals standards is <em>not</em> the most important reason to follow the suggestions above. Write short articles because they&#x27;re easier to follow. Open with the context and goals of your article because that makes it easier to understand, and lets people decide right away whether your article fits their interests. Use standard terms so that people already familiar with the topic aren&#x27;t annoyed at having to learn a whole new vocabulary just to read your paper. Cite the relevant positions and arguments so that people have a sense of the context of what you&#x27;re doing, and can look up what other people have said on the topic. Write clearly and simply and with much organization so that your paper is not wearying to read. Write lots of hand-holding sentences because we always communicate less effectively then we <em>thought</em> we did. Cite the relevant literature as much as possible to assist your most careful readers in getting the information they want to know. Use your rationality training to remain sharp at all times. And so on.</p><p><em>That</em> is what cutting-edge philosophy could look like, I think.</p><p></p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">How You Make Judgments</a></p><p>Previous post: <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">Less Wrong Rationality and Mainstream Philosophy</a></p><p></p><p></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GLykb6NukBeBQtDvQ": 9, "3uE2pXvbcnS9nnZRE": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FwiPfF8Woe5JrzqEu", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 123, "baseScore": 137, "extendedScore": null, "score": 0.000253, "legacy": true, "legacyId": "6472", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "yFvZa9wkv5JoqhM8F", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "how-you-make-judgments-the-elephant-and-its-rider", "canonicalPrevPostSlug": "less-wrong-rationality-and-mainstream-philosophy", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 137, "bannedUserIds": null, "commentsLocked": false, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></p><p>Eliezer's anti-philosophy post <a href=\"https://www.lesserwrong.com/lw/tg/against_modal_logics/\">Against Modal Logics</a> was pretty controversial, while my recent pro-philosophy (by LW standards) <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">post</a> and my <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qe4\">list of useful mainstream philosophy contributions</a> were massively up-voted. This suggests a significant appreciation for mainstream philosophy on Less Wrong - not surprising, since <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\">Less</a> <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">Wrong</a> <a href=\"http://wiki.lesswrong.com/wiki/Free_will\">covers</a> <a href=\"http://wiki.lesswrong.com/wiki/Reductionism_(sequence)\">so</a> <a href=\"http://wiki.lesswrong.com/wiki/Metaethics_sequence\">many</a> <a href=\"https://www.lesserwrong.com/lw/n3/circular_altruism/\">philosophical</a> <a href=\"http://wiki.lesswrong.com/wiki/Zombies_(sequence)\">topics</a>.</p><p>If you followed the recent <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3q6b\">very</a> <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qan\">long</a> <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qth\">debate</a> between Eliezer and I over the value of mainstream philosophy, you may have gotten the impression that Eliezer and I strongly diverge on the subject. But I suspect I agree more with Eliezer on the value of mainstream philosophy than I do with many Less Wrong readers - perhaps most.</p><p>That might sound odd coming from someone who writes <a href=\"http://commonsenseatheism.com/\">a philosophy blog</a> and spends most of his spare time doing philosophy, so let me explain myself. (Warning: broad generalizations ahead! There are exceptions.)</p><h2 id=\"Failed_methods\">Failed methods</h2><p>Large swaths of philosophy (e.g. <a href=\"http://en.wikipedia.org/wiki/Continental_philosophy\">continental</a> and <a href=\"http://en.wikipedia.org/wiki/Postmodern_philosophy\">postmodern</a> philosophy) often don't even <em>try</em> to be clear, rigorous, or scientifically respectable. This is philosophy of the \"Uncle Joe's musings on the meaning of life\" sort, except that it's <a href=\"http://el-prod.baylor.edu/certain_doubts/?p=453\">dressed up</a> in big words and long footnotes. You will occasionally stumble upon an <em>argument</em>, but it falls prey to <a href=\"https://www.lesserwrong.com/lw/td/magical_categories/\">magical categories</a> and <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">language confusions</a> and <a href=\"https://www.lesserwrong.com/lw/on/reductionism/\">non-natural hypotheses</a>. You may also stumble upon science or math, but they are used to 'prove' things <a href=\"http://richarddawkins.net/articles/824-postmodernism-disrobed\">irrelevant</a> to the actual scientific data or the equations used.</p><p><a href=\"http://commonsenseatheism.com/?p=13499\">Analytic</a> philosophy is clearer, more rigorous, and better with math and science, but only does a slightly better job of avoiding magical categories, language confusions, and non-natural hypotheses. Moreover, its central tool is <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/#non-quine\">intuition</a>, and this displays a near-total ignorance of <a href=\"http://www.amazon.com/Kluge-Haphazard-Evolution-Human-Mind/dp/054723824X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">how</a> <a href=\"http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">brains</a> <a href=\"http://www.amazon.com/Foundations-Neuroeconomic-Analysis-Paul-Glimcher/dp/0199744254/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">work</a>. As <a href=\"http://en.wikipedia.org/wiki/Michael_Vassar\">Michael Vassar</a> observes, philosophers are \"spectacularly bad\" at understanding that their intuitions are <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">generated by cognitive algorithms</a>.</p><h2 id=\"A_diseased_discipline\">A diseased discipline</h2><p>What about <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy\">Quinean naturalists</a>? Many of them at <em>least</em> understand the basics: that <a href=\"https://www.lesserwrong.com/lw/on/reductionism/\">things are made of atoms</a>, that many questions don't need to be answered but instead <a href=\"https://www.lesserwrong.com/lw/of/dissolving_the_question/\">dissolved</a>, that <a href=\"https://www<em>.lesserwr</em>ong.com/lw/k2/a_priori/\">the brain is not an a priori truth factory</a>, that <a href=\"https://www.lesserwrong.com/lw/no/how_an_algorithm_feels_from_inside/\">intuitions come from cognitive algorithms</a>, that <a href=\"http://wiki.lesswrong.com/wiki/Bias\">humans are loaded with bias</a>, that <a href=\"https://www.lesserwrong.com/lw/od/37_ways_that_words_can_be_wrong/\">language is full of tricks</a>, and that <a href=\"https://www.lesserwrong.com/lw/s0/where_recursive_justification_hits_bottom/\">justification rests</a> in <a href=\"https://www.lesserwrong.com/lw/jm/the_lens_that_sees_its_flaws/\">the lens that can see its flaws</a>. Some of them are even <a href=\"http://commonsenseatheism.com/?p=13156\">Bayesians</a>.</p><p>Like I said, a few naturalistic philosophers are doing <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/3qe4\">some useful work</a>. But the signal-to-noise ratio is <em>much</em> lower even in naturalistic philosophy than it is in, say, behavioral economics or cognitive neuroscience or artificial intelligence or statistics. Why? Here are some hypotheses, based on my thousands of hours in the literature:</p><ol><li>Many philosophers have been infected (often by <a href=\"http://en.wikipedia.org/wiki/Philosophical_Investigations\">later Wittgenstein</a>) with the idea that philosophy is <em>supposed</em> to be useless. If it's useful, then it's science or math or something else, but not philosophy. Michael Bishop <a href=\"http://commonsenseatheism.com/?p=10553\">says</a> a common complaint from his colleagues about <a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">his 2004 book</a> is that it is <em>too useful</em>.</li><li>Most philosophers <em>don't</em> understand the basics, so naturalists spend much of their time coming up with new ways to argue that people are made of atoms and intuitions don't trump science. They fight beside the poor atheistic philosophers who keep coming up with <a href=\"http://www.amazon.com/Logic-Theism-Arguments-Against-Beliefs/dp/0521108667/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">new</a> <a href=\"http://www.amazon.com/Arguing-about-Gods-Graham-Oppy/dp/0521122643/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">ways</a> to argue that the universe was not created by someone's invisible magical friend.</li><li>Philosophy has grown into an abnormally backward-looking discipline. Scientists like to put their work in the context of what old dead guys said, too, but philosophers have a real <em>fetish</em> for it. Even naturalists spend a fair amount of time re-interpreting Hume and Dewey yet again.</li><li>Because they were trained in traditional philosophical ideas, arguments, and frames of mind, naturalists will <a href=\"https://www.lesserwrong.com/lw/j7/anchoring_and_adjustment/\">anchor and adjust</a> from traditional philosophy when they make progress, rather than scrapping the whole mess and starting from scratch with a correct understanding of language, physics, and cognitive science. Sometimes, philosophical work is useful to build from: Judea Pearl's triumphant <a href=\"http://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">work on causality</a> built on earlier counterfactual accounts of causality from philosophy. Other times, it's best to ignore the past confusions. Eliezer made most of his philosophical progress on his own, in order to solve problems in AI, and only later looked around in philosophy to see which standard position his own theory was most similar to.</li><li>Many naturalists aren't trained in cognitive science or AI. Cognitive science is essential because the tool we use to philosophize is the brain, and if you don't know how your tool works then you'll use it poorly. AI is useful because it keeps you honest: you can't write confused concepts or non-natural hypotheses in a programming language.</li><li>Mainstream philosophy publishing favors the established positions and arguments. You're more likely to get published if you can write about how intuitions are useless in solving Gettier problems (which is a confused set of non-problems anyway) than if you write about how to make a superintelligent machine preserve its utility function across millions of self-modifications.</li><li>Even much of the <em>useful</em> work naturalistic philosophers do is not at the cutting-edge. Chalmers' <a href=\"https://www.lesserwrong.com/lw/42l/david_chalmers_the_singularity_a_philosophical/\">update</a> for I.J. Good's 'intelligence explosion' argument is the best one-stop summary available, but it doesn't get as far as the <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">Hanson-Yudkowsky AI-Foom debate</a> in 2008 did. Talbot (<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Talbot-How-to-use-intuitions-in-philosophy.pdf\">2009</a>) and Bishop &amp; Trout (<a href=\"http://www.amazon.com/Epistemology-Psychology-Judgment-Michael-Bishop/dp/0195162307/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">2004</a>) provide handy summaries of much of the heuristics and biases literature, just like Eliezer has so usefully done on Less Wrong, but of course this isn't cutting edge. You could always just read it in the primary literature by Kahneman and Tversky and others.</li></ol><p>Of course, there <em>is</em> mainstream philosophy that is both good and cutting-edge: the work of <a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a> and <a href=\"http://ase.tufts.edu/cogstud/incbios/dennettd/dennettd.htm\">Daniel Dennett</a> stands out. And of course there <em>is</em> a role for those who keep arguing for atheism and reductionism and so on. I was a fundamentalist Christian <a href=\"http://commonsenseatheism.com/?p=12\">until</a> I read some contemporary atheistic philosophy, so that kind of work definitely does some good.</p><p>But if you're looking to solve cutting-edge problems, mainstream philosophy is one of the <em>last</em> places you should look. Try to find the answer in the cognitive science or AI literature first, or try to solve the problem by applying rationalist thinking: <a href=\"https://www.lesserwrong.com/lw/2as/diseased_thinking_dissolving_questions_about/\">like this</a>.</p><p>Swimming the murky waters of mainstream philosophy is perhaps a job best left for those who already spent several years studying it - that is, people like <em>me</em>. I already know what things are called and where to look, and I have an efficient filter for skipping past the 95% of philosophy that isn't useful to me. And hopefully my rationalist training will protect me from picking up bad habits of thought.</p><h1 id=\"Philosophy__the_way_forward\">Philosophy: the way forward</h1><p>Unfortunately, many important problems are fundamentally <em>philosophical</em> problems. Philosophy itself is unavoidable. How can we proceed?</p><p>First, we must remain vigilant with our rationality training. It is not easy to overcome millions of years of brain evolution, and as long as you are human there is no final victory. You will always wake up the next morning as <em>homo sapiens</em>.</p><p>Second, if you want to contribute to cutting-edge problems, even ones that seem philosophical, it's far more productive to study math and science than it is to study philosophy. You'll learn more in math and science, and your learning will be of a higher quality. Ask a fellow rationalist who is knowledgeable about philosophy what the standard positions and arguments in philosophy are on your topic. If any of them seem <em>really</em> useful, grab those particular works and read them. But again: you're probably better off trying to solve the problem by thinking like a cognitive scientist or an AI programmer than by ingesting mainstream philosophy.</p><p>However, I must say that I wish so much of Eliezer's cutting-edge work wasn't spread out across hundreds of Less Wrong blog posts and long SIAI articles written in with an idiosyncratic style and vocabulary. I would rather these ideas were written in standard academic form, even if they transcended the standard game of mainstream philosophy.</p><p>But it's one thing to complain; another to offer solutions. So let me tell you what I think cutting-edge philosophy should be. As you might expect, my vision is to combine what's good in LW-style philosophy with what's good in mainstream philosophy, and toss out the rest:</p><ol><li>Write short articles. One or two major ideas or arguments per article, maximum. Try to keep each article under 20 pages. It's hard to follow a <a href=\"http://intelligence.org/upload/TDT-v01o.pdf\">hundred-page argument</a>.</li><li>Open each article by explaining the context and goals of the article (even if you cover mostly the same ground in the opening of 5 other articles). What topic are you discussing? Which problem do you want to solve? What have other people said about the problem? What will you accomplish in the paper? Introduce key terms, cite standard sources and positions on the problem you'll be discussing, even if you disagree with them.</li><li>If possible, use the standard terms in the field. If the standard terms are flawed, explain why they are flawed and then introduce your new terms in that context so everybody knows what you're talking about. This requires that you research your topic so you know what the standard terms and positions <em>are</em>. If you're talking about a problem in cognitive science, you'll need to read cognitive science literature. If you're talking about a problem in social science, you'll need to read social science literature. If you're talking about a problem in epistemology or morality, you'll need to read philosophy.</li><li>Write as clearly and simply as possible. Organize the paper with lots of heading and subheadings. Put in lots of 'hand-holding' sentences to help your reader along: explain the point of the previous section, then explain why the next section is necessary, etc. Patiently guide your reader through every step of the argument, especially if it is long and complicated.</li><li>Always cite the relevant literature. If you <a href=\"http://intelligence.org/upload/artificial-intelligence-risk.pdf\">can't find</a> much work relevant to your topic, you almost certainly <a href=\"https://www.lesserwrong.com/lw/3m3/the_neglected_virtue_of_scholarship/\">haven't looked hard enough</a>. Citing the relevant literature not only lends weight to your argument, but also enables the reader to track down and examine the ideas or claims you are discussing. Being lazy with your citations is a sure way to frustrate precisely those readers who care enough to read your paper closely.</li><li>Think like a cognitive scientist and AI programmer. Watch out for biases. Avoid magical categories and language confusions and non-natural hypotheses. Look at your intuitions from the outside, as cognitive algorithms. Update your beliefs in response to evidence. [<strong>This one is central. This is LW-style philosophy</strong>.]</li><li>Use your rationality training, but avoid language that is unique to Less Wrong. Nearly all these terms and ideas have standard names outside of Less Wrong (though in many cases Less Wrong already uses the standard language).</li><li>Don't dwell too long on what old dead guys said, nor on semantic debates. Dissolve semantic problems and move on.</li><li>Conclude with a summary of your paper, and suggest directions for future research.</li><li>Ask fellow rationalists to read drafts of your article, then re-write. Then rewrite again, adding more citations and hand-holding sentences.</li><li>Format the article attractively. A well-chosen font makes for an <a href=\"http://en.wikipedia.org/wiki/Typography#Readability_and_legibility\">easier read</a>. Then publish (in a journal or elsewhere).</li></ol><p>Note that this is <em>not</em> just my vision of <a href=\"https://www.<em>lesserwrong</em>.com/lw/4r1/how_siai_could_publish_in_mainstream_cognitive/\">how to get published in journals</a>. It's my vision of <em>how to do philosophy</em>.</p><p>Meeting journals standards is <em>not</em> the most important reason to follow the suggestions above. Write short articles because they're easier to follow. Open with the context and goals of your article because that makes it easier to understand, and lets people decide right away whether your article fits their interests. Use standard terms so that people already familiar with the topic aren't annoyed at having to learn a whole new vocabulary just to read your paper. Cite the relevant positions and arguments so that people have a sense of the context of what you're doing, and can look up what other people have said on the topic. Write clearly and simply and with much organization so that your paper is not wearying to read. Write lots of hand-holding sentences because we always communicate less effectively then we <em>thought</em> we did. Cite the relevant literature as much as possible to assist your most careful readers in getting the information they want to know. Use your rationality training to remain sharp at all times. And so on.</p><p><em>That</em> is what cutting-edge philosophy could look like, I think.</p><p></p><p>Next post: <a href=\"https://www.lesserwrong.com/lw/531/how_you_make_judgments_the_elephant_and_its_rider/\">How You Make Judgments</a></p><p>Previous post: <a href=\"https://www.lesserwrong.com/lw/4vr/less_wrong_rationality_and_mainstream_philosophy/\">Less Wrong Rationality and Mainstream Philosophy</a></p><p></p><p></p>", "sections": [{"title": "Failed methods", "anchor": "Failed_methods", "level": 2}, {"title": "A diseased discipline", "anchor": "A_diseased_discipline", "level": 2}, {"title": "Philosophy: the way forward", "anchor": "Philosophy__the_way_forward", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "448 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 448, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["vzLrQaGPa9DNCpuZz", "oTX2LXHqXqYg2u4g6", "FaJaCgqBKphrDzDSj", "4ZzefKQwAtMo5yp99", "PoDAyQMWEXBBBEJ5P", "tPqQdLCuxanjhoaNs", "yA4gF5KrboK2m2Xu7", "Mc6QcrsbH5NRXbCRX", "C8nEXTcjZb9oauTCW", "46qnWRSR7L2eyNbMA", "bMkCEZoBNhgRBtzoj", "Sh4HPbqRDJsbB9ENK", "895quRDaK6gR2rM82", "64FdKLwmea8MCLWkE", "du395YvCnQXBPSJax"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2011-03-28T19:31:58.441Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-28T20:36:26.967Z", "modifiedAt": null, "url": null, "title": "Creationism's effect on the progress of our understanding of evolution", "slug": "creationism-s-effect-on-the-progress-of-our-understanding-of", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.065Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlexMennen", "createdAt": "2009-11-27T18:24:19.500Z", "isAdmin": false, "displayName": "AlexMennen"}, "userId": "KgzPEGnYWvKDmWuNY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iot6k4D5zkCvNwFKQ/creationism-s-effect-on-the-progress-of-our-understanding-of", "pageUrlRelative": "/posts/iot6k4D5zkCvNwFKQ/creationism-s-effect-on-the-progress-of-our-understanding-of", "linkUrl": "https://www.lesswrong.com/posts/iot6k4D5zkCvNwFKQ/creationism-s-effect-on-the-progress-of-our-understanding-of", "postedAtFormatted": "Monday, March 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Creationism's%20effect%20on%20the%20progress%20of%20our%20understanding%20of%20evolution&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACreationism's%20effect%20on%20the%20progress%20of%20our%20understanding%20of%20evolution%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiot6k4D5zkCvNwFKQ%2Fcreationism-s-effect-on-the-progress-of-our-understanding-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Creationism's%20effect%20on%20the%20progress%20of%20our%20understanding%20of%20evolution%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiot6k4D5zkCvNwFKQ%2Fcreationism-s-effect-on-the-progress-of-our-understanding-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fiot6k4D5zkCvNwFKQ%2Fcreationism-s-effect-on-the-progress-of-our-understanding-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 267, "htmlBody": "<p><a href=\"http://en.wikipedia.org/wiki/Lynn_Margulis\">Lynn Margulis</a> argues that natural selection cannot provide a powerful enough evolutionary force to account for the punctuated equilibrium demonstrated in the fossil record. She proposes as an alternative that evolution is driven by changes in symbiotic relationships. I'm not a biologist, and I don't understand what exactly her theory means, so I'm not going to try to argue for or against it, but it got me thinking:</p>\n<p>Evolutionary biologists cannot afford to let Margulis's theory become well-known and accepted as a mainstream theory, because that would create a rift in the pro-evolution camp, and creationists would be able to exploit this by combining Margulis's argument that natural selection cannot account for punctuated equilibrium with arguments by Neo-Darwinists against Margulis's theory to support their claim that evolution is false. This would be effective because many people would not understand that \"we do not understand everything about how evolution works\" does not imply \"creationism is correct\". Thus, many evolutionary biologists might feel that they have to be very careful to look like they do know everything about how evolution works. This could make it more difficult for them to spot aspects in which their assumptions about evolution are mistaken. Maybe the biggest damage caused by creationism is that it suppresses legitimate criticism of the current accepted models of evolution, besides spreading false information to the general public.</p>\n<p>Again, I'm not arguing in favor of Margulis's theory in particular, but the statement \"There exists at least one false fact about evolutionary biology that is accepted as true by a consensus of researchers in that field\" seems fairly likely to be true.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iot6k4D5zkCvNwFKQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 0, "extendedScore": null, "score": 6e-06, "legacy": true, "legacyId": "6487", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-28T22:07:11.820Z", "modifiedAt": null, "url": null, "title": "Claremont Meetup", "slug": "claremont-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:07.768Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fjXRjEMi5iSikMuRt/claremont-meetup", "pageUrlRelative": "/posts/fjXRjEMi5iSikMuRt/claremont-meetup", "linkUrl": "https://www.lesswrong.com/posts/fjXRjEMi5iSikMuRt/claremont-meetup", "postedAtFormatted": "Monday, March 28th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Claremont%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AClaremont%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfjXRjEMi5iSikMuRt%2Fclaremont-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Claremont%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfjXRjEMi5iSikMuRt%2Fclaremont-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfjXRjEMi5iSikMuRt%2Fclaremont-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 68, "htmlBody": "<p>I got into Harvey Mudd, and will be attending the Admitted Students Program from April 10th-11th.<br /><br />Anyone want to do a Claremont Meetup on those dates? Or the 12th.<br /><br />I didn't post this on the front page because I'm not actually in Claremont, nor do I know people there, nor do I even know where would be a good place/time to meet.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fjXRjEMi5iSikMuRt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 6.955600556309202e-07, "legacy": true, "legacyId": "6488", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T01:10:11.929Z", "modifiedAt": null, "url": null, "title": "Q: Experiment on blaming the one you hurt?", "slug": "q-experiment-on-blaming-the-one-you-hurt", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:08.380Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zyTq2EfQoYSThLZiP/q-experiment-on-blaming-the-one-you-hurt", "pageUrlRelative": "/posts/zyTq2EfQoYSThLZiP/q-experiment-on-blaming-the-one-you-hurt", "linkUrl": "https://www.lesswrong.com/posts/zyTq2EfQoYSThLZiP/q-experiment-on-blaming-the-one-you-hurt", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Q%3A%20Experiment%20on%20blaming%20the%20one%20you%20hurt%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQ%3A%20Experiment%20on%20blaming%20the%20one%20you%20hurt%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzyTq2EfQoYSThLZiP%2Fq-experiment-on-blaming-the-one-you-hurt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Q%3A%20Experiment%20on%20blaming%20the%20one%20you%20hurt%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzyTq2EfQoYSThLZiP%2Fq-experiment-on-blaming-the-one-you-hurt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzyTq2EfQoYSThLZiP%2Fq-experiment-on-blaming-the-one-you-hurt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 46, "htmlBody": "<p>For bookwriting - Does anyone have a quick ref for experiments where the subject is forced to hurt someone, and then evaluates that person negatively (\"The victim deserved it\")?&nbsp; I can't recall the Google keyword; it doesn't show up for \"blaming the victim\" or \"just-world hypothesis\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zyTq2EfQoYSThLZiP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 6, "extendedScore": null, "score": 6.956106316130304e-07, "legacy": true, "legacyId": "6489", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T03:22:52.721Z", "modifiedAt": null, "url": null, "title": "Life hacks from the dark side", "slug": "life-hacks-from-the-dark-side", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:32.586Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ata", "createdAt": "2009-07-20T22:13:53.102Z", "isAdmin": false, "displayName": "ata"}, "userId": "KppHkGEqTNeDaGJTc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DD8M8Jk4BqT28bbQd/life-hacks-from-the-dark-side", "pageUrlRelative": "/posts/DD8M8Jk4BqT28bbQd/life-hacks-from-the-dark-side", "linkUrl": "https://www.lesswrong.com/posts/DD8M8Jk4BqT28bbQd/life-hacks-from-the-dark-side", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Life%20hacks%20from%20the%20dark%20side&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALife%20hacks%20from%20the%20dark%20side%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDD8M8Jk4BqT28bbQd%2Flife-hacks-from-the-dark-side%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Life%20hacks%20from%20the%20dark%20side%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDD8M8Jk4BqT28bbQd%2Flife-hacks-from-the-dark-side", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDD8M8Jk4BqT28bbQd%2Flife-hacks-from-the-dark-side", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 615, "htmlBody": "<div style=\"margin: 0 100pt; font-style: italic\">\n<p>&ldquo;So, Lone Starr, now you see that evil will always triumph, because good is dumb.&rdquo;</p>\n<p>&mdash; Dark Helmet</p>\n</div>\n<p>In a recent article, the unusually well-researched comedy site Cracked.com discussed &ldquo;<a href=\"http://www.cracked.com/article_18956_5-scientific-reasons-dark-side-will-always-win.html\">5 scientific reasons the dark side will always win</a>,&rdquo; including:</p>\n<ul>\n<li>Clenching your fists and thinking evil thoughts can increase strength and willpower. (Hung &amp; Labroo 2011, Schubert 2004, Gray 2010)</li>\n<li>Particular &ldquo;power poses&rdquo; raise testosterone and lower cortisol levels (in both men and women) and increase feelings of power and tolerance for risk. (Carney et al. 2010)</li>\n<li>Boosts in pride can allow you to work longer and harder on &ldquo;effortful and hedonically negative&rdquo; tasks. (Williams &amp; DeSteno 2008)</li>\n<li>Negative moods can decrease gullibility, increase persuasiveness and social influence, and improve the accuracy of eyewitness recollections. (Forgas 2007, Forgas 2008, Forgas et al. 2005)</li>\n</ul>\n<p>Perhaps, then, it could be useful to intentionally cultivate a Mysterious Dark Side, or just ask yourself &ldquo;What would Voldemort do?&rdquo; once in a while (please do not murder anyone). I&rsquo;m definitely going to be giving some of these a try; fist-clenching and power-posing are easy, and as a source of evil thoughts and pride, I already have a dark lord alter-ego I could channel when necessary (I&rsquo;ll probably need to flesh out his character a bit more than I have so far).</p>\n<p>The Cracked.com article mostly links to news stories, so, for your convenience, here are the original papers they refer to:</p>\n<ul>\n<li>\n<p>Frank, Mark G. and Gilovich, Thomas (1988). &ldquo;<a href=\"http://people.uncw.edu/tothj/PSY355/Frank-Black%20Uniforms-JPSP-1988.pdf\">The Dark Side of Self- and Social Perception: Black Uniforms and Aggression in Professional Sports.</a>&rdquo; <em>Journal of Personality and Social Psychology</em>, 54(1), 74-85.</p>\n</li>\n<li>\n<p>Hung, Iris W. and Labroo, Aparna A. (2011). &ldquo;<a href=\"http://atlas.ai/swag/hung-labroo-2011.pdf\">From Firm Muscles to Firm Willpower: Understanding the Role of Embodied Cognition in Self-Regulation.</a>&rdquo; <em>Journal of Consumer Research</em>, 37(6), 1046-1064.</p>\n</li>\n<li>\n<p>Gray, Kurt (2010). &ldquo;<a href=\"http://www.mpm.umd.edu/Gray%20-%202010%20-%20Moral%20Transformation.pdf\">Moral Transformation: Good and Evil Turn the Weak Into the Mighty.</a>&rdquo; <em>Social Psychological and Personality Science</em>, 1(3), 253-258.</p>\n</li>\n<li>\n<p>Carney, Dana R., Cuddy, Amy J.C., and Yap, Andy J. (2010). &ldquo;<a href=\"http://atlas.ai/swag/carney-et-al-2010.pdf\">Power Posing: Brief Nonverbal Displays Affect Neuroendocrine Levels and Risk Tolerance.</a>&rdquo; <em>Psychological Science</em>, 21(10), 1363&ndash;1368.</p>\n</li>\n<li>\n<p>Schubert, Thomas W. (2004). &ldquo;<a href=\"http://www.igroup.org/schubert/papers/schubert_pspb04.pdf\">The Power In Your Hand: Gender Differences In Bodily Feedback From Making a Fist.</a>&rdquo; <em>Personality and Social Psychology Bulletin</em>, 30(6), 757-769.</p>\n</li>\n<li>\n<p>Tracy, Jessica L. and Robins, Richard W. (2008). &ldquo;<a href=\"http://ubc-emotionlab.ca/wp-content/images/2008/03/tracy-robins-jpsp-2008-pride-culture.pdf\">The Nonverbal Expression of Pride: Evidence for Cross-Cultural Recognition.</a>&rdquo; <em>Journal of Personality and Social Psychology</em>, 94(3), 516-530.</p>\n</li>\n<li>\n<p>Williams, Lisa A. and DeSteno, David (2008). &ldquo;<a href=\"http://www.socialemotions.org/page5/files/Williams.DeSteno.2008.pdf\">Pride and Perseverance: The Motivational Role of Pride.</a>&rdquo; <em>Journal of Personality and Social Psychology</em>, 94(6), 1007&ndash;1017.</p>\n</li>\n<li>\n<p>Williams, Lisa A. and DeSteno, David (2009). &ldquo;<a href=\"http://www.socialemotions.org/page5/files/Williams.DeSteno.2009.pdf\">Pride: Adaptive Social Emotion or Seventh Sin?</a>&rdquo; <em>Psychological Science</em>, 20(3), 284-288.</p>\n</li>\n<li>\n<p>Forgas, Joseph P. (2007). &ldquo;<a href=\"http://www.elsevier.com/authored_subject_sections/S05/S05_361/misc/JESP_Forgas2.pdf\">When sad is better than happy: Negative affect can improve the quality and effectiveness of persuasive messages and social influence strategies.</a>&rdquo; <em>Journal of Experimental Social Psychology</em>, 43(4), 513-528.</p>\n</li>\n<li>\n<p>Forgas, Joseph P. and East, Rebekah. (2008). &ldquo;<a href=\"http://atlas.ai/swag/forgas-east-2008.pdf\">On being happy and gullible: Mood effects on skepticism and the detection of deception.</a>&rdquo; <em>Journal of Experimental Social Psychology</em>, 44(5), 1362-1367.</p>\n</li>\n<li>\n<p>Forgas, Joseph P., Laham, Simon M., and Vargas, Patrick T. (2005). &ldquo;<a href=\"http://www.elsevier.com/authored_subject_sections/S05/S05_361/misc/JESP_Forgas.pdf\">Mood effects on eyewitness memory: Affective influences on susceptibility to misinformation.</a>&rdquo; <em>Journal of Experimental Social Psychology</em>, 41(6), 574-588.</p>\n</li>\n<li>\n<p>Wolff, Sarah E. and Puts, David A. (2010). &ldquo;<a href=\"http://www.putslab.psu.edu/pdfs/wolff_bes.pdf\">Vocal masculinity is a robust dominance signal in men.</a>&rdquo; <em>Behavioral Ecology and Sociobiology</em>, 64(10), 1673-1683.</p>\n</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DD8M8Jk4BqT28bbQd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 27, "extendedScore": null, "score": 6.956473042427391e-07, "legacy": true, "legacyId": "6491", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T05:40:26.696Z", "modifiedAt": null, "url": null, "title": "12-year old challenges the Big Bang", "slug": "12-year-old-challenges-the-big-bang", "viewCount": null, "lastCommentedAt": "2017-06-17T04:14:30.887Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "YTcLqiv4mD6QeH3Ap", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BawYi7jNkxhzhhata/12-year-old-challenges-the-big-bang", "pageUrlRelative": "/posts/BawYi7jNkxhzhhata/12-year-old-challenges-the-big-bang", "linkUrl": "https://www.lesswrong.com/posts/BawYi7jNkxhzhhata/12-year-old-challenges-the-big-bang", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2012-year%20old%20challenges%20the%20Big%20Bang&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A12-year%20old%20challenges%20the%20Big%20Bang%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBawYi7jNkxhzhhata%2F12-year-old-challenges-the-big-bang%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=12-year%20old%20challenges%20the%20Big%20Bang%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBawYi7jNkxhzhhata%2F12-year-old-challenges-the-big-bang", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBawYi7jNkxhzhhata%2F12-year-old-challenges-the-big-bang", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 154, "htmlBody": "<p>I thought this may be of interest to the LW community.&nbsp;<a href=\"http://en.wikipedia.org/wiki/Jacob_Barnett\">Jacob Barnett</a>&nbsp;is a 12-year old male who taught himself all of high school math (algebra through calculus), has a currently scored math IQ of 170 (<a href=\"/tag/whatintelligencetestsmiss\">for what that's worth</a>) and is currently on track to become a researcher of astrophysics. His current major news worthy claim-to-fame (aside from being really young): The Big Bang Theory is currently incorrect (I believe the article states he has something about a lack of carbon in the model), and he's planning to develop a new theory. <br /><br />I haven't learned anything serious in physics, so I have nothing to note on his claim. I realize the news article cited puts him claim fairly generally, so I'll ask this: Can someone explain how elements are generally modeled to have formed from the big bang? And is there anything that it Jacob may be missing in the current&nbsp;literature?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BawYi7jNkxhzhhata", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 3, "extendedScore": null, "score": 6.956853310505553e-07, "legacy": true, "legacyId": "6495", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T06:05:02.356Z", "modifiedAt": null, "url": null, "title": "HP:MoR Audio Book Pilot", "slug": "hp-mor-audio-book-pilot", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:19.846Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4jNSyjEHi8vbm7yiT/hp-mor-audio-book-pilot", "pageUrlRelative": "/posts/4jNSyjEHi8vbm7yiT/hp-mor-audio-book-pilot", "linkUrl": "https://www.lesswrong.com/posts/4jNSyjEHi8vbm7yiT/hp-mor-audio-book-pilot", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20HP%3AMoR%20Audio%20Book%20Pilot&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHP%3AMoR%20Audio%20Book%20Pilot%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4jNSyjEHi8vbm7yiT%2Fhp-mor-audio-book-pilot%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=HP%3AMoR%20Audio%20Book%20Pilot%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4jNSyjEHi8vbm7yiT%2Fhp-mor-audio-book-pilot", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4jNSyjEHi8vbm7yiT%2Fhp-mor-audio-book-pilot", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 314, "htmlBody": "<p>Like far too many people, I have a job that for decent chunks of my day doesn't require much concentration. I listen to various podcasts and ebooks to&nbsp;alleviate&nbsp;the boredom at these times, as well as to get me through my daily commute. I have several friends with plenty of audio-listening time, a fair bit of which is given to&nbsp;amateur&nbsp;podcasts (in the \"not getting paid for it\" sense), who have much less time available for straight reading. I have, on more than one occasion, thought \"Wouldn't it be great if Methods of Rationality was available in audio format?\"</p>\n<p>Well, now it is.</p>\n<p>At least, the first chapter is, in a \"testing the waters\" sort of way.</p>\n<p>If you have 17 minutes free and any interest, here's the file - http://www.filedropper.com/hpmorpilot</p>\n<p>I have one over-riding question to anyone/everyone: is this of any value? Would this be useful to anyone here, either personally, or to share with others? Would a spruced-up first chapter, and regular production of further chapters, be something you want more of?</p>\n<p>A closely-related follow-up question: if so - am I the right person to do this? Even \"acceptable\", I'm not shooting for perfection. Or is something about my voice/manner so grating I should stick to non-radio work.</p>\n<p>If the answer to these is \"yes\", then are there any comments/suggestions? I'm new to this recording thing. I got a decent mic and a pop-filter, and I've played around with the software a bit, but I'm still learning. I have noticed that I need to enunciate more, it turns out my \"can't win\" sounds just like my \"can win\". Further suggestions? I'm thinking of varying my pitch when different&nbsp;characters&nbsp;are talking to make it more apparent when dialog is switching back and forth, hopefully that won't be too cheesy.</p>\n<p>If people want more of this I'll get an actual server to host the files and make it available through iTunes as a podcast.</p>\n<p>Again:&nbsp;http://www.filedropper.com/hpmorpilot</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"yrg267i4a8EsgYAXp": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4jNSyjEHi8vbm7yiT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 24, "extendedScore": null, "score": 5.9e-05, "legacy": true, "legacyId": "6497", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T14:57:40.930Z", "modifiedAt": null, "url": null, "title": "London Hackday, this Friday, April 1st (No, this is not a joke)", "slug": "london-hackday-this-friday-april-1st-no-this-is-not-a-joke", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.603Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cyBkMoRYc5ozHk8gq/london-hackday-this-friday-april-1st-no-this-is-not-a-joke", "pageUrlRelative": "/posts/cyBkMoRYc5ozHk8gq/london-hackday-this-friday-april-1st-no-this-is-not-a-joke", "linkUrl": "https://www.lesswrong.com/posts/cyBkMoRYc5ozHk8gq/london-hackday-this-friday-april-1st-no-this-is-not-a-joke", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20London%20Hackday%2C%20this%20Friday%2C%20April%201st%20(No%2C%20this%20is%20not%20a%20joke)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALondon%20Hackday%2C%20this%20Friday%2C%20April%201st%20(No%2C%20this%20is%20not%20a%20joke)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcyBkMoRYc5ozHk8gq%2Flondon-hackday-this-friday-april-1st-no-this-is-not-a-joke%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=London%20Hackday%2C%20this%20Friday%2C%20April%201st%20(No%2C%20this%20is%20not%20a%20joke)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcyBkMoRYc5ozHk8gq%2Flondon-hackday-this-friday-april-1st-no-this-is-not-a-joke", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcyBkMoRYc5ozHk8gq%2Flondon-hackday-this-friday-april-1st-no-this-is-not-a-joke", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 167, "htmlBody": "<p><a id=\"more\"></a>This coming Friday, April 1st 2011, a few of us from London will be getting together to hack on some as yet unidentified project. The event will be held at the <a href=\"http://wiki.hackspace.org.uk/wiki/Laboratory_24/Getting_There\">London Hackspace</a>. We'll be starting at 10am and expect to be there for most of the day.</p>\n<p>We have <a href=\"/r/discussion/lw/4vu/project_ideas_for_the_london_hackday/\">quite</a> <a href=\"/r/discussion/lw/4wp/designing_serious_games_a_request_for_help/\">a few</a> suggestions and will probably spend the first hour of our meeting figuring out what to do. Being there early means you will be able to contribute in the direction the day will take. You're welcome to turn up later of course. There is no particular skill level required to attend, just a desire for hacking on things with others. Teaching each other is just as important as the actual outcome. Letting us know you're coming in advance will help us plan better.</p>\n<p>If you would like to be in the loop for future LessWrong events in London, send me with your e-mail via private message so I can add you to the LessWrong London mailing list.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cyBkMoRYc5ozHk8gq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 6.95839403296677e-07, "legacy": true, "legacyId": "6503", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["tQ5AxChGZz5RvWBD2", "mAK7ryHLq5PJqoXLN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T17:36:12.514Z", "modifiedAt": null, "url": null, "title": "John Baez Interviews with Eliezer (Parts 2 and 3)", "slug": "john-baez-interviews-with-eliezer-parts-2-and-3", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:30.294Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "multifoliaterose", "createdAt": "2010-06-13T08:56:10.885Z", "isAdmin": false, "displayName": "multifoliaterose"}, "userId": "747HfTZFyfTqGyoPM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2sTYE8DbTceNTsxbM/john-baez-interviews-with-eliezer-parts-2-and-3", "pageUrlRelative": "/posts/2sTYE8DbTceNTsxbM/john-baez-interviews-with-eliezer-parts-2-and-3", "linkUrl": "https://www.lesswrong.com/posts/2sTYE8DbTceNTsxbM/john-baez-interviews-with-eliezer-parts-2-and-3", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20John%20Baez%20Interviews%20with%20Eliezer%20(Parts%202%20and%203)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJohn%20Baez%20Interviews%20with%20Eliezer%20(Parts%202%20and%203)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2sTYE8DbTceNTsxbM%2Fjohn-baez-interviews-with-eliezer-parts-2-and-3%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=John%20Baez%20Interviews%20with%20Eliezer%20(Parts%202%20and%203)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2sTYE8DbTceNTsxbM%2Fjohn-baez-interviews-with-eliezer-parts-2-and-3", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2sTYE8DbTceNTsxbM%2Fjohn-baez-interviews-with-eliezer-parts-2-and-3", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 250, "htmlBody": "<p><a href=\"http://johncarlosbaez.wordpress.com/2011/03/07/this-weeks-finds-week-311/\">John Baez's This Week's Finds (Week 311)</a> [Part 1; added for convenience following Nancy Lebovitz's comment]</p>\n<p><a href=\"http://johncarlosbaez.wordpress.com/2011/03/14/this-weeks-finds-week-312/\">John Baez's This Week's Finds (Week 312)</a></p>\n<p><a href=\"http://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/\">John Baez's This Week's Finds (Week 313)</a></p>\n<p>I really like Eliezer's response to John Baez's last question in Week 313 about environmentalism vs. AI risks. I think it satisfactorily deflects much of the concern that I had when I wrote <a href=\"/lw/2lr/the_importance_of_selfdoubt/\">The Importance of Self-Doubt</a>.</p>\n<p>Eliezer says</p>\n<blockquote>\n<p>Anyway: In terms of expected utility maximization, even <em>large</em> probabilities of jumping the interval between a universe-history in which 95% of existing biological species survive Earth&rsquo;s 21st century, versus a universe-history where 80% of species survive, are just about impossible to trade off against <em>tiny</em> probabilities of jumping the interval between interesting universe-histories, versus boring ones where intelligent life goes extinct, or the wrong sort of AI self-improves.</p>\n</blockquote>\n<p>This is true as stated but ignores an important issue which is there is feedback between more mundane current events and the eventual potential extinction of the humane race. For example, the United States' involvement in Libya has a (small) influence on&nbsp; existential risk (I don't have an opinion as to what sort). Any impact on human society impact due to global warming has some influence on existential risk.</p>\n<p>Eliezer's points about comparative advantage and of existential risk <em>in principle</em> dominating all other considerations are valid, important, and well-made, but passing from principle to practice is very murky in the complex human world that we live in.</p>\n<p>Note also the points that I make in <a href=\"/lw/3aa/friendly_ai_research_and_taskification/\">Friendly AI Research and Taskification</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2sTYE8DbTceNTsxbM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 10, "extendedScore": null, "score": 6.958832458008646e-07, "legacy": true, "legacyId": "6504", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["AWZ7butnGwwqyeCuc", "7sxR8qLG6rqDht6aR"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T21:31:35.562Z", "modifiedAt": null, "url": null, "title": "Audio from Eliezer's talk at the Oxford Transhumanists", "slug": "audio-from-eliezer-s-talk-at-the-oxford-transhumanists", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:10.094Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6oGHjWt3rzyxCxbwh/audio-from-eliezer-s-talk-at-the-oxford-transhumanists", "pageUrlRelative": "/posts/6oGHjWt3rzyxCxbwh/audio-from-eliezer-s-talk-at-the-oxford-transhumanists", "linkUrl": "https://www.lesswrong.com/posts/6oGHjWt3rzyxCxbwh/audio-from-eliezer-s-talk-at-the-oxford-transhumanists", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Audio%20from%20Eliezer's%20talk%20at%20the%20Oxford%20Transhumanists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAudio%20from%20Eliezer's%20talk%20at%20the%20Oxford%20Transhumanists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6oGHjWt3rzyxCxbwh%2Faudio-from-eliezer-s-talk-at-the-oxford-transhumanists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Audio%20from%20Eliezer's%20talk%20at%20the%20Oxford%20Transhumanists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6oGHjWt3rzyxCxbwh%2Faudio-from-eliezer-s-talk-at-the-oxford-transhumanists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6oGHjWt3rzyxCxbwh%2Faudio-from-eliezer-s-talk-at-the-oxford-transhumanists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 48, "htmlBody": "<p>In January we hosted Eliezer at an Oxford Transhumanists meeting. He spoke about why AI is such an incredibly consequential consideration, over and above other technologies. This will not be new material for regular lesswrong readers. The recordings from Eliezer's talk, along with previous talks, are available at&nbsp;http://groupspaces.com/oxfordtranshumanists/pages/past-talks.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6oGHjWt3rzyxCxbwh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 13, "extendedScore": null, "score": 6.959483533041199e-07, "legacy": true, "legacyId": "6506", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-29T23:40:26.774Z", "modifiedAt": null, "url": null, "title": "Towards an Algorithm for (Human) Self-Modification", "slug": "towards-an-algorithm-for-human-self-modification", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.544Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "moridinamael", "createdAt": "2011-01-20T18:55:32.068Z", "isAdmin": false, "displayName": "moridinamael"}, "userId": "sWA9eDCM9AgFaZho8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2qMgQCNSooaG8XThf/towards-an-algorithm-for-human-self-modification", "pageUrlRelative": "/posts/2qMgQCNSooaG8XThf/towards-an-algorithm-for-human-self-modification", "linkUrl": "https://www.lesswrong.com/posts/2qMgQCNSooaG8XThf/towards-an-algorithm-for-human-self-modification", "postedAtFormatted": "Tuesday, March 29th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Towards%20an%20Algorithm%20for%20(Human)%20Self-Modification&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATowards%20an%20Algorithm%20for%20(Human)%20Self-Modification%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qMgQCNSooaG8XThf%2Ftowards-an-algorithm-for-human-self-modification%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Towards%20an%20Algorithm%20for%20(Human)%20Self-Modification%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qMgQCNSooaG8XThf%2Ftowards-an-algorithm-for-human-self-modification", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2qMgQCNSooaG8XThf%2Ftowards-an-algorithm-for-human-self-modification", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 478, "htmlBody": "<p>LessWrong is wonderful.&nbsp; Life-changing.&nbsp; Best thing that ever happened to me.</p>\r\n<p>But it's not really <em>enough</em> to make one a rationalist, is it?&nbsp; I don't assimilate or even remember all of the knowledge contained in what I read, and I certainly don't dynamically incorporate it into my life-strategy.</p>\r\n<p>Say you want your computer to be able to open Microsoft Word files.&nbsp; In order to do this, you do not upload a PDF which contains a description of how Microsoft Word works.&nbsp; No, you <em>install</em> the program and then you run the program.</p>\r\n<p>Over several months of reading LessWrong I found myself wishing I had (a) computer program(s) that could <em>train</em> me to be a rationalist instead of a website that <em>told</em> me about how to be a rationalist.&nbsp; I would read an article with a tremendous sense of excitement, thinking to myself, \"This is it, I have to implement this insight into my life.&nbsp; This is a change that I <em>must</em> realize.\"&nbsp; But I would inevitably hit a mental wall when I saw that just knowing that something was a good idea didn't actually rewire my brain toward better cognitive habits.</p>\r\n<p>I wanted a rationality <em>installer</em>.</p>\r\n<p>I found myself in the midst of a personal crisis.&nbsp; I came to suspect that the reason for my unhappiness and akrasia was that my goals and my actions had become decoupled - I just couldn't figure out <em>where,</em> or <em>how</em>.</p>\r\n<p>So I set out to make a program that would help me organize what my actual terminal goals and values are, and then help me causally connect my day-to-day activities with these goals and values.&nbsp; The idea was to create a kind of tree with end-goals at the parents and daily tasks as the children.&nbsp; The resulting application was not very user-friendly, but it still <em>worked</em>.&nbsp;</p>\r\n<p>With the help of my program, I saw that a year ago, I was very happy with my life because all the activities I pursued on a daily basis were very high-utility and directly connected to the achievement of&nbsp;my goals.&nbsp; I saw that I had recently formed a new long-term goal, the existence of which altered my utility function, but I had not altered my life to sufficiently accommodate this new goal.&nbsp; I made some changes in my life which I thought were going to be painful sacrifices, but ended up feeling exactly right once I crossed the threshold.&nbsp; It shocked me how quickly I felt better, how completely I returned to \"normal.\"</p>\r\n<p>And I thought to myself, hey, why do our cognitive algorithms have to actually be inside our heads?&nbsp; I implemented this one into C++ and it helped me sort out something which was just frustrating and painful and confusing when I tried to manage it on my own.</p>\r\n<p>What other rationality techniques deserve to be coded into \"rationality assistant applications?\"</p>\r\n<p>(And how much of a desire would there be for such products?)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"WqLn4pAWi5hn6McHQ": 1, "TkZ7MFwCi4D63LJ5n": 1, "Ng8Gice9KNkncxqcj": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2qMgQCNSooaG8XThf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 37, "extendedScore": null, "score": 6.959839988833143e-07, "legacy": true, "legacyId": "6507", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T00:51:11.793Z", "modifiedAt": null, "url": null, "title": "Ithaca Meetup?", "slug": "ithaca-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:33.834Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jB5CFa3Q8HKEucWX4/ithaca-meetup", "pageUrlRelative": "/posts/jB5CFa3Q8HKEucWX4/ithaca-meetup", "linkUrl": "https://www.lesswrong.com/posts/jB5CFa3Q8HKEucWX4/ithaca-meetup", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ithaca%20Meetup%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIthaca%20Meetup%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjB5CFa3Q8HKEucWX4%2Fithaca-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ithaca%20Meetup%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjB5CFa3Q8HKEucWX4%2Fithaca-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjB5CFa3Q8HKEucWX4%2Fithaca-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 33, "htmlBody": "<p>I'm at Cornell University in the rather small town of Ithaca, NY. Are there any rationalists around here who might be interested in a meetup / is there a meetup already taking place?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jB5CFa3Q8HKEucWX4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 6.960035723671241e-07, "legacy": true, "legacyId": "6508", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T02:50:36.129Z", "modifiedAt": null, "url": null, "title": "Timescales Matter", "slug": "timescales-matter", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:20.380Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hRGjjHma3JYcGavt7/timescales-matter", "pageUrlRelative": "/posts/hRGjjHma3JYcGavt7/timescales-matter", "linkUrl": "https://www.lesswrong.com/posts/hRGjjHma3JYcGavt7/timescales-matter", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Timescales%20Matter&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATimescales%20Matter%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRGjjHma3JYcGavt7%2Ftimescales-matter%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Timescales%20Matter%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRGjjHma3JYcGavt7%2Ftimescales-matter", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhRGjjHma3JYcGavt7%2Ftimescales-matter", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 386, "htmlBody": "<p>In an <a href=\"http://johncarlosbaez.wordpress.com/2011/03/25/this-weeks-finds-week-313/\">interview with John Baez</a>, Eliezer responds:</p>\n<blockquote>\n<p>I&rsquo;ll try to answer the question about timescales, but first let me explain in some detail why I don&rsquo;t think the decision should be dominated by that question.</p>\n</blockquote>\n<p>He was in part addressing the tradeoff between environmental work and work on technology related to AGI or other existential risks. In this context I agree with his position.</p>\n<p>But more broadly, as a person setting out into the wold and deciding what I should do with each moment, the question about timescales is one of the most important issues bearing on my decision and my uncertainty about it (coupled with the difficulty of acquiring evidence) is almost physically painful.</p>\n<p>If AGI is likely in the next couple of decades (I am rather skeptical) then long-term activism or outreach are probably pointless. If AGI is not likely within this century (which also seems unlikely) then working on AGI is probably pointless.</p>\n<p>I believe it is quite possible that I am smart enough to have a significant effect on the course of whatever field I participate in.&nbsp; I also believe I could have a significant impact on the number of altruistic rationalists in the world. It seems likely that one of these options is way better than the other, and spending some time figuring out which one (and answering related, more specific questions) seems important. One of the most important ingredients in that calculation is a question of timescales. I don't trust the opinion of anyone involved with the SIAI. I don't trust the opinion of anyone in the mainstream. (In both cases I am happy to update on evidence they provide.) I don't have any good ideas on how to improve my estimate, but it feels like I should be able to.</p>\n<p>I encounter relatively smart people giving estimates completely out of line with mine which would radically alter my behavior if I believed them. What argument have I not thought through? What evidence have I not seen? I like to believe that smart, rational people don't disagree too dramatically about questions of fact that they have huge stakes in. General confusion about AI was fine when I had it walled off in a corner of my brain with other abstruse speculation, but now that the question matters to me my uncertainty seems more dire.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hRGjjHma3JYcGavt7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 20, "extendedScore": null, "score": 6.960366087193126e-07, "legacy": true, "legacyId": "6514", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T03:07:08.057Z", "modifiedAt": null, "url": null, "title": "Mental Metadata", "slug": "mental-metadata", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.590Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alicorn", "createdAt": "2009-03-17T18:52:42.458Z", "isAdmin": false, "displayName": "Alicorn"}, "userId": "iPdmf2tiNRtfJbvdQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fQcaoQ247iuh267rR/mental-metadata", "pageUrlRelative": "/posts/fQcaoQ247iuh267rR/mental-metadata", "linkUrl": "https://www.lesswrong.com/posts/fQcaoQ247iuh267rR/mental-metadata", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mental%20Metadata&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMental%20Metadata%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfQcaoQ247iuh267rR%2Fmental-metadata%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mental%20Metadata%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfQcaoQ247iuh267rR%2Fmental-metadata", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfQcaoQ247iuh267rR%2Fmental-metadata", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 788, "htmlBody": "<p>Once when I was probably eleven-ish, I asked a friend of my family who had just gotten a new car, \"What kind of car is it?\"&nbsp; He began to tell me the make and model and the interesting features of this particular vehicle.</p>\n<p>I interrupted him, and said, \"I meant, what color is it?\"</p>\n<p>This is just a mildly cute story about how little I knew or cared about cars at age eleven-ish, but it uncovers a communication issue that applies to people who are not eleven-ish anymore.&nbsp; I should have just asked in the first place what color the car was, since that was what I wanted to know.&nbsp; Asking what <em>kind</em> it was allowed a misunderstanding to creep into the interaction, since \"kind\" doesn't have a fixed meaning as regards cars and my interlocutor attached his own understanding of the question when he interpreted it.&nbsp; I didn't correctly pin down the metadata of my question, so he didn't know what kind of answer I was looking for.</p>\n<p>Garbled or missing metadata can cost time and cause fights, so I have developed a number of techniques to mitigate or eliminate it, both incoming and outgoing.&nbsp; They're pretty simple to apply, and bringing them to bear early is very instrumentally useful both for social and informational reasons.<a id=\"more\"></a></p>\n<p>Ask yourself <strong>what kind of answer you're looking for</strong>, then ask a question that calls for that kind of answer, or give an example of what would constitute a good answer to the person you're asking.&nbsp; <em>Examples of extensions/replacements for the question \"What kind of house are you going to build?\"</em></p>\n<blockquote>\n<p>\"Will it be, like, a cute suburban place with azaleas out front?\"</p>\n<p>\"I bet you're going with a brick facade, am I right?\"</p>\n<p>\"What square footage are you looking at, ballpark?\"</p>\n</blockquote>\n<p>For <strong>numerical inquiries</strong> that your interlocutor cannot seem to answer, pick one or more <strong>threshold numbers</strong> (surprisingly often, people who have \"no idea\" how to answer a numerical question can tell you whether the answer is greater or lesser than an arbitrary quantity).&nbsp; Explain why you need the information.&nbsp; Or ask for a related more-concrete detail that will give you an adequate estimate.&nbsp; <em>Examples of extensions/replacements for the question \"How many people are coming to the party?\"</em></p>\n<blockquote>\n<p>\"Is it more, or fewer, than 40 guests?\"</p>\n<p>\"I'm just trying to figure out how many boxes of plastic forks to buy - they come in 50ct boxes, and it'd be better to have extra than to fall short if we have to guess.\"</p>\n<p>\"How many invites did you send out, and how many RSVPs did you get back, and what did they say?\"</p>\n</blockquote>\n<p>Make sure the <strong>definitions of key words</strong> are agreed upon so you don't miss connotations or implications that are eluding one or both of the persons in an exchange.&nbsp; (You may need to agree to use a silly or even incoherent definition for something to forestall exasperating argument, especially if you are talking to people who believe in things like libertarian free will.&nbsp; Then you can give your own concepts their own labels for the duration of the conversation.)&nbsp; <em>Examples of extension/replacements for the question, \"<a href=\"/lw/np/disputing_definitions/\">If a tree falls in the forest and no one hears it, does it make a sound?</a>\"</em></p>\n<blockquote>\"What are you using \"sound\" to mean here...?&nbsp; Okay, I've been using it differently, but we'll go with that.&nbsp; I'm talking about this other thing which I'll call an alberzle...\"</blockquote>\n<blockquote>\"I've been thinking about kirrenberry trees all day, sorry - they're a fictional plant that doesn't make noise even when people <em>are</em> listening - but I'm guessing that's not what you had in mind when you said <em>tree</em>.\"</blockquote>\n<blockquote>\"That's the sixth time you've brought up squirrels - oh, my bad.&nbsp; I should've specified when I asked, I meant <em>nothing with ears</em> is around to hear it, I wasn't trying to specify humans.\"</blockquote>\n<p>Keep track of what <strong>kind of metadata</strong> your frequent associates natively use, so you can jump immediately to the correct information.&nbsp; This will also let you work backwards, if someone's going on a chain of inferences you can't follow easily (\"What?&nbsp; I'm not talking about X at all.&nbsp; Are you thinking of X because it shares a national origin with my topic Y?\").&nbsp; <em>Examples of extensions/replacements for the question \"Have you read this book?\"</em></p>\n<blockquote>\"You would have had my copy - it was blue, with a beat-up corner and the library jacket on?\"</blockquote>\n<blockquote>\"It's The Placeholder by X. Ample.&nbsp; Ample also wrote Exemplar, remember?\"</blockquote>\n<blockquote>\"The main character finds a magical amulet called The Self-Explanatory Magical Amulet and he - the amulet - talks about himself in a faux-medieval dialect the whole book.\"</blockquote>\n<p>I'm sure this isn't an exhaustive list of workarounds for metadata problems.&nbsp; What am I missing?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"YQW2DxpZFTrqrxHBJ": 1, "ZXFpyQWPB5ideFbEG": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fQcaoQ247iuh267rR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 47, "extendedScore": null, "score": 9.4e-05, "legacy": true, "legacyId": "6515", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 47, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7X2j8HAkWdmMoS8PE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T03:56:54.948Z", "modifiedAt": null, "url": null, "title": "San Francisco Meetup 4/4 7:00 PM", "slug": "san-francisco-meetup-4-4-7-00-pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.997Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "bisserlis", "createdAt": "2010-06-09T21:20:48.506Z", "isAdmin": false, "displayName": "bisserlis"}, "userId": "9WXfMey6djaARDzBQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LGNRM2sLgehyQ9ut6/san-francisco-meetup-4-4-7-00-pm", "pageUrlRelative": "/posts/LGNRM2sLgehyQ9ut6/san-francisco-meetup-4-4-7-00-pm", "linkUrl": "https://www.lesswrong.com/posts/LGNRM2sLgehyQ9ut6/san-francisco-meetup-4-4-7-00-pm", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20San%20Francisco%20Meetup%204%2F4%207%3A00%20PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASan%20Francisco%20Meetup%204%2F4%207%3A00%20PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLGNRM2sLgehyQ9ut6%2Fsan-francisco-meetup-4-4-7-00-pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=San%20Francisco%20Meetup%204%2F4%207%3A00%20PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLGNRM2sLgehyQ9ut6%2Fsan-francisco-meetup-4-4-7-00-pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLGNRM2sLgehyQ9ut6%2Fsan-francisco-meetup-4-4-7-00-pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 193, "htmlBody": "<address>Monday April 4th at 7:00 PM<br /></address><address>Green Papaya<br /></address><address>825 Mission Street (4th and Mission)</address><address>San Francisco, CA 94103</address>\n<p><a id=\"more\"></a></p>\n<p>Announcing the creation of a third Bay Area LW meetup, <strong>San Francisco</strong>! The first meeting of the San Francisco group will be this coming Monday, April 4th, from 7:00-9:00 at <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=Green+Papaya,+Mission+Street,+San+Francisco,+CA&amp;aq=0&amp;sll=37.0625,-95.677068&amp;sspn=40.681389,79.013672&amp;ie=UTF8&amp;hq=Green+Papaya,&amp;hnear=Mission+St,+San+Francisco,+California&amp;ll=37.783876,-122.404861&amp;spn=0.019875,0.038581&amp;z=15&amp;iwloc=A\" target=\"_blank\">Green Papaya near 4th and Mission</a>. We'll be introducing ourselves, talking about what about rationality interests each of us, and having fun! Please join us! <em>If you have urgent questions regarding this meetup (need directions, at the location but can't find the group, &amp;c) please call Ben Isserlis at *edit: elided*.</em></p>\n<p>If you've never been to a LessWrong meetup before and feel awkward just showing up, or if you think you haven't read enough of the Sequences and won't fit in, stop thinking that! All weekly meetings of SF Bay LessWrong groups are newcomer-friendly, and many people who come are in the same boat.</p>\n<p>If you want to stay informed about upcoming events in the Bay Area, join the <a href=\"https://groups.google.com/group/bayarealesswrong\">Bay Area LessWrong Google Group</a>! Not all events or meetups will be posted to LessWrong, so stay on top of local events and discussions by subscribing.</p>\n<p>See you soon!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LGNRM2sLgehyQ9ut6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 6.960549571609193e-07, "legacy": true, "legacyId": "6518", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T09:09:29.865Z", "modifiedAt": null, "url": null, "title": "Advice in fighting depression?", "slug": "advice-in-fighting-depression", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:16.680Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "N_R", "createdAt": "2010-01-03T16:17:39.394Z", "isAdmin": false, "displayName": "N_R"}, "userId": "PNay8MXoSvuDGJvgB", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qGyrtXgqYKpwZvLSn/advice-in-fighting-depression", "pageUrlRelative": "/posts/qGyrtXgqYKpwZvLSn/advice-in-fighting-depression", "linkUrl": "https://www.lesswrong.com/posts/qGyrtXgqYKpwZvLSn/advice-in-fighting-depression", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Advice%20in%20fighting%20depression%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAdvice%20in%20fighting%20depression%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqGyrtXgqYKpwZvLSn%2Fadvice-in-fighting-depression%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Advice%20in%20fighting%20depression%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqGyrtXgqYKpwZvLSn%2Fadvice-in-fighting-depression", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqGyrtXgqYKpwZvLSn%2Fadvice-in-fighting-depression", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 249, "htmlBody": "<p>My girlfriend suffers serious depression. She has sleep disorder, anorexia, chronic pain, problems to concentrate, low selfesteem, daily low mood, listlessness and is very indecisive. On the other side she considers herself very happy apart from the \"depression periods\" and we have a great time together. We already consulted a psychotherapist, but there is waiting time about one month. I buyed her fishoil capsules, because she eats no fish and there is mild evidence that it helps treating depression (I don't think this will affect her depression greatly, but fishoil seems like an overall good idea). We often go on walks to catch some sunlight and get her some exercise.</p>\n<p>She says she never want's to take antidepressants because she fears to get dependent from them. I think she might change her mind if there are very good arguments in favour of them. She is quite rational in spite of not knowing the LW-stuff. Does anybody of you know if there is any information of the succes rate of medicamentous (and psycho therapeutic) treatment available?</p>\n<p>I highly appreciate any advice.</p>\n<p>Furthermore i want to call attention to the topic of depression. A <strong>huge</strong> share of the population suffers at least once in their lifetime under depression (~20% in Germany). Sadly it's often not taken serious and a big taboo to speak about. Many people see it as self-inflicted. My girlfriend's mother doesn't believe in depression as a disease (<a title=\"see diseased thinking\" href=\"/lw/2as/diseased_thinking_dissolving_questions_about/\" target=\"_blank\">see diseased thinking</a>). It's a paradigm of irrationality that hurts people.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qGyrtXgqYKpwZvLSn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 19, "extendedScore": null, "score": 6.961414577339835e-07, "legacy": true, "legacyId": "6523", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["895quRDaK6gR2rM82"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T17:13:07.976Z", "modifiedAt": null, "url": null, "title": "Software for Critical Thinking, Prof. Geoff Cumming", "slug": "software-for-critical-thinking-prof-geoff-cumming", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:08.323Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MichaelBishop", "createdAt": "2009-02-27T21:29:30.329Z", "isAdmin": false, "displayName": "MichaelBishop"}, "userId": "HEJJhygH2QnAxDddx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CguJ3j39MRAnCsW8K/software-for-critical-thinking-prof-geoff-cumming", "pageUrlRelative": "/posts/CguJ3j39MRAnCsW8K/software-for-critical-thinking-prof-geoff-cumming", "linkUrl": "https://www.lesswrong.com/posts/CguJ3j39MRAnCsW8K/software-for-critical-thinking-prof-geoff-cumming", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Software%20for%20Critical%20Thinking%2C%20Prof.%20Geoff%20Cumming&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASoftware%20for%20Critical%20Thinking%2C%20Prof.%20Geoff%20Cumming%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCguJ3j39MRAnCsW8K%2Fsoftware-for-critical-thinking-prof-geoff-cumming%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Software%20for%20Critical%20Thinking%2C%20Prof.%20Geoff%20Cumming%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCguJ3j39MRAnCsW8K%2Fsoftware-for-critical-thinking-prof-geoff-cumming", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCguJ3j39MRAnCsW8K%2Fsoftware-for-critical-thinking-prof-geoff-cumming", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 139, "htmlBody": "<p><a href=\"http://www.latrobe.edu.au/psy/staff/cumming.html\">Prof. Geoff Cumming</a> has done some interesting work. &nbsp;Of particular relevance to the LW community, he has studied software for enhancing critical thinking.</p>\n<p>&nbsp;</p>\n<blockquote>\n<p><span style=\"color: #333333; font-size: 12px; line-height: 14px;\">\n<p style=\"line-height: 1.35em; margin-top: 0px; margin-right: 0.3em; margin-bottom: 1.3em; margin-left: 0px; padding: 0px;\"><span class=\"TextDarkGreySmallBold\" style=\"color: #333333; font-family: Verdana, Geneva, Tahoma, Arial; font-size: 11px; font-weight: bold;\">My past research</span><span class=\"TextDarkGreySmall\" style=\"color: #333333; font-family: Verdana, Geneva, Tahoma, Arial; font-size: 11px !important;\">: I worked on Computer tools for enhancing critical thinking, with Tim van Gelder. We studied argument mapping, and Tim&rsquo;s wonderful Reason!Able software for critical thinking. This has proved very effective in university and school classrooms as the basis for effective enhancement of critical thinking. In an ARC-funded project we evaluated the software and Tim&rsquo;s related educational materials. We found evidence that a one semester critical thinking course, based on Reason!Able, gives a very substantial increase&mdash;considerably greater than reported in previous evaluations of critical thinking courses&mdash;in performance on standardised tests.</span></p>\n<p class=\"TextDarkGreySmall\" style=\"line-height: 1.35em; margin-top: 0px; margin-right: 0.3em; margin-bottom: 1.3em; margin-left: 0px; color: #000000; font-family: Verdana, Geneva, Tahoma, Arial; font-size: 11px !important; padding: 0px;\">Tim&rsquo;s software has been further developed by his company Austhink Software, and is now available commercially as Rationale and bCisive: both are fabulous!&nbsp;<a style=\"color: #333333; text-decoration: underline; background-image: url(http://www.latrobe.edu.au/ltu_assets/images/devices/externalLink.gif); background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; padding-right: 10px; background-position: 100% 0%; background-repeat: no-repeat no-repeat;\" href=\"http://www.austhink.org/\">http://www.austhink.org/</a>&nbsp;<a style=\"color: #333333; text-decoration: underline; background-image: url(http://www.latrobe.edu.au/ltu_assets/images/devices/externalLink.gif); background-attachment: initial; background-origin: initial; background-clip: initial; background-color: initial; padding-right: 10px; background-position: 100% 0%; background-repeat: no-repeat no-repeat;\" href=\"http://bcisive.austhink.com/\">http://bcisive.austhink.com/</a></p>\n</span></p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"TkZ7MFwCi4D63LJ5n": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CguJ3j39MRAnCsW8K", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 6.962753312832518e-07, "legacy": true, "legacyId": "6526", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-30T23:31:52.022Z", "modifiedAt": null, "url": null, "title": "Size of the smallest recursively self-improving AI?", "slug": "size-of-the-smallest-recursively-self-improving-ai", "viewCount": null, "lastCommentedAt": "2015-02-03T20:28:26.685Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WGhxXto76ECJSfw3M/size-of-the-smallest-recursively-self-improving-ai", "pageUrlRelative": "/posts/WGhxXto76ECJSfw3M/size-of-the-smallest-recursively-self-improving-ai", "linkUrl": "https://www.lesswrong.com/posts/WGhxXto76ECJSfw3M/size-of-the-smallest-recursively-self-improving-ai", "postedAtFormatted": "Wednesday, March 30th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Size%20of%20the%20smallest%20recursively%20self-improving%20AI%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASize%20of%20the%20smallest%20recursively%20self-improving%20AI%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGhxXto76ECJSfw3M%2Fsize-of-the-smallest-recursively-self-improving-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Size%20of%20the%20smallest%20recursively%20self-improving%20AI%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGhxXto76ECJSfw3M%2Fsize-of-the-smallest-recursively-self-improving-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWGhxXto76ECJSfw3M%2Fsize-of-the-smallest-recursively-self-improving-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 285, "htmlBody": "<p>For no reason in particular I'm wondering about the size of the smallest program that would constitute a starting point of a recursively self-improving AI.</p>\n<p>The analysis of FOOM as a self-amplifying process would seem to indicate that in principle one could get it started from a relatively modest starting point -- perhaps just a few bytes of the right code could begin the process. Or could it? I wonder whether any other considerations give tighter lower-bounds.</p>\n<p>One consideration is that FOOM hasn't already happened -- at least not here on Earth. If the smallest FOOM seed were very small (like a few hundred bytes) then we would expect evolution to have already bumped into it at some point. Although evolution is under no specific pressure to produce a FOOM, it has probably produced over the last few billion years all the interesting computations up to some minor level of complexity, and if there were a FOOM seed among those then we would see the results about us.</p>\n<p>Then there is the more speculative analysis of what minimal expertise the algorithm constituting the FOOM seed would actually need.</p>\n<p>Then there is the fact that any algorithm that naively enumerates some space of algorithms qualifies in some sense as a FOOM seed as it will <em>eventually</em> hit on some recursively self-improving AI. But that could take gigayears so is really <em>not</em> FOOM in the usual sense.</p>\n<p>I wonder also whether the fact that mainstream AI hasn't <em>yet</em> produced FOOM could lower-bound the complexity of doing so.</p>\n<p>Note that here I'm referring to recursively self-improving AI in general -- I'd be interested if the answers to these questions change substantially for the special case of friendly AIs.</p>\n<p>Anyway, just idle thoughts, do add yours.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WGhxXto76ECJSfw3M", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 5, "extendedScore": null, "score": 6.963801993055149e-07, "legacy": true, "legacyId": "6530", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T00:27:15.271Z", "modifiedAt": null, "url": null, "title": "Guilt: Another Gift Nobody Wants", "slug": "guilt-another-gift-nobody-wants", "viewCount": null, "lastCommentedAt": "2017-06-17T04:08:38.466Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CZnBQtvDw33rmWpBD/guilt-another-gift-nobody-wants", "pageUrlRelative": "/posts/CZnBQtvDw33rmWpBD/guilt-another-gift-nobody-wants", "linkUrl": "https://www.lesswrong.com/posts/CZnBQtvDw33rmWpBD/guilt-another-gift-nobody-wants", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Guilt%3A%20Another%20Gift%20Nobody%20Wants&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGuilt%3A%20Another%20Gift%20Nobody%20Wants%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZnBQtvDw33rmWpBD%2Fguilt-another-gift-nobody-wants%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Guilt%3A%20Another%20Gift%20Nobody%20Wants%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZnBQtvDw33rmWpBD%2Fguilt-another-gift-nobody-wants", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCZnBQtvDw33rmWpBD%2Fguilt-another-gift-nobody-wants", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2287, "htmlBody": "<p>Evolutionary psychology has made impressive progress in understanding the origins of morality. Along with the <a href=\"http://wiki.lesswrong.com/wiki/Evolutionary_psychology\">many posts</a> about these origins on Less Wrong I recommend Robert Wright's <em>The Moral Animal</em> for an excellent introduction to the subject.<br /><br />Guilt does not naturally fall out of these explanations. One can imagine a mind design that although often behaving morally for the same reasons we do, sometimes decides a selfish approach is best and pursues that approach without compunction. In fact, this design would have advantages; it would remove a potentially crippling psychological burden, prevent loss of status from admission of wrongdoing, and allow more rational calculation of when moral actions are or are not advantageous. So why guilt?<br /><br />In one of the few existing writings I could find on the subject, Tooby and Cosmides <a href=\"http://www.psych.ucsb.edu/research/cep/emotion.html\">theorize that</a> \"guilt functions as an emotion mode specialized for recalibration of regulatory variables that control trade-offs in welfare between self and other.\" <br /><br />If I understand their meaning, they are saying that when an action results in a bad outcome, guilt is a byproduct of updating your mental processes so that it doesn't happen again. In their example, if you don't share food with your sister, and your sister starves and becomes sick, your brain gives you a strong burst of negative emotion around the event so that you reconsider your decision not to share. It is generally a bad idea to disagree with Tooby and Cosmides, but this explanation doesn't satisfy me for several reasons. <br /><br />First, guilt is just as associated with good outcomes as bad outcomes. If I kill my brother so I can inherit the throne, then even if everything goes according to plan and I become king, I may still feel guilt. But why should I recalibrate here? My original assumptions - that fratricide would be easy and useful - were entirely correct. But I am still likely to feel bad about it. In fact, some criminals report feeling \"relieved\" when caught, as if a negative outcome decreased their feelings of guilt instead of exacerbating them.<br /><br />Second, guilt is not only an emotion, but an entire complex of behaviors. Our modern word self-flagellation comes from the old practice of literally whipping one's self out of feelings of guilt or unworthiness. We may not literally self-flagellate anymore, but when I feel guilty I am less likely to do activities I enjoy and more likely to deliberately make myself miserable.<br /><br />Third, although guilt can be very private it has an undeniable social aspect. People have messaged me at 3 AM in the morning just to tell me how guilty they feel about something they did to someone I've never met; this sort of outpouring of emotion can even be therapeutic. The aforementioned self-flagellators would parade around town in their sackcloth and ashes, just in case anyone didn't know how guilty they felt. And we expect guilt in certain situations: a criminal who feels guilty about what ey has done may get a shorter sentence.<br /><br />Fourth, guilt sometimes occurs even when a person has done nothing wrong. People who through no fault of their own are associated with disasters can nevertheless report \"survivor's guilt\" and feel like events were partly their fault. If this is a tool for recalibrating choices, it is a very bad one. This is not a knockdown argument - a lot of mental adaptations are very bad at what they do - but it should at least raise suspicion that there is another part to the puzzle besides recalibration.</p>\n<p><a id=\"more\"></a><br /><strong>THE PARABLE OF THE LAWYER</strong><br /><br />Suppose you need a lawyer for some important and very lucrative legal case. And suppose by a freak legislative oversight, your state has no laws against legal malpractice and unethical lawyers can get off scot-free. You are going to want to invest a lot of effort into evaluating the morals of the many lawyers anxious to take your case.<br /><br />One lawyer you meet, Mr. Dewey, has an unusual appearance. A small angel, about the size of a rat, sits on his right shoulder holding an electric cattle prod. This is remarkable, and so you remark upon it.<br /><br />Mr. Dewey scowls. \"That angel has been sitting there for as long as I can remember,\" he tells you. \"Every time I do something wrong, she pokes me with her prod. If it's a minor sin like profanity, maybe she'll only poke me once or twice, but if I lie or swindle, she'll turn the power up on max and keep shocking me for days. It's a miserable, miserable existence, and I'm constantly scared to death I'll slip up and make her angry, but I can't figure out how to get rid of her.\"<br /><br />You express some skepticism about this story, so Mr. Dewey offers to demonstrate. He says a mild curse word, and sure enough, the angel pokes him with the cattle prod, giving him a mild electric shock.<br /><br />Suddenly, Mr. Dewey is a very attractive candidate for your lucrative case. You can be assured that he won't swindle you, because whatever gains he might take from the swindle are less attractive than the punishment he would get from the angel afterwards.<br /><br />Surgeon Paul Brand considered pain so useful to the body's functioning that he <a href=\"http://www.amazon.com/Pain-Nobody-Paul-W-Brand/dp/0310616786\">called it</a> \"the gift nobody wants\". Mr. Dewey's angel is also such a gift, even though he might not appreciate it: clients worried about ethical issues will bring their patronage to his law firm, giving him a major advantage over the competition. <br /><br />Whereas normally we must trust a lawyer's altruism if we expect em not to con us, in Mr. Dewey's case we need only trust him to pursue his own self-interest. This, then, is the role of guilt: it provides assurance to others that we will be punished for our misdeeds even if there is no external authority to punish us, avoiding Parfitian hitchhiker&nbsp; dilemmas and ensuring fair play. The assurance of punishment ensures fair play and makes mutually beneficial transactions possible.<br /><br /><strong>FAKEABLE AND UNFAKEABLE SIGNALS<br /></strong><br />The big difference between Mr. Dewey and ourselves is that where Mr. Dewey has unquestionable evidence of his commitment to self punishment in the form of a very visible angel on his shoulder, for the rest of us guilt is a private mental affair and can be faked. It would seem to be a winning strategy, then, to claim a tendency to guilt while not really having one.<br /><br />Ms. Wolfram is Mr. Dewey's main competitor, and is outraged at her rival's business success. In an attempt to even the scales, she buys a plastic angel figure from the local church and glues it to her shoulder. \"Look!\" she tells clients. \"I, too, suffer pain when I commit misdeeds!\" Her business shoots up to the same high levels as Mr. Dewey's.<br /><br />One day, the news comes that Mr. Dewey was spotted whipping himself in the town square. When asked why, he explained that in a moment of weakness, he had overcharged a customer. His angel, who had lost its cattle prod, was mind-controlling him into the self-flagellation in place of its more usual punishment.<br /><br />This provides an impressive bar for Ms. Wolfram to live up to. Sure, she could just whip herself like Mr. Dewey is doing. But it wouldn't be worth it - she just doesn't like the money enough that she would whip herself after every swindle just to drum up business. If she's going to have to whip herself to fake remorse whenever she commits wrongdoing,&nbsp; her best policy really <em>is</em> to genuinely stop swindling people.<br /><br />Mr. Dewey has found an unfakeable signal. Even though whipping himself in public is one of the most unpleasant things he could do, in this case it is good business practice. It once again differentiates him from Ms. Wolfram and restores his status as the city's most desirable attorney.<br /><br />In evolutionary terms, guilt becomes more credible the more it requires publicly visible behavior that no reasonable cheat would want to fake. Hurting oneself, avoiding pleasurable activities, lowering your own status, and withdrawing from social activities are all evolutionary costly and therefore good ways to prove you are experiencing guilt; the usual vocal, postural, and facial cues of being miserable are also useful.<br /><br />There's no reason people should evolve an all-consuming sense of guilt. If an opportunity comes along where the benefits of cheating are greater than the social costs, an organism should still take it. Therefore, guilt has to be unpleasant but not infinitely unpleasant. A person who committed suicide in response to even the slightest moral infraction would be trustworthy, but they'd miss out if an excellent opportunity to win major gains for cheating happened to fall into their lap.<br /><br />The conspicuous experience of guilt is an evolutionarily advantageous way of assuring potential trading partners that you will be punished for defection. The behaviors associated with guilt are costly signals that help differentiate false claims of guilt from the real thing and add to public verifiability of the punishment involved.<br /><br /><strong>UNDESERVED GUILT</strong><br /><br />If you kill your brother in order to inherit the throne, you probably deserve whatever guilt you feel. But in the phenomenon of \"survivor's guilt\", people feel guilt for events that weren't even remotely their fault. Maybe you go hiking with your brother, and through no fault of your own he trips and falls down a crevasse and dies, and now you feel guilty. Why?<br /><br />Hunter-gatherer societies were more violent than our own; statistics differ but by <a href=\"http://www.economist.com/node/10278703\">some estimates </a>around 30% of hunter-gatherer males died of homicide. Even as late as the Bronze Age, Biblical figures who killed their brothers comprise a rather impressive list including Cain, Solomon, Ammon, Abimelech, and Jehoram; Jacob's sons merely attempted to do so. So the priors for suspicious death must have been very different in the olden days.<br /><br />Further, in such a crime-ridden culture, there may have been more incentives to blame an enemy for a death, even if that enemy was not responsible. A person whose brother has accidentally died on a hiking trip with no witnesses would be very targetable.<br /><br />And even in less drastic situations than blaming survivors for a death, there may be other possible threats to reputation. If there is only one survivor of a battle, he may be suspected of cowardice; if there is only one survivor of a disaster, she may be suspected of running away without helping others. <br /><br />Therefore, it would be advantageous to have a method of proving your innocence. Suppose that you would gain benefits X from killing your brother and covering it up, but that you would suffer losses Y if you were suspected of the crime and punished. A precommitment to a policy of experiencing a level of guilt between X and Y provides a tool for proving your innocence. It would no longer be in your self-interest to kill your brother, because you will suffer so much guilt that you won't be able to enjoy the benefits of your crime; your would-be accusers realize this and admit your innocence, saving you from the still worse outcome Y.<br /><br />In this case, guilt would be an entirely adaptive response to a disaster with which you were associated, even if your own actions were beyond reproach. A level of unhappiness worse than any benefits you could get by profiting the tragedy, but less than any punishment you might receive if you were suspected of profiting from the tragedy, would be helpful in clearing your name of any wrongdoing.</p>\n<p>(The proposed mechanism is almost identical to one cited in Thornhill and Palmer's controversial and unpleasant evolutionary <a href=\"http://books.google.com/books?id=xH6v-nB6EegC&amp;lpg=PA96&amp;ots=Q2FNixrDci&amp;dq=thornhill%20psychological%20adaptation%20women&amp;pg=PA86#v=onepage&amp;q=thornhill%20psychological%20adaptation%20women&amp;f=false\">account of post-traumatic stress after rape</a>.)<br /><br />This theory makes some testable predictions, which as far as I know have not been tested:</p>\n<p>- People should feel guiltier about events for which reasonable suspicion might exist that they played a part; for example, if your brother slipped and fell while you were hiking alone with him rather than in a large group with many witnesses.<br />- People should feel guiltier about events for which they might profit; for example, if you stood to inherit money from your brother, or never liked him much anyway.<br />- People may be suspicious of people who come out of a disaster feeling no survivor's guilt.</p>\n<p><strong>CONCLUSION</strong></p>\n<p>Guilt, like pain, is \"a gift nobody wants\". Because people with guilt are known to punish themselves for moral wrongdoing, their social group considers them more trustworthy and they gain the advantages of trade and cooperation. In order to prove that their guilt is real rather than feigned, they use costly signals like deliberate self-harm and self-denial to display their punishment publicly<br /><br />When one has done nothing wrong, it can sometimes be advantageous to paradoxically display guilt in order to prove one's lack of wrongdoing. These costly signals demonstrate that it is not in one's self-interest to lie about these matters, while still being less costly than the punishment for defection.<br /><br />Although this could theoretically be mediated by the behavioral strategies of a sufficiently intelligent and Machiavellian unconscious mind, it fits within the framework of evolutionary psychology and can also be interpreted in evolutionary terms.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"3ee9k6NJfcGzL6kMS": 1, "Q6P8jLn8hH7kbuXRr": 1, "exZi6Bing5AiM4ZQB": 1, "5ueqn4r7N3WvaLfGy": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CZnBQtvDw33rmWpBD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 80, "baseScore": 97, "extendedScore": null, "score": 0.000178, "legacy": true, "legacyId": "6531", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 97, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 103, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T01:35:50.905Z", "modifiedAt": null, "url": null, "title": "Reflections on rationality a year out", "slug": "reflections-on-rationality-a-year-out", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:39.548Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "gxaj4KAzYhSRgqvsh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SFG9Cm7mf5eP4juKs/reflections-on-rationality-a-year-out", "pageUrlRelative": "/posts/SFG9Cm7mf5eP4juKs/reflections-on-rationality-a-year-out", "linkUrl": "https://www.lesswrong.com/posts/SFG9Cm7mf5eP4juKs/reflections-on-rationality-a-year-out", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reflections%20on%20rationality%20a%20year%20out&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReflections%20on%20rationality%20a%20year%20out%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFG9Cm7mf5eP4juKs%2Freflections-on-rationality-a-year-out%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reflections%20on%20rationality%20a%20year%20out%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFG9Cm7mf5eP4juKs%2Freflections-on-rationality-a-year-out", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSFG9Cm7mf5eP4juKs%2Freflections-on-rationality-a-year-out", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1090, "htmlBody": "<p><em>Edited for concreteness.</em></p>\n<p>Exactly one year ago, LessWrong helped me <a href=\"/lw/i4/belief_in_belief/1xw2\" target=\"_blank\">change my mind</a> about something important.&nbsp;</p>\n<p>Since then, my life has been changing very rapidly, as a direct result of the rationalist community.&nbsp; I got in touch with other rationalists in person, which made my social life vastly more interesting (not to say surreal).&nbsp; My plans for the future have definitely shifted a bit.&nbsp; I began a deliberate habit of trying new things and learning new skills, and facing up to my flaws, often with advice from LessWrongers or IRL rationalist friends. &nbsp;</p>\n<p>A few examples: I improved my diet (paleo), tried yoga, took up cognitive behavioral therapy to work on some chronic insecurities, moved Python from the \"wish I knew\" box to the \"have a detailed plan to learn\" box, dared to publish some popular-science articles under my real name, learned to do Fermi calculations in my head. &nbsp;I also noticed that my habits of thought have been changing: for one thing, I'm getting better calibrated about probabilities -- I'm better at estimating how I did on schoolwork. &nbsp;For another thing, I'm getting better at not reflexively dismissing non-standard ideas: the first time someone mentioned me that a good statistician could make a lot of money in car insurance by finding new correlations to monetize, I thought \"Car insurance? Hmph, low status.\" &nbsp;The second time I heard that suggestion, about five months later, I thought \"Hey, that's a decent idea.\" &nbsp;Some of these changes have begun to show results -- the time-management habits* I came up with have started to improve my academic performance, and I notice I'm far less inhibited about taking the initiative to work on projects (I have a couple of interesting balls in the air now, including a business idea and some volunteer work for SIAI, whereas I used to be very reluctant to volunteer for things.)&nbsp; I've become much more open to cold-emailing people who work on interesting things (on one occasion I got a job offer out of an AI researcher); I'm more comfortable viewing myself as a junior member of the Interesting-People Club.&nbsp; I made a unilateral decision to be happier, and though I hate to jinx it, I think it's working.</p>\n<p>I say this just to offer evidence that something about \"rationality\" works.&nbsp; I'm not sure what it is; many of the components of LessWrong-style rationality exist elsewhere (cognitive biases are fairly common knowledge; self-improvement hacks aren't unique to LessWrong; Bayesian statistics wasn't news to me when I got here).&nbsp; If anything, it's the sense that rationality <em>can</em> be an art, a superpower, a movement.&nbsp; It's the very fact of consolidating and giving a name and culture to the ideas surrounding how humans can think clearly.&nbsp; I'm never sure how much of that is a subjective primate in-group thing, but I'm hesitant to be too suspicious -- I don't want to blow out the spark before the fire has even started.&nbsp; My point is, there's something here that's worthwhile.&nbsp; It's not just social hour for nerds (not that we can't enjoy that aspect) -- it actually is possible to reach out to people and make a difference in how they live and see the world.<a id=\"more\"></a></p>\n<p>Once upon a time -- it seems like ages ago -- I used to envy a certain kind of person.&nbsp; The kind who has confidence that he can make a decent stab at ethical behavior without the threat of divine wrath.&nbsp; The kind who thinks that human beings have something to be proud of, that we're getting better at understanding the world and fitfully reducing suffering and injustice.&nbsp; The kind who thinks that he, personally, has some chance to make a valuable contribution.&nbsp; The kind who's audacious, who won't let anybody tell him what to think.&nbsp; The kind who whistles as he wins. &nbsp;Bertrand Russell seemed to be like that; also Robert Heinlein, and a couple of close friends of mine. &nbsp;That attitude, to me, seemed like a world of cloudless blue sky -- what a pity that I couldn't go there!&nbsp;</p>\n<p>Ah, folly.&nbsp; Thing is, none of that attitude, strictly speaking, is rationality -- it might be what comes before rationality.&nbsp; It might be what makes rationality seem worthwhile.&nbsp; It might simply be the way you think if you read a lot of science fiction in your youth.&nbsp; But I've never seen it encouraged so well as here. When people ask me \"What's a rationalist anyway,\" I tell them it's living the empirical life: trying to look at <em>everything</em>&nbsp;as though it's science, not just the lab -- trying different things and seeing what works, trying to actually <em>learn</em>&nbsp;from everything you observe.</p>\n<p>I'm grateful for all this.&nbsp; While it's probably for the best that we don't pat ourselves on the back too much, I'm convinced that we should notice and appreciate what works.&nbsp; I used to be uncomfortable with evangelism, but now I tend to refer people to LessWrong when they mention a related idea (like complaining about incoherent arguments in debates).&nbsp; I think more visibility for us would be a good thing.&nbsp; I have plans to make a \"rationality toy\" of sorts -- I know other people have projects in that vein -- the more <em>things </em>we can create beyond the blog, the more alternate channels people have to learn about these ideas.&nbsp; And the more we can inspire the less confident among us that yes, you can do something, you can contribute.</p>\n<p>*My anti-procrastination tactics are goal tracking via Joe's Goals and selective internet blocking via Self Control. &nbsp;Also posting my weekly goals to the New York Less Wrong mailing list. &nbsp;My problem up until now has really been spending too few hours on work -- in the bad old days I would frequently spend only 5 hours working on a weekday or 3 hours on a Saturday and the rest fooling around on the internet. &nbsp;I was really hooked on the intermittent stimulation of certain message boards, which I'm mostly glad to have given up. Now I'm aiming for 60-hour weeks. &nbsp;One thing that works in my favor is that I've almost completely stopped motivating myself by the ideal of being a \"good girl\" who receives approval; the reason I'm trying to get more work done is so that I can get credentials and preparation for the life I actually want to lead. &nbsp;I'm trying to be strategic, not ascetic. &nbsp;I don't know if what I've done is enough -- there's always someone who works harder or longer and seems to never need a break. &nbsp;But it's definitely better than nothing. &nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"zcvsZQWJBFK6SxK4K": 4, "Ng8Gice9KNkncxqcj": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SFG9Cm7mf5eP4juKs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 108, "baseScore": 123, "extendedScore": null, "score": 0.000232, "legacy": true, "legacyId": "6505", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 123, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 108, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T02:01:56.175Z", "modifiedAt": null, "url": null, "title": "Reading the Sequences before Starting to Post: Costs and Benefits", "slug": "reading-the-sequences-before-starting-to-post-costs-and", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.504Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Normal_Anomaly", "createdAt": "2010-11-14T03:31:54.691Z", "isAdmin": false, "displayName": "Normal_Anomaly"}, "userId": "WgGYj5bqcZKsFNG6F", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EauwsXht4jrjTTE9m/reading-the-sequences-before-starting-to-post-costs-and", "pageUrlRelative": "/posts/EauwsXht4jrjTTE9m/reading-the-sequences-before-starting-to-post-costs-and", "linkUrl": "https://www.lesswrong.com/posts/EauwsXht4jrjTTE9m/reading-the-sequences-before-starting-to-post-costs-and", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reading%20the%20Sequences%20before%20Starting%20to%20Post%3A%20Costs%20and%20Benefits&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReading%20the%20Sequences%20before%20Starting%20to%20Post%3A%20Costs%20and%20Benefits%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEauwsXht4jrjTTE9m%2Freading-the-sequences-before-starting-to-post-costs-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reading%20the%20Sequences%20before%20Starting%20to%20Post%3A%20Costs%20and%20Benefits%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEauwsXht4jrjTTE9m%2Freading-the-sequences-before-starting-to-post-costs-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEauwsXht4jrjTTE9m%2Freading-the-sequences-before-starting-to-post-costs-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 804, "htmlBody": "<p>This post arose from <a title=\"Philosophy: a Diseased Discipline\" href=\"/lw/4zs/philosophy_a_diseased_discipline/3sq5?context=5#comments\" target=\"_self\">this discussion</a> in the \"Philosophy: a Diseased Discipline\" post.</p>\n<h2><strong>Current Practice</strong><br /></h2>\n<p>There have been several conversations lately about the costs and benefits of scholarship, the effort of reading the sequences, and attempts to repackage the sequence material in an easier form [1]. There also used to be a practice on LW of telling newbies who weren't producing good content to come back when they'd read the sequences. However, David Gerard, who has been paying more attention than me, has noticed that this practice has stopped. One plausible explanation is that the stoppage is due to a rising awareness of the effort that reading the sequences takes.&nbsp;</p>\n<p>In an impromptu unscientific poll, 10 respondents said that they had read the sequences while still lurking on LW, 3 that they read them after creating accounts, and 8 that they had read them while they were still on OB. Nobody said that they still hadn't read the sequences [2]. So, assuming that this roughly represents the status quo, most LW posts/comments come from people who have read the sequences. The questions are: One, is this situation changing (are fewer people reading the sequences than in the past)? And two, should it change, and in what direction?</p>\n<p>To answer this, one needs to look at the costs and benefits.</p>\n<h2><strong>Costs</strong></h2>\n<p><strong>Length:</strong> The sequences comprise over a million words, not counting the comments. They cover material as diverse as semantics, quantum theory, cognitive science, metaethics, and how to write a good eutopia.</p>\n<p><strong>Interdependency:</strong> Each post in a sequence requires understanding of the previous posts in that sequence, and sometimes posts from earlier sequences. As well as being a source of intimidating and annoying tab explosions, this exacerbates the problem of length. It's hard to read the sequences except going through large chunks systematically, so they can't be broken up and read in a person's spare time.</p>\n<p><strong>Possible Memetic Hazard: </strong>Some of the ideas in the Sequences are controversial [3]. These points are often clearly marked in the posts and debated in the comments, so they won't sneak up on anyone; on the other hand, Memetic Hazard was used to describe controversial topics <a href=\"/lw/2un/references_resources_for_lesswrong\">here</a>, so at least someone thinks it's a problem. Some potential readers may not want to be exposed to treatments of  controversial issues that argue for one side before they read balanced  overviews. Also, discomfort has been expressed over the possibility of LW being a cult.&nbsp; I don't want this post to turn into a forum for the is-it-a-cult conversation, so it's up here as something that may cause disutility to some people who read the Sequences.</p>\n<h2>Benefits</h2>\n<p><strong>Usefulness:</strong> various people [4] have discussed the various benefits of rationality knowledge in helping them \"Win at Life\". These benefits vary widely from person to person, so there are many ways to take advantage of the sequences in one's own life.</p>\n<p><strong>Informativeness:</strong> On questions that don't have immediate practical relevance, it's still good for the community if everyone is familiar with the basic material. Discussions of uploading, for example, wouldn't go very far if people had to stop to explain why they believe that consciousness is physical. Having all participants start out with a minimum number of undissolved confusions improves the SNR of Less Wrong even when it doesn't directly help the individual members win.</p>\n<p><strong>A Common Vocabulary:</strong> on a forum where everyone has read the sequences, it's easy to refer to them in conversation. Telling someone that their position is equivalent to two-boxing on Newcomb's problem will quickly convey what you mean and allow the person an easy way to craft an answer. Pointing out that a debate is over the meaning of a word will do more to prevent it from expanding into a giant mess than if the participants hadn't read Making Beliefs Pay Rent. And using examples like Bleggs and Rubes or similar can connect a commenter's example to ver audience's current knowlege of the concept.</p>\n<p>Please comment to suggest more costs and benefits, provide more info on the sequence-reading habits of commenters, share your experience, or explain why everything I just said is wrong.</p>\n<p>\n<hr />\n</p>\n<p>[1] Some examples: <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\" target=\"_self\">The Neglected Virtue of Scholarship</a>, <a href=\"/lw/4sn/costs_and_benefits_of_scholarship/\">Costs and Benefits of Scholarship</a>, <a href=\"/lw/3oj/a_lesswrong_rationality_workbook_idea/\">Rationality Workbook Proposal</a>.</p>\n<p>[2] This option in the poll was created after the others and would up being elsewhere on the page, so it is probably underrepresented. I'm just taking the results as a first approximation, and will edit this post if the comments suggest the status quo is not what I thought it was.</p>\n<p>[3] Some examples: The <a href=\"/lw/q8/many_worlds_one_best_guess/\">Many-Worlds</a> and <a href=\"/lw/qp/timeless_physics/\">Timeless</a> formulations of quantum mechanics are still being debated by Physicists. Perhaps less importantly, as an average reader can understand the debate and form ver own opinion, issues like the Zombie World are still being debated by philosophers.</p>\n<p>[4] See this post for an example: <a href=\"/lw/50p/reflections_on_rationality_a_year_out/\">Reflections on Rationality a Year Out</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EauwsXht4jrjTTE9m", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 22, "extendedScore": null, "score": 4.1e-05, "legacy": true, "legacyId": "6535", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>This post arose from <a title=\"Philosophy: a Diseased Discipline\" href=\"/lw/4zs/philosophy_a_diseased_discipline/3sq5?context=5#comments\" target=\"_self\">this discussion</a> in the \"Philosophy: a Diseased Discipline\" post.</p>\n<h2 id=\"Current_Practice\"><strong>Current Practice</strong><br></h2>\n<p>There have been several conversations lately about the costs and benefits of scholarship, the effort of reading the sequences, and attempts to repackage the sequence material in an easier form [1]. There also used to be a practice on LW of telling newbies who weren't producing good content to come back when they'd read the sequences. However, David Gerard, who has been paying more attention than me, has noticed that this practice has stopped. One plausible explanation is that the stoppage is due to a rising awareness of the effort that reading the sequences takes.&nbsp;</p>\n<p>In an impromptu unscientific poll, 10 respondents said that they had read the sequences while still lurking on LW, 3 that they read them after creating accounts, and 8 that they had read them while they were still on OB. Nobody said that they still hadn't read the sequences [2]. So, assuming that this roughly represents the status quo, most LW posts/comments come from people who have read the sequences. The questions are: One, is this situation changing (are fewer people reading the sequences than in the past)? And two, should it change, and in what direction?</p>\n<p>To answer this, one needs to look at the costs and benefits.</p>\n<h2 id=\"Costs\"><strong>Costs</strong></h2>\n<p><strong>Length:</strong> The sequences comprise over a million words, not counting the comments. They cover material as diverse as semantics, quantum theory, cognitive science, metaethics, and how to write a good eutopia.</p>\n<p><strong>Interdependency:</strong> Each post in a sequence requires understanding of the previous posts in that sequence, and sometimes posts from earlier sequences. As well as being a source of intimidating and annoying tab explosions, this exacerbates the problem of length. It's hard to read the sequences except going through large chunks systematically, so they can't be broken up and read in a person's spare time.</p>\n<p><strong>Possible Memetic Hazard: </strong>Some of the ideas in the Sequences are controversial [3]. These points are often clearly marked in the posts and debated in the comments, so they won't sneak up on anyone; on the other hand, Memetic Hazard was used to describe controversial topics <a href=\"/lw/2un/references_resources_for_lesswrong\">here</a>, so at least someone thinks it's a problem. Some potential readers may not want to be exposed to treatments of  controversial issues that argue for one side before they read balanced  overviews. Also, discomfort has been expressed over the possibility of LW being a cult.&nbsp; I don't want this post to turn into a forum for the is-it-a-cult conversation, so it's up here as something that may cause disutility to some people who read the Sequences.</p>\n<h2 id=\"Benefits\">Benefits</h2>\n<p><strong>Usefulness:</strong> various people [4] have discussed the various benefits of rationality knowledge in helping them \"Win at Life\". These benefits vary widely from person to person, so there are many ways to take advantage of the sequences in one's own life.</p>\n<p><strong>Informativeness:</strong> On questions that don't have immediate practical relevance, it's still good for the community if everyone is familiar with the basic material. Discussions of uploading, for example, wouldn't go very far if people had to stop to explain why they believe that consciousness is physical. Having all participants start out with a minimum number of undissolved confusions improves the SNR of Less Wrong even when it doesn't directly help the individual members win.</p>\n<p><strong>A Common Vocabulary:</strong> on a forum where everyone has read the sequences, it's easy to refer to them in conversation. Telling someone that their position is equivalent to two-boxing on Newcomb's problem will quickly convey what you mean and allow the person an easy way to craft an answer. Pointing out that a debate is over the meaning of a word will do more to prevent it from expanding into a giant mess than if the participants hadn't read Making Beliefs Pay Rent. And using examples like Bleggs and Rubes or similar can connect a commenter's example to ver audience's current knowlege of the concept.</p>\n<p>Please comment to suggest more costs and benefits, provide more info on the sequence-reading habits of commenters, share your experience, or explain why everything I just said is wrong.</p>\n<p>\n</p><hr>\n<p></p>\n<p>[1] Some examples: <a href=\"/lw/3m3/the_neglected_virtue_of_scholarship/\" target=\"_self\">The Neglected Virtue of Scholarship</a>, <a href=\"/lw/4sn/costs_and_benefits_of_scholarship/\">Costs and Benefits of Scholarship</a>, <a href=\"/lw/3oj/a_lesswrong_rationality_workbook_idea/\">Rationality Workbook Proposal</a>.</p>\n<p>[2] This option in the poll was created after the others and would up being elsewhere on the page, so it is probably underrepresented. I'm just taking the results as a first approximation, and will edit this post if the comments suggest the status quo is not what I thought it was.</p>\n<p>[3] Some examples: The <a href=\"/lw/q8/many_worlds_one_best_guess/\">Many-Worlds</a> and <a href=\"/lw/qp/timeless_physics/\">Timeless</a> formulations of quantum mechanics are still being debated by Physicists. Perhaps less importantly, as an average reader can understand the debate and form ver own opinion, issues like the Zombie World are still being debated by philosophers.</p>\n<p>[4] See this post for an example: <a href=\"/lw/50p/reflections_on_rationality_a_year_out/\">Reflections on Rationality a Year Out</a></p>", "sections": [{"title": "Current Practice", "anchor": "Current_Practice", "level": 1}, {"title": "Costs", "anchor": "Costs", "level": 1}, {"title": "Benefits", "anchor": "Benefits", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "22 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TNHQLZK5pHbxdnz4e", "64FdKLwmea8MCLWkE", "TFbAMgeiCLjdX4Smw", "gPSCQC3WMeJnW9q4W", "S8ysHqeRGuySPttrS", "rrW7yf42vQYDf8AcH", "SFG9Cm7mf5eP4juKs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T06:23:33.649Z", "modifiedAt": null, "url": null, "title": "Iconoclastic rational critique of parlimentary democracy", "slug": "iconoclastic-rational-critique-of-parlimentary-democracy", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ziAGPmXhLcpYj8Zjv", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hHyD7WtJzKwNXaRDj/iconoclastic-rational-critique-of-parlimentary-democracy", "pageUrlRelative": "/posts/hHyD7WtJzKwNXaRDj/iconoclastic-rational-critique-of-parlimentary-democracy", "linkUrl": "https://www.lesswrong.com/posts/hHyD7WtJzKwNXaRDj/iconoclastic-rational-critique-of-parlimentary-democracy", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Iconoclastic%20rational%20critique%20of%20parlimentary%20democracy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIconoclastic%20rational%20critique%20of%20parlimentary%20democracy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhHyD7WtJzKwNXaRDj%2Ficonoclastic-rational-critique-of-parlimentary-democracy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Iconoclastic%20rational%20critique%20of%20parlimentary%20democracy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhHyD7WtJzKwNXaRDj%2Ficonoclastic-rational-critique-of-parlimentary-democracy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhHyD7WtJzKwNXaRDj%2Ficonoclastic-rational-critique-of-parlimentary-democracy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4, "htmlBody": "<p>I want a reasonbal</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hHyD7WtJzKwNXaRDj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6539", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T08:56:27.796Z", "modifiedAt": null, "url": null, "title": "Where do dualists go wrong?", "slug": "where-do-dualists-go-wrong", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AlephNeil", "createdAt": "2010-05-12T14:43:28.879Z", "isAdmin": false, "displayName": "AlephNeil"}, "userId": "qSNSSwAXbki7JTNSd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ha4Dvys9gA9hWTWSg/where-do-dualists-go-wrong", "pageUrlRelative": "/posts/ha4Dvys9gA9hWTWSg/where-do-dualists-go-wrong", "linkUrl": "https://www.lesswrong.com/posts/ha4Dvys9gA9hWTWSg/where-do-dualists-go-wrong", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Where%20do%20dualists%20go%20wrong%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhere%20do%20dualists%20go%20wrong%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fha4Dvys9gA9hWTWSg%2Fwhere-do-dualists-go-wrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Where%20do%20dualists%20go%20wrong%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fha4Dvys9gA9hWTWSg%2Fwhere-do-dualists-go-wrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fha4Dvys9gA9hWTWSg%2Fwhere-do-dualists-go-wrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 537, "htmlBody": "<p>The latest <a href=\"/lw/4zs/philosophy_a_diseased_discipline/3sht\">zombie</a> debates have made me reflect on how a purely philosophical dispute may lack any resolution and yet be harmless as long as the consequences of a 'confused' position don't leak out into the world. Hence, I've brainstormed a short list of practical ways in which dualists may go wrong. (And yes, one or two of the 'dualist errors' are standard LW positions!)</p>\n<ol>\n<li>Undue skepticism about the minds of artificial intelligences, leading to the possibility of prejudice. (<a href=\"http://bloggingheads.tv/diavlogs/15555\">Jaron</a> <a href=\"http://www.edge.org/3rd_culture/lanier/lanier_index.html\">Lanier</a> assumes, as a matter of faith, that people are metaphysically special in a way that no AI could possibly be. His belief would have the potential to become ethically monstrous precisely at the point when AGI emerged.)</li>\n<li>A desire to answer the misguided question: \"What evolutionary benefit is conferred by phenomenal consciousness (as distinct from the merely 'functional' abilities to learn, represent the environment, introspect on one's own state etc)?\"</li>\n<li>A belief that the 'all or nothing' nature of consciousness is detectable somehow. That psychology is incomplete until it tracks down 'neural correlates of consciousness' that respect this 'all or nothingness', and can resolve all of Dennett's Orwellian vs Stalinesque disputes.</li>\n<li>Grave skepticism about 'simulationism' leading to skewed ethics / decision theory. For instance, believing that it would be or might be catastrophic if the earth were replaced by a perfectly and reliably simulated earth.</li>\n<li>Belief in transtemporal identity leading to skewed ethics / decision theory: Believing that one would 'die' in a teleporter. <a href=\"/lw/wq/you_only_live_twice/3gog\">Vastly overestimating</a> the value of cryonics. (Yes, I think these two are sides of the same coin.)</li>\n<li>Belief in the existence of a duality between 'mental states' and the underlying physical state suggesting 'utilitarianism' in which all moral value is supervenient on mental states, irrespective of the wider universe.</li>\n<li>Being under the mistaken impression that there is something meritorious, useful or valuable about the practice of discussing certain philosophical questions (e.g. those concerning the persistence of subjective identity, or whether/how we can know that physiologically normal people have minds, and have non-inverted qualia).</li>\n<li>Inference from 'consciousness' to the necessity to wreck our best models of physics in some way. (Penrose seeking a non-algorithmic quantum gravity, Chalmers endorsing 'consciousness causes collapse of the wavefunction' etc.)</li>\n<li><span style=\"text-decoration: line-through;\">Something about libertarian free will and libertarianism, the details of which have been deleted to avert a mind-killing political dispute</span>.</li>\n<li>Inference from 'consciousness' to the existence of an immortal soul (together with a corresponding skewing of decision theory: overacceptance of death, overeagerness to die for one's cause.)</li>\n</ol>\n<p>Some of these (1, 4, 5 and 10) are fairly specific misattributions of ethical value. Others (2, 3, 7 and 8) are or might turn into <a href=\"http://en.wikipedia.org/wiki/Imre_Lakatos#Research_programmes\">degenerating research programmes</a>&nbsp;(or, in the case of 7, just a waste of time). 6 and 9 are very broad. Even if the conclusions (utilitarianism and libertarianism respectively) are 'correct' or 'right' in some sense (I would say not, but this isn't the place to thrash it out) I do think it would be a mistake to justify them to oneself using philosophical beliefs about determinate, autonomous, 'sovereign' mental states.</p>\n<p>Would anyone like to add any others? Or vehemently disagree with me about something on my list? :-)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ha4Dvys9gA9hWTWSg", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6545", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T17:29:23.350Z", "modifiedAt": null, "url": null, "title": "Examine success as much as failure", "slug": "examine-success-as-much-as-failure", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.369Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "gwern", "createdAt": "2009-02-27T22:16:11.237Z", "isAdmin": false, "displayName": "gwern"}, "userId": "BtbwfsEyeT4P2eqXu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iHYZooz6DzQNhc5jE/examine-success-as-much-as-failure", "pageUrlRelative": "/posts/iHYZooz6DzQNhc5jE/examine-success-as-much-as-failure", "linkUrl": "https://www.lesswrong.com/posts/iHYZooz6DzQNhc5jE/examine-success-as-much-as-failure", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Examine%20success%20as%20much%20as%20failure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AExamine%20success%20as%20much%20as%20failure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiHYZooz6DzQNhc5jE%2Fexamine-success-as-much-as-failure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Examine%20success%20as%20much%20as%20failure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiHYZooz6DzQNhc5jE%2Fexamine-success-as-much-as-failure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiHYZooz6DzQNhc5jE%2Fexamine-success-as-much-as-failure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 51, "htmlBody": "<p><em>Harvard Business Review</em> has posted something right up our alley:  <a href=\"http://hbr.org/2011/04/why-leaders-dont-learn-from-success/ar/pr\">\"Why Leaders Don't Learn From Success\"</a></p>\n<p>Also, the HBR essay links to a similar discussion of how Pixar avoids being brainwashed by its own success (something I had always wondered about - they seem <em>too</em> consistently successful): <a href=\"http://www.mekonginsight.com/?p=579\">\"How Pixar Fosters Collective Creativity\"</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iHYZooz6DzQNhc5jE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 6.966787078898629e-07, "legacy": true, "legacyId": "6547", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T19:22:53.421Z", "modifiedAt": null, "url": null, "title": "Analyzing our discussions in other forums", "slug": "analyzing-our-discussions-in-other-forums", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:16.369Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ArisKatsaris", "createdAt": "2010-10-07T10:24:25.721Z", "isAdmin": false, "displayName": "ArisKatsaris"}, "userId": "fLbksBTnFsbwYmzsT", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Y5PMuNvRFhr4C9m4P/analyzing-our-discussions-in-other-forums", "pageUrlRelative": "/posts/Y5PMuNvRFhr4C9m4P/analyzing-our-discussions-in-other-forums", "linkUrl": "https://www.lesswrong.com/posts/Y5PMuNvRFhr4C9m4P/analyzing-our-discussions-in-other-forums", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Analyzing%20our%20discussions%20in%20other%20forums&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnalyzing%20our%20discussions%20in%20other%20forums%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY5PMuNvRFhr4C9m4P%2Fanalyzing-our-discussions-in-other-forums%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Analyzing%20our%20discussions%20in%20other%20forums%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY5PMuNvRFhr4C9m4P%2Fanalyzing-our-discussions-in-other-forums", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FY5PMuNvRFhr4C9m4P%2Fanalyzing-our-discussions-in-other-forums", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 232, "htmlBody": "<p>I frequent several boards about several topics, mainly fandom-related ones. In the large majority of them, I've eventually felt&nbsp; the urgent need to inject some rationalist ideas into threads that seemed to be sorely needing them.</p>\n<p>Even in the best of cases, those that don't devolve into flame wars and remain overall polite, I usually meet with limited success at best. So I wonder -- assuming my own experience is shared by others here -- should we perhaps share links for some of those threads, and discuss here how we could have handled the conversation better, possibly how we could have had more success injecting rationality than we actually did?</p>\n<p>The most recent such discussion I had was today, in the forums of Gunnerkrigg Court. I made a post very early on in the thread in question, but my real contribution began <a title=\"here\" href=\"http://gunnerkrigg.proboards.com/index.cgi?action=display&amp;board=general&amp;thread=1253&amp;page=2#54658\">here</a> after another poster (who actually seemed science-minded in desire, if not in practice!) asked \"What if the soul is the energy?\" I had to cringe at that, and tried to explain how meaningless a statement that was -- but I don't seem to have succeeded much, even though I don't know how I could have done better.</p>\n<p>Please say what you think about my idea of discussing our threads in other forums in general, and/or any ideas you have about how I could have handled better that specific thread in particular...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Y5PMuNvRFhr4C9m4P", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 13, "extendedScore": null, "score": 6.967101646048156e-07, "legacy": true, "legacyId": "6548", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T20:29:25.878Z", "modifiedAt": null, "url": null, "title": "Seattle Meetup Sun April 10th 5pm + new mailing list", "slug": "seattle-meetup-sun-april-10th-5pm-new-mailing-list", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.045Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HvFdtsvwEs3m6DeTK/seattle-meetup-sun-april-10th-5pm-new-mailing-list", "pageUrlRelative": "/posts/HvFdtsvwEs3m6DeTK/seattle-meetup-sun-april-10th-5pm-new-mailing-list", "linkUrl": "https://www.lesswrong.com/posts/HvFdtsvwEs3m6DeTK/seattle-meetup-sun-april-10th-5pm-new-mailing-list", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Seattle%20Meetup%20Sun%20April%2010th%205pm%20%2B%20new%20mailing%20list&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeattle%20Meetup%20Sun%20April%2010th%205pm%20%2B%20new%20mailing%20list%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHvFdtsvwEs3m6DeTK%2Fseattle-meetup-sun-april-10th-5pm-new-mailing-list%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Seattle%20Meetup%20Sun%20April%2010th%205pm%20%2B%20new%20mailing%20list%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHvFdtsvwEs3m6DeTK%2Fseattle-meetup-sun-april-10th-5pm-new-mailing-list", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHvFdtsvwEs3m6DeTK%2Fseattle-meetup-sun-april-10th-5pm-new-mailing-list", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 83, "htmlBody": "<p>&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">The last Seattle meetup was fun, so we're having another! Same place and time:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Big Time Brewery</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">4133 University Way NE</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Seattle, WA&nbsp; 98105</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Sunday, April 10, 5 pm</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><a href=\"http://maps.google.com/maps/place?um=1&amp;ie=UTF-8&amp;q=big+time+brewery&amp;fb=1&amp;gl=us&amp;hq=big+time+brewery&amp;hnear=Seattle,+WA&amp;cid=16616735976939019097\">google maps</a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">The place is open to minors until 8 pm. &nbsp;We'll be there with a sign reading \"LW\".&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19px;\">There is now also a <a href=\"http://groups.google.com/group/lw-seattle\">mailing list</a></span></span><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19px;\">&nbsp;for&nbsp;arranging&nbsp;meetups and chatting to LW people in Seattle.</span></span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">We will hopefully meet regularly in the future. If Sunday evenings do not work for you, say so in the comments or send an email to the mailing list.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HvFdtsvwEs3m6DeTK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6.9672860751556e-07, "legacy": true, "legacyId": "6549", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T20:35:50.058Z", "modifiedAt": null, "url": null, "title": "Link: Gizmodo discusses SIAI, matches donations", "slug": "link-gizmodo-discusses-siai-matches-donations", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:16.192Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Normal_Anomaly", "createdAt": "2010-11-14T03:31:54.691Z", "isAdmin": false, "displayName": "Normal_Anomaly"}, "userId": "WgGYj5bqcZKsFNG6F", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aBRhavTere8DejrBH/link-gizmodo-discusses-siai-matches-donations", "pageUrlRelative": "/posts/aBRhavTere8DejrBH/link-gizmodo-discusses-siai-matches-donations", "linkUrl": "https://www.lesswrong.com/posts/aBRhavTere8DejrBH/link-gizmodo-discusses-siai-matches-donations", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Gizmodo%20discusses%20SIAI%2C%20matches%20donations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Gizmodo%20discusses%20SIAI%2C%20matches%20donations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaBRhavTere8DejrBH%2Flink-gizmodo-discusses-siai-matches-donations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Gizmodo%20discusses%20SIAI%2C%20matches%20donations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaBRhavTere8DejrBH%2Flink-gizmodo-discusses-siai-matches-donations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaBRhavTere8DejrBH%2Flink-gizmodo-discusses-siai-matches-donations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 79, "htmlBody": "<p>Gizmodo, a popular technology blog, posted this artice about SIAI. It's partly tongue-in-cheek, but also apparently thinks well of the Singularity Institute, claiming they are \"a research organization that's as forward-thinking as most Gizmodo readers (read: sci-fi nerds).\" More importantly, they link to Philanthroper, where you can donate and see your donation be matched. File this under \"cultural penetration of Singularity memes\" and also as a chance to make your donation more effective.</p>\n<p>http://gizmodo.com/#!5787599/give-1-to-stop-terminators-seriously</p>\n<p>Edit: <a href=\"http://gizmodo.com/#!5787599/give-1-to-stop-terminators-seriously\">Better link to the above URL</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aBRhavTere8DejrBH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 6.967303822441428e-07, "legacy": true, "legacyId": "6550", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-03-31T21:01:01.878Z", "modifiedAt": null, "url": null, "title": "Baltimore Meetup 4/10 1PM", "slug": "baltimore-meetup-4-10-1pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.064Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "groupuscule", "createdAt": "2009-11-16T02:54:49.400Z", "isAdmin": false, "displayName": "groupuscule"}, "userId": "KnHguEErzcfgo37dJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/oE37e48WwQekGbWPH/baltimore-meetup-4-10-1pm", "pageUrlRelative": "/posts/oE37e48WwQekGbWPH/baltimore-meetup-4-10-1pm", "linkUrl": "https://www.lesswrong.com/posts/oE37e48WwQekGbWPH/baltimore-meetup-4-10-1pm", "postedAtFormatted": "Thursday, March 31st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Baltimore%20Meetup%204%2F10%201PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABaltimore%20Meetup%204%2F10%201PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoE37e48WwQekGbWPH%2Fbaltimore-meetup-4-10-1pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Baltimore%20Meetup%204%2F10%201PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoE37e48WwQekGbWPH%2Fbaltimore-meetup-4-10-1pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FoE37e48WwQekGbWPH%2Fbaltimore-meetup-4-10-1pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 6, "htmlBody": "<p><a id=\"more\"></a>Date: Sunday April 10</p>\n<p>Time: 1PM</p>\n<p>Location: <a href=\"http://maps.google.com/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=charmington's&amp;sll=39.320049,-76.611108&amp;sspn=0.011238,0.021865&amp;ie=UTF8&amp;hq=charmington's&amp;hnear=&amp;ll=39.31896,-76.620884&amp;spn=0.022477,0.043731&amp;z=15\">Charmington's</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "oE37e48WwQekGbWPH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 6.967373662552997e-07, "legacy": true, "legacyId": "6552", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T01:48:37.732Z", "modifiedAt": null, "url": null, "title": "Anyone read Erfworld?", "slug": "anyone-read-erfworld", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:21.410Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/scDB2qHwT9PXGkE8A/anyone-read-erfworld", "pageUrlRelative": "/posts/scDB2qHwT9PXGkE8A/anyone-read-erfworld", "linkUrl": "https://www.lesswrong.com/posts/scDB2qHwT9PXGkE8A/anyone-read-erfworld", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anyone%20read%20Erfworld%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnyone%20read%20Erfworld%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscDB2qHwT9PXGkE8A%2Fanyone-read-erfworld%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anyone%20read%20Erfworld%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscDB2qHwT9PXGkE8A%2Fanyone-read-erfworld", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FscDB2qHwT9PXGkE8A%2Fanyone-read-erfworld", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 379, "htmlBody": "<p>Periodically people link to \"rationalist\" stories (or comics that are not really rational at all, that just happen to be vaguely related to AI), so I was a bit surprised to find not a single reference to Erfworld on a Lesswrong search.&nbsp;</p>\n<p><a title=\"Erfworld\" href=\"http://www.erfworld.com/book-1-archive/?px=%2F001.jpg\">Erfworld</a> is a webcomic that essentially tells the same story as Harry Potter and the Methods of Rationality. Regular (but very smart) guy is transported to magical world. He systematically tries to understand the rules of that world and accomplishes all kinds of awesome stuff as a result. I feel like I've read the story a bunch of times, but HP:MoR and Erfworld are the only ones I recall that really did it justice on an epic scale.</p>\n<p>While in many ways it's almost identical, it's playing with a different set of rules than Harry is, and the jokes and philosophical questions are playing around with different material. The main character is a strategy war gamer, and he finds himself summoned into a world that runs on Turn Based Strategy Rules. People can only take certain actions on their own \"turn.\" Everyone has \"stats\", gain experience and level up. At first the whole thing seems like a silly gimmick, with the protagonist benefiting from genre-savviness. He starts out asking basic questions about the rules. Later on he starts challenging those rules - what is an actual law of the universe and what is merely convention that the inhabitants follow. Eventually he starts grappling with questions about how the morality of his old world plays into the morality of a world where everyone is tied ideologically to the side that they were created to serve, and people are not born - they pop into existence as adults as soon as their commander pays for them.</p>\n<p>I think it does a better job of showing how a \"real,\" \"typical\" smart person would try and understand a new, strange world. Harry is awesome, but he strains credibility in regards to how much he knows at the age he knows it.</p>\n<p>Book 1 is done, and is a very solid, complete work that I recommend on its own.&nbsp;It features what is, to my recollection, the best use of the F-word in a work of fiction.</p>\n<p>&nbsp;</p>\n<p>Book 2's still in progress. <a href=\"http://www.erfworld.com/book-1-archive/?px=%2F001.jpg\">You can start reading here.</a>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GBpwq8cWvaeRoE9X5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "scDB2qHwT9PXGkE8A", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 32, "extendedScore": null, "score": 6.968169555503244e-07, "legacy": true, "legacyId": "6557", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T03:37:02.357Z", "modifiedAt": null, "url": null, "title": "Dense Math Notation", "slug": "dense-math-notation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:25.455Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JK_Ravenclaw", "createdAt": "2010-12-18T17:44:28.376Z", "isAdmin": false, "displayName": "JK_Ravenclaw"}, "userId": "GttNkFPbQbPkxsR79", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HLqkT4XgFtqT5P2tY/dense-math-notation", "pageUrlRelative": "/posts/HLqkT4XgFtqT5P2tY/dense-math-notation", "linkUrl": "https://www.lesswrong.com/posts/HLqkT4XgFtqT5P2tY/dense-math-notation", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Dense%20Math%20Notation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADense%20Math%20Notation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLqkT4XgFtqT5P2tY%2Fdense-math-notation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Dense%20Math%20Notation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLqkT4XgFtqT5P2tY%2Fdense-math-notation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLqkT4XgFtqT5P2tY%2Fdense-math-notation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 244, "htmlBody": "<p>I program, and am also presently working my way through some math books. I find that I often have to backtrack to look up pieces of notation like variables and operators. Unfortunately, this is very problematic. Greek and Latin letters give no indication of where they came from and are not usable search terms, even knowing the full context in which they appeared. Many authors have their own bits of idiosyncratic notation, often combinations of subscripting and line art generated by TeX macros. Since expanding equations out to their definitions is so difficult, I sometimes don't bother to investigate when one looks odd, which as you might expect leads to big trouble later when errors in understanding creep by.</p>\n<p>This is not nearly as big a problem for me when reading code, however, because there every variable and nonstandard operator has a descriptive name wherever it's used, and documentation is never more than a few hotkeys away. The same thing could be done for math. Suppose you took a typical higher math book, and replaced every single-letter variable and operator with an appropriate identifier. For me, this would make it much more readable; I would gain a better understanding in less time. However, I don't know the effect size or how broadly this generalizes.</p>\n<p>Do other people have this problem? Might this issue deter some people from studying math entirely? Has anyone tried the obvious controlled experiment? How about with an experimental group specifically of programmers?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"6nS8oYmSMuFMaiowF": 1, "EdDGrAxYcrXnKkDca": 1, "7mTviCYysGmLqiHai": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HLqkT4XgFtqT5P2tY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 33, "extendedScore": null, "score": 6.968471466163975e-07, "legacy": true, "legacyId": "6561", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T04:46:40.305Z", "modifiedAt": null, "url": null, "title": "Decision theory and partition dependence", "slug": "decision-theory-and-partition-dependence", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:09.591Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "4226XqZuqq6N4Qore", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7QaT2L6XyenfSDbCW/decision-theory-and-partition-dependence", "pageUrlRelative": "/posts/7QaT2L6XyenfSDbCW/decision-theory-and-partition-dependence", "linkUrl": "https://www.lesswrong.com/posts/7QaT2L6XyenfSDbCW/decision-theory-and-partition-dependence", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Decision%20theory%20and%20partition%20dependence&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADecision%20theory%20and%20partition%20dependence%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7QaT2L6XyenfSDbCW%2Fdecision-theory-and-partition-dependence%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Decision%20theory%20and%20partition%20dependence%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7QaT2L6XyenfSDbCW%2Fdecision-theory-and-partition-dependence", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7QaT2L6XyenfSDbCW%2Fdecision-theory-and-partition-dependence", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 255, "htmlBody": "<p class=\"western\" style=\"margin-bottom: 0cm;\">I'm trying to understand partition dependence in causal decision theories and I'm struggling to think of a case where an act (as opposed to simply the expected utility) is partition dependent. Some detail (very much in order of what I'm wanting to figure out):</p>\n<p class=\"western\" style=\"margin-bottom: 0cm;\">1.) I known that Joyce's causal decision theory is partition-invariant but Sobel's and Lewis's theories aren't and require some specification of what partition is adequate. What happens if such a specification isn't provided? More specifically, what's an example of a decision problem where the acts are partition dependent if you don't ensure you use only adequate partitions?</p>\n<p>2.) Extending this: If you do make sure to only use adequate partitions, are there still problems with partition-dependence (other than the small world/grand world problem that Joyce talks about)? In other words, do current definitions of adequate partions:</p>\n<p>i.) Ensure that no act will be partition dependent in decision problems that can be discussed.</p>\n<p>ii.) Allow all decision problems to be discussed.</p>\n<p>I guess what I'm trying to figure out is what the problem of decision dependence is. Is the problem that it means you require a definition of adequate partitions (but that such a definition is easy to find and solves the problem)? Or even with such a definition, does partition dependence still cause problems? Are these problems just about small world/grand world stuff or are they about other partition related issues as well?</p>\n<p>I can't seem to get my head around it and was hoping some concrete answers to my questions would help. Anyone able to help?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7QaT2L6XyenfSDbCW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "6562", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T05:25:59.052Z", "modifiedAt": null, "url": null, "title": "Link: \"Health Care Myth Busters: Is There a High Degree of Scientific Certainty in Modern Medicine?\"", "slug": "link-health-care-myth-busters-is-there-a-high-degree-of", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.802Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CronoDAS", "createdAt": "2009-02-27T04:42:19.587Z", "isAdmin": false, "displayName": "CronoDAS"}, "userId": "Q2oaNonArzibx5cQN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/huMyt5Hrjte7J3q8Y/link-health-care-myth-busters-is-there-a-high-degree-of", "pageUrlRelative": "/posts/huMyt5Hrjte7J3q8Y/link-health-care-myth-busters-is-there-a-high-degree-of", "linkUrl": "https://www.lesswrong.com/posts/huMyt5Hrjte7J3q8Y/link-health-care-myth-busters-is-there-a-high-degree-of", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20%22Health%20Care%20Myth%20Busters%3A%20Is%20There%20a%20High%20Degree%20of%20Scientific%20Certainty%20in%20Modern%20Medicine%3F%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20%22Health%20Care%20Myth%20Busters%3A%20Is%20There%20a%20High%20Degree%20of%20Scientific%20Certainty%20in%20Modern%20Medicine%3F%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhuMyt5Hrjte7J3q8Y%2Flink-health-care-myth-busters-is-there-a-high-degree-of%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20%22Health%20Care%20Myth%20Busters%3A%20Is%20There%20a%20High%20Degree%20of%20Scientific%20Certainty%20in%20Modern%20Medicine%3F%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhuMyt5Hrjte7J3q8Y%2Flink-health-care-myth-busters-is-there-a-high-degree-of", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhuMyt5Hrjte7J3q8Y%2Flink-health-care-myth-busters-is-there-a-high-degree-of", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 98, "htmlBody": "<p>A feature in Scientific American magazine casts some light on the troubled state of modern medicine.</p>\n<p class=\"articleTitle\"><a href=\"http://www.scientificamerican.com/article.cfm?id=demand-better-health-care-book\">Health Care Myth Busters: Is There a High Degree of Scientific Certainty in Modern Medicine?</a></p>\n<p class=\"articleTitle\">Short excerpt:</p>\n<blockquote>We could accurately say, \"Half of what physicians do is wrong,\" or \"Less than 20 percent of what physicians do has solid research to support it.\" Although these claims sound absurd, they are solidly supported by research that is largely agreed upon by experts. <br /></blockquote>\n<p>Scientific American often gates its online articles after some time has passed, so I don't know how long it will be available.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "huMyt5Hrjte7J3q8Y", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "6563", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 34, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T05:46:36.658Z", "modifiedAt": null, "url": null, "title": "Singularity Institute featured on Philanthroper", "slug": "singularity-institute-featured-on-philanthroper", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.673Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Louie", "createdAt": "2010-05-10T21:41:14.619Z", "isAdmin": false, "displayName": "Louie"}, "userId": "JPwZspDjBcfwwuy7W", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Sxn32Wc5LjB5unCWR/singularity-institute-featured-on-philanthroper", "pageUrlRelative": "/posts/Sxn32Wc5LjB5unCWR/singularity-institute-featured-on-philanthroper", "linkUrl": "https://www.lesswrong.com/posts/Sxn32Wc5LjB5unCWR/singularity-institute-featured-on-philanthroper", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20Institute%20featured%20on%20Philanthroper&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20Institute%20featured%20on%20Philanthroper%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSxn32Wc5LjB5unCWR%2Fsingularity-institute-featured-on-philanthroper%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20Institute%20featured%20on%20Philanthroper%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSxn32Wc5LjB5unCWR%2Fsingularity-institute-featured-on-philanthroper", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSxn32Wc5LjB5unCWR%2Fsingularity-institute-featured-on-philanthroper", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 110, "htmlBody": "<p>Singularity Institute is today's featured charity on <a href=\"https://philanthroper.com/deals/singularity-institute \">Philanthroper.com</a></p>\n<p>Philanthroper is a micro-giving site that profiles small charities hand-selected by their editors. Their site encourages donors to &ldquo;give every day&rdquo; by only requesting $1 contributions.</p>\n<p>A group of Singularity Institute donors has stepped forward to match all donations given through Philanthroper today so I'd encourage each of you to <strong>give $1 now</strong>&nbsp;if you support Singularity Institute and have a US-based bank account (Philanthroper requirement). We'd like to have a healthy total raised by the end of the day. The fundraiser has already been <a href=\"http://gizmodo.com/#!5787599/give-1-to-stop-terminators-seriously\">featured on Gizmodo</a>&nbsp;but please submit it to other news sites if you can.</p>\n<p>I signed up and gave my $1.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Sxn32Wc5LjB5unCWR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 15, "extendedScore": null, "score": 6.968830728048045e-07, "legacy": true, "legacyId": "6551", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T14:19:03.444Z", "modifiedAt": null, "url": null, "title": "An Anchoring Experiment", "slug": "an-anchoring-experiment", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.307Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "prase", "createdAt": "2009-02-28T10:00:10.260Z", "isAdmin": false, "displayName": "prase"}, "userId": "WAP32wvmNt9QdutSu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TTyxi2JCb7ZTmEZDB/an-anchoring-experiment", "pageUrlRelative": "/posts/TTyxi2JCb7ZTmEZDB/an-anchoring-experiment", "linkUrl": "https://www.lesswrong.com/posts/TTyxi2JCb7ZTmEZDB/an-anchoring-experiment", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20Anchoring%20Experiment&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20Anchoring%20Experiment%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTTyxi2JCb7ZTmEZDB%2Fan-anchoring-experiment%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20Anchoring%20Experiment%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTTyxi2JCb7ZTmEZDB%2Fan-anchoring-experiment", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTTyxi2JCb7ZTmEZDB%2Fan-anchoring-experiment", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 431, "htmlBody": "<p><strong>The experiment is closed, for the results look <a href=\"/r/discussion/lw/53d/an_anchoring_experiment_results/\">here</a>.</strong></p>\n<p>In recent discussion I have expressed an opinion that anchoring may, for some quantitative questions, cause the answer to lie further away from the correct value than the anchor itself. For concreteness, let's suppose that the correct value of a quantity <em>Q</em> is <em>x</em>, and the subject is asked whether <em>Q</em> is greater or lower than <em>y</em>, <em>y &gt; x</em>. My hypothesis is that the anchor moves the subject's probability distribution up as a whole, <em>including the part which already has been lying above y</em>. Therefore the subjects will positively answer the question \"Is <em>Q &gt; y</em> ?\" more often than their guess would exceed <em>y</em> if they were just asked to estimate the value of <em>Q</em> with no anchor given. One commenter apparently <a href=\"/lw/50z/mental_metadata/3sy3\">disagreed</a>. I thought it may be interesting to resolve the disagreement experimentally. (More generally, I would like to see how well LW audience fights the standard biases, and if this experiment turns out successful - which means the number of respondents be greater than, say, five - I would think about posting more of this kind.)</p>\n<p><em>How to participate:</em></p>\n<p>The experiment has two parts.</p>\n<p>First, toss a coin to decide whether you belong to the biased group I or the control group II for the first question. If you belong to the group I, look at a comment linked below, which will give you a question of form \"is <em>Q</em> is greater or lower than <em>y</em>\", where <em>y</em> is either significantly lower or significantly greater than the correct value of <em>Q</em>. The comment has a form of a typical LW poll. If you belong to the group II, look at different linked comment which asks \"what is the value of <em>Q</em>\", and then give your estimate in a subcomment there.</p>\n<p>The second part is completely analogical to the first one, only with a different question. If you have participated in the first part within the group I, take part in the group II for the second part, and vice versa. Try to eliminate the irrelevant biases: switch on the anti-kibitzer before looking on the group I questions to avoid being influenced by the votes of others. Don't read the subcomments of the group II questions before writing down your own.</p>\n<p>The hypothesis is that the percentage of the group I respondents answering incorrectly will be greater than the percentage of the group II respondents estimating on the incorrect side of the anchor.</p>\n<p>First part: <a href=\"/r/discussion/lw/52f/an_anchoring_experiment/3t2o\">Question for the group I</a>. <a href=\"/r/discussion/lw/52f/an_anchoring_experiment/3t2s\">Question for the group II</a>.</p>\n<p>Second part: <a href=\"/r/discussion/lw/52f/an_anchoring_experiment/3t2t\">Question for the group I</a>. <a href=\"/r/discussion/lw/52f/an_anchoring_experiment/3t2w\">Question for the group II</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TTyxi2JCb7ZTmEZDB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 17, "extendedScore": null, "score": 6.970251904254277e-07, "legacy": true, "legacyId": "6567", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 12, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 89, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SPmxzR56jkoxekZqQ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T19:28:07.295Z", "modifiedAt": null, "url": null, "title": "The Good News of Situationist Psychology", "slug": "the-good-news-of-situationist-psychology", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:31.003Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q5CjE8pRiACqTvhRM/the-good-news-of-situationist-psychology", "pageUrlRelative": "/posts/Q5CjE8pRiACqTvhRM/the-good-news-of-situationist-psychology", "linkUrl": "https://www.lesswrong.com/posts/Q5CjE8pRiACqTvhRM/the-good-news-of-situationist-psychology", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Good%20News%20of%20Situationist%20Psychology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Good%20News%20of%20Situationist%20Psychology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ5CjE8pRiACqTvhRM%2Fthe-good-news-of-situationist-psychology%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Good%20News%20of%20Situationist%20Psychology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ5CjE8pRiACqTvhRM%2Fthe-good-news-of-situationist-psychology", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ5CjE8pRiACqTvhRM%2Fthe-good-news-of-situationist-psychology", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 921, "htmlBody": "<p><span style=\"font-size: 11px;\">Part of the sequence:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a></span></p>\n<p>In 1961, Stanley Milgram began his famous <a href=\"http://en.wikipedia.org/wiki/Milgram_experiment\">obedience experiments</a>. He found that ordinary people would deliver (what they believed to be) excruciatingly painful electric shocks to another person if instructed to do so by an authority figure. Milgram claimed these results showed that in certain cases, people are more heavily influenced by their <em>situation</em>&nbsp;than by their internal character.</p>\n<p>Fifty years and hundreds of studies later, this kind of&nbsp;<em>situationism</em>&nbsp;is widely accepted for broad domains of human action. People can inflict incredible cruelties upon each other in a prison simulation.<sup>b</sup> Hurried passersby step over a stricken person in their path, while unhurried passersby stop to help.<sup>a</sup> Willingness to help varies with the <a href=\"http://en.wikipedia.org/wiki/Bystander_effect\">number of bystanders</a>, and with proximity to a fragrant bakery or cofee shop.<sup>c</sup><span style=\"font-size: 11px;\">&nbsp;</span>The list goes on and on.<sup>d</sup></p>\n<p>Our inability to realize how powerful the effect&nbsp;<em>situation</em> has on human action is so well-known that it has a name. Our tendency to over-value trait-based explanations of others' behavior and under-value <em>situation</em>-based explanations of their behavior is called the <a href=\"http://en.wikipedia.org/wiki/Fundamental_attribution_error\">fundamental attribution error</a>&nbsp;(aka <a href=\"http://wiki.lesswrong.com/wiki/Correspondence_bias\">correspondence bias</a>).</p>\n<p>Recently, some have worried that this understanding undermines the traditional picture we have of ourselves as stable persons with robust characteristics. How can we trust others if their unpredictable situation may have so powerful an effect that it overwhelms the effect of their virtuous character traits?</p>\n<p>But as I see it, situationist psychology is <em>wonderful news</em>, for it means we can change!</p>\n<p>If situation has a powerful effect on behavior, then we have significant powers to improve our own behavior. It would be much worse to discover that our behavior was almost entirely determined by traits we were born with and cannot control.</p>\n<p><a id=\"more\"></a></p>\n<p>For example, drug addicts can be more successful in beating addiction if they change their peer group - if they stop spending recreational time with other addicts, and spend time with drug-free people instead, or in a treatment environment.<sup>e</sup></p>\n<p>&nbsp;</p>\n<h4>Improving rationality</h4>\n<p>What about improving your rationality? Situationist psychology suggests it may be wise to surround yourself with fellow rationalists. Having now been a visiting fellow with the <a href=\"http://intelligence.org/\">Singularity Institute</a> for only two days, I can already tell that almost everyone I've met who is with the Singularity Institute or has been through its visiting fellows program is a level or two above me - not just in knowledge about Friendly AI and simulation arguments and so on, but in day-to-day rationality skills.</p>\n<p>It's fascinating to take part in a conversation with <em>really</em>&nbsp;trained rationalists. It might go something like this:</p>\n<blockquote>\n<p>Person One: \"I suspect that <em>P</em>, though I know that cognitive bias <em>A</em>&nbsp;and <em>B</em>&nbsp;and <em>C</em>&nbsp;are probably influencing me here. However, I think that evidence <em>X</em>&nbsp;and <em>Y</em>&nbsp;offer fairly strong support for <em>P</em>.\"</p>\n<p>Person Two: \"But what about <em>Z</em>? This provides evidence against <em>P</em>&nbsp;because blah blah blah...\"</p>\n<p>Person One: \"Huh. I hadn't thought that. Well, I'm going to downshift my probability that <em>P</em>.\"</p>\n<p>Person Three: \"But what about <em>W</em>? The way Schmidhuber argues is this: blah blah blah.\"</p>\n<p>Person One: \"No, that doesn't work because blah blah blah.\"</p>\n<p>Person Three: \"Hmmm. Well, I have a lot of confusion and uncertainty about that.\"</p>\n</blockquote>\n<p>This kind of thing can go on for hours, and not just on abstract subjects like simulation arguments, but also on more personal issues like fears and dreams and dating.</p>\n<p>I've had several of these many-hours-long group conversations already - people arguing vigorously, often 'trashing' others' views (with logic and evidence), but with everybody apparently willing to update their beliefs, nobody getting mad or hurt, and people even <em>making decisions to change something in their life</em>&nbsp;in response to a <a href=\"/lw/1fu/why_and_why_not_bayesian_updating/\">Bayesian update</a> about something.</p>\n<p>The community norms reinforce this behavior, and it has had an obvious effect. All these people have spent time living with at least two other rationalists for many months - most of them, for longer than that. I haven't done an experiment that allows causal inference, but... <em>community</em>&nbsp;seems to be working splendidly for improving rationality. And situationist psychology explains why.</p>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>Want to change your behavior, your self? In many cases, one of the most effective things you can do is to <em>change your situation</em>.</p>\n<p>Live with rationalists. Stop hanging out with downward-spiral, drug-abusing friends. Move to another state or province or nation. Get a different job. Spend more time at the park, less time at home. Or less time at the park, and more at home. Consider what you want to achieve, and how a change of situation might help you do that. Then change your situation, and change yourself.</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/cu2/the_power_of_reinforcement/\">The Power of Reinforcement</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/4su/how_to_be_happy/\">How to Be Happy</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>a</sup> Darley &amp; Batson (1973).</small></p>\n<p><small><sup>b</sup> Zimbardo et al. (1973).</small></p>\n<p><small><sup>c</sup>&nbsp;Baron (1997).</small></p>\n<p><small><sup>d</sup> Much of the literature is helpfully reviewed in Doris (2005).</small></p>\n<p><small><sup>e</sup> Velasquez et al. (2001); Connors et al. (2004, ch. 6.); Galanter (2010).</small></p>\n<p>&nbsp;</p>\n<h4>References</h4>\n<p><small>Baron (1997). The sweet smell of... helping: Effects of pleasant ambient fragrance on prosocial behavior in shopping malls. P<em>ersonality and Social Psychology Bulletin, 23</em>: 498-503.</small></p>\n<p><small>Connors, Donovan, &amp; DiClemente (2004). <em><a href=\"http://www.amazon.com/Substance-Abuse-Treatment-Stages-Change/dp/1593850972/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Substance abuse treatment and stages of change: Selecting and planning interventions</a></em>. Guilford.</small></p>\n<p><small>Darley &amp; Batson (1973). From Jerusalem to Jericho: a study of situational and dispositional variables in helping behavior. <em>Journal of Personality and Social Psychology, 27</em>: 100-108.</small></p>\n<p><small>Doris (2005). <em><a href=\"http://www.amazon.com/Lack-Character-Personality-Moral-Behavior/dp/0521608902/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Lack of Character</a></em>. Cambridge University Press.</small></p>\n<p><small>Galanter (2010). Network therapy. In Marc Galanter and Herbert Kleber (eds.), <em>Psychotherapy for the treatment of substance abuse</em> (pp. 249-276). American Psychiatric.</small></p>\n<p><small>Velasquez, Maurer, Crouch, &amp; DiClemente (2001). <em><a href=\"http://www.amazon.com/Group-Treatment-Substance-Stages-Change/dp/1572306254/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Group Treatment for Substance Abuse: A Stages-of-Change Therapy Manual</a></em>. Guilford.</small></p>\n<p><small>Zimbardo, Banks, Haney, &amp; Jaffee (1973). The mind is a formidable jailer: a pirandellian prison.&nbsp;<em>New York Times Magazine, April 8, 1973</em>, pp. 38-60.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Ng8Gice9KNkncxqcj": 1, "4R8JYu4QF2FqzJxE5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q5CjE8pRiACqTvhRM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 72, "baseScore": 76, "extendedScore": null, "score": 0.000139, "legacy": true, "legacyId": "6568", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 76, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><span style=\"font-size: 11px;\">Part of the sequence:&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">The Science of Winning at Life</a></span></p>\n<p>In 1961, Stanley Milgram began his famous <a href=\"http://en.wikipedia.org/wiki/Milgram_experiment\">obedience experiments</a>. He found that ordinary people would deliver (what they believed to be) excruciatingly painful electric shocks to another person if instructed to do so by an authority figure. Milgram claimed these results showed that in certain cases, people are more heavily influenced by their <em>situation</em>&nbsp;than by their internal character.</p>\n<p>Fifty years and hundreds of studies later, this kind of&nbsp;<em>situationism</em>&nbsp;is widely accepted for broad domains of human action. People can inflict incredible cruelties upon each other in a prison simulation.<sup>b</sup> Hurried passersby step over a stricken person in their path, while unhurried passersby stop to help.<sup>a</sup> Willingness to help varies with the <a href=\"http://en.wikipedia.org/wiki/Bystander_effect\">number of bystanders</a>, and with proximity to a fragrant bakery or cofee shop.<sup>c</sup><span style=\"font-size: 11px;\">&nbsp;</span>The list goes on and on.<sup>d</sup></p>\n<p>Our inability to realize how powerful the effect&nbsp;<em>situation</em> has on human action is so well-known that it has a name. Our tendency to over-value trait-based explanations of others' behavior and under-value <em>situation</em>-based explanations of their behavior is called the <a href=\"http://en.wikipedia.org/wiki/Fundamental_attribution_error\">fundamental attribution error</a>&nbsp;(aka <a href=\"http://wiki.lesswrong.com/wiki/Correspondence_bias\">correspondence bias</a>).</p>\n<p>Recently, some have worried that this understanding undermines the traditional picture we have of ourselves as stable persons with robust characteristics. How can we trust others if their unpredictable situation may have so powerful an effect that it overwhelms the effect of their virtuous character traits?</p>\n<p>But as I see it, situationist psychology is <em>wonderful news</em>, for it means we can change!</p>\n<p>If situation has a powerful effect on behavior, then we have significant powers to improve our own behavior. It would be much worse to discover that our behavior was almost entirely determined by traits we were born with and cannot control.</p>\n<p><a id=\"more\"></a></p>\n<p>For example, drug addicts can be more successful in beating addiction if they change their peer group - if they stop spending recreational time with other addicts, and spend time with drug-free people instead, or in a treatment environment.<sup>e</sup></p>\n<p>&nbsp;</p>\n<h4 id=\"Improving_rationality\">Improving rationality</h4>\n<p>What about improving your rationality? Situationist psychology suggests it may be wise to surround yourself with fellow rationalists. Having now been a visiting fellow with the <a href=\"http://intelligence.org/\">Singularity Institute</a> for only two days, I can already tell that almost everyone I've met who is with the Singularity Institute or has been through its visiting fellows program is a level or two above me - not just in knowledge about Friendly AI and simulation arguments and so on, but in day-to-day rationality skills.</p>\n<p>It's fascinating to take part in a conversation with <em>really</em>&nbsp;trained rationalists. It might go something like this:</p>\n<blockquote>\n<p>Person One: \"I suspect that <em>P</em>, though I know that cognitive bias <em>A</em>&nbsp;and <em>B</em>&nbsp;and <em>C</em>&nbsp;are probably influencing me here. However, I think that evidence <em>X</em>&nbsp;and <em>Y</em>&nbsp;offer fairly strong support for <em>P</em>.\"</p>\n<p>Person Two: \"But what about <em>Z</em>? This provides evidence against <em>P</em>&nbsp;because blah blah blah...\"</p>\n<p>Person One: \"Huh. I hadn't thought that. Well, I'm going to downshift my probability that <em>P</em>.\"</p>\n<p>Person Three: \"But what about <em>W</em>? The way Schmidhuber argues is this: blah blah blah.\"</p>\n<p>Person One: \"No, that doesn't work because blah blah blah.\"</p>\n<p>Person Three: \"Hmmm. Well, I have a lot of confusion and uncertainty about that.\"</p>\n</blockquote>\n<p>This kind of thing can go on for hours, and not just on abstract subjects like simulation arguments, but also on more personal issues like fears and dreams and dating.</p>\n<p>I've had several of these many-hours-long group conversations already - people arguing vigorously, often 'trashing' others' views (with logic and evidence), but with everybody apparently willing to update their beliefs, nobody getting mad or hurt, and people even <em>making decisions to change something in their life</em>&nbsp;in response to a <a href=\"/lw/1fu/why_and_why_not_bayesian_updating/\">Bayesian update</a> about something.</p>\n<p>The community norms reinforce this behavior, and it has had an obvious effect. All these people have spent time living with at least two other rationalists for many months - most of them, for longer than that. I haven't done an experiment that allows causal inference, but... <em>community</em>&nbsp;seems to be working splendidly for improving rationality. And situationist psychology explains why.</p>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>Want to change your behavior, your self? In many cases, one of the most effective things you can do is to <em>change your situation</em>.</p>\n<p>Live with rationalists. Stop hanging out with downward-spiral, drug-abusing friends. Move to another state or province or nation. Get a different job. Spend more time at the park, less time at home. Or less time at the park, and more at home. Consider what you want to achieve, and how a change of situation might help you do that. Then change your situation, and change yourself.</p>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/cu2/the_power_of_reinforcement/\">The Power of Reinforcement</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/4su/how_to_be_happy/\">How to Be Happy</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>a</sup> Darley &amp; Batson (1973).</small></p>\n<p><small><sup>b</sup> Zimbardo et al. (1973).</small></p>\n<p><small><sup>c</sup>&nbsp;Baron (1997).</small></p>\n<p><small><sup>d</sup> Much of the literature is helpfully reviewed in Doris (2005).</small></p>\n<p><small><sup>e</sup> Velasquez et al. (2001); Connors et al. (2004, ch. 6.); Galanter (2010).</small></p>\n<p>&nbsp;</p>\n<h4 id=\"References\">References</h4>\n<p><small>Baron (1997). The sweet smell of... helping: Effects of pleasant ambient fragrance on prosocial behavior in shopping malls. P<em>ersonality and Social Psychology Bulletin, 23</em>: 498-503.</small></p>\n<p><small>Connors, Donovan, &amp; DiClemente (2004). <em><a href=\"http://www.amazon.com/Substance-Abuse-Treatment-Stages-Change/dp/1593850972/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Substance abuse treatment and stages of change: Selecting and planning interventions</a></em>. Guilford.</small></p>\n<p><small>Darley &amp; Batson (1973). From Jerusalem to Jericho: a study of situational and dispositional variables in helping behavior. <em>Journal of Personality and Social Psychology, 27</em>: 100-108.</small></p>\n<p><small>Doris (2005). <em><a href=\"http://www.amazon.com/Lack-Character-Personality-Moral-Behavior/dp/0521608902/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Lack of Character</a></em>. Cambridge University Press.</small></p>\n<p><small>Galanter (2010). Network therapy. In Marc Galanter and Herbert Kleber (eds.), <em>Psychotherapy for the treatment of substance abuse</em> (pp. 249-276). American Psychiatric.</small></p>\n<p><small>Velasquez, Maurer, Crouch, &amp; DiClemente (2001). <em><a href=\"http://www.amazon.com/Group-Treatment-Substance-Stages-Change/dp/1572306254/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Group Treatment for Substance Abuse: A Stages-of-Change Therapy Manual</a></em>. Guilford.</small></p>\n<p><small>Zimbardo, Banks, Haney, &amp; Jaffee (1973). The mind is a formidable jailer: a pirandellian prison.&nbsp;<em>New York Times Magazine, April 8, 1973</em>, pp. 38-60.</small></p>", "sections": [{"title": "Improving rationality", "anchor": "Improving_rationality", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "48 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["W6nXfmKTrgaiaLSRg", "GGn8MBiY8Xz6NdNdH", "ZbgCx2ntD5eu8Cno9"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-01T20:11:37.523Z", "modifiedAt": null, "url": null, "title": "New Rationality Blog: 'Measure of Doubt'", "slug": "new-rationality-blog-measure-of-doubt", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:12.781Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/65kj5CS3bgGy62QQz/new-rationality-blog-measure-of-doubt", "pageUrlRelative": "/posts/65kj5CS3bgGy62QQz/new-rationality-blog-measure-of-doubt", "linkUrl": "https://www.lesswrong.com/posts/65kj5CS3bgGy62QQz/new-rationality-blog-measure-of-doubt", "postedAtFormatted": "Friday, April 1st 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20Rationality%20Blog%3A%20'Measure%20of%20Doubt'&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20Rationality%20Blog%3A%20'Measure%20of%20Doubt'%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F65kj5CS3bgGy62QQz%2Fnew-rationality-blog-measure-of-doubt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20Rationality%20Blog%3A%20'Measure%20of%20Doubt'%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F65kj5CS3bgGy62QQz%2Fnew-rationality-blog-measure-of-doubt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F65kj5CS3bgGy62QQz%2Fnew-rationality-blog-measure-of-doubt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 159, "htmlBody": "<p><a href=\"http://measureofdoubt.com/\">Measure of Doubt</a> is a new rationality blog from <a href=\"http://measureofdoubt.com/author/measureofdoubt/\">Julia</a> and <a href=\"http://measureofdoubt.com/author/jessegalef/\">Jesse</a> Galef (a sister-brother team), aimed at a much broader audience than Less Wrong.</p>\n<p>Julia is the author of the <a href=\"/lw/48i/are_intuitions_good_evidence_link/\">recently-linked</a> article <a href=\"http://rationallyspeaking.blogspot.com/2011/01/are-intuitions-good-evidence.html\">Are Intuitions Good Evidence?</a>&nbsp;and many other <a href=\"http://juliagalef.com/writing/\">writings</a>. I know less about <a href=\"http://www.youtube.com/watch?v=mgB762QNvM8\">Jesse</a>, but I can say a bit more about Julia. She co-hosts the <a href=\"http://www.rationallyspeakingpodcast.org/\">Rationally Speaking podcast</a> with philosopher-biologist Massimo Pigliucci. She writes quite a bit about <a href=\"http://rationallyspeaking.blogspot.com/2010/01/is-google-making-us-less-rational.html\">becoming more rational</a>, <a href=\"http://rationallyspeaking.blogspot.com/2010/06/dissolving-ultimate-question.html\">dissolving Big Questions</a>, and <a href=\"http://rationallyspeaking.blogspot.com/2010/02/how-to-want-to-change-your-mind.html\"><em>wanting</em>&nbsp;to change your mind</a>. Her video on <a href=\"http://measureofdoubt.com/2011/03/29/four-ways-to-define-rational/\">different definitions of 'rationality'</a> distinguishes Hollywood rationality, epistemic rationality, and instrumental rationality. She <a href=\"http://measureofdoubt.com/2011/03/31/mirror-paradox/\">explains the mirror paradox</a> <em>ala</em>&nbsp;Gary Drescher in <em>Good and Real</em>. She <a href=\"http://www.3quarksdaily.com/3quarksdaily/2011/03/teaching_science_with_magic.html\">blogged</a><em>&nbsp;Harry Potter and the Methods of Rationality</em>.</p>\n<p>I suspect Less Wrong readers will enjoy <a href=\"http://measureofdoubt.com/\">Measure of Doubt</a>, and will find it a useful place to send people who don't have the patience to read the Less Wrong Sequences and long posts about Bayesian updating and the relevance of universe-simulation arguments to decision theory.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "65kj5CS3bgGy62QQz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 24, "baseScore": 33, "extendedScore": null, "score": 6.971229984751957e-07, "legacy": true, "legacyId": "6569", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4GXBPWimqz9nyJkL4"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T04:13:34.789Z", "modifiedAt": null, "url": null, "title": "Q: What has Rationality Done for You?", "slug": "q-what-has-rationality-done-for-you", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:48.174Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4Yb52EoyqQ7TthFe5/q-what-has-rationality-done-for-you", "pageUrlRelative": "/posts/4Yb52EoyqQ7TthFe5/q-what-has-rationality-done-for-you", "linkUrl": "https://www.lesswrong.com/posts/4Yb52EoyqQ7TthFe5/q-what-has-rationality-done-for-you", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Q%3A%20What%20has%20Rationality%20Done%20for%20You%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AQ%3A%20What%20has%20Rationality%20Done%20for%20You%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yb52EoyqQ7TthFe5%2Fq-what-has-rationality-done-for-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Q%3A%20What%20has%20Rationality%20Done%20for%20You%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yb52EoyqQ7TthFe5%2Fq-what-has-rationality-done-for-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Yb52EoyqQ7TthFe5%2Fq-what-has-rationality-done-for-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 307, "htmlBody": "<p>So after reading <a href=\"/lw/50p/reflections_on_rationality_a_year_out/\">SarahC's latest post</a>&nbsp;I noticed that she's gotten a lot out of rationality.<br /><br />More importantly, she got different things out of it than I have.<br /><br />Off the top of my head, I've learned...</p>\n<ul>\n<li>that other people see themselves differently, and should be understood on their terms (mostly from <a href=\"/lw/i0/are_your_enemies_innately_evil/\">here</a>)</li>\n<li>that I can pay attention to what I'm doing, and try to notice patterns to make intervention more effective.</li>\n<li>the whole <a href=\"/lw/rb/possibility_and_couldness/\">utilitarian structure of having a goal that you take actions to achieve</a>, coupled with the idea of an <a href=\"/lw/tx/optimization/\">optimization process</a>. It was really helpful to me to realize that you can do whatever it takes to achieve something, not just what has been suggested.</li>\n<li>the importance/usefulness of <a href=\"/lw/of/dissolving_the_question/\">dissolving the question</a>/<a href=\"/lw/od/37_ways_that_words_can_be_wrong/\">how words work</a>&nbsp;(especially great when combined with previous part)</li>\n<li>that an <a href=\"/lw/i4/belief_in_belief/\">event is evidence for something</a>, not just what I think it can support</li>\n<li>to&nbsp;<a href=\"/lw/38x/bridging_inferential_gaps/33a9\">pull people in, don't force them</a>. Seriously that one is ridiculously useful. Thanks David Gerard.</li>\n<li>that things don't happen unless something makes them happen.</li>\n<li>that other people are smart and cool, and often have good advice</li>\n</ul>\n<div>On top of becoming a little bit more effective at a lot of things, and with many fewer problems.</div>\n<div>(I could post more on the consequences of this, but I'm going for a different point)</div>\n<p>Where she got...</p>\n<ul>\n<li>a habit of learning new skills</li>\n<li>better time-management habits</li>\n<li>an awesome community</li>\n<li>more initiative</li>\n<li>the idea that she can change the world</li>\n</ul>\n<p>I've only recently making a habit out of trying new things, and that's been going really well for me. Is there other low hanging fruit that I'm missing?<br /><br />What cool/important/useful things has rationality gotten you?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4Yb52EoyqQ7TthFe5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 18, "extendedScore": null, "score": 6.972567396616517e-07, "legacy": true, "legacyId": "6575", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 91, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SFG9Cm7mf5eP4juKs", "28bAMAxhoX3bwbAKC", "3buXtNiSK8gcRLMSG", "D7EcMhL26zFNbJ3ED", "Mc6QcrsbH5NRXbCRX", "FaJaCgqBKphrDzDSj", "CqyJzDZWvGhhFJ7dY"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T10:22:27.886Z", "modifiedAt": null, "url": null, "title": "[LINK] What\u2019s The Most Difficult CEO Skill? Managing Your Own Psychology", "slug": "link-what-s-the-most-difficult-ceo-skill-managing-your-own", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "David_Gerard", "createdAt": "2010-10-25T18:56:54.228Z", "isAdmin": false, "displayName": "David_Gerard"}, "userId": "KneTmopEjYGsaPYNi", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CYxiEtyd58254E4GK/link-what-s-the-most-difficult-ceo-skill-managing-your-own", "pageUrlRelative": "/posts/CYxiEtyd58254E4GK/link-what-s-the-most-difficult-ceo-skill-managing-your-own", "linkUrl": "https://www.lesswrong.com/posts/CYxiEtyd58254E4GK/link-what-s-the-most-difficult-ceo-skill-managing-your-own", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20What%E2%80%99s%20The%20Most%20Difficult%20CEO%20Skill%3F%20Managing%20Your%20Own%20Psychology&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20What%E2%80%99s%20The%20Most%20Difficult%20CEO%20Skill%3F%20Managing%20Your%20Own%20Psychology%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCYxiEtyd58254E4GK%2Flink-what-s-the-most-difficult-ceo-skill-managing-your-own%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20What%E2%80%99s%20The%20Most%20Difficult%20CEO%20Skill%3F%20Managing%20Your%20Own%20Psychology%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCYxiEtyd58254E4GK%2Flink-what-s-the-most-difficult-ceo-skill-managing-your-own", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCYxiEtyd58254E4GK%2Flink-what-s-the-most-difficult-ceo-skill-managing-your-own", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 185, "htmlBody": "<p>The general application to life - ultimately, you are the person responsible for turning the crank that makes your world go round - is obvious. His methods to deal with it will ring true with LW readers.</p>\n<p style=\"padding-left: 30px;\">By far the most difficult skill for me to learn as CEO was the ability to manage my own psychology. Organizational design, process design, metrics, hiring and firing were all relatively straightforward skills to master compared to keeping my mind in check. Over the years, I&rsquo;ve spoken to hundreds of CEOs all with the same experience. Nonetheless, very few people talk about it and I have never read anything on the topic. It&rsquo;s like the fight club of management: The first rule of the CEO psychological meltdown is don&rsquo;t talk about the psychological meltdown.</p>\n<p style=\"padding-left: 30px;\">[...]</p>\n<p style=\"padding-left: 30px;\">This means that you will face a broad set of things that you don&rsquo;t know how to do that require skills that you don&rsquo;t have. Nevertheless, everybody will expect you to know how to do them, because, well, you are the CEO.</p>\n<p>Ben Horowitz. <a href=\"http://bhorowitz.com/2011/04/01/what%E2%80%99s-the-most-difficult-ceo-skill-managing-your-own-psychology/\">\"What&rsquo;s The Most Difficult CEO Skill? Managing Your Own Psychology.\"</a> <em>Ben's Blog</em>, 2001-04-01.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CYxiEtyd58254E4GK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "6583", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T11:07:30.995Z", "modifiedAt": null, "url": null, "title": "Inclusive fitness", "slug": "inclusive-fitness", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cerebus", "createdAt": "2009-04-17T11:35:40.072Z", "isAdmin": false, "displayName": "cerebus"}, "userId": "JXtLRSjXNt8vjffnF", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Fz5kFgP895dAehRns/inclusive-fitness", "pageUrlRelative": "/posts/Fz5kFgP895dAehRns/inclusive-fitness", "linkUrl": "https://www.lesswrong.com/posts/Fz5kFgP895dAehRns/inclusive-fitness", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Inclusive%20fitness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInclusive%20fitness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFz5kFgP895dAehRns%2Finclusive-fitness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Inclusive%20fitness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFz5kFgP895dAehRns%2Finclusive-fitness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFz5kFgP895dAehRns%2Finclusive-fitness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 12, "htmlBody": "<p>http://www.youtube.com/embed/zHYsTSmD84w</p>\n<p>&nbsp;</p>\n<p>Yes, pretty sure they <em>did</em> just compare E.O. Wilson to Bill O'Reilly.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Fz5kFgP895dAehRns", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": -2, "extendedScore": null, "score": 6.973716423211462e-07, "legacy": true, "legacyId": "6584", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T11:36:01.147Z", "modifiedAt": null, "url": null, "title": "I want a better memory.", "slug": "i-want-a-better-memory", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:03.954Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fb2tg9LDN3jC7gpXZ/i-want-a-better-memory", "pageUrlRelative": "/posts/fb2tg9LDN3jC7gpXZ/i-want-a-better-memory", "linkUrl": "https://www.lesswrong.com/posts/fb2tg9LDN3jC7gpXZ/i-want-a-better-memory", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20I%20want%20a%20better%20memory.&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AI%20want%20a%20better%20memory.%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffb2tg9LDN3jC7gpXZ%2Fi-want-a-better-memory%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=I%20want%20a%20better%20memory.%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffb2tg9LDN3jC7gpXZ%2Fi-want-a-better-memory", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ffb2tg9LDN3jC7gpXZ%2Fi-want-a-better-memory", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 405, "htmlBody": "<p>I suspect that forgetfulness is the single largest hindrance to me improving my rationality. This isn't something I've seen others report on LessWrong, so I'm suspicious that I'm in some kind of self-serving spiral, or that I'm doing something obvious wrong. So,&nbsp;I'm seeking feedback on (a) whether the above statement is true -- whether forgetfulness is likely to really be a dominant hindrance; (b) what I can do about it; and (c) why others haven't reported this.</p>\n<p>Ways that I suspect&nbsp;forgetfulness&nbsp;harms me:</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>I forget past experiences that would otherwise allow me to observe correlations and&nbsp;extrapolate&nbsp;time-series style. Did my mood improve last time I called this friend? Was I more productive during that period where I got less sleep?</li>\n<li>I fail to recall evidence that would be salient when evaluating probabilities. This includes evidence relevant not only to coffee-time discussions on abstract topics, but also questions that occur to me about akrasia and the like.</li>\n<li>I can't remember names of authors and papers that could be relevant to ideas that arise during my research. Searching online for papers is fine for major literature reviews, but enormously expensive to evaluate hour-by-hour conjectures that occur to me.</li>\n<li>When I encounter the same problem multiple times, I forget how I solved the problem last time.</li>\n<li>When a new productivity/social/rationality strategy *does* work, I forget to keep using it. This isn't only about laziness: sometimes I actually wonder explicitly whether strategy X worked, and I can't remember.</li>\n<li>I forget names, faces, places, facts and figures. But I understand this one is quite common.</li>\n<li>I forget all the ways that forgetfulness frustrates me.</li>\n</ul>\n<p>Steps I've taken:</p>\n<ul>\n<li>I keep an elaborate diary with appointments like \"bring USB drive home from work\" and \"purchase bread en route to Sam's house\".</li>\n<li>I keep an elaborate e-notebook where I try to record my \"brain state\" so that I can more quickly pick up where I left off with my work.</li>\n<li>Every time I solve a technical problem, I write it down.</li>\n<li>I use a memory app called mnemosyne to memorize foreign language words, names of jitsu techniques, etc.</li>\n</ul>\n<div>The write-everything-down strategy has helped some, but it's *orders of magnitude less effective* than recalling stuff right from my brain. It's like replacing a CPU's L1 cache with a magnetic hard drive and expecting performance not to drop.</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"H2q58pKG6xFrv8bPz": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fb2tg9LDN3jC7gpXZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 24, "extendedScore": null, "score": 4.4e-05, "legacy": true, "legacyId": "6585", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T12:09:42.602Z", "modifiedAt": null, "url": null, "title": "The AI-box for hunter-gatherers", "slug": "the-ai-box-for-hunter-gatherers", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.041Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ReCwgAiFrvwnXagnp/the-ai-box-for-hunter-gatherers", "pageUrlRelative": "/posts/ReCwgAiFrvwnXagnp/the-ai-box-for-hunter-gatherers", "linkUrl": "https://www.lesswrong.com/posts/ReCwgAiFrvwnXagnp/the-ai-box-for-hunter-gatherers", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20AI-box%20for%20hunter-gatherers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20AI-box%20for%20hunter-gatherers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FReCwgAiFrvwnXagnp%2Fthe-ai-box-for-hunter-gatherers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20AI-box%20for%20hunter-gatherers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FReCwgAiFrvwnXagnp%2Fthe-ai-box-for-hunter-gatherers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FReCwgAiFrvwnXagnp%2Fthe-ai-box-for-hunter-gatherers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 348, "htmlBody": "<p>The following is a minor curiosity that occurred to me regarding real-world analogies to the AI-box concept.</p>\n<p>Fundamentally, the reason that we fear a randomly-chosen super-intelligent AI is twofold:</p>\n<p>&nbsp;</p>\n<ol>\n<li>It would be smarter than us, so it could outwit us no matter what its goals.</li>\n<li>We have no &nbsp;reason to expect its goals to exactly coincide with ours, so we expect its actions to be detrimental to us.</li>\n</ol>\n<div>Now, let's say you're playing a game with a wide range of outcomes, over which you have a well-defined utility function. Let's say you can choose a partner from some pool of potential partners, each with a random utility function. Let's say the intelligence of each player is known to you. It would be unwise to choose a player more intelligent than yourself because</div>\n<div><ol>\n<li>They could outwit you.</li>\n<li>You have no reason to expect their goals to coincide with yours.</li>\n</ol>\n<div>On the other hand, if you pick a less intelligent player then perhaps you could trick them into furthering your own goals, or at least ascertain whether their motives coincide with yours. At the very least you would be able to keep them from subverting your own goal-directed actions.</div>\n<div>I conjecture that this explains why people sometimes fear those more intelligent than themselves, and also why people sometimes act dumb. Imagine a hunter-gatherer group considering inviting an outsider to join them. If the outsider's motives are uncertain then the more intelligent the outsider, the less well-advised the group would be to let em in.</div>\n<div>In fact, a situation analogous to an AI-box could arise:</div>\n<div><strong>Group member 1</strong>: We should let this intelligent outsider in, but we should keep tabs on them should they act against us.</div>\n<div><strong>Group member 2</strong>: But the fact that they're more intelligent than us means that you *can't* expect to keep tabs on them.</div>\n<div><strong>Group member 1</strong>: But couldn't we set a test of their motives and only allow them in if they proves to have motives coinciding with ours?</div>\n<div><strong>Group member 2</strong>: &nbsp;<a href=\"http://www.yudkowsky.net/essays/aibox.html\">No matter what test you set, we can expect them to outwit us -- that's what intelligence means</a>.</div>\n<div><br /></div>\n</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ReCwgAiFrvwnXagnp", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 2.7e-05, "legacy": true, "legacyId": "6586", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T12:27:11.672Z", "modifiedAt": null, "url": null, "title": "Paris Meetup, Saturday April 30th, 2PM", "slug": "paris-meetup-saturday-april-30th-2pm-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.789Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Emile", "createdAt": "2009-02-27T09:35:34.359Z", "isAdmin": false, "displayName": "Emile"}, "userId": "4PkX6dj649JqKSh4s", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/w7HiuFcAzjbfz6zYB/paris-meetup-saturday-april-30th-2pm-0", "pageUrlRelative": "/posts/w7HiuFcAzjbfz6zYB/paris-meetup-saturday-april-30th-2pm-0", "linkUrl": "https://www.lesswrong.com/posts/w7HiuFcAzjbfz6zYB/paris-meetup-saturday-april-30th-2pm-0", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Paris%20Meetup%2C%20Saturday%20April%2030th%2C%202PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AParis%20Meetup%2C%20Saturday%20April%2030th%2C%202PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw7HiuFcAzjbfz6zYB%2Fparis-meetup-saturday-april-30th-2pm-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Paris%20Meetup%2C%20Saturday%20April%2030th%2C%202PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw7HiuFcAzjbfz6zYB%2Fparis-meetup-saturday-april-30th-2pm-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fw7HiuFcAzjbfz6zYB%2Fparis-meetup-saturday-april-30th-2pm-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 65, "htmlBody": "<p><strong>When</strong>:&nbsp; <del>Saturday, April 16st, 2:00 PM</del> Saturday, April 30th, 2PM.</p>\n<p><strong>Where</strong>: Au Pt'it Chat, a little Caf&eacute; near <a><span class=\"pp-place-title\"><span>Ch&acirc;telet</span></span></a>, which is <a href=\"http://maps.google.fr/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=paris&amp;aq=&amp;sll=48.860318,2.348306&amp;sspn=0.00186,0.004823&amp;gl=fr&amp;ie=UTF8&amp;hq=&amp;hnear=Paris,+%C3%8Ele-de-France&amp;ll=48.859206,2.347764&amp;spn=0.00084,0.004823&amp;z=18&amp;layer=c&amp;cbll=48.859205,2.347764&amp;panoid=KtpE5z8iB3CwytC7FkmpQA&amp;cbp=11,296.05,,0,12\">here</a>. I'll be there with a LessWrong sign.</p>\n<p><strong><a id=\"more\"></a></strong>I know there are a few LessWrongers that live around Paris, but I've only met Morendil ... so let's try a more formal meetup.</p>\n<p>Depending on the attendance, we could organize something more regular.</p>\n<p>Lurkers and newbies are very welcome!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "w7HiuFcAzjbfz6zYB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 6.973937635799534e-07, "legacy": true, "legacyId": "6587", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T14:01:05.081Z", "modifiedAt": null, "url": null, "title": "Describing how much attention you've paid to an argument", "slug": "describing-how-much-attention-you-ve-paid-to-an-argument", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.821Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5huogLzPZkAJrqRWQ/describing-how-much-attention-you-ve-paid-to-an-argument", "pageUrlRelative": "/posts/5huogLzPZkAJrqRWQ/describing-how-much-attention-you-ve-paid-to-an-argument", "linkUrl": "https://www.lesswrong.com/posts/5huogLzPZkAJrqRWQ/describing-how-much-attention-you-ve-paid-to-an-argument", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Describing%20how%20much%20attention%20you've%20paid%20to%20an%20argument&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADescribing%20how%20much%20attention%20you've%20paid%20to%20an%20argument%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5huogLzPZkAJrqRWQ%2Fdescribing-how-much-attention-you-ve-paid-to-an-argument%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Describing%20how%20much%20attention%20you've%20paid%20to%20an%20argument%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5huogLzPZkAJrqRWQ%2Fdescribing-how-much-attention-you-ve-paid-to-an-argument", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5huogLzPZkAJrqRWQ%2Fdescribing-how-much-attention-you-ve-paid-to-an-argument", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p>There seems to be a hole in English (I don't know about other languages) for efficiently describing how much attention you've paid to an argument.</p>\n<p>I can think of a variety of amounts and sorts of attention-- looks cool and plausible, examined for attractive arguments against the other side, checked math for accuracy, checked math for plausibility of application, looked for counter-arguments, looked for evidence in favor, checked factual material, checked for whether some parts are sound even if there are some errors.....</p>\n<p>Any other suggestions for types of attention?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5huogLzPZkAJrqRWQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 17, "extendedScore": null, "score": 6.974198322150187e-07, "legacy": true, "legacyId": "6588", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T15:41:39.303Z", "modifiedAt": null, "url": null, "title": "[LINK] Clothing as status signalling, logos and co-operation", "slug": "link-clothing-as-status-signalling-logos-and-co-operation", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.097Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Barry_Cotter", "createdAt": "2010-04-19T16:29:03.629Z", "isAdmin": false, "displayName": "Barry_Cotter"}, "userId": "5pZXxaf79kj37Rwq2", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/FrnjDFy5HeFx6a284/link-clothing-as-status-signalling-logos-and-co-operation", "pageUrlRelative": "/posts/FrnjDFy5HeFx6a284/link-clothing-as-status-signalling-logos-and-co-operation", "linkUrl": "https://www.lesswrong.com/posts/FrnjDFy5HeFx6a284/link-clothing-as-status-signalling-logos-and-co-operation", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Clothing%20as%20status%20signalling%2C%20logos%20and%20co-operation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Clothing%20as%20status%20signalling%2C%20logos%20and%20co-operation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrnjDFy5HeFx6a284%2Flink-clothing-as-status-signalling-logos-and-co-operation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Clothing%20as%20status%20signalling%2C%20logos%20and%20co-operation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrnjDFy5HeFx6a284%2Flink-clothing-as-status-signalling-logos-and-co-operation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FFrnjDFy5HeFx6a284%2Flink-clothing-as-status-signalling-logos-and-co-operation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 34, "htmlBody": "<p><a href=\"http://www.economist.com/node/18483423?story_id=18483423&amp;CFID=160796263&amp;CFTOKEN=71303356\">http://www.economist.com/node/18483423?story_id=18483423&amp;CFID=160796263&amp;CFTOKEN=71303356</a></p>\n<p>After reading this, I'm seriously considering finding someplace online that sells those little Lacoste crocodiles and sewing them onto all my shirts. The power of logos appears to be ridiculous for the trivial outlay.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"2EFq8dJbxKNzforjM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "FrnjDFy5HeFx6a284", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 14, "extendedScore": null, "score": 6.974477575278248e-07, "legacy": true, "legacyId": "6590", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T17:18:35.530Z", "modifiedAt": null, "url": null, "title": "Where does uncertainty come from?", "slug": "where-does-uncertainty-come-from", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.155Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MQiuhw6faHte9xcBS/where-does-uncertainty-come-from", "pageUrlRelative": "/posts/MQiuhw6faHte9xcBS/where-does-uncertainty-come-from", "linkUrl": "https://www.lesswrong.com/posts/MQiuhw6faHte9xcBS/where-does-uncertainty-come-from", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Where%20does%20uncertainty%20come%20from%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhere%20does%20uncertainty%20come%20from%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMQiuhw6faHte9xcBS%2Fwhere-does-uncertainty-come-from%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Where%20does%20uncertainty%20come%20from%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMQiuhw6faHte9xcBS%2Fwhere-does-uncertainty-come-from", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMQiuhw6faHte9xcBS%2Fwhere-does-uncertainty-come-from", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 947, "htmlBody": "<p>Idealized rational agents are often discussed as operating in an uncertain environment, or as using probabilities to correctly reason anthropically (especially in MWI or Tegmark style multiverses). I believe that both of these sources of uncertainty are essential for a rational agent, but thinking about them obscures an important (I suspect ultimately more important) type of uncertainty, faced by computationally bounded agents making predictions about a fixed, perfectly understood, deterministic universe. This type of uncertainty is described by Eliezer in <a href=\"/r/discussion/lw/3mn/discussion_for_eliezer_yudkowskys_paper_timeless/\">his description of TDT</a>, but he doesn't deal there with any of the mathematical theory that would govern such uncertainties. I am somewhat surprised that I have not encountered more discussion of this form of uncertainty and the difficulty of dealing with it mathematically.</p>\n<p>Consider a system consisting of two interacting algorithms: a predictor and a universe. Periodically the universe sends observations to the predictor, or asks the predictor to make a prediction (ie to answer some question about the state of the universe). The observer must answer these queries using some bounded resource as dictated by the universe; typically we imagine that the observer is allotted a fixed length of time. We rate the quality of a predictor by measuring how often its predictions agree with what the universe expects.</p>\n<p>Now suppose I give you the description of the universe, and ask for the description of a good predictor. In some universes, I believe that there are very good predictors who perform something like Bayesian inference over mathematical statements---despite the fact that any consistent assignment of probabilities gives most statements of interest probability either 0 or 1.</p>\n<p>For example, suppose that a particular theorem X would be useful to make future predictions. I would like to know whether or not X is true, but the proof may be too complex to deal with (or X may be independent of whatever axioms I have programmed the predictor to believe, or finding a perfectly valid proof may be too hard a problem...). To this end, the predictor may develop much more powerful rules of inference which allow it to establish the truth of X more directly, but which are only valid heuristically. That is, it may use rules of the form \"If A and B are true, C is probably true.\"</p>\n<p>This immediately raises two questions: how can we formally describe such a rule, and how could a predictor ever acquire this sort of probabilistic knowledge?</p>\n<div>One way to formalize this sort of knowledge is to assign statements---for example the statement, \"A and B =&gt; C\"---a probability. This works well for many classes of statements, such as \"The algorithm A will always output a prime factorization of its input.\" But we may think that a particularly implication is not likely to hold universally, while still suspecting that it does hold for a \"typical\" invocation in some appropriate sense. For example, we may use the rule \"From A(x), B(x), conclude C(x)\" and believe that the inference is valid with probability 95% for a random large x. I don't really have any idea how you should represent such knowledge, and I imagine that you could only say that a particular representation was good if it came along with a satisfactory theory for inference. <br /></div>\n<p>This does not answer the question of how such knowledge is acquired. I can be included as an axiom in a system: for example, I can believe the axioms of PA with probability 1, that ZFC is consistent with probability 99%, that the RH is true with probability 95%, that the RH is provable in ZFC with probability 90%, or that the results of my inference algorithm are \"well-calibrated\" in a precise sense with probability 50%. I can also derive probabilistic knowledge from exact knowledge: for example, I can believe that random strings probably have high Kolmogorov complexity; I can believe that if you randomly choose whether to negate a statement, the result is true with probabiltiy 50%. I can also learn acquire new beliefs by performing inference, once I already have some beliefs which are probabilistic. This is particularly important when combined with access to observations from the universe. For example, if I believe that algorithm A probably plays Go optimally, then when I observe A's play it alters many beliefs: it will affect my confidence that A actually plays optimally and all of the beliefs which shaped my belief that A plays optimally, it will affect my beliefs about the optimal play in that position, it may affect my beliefs about other Go playing algorithms I have considered, etc.</p>\n<p>The possibility of probabilistic rather than exact beliefs may also allow us to get around hard problems with self-reference. For example, it may be that I can be \"quite confident\" that \"almost everything\" I am \"quite confident\" about is true, while it can never be the case that I am certain that everything I am certain about is true. I feel that questions of this form are currently of fundamental importance to our efforts to understand automated reasoning (especially for agents who are actually embedded in the universe they are reasoning about) which makes me particularly interested in this form of uncertainty. Unfortunately, even to evaluate the possibility of an end-run around incompleteness requires a much deeper understanding of mathematical uncertainty than anyone seems to have yet developed.</p>\n<p>I haven't said anything of mathematical substance. What I mean to argue is that:</p>\n<p>1. This is an interesting and important mathematical question.</p>\n<p>2. There are a lot of mathematical subtleties involved; moreover, they don't just govern weird corner cases. It is generally unclear how to perform such inference or evaluate the correctness of a particular inference / the reasonableness of a set of beliefs. .</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MQiuhw6faHte9xcBS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 6.974746758703867e-07, "legacy": true, "legacyId": "6592", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 41, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["etq6bmu3sFjRfzLgt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T18:34:09.781Z", "modifiedAt": null, "url": null, "title": "Anthropics in a Tegmark Multiverse", "slug": "anthropics-in-a-tegmark-multiverse", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.296Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sEAW5KbWAf6onq9Mi/anthropics-in-a-tegmark-multiverse", "pageUrlRelative": "/posts/sEAW5KbWAf6onq9Mi/anthropics-in-a-tegmark-multiverse", "linkUrl": "https://www.lesswrong.com/posts/sEAW5KbWAf6onq9Mi/anthropics-in-a-tegmark-multiverse", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anthropics%20in%20a%20Tegmark%20Multiverse&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnthropics%20in%20a%20Tegmark%20Multiverse%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsEAW5KbWAf6onq9Mi%2Fanthropics-in-a-tegmark-multiverse%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anthropics%20in%20a%20Tegmark%20Multiverse%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsEAW5KbWAf6onq9Mi%2Fanthropics-in-a-tegmark-multiverse", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsEAW5KbWAf6onq9Mi%2Fanthropics-in-a-tegmark-multiverse", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 588, "htmlBody": "<p>I believe that the execution of a certain computation is a necessary and sufficient condition for my conscious experience. Following Tegmark, by \"execution\" I don't refer to any notion of physical existence--I suspect that the mathematical possibility of my thoughts implies conscious experience. By observing the world and postulating my own representativeness, I conjecture the following measure on different possible experiences: the probability of any particular experience drops off exponentially with the complexity required to specify the corresponding computation.</p>\n<p>It is typical to use some complexity prior to select a universe, and then to appeal to some different notion to handle the remaining anthropic reasoning (to ask: how many beings have my experiences within this universe?). What I am suggesting is to instead apply a complexity prior to our experiences directly.</p>\n<p>If I believe a brain embodying my thoughts exists in some simple universe, then my thoughts can be described precisely by first describing that universe and then pointing to the network of causal relationships which constitute my thoughts. If I have seen enough of the universe, then this will be the most concise description consistent with my experiences. If there are many \"copies\" of that brain within the universe, then it becomes that much easier to specify my thoughts. In fact, it is easy to check that you recover essentially intuitive anthropics in this way.</p>\n<p>This prior has a significant impact on the status of simulations. In general, making two simulations of a brain puts twice as much probability on the associated experiences. However, we no longer maintain substrate independence (which I now consider a good thing, having discovered that my naive treatment of anthropics for simulations is wildly inconsistent). The significance of a particular simulation depends on how difficult it is to specify (within the simple universe containing that simulation) the causal relationships that represent its thoughts. So if we imagine the process of \"splitting\" a simulation running on a computer which is two atoms thick, we predict that (at least under certain circumstances) the number of copies doubles but the complexity of specifying each one increases to cancel the effect.</p>\n<p>This prior also gives precise answers to anthropic questions in cosmology. Even in an infinite universe, description complexity still answers questions such as \"how much of you is there? Why aren't you a Boltzmann brain?\" (of course this still supposes that a complexity prior is applicable to the universe).</p>\n<p>This prior also, at least in principle, tells you how to handle anthropics across quantum worlds. Either it can account for the Born probabilities (possibly in conjunction with some additional physics, like stray probability mass wandering in from nearby incoherent worlds) or it can't. In that sense, this theory makes a testable \"prediction.\" If it does correctly explain the Born probabilities, then I feel significantly more confidence in my understanding of quantum mechanics and in this version of a mathematical multiverse. If it doesn't, then I tentatively reject this version of a mathematical multiverse (tentatively because there could certainly be more complicated things still happening in quantum mechanics, and I don't yet know of any satisfactory explanation for the Born probabilities).</p>\n<p>&nbsp;</p>\n<p>Edit: this idea is exactly the same as <a href=\"http://finney.org/hal/udassa/summary1.html\">UDASSA</a> as initially articulated by Wei Dai. I think it is a shame that the arguments aren't more widespread, since it very cleanly resolves some of my confusion about simulations and infinite cosmologies. My only contribution appears to be a slightly more concrete plan for calculating (or failing to calculate) the Born probabilities; I will report back later about how the computation goes.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sEAW5KbWAf6onq9Mi", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 19, "extendedScore": null, "score": 3.7e-05, "legacy": true, "legacyId": "6593", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-02T18:43:26.253Z", "modifiedAt": null, "url": null, "title": "Open Thread, April 2011", "slug": "open-thread-april-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:06.153Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ata", "createdAt": "2009-07-20T22:13:53.102Z", "isAdmin": false, "displayName": "ata"}, "userId": "KppHkGEqTNeDaGJTc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/c8CtACf3YqNWuGPhJ/open-thread-april-2011", "pageUrlRelative": "/posts/c8CtACf3YqNWuGPhJ/open-thread-april-2011", "linkUrl": "https://www.lesswrong.com/posts/c8CtACf3YqNWuGPhJ/open-thread-april-2011", "postedAtFormatted": "Saturday, April 2nd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Open%20Thread%2C%20April%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOpen%20Thread%2C%20April%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc8CtACf3YqNWuGPhJ%2Fopen-thread-april-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Open%20Thread%2C%20April%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc8CtACf3YqNWuGPhJ%2Fopen-thread-april-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fc8CtACf3YqNWuGPhJ%2Fopen-thread-april-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 24, "htmlBody": "<p>It seems we have agreed that open threads will continue but that they will go in the Discussion section, so here's this month's thread.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "c8CtACf3YqNWuGPhJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 6.97498237973264e-07, "legacy": true, "legacyId": "6594", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 111, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T03:16:34.335Z", "modifiedAt": null, "url": null, "title": "Cambridge Meetup", "slug": "cambridge-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:16.755Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mh3AJJrWxfjR7mJ5w/cambridge-meetup", "pageUrlRelative": "/posts/mh3AJJrWxfjR7mJ5w/cambridge-meetup", "linkUrl": "https://www.lesswrong.com/posts/mh3AJJrWxfjR7mJ5w/cambridge-meetup", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cambridge%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACambridge%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmh3AJJrWxfjR7mJ5w%2Fcambridge-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cambridge%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmh3AJJrWxfjR7mJ5w%2Fcambridge-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmh3AJJrWxfjR7mJ5w%2Fcambridge-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>I'm going to be in Boston from the 16th to 20somethingth doing college visits (Harvard and MIT).<br /><br />If I understand correctly, there are Cambridge meetups on the first and third Sundays of the month. However, the Harvard visit program has other things for me to do during that time, so I'm going to have to miss that.<br /><br />Is there anyone in Cambridge who I could meet up with while I'm there? &nbsp;I'll probably be pretty flexible while I'm at MIT, since I'm just planning to stay with friends there.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mh3AJJrWxfjR7mJ5w", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6596", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T07:56:35.589Z", "modifiedAt": null, "url": null, "title": "Helsinki meetup Saturday 9.4 (cancelled)", "slug": "helsinki-meetup-saturday-9-4-cancelled", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.501Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Bongo", "createdAt": "2009-02-27T12:08:06.258Z", "isAdmin": false, "displayName": "Bongo"}, "userId": "mLnNK3xEMczLs8ind", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a2fhaRKvEY2N3un3q/helsinki-meetup-saturday-9-4-cancelled", "pageUrlRelative": "/posts/a2fhaRKvEY2N3un3q/helsinki-meetup-saturday-9-4-cancelled", "linkUrl": "https://www.lesswrong.com/posts/a2fhaRKvEY2N3un3q/helsinki-meetup-saturday-9-4-cancelled", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Helsinki%20meetup%20Saturday%209.4%20(cancelled)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelsinki%20meetup%20Saturday%209.4%20(cancelled)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa2fhaRKvEY2N3un3q%2Fhelsinki-meetup-saturday-9-4-cancelled%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Helsinki%20meetup%20Saturday%209.4%20(cancelled)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa2fhaRKvEY2N3un3q%2Fhelsinki-meetup-saturday-9-4-cancelled", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa2fhaRKvEY2N3un3q%2Fhelsinki-meetup-saturday-9-4-cancelled", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p><strong><a id=\"more\"></a><del>Time:</del></strong><del> Saturday 9th of April from 15:00 onwards</del></p>\n<p><del><strong>Place:</strong> Cafe Picnic at Yliopistonkatu 5</del></p>\n<p>This is the second Helsinki meetup. <a href=\"/lw/4h8/helsinki_lw_meetup_sat_march_5th/\">The last one</a> was successful, going on for three hours with around ten people there. Like before, lurkers and newbies are extremely welcome, as well as people who don't speak Finnish but do speak English.</p>\n<p>This time, User:Erebus thought we could talk about at least these topics:</p>\n<ul>\n<li>concrete benefits of having read Less Wrong</li>\n<li>optimal career or study choices.</li>\n</ul>\n<p>but suggest more.</p>\n<p><strong>EDIT: The original time was a bad time, so the meetup at that time is hereby cancelled. What time would be better?</strong></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a2fhaRKvEY2N3un3q", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "6597", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bzqgrRTWpfsk9utaN"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T09:47:23.852Z", "modifiedAt": null, "url": null, "title": "London meetup, Sunday 1 May, 2pm, near Holborn", "slug": "london-meetup-sunday-1-may-2pm-near-holborn", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:36.439Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "ciphergoth", "createdAt": "2009-02-27T14:23:33.426Z", "isAdmin": false, "displayName": "Paul Crowley"}, "userId": "baGAQoNAH4hXaC6qf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yRo8STCdGu7ztsQva/london-meetup-sunday-1-may-2pm-near-holborn", "pageUrlRelative": "/posts/yRo8STCdGu7ztsQva/london-meetup-sunday-1-may-2pm-near-holborn", "linkUrl": "https://www.lesswrong.com/posts/yRo8STCdGu7ztsQva/london-meetup-sunday-1-may-2pm-near-holborn", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20London%20meetup%2C%20Sunday%201%20May%2C%202pm%2C%20near%20Holborn&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALondon%20meetup%2C%20Sunday%201%20May%2C%202pm%2C%20near%20Holborn%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRo8STCdGu7ztsQva%2Flondon-meetup-sunday-1-may-2pm-near-holborn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=London%20meetup%2C%20Sunday%201%20May%2C%202pm%2C%20near%20Holborn%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRo8STCdGu7ztsQva%2Flondon-meetup-sunday-1-may-2pm-near-holborn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FyRo8STCdGu7ztsQva%2Flondon-meetup-sunday-1-may-2pm-near-holborn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 85, "htmlBody": "<p><a id=\"more\"></a>The London LessWrong meetup takes place on the first Sunday of every other month. We're getting good at these now! &nbsp;The next one is 2011-05-01 14:00, at the&nbsp;<a href=\"http://maps.google.co.uk/maps?f=q&amp;source=s_q&amp;hl=en&amp;geocode=&amp;q=shakespeare's+head&amp;sll=51.42559,-0.130394&amp;sspn=0.011854,0.020943&amp;ie=UTF8&amp;hq=shakespeare's+head&amp;hnear=&amp;layer=c&amp;cbll=51.516734,-0.119933&amp;panoid=kXPwAeowAo9LzJJA34agOw&amp;cbp=11,76.42,,1,-1.06&amp;ll=51.516728,-0.124025&amp;spn=0.005622,0.022488&amp;z=16\">Shakespeares Head</a>&nbsp;(<a href=\"http://www.jdwetherspoon.co.uk/home/pubs/shakespeares-head\">official page</a>) on Kingsway near Holborn Tube station. &nbsp;Note that there's more than one pub in London with that name, so make sure you get the right one. &nbsp;As always, we'll have a big picture of a paperclip on the table so you can find us; I <a href=\"http://pics.babysimon.co.uk/index.py/photos/3902?tag=Paul\">look like this</a>. &nbsp;Hope to see lots of you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yRo8STCdGu7ztsQva", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 6.977493610617151e-07, "legacy": true, "legacyId": "6598", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T17:15:24.712Z", "modifiedAt": null, "url": null, "title": "The peril of ignoring emotions", "slug": "the-peril-of-ignoring-emotions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.920Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iA6dNPKFNhXd3JiZs/the-peril-of-ignoring-emotions", "pageUrlRelative": "/posts/iA6dNPKFNhXd3JiZs/the-peril-of-ignoring-emotions", "linkUrl": "https://www.lesswrong.com/posts/iA6dNPKFNhXd3JiZs/the-peril-of-ignoring-emotions", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20peril%20of%20ignoring%20emotions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20peril%20of%20ignoring%20emotions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA6dNPKFNhXd3JiZs%2Fthe-peril-of-ignoring-emotions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20peril%20of%20ignoring%20emotions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA6dNPKFNhXd3JiZs%2Fthe-peril-of-ignoring-emotions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiA6dNPKFNhXd3JiZs%2Fthe-peril-of-ignoring-emotions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 835, "htmlBody": "<p><!--StartFragment--></p>\n<p>Related to:&nbsp;<a href=\"/lw/1xh/living_luminously/\">Luminosity Sequence</a>, <a href=\"/lw/2ee/unknown_knowns_why_did_you_choose_to_be_monogamous/\">Unknown Knowns</a>,&nbsp;</p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Let me introduce you to a hypothetical high school student, Sally. She&rsquo;s smart and pretty and outgoing, and so are her friends. She considers herself a modern woman, sexually liberated, and this is in line with the lifestyle her friends practice. They think sex is normal and healthy and fun. Sally isn&rsquo;t just pretending in order to fit in; these really are her friends, this really is her milieu, and according to health class, sex between consenting adults is nothing to be ashamed of. Sally isn't a rigorous rationalist, although she likes to think of herself as rational, and she's no more self-aware than the average high school girl.&nbsp;</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Now Sally meets a boy, Bob, and she things he&rsquo;s cute, and he thinks she&rsquo;s cute too. Bob is part of her crowd. Her friends like him; he respects women and treats Sally well and, like any healthy teenage boy, fairly horny. According to her belief system, that shouldn&rsquo;t set off any alarm bells. She&rsquo;s been warned about abusive relationships, but Bob is a <em>nice guy</em></span><span lang=\"EN-GB\">. So when they go upstairs together at her friend&rsquo;s party, she has every reason to be excited and a little nervous, but not <em>uncomfortable</em></span><span lang=\"EN-GB\">. The idea that <em>Mom wouldn&rsquo;t approve </em></span><span lang=\"EN-GB\">is so obviously irrelevant that she ignores it completely.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">...And afterwards, she feels guilty and violated and horrible about herself, even though it was <em>her </em></span><span lang=\"EN-GB\">decision.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I used this example because I expect it&rsquo;s not unusual. On the surface, Sally&rsquo;s discomfort seems to come out of nowhere, but modern North American society is chock-full of contradictory beliefs about sex. Sex is normal and healthy. Sex is dirty. Sex is only for when you&rsquo;re married. If Sally&rsquo;s mother is Christian, or even just conservative, Sally would have internalized those beliefs when she was a child. It would have been hard <em>not </em></span><span lang=\"EN-GB\">to. They&rsquo;re her unknown knowns, and she may not have noticed them before, because there&rsquo;s a wide psychological gap between believing it&rsquo;s okay for <em>others </em></span><span lang=\"EN-GB\">to behave a particular way, and believing it&rsquo;s okay for <em>you</em></span><span lang=\"EN-GB\">. The meme &lsquo;don&rsquo;t pass judgement on other people&rsquo; is, I think, pretty widespread in North America and maybe more so in Canada, but so is holding oneself to a high standard...and those are contradictory.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">I think that the nagging, seemingly irrational moment of &lsquo;that doesn&rsquo;t feel right&rsquo; is <em>important</em></span><span lang=\"EN-GB\">. It potentially reveals something about the beliefs and attitudes you hold that you don&rsquo;t even know about. Sally&rsquo;s response to her nagging doubt could have been the following:</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\"><em>Hmm, that&rsquo;s interesting, why does it bother me so much that Mom would disapprove? I guess when we used to go to church, they said sex was only for when you&rsquo;re married. But I don&rsquo;t believe anything </em></span><span lang=\"EN-GB\">else <em>they said in church. ...Well, I guess I want Mom to be proud of me. I want her to praise me for doing well in school. And I think lying is wrong, so the fact that I either have to lie to her about having had sex, or face her disapproval, maybe that&rsquo;s why I&rsquo;m uncomfortable? But I don&rsquo;t want to say no, it&rsquo;ll make me look like a prude... Still, what if </em></span><span lang=\"EN-GB\">everyone <em>feels this way at the start? I know Alice went to church too when she was a kid, and her mom would </em></span><span lang=\"EN-GB\">kill <em>her if she knew she was sexually active, I wonder if that bothers Alice? Hmm, I think maybe it&rsquo;s still the right choice to sleep with Bob, but maybe I&rsquo;m taking this too lightly? Maybe this should be a big deal and I should feel anxious? After all, he might judge me anyway, he might think I&rsquo;m too easy, or a slut. Maybe I can just explain to him that I want to think about this longer... After all, why should I assume something is right just because they told us in health class? That&rsquo;s just like in church, it&rsquo;s taking someone else&rsquo;s opinion on faith. I&rsquo;ve never actually thought about this, I&rsquo;ve just followed other people. Who&rsquo;s to say </em></span><span lang=\"EN-GB\">they&rsquo;re <em>right?</em></span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">Whatever decision Sally makes, she probably won&rsquo;t feel violated. She <em>listened </em></span><span lang=\"EN-GB\">to her feelings and took them into consideration, even though they seemed irrational. As it turned out, they were a reasonable consequence of a belief-fragment that she hadn&rsquo;t even known she had. So as a consequence of stopping to think, she knows herself better too. She&rsquo;ll be better able to predict her behaviour in future situations. She&rsquo;ll be less likely to ignore her threshold-warning discomfort and make risky choices as a result of peer pressure alone. She&rsquo;ll be more likely to <em>think</em></span><span lang=\"EN-GB\">.</span></p>\n<p class=\"MsoNormal\"><span lang=\"EN-GB\">To conclude: emotions exist. They are real. If you ignore them and plow on ahead, you won&rsquo;t necessarily thank yourself afterwards. And that nagging feeling is a priceless moment to find out about your unknown knowns</span><span lang=\"EN-GB\">...which may not be rational, which may have been laid down in some previous era and never questioned since, but which part of you is going to try to uphold until you consciously deconstruct them.&nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iA6dNPKFNhXd3JiZs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 22, "extendedScore": null, "score": 6.978738802230881e-07, "legacy": true, "legacyId": "6600", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 103, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9o3Cjjem7AbmmZfBs", "hEeapgs2Y8tNyZkXD"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T17:26:54.597Z", "modifiedAt": null, "url": null, "title": "Manufacturing prejudice", "slug": "manufacturing-prejudice", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:31.481Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eLJANrQG3sbrPjZk2/manufacturing-prejudice", "pageUrlRelative": "/posts/eLJANrQG3sbrPjZk2/manufacturing-prejudice", "linkUrl": "https://www.lesswrong.com/posts/eLJANrQG3sbrPjZk2/manufacturing-prejudice", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Manufacturing%20prejudice&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AManufacturing%20prejudice%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeLJANrQG3sbrPjZk2%2Fmanufacturing-prejudice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Manufacturing%20prejudice%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeLJANrQG3sbrPjZk2%2Fmanufacturing-prejudice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeLJANrQG3sbrPjZk2%2Fmanufacturing-prejudice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 287, "htmlBody": "<p>There's a tradition in England - I don't know how old - of abusing red-headed people. &nbsp;It's a <a href=\"http://www.mirror.co.uk/news/top-stories/2010/04/24/7-death-threats-a-day-for-having-ginger-hair-115875-22208033/\">genuine prejudice</a>&nbsp;<a href=\"http://www.google.com/trends?q=ginger+hair&amp;ctab=0&amp;geo=all&amp;date=all&amp;sort=0\">in England</a>. &nbsp;From this&nbsp;<a href=\"http://ta-in.facebook.com/topic.php?uid=2204571866&amp;topic=4340\">facebook page</a>:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px; \">\n<p><span style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; line-height: 14px; \">'Ginger' in England basically is like saying:<br /><br />\"Look there's an ugly, smelly, no friends, socially unacceptable, negative, aggressive, angry, violent, unclean, nasty, non boyfriend material, low self esteem, unattractive, social misfit, nerdy, moron, low education, non human...etc etc etc\"<br /><br />The term 'ginger' didn't become 'mainstream' just because of that South Park episode, I was being shot at, having acid thrown over me, stabbed, headbutted, punched, spat on, kicked, dehumanised, singled out, socially excluded, avoided, belittled, character assassinated etc since I can remember and to be fair I found that treatment was at its peak years before that South Park episode was even thought up.</span></p>\n</blockquote>\n<p>This spread to the US in 2005, when Cartman tried to incite violence against redheads in a South Park episode with \"Kick a Ginger Day\".</p>\n<p>What's interesting is how this meme is spreading in the US: As humor. &nbsp;This meme is promoted by sites like CollegeHumor.com and MyLifeIsAverage.com, which mine it as a source of ironic humor. &nbsp;The Cheezburger Network is pushing ginger-hatred almost as aggressively as they push pedophilia as a fount of humor.</p>\n<p>Are humans capable of, collectively, keeping real and humorous/ironic racism separate? &nbsp;<a href=\"http://www.calgarysun.com/news/alberta/2009/05/09/9405226-sun.html\">No,</a>&nbsp;<a href=\"http://middletownpress.com/articles/2011/03/06/news/doc4d73d9cc59b0b946978590.txt\">they</a> <a href=\"http://www.telegraph.co.uk/news/worldnews/northamerica/canada/3498766/Facebook-Kick-a-Ginger-campaign-prompts-attacks-on-redheads.html\">are</a> <a href=\"http://www.newsday.com/news/nation/5-socal-kids-victims-of-ginger-attacks-1.1620428\">not</a>.&nbsp;What South Park \"kicked\" off as an ironic commentary on racism is becoming actual racism.</p>\n<p>One clue that you're going too far in your ironic humor is when you start finding the <a href=\"http://www.collegehumor.com/video/5882397/ginger-rallying-cry\">real thing</a> funny.</p>\n<p>Do humans have an instinctive need to bond over shared prejudices? &nbsp;Is combating racism a game of whack-a-mole, in which society invents new prejudices to replace the ones being taken away?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DdgSyQoZXjj3KnF4N": 1, "FkzScn5byCs9PxGsA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eLJANrQG3sbrPjZk2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 37, "extendedScore": null, "score": 7.7e-05, "legacy": true, "legacyId": "6591", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 26, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 73, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T22:48:08.851Z", "modifiedAt": null, "url": null, "title": "An Anchoring Experiment: Results", "slug": "an-anchoring-experiment-results", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:17.738Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "prase", "createdAt": "2009-02-28T10:00:10.260Z", "isAdmin": false, "displayName": "prase"}, "userId": "WAP32wvmNt9QdutSu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SPmxzR56jkoxekZqQ/an-anchoring-experiment-results", "pageUrlRelative": "/posts/SPmxzR56jkoxekZqQ/an-anchoring-experiment-results", "linkUrl": "https://www.lesswrong.com/posts/SPmxzR56jkoxekZqQ/an-anchoring-experiment-results", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20An%20Anchoring%20Experiment%3A%20Results&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAn%20Anchoring%20Experiment%3A%20Results%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSPmxzR56jkoxekZqQ%2Fan-anchoring-experiment-results%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=An%20Anchoring%20Experiment%3A%20Results%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSPmxzR56jkoxekZqQ%2Fan-anchoring-experiment-results", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSPmxzR56jkoxekZqQ%2Fan-anchoring-experiment-results", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 585, "htmlBody": "<p>This post summarises the results of the experiment which tested how anchoring works on the LW audience. <a href=\"/r/discussion/lw/52f/an_anchoring_experiment/\">Here</a> is the original post which describes the experiment in more detail. The experiment was supposed to decide between two ways of how anchoring may work. The first hypothesis is that the subject always starts from the anchor and continues in the direction of his/her unbiased estimate, but doesn't go far enough. The alternative hypothesis is that anchoring shifts the centre of the subject's probability distribution towards the anchor, and the whole distribution moves along.</p>\n<p>To illustrate the difference, consider the first experimental question, which was about the population of the Central African Republic. The correct value (i.e. the estimate for 2009 listed on Wikipedia) is 4,422,000. The anchor which I have offered here was 20 million. Now, if the first hypothesis is true, the people who, in their unbiased state of mind, would guess less than 20 million, would slide down starting from the 20 million value and stop prematurely; their guesses will be attracted towards the anchor, but not across. The distribution of the biased guesses would be narrower and overall closer to 20 million than the unbiased distribution, but the probability of answering whatever number lower than 20 million would not be changed by anchoring. On the other hand, if the second hypothesis holds, the biased group should guess more than 20 million more often than the control group.</p>\n<p>The actual results are such:</p>\n<p><strong>Group I</strong> (biased; 36 answers collected)</p>\n<ul>\n<li>more than 20 million: 15 (<strong>41.7%</strong>)</li>\n<li>less than 20 million: 21 (<strong>58.3%</strong>) </li>\n</ul>\n<p><strong>Group II</strong> (control; 16 answers collected)</p>\n<ul>\n<li>more than 20 million: 3 (<strong>18.7%</strong>) </li>\n<li>less than 20 million: 13 (<strong>81.3%</strong>)</li>\n<li>20 million: 1 (<strong>6.3%</strong>)</li>\n</ul>\n<p>The second question asked for the altitude of the highest point in Sweden (2140 m / 6903 ft). The anchor was 3500 m or 11500 ft (there is about 5 m / 18 ft difference between the values, but I wanted both the metric and the imperial anchor to be round numbers). Here the results are:</p>\n<p><strong>Group I</strong> (biased; 24 answers collected)</p>\n<ul>\n<li>more than 3500 m: 9 (<strong>37.5%</strong>) </li>\n<li>less than 3500 m: 15 (<strong>62.5%</strong>) </li>\n</ul>\n<p><strong>Group II</strong> (control; 30 answers collected)</p>\n<ul>\n<li>more than 3500 m: 5 (<strong>16.7%</strong>) </li>\n<li>less than 3500 m: 13 (<strong>83.3%</strong>)</li>\n</ul>\n<p>The results seem to favour the second hypothesis.</p>\n<p>Some more remarks: The participants were expected to change the groups between both parts and the numbers should reflect that, however, six and eight answers are missing from the group II summaries. Few people (about 16% and 33% actually) thus refused to guess the concrete number although they voted in \"greater/lower than anchor\" questions. It may skew the results, although I don't see in which direction.</p>\n<p>There were few weird answers, too. The altitude of the Sweden's highest summit was reported to be both 100 m and 5000 km. Those can be simply interpreted as statistical deviations from common sense* (or typos), however I started to doubt whether all participants were serious. (Which leads to a moral: If you intend to post a survey and be certain about its accuracy, don't do it on the 1st of April.)</p>\n<p>Finally, I would like to thank all the commenters who had pointed out several technical problems with the test (such as the answers appearing in the \"recent comments\" bar).</p>\n<p>*) The 100 m guess may even be reasonable: The summit of Yding Skovh&oslash;j, the highest point of extraordinarily flat Denmark, lies only 175 metres above the sea.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb128": 2, "RxuepsZgBEKax9bmP": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SPmxzR56jkoxekZqQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 28, "extendedScore": null, "score": 6.979663847566481e-07, "legacy": true, "legacyId": "6601", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["TTyxi2JCb7ZTmEZDB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-03T22:52:32.694Z", "modifiedAt": null, "url": null, "title": "Don't Fear Failure", "slug": "don-t-fear-failure", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:19.037Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/83naYmTXYcupTRGRW/don-t-fear-failure", "pageUrlRelative": "/posts/83naYmTXYcupTRGRW/don-t-fear-failure", "linkUrl": "https://www.lesswrong.com/posts/83naYmTXYcupTRGRW/don-t-fear-failure", "postedAtFormatted": "Sunday, April 3rd 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Don't%20Fear%20Failure&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADon't%20Fear%20Failure%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F83naYmTXYcupTRGRW%2Fdon-t-fear-failure%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Don't%20Fear%20Failure%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F83naYmTXYcupTRGRW%2Fdon-t-fear-failure", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F83naYmTXYcupTRGRW%2Fdon-t-fear-failure", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 614, "htmlBody": "<p><a href=\"/lw/4ln/go_try_things/\">Last post</a>, I talked about how trying things out yourself is a good way to learn about them. This post, I'm going to talk about ideas that helped me overcome one of my major obstacles to trying something -- fear of failure.</p>\n<p><strong style=\"font-weight: bold;\">Overestimation of Damages: \"Its not that big a deal\"</strong></p>\n<p>In most cases, failure really isn't that big of a deal. Really.&nbsp;The difference between failure and a null action is the attempt. If the attempt isn't damaging, failure isn't damaging.</p>\n<p>A few cases:</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>Trying a new food/recipe? Maybe you don't like it and waste a few dollars. Maybe you mess it up. So you eat something else. Just don't do it for your first dinner with the in-laws and it should be fine. But a new dish might be totally delicious.</li>\n<li>Total stranger you think might be a cool person? Maybe they get annoyed at you. Then you can just break off and never talk to/see them again. Chatting with people I run into has made college visits much more enjoyable.</li>\n<li>Competition you might want to enter? Worst case scenario is that you lose. I learned a lot from&nbsp;<a href=\"http://m3challenge.siam.org/\">Moody's Mega Math Challenge</a>, and even though I don't think we did a particularly good job at&nbsp;<a href=\"http://m3challenge.siam.org/pdf/M3challenge_problem_11.pdf\">modeling Lake Powell</a>&nbsp;I still learned a lot about how mathematical modeling works.</li>\n<li>Dance you want to try? The worst that's likely is that you look a bit silly. Laugh it off.</li>\n</ul>\n<p>There's lots of things where an attempt is actually worse than doing nothing. Jumping halfway to the other side of the ledge, for instance. Or only removing most of the toxic part of a pufferfish. But for a lot of potentially high-value things, a failed attempt doesn't really do much, so you might as well try them.</p>\n<p><strong>Rationality and Failure: \"Don't panic\"</strong></p>\n<p>Some people I know basically buckle under failure. A common failure mode seems to be to do something badly, establish an&nbsp;<a href=\"/lw/21b/ugh_fields/\">ugh field</a>&nbsp;around that area, and then continue in a downward spiral. Getting a B on a math test turns into \"Ugh, math\", turns into \"well I was never really good at that anyway\", turns into a complete lack of effort. Here a little failure becomes a huge problem. A failure isn't catastrophic on its own, but giving up is.<a id=\"more\"></a></p>\n<p>Rather than focusing on what you didn't accomplish, try to figure out what happened insofar as understanding that helps you fix it.&nbsp;Toyota apparently emphasized this as their &nbsp;<a href=\"http://en.wikipedia.org/wiki/5_Whys\">5 Whys system</a>, and it has become widespread in industry.</p>\n<p>Another good reaction to failure from my life, at a robotics competition:&nbsp;<a href=\"http://www.youtube.com/watch?v=0GYoHullfxc\">http://www.youtube.com/watch?v=0GYoHullfxc</a></p>\n<ul>\n<li>In autonomous mode, the robot raised its arm and kept raising it. In doing so, it broke off of its first actuation. This made it impossible for us to hang tubes for the rest of the game.</li>\n<li>What can we do? We can't score, but we can play defense, and maybe deploy at the end of the game (that little robot that got shot out)</li>\n<li>We don't want to play defense, because that has a high chance of further breaking our arm.</li>\n<li>So deploy it is.</li>\n<li>So we need to figure out how to get the arm out of the way, cue messing around.</li>\n<li>That worked! Now go wait and try to deploy.</li>\n<li>Success! We looked terrible, but we won that match.</li>\n</ul>\n<p><em>Just</em>&nbsp;&nbsp;learn from your mistakes -- figure out what happened and what can be done to fix them. Then do whatever is needed. Try things you're interested in and learn enough to carry them to completion, or just be the wiser for having started them.&nbsp;</p>\n<p><sup>1&nbsp;</sup>quote paraphrased from &nbsp;<a href=\"http://www.sebastianmarshall.com/bad-stuff-happening-are-expensive-lessons-youve-already-paid-for\">here</a>. His username on LW is lionhearted.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"WSZifR5rmzZCwbPNJ": 2, "hrezrpGqXXdSe76ks": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "83naYmTXYcupTRGRW", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 32, "baseScore": 39, "extendedScore": null, "score": 9.4e-05, "legacy": true, "legacyId": "6289", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><a href=\"/lw/4ln/go_try_things/\">Last post</a>, I talked about how trying things out yourself is a good way to learn about them. This post, I'm going to talk about ideas that helped me overcome one of my major obstacles to trying something -- fear of failure.</p>\n<p><strong style=\"font-weight: bold;\" id=\"Overestimation_of_Damages___Its_not_that_big_a_deal_\">Overestimation of Damages: \"Its not that big a deal\"</strong></p>\n<p>In most cases, failure really isn't that big of a deal. Really.&nbsp;The difference between failure and a null action is the attempt. If the attempt isn't damaging, failure isn't damaging.</p>\n<p>A few cases:</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: disc; list-style-position: outside; list-style-image: initial;\">\n<li>Trying a new food/recipe? Maybe you don't like it and waste a few dollars. Maybe you mess it up. So you eat something else. Just don't do it for your first dinner with the in-laws and it should be fine. But a new dish might be totally delicious.</li>\n<li>Total stranger you think might be a cool person? Maybe they get annoyed at you. Then you can just break off and never talk to/see them again. Chatting with people I run into has made college visits much more enjoyable.</li>\n<li>Competition you might want to enter? Worst case scenario is that you lose. I learned a lot from&nbsp;<a href=\"http://m3challenge.siam.org/\">Moody's Mega Math Challenge</a>, and even though I don't think we did a particularly good job at&nbsp;<a href=\"http://m3challenge.siam.org/pdf/M3challenge_problem_11.pdf\">modeling Lake Powell</a>&nbsp;I still learned a lot about how mathematical modeling works.</li>\n<li>Dance you want to try? The worst that's likely is that you look a bit silly. Laugh it off.</li>\n</ul>\n<p>There's lots of things where an attempt is actually worse than doing nothing. Jumping halfway to the other side of the ledge, for instance. Or only removing most of the toxic part of a pufferfish. But for a lot of potentially high-value things, a failed attempt doesn't really do much, so you might as well try them.</p>\n<p><strong id=\"Rationality_and_Failure___Don_t_panic_\">Rationality and Failure: \"Don't panic\"</strong></p>\n<p>Some people I know basically buckle under failure. A common failure mode seems to be to do something badly, establish an&nbsp;<a href=\"/lw/21b/ugh_fields/\">ugh field</a>&nbsp;around that area, and then continue in a downward spiral. Getting a B on a math test turns into \"Ugh, math\", turns into \"well I was never really good at that anyway\", turns into a complete lack of effort. Here a little failure becomes a huge problem. A failure isn't catastrophic on its own, but giving up is.<a id=\"more\"></a></p>\n<p>Rather than focusing on what you didn't accomplish, try to figure out what happened insofar as understanding that helps you fix it.&nbsp;Toyota apparently emphasized this as their &nbsp;<a href=\"http://en.wikipedia.org/wiki/5_Whys\">5 Whys system</a>, and it has become widespread in industry.</p>\n<p>Another good reaction to failure from my life, at a robotics competition:&nbsp;<a href=\"http://www.youtube.com/watch?v=0GYoHullfxc\">http://www.youtube.com/watch?v=0GYoHullfxc</a></p>\n<ul>\n<li>In autonomous mode, the robot raised its arm and kept raising it. In doing so, it broke off of its first actuation. This made it impossible for us to hang tubes for the rest of the game.</li>\n<li>What can we do? We can't score, but we can play defense, and maybe deploy at the end of the game (that little robot that got shot out)</li>\n<li>We don't want to play defense, because that has a high chance of further breaking our arm.</li>\n<li>So deploy it is.</li>\n<li>So we need to figure out how to get the arm out of the way, cue messing around.</li>\n<li>That worked! Now go wait and try to deploy.</li>\n<li>Success! We looked terrible, but we won that match.</li>\n</ul>\n<p><em>Just</em>&nbsp;&nbsp;learn from your mistakes -- figure out what happened and what can be done to fix them. Then do whatever is needed. Try things you're interested in and learn enough to carry them to completion, or just be the wiser for having started them.&nbsp;</p>\n<p><sup>1&nbsp;</sup>quote paraphrased from &nbsp;<a href=\"http://www.sebastianmarshall.com/bad-stuff-happening-are-expensive-lessons-youve-already-paid-for\">here</a>. His username on LW is lionhearted.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Overestimation of Damages: \"Its not that big a deal\"", "anchor": "Overestimation_of_Damages___Its_not_that_big_a_deal_", "level": 1}, {"title": "Rationality and Failure: \"Don't panic\"", "anchor": "Rationality_and_Failure___Don_t_panic_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "12 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["ADaZaEsmJMnKKhRqS", "EFQ3F6kmt4WHXRqik"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T01:13:45.765Z", "modifiedAt": null, "url": null, "title": "Just Try It: Quantity Trumps Quality", "slug": "just-try-it-quantity-trumps-quality", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:38.416Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hY86FhYysQ7dBg3d8/just-try-it-quantity-trumps-quality", "pageUrlRelative": "/posts/hY86FhYysQ7dBg3d8/just-try-it-quantity-trumps-quality", "linkUrl": "https://www.lesswrong.com/posts/hY86FhYysQ7dBg3d8/just-try-it-quantity-trumps-quality", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Just%20Try%20It%3A%20Quantity%20Trumps%20Quality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AJust%20Try%20It%3A%20Quantity%20Trumps%20Quality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhY86FhYysQ7dBg3d8%2Fjust-try-it-quantity-trumps-quality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Just%20Try%20It%3A%20Quantity%20Trumps%20Quality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhY86FhYysQ7dBg3d8%2Fjust-try-it-quantity-trumps-quality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhY86FhYysQ7dBg3d8%2Fjust-try-it-quantity-trumps-quality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 496, "htmlBody": "<p>Followup to:&nbsp;<a href=\"/lw/4up/dont_fear_failure/\">Don't Fear Failure</a></p>\n<p>In the same theme as the last article, I think that failure is actually pretty important in learning. Rationality needs data, and trying is a good source of it.<br /><br />When you're trying to do something new, you probably won't be able to do it right the first time. Even if you obsess over it. Jeff Atwood is a programmer who says&nbsp;<a href=\"http://www.codinghorror.com/blog/2008/08/quantity-always-trumps-quality.html\">Quantity Always Trumps Quality</a></p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<blockquote style=\"font-family: calibri, tahoma, arial, sans-serif; background-image: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: #f5f5f5; color: #333333; background-position: initial initial; background-repeat: initial initial; padding: 5px;\">The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the \"quantity\" group: fifty pound of pots rated an \"A\", forty pounds a \"B\", and so on. Those being graded on \"quality\", however, needed to produce only one pot - albeit a perfect one - to get an \"A\".\n<p>Well, came grading time and a curious fact emerged:&nbsp;<strong style=\"font-weight: bold;\">the works of highest quality were all produced by the group being graded for quantity</strong>. It seems that while the \"quantity\" group was busily churning out piles of work - and learning from their mistakes - the \"quality\" group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay.</p>\n</blockquote>\n<p>Where have I heard this before?<a id=\"more\"></a></p>\n<ol style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; list-style-type: decimal; list-style-position: outside; list-style-image: initial;\">\n<li><a style=\"color: #0066cc; text-decoration: none;\" href=\"http://www.codinghorror.com/blog/archives/000165.html\">Stop theorizing</a>.</li>\n<li><a style=\"color: #0066cc; text-decoration: none;\" href=\"http://www.codinghorror.com/blog/archives/000684.html\">Write lots of software</a>.</li>\n<li><a style=\"color: #0066cc; text-decoration: none;\" href=\"http://www.codinghorror.com/blog/archives/000300.html\">Learn from your mistakes</a>.</li>\n</ol>\n<div style=\"margin-bottom: 1em;\">\n<p>Quantity always trumps quality.&nbsp;</p>\n<p>When it comes to software, the same rule applies. If you aren't building, you aren't learning. Rather than agonizing over whether you're building the right thing,&nbsp;<em style=\"font-style: italic;\">just build it</em>. And if that one doesn't work,&nbsp;<a style=\"color: #0066cc; text-decoration: none;\" href=\"http://www.codinghorror.com/blog/archives/000190.html\">keep building</a>&nbsp;until you get one that does.</p>\n</div>\n</blockquote>\n<p>The people who tried more did better, even though they failed more too. Of course you shouldn't try to fail, but you shouldn't let the fear of it stop you from tyring.<br /><br />I wouldn't go as far as to say that quantity always trumps quality, but where the cost of failure is low lots of failures that you pay attention to is a pretty good way of learning. You should &nbsp;<a href=\"/lw/ka/hold_off_on_proposing_solutions/\">hold off on proposing solutions</a>, but you also need to get around to actually trying the proposed solution.<br /><br />I'm normed such that I'll spend more time talking about if something will work than trying it out to see if it works. The problem is that if you don't know about something already, your thoughts about what will work aren't going to be particularly accurate. Trying something will very conclusively demonstrate if something works or not.<br /><br />Note:<br />I originally had this as part of Don't Fear Failure, but that post got too long.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fkABsGCJZ6y9qConW": 1, "fR7QfYx4JA3BnptT9": 1, "7thPfS2WbD2JKizr7": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hY86FhYysQ7dBg3d8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 73, "baseScore": 83, "extendedScore": null, "score": 0.000153, "legacy": true, "legacyId": "6602", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 84, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 83, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["83naYmTXYcupTRGRW", "uHYYA32CKgKT3FagE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 4, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T01:39:53.567Z", "modifiedAt": null, "url": null, "title": "Sequence Posts Exercises", "slug": "sequence-posts-exercises", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:08.305Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "folkTheory", "createdAt": "2010-09-26T04:46:43.892Z", "isAdmin": false, "displayName": "folkTheory"}, "userId": "KW8h2pTMhavF7Rsic", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SoadQym38wGBDJ7AH/sequence-posts-exercises", "pageUrlRelative": "/posts/SoadQym38wGBDJ7AH/sequence-posts-exercises", "linkUrl": "https://www.lesswrong.com/posts/SoadQym38wGBDJ7AH/sequence-posts-exercises", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sequence%20Posts%20Exercises&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASequence%20Posts%20Exercises%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSoadQym38wGBDJ7AH%2Fsequence-posts-exercises%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sequence%20Posts%20Exercises%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSoadQym38wGBDJ7AH%2Fsequence-posts-exercises", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSoadQym38wGBDJ7AH%2Fsequence-posts-exercises", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>Based on <a title=\"this\" href=\"/lw/536/open_thread_april_2011/3ti1\">this</a> thread from this month's (April 2011) Open Thread, we have started work on exercises to go along with the posts and help readers internalize the material better. The idea is to have exercises covering all of the sequences eventually (though there doesn't have to be a 1:1 correspondence between exercises and single posts)</p>\n<p>help is very much appreciated. If you want to take up writing exercises for a post, please claim it on our wiki <a title=\"page\" href=\"http://wiki.lesswrong.com/wiki/Lesswrongwiki:Sequence_Post_Exercises\">page</a>.</p>\n<p>A few drafts have started to circulate, and soon we will have our first exercises posted.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SoadQym38wGBDJ7AH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 21, "extendedScore": null, "score": 6.980141404972293e-07, "legacy": true, "legacyId": "6603", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T03:25:02.450Z", "modifiedAt": null, "url": null, "title": "Recent de-convert saturated by religious community; advice?", "slug": "recent-de-convert-saturated-by-religious-community-advice", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:32.482Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jwhendy", "createdAt": "2011-01-04T19:53:21.160Z", "isAdmin": false, "displayName": "jwhendy"}, "userId": "ZaJctSZkCvg7qvSEC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fnTHrfFz5TMW8c9R2/recent-de-convert-saturated-by-religious-community-advice", "pageUrlRelative": "/posts/fnTHrfFz5TMW8c9R2/recent-de-convert-saturated-by-religious-community-advice", "linkUrl": "https://www.lesswrong.com/posts/fnTHrfFz5TMW8c9R2/recent-de-convert-saturated-by-religious-community-advice", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Recent%20de-convert%20saturated%20by%20religious%20community%3B%20advice%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARecent%20de-convert%20saturated%20by%20religious%20community%3B%20advice%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfnTHrfFz5TMW8c9R2%2Frecent-de-convert-saturated-by-religious-community-advice%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Recent%20de-convert%20saturated%20by%20religious%20community%3B%20advice%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfnTHrfFz5TMW8c9R2%2Frecent-de-convert-saturated-by-religious-community-advice", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfnTHrfFz5TMW8c9R2%2Frecent-de-convert-saturated-by-religious-community-advice", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2173, "htmlBody": "<p><em style=\"font-weight: bold;\">Edit/Update:</em>&nbsp;Wow, not even a day later this has had quite the number of comments. Hopefully more will come in, but I'd like to thank those who have contributed so far. The suggestions that I think I'm really going to run with are:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Finishing my \"statement\" (<a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">in progress</a> already) and deferring to that when specifics are requested (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tte\">Yvain</a>)</li>\n<li>Have a suggestion of a convincing book or online article to which I can refer challengers (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tso\">David Gerard</a>)</li>\n<li>Reminding myself that I haven't eaten any babies, to date, and that questioning is/was okay (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tvb\">jsalvatier</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3trt\">RobinZ</a>)</li>\n<li>Just try to avoid the topic (pretty much what I already do) (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tsi\">Risto Saarelma</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tt0\">thakil</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3txa\">MinibearRex</a>)</li>\n<li>Focus on the point of a \"quest\" -- enough confidence to practically advance, not pursuing a question so far that no progres is made anymore or because doubt/uncertainty seems virtuous (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tub\">Desrtopa</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3ty4\">Vladimir_Nesov</a>)</li>\n<li>Come to accept that since such a large amount of energy and time was invested in this particular belief system, the nagging I feel about my research into it might never go away/take some time to go away (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tup\">beriukay</a>)</li>\n</ul>\n<p>I'd like to \"honorable mention\" a suggestion begun by <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3ts0\">James Miller</a>&nbsp;that I could just pretend to believe for the sake of preserving relationships and social satisfaction. I see some merit to this but think it might have been based on thinking that my closer/est friends/wife didn't already know (they do). The comment made for some interesting comments, but I think I'd just feel like a phony and even more miserable if I were to really implement this suggestion for any extended period of time.</p>\n<p>&nbsp;</p>\n<p>---</p>\n<p>This issue has been negatively affecting me for quite some time and for lack of clear solutions on my own and knowing that some here have traversed the same stream, I thought I'd ask for help and suggestions. If you're interested, some background information about my story exists <a href=\"http://technologeekery.blogspot.com/2010/07/quest.html\">here</a>, <a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">here</a>, and <a href=\"/lw/3n2/my_story_owning_ones_reasons/\">here</a>.</p>\n<p>&nbsp;</p>\n<p><strong><em>Background</em></strong></p>\n<p>For the sake of having at least some information here, the brief synopsis is like so:<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">&nbsp;</span></p>\n<ul>\n<li>In my middle school/high school years, I was quite insecure, attention-hungry, and had poor methods of dealing with emotional burdens. This manifested itself in highly addictive tendencies, specifically my use of tobacco, alcohol, and marijuana as often as possible.&nbsp;This led my parents to send me from my hometown of Milwaukee, WI to a&nbsp;<a style=\"color: #6a8a6b;\" href=\"http://en.wikipedia.org/wiki/Twelve-step_program\">twelve-step</a>&nbsp;<a style=\"color: #6a8a6b;\" href=\"http://www.thefamilyschool.com/\">boarding school</a>&nbsp;in upstate NY.</li>\n<li>After being there a year, &nbsp;I ran away, broke into a house to get drunk, managed to find someone in a town seven miles away to get me high, and was found and captured after boarding school staff after two days.&nbsp;I underwent subsequent legal proceedings and was eventually sentenced to a mere three years of probation and a&nbsp;<a style=\"color: #6a8a6b;\" href=\"http://en.wikipedia.org/wiki/Young_offender\">youthful offender status</a>&nbsp;rather than a potential third degree burglary charge (and possible prison sentence).</li>\n<li>This rapid rebellion, breaking a serious law for a substance (something previously foreign to me), and apparent \"fortune\" of a sentence brought about a strong conviction that god had provided me with another chance to live a \"good life\" in service of him as a sober member of Alcoholics Anonymous whose purpose was to get to heaven and spend an eternity with him.</li>\n</ul>\n<p>Yes, that last conclusion had some more contributing to it, but for the sake of brevity, just accept that this was my stance. Following the outburst and relatively minor consequence, it was almost like my \"second chance\" holy life was just waiting there to be lived. I had a renewed sense of purpose and ran with it.</p>\n<p>I built the next seven or so years of my life completely around god and my Catholic faith. Much of this is covered in the link above to my blog, where I've written down a rough draft to <a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">my story</a>. In short,&nbsp;I married who I did because of god/religion, went to the college I did because there was an extremely active <a href=\"http://www.spoweb.org/\">Catholic outreach group</a> connected to it, and a couple years ago even professed a <em>lifelong</em>&nbsp;commitment to a <a href=\"http://ccredeemer.org/home/\">lay association of Catholic families</a> who pledge themselves to live their lives with a common vision, attend bi-weekly events, complete [theological] education courses [taught by members of the same community], attend a couple of retreats together each year, and more.</p>\n<p>Then I, literally out of the blue, a question popped into my head; I wondered whether other historians had written about Jesus. I googled the question various ways and was surprised/disappointed to find out that none had in the manner I expected. The rest is history. It's about 15mos later and I'm a non-believer.</p>\n<p>&nbsp;</p>\n<p><strong><em>What now?</em></strong></p>\n<p>I'm posting as trying to navigate the social implications of my deconversion has been quite difficult. My close friends were some of the first I informed, probably within a month. This community, however, is probably ~300 members strong. I know <em>a lot</em>&nbsp;of acquaintances via our [former] common religious beliefs.</p>\n<p>I find myself quite fearful when I see these individuals. I'm afraid something will come up that will be awkward or that I'll be in a large-group setting and somehow a lot of individuals will find out about my non-belief at once in an \"untactful\" manner. Some of this is due to a sense of friendship -- if someone learns something more serious about my life, I'd prefer that it be from me.</p>\n<p>A bit more irrationally, I fear how their opinions about me will be affected. I already think some think I'm \"broken\" somehow. In fact, I had a member of my former men's group tell me I was \"crazy\" (verbatim) when I told him it may very well be possible that some or all of the gospels were made up. I felt talked to like a small child by my men's group leader as a result of my non-belief. Heck, some might think I'm possessed by a demon. My wife and I turned our mattress a couple weeks ago and there was some sort of religious trinket (maybe a <a href=\"http://en.wikipedia.org/wiki/Scapular\">scapular</a>?)&nbsp;under my side of the mattress on the box spring. She said someone suggested that it might be helpful...</p>\n<p>I also find myself balancing between insecurity and anger. I'm insecure because I just plain wish I was more secure in my non-belief... yet I find myself looking back over my shoulder wondering if I've made a wrong turn in my reasoning, if I've simply pendulum-swung over to the opposite extreme as a result of my initial doubts, or if there's some remaining book that would answer my questions. I read mostly atheistic material, though I have read a couple books per the requests of those close to me. I've also been adding books suggested to <a href=\"http://technologeekery.blogspot.com/2010/07/truth-seeker-challenge.html\">my list</a>. I admit, though, it's been far more rewarding to do woodworking than analyze the latest solution of the problem of evil. I guess I'd just say that it's been hard to \"fully let go\" and just walk away from my past belief, hence the insecurity.</p>\n<p>On the other hand, I am easily angered in certain situations, perhaps resulting out of feeling insulted and addressed by hypocrites. Those around me want to know if I've read x, y, and z books by a, b, and c apologists. They want to remind me of how hard this is on my wife (who's still a believer). They would like to make the case for my wife raising our children as believers due to the incredible gravity of the future of their souls. And this all from, as far as I can tell, the comfort of ignorance of the theological/apologetical landscape. Some are fairly educated, but the average individual who would like to critique my path could not provide anything in the way of even a <em>summary</em>&nbsp;of the various topics and arguments involved when trying to answer the question of god's likelihood. That's frustrating.</p>\n<p>&nbsp;</p>\n<p><strong><em>What I'm looking for</em></strong></p>\n<p>&nbsp;</p>\n<ul>\n<li>Have any of you been in a situation like this? How did you \"come out.\" I think I may be approaching a time when this may be advised. It just might help me be more at ease if at least everyone knew. I've thought of writing up some kind of \"cumulative case summary\" and then making it widely available somehow. What did you do, primarily for the \"acquaintance\" types who were the last to know?</li>\n<li>I'd very much appreciate suggestions for dealing with my intellectual insecurity. How could I be more at ease? When can one rationally conclude that they've \"done enough\", at least for the present moment and apply their energies elsewhere? I've felt like this is such a large question with respect to one's \"life framework\" that I've pretty much been consumed with this one question because it seems like the answer would affect so much else going forward. Were it conclusively answered (or perhaps better phrased, could I be <em>convinced</em> that I'm aligned with the truth), it might be easier to pursue applying rationality to other areas of life (I also do this, but think much more biological CPU/RAM could be freed up).    \n<ul>\n<li>The solution to this might honestly be that I just need to move on. While insecure about my <em>justification</em>, there is nothing insecure about stating my current state. I think god is quite unlikely, at least in the theistic sense. Perhaps the solution is to see that I'm irrationally favoring the prospect of certainty in this one area while ignoring the fact that there are tons of other areas I'm not certain about that don't even cross my mind in daily life. I'm not sure why this one bothers me so much -- perhaps the social aspect of it, recentness, and affect on daily living make it more acute?</li>\n</ul>\n</li>\n<li>For those associated with primarily religious communities (still or in the past), do you have any suggestions about how to engage on-the-fly discussions? For example, I've thought than an <a href=\"http://en.wikipedia.org/wiki/Elevator_pitch\">elevator-pitch</a>&nbsp;about my non-belief would be helpful... but I have found that previous conversations almost always degrade into pointless debate. How might I clearly express my stance while avoiding the pitfall of purposeless ruffled feathers? It's so darn <em>natural</em>&nbsp;for the conversation to flow like so:&nbsp;    \n<ul>\n<li><strong>Me:&nbsp;</strong>\"I don't believe anymore.\"&nbsp;</li>\n<li>\"Why?\"</li>\n<li><strong>Me:&nbsp;</strong>\"Well, many reasons. Since you asked, one would be X.\"</li>\n<li>Followed by extremely long summary of why X is, in fact, incorrect, list of apologists who've covered this topic, suggestion of a few older Christians this person knows that I should schedule time with, etc.</li>\n<li><strong>Me:&nbsp;</strong>I respond in any number of ways... perhaps saying that I might check out such a book later, or simply that I'm not convinced by the response.</li>\n<li>\"But didh't you hear? So-and-so <em>covered this. The answer is already in his book! Also, from talking to Mr. X, he clearly knows his stuff an also agrees.\"</em></li>\n<li>So clearly the conversation isn't going anywhere. It's like being asked for money to support a cause you just don't currently support, having your pockets stuffed with pamphlets, again stating that you just don't support the cause at the moment... and the person continues to stand in your way, palm outstretched for money as if you might instantaneously change you mind because of the pamphlets.</li>\n</ul>\n</li>\n</ul>\n<p>&nbsp;</p>\n<p>For my own part, I'd say that I need to do more work&nbsp;<a href=\"/lw/hu/the_third_alternative/\">brainstorming</a>&nbsp;through possible conversation paths, and especially identifying why this all bothers me so much. Or perhaps the latter is simply obvious -- I don't have any close friends anymore who think I'm rationally justified in not believing in their deity. In writing that out, I suppose that is a pretty heavy social hit to take. Even after having these friends for seven years, I'm more \"at ease\" talking with those at <a href=\"http://mnatheists.org/\">Minnesota Atheists</a>&nbsp;meetups that I've only been attending about 1-2x/month for less than a year.</p>\n<p>This ended up far longer than I expected. I knew that was a potential issue when I started it and tried revising some bits and pieces, but I think I'll leave it. For one, this is the discussion area and I'm not necessary trying to present a well-thought out proposal; this is a request for input, ideas, support, and especially suggestions from those who may have been through something similar.</p>\n<p>Also, I have to say that writing this out is slightly like talking to the close friend I don't really have. Much of my \"real feelings\" about this whole issue are kept inside because I simply don't want to hurt those around me by expressing them or bringing it up. My relationships go <em>far better</em>&nbsp;when god just doesn't come up at all, or at least stays to \"meta-discussion\" like, \"How's this all going for your wife and you?\" vs. \"Here's this new book you should read which will definitely prove you are wrong.\" As a result, my outlets for bouncing these questions and difficulties around are a bit limited.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"NSMKfa8emSbGNXRKD": 1, "irYLXtT9hkPXoZqhH": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fnTHrfFz5TMW8c9R2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 33, "baseScore": 38, "extendedScore": null, "score": 6.980433809733864e-07, "legacy": true, "legacyId": "6605", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 30, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><em style=\"font-weight: bold;\">Edit/Update:</em>&nbsp;Wow, not even a day later this has had quite the number of comments. Hopefully more will come in, but I'd like to thank those who have contributed so far. The suggestions that I think I'm really going to run with are:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Finishing my \"statement\" (<a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">in progress</a> already) and deferring to that when specifics are requested (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tte\">Yvain</a>)</li>\n<li>Have a suggestion of a convincing book or online article to which I can refer challengers (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tso\">David Gerard</a>)</li>\n<li>Reminding myself that I haven't eaten any babies, to date, and that questioning is/was okay (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tvb\">jsalvatier</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3trt\">RobinZ</a>)</li>\n<li>Just try to avoid the topic (pretty much what I already do) (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tsi\">Risto Saarelma</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tt0\">thakil</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3txa\">MinibearRex</a>)</li>\n<li>Focus on the point of a \"quest\" -- enough confidence to practically advance, not pursuing a question so far that no progres is made anymore or because doubt/uncertainty seems virtuous (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tub\">Desrtopa</a>, <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3ty4\">Vladimir_Nesov</a>)</li>\n<li>Come to accept that since such a large amount of energy and time was invested in this particular belief system, the nagging I feel about my research into it might never go away/take some time to go away (<a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3tup\">beriukay</a>)</li>\n</ul>\n<p>I'd like to \"honorable mention\" a suggestion begun by <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3ts0\">James Miller</a>&nbsp;that I could just pretend to believe for the sake of preserving relationships and social satisfaction. I see some merit to this but think it might have been based on thinking that my closer/est friends/wife didn't already know (they do). The comment made for some interesting comments, but I think I'd just feel like a phony and even more miserable if I were to really implement this suggestion for any extended period of time.</p>\n<p>&nbsp;</p>\n<p>---</p>\n<p>This issue has been negatively affecting me for quite some time and for lack of clear solutions on my own and knowing that some here have traversed the same stream, I thought I'd ask for help and suggestions. If you're interested, some background information about my story exists <a href=\"http://technologeekery.blogspot.com/2010/07/quest.html\">here</a>, <a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">here</a>, and <a href=\"/lw/3n2/my_story_owning_ones_reasons/\">here</a>.</p>\n<p>&nbsp;</p>\n<p><strong id=\"Background\"><em>Background</em></strong></p>\n<p>For the sake of having at least some information here, the brief synopsis is like so:<span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">&nbsp;</span></p>\n<ul>\n<li>In my middle school/high school years, I was quite insecure, attention-hungry, and had poor methods of dealing with emotional burdens. This manifested itself in highly addictive tendencies, specifically my use of tobacco, alcohol, and marijuana as often as possible.&nbsp;This led my parents to send me from my hometown of Milwaukee, WI to a&nbsp;<a style=\"color: #6a8a6b;\" href=\"http://en.wikipedia.org/wiki/Twelve-step_program\">twelve-step</a>&nbsp;<a style=\"color: #6a8a6b;\" href=\"http://www.thefamilyschool.com/\">boarding school</a>&nbsp;in upstate NY.</li>\n<li>After being there a year, &nbsp;I ran away, broke into a house to get drunk, managed to find someone in a town seven miles away to get me high, and was found and captured after boarding school staff after two days.&nbsp;I underwent subsequent legal proceedings and was eventually sentenced to a mere three years of probation and a&nbsp;<a style=\"color: #6a8a6b;\" href=\"http://en.wikipedia.org/wiki/Young_offender\">youthful offender status</a>&nbsp;rather than a potential third degree burglary charge (and possible prison sentence).</li>\n<li>This rapid rebellion, breaking a serious law for a substance (something previously foreign to me), and apparent \"fortune\" of a sentence brought about a strong conviction that god had provided me with another chance to live a \"good life\" in service of him as a sober member of Alcoholics Anonymous whose purpose was to get to heaven and spend an eternity with him.</li>\n</ul>\n<p>Yes, that last conclusion had some more contributing to it, but for the sake of brevity, just accept that this was my stance. Following the outburst and relatively minor consequence, it was almost like my \"second chance\" holy life was just waiting there to be lived. I had a renewed sense of purpose and ran with it.</p>\n<p>I built the next seven or so years of my life completely around god and my Catholic faith. Much of this is covered in the link above to my blog, where I've written down a rough draft to <a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">my story</a>. In short,&nbsp;I married who I did because of god/religion, went to the college I did because there was an extremely active <a href=\"http://www.spoweb.org/\">Catholic outreach group</a> connected to it, and a couple years ago even professed a <em>lifelong</em>&nbsp;commitment to a <a href=\"http://ccredeemer.org/home/\">lay association of Catholic families</a> who pledge themselves to live their lives with a common vision, attend bi-weekly events, complete [theological] education courses [taught by members of the same community], attend a couple of retreats together each year, and more.</p>\n<p>Then I, literally out of the blue, a question popped into my head; I wondered whether other historians had written about Jesus. I googled the question various ways and was surprised/disappointed to find out that none had in the manner I expected. The rest is history. It's about 15mos later and I'm a non-believer.</p>\n<p>&nbsp;</p>\n<p><strong id=\"What_now_\"><em>What now?</em></strong></p>\n<p>I'm posting as trying to navigate the social implications of my deconversion has been quite difficult. My close friends were some of the first I informed, probably within a month. This community, however, is probably ~300 members strong. I know <em>a lot</em>&nbsp;of acquaintances via our [former] common religious beliefs.</p>\n<p>I find myself quite fearful when I see these individuals. I'm afraid something will come up that will be awkward or that I'll be in a large-group setting and somehow a lot of individuals will find out about my non-belief at once in an \"untactful\" manner. Some of this is due to a sense of friendship -- if someone learns something more serious about my life, I'd prefer that it be from me.</p>\n<p>A bit more irrationally, I fear how their opinions about me will be affected. I already think some think I'm \"broken\" somehow. In fact, I had a member of my former men's group tell me I was \"crazy\" (verbatim) when I told him it may very well be possible that some or all of the gospels were made up. I felt talked to like a small child by my men's group leader as a result of my non-belief. Heck, some might think I'm possessed by a demon. My wife and I turned our mattress a couple weeks ago and there was some sort of religious trinket (maybe a <a href=\"http://en.wikipedia.org/wiki/Scapular\">scapular</a>?)&nbsp;under my side of the mattress on the box spring. She said someone suggested that it might be helpful...</p>\n<p>I also find myself balancing between insecurity and anger. I'm insecure because I just plain wish I was more secure in my non-belief... yet I find myself looking back over my shoulder wondering if I've made a wrong turn in my reasoning, if I've simply pendulum-swung over to the opposite extreme as a result of my initial doubts, or if there's some remaining book that would answer my questions. I read mostly atheistic material, though I have read a couple books per the requests of those close to me. I've also been adding books suggested to <a href=\"http://technologeekery.blogspot.com/2010/07/truth-seeker-challenge.html\">my list</a>. I admit, though, it's been far more rewarding to do woodworking than analyze the latest solution of the problem of evil. I guess I'd just say that it's been hard to \"fully let go\" and just walk away from my past belief, hence the insecurity.</p>\n<p>On the other hand, I am easily angered in certain situations, perhaps resulting out of feeling insulted and addressed by hypocrites. Those around me want to know if I've read x, y, and z books by a, b, and c apologists. They want to remind me of how hard this is on my wife (who's still a believer). They would like to make the case for my wife raising our children as believers due to the incredible gravity of the future of their souls. And this all from, as far as I can tell, the comfort of ignorance of the theological/apologetical landscape. Some are fairly educated, but the average individual who would like to critique my path could not provide anything in the way of even a <em>summary</em>&nbsp;of the various topics and arguments involved when trying to answer the question of god's likelihood. That's frustrating.</p>\n<p>&nbsp;</p>\n<p><strong id=\"What_I_m_looking_for\"><em>What I'm looking for</em></strong></p>\n<p>&nbsp;</p>\n<ul>\n<li>Have any of you been in a situation like this? How did you \"come out.\" I think I may be approaching a time when this may be advised. It just might help me be more at ease if at least everyone knew. I've thought of writing up some kind of \"cumulative case summary\" and then making it widely available somehow. What did you do, primarily for the \"acquaintance\" types who were the last to know?</li>\n<li>I'd very much appreciate suggestions for dealing with my intellectual insecurity. How could I be more at ease? When can one rationally conclude that they've \"done enough\", at least for the present moment and apply their energies elsewhere? I've felt like this is such a large question with respect to one's \"life framework\" that I've pretty much been consumed with this one question because it seems like the answer would affect so much else going forward. Were it conclusively answered (or perhaps better phrased, could I be <em>convinced</em> that I'm aligned with the truth), it might be easier to pursue applying rationality to other areas of life (I also do this, but think much more biological CPU/RAM could be freed up).    \n<ul>\n<li>The solution to this might honestly be that I just need to move on. While insecure about my <em>justification</em>, there is nothing insecure about stating my current state. I think god is quite unlikely, at least in the theistic sense. Perhaps the solution is to see that I'm irrationally favoring the prospect of certainty in this one area while ignoring the fact that there are tons of other areas I'm not certain about that don't even cross my mind in daily life. I'm not sure why this one bothers me so much -- perhaps the social aspect of it, recentness, and affect on daily living make it more acute?</li>\n</ul>\n</li>\n<li>For those associated with primarily religious communities (still or in the past), do you have any suggestions about how to engage on-the-fly discussions? For example, I've thought than an <a href=\"http://en.wikipedia.org/wiki/Elevator_pitch\">elevator-pitch</a>&nbsp;about my non-belief would be helpful... but I have found that previous conversations almost always degrade into pointless debate. How might I clearly express my stance while avoiding the pitfall of purposeless ruffled feathers? It's so darn <em>natural</em>&nbsp;for the conversation to flow like so:&nbsp;    \n<ul>\n<li><strong>Me:&nbsp;</strong>\"I don't believe anymore.\"&nbsp;</li>\n<li>\"Why?\"</li>\n<li><strong>Me:&nbsp;</strong>\"Well, many reasons. Since you asked, one would be X.\"</li>\n<li>Followed by extremely long summary of why X is, in fact, incorrect, list of apologists who've covered this topic, suggestion of a few older Christians this person knows that I should schedule time with, etc.</li>\n<li><strong>Me:&nbsp;</strong>I respond in any number of ways... perhaps saying that I might check out such a book later, or simply that I'm not convinced by the response.</li>\n<li>\"But didh't you hear? So-and-so <em>covered this. The answer is already in his book! Also, from talking to Mr. X, he clearly knows his stuff an also agrees.\"</em></li>\n<li>So clearly the conversation isn't going anywhere. It's like being asked for money to support a cause you just don't currently support, having your pockets stuffed with pamphlets, again stating that you just don't support the cause at the moment... and the person continues to stand in your way, palm outstretched for money as if you might instantaneously change you mind because of the pamphlets.</li>\n</ul>\n</li>\n</ul>\n<p>&nbsp;</p>\n<p>For my own part, I'd say that I need to do more work&nbsp;<a href=\"/lw/hu/the_third_alternative/\">brainstorming</a>&nbsp;through possible conversation paths, and especially identifying why this all bothers me so much. Or perhaps the latter is simply obvious -- I don't have any close friends anymore who think I'm rationally justified in not believing in their deity. In writing that out, I suppose that is a pretty heavy social hit to take. Even after having these friends for seven years, I'm more \"at ease\" talking with those at <a href=\"http://mnatheists.org/\">Minnesota Atheists</a>&nbsp;meetups that I've only been attending about 1-2x/month for less than a year.</p>\n<p>This ended up far longer than I expected. I knew that was a potential issue when I started it and tried revising some bits and pieces, but I think I'll leave it. For one, this is the discussion area and I'm not necessary trying to present a well-thought out proposal; this is a request for input, ideas, support, and especially suggestions from those who may have been through something similar.</p>\n<p>Also, I have to say that writing this out is slightly like talking to the close friend I don't really have. Much of my \"real feelings\" about this whole issue are kept inside because I simply don't want to hurt those around me by expressing them or bringing it up. My relationships go <em>far better</em>&nbsp;when god just doesn't come up at all, or at least stays to \"meta-discussion\" like, \"How's this all going for your wife and you?\" vs. \"Here's this new book you should read which will definitely prove you are wrong.\" As a result, my outlets for bouncing these questions and difficulties around are a bit limited.</p>\n<p>&nbsp;</p>", "sections": [{"title": "Background", "anchor": "Background", "level": 1}, {"title": "What now?", "anchor": "What_now_", "level": 1}, {"title": "What I'm looking for", "anchor": "What_I_m_looking_for", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "158 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 158, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["g3RwsGofS6FE5nBsG", "erGipespbbzdG5zYb"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T03:37:31.422Z", "modifiedAt": null, "url": null, "title": "Berkeley LW Meet-Up Saturday April 9", "slug": "berkeley-lw-meet-up-saturday-april-9", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:22.610Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "LucasSloan", "createdAt": "2009-05-28T05:04:38.345Z", "isAdmin": false, "displayName": "LucasSloan"}, "userId": "ouo6Fqn5kTNY7LvqM", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4kHhi7TFwyfh2rM2H/berkeley-lw-meet-up-saturday-april-9", "pageUrlRelative": "/posts/4kHhi7TFwyfh2rM2H/berkeley-lw-meet-up-saturday-april-9", "linkUrl": "https://www.lesswrong.com/posts/4kHhi7TFwyfh2rM2H/berkeley-lw-meet-up-saturday-april-9", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Berkeley%20LW%20Meet-Up%20Saturday%20April%209&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABerkeley%20LW%20Meet-Up%20Saturday%20April%209%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4kHhi7TFwyfh2rM2H%2Fberkeley-lw-meet-up-saturday-april-9%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Berkeley%20LW%20Meet-Up%20Saturday%20April%209%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4kHhi7TFwyfh2rM2H%2Fberkeley-lw-meet-up-saturday-april-9", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4kHhi7TFwyfh2rM2H%2Fberkeley-lw-meet-up-saturday-april-9", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 211, "htmlBody": "<p><a id=\"more\"></a>Hey everyone!&nbsp; Since the Berkeley Meet up group added a <a href=\"/lw/4un/towards_a_bay_area_less_wrong_community/\">weekly meet up</a> to the monthly, we've had two weekly meetups (with two more at Tortuga) which went splendidly, including a trip to a karaoke place.&nbsp; But the weekly meet up is only an addition to the usual monthly meet up, which this month will happen on Saturday April 9, at 7 pm.&nbsp; As usual, we will be meeting at the <a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">Oxford Street Starbucks</a> and then moving to Free Speech Cafe on the UC Berkeley Campus (the Cafe is outdoors, bring a coat).&nbsp; We will make time for people to get take out dinner from restaurants in downtown Berkeley, to be eaten at the Cafe.&nbsp; This is great time to meet the Bay Area Less Wrong community, and I welcome newcomers and, from the old hands, guests.</p>\n<p>If you enjoy LW meetups, and want to go to them more often, there is the weekly meetup in Berkeley, which also meets at the <a href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=Downtown+Berkeley+BART&amp;daddr=2128+Oxford+St,+Berkeley,+CA+94704-1311+%28Starbucks%29&amp;geocode=FSzZQQIdbVa2-Ck7jvjKnX6FgDG3LOQ7rN5ZmA%3BFW7bQQIdQl62-CEGuQ_bapaUqCmz2L6SnX6FgDHtCjCMFeuX-A&amp;hl=en&amp;mra=ltm&amp;dirflg=w&amp;sll=37.86999,-122.26696&amp;sspn=0.001931,0.005284&amp;ie=UTF8&amp;ll=37.870225,-122.266577&amp;spn=0.001931,0.005284&amp;z=18\">Oxford Street Starbucks</a>, on Wednesdays at 7.&nbsp; This week we will be playing board games, so if you enjoy being strategic, please come.&nbsp; Bringing your favorite board game is welcomed.&nbsp; To receive regular information about the LW events planned in the Bay Area, please sign up for the <a href=\"http://groups.google.com/group/bayarealesswrong\">Google Group</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4kHhi7TFwyfh2rM2H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 6, "extendedScore": null, "score": 6.980468524522969e-07, "legacy": true, "legacyId": "6606", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["N8DaeP83CSgKnjcid"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T05:51:49.929Z", "modifiedAt": null, "url": null, "title": "Approaching rationality via a slippery slope", "slug": "approaching-rationality-via-a-slippery-slope", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:06.977Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/quSNJkEc8aYbtTjmC/approaching-rationality-via-a-slippery-slope", "pageUrlRelative": "/posts/quSNJkEc8aYbtTjmC/approaching-rationality-via-a-slippery-slope", "linkUrl": "https://www.lesswrong.com/posts/quSNJkEc8aYbtTjmC/approaching-rationality-via-a-slippery-slope", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Approaching%20rationality%20via%20a%20slippery%20slope&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApproaching%20rationality%20via%20a%20slippery%20slope%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FquSNJkEc8aYbtTjmC%2Fapproaching-rationality-via-a-slippery-slope%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Approaching%20rationality%20via%20a%20slippery%20slope%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FquSNJkEc8aYbtTjmC%2Fapproaching-rationality-via-a-slippery-slope", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FquSNJkEc8aYbtTjmC%2Fapproaching-rationality-via-a-slippery-slope", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1330, "htmlBody": "<p>I have been thinking recently about how to get other people to do the things I want them to do, because it seems like overwhelmingly the best way to get those things done.</p>\n<p>I typically encounter two difficulties off the bat:</p>\n<ul>\n<li>Convincing people they should care about the future of humanity.</li>\n<li>Convincing people that they should spend time thinking about how to act strategically on that preference.&nbsp;</li>\n</ul>\n<p>One interesting observation is that people typically reject either one or the other. Some people agree that <em>if</em> they wanted to help other people, they should do rather extreme and unusual things, but claim to not care about other people. Some people agree that helping other people is very important, but think that typical philanthropic activity is reasonably effective (so effective that its not worth spending much time to optimize further). I think this is a consistent quirk of human nature: people encounter a conclusion they don't like and a bunch of premises that seem reasonable, and they choose one premise to reject while they can be manipulated into accepting the others. This is probably a useful thing to make a mental note of and try to exploit productively.</p>\n<p>That observation aside, I think the easiest plan is to talk to smart people who already care deeply about other humans, but don't think too hard about how to act strategically on that preference. One approach is to present an idea very concisely which strongly suggests that 5 minutes of thought about strategic behavior is warranted. With the 5 minutes, maybe an idea can be communicated which implies that an hour of thought about strategic behavior is warranted. With an hour, maybe more progress can be made. And so on.</p>\n<p>I would like to brainstorm ideas which have a good ratio of \"Amount of re-evaluation of priorities / strategies they inspire in someone who is unconsciously trying very hard to avoid changing their behavior\" / \"Amount of time required to communicate to someone who is attentive but unconsciously trying very hard to avoid changing their behavior.\" Perhaps more important are thoughts about how to present these ideas efficiently. A lot of what I am about to say is somewhat redundant with other content at LW: try and consider it particularly in the context of strong time limitations and trying to talk to someone who is not fundamentally interested in becoming rational.</p>\n<p>1. Rational philanthropy. Present two or more activities many people engage in (donating to different charitable organizations, donating vs. volunteering, solving the same social problem in different ways), together with a concise and maximally incontrovertible argument that one of those activities is <em>significantly</em> better than the other, and that anyone who does the other is <em>wasting their energy</em>. Suggest that the collective behavior of society is a horrible marker for what is effective. Suggest that to the extent that socially typical activities are optimally useful, it is coincidental. Suggest that if some people do very little good in the world because they don't think enough, we may also do very little good (compared to our potential) because we don't think enough.</p>\n<p>2. Value of technological progress. Present a plausible deductive argument that either (A) the value of increasing the speed of technological progress is immensely higher than the value of doing traditional philanthropic work or (B) the value of controlling the direction of technological progress is immensely higher than the value of doing traditional philanthropic work. Suggest that, regardless of how their careful consideration of the argument turns out, it <em>could</em> cause a complete change in priorities. Suggest further that, if the argument fails and the listener doesn't have to change their behavior, its <em>not</em> because the listener has considered all the possibilities at length and chosen the best one. Indeed, the majority of people engaged in philanthropic work haven't; to the extent that their behavior is maximally effective it is coincidental. The potential difference between \"maximally effective\" and the default is incredibly large.</p>\n<p>5/2. Any other extremely important considerations which you can plausibly argue might change someone's priorities completely. That was the best one I could think of, but having more seems good. Even if the listener ultimately rejects the argument, if you can maintain even for a couple of minutes the possibility that this idea--which they haven't even given a minute's thought--could change their views, then you might be able to get some leverage out of it.</p>\n<p>3. Scope insensitivity. Point out that scope insensitivity exists and can do ridiculous things to people's judgments, using the most quickly convincing empirical evidence available; so far the best I have heard (probably from EY, though I don't know) is a study about saving wildlife, whose details I should surely know by heart if there is no more effective study (and whose methodological soundness I should briefly confirm before using it in such an argument). Point out that a billion people is a lot, and its unlikely that human intuition ever comes up with the right answer on questions that concern a billion people (much less larger numbers).</p>\n<p>4. Society is generally insane. Offer any evidence that suggests that, especially when a market isn't filtering out the bad ideas, social consensus can fail catastrophically. Suggest that any beliefs derived from social consensus should be questioned, and that even very good ideas don't actually propagate through society that quickly when they don't help people make money.</p>\n<p>These arguments are all more towards the quick end of the spectrum, because thats what I think about most right now. The hope is that if you can win a little more actual introspection from a listener, you can make more progress. The other stages are better covered by existing material on LW, but I think it is worth looking at exactly what you would do with, say, thirty minutes of introspection. I feel like I have less to contribute here, so I will just mention some things briefly.</p>\n<p>5. Examples of common biases. This is a harder argument to make than LW collectively seems to think. It is not obvious to me that my hindsight bias is a big deal--you need to really convince me that the quality of my reasoning is important and that a particular bias affects it in a significant way.</p>\n<p>6. Evidence that people rarely change their mind. This seems like the most important one, but it again is a fairly hard argument. You need to actually convince the listener that they personally should be changing their mind more often than they do, and that they are suffering significantly (or are significantly less effective at helping others) as a result.</p>\n<p>7. The importance of thinking about the value of future humans. This is also difficult, because discussions along these lines seem invariably to get pulled into the category of \"philosophical garbage\" (about which people are happy to talk at great length without thinking very much or updating any beliefs) rather than discussions about what to actually do with yourself tomorrow. But thinking explicitly about the value of the future is not too far fetched for most people to stomach, and realizing how important this question is (whatever the answer turns out to be) may suggest how important thinking about other previously unconsidered things may be.</p>\n<p>These ideas are towards the middle of the range. I expect if carefully constructed you could get mileage out of them in the course of a single conversation (starting from some easier topics). Here are what I imagine as the last and hardest things to sell, though I can't say anything about how to do it.</p>\n<p>8. Let your thoughts about what you should do control what you actually do. Seriously, when you walk away from this, let it have some effect on your behavior.</p>\n<p>9. You have to make decisions in the face of incredible uncertainty. You don't get to abstain from having beliefs just because thinking about the future is hard. Learn to think precisely about uncertainty, and then do it. Don't reject a belief because it is ridiculous.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "quSNJkEc8aYbtTjmC", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "6607", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T09:55:03.526Z", "modifiedAt": null, "url": null, "title": "Rationality Quotes: April 2011", "slug": "rationality-quotes-april-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:05:51.886Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "benelliott", "createdAt": "2010-10-24T16:54:14.159Z", "isAdmin": false, "displayName": "benelliott"}, "userId": "H4iHqStnPyuAkniAA", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NdmbbhWp79qf4ivtF/rationality-quotes-april-2011", "pageUrlRelative": "/posts/NdmbbhWp79qf4ivtF/rationality-quotes-april-2011", "linkUrl": "https://www.lesswrong.com/posts/NdmbbhWp79qf4ivtF/rationality-quotes-april-2011", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%20Quotes%3A%20April%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%20Quotes%3A%20April%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdmbbhWp79qf4ivtF%2Frationality-quotes-april-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%20Quotes%3A%20April%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdmbbhWp79qf4ivtF%2Frationality-quotes-april-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNdmbbhWp79qf4ivtF%2Frationality-quotes-april-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 67, "htmlBody": "<p>You all know the rules:</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; list-style-type: disc; list-style-position: outside; list-style-image: initial; \">\n<li>Please post all quotes separately, so that they can be voted up/down separately.&nbsp; (If they are strongly related, reply to your own comments.&nbsp; If strongly ordered, then go ahead and post them together.)</li>\n<li>Do not quote yourself.</li>\n<li>Do not quote comments/posts on LW/OB.</li>\n<li>No more than 5 quotes per person per monthly thread, please.</li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Zwc2JcT5az4e5YpJy": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NdmbbhWp79qf4ivtF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 6.981518594588325e-07, "legacy": true, "legacyId": "6608", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 393, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T11:40:05.167Z", "modifiedAt": null, "url": null, "title": "Talk and Meetup today 4/4 in San Diego", "slug": "talk-and-meetup-today-4-4-in-san-diego", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.637Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yu5zL3f6KXbkyykfm/talk-and-meetup-today-4-4-in-san-diego", "pageUrlRelative": "/posts/yu5zL3f6KXbkyykfm/talk-and-meetup-today-4-4-in-san-diego", "linkUrl": "https://www.lesswrong.com/posts/yu5zL3f6KXbkyykfm/talk-and-meetup-today-4-4-in-san-diego", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Talk%20and%20Meetup%20today%204%2F4%20in%20San%20Diego&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATalk%20and%20Meetup%20today%204%2F4%20in%20San%20Diego%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyu5zL3f6KXbkyykfm%2Ftalk-and-meetup-today-4-4-in-san-diego%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Talk%20and%20Meetup%20today%204%2F4%20in%20San%20Diego%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyu5zL3f6KXbkyykfm%2Ftalk-and-meetup-today-4-4-in-san-diego", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyu5zL3f6KXbkyykfm%2Ftalk-and-meetup-today-4-4-in-san-diego", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 130, "htmlBody": "<p><a id=\"more\"></a>Today in San Diego, Carl Shulman and I will be giving a talk at 3:30pm at San Diego State University, on whether whole brain emulation can help us safely navigate the Singularity. &nbsp;There will be a gathering afterward for beer and discussion. &nbsp;Come join us for the talk, beer, or both; it should be stimulating.</p>\n<p>The talk is in the GMCS (Geology, Mathematics and Computer Science) building, room 405. &nbsp;(This is on the East side of campus, near the college avenue exit off the 8 freeway. &nbsp;But campus is small enough that parking anywhere and then asking someone should also work; feel free also to give me a call). &nbsp;The after-party is walking distance from the same place; give me a call for directions, at&nbsp;619 213 2741.</p>\n<p>Hope to see you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yu5zL3f6KXbkyykfm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 6.981810765646686e-07, "legacy": true, "legacyId": "6609", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T16:24:55.979Z", "modifiedAt": null, "url": null, "title": "How to offer peer review comments", "slug": "how-to-offer-peer-review-comments", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.135Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WoGsjW5oLE5Af8di6/how-to-offer-peer-review-comments", "pageUrlRelative": "/posts/WoGsjW5oLE5Af8di6/how-to-offer-peer-review-comments", "linkUrl": "https://www.lesswrong.com/posts/WoGsjW5oLE5Af8di6/how-to-offer-peer-review-comments", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20to%20offer%20peer%20review%20comments&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20to%20offer%20peer%20review%20comments%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWoGsjW5oLE5Af8di6%2Fhow-to-offer-peer-review-comments%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20to%20offer%20peer%20review%20comments%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWoGsjW5oLE5Af8di6%2Fhow-to-offer-peer-review-comments", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWoGsjW5oLE5Af8di6%2Fhow-to-offer-peer-review-comments", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 114, "htmlBody": "<p>I was recently asked by an editor to offer (<a href=\"http://en.wikipedia.org/wiki/Peer_review#Different_styles_of_review\">single-blind</a>) peer review comments for some upcoming academic work on the Singularity. Having never done this before, I sought out some literature on how to do it.</p>\n<p>In case others find themselves in this position, here are some helpful papers I found:</p>\n<p>\n<ul>\n<li>Benos et al., <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Benos-How-to-review-a-paper.pdf\">How to review a paper</a></li>\n<li>Guilford, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Guilford-Teaching-peer-review-and-the-process-of-scientific-writing.pdf\">Teaching peer review and the process of scientific writing</a></li>\n<li>Provenzale &amp; Stanley, <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Provenzale-A-systematic-guide-to-reviewing-a-manuscript.pdf\">A systematic guide to reviewing a manuscript</a></li>\n</ul>\n<div>But I know that many Less Wrongers have been engaged in the peer review process for many years. If so, please offer your own comments or link to other helpful instructions!</div>\n<div><br /></div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WoGsjW5oLE5Af8di6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 9, "extendedScore": null, "score": 6.982603277979197e-07, "legacy": true, "legacyId": "6610", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T17:02:11.012Z", "modifiedAt": null, "url": null, "title": "Economics of Bitcoin", "slug": "economics-of-bitcoin", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.519Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Matt_Simpson", "createdAt": "2009-03-05T21:06:45.432Z", "isAdmin": false, "displayName": "Matt_Simpson"}, "userId": "v4krJe8Qa4jnhPTmd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jwuZgk3BXnNqkyK29/economics-of-bitcoin", "pageUrlRelative": "/posts/jwuZgk3BXnNqkyK29/economics-of-bitcoin", "linkUrl": "https://www.lesswrong.com/posts/jwuZgk3BXnNqkyK29/economics-of-bitcoin", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Economics%20of%20Bitcoin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEconomics%20of%20Bitcoin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwuZgk3BXnNqkyK29%2Feconomics-of-bitcoin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Economics%20of%20Bitcoin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwuZgk3BXnNqkyK29%2Feconomics-of-bitcoin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjwuZgk3BXnNqkyK29%2Feconomics-of-bitcoin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 69, "htmlBody": "<p>I haven't read/listened to them, but I thought these might be interesting to the local bitcoin users:</p>\n<p>Eli Dourado (GMU econ PhD candidate) on <a href=\"http://elidourado.com/blog/economics-cryptocurrency/\">the economics of cryptocurrency</a>.</p>\n<p>Econtalk podcast - Russ Roberts (GMU econ prof) with Gavin Andresen, Principal of the BitCoin Virtual Currency Project on, <a href=\"http://www.econtalk.org/archives/2011/04/andresen_on_bit.html\">Virtual Currency</a>.</p>\n<p>Roberts' podcast is always stimulating even if I disagree with him, and Eli is a pretty insightful guy who I've met in meatspace.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jwuZgk3BXnNqkyK29", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 10, "extendedScore": null, "score": 6.982706929675163e-07, "legacy": true, "legacyId": "6611", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T17:07:01.524Z", "modifiedAt": null, "url": null, "title": "Rationality, Community, and Death", "slug": "rationality-community-and-death", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.245Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "zaph", "createdAt": "2009-03-09T16:48:24.816Z", "isAdmin": false, "displayName": "zaph"}, "userId": "j6gu6vjBnANKCcfsR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/G5tWzsvJFbh4H7Aqd/rationality-community-and-death", "pageUrlRelative": "/posts/G5tWzsvJFbh4H7Aqd/rationality-community-and-death", "linkUrl": "https://www.lesswrong.com/posts/G5tWzsvJFbh4H7Aqd/rationality-community-and-death", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rationality%2C%20Community%2C%20and%20Death&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARationality%2C%20Community%2C%20and%20Death%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5tWzsvJFbh4H7Aqd%2Frationality-community-and-death%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rationality%2C%20Community%2C%20and%20Death%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5tWzsvJFbh4H7Aqd%2Frationality-community-and-death", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FG5tWzsvJFbh4H7Aqd%2Frationality-community-and-death", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 875, "htmlBody": "<p>(I was really on the fence about posting this. It's just some thoughts tend to go through around this time of year, plus some current new thinking that resulted from being a LW lurker).</p>\n<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:TrackMoves /> <w:TrackFormatting /> <w:PunctuationKerning /> <w:ValidateAgainstSchemas /> <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid> <w:IgnoreMixedContent>false</w:IgnoreMixedContent> <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText> <w:DoNotPromoteQF /> <w:LidThemeOther>EN-US</w:LidThemeOther> <w:LidThemeAsian>X-NONE</w:LidThemeAsian> <w:LidThemeComplexScript>X-NONE</w:LidThemeComplexScript> <w:Compatibility> <w:BreakWrappedTables /> <w:SnapToGridInCell /> <w:WrapTextWithPunct /> <w:UseAsianBreakRules /> <w:DontGrowAutofit /> <w:SplitPgBreakAndParaMark /> <w:DontVertAlignCellWithSp /> <w:DontBreakConstrainedForcedTables /> <w:DontVertAlignInTxbx /> <w:Word11KerningPairs /> <w:CachedColBalance /> </w:Compatibility> <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel> <m:mathPr> <m:mathFont m:val=\"Cambria Math\" /> <m:brkBin m:val=\"before\" /> <m:brkBinSub m:val=\"&#45;-\" /> <m:smallFrac m:val=\"off\" /> <m:dispDef /> <m:lMargin m:val=\"0\" /> <m:rMargin m:val=\"0\" /> <m:defJc m:val=\"centerGroup\" /> <m:wrapIndent m:val=\"1440\" /> <m:intLim m:val=\"subSup\" /> <m:naryLim m:val=\"undOvr\" /> </m:mathPr></w:WordDocument> </xml><![endif]--><!--[if gte mso 9]><xml> <w:LatentStyles DefLockedState=\"false\" DefUnhideWhenUsed=\"true\"   DefSemiHidden=\"true\" DefQFormat=\"false\" DefPriority=\"99\"   LatentStyleCount=\"267\"> <w:LsdException Locked=\"false\" Priority=\"0\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Normal\" /> <w:LsdException Locked=\"false\" Priority=\"9\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"heading 1\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 2\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 3\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 4\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 5\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 6\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 7\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 8\" /> <w:LsdException Locked=\"false\" Priority=\"9\" QFormat=\"true\" Name=\"heading 9\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 1\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 2\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 3\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 4\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 5\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 6\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 7\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 8\" /> <w:LsdException Locked=\"false\" Priority=\"39\" Name=\"toc 9\" /> <w:LsdException Locked=\"false\" Priority=\"35\" QFormat=\"true\" Name=\"caption\" /> <w:LsdException Locked=\"false\" Priority=\"10\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Title\" /> <w:LsdException Locked=\"false\" Priority=\"1\" Name=\"Default Paragraph Font\" /> <w:LsdException Locked=\"false\" Priority=\"11\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtitle\" /> <w:LsdException Locked=\"false\" Priority=\"22\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Strong\" /> <w:LsdException Locked=\"false\" Priority=\"20\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"59\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Table Grid\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Placeholder Text\" /> <w:LsdException Locked=\"false\" Priority=\"1\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"No Spacing\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 1\" /> <w:LsdException Locked=\"false\" UnhideWhenUsed=\"false\" Name=\"Revision\" /> <w:LsdException Locked=\"false\" Priority=\"34\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"List Paragraph\" /> <w:LsdException Locked=\"false\" Priority=\"29\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Quote\" /> <w:LsdException Locked=\"false\" Priority=\"30\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Quote\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 1\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 2\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 3\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 4\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 5\" /> <w:LsdException Locked=\"false\" Priority=\"60\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"61\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"62\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Light Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"63\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"64\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Shading 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"65\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"66\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium List 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"67\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 1 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"68\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 2 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"69\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Medium Grid 3 Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"70\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Dark List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"71\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Shading Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"72\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful List Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"73\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" Name=\"Colorful Grid Accent 6\" /> <w:LsdException Locked=\"false\" Priority=\"19\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"21\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Emphasis\" /> <w:LsdException Locked=\"false\" Priority=\"31\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Subtle Reference\" /> <w:LsdException Locked=\"false\" Priority=\"32\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Intense Reference\" /> <w:LsdException Locked=\"false\" Priority=\"33\" SemiHidden=\"false\"    UnhideWhenUsed=\"false\" QFormat=\"true\" Name=\"Book Title\" /> <w:LsdException Locked=\"false\" Priority=\"37\" Name=\"Bibliography\" /> <w:LsdException Locked=\"false\" Priority=\"39\" QFormat=\"true\" Name=\"TOC Heading\" /> </w:LatentStyles> </xml><![endif]--><!--[if gte mso 10]>\n<style>\n /* Style Definitions */\n table.MsoNormalTable\n\t{mso-style-name:\"Table Normal\";\n\tmso-tstyle-rowband-size:0;\n\tmso-tstyle-colband-size:0;\n\tmso-style-noshow:yes;\n\tmso-style-priority:99;\n\tmso-style-qformat:yes;\n\tmso-style-parent:\"\";\n\tmso-padding-alt:0in 5.4pt 0in 5.4pt;\n\tmso-para-margin-top:0in;\n\tmso-para-margin-right:0in;\n\tmso-para-margin-bottom:10.0pt;\n\tmso-para-margin-left:0in;\n\tline-height:115%;\n\tmso-pagination:widow-orphan;\n\tfont-size:11.0pt;\n\tfont-family:\"Calibri\",\"sans-serif\";\n\tmso-ascii-font-family:Calibri;\n\tmso-ascii-theme-font:minor-latin;\n\tmso-fareast-font-family:\"Times New Roman\";\n\tmso-fareast-theme-font:minor-fareast;\n\tmso-hansi-font-family:Calibri;\n\tmso-hansi-theme-font:minor-latin;}\n</style>\n<![endif]--></p>\n<p class=\"MsoNormal\">Around this time of year, I tend to start thinking about death a lot. My dad died 12 years ago this month, and it&rsquo;s still one of the most significant events of my life. Death is something that still seems to be solidly in the hands of religious and spiritual types as a discussion topic. I&rsquo;m hoping that this post (in addition to not being too rambling) can provide some impetus for people to challenge that in daily life.</p>\n<p class=\"MsoNormal\">I don&rsquo;t mean this to be an angry screed against religions. There was a priest on hand when my dad died. My mom, sister and aunt were gathered around, and it was in the midst of praying that my dad finally passed away (I apologize for the wording; our language can be so spiritually loaded, I just want to avoid saying died over and over). He told a really nice story about my dad being in heaven. It was comforting at the moment, a kind of way for my family to keep those awful, overwhelming feelings of loss at bay.</p>\n<p class=\"MsoNormal\">But it was after I got home and started calling my relatives that the enormity of the situation hit me. My uncle in particular broke down into angry tears when I told him the news. My dad was his older brother, and meant so much to him. There wasn&rsquo;t any story that was going to make that loss any better. My uncle really thought there was more that could have been done medically. At the time (I don&rsquo;t know what the state of the art medicine of today could have done), I really don&rsquo;t believe that was the case. I remember watching my dad have seizures at the rate of about twice a minute. When he died, I was relieved to see that come to an end. He was going through intensive chemotherapy at the time, and died of sepsis. His body was just facing too much, and finally succumbed. There just wasn&rsquo;t any way around what the eventual outcome was going to be, sadly.</p>\n<p class=\"MsoNormal\">The bright side in the situation, and what I hope to impart, was the strength I got from being around my friends and family; the community of people that came around to take care of us. We were inundated with food baskets, for instance. I was in such a state of shock in trying to process the situation, not having to worry about basic things like meals was a relief. And so many people who knew my dad or our family came by to share their condolences. The conversations were awkward. People didn&rsquo;t know what to say. And it meant the world to me that they tried. Friends of mine came out of town to be with me specifically. I was so, so grateful that they took time out of their lives to do that.</p>\n<p class=\"MsoNormal\">I can give you all the standard but true things about death; live everyday like it matters, tell people that you love them today, for examples. But, I wanted to share that I think the best rational response to death is for the community to be there for people. I&rsquo;ve been reading about the various meetups here on LW, and something that stood out for me was the community aspect of bonding. I really and truly believe that the way to make rationality matter is to keep building these rational communities, just as communities. I think it was the New York meetup that has really emerged into a group with strong bonds. I don&rsquo;t see this as a condolences arms race, necessarily. But over time, these groups will be able to take care of themselves when these hard times come. We give a lot of power to religious groups, because they&rsquo;re one of the few who step up when these hard times hit families. Often times, they are the only larger community a person is a part of. It&rsquo;s really important, in my eyes, to offer alternatives to that.</p>\n<p class=\"MsoNormal\">So, I would encourage the meetups up and the like to emulate what I read about in New York. Sure, talk about rationality and related topics. But please do recognize the impact of just bonding in a group. Eventually, being the group of people that supports someone as they grieve is exemplary work, and I believe that is something that will naturally arise out of these communities. If you can step outside of that group and be there for others, so much the better. Rationally speaking, I think humans would be better off if there were ways to grieve openly and fully, without having to factor in religious stories.</p>\n<p class=\"MsoNormal\">I apologize if this post is a bit rambling; it brings up a lot of emotions for me. It meant so much to me that my dad said he was proud of me while he was still coherent, at a time when I wasn&rsquo;t very proud of myself, for instance. That and so many other things are going through my head. I just wanted to get this out. Thanks for reading.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"E9ihK6bA9YKkmJs2f": 1, "C7LDCaPh9vF6TFubF": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "G5tWzsvJFbh4H7Aqd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 31, "extendedScore": null, "score": 6e-05, "legacy": true, "legacyId": "6613", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 21, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T22:08:41.998Z", "modifiedAt": null, "url": null, "title": "The Importance of Research", "slug": "the-importance-of-research", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:39.601Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "falenas108", "createdAt": "2010-10-28T17:32:39.696Z", "isAdmin": false, "displayName": "falenas108"}, "userId": "BCX7q7NMQphQiXc8j", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uqW4wDk4JWwBpYQf6/the-importance-of-research", "pageUrlRelative": "/posts/uqW4wDk4JWwBpYQf6/the-importance-of-research", "linkUrl": "https://www.lesswrong.com/posts/uqW4wDk4JWwBpYQf6/the-importance-of-research", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Importance%20of%20Research&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Importance%20of%20Research%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuqW4wDk4JWwBpYQf6%2Fthe-importance-of-research%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Importance%20of%20Research%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuqW4wDk4JWwBpYQf6%2Fthe-importance-of-research", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuqW4wDk4JWwBpYQf6%2Fthe-importance-of-research", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 312, "htmlBody": "<p>This is just a quick example of why it's always good to check the source material.</p>\n<p>&nbsp;</p>\n<p>Cracked <a href=\"http://www.cracked.com/article_19121_7-basic-things-you-wont-believe-youre-all-doing-wrong_p2.html\">ran an article today</a> about several things people are doing wrong, and the number one thing they listed was sitting.&nbsp; According to a an experiment they cite, one researcher tested disk movement for people slouching, sitting up straight, and leaning back at a 135\u02da angle.&nbsp; They found that leaning back does the least damage to the spine.</p>\n<p>Interested, I clicked on their link which sent me to <a href=\"http://www.msnbc.msn.com/id/15939377/ns/health-health_care/\">this article</a> from MSNBC, which among other things, says:</p>\n<blockquote>\n<p>When strain is placed on the spine, the spinal disks start to move and misalign. At a 90-degree sitting position, this movement was most prominent.</p>\n</blockquote>\n<p>With this, I was considered making a lifestyle change to slouching when using the computer, as leaning back isn't usually an option for serious work.&nbsp; But, I still wanted to read more about the experiment.</p>\n<p>Unfortunately, they didn't have the link to the actual paper.&nbsp; A bit of googling led me to <a href=\"http://www.familypracticenews.com/index.php?id=2934&amp;type=98&amp;tx_ttnews[tt_news]=45417&amp;cHash=da03e20e36\">an article that actually had the experiment's methodology</a>, which says that slouching was actually the worst position!&nbsp;</p>\n<p>It maintained that leaning back is best, but according to the results the 90\u02da angle isn't that bad, especially since most of the other articles I found were implying that the advice to sit up straight is wrong.&nbsp; Considering that people are usually slouching when the advice is given, sitting up is still an improvement.&nbsp; This is especially true at places like dinner tables, where leaning back as suggested isn't really an option.</p>\n<p>&nbsp;</p>\n<p>Moral of the story: Do research before changing personal habits, regardless of where the information comes from.</p>\n<p>&nbsp;</p>\n<p>Note: Afterwards, I did a bit more googling to see which other news sources carried this story incorrectly.&nbsp; The most prominent misinformation came from <a href=\"http://www.foxnews.com/story/0,2933,232237,00.html\">a Fox News article</a>, who carried the following headline:</p>\n<blockquote>\n<p class=\"head\">Study: Slouching Better for Back Than Sitting Up Straight</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"XqykXFKL9t38pbSEm": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uqW4wDk4JWwBpYQf6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 31, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "6615", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 23, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-04T23:27:50.032Z", "modifiedAt": null, "url": null, "title": "DC Meetup Discussion", "slug": "dc-meetup-discussion", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.876Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aHhtMsf5kX8LDTQJZ/dc-meetup-discussion", "pageUrlRelative": "/posts/aHhtMsf5kX8LDTQJZ/dc-meetup-discussion", "linkUrl": "https://www.lesswrong.com/posts/aHhtMsf5kX8LDTQJZ/dc-meetup-discussion", "postedAtFormatted": "Monday, April 4th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20DC%20Meetup%20Discussion&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADC%20Meetup%20Discussion%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaHhtMsf5kX8LDTQJZ%2Fdc-meetup-discussion%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=DC%20Meetup%20Discussion%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaHhtMsf5kX8LDTQJZ%2Fdc-meetup-discussion", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaHhtMsf5kX8LDTQJZ%2Fdc-meetup-discussion", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 162, "htmlBody": "<p>There are some LWers in the DC area. We should meet up.<br /><br />Unfortunately, I'm out of town pretty much until the end of April. But there are a few things to work out before then, so I might as well post now.<br /><br />A meetup needs:</p>\n<ul>\n<li>People</li>\n<li>Location</li>\n<li>Time/Day</li>\n<li>Things to do/talk about</li>\n</ul>\n<div>The first one is covered by you and your rational friends showing up.<br /><br />I'm not sure about the other three. Does anyone else have input on these? I'm particularly clueless about the location, but think we should meet on the weekends. I'm fine arbitrarily deciding these, but if there's anything more convenient for other people we have time to plan before I'm available again.</div>\n<div>Please comment if you're interested, or have suggestions.</div>\n<div>I hereby precommit to having a meetup in May planned by April 26th.<br /></div>\n<div><a href=\"/lw/520/baltimore_meetup_410_1pm/3tao\">This</a>&nbsp; also talked about having a meeting on May 15th.</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aHhtMsf5kX8LDTQJZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 6.983780182774622e-07, "legacy": true, "legacyId": "6618", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T09:14:40.772Z", "modifiedAt": null, "url": null, "title": "[link] flowchart for rational discussions", "slug": "link-flowchart-for-rational-discussions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.253Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alexflint", "createdAt": "2009-07-17T10:07:09.115Z", "isAdmin": false, "displayName": "Alex Flint"}, "userId": "ifEGDHySkAejhCFDf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jnjgSFdR96D4aQAFm/link-flowchart-for-rational-discussions", "pageUrlRelative": "/posts/jnjgSFdR96D4aQAFm/link-flowchart-for-rational-discussions", "linkUrl": "https://www.lesswrong.com/posts/jnjgSFdR96D4aQAFm/link-flowchart-for-rational-discussions", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5Blink%5D%20flowchart%20for%20rational%20discussions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5Blink%5D%20flowchart%20for%20rational%20discussions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjnjgSFdR96D4aQAFm%2Flink-flowchart-for-rational-discussions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5Blink%5D%20flowchart%20for%20rational%20discussions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjnjgSFdR96D4aQAFm%2Flink-flowchart-for-rational-discussions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjnjgSFdR96D4aQAFm%2Flink-flowchart-for-rational-discussions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 20, "htmlBody": "<p>I came across the following flow chart on a climate change blog and thought LWers would be interested to comment:</p>\n<p><a href=\"http://thoughtcatalog.com/wp-content/uploads/2011/03/A-Flowchart-to-Help-You-Determine-if-Yoursquore-Having-a-Rational-Discussion.jpg\">http://thoughtcatalog.com/wp-content/uploads/2011/03/A-Flowchart-to-Help-You-Determine-if-Yoursquore-Having-a-Rational-Discussion.jpg</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jnjgSFdR96D4aQAFm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 0, "extendedScore": null, "score": 6.985413916885327e-07, "legacy": true, "legacyId": "6621", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T10:52:31.807Z", "modifiedAt": null, "url": null, "title": "The Nature of Self", "slug": "the-nature-of-self", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.858Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SRf3P5Lqje4TC4nrX/the-nature-of-self", "pageUrlRelative": "/posts/SRf3P5Lqje4TC4nrX/the-nature-of-self", "linkUrl": "https://www.lesswrong.com/posts/SRf3P5Lqje4TC4nrX/the-nature-of-self", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Nature%20of%20Self&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Nature%20of%20Self%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSRf3P5Lqje4TC4nrX%2Fthe-nature-of-self%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Nature%20of%20Self%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSRf3P5Lqje4TC4nrX%2Fthe-nature-of-self", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSRf3P5Lqje4TC4nrX%2Fthe-nature-of-self", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 935, "htmlBody": "<p>In this post I try to fathom an informal definition of <span style=\"text-decoration: underline;\">Self</span>, the <em>\"essential qualities that constitute a person's uniqueness\"</em>. I assume that the most important requirement for a definition of <em>self</em> is time-consistency. A reliable definition of identity needs to allow for time-consistent <a href=\"http://en.wikipedia.org/wiki/Self-reference\" target=\"_blank\">self-referencing</a> since any agent that is unable to identify itself over time will be prone to make inconsistent decisions.</p>\n<h4>Data Loss<br /></h4>\n<p>Obviously most humans don't want to die, but what does that mean? What is it that humans try to preserve when they sign up for <a href=\"http://wiki.lesswrong.com/wiki/Cryonics\">Cryonics</a>? It seems that an explanation must account and allow for some sort of data loss.</p>\n<h4>The Continuity of Consciousness</h4>\n<p>It can't be about the continuity of consciousness as we would have to refuse <a href=\"http://en.wikipedia.org/wiki/General_anaesthesia\">general anesthesia</a> due to the risk of <em>\"dying\" </em>and most of us will agree that there is something more important than the continuity of consciousness that makes us accept a general anesthesia when necessary.</p>\n<h4>Computation<br /></h4>\n<p>If the continuity of <a href=\"http://consc.net/chalmers/\">consciousness</a> isn't the most important detail about the <a href=\"http://en.wikipedia.org/wiki/Self\"><em>self</em></a> then it very likely isn't the continuity of computation either. Imagine that for some reason the process evoked when <em>\"we\"</em> act on our inputs under the control of an algorithm halts for a second and then continues otherwise unaffected, would we don't mind to be <em>alive</em> ever after because we <em>died</em> when the computation halted? This doesn't seem to be the case.</p>\n<h4>Static Algorithmic Descriptions<br /></h4>\n<p>Although we are not partly software and partly hardware we could, in theory, come up with an algorithmic description of the human machine, of our <em>selfs</em>. Might it be <em>that</em> algorithm that we care about? If we were to digitize our <em>self</em> we would end up with a description of our spatial parts, our <em>self</em> at a certain time. Yet we forget that all of us possess such an algorithmic description of our <em>selfs</em> and we're already able back it up. It is our DNA.</p>\n<h4>Temporal Parts<br /></h4>\n<p>Admittedly our DNA is the earliest version of our <em>selfs</em>, but if we don't care about the <a href=\"http://plato.stanford.edu/entries/temporal-parts/\">temporal parts</a> of our<em> selfs</em> but only about a static algorithmic description of a certain spatiotemporal position, then what's wrong with that? It seems a lot, we stop caring about past reifications of our <em>selfs</em>, at some point our backups become obsolete and having to fall back on them would equal <em>death</em>. But what is it that <em>we</em> lost, what information is it that we value more than all of the previously mentioned possibilities? One might think that it must be our memories, the data that represents what we learnt and experienced. But even if this is the case, would it be a reasonable choice?</p>\n<h4>Indentity and Memory<br /></h4>\n<p>Let's just disregard the possibility that we often might not value our future selfs and so do not value our past selfs either for that we lost or updated important information, e.g. if we became religious or have been able to overcome religion.</p>\n<p>If we had perfect memory and only ever <em>improved</em> upon our past knowledge and experiences we wouldn't be able to do so for very long, at least not given our human body. The upper limit on the information that can be contained within a human body is <a href=\"http://en.wikipedia.org/wiki/Bekenstein_bound\">2.5072178&times;10<sup>38</sup> megabytes</a>, <em>if</em> it was used as a perfect data storage. Given that we gather much more than 1 megabyte of information per year, it is foreseeable that if we equate our memories with our <em>self</em> we'll die long before the <a href=\"http://en.wikipedia.org/wiki/Future_of_an_expanding_universe\">heat death of the universe</a>. We might overcome this by growing in size, by achieving a posthuman form, yet if we in turn also become much smarter we'll also produce and gather more information. We are not alone either and the resources are limited. One way or the other we'll die rather quickly.</p>\n<p>Does this mean we shouldn't even bother about the far future or is there maybe something else we value even more than our memories? After all we don't really mind much if we forget what we have done a few years ago.</p>\n<h4>Time-Consistency and Self-Reference</h4>\n<p>It seems that there is something even more important than our causal history. I think that more than everything we care about our values and goals. Indeed, we value the preservation of our values. As long as we want the same we are the same. Our goal system seems to be the critical part of our implicit definition of <em>self</em>, that which we want to protect and preserve. Our values and goals seem to be the missing temporal parts that allow us to consistently refer to <em>us</em>, to identify our <em>selfs</em> at different spatiotempiral positions.</p>\n<p>Using our values and goals as identifiers also resolves the problem of how we should treat copies of our <em>self</em> that are featuring alternating histories and memories, copies with different causal histories. Any agent that does feature a copy of our utility function ought to be incorporated into our decisions as an instance, as a reification of our <em>selfs</em>. We should identify with our utility-function regardless of its instantiation.</p>\n<h4>Stable Utility-Functions</h4>\n<p>To recapitulate, we can value our memories, the continuity of experience and even our DNA, but the only reliable marker for the <em>self identity</em> of goal-oriented agents seems to be a stable utility function. Rational agents with an identical utility function will to some extent converge to exhibit similar behavior and are therefore able to cooperate. We can more consistently identify with our values and goals than with our past and future memories, digitized backups or causal history.</p>\n<p>But even if this is true there is one problem, <a href=\"http://kruel.co/2011/07/22/objections-to-coherent-extrapolated-volition/\">humans might not exhibit goal-stability</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SRf3P5Lqje4TC4nrX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 6, "extendedScore": null, "score": 6.985686391230748e-07, "legacy": true, "legacyId": "6623", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>In this post I try to fathom an informal definition of <span style=\"text-decoration: underline;\">Self</span>, the <em>\"essential qualities that constitute a person's uniqueness\"</em>. I assume that the most important requirement for a definition of <em>self</em> is time-consistency. A reliable definition of identity needs to allow for time-consistent <a href=\"http://en.wikipedia.org/wiki/Self-reference\" target=\"_blank\">self-referencing</a> since any agent that is unable to identify itself over time will be prone to make inconsistent decisions.</p>\n<h4 id=\"Data_Loss\">Data Loss<br></h4>\n<p>Obviously most humans don't want to die, but what does that mean? What is it that humans try to preserve when they sign up for <a href=\"http://wiki.lesswrong.com/wiki/Cryonics\">Cryonics</a>? It seems that an explanation must account and allow for some sort of data loss.</p>\n<h4 id=\"The_Continuity_of_Consciousness\">The Continuity of Consciousness</h4>\n<p>It can't be about the continuity of consciousness as we would have to refuse <a href=\"http://en.wikipedia.org/wiki/General_anaesthesia\">general anesthesia</a> due to the risk of <em>\"dying\" </em>and most of us will agree that there is something more important than the continuity of consciousness that makes us accept a general anesthesia when necessary.</p>\n<h4 id=\"Computation\">Computation<br></h4>\n<p>If the continuity of <a href=\"http://consc.net/chalmers/\">consciousness</a> isn't the most important detail about the <a href=\"http://en.wikipedia.org/wiki/Self\"><em>self</em></a> then it very likely isn't the continuity of computation either. Imagine that for some reason the process evoked when <em>\"we\"</em> act on our inputs under the control of an algorithm halts for a second and then continues otherwise unaffected, would we don't mind to be <em>alive</em> ever after because we <em>died</em> when the computation halted? This doesn't seem to be the case.</p>\n<h4 id=\"Static_Algorithmic_Descriptions\">Static Algorithmic Descriptions<br></h4>\n<p>Although we are not partly software and partly hardware we could, in theory, come up with an algorithmic description of the human machine, of our <em>selfs</em>. Might it be <em>that</em> algorithm that we care about? If we were to digitize our <em>self</em> we would end up with a description of our spatial parts, our <em>self</em> at a certain time. Yet we forget that all of us possess such an algorithmic description of our <em>selfs</em> and we're already able back it up. It is our DNA.</p>\n<h4 id=\"Temporal_Parts\">Temporal Parts<br></h4>\n<p>Admittedly our DNA is the earliest version of our <em>selfs</em>, but if we don't care about the <a href=\"http://plato.stanford.edu/entries/temporal-parts/\">temporal parts</a> of our<em> selfs</em> but only about a static algorithmic description of a certain spatiotemporal position, then what's wrong with that? It seems a lot, we stop caring about past reifications of our <em>selfs</em>, at some point our backups become obsolete and having to fall back on them would equal <em>death</em>. But what is it that <em>we</em> lost, what information is it that we value more than all of the previously mentioned possibilities? One might think that it must be our memories, the data that represents what we learnt and experienced. But even if this is the case, would it be a reasonable choice?</p>\n<h4 id=\"Indentity_and_Memory\">Indentity and Memory<br></h4>\n<p>Let's just disregard the possibility that we often might not value our future selfs and so do not value our past selfs either for that we lost or updated important information, e.g. if we became religious or have been able to overcome religion.</p>\n<p>If we had perfect memory and only ever <em>improved</em> upon our past knowledge and experiences we wouldn't be able to do so for very long, at least not given our human body. The upper limit on the information that can be contained within a human body is <a href=\"http://en.wikipedia.org/wiki/Bekenstein_bound\">2.5072178\u00d710<sup>38</sup> megabytes</a>, <em>if</em> it was used as a perfect data storage. Given that we gather much more than 1 megabyte of information per year, it is foreseeable that if we equate our memories with our <em>self</em> we'll die long before the <a href=\"http://en.wikipedia.org/wiki/Future_of_an_expanding_universe\">heat death of the universe</a>. We might overcome this by growing in size, by achieving a posthuman form, yet if we in turn also become much smarter we'll also produce and gather more information. We are not alone either and the resources are limited. One way or the other we'll die rather quickly.</p>\n<p>Does this mean we shouldn't even bother about the far future or is there maybe something else we value even more than our memories? After all we don't really mind much if we forget what we have done a few years ago.</p>\n<h4 id=\"Time_Consistency_and_Self_Reference\">Time-Consistency and Self-Reference</h4>\n<p>It seems that there is something even more important than our causal history. I think that more than everything we care about our values and goals. Indeed, we value the preservation of our values. As long as we want the same we are the same. Our goal system seems to be the critical part of our implicit definition of <em>self</em>, that which we want to protect and preserve. Our values and goals seem to be the missing temporal parts that allow us to consistently refer to <em>us</em>, to identify our <em>selfs</em> at different spatiotempiral positions.</p>\n<p>Using our values and goals as identifiers also resolves the problem of how we should treat copies of our <em>self</em> that are featuring alternating histories and memories, copies with different causal histories. Any agent that does feature a copy of our utility function ought to be incorporated into our decisions as an instance, as a reification of our <em>selfs</em>. We should identify with our utility-function regardless of its instantiation.</p>\n<h4 id=\"Stable_Utility_Functions\">Stable Utility-Functions</h4>\n<p>To recapitulate, we can value our memories, the continuity of experience and even our DNA, but the only reliable marker for the <em>self identity</em> of goal-oriented agents seems to be a stable utility function. Rational agents with an identical utility function will to some extent converge to exhibit similar behavior and are therefore able to cooperate. We can more consistently identify with our values and goals than with our past and future memories, digitized backups or causal history.</p>\n<p>But even if this is true there is one problem, <a href=\"http://kruel.co/2011/07/22/objections-to-coherent-extrapolated-volition/\">humans might not exhibit goal-stability</a>.</p>", "sections": [{"title": "Data Loss", "anchor": "Data_Loss", "level": 1}, {"title": "The Continuity of Consciousness", "anchor": "The_Continuity_of_Consciousness", "level": 1}, {"title": "Computation", "anchor": "Computation", "level": 1}, {"title": "Static Algorithmic Descriptions", "anchor": "Static_Algorithmic_Descriptions", "level": 1}, {"title": "Temporal Parts", "anchor": "Temporal_Parts", "level": 1}, {"title": "Indentity and Memory", "anchor": "Indentity_and_Memory", "level": 1}, {"title": "Time-Consistency and Self-Reference", "anchor": "Time_Consistency_and_Self_Reference", "level": 1}, {"title": "Stable Utility-Functions", "anchor": "Stable_Utility_Functions", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "22 comments"}], "headingsCount": 10}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T13:49:05.452Z", "modifiedAt": null, "url": null, "title": "[Link] A review of proposals toward safe AI", "slug": "link-a-review-of-proposals-toward-safe-ai", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:22.321Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "XiXiDu", "createdAt": "2009-03-07T18:49:18.890Z", "isAdmin": false, "displayName": "XiXiDu"}, "userId": "DH3Hiv6kJp93dDF4J", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3xunBhXAoFHzaFDbs/link-a-review-of-proposals-toward-safe-ai", "pageUrlRelative": "/posts/3xunBhXAoFHzaFDbs/link-a-review-of-proposals-toward-safe-ai", "linkUrl": "https://www.lesswrong.com/posts/3xunBhXAoFHzaFDbs/link-a-review-of-proposals-toward-safe-ai", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLink%5D%20A%20review%20of%20proposals%20toward%20safe%20AI&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLink%5D%20A%20review%20of%20proposals%20toward%20safe%20AI%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xunBhXAoFHzaFDbs%2Flink-a-review-of-proposals-toward-safe-ai%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLink%5D%20A%20review%20of%20proposals%20toward%20safe%20AI%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xunBhXAoFHzaFDbs%2Flink-a-review-of-proposals-toward-safe-ai", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3xunBhXAoFHzaFDbs%2Flink-a-review-of-proposals-toward-safe-ai", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 274, "htmlBody": "<blockquote>\n<p>Eliezer Yudkowsky set out to define more precisely what it means for an entity to have &ldquo;what people really want&rdquo; as a goal. Coherent Extrapolated Volition was his proposal. Though CEV was never meant as more than a working proposal; his write-up provides the best insights to date into the challenges of the Friendly AI problem, the pitfalls and possible paths to a solution.</p>\n<p>[...]</p>\n<p>Ben Goertzel responded with Coherent Aggregated Volition, a simplified variant of CEV. In CAV, the entity&rsquo;s goal is a balance between&nbsp; the desires of all humans, but it looks at the volition of humans directly, without extrapolation to a wiser future. This omission is not just to make the computation easier (it is still quite intractable), but rather to show some respect to humanity&rsquo;s desires as they are, without extrapolation to a hypothetical improved morality.</p>\n<p>[...]</p>\n<p>Stuart Armstrong&rsquo;s &ldquo;Chaining God&rdquo; is a different approach, aimed at the problem of interacting with and trusting the good will of an ultraintelligence so far beyond us that we have nothing in common with it. A succession of AIs, of gradually increasing intelligence, each guarantees the trustworthiness of one which is slightly smarter than it. This resembles Yudkowsy&rsquo;s idea of a self-improving machine which verifies that its next stage has the same goals, but the successive levels of intelligence remain active simultaneously, so that they can continue to verify Friendliness.</p>\n<p>Ray Kurzweil thinks that we will achieve safe ultraintelligence by gradually becoming that ultraintelligence. We will merge with the rising new intelligence, whether by interfacing with computers or by uploading our brains to a computer substrate.</p>\n</blockquote>\n<p><strong>Link:</strong> <a href=\"http://adarti.blogspot.com/2011/04/review-of-proposals-toward-safe-ai.html\">adarti.blogspot.com/2011/04/review-of-proposals-toward-safe-ai.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3xunBhXAoFHzaFDbs", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 13, "extendedScore": null, "score": 6.986178089376407e-07, "legacy": true, "legacyId": "6624", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T17:12:04.741Z", "modifiedAt": null, "url": null, "title": "How can I delete my less wrong account?", "slug": "how-can-i-delete-my-less-wrong-account", "viewCount": null, "lastCommentedAt": "2017-06-17T04:33:35.852Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "zRwEwWNXmoTPueowb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DfeLeAhkmxaqtsxBM/how-can-i-delete-my-less-wrong-account", "pageUrlRelative": "/posts/DfeLeAhkmxaqtsxBM/how-can-i-delete-my-less-wrong-account", "linkUrl": "https://www.lesswrong.com/posts/DfeLeAhkmxaqtsxBM/how-can-i-delete-my-less-wrong-account", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20can%20I%20delete%20my%20less%20wrong%20account%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20can%20I%20delete%20my%20less%20wrong%20account%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfeLeAhkmxaqtsxBM%2Fhow-can-i-delete-my-less-wrong-account%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20can%20I%20delete%20my%20less%20wrong%20account%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfeLeAhkmxaqtsxBM%2Fhow-can-i-delete-my-less-wrong-account", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDfeLeAhkmxaqtsxBM%2Fhow-can-i-delete-my-less-wrong-account", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 64, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Where can I get my less wrong account deleted?</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">No, the 'delete account' function doesn't work, and I am not posting from the account I want to have deleted as I don't want the name to stay in the google cache for another couple of months</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">I already asked that question&nbsp;<span style=\"font-family: Verdana, Arial, Helvetica, sans-serif; line-height: normal;\"><a href=\"/lw/51z/singularity_institute_featured_on_philanthroper/3t3h\">here</a>; I got no reaction that gets me further but were upvoted enough to post here.</span></p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DfeLeAhkmxaqtsxBM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 6, "extendedScore": null, "score": 1.3e-05, "legacy": true, "legacyId": "6626", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T17:16:05.819Z", "modifiedAt": null, "url": null, "title": "Details of Taskforces; or, Cooperate Now", "slug": "details-of-taskforces-or-cooperate-now", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.264Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2ypea6pY9NbxK8Mav/details-of-taskforces-or-cooperate-now", "pageUrlRelative": "/posts/2ypea6pY9NbxK8Mav/details-of-taskforces-or-cooperate-now", "linkUrl": "https://www.lesswrong.com/posts/2ypea6pY9NbxK8Mav/details-of-taskforces-or-cooperate-now", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Details%20of%20Taskforces%3B%20or%2C%20Cooperate%20Now&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADetails%20of%20Taskforces%3B%20or%2C%20Cooperate%20Now%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2ypea6pY9NbxK8Mav%2Fdetails-of-taskforces-or-cooperate-now%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Details%20of%20Taskforces%3B%20or%2C%20Cooperate%20Now%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2ypea6pY9NbxK8Mav%2Fdetails-of-taskforces-or-cooperate-now", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2ypea6pY9NbxK8Mav%2Fdetails-of-taskforces-or-cooperate-now", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2141, "htmlBody": "<p>Recently I've spent a lot of time thinking about what exactly I should be doing with my life. I'm lucky enough to be in an environment where I can occasionally have productive conversations about the question with smart peers, but I suspect I would think much faster if I spent more of my time with a community grappling with the same issues. Moreover, I expect I could be more productive if I spent time with others trying to get similar things done, not to mention the benefits of explicit collaboration.<br /><br />I would like to organize a nonstandard sort of meetup: regular gatherings with people who are dealing with the question \"How do I do the most good in the world?\" focused explicitly on answering the question and acting on the answer. If I could find a group with which I am socially compatible, I might spend a large part of my time working with them. I am going to use the term \"taskforce\" because I don't know of a better one. It is vaguely related to but quite different from the potential taskforces <a href=\"/lw/5v/church_vs_taskforce/\">Eliezer discusses</a>.<br /><br />Starting such a taskforce requires making many decisions.<br /><br /><strong>Size:<br /></strong><br />I believe that even two people who think through issues together and hold each other accountable are significantly more effective than two people working independently. At the other limit, eventually the addition of individuals doesn't increase the effectiveness of the group and increases coordination costs. Based on a purely intuitive feeling for group dynamics, I would feel most comfortable with a group of 5-6 until I knew of a better scheme for productively organizing large groups of rationalists (at which point I would want to grow as large as that scheme could support). I suspect in practice there will be huge constraints based on interest and commitment; I don't think this is a terminal problem, because there are probably significant gains even for 2-4 people, and I don't think its a permanent one, because I am optimistic about our ability as a community to grow rapidly. <br /><br /><strong>Frequency: <br /></strong><br />Where I am right now in life, I believe that thinking about this question and gathering relevant evidence is the most important thing for me to be doing. I would be comfortable spending several hours several times a week working with a group I got along with. Due to scheduling issues and interest limitations, I think this means that I would like to invest as much time as schedules and interests allow. I think the best plan is to allow and expect self-modification: make the choice of time-commitment an explicit decision controlled by the group. Meeting once a week seems like a fair default which can be supported by most schedules.<br /><br /><strong>Concreteness:<br /></strong><br />There are three levels of concreteness I can imagine for the initial goals of a taskforce:</p>\n<ul>\n<li>The taskforce is created with a particular project or a small collection of possible projects in mind. Although the possibility of abandoning a project is available (like all other changes), having a strong concrete focus may help a great deal with maintaining initial enthusiasm, attracting people, and fostering a sense of having a real effect on the world rather than empty theorizing. The risk is that, while I suspect many of us have many good ideas, deciding what projects are best is really an important part of why I care about interacting with other people. Just starting something may be the quickest way to get a sense of what is most important, but it may also slow progress down significantly.</li>\n<li>The taskforce is created with the goal of converging to a practical project quickly. The discussion is of the form \"How should we be doing the most good <em>right now</em>: what project are we equipped to solve given our current resources?\" While not quite as focused as the first possibility, it does at least keep the conversation grounded. </li>\n<li>The taskforce is created with the most open-ended possible goal. Helping its members decide how to spend their time in the coming years is just as important as coming up with a project to work on next week. A particular project is adopted only if the value of that project exceeds the value of further deliberation, or if working on a project is a good way to gather evidence or develop important skills.</li>\n</ul>\n<p>I am inclined towards the most abstract level if it is possible to get enough support, since it is always capable of descending to either of the others. I think the most important question is how much confidence you have in a group of rationalists to understand the effectiveness of their own collective behavior and modify appropriately. I have a great deal, especially when the same group meets repeatedly and individuals have time to think carefully in between meetings. <br /><br /><strong>Metaness:<br /></strong><br />A group may spend a long time discussing efficient structures for organizing, communicating, gathering information, making decisions, etc. Alternatively, a group may avoid these issues in favor of actually doing things--even if by doing things we only mean discussing the issues the group was created to discuss. Most groups I have been a part of have very much tried to do things instead of refining their own processes.<br /><br />My best plan is to begin by working on non-meta issues. However, the ability of groups of rationalists to efficiently deliberate is an important one to develop, so it is worth paying a lot of attention to anything that reduces effectiveness. In particular, I would support very long digressions to deal with very minor problems as long as they are actually problems. Our experiences can be shared, any question answered definitively remains answered definitively, and any evidence gathered is there for anyone else who wants to see it. A procedural digression should end when it is no longer the best use of time--not because of a desire to keep getting things done for the sake of getting things done. Improving our rationality as individuals should be treated similarly; I am no longer interested in setting out to improve my rationality for the sake of becoming more rational, but I <em>am</em> interested in looking very carefully for failures of rationality that actually impact my effectiveness.<br /><br />I can see how this approach might be dangerous; but it has the great advantage of being able to rescue itself from failure, by correctly noticing that entertaining procedural digressions is counter-productive. In some sense this is universally true: a system which does not limit self-examination can at least in principle recover from arbitrary failures. Moreover, it offers the prospect of refining the rationality of the group, which in turn improves the group's ability to select and implement efficient structures, which closes a feedback loop whose limit may be an unusually effective group.<br /><br /><strong>Homogeneity:<br /></strong><br />A homogeneous taskforce is composed of members who face similar questions in their own lives, and who are more likely to agree about which issues require discussion and which projects they could work profitably on. An inhomogeneous taskforce is composed of members with a greater variety of perspectives, who are more likely to be able have complementary information and to avoid failures. In general, I believe that working for the common good involves enough questions of general importance (ie, of importance to people in very different positions) that the benefits of inhomogeneity seem greater than the costs.&nbsp; <br /><br />In practice, this issue is probably forced for now. Whoever is interested enough to participate will participate (and should be encouraged to participate), until there is enough interest that groups can form selectively.<br /><br /><strong>Atmosphere:<br /></strong><br />In principle the atmosphere of a community is difficult to control. But the content of discussion and structure of expectations prior to the first meeting have a significant effect on the atmosphere. Intuitively, I expect there is a significant risk of a group falling apart immediately for a variety of reasons: social incompatibility, apparent uselessness, inability to maintain initial enthusiasm based on unrealistic expectations, etc. Forcing even a tiny commmunity into existence is hard (though I suspect not impossible). <br /><br />I think the most important part of the atmosphere of a community is its support for criticism, and willingness to submit beliefs to criticism. There is a sense (articulated by Orson Scott Card somewhere at some point) that you maintain status by never showing your full hand; by never admitting \"That's it. That's all I have. Now you can help me decide whether I am right or wrong.\" This attitude is very dangerous coupled with normal status-seeking, because its not clear to me that it is possible to recover from it. I don't believe that having rational members is enough to avoid this failure.<br /><br />I don't have any other observations, except that factors controlling atmosphere should be noted when trying to understand the effectiveness of particular efforts to start communities of any sort, even though such factors are difficult to measure or describe.<br /><br /><strong>Finding People:<br /></strong><br />The internet is a good place to find people, but there is only a weak sense of personal responsibility throughout much of it, and committing to dealing with people you don't know well is hard/unwise. The real world is a much harder place to find people, but conversations in person quickly establish a sense of personal responsibility and can be used to easily estimate social compatibility. Most people are strangers, and the set of people who could possibly be convinced to work with a taskforce is extremely sparse. On the other hand, your chances of convincing an acquaintance to engage in an involved project with you seem to be way higher. <br /><br />My hope is that LW is large enough, and unusual enough, that it may be possible to start something just by exchanging cheap talk here. At least, I think this is possible and therefore worth acting on, since alternative states of the world will require more time to get something like this rolling. Another approach is to use the internet to orchestrate low-key meetings, and then bootstrap up from modest personal engagement to something more involved. Another is to try and use the internet to develop a community which can better support/encourage the desired behavior. Of course there are approaches that don't go through the internet, but those approaches will be much more difficult and I would like to explore easy possibilities first.<br /><br /><strong>Recovery from Failure:<br /></strong><br />I can basically guarantee that if anything comes of my desire, it will include at least one failure. The real cost of failure is extremely small. My fear, based on experience, is that every time an effort at social organization fails it significantly decreases enthusiasm for similar efforts in the future. My only response to this fear is: don't be too optimistic, and don't be too pessimistic. Don't stake too much of your hope on the next try, but don't assume the next try will fail just because the last one did. In short: be rational.</p>\n<p><br /><strong>Conclusion:<br /></strong><br />There are more logistical issues, many reasons a taskforce might fail, and many reasons it might not be worth the effort. But I believe I can do much more good in the future than I have done in the past, and that part of that will involve more effectively exploiting the fact that I am not alone as a rationalist. Even if the only conclusion of a taskforce is to disband itself, I would like to give it a shot.</p>\n<p>As groups succeed or fail, different answers to these questions can be tested. My initial impulse in favor of starting abstractly and self-modifying towards concreteness can be replaced by emulating the success of other groups. Of course, this is an optimistic vision: for now, I am focused on getting one group to work once.</p>\n<p>I welcome thoughts on other high-level issues, criticism of my beliefs,&nbsp; or (optimistically) discussions/prioritization of particular logistical issues. But right now I would mostly like to gauge interest. What arguments could convince you that such a taskforce would be useful / what uncertainties would have to be resolved? What arguments could convince you to participate? Under what conditions would you be likely to participate? Where do you live?<br /><br />I am in Cambridge, am willing to travel anywhere in the Boston area, need no additional arguments to convince me that such a taskforce would be useful, and would participate in any group I thought had a reasonable chance of moderate success.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2ypea6pY9NbxK8Mav", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 22, "extendedScore": null, "score": 6.98675465156862e-07, "legacy": true, "legacyId": "6625", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["p5DmraxDmhvMoZx8J"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T17:38:22.998Z", "modifiedAt": null, "url": null, "title": "Science Fiction Recommendations", "slug": "science-fiction-recommendations", "viewCount": null, "lastCommentedAt": "2017-06-17T04:02:33.315Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KDsMB4Zhcu8qfWjry/science-fiction-recommendations", "pageUrlRelative": "/posts/KDsMB4Zhcu8qfWjry/science-fiction-recommendations", "linkUrl": "https://www.lesswrong.com/posts/KDsMB4Zhcu8qfWjry/science-fiction-recommendations", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Science%20Fiction%20Recommendations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AScience%20Fiction%20Recommendations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDsMB4Zhcu8qfWjry%2Fscience-fiction-recommendations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Science%20Fiction%20Recommendations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDsMB4Zhcu8qfWjry%2Fscience-fiction-recommendations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKDsMB4Zhcu8qfWjry%2Fscience-fiction-recommendations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 101, "htmlBody": "<p>I have never read very much Science Fiction, unlike some of the people here on Less Wrong, and I think I would like to. At least, the few books I have read I enjoyed. I've read a couple of books from Asimov's Foundation Series, two Michael Crichton books, Twenty Thousand Leagues Under the Sea by Jules Verne, and an anthology of SciFi short stories (no really famous authors) that my dad owned.</p>\n<p>That list looks very short. I just finished reading a fiction book, and am looking to start another. Recommendations? What are the two or three books I simply must read?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KDsMB4Zhcu8qfWjry", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 16, "extendedScore": null, "score": 3e-05, "legacy": true, "legacyId": "6627", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-05T23:40:09.093Z", "modifiedAt": null, "url": null, "title": "Problem noticed in aspect of LW comunity bonding?", "slug": "problem-noticed-in-aspect-of-lw-comunity-bonding", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:36.789Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pqDAFjJiP4LP5ZLMh/problem-noticed-in-aspect-of-lw-comunity-bonding", "pageUrlRelative": "/posts/pqDAFjJiP4LP5ZLMh/problem-noticed-in-aspect-of-lw-comunity-bonding", "linkUrl": "https://www.lesswrong.com/posts/pqDAFjJiP4LP5ZLMh/problem-noticed-in-aspect-of-lw-comunity-bonding", "postedAtFormatted": "Tuesday, April 5th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Problem%20noticed%20in%20aspect%20of%20LW%20comunity%20bonding%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProblem%20noticed%20in%20aspect%20of%20LW%20comunity%20bonding%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqDAFjJiP4LP5ZLMh%2Fproblem-noticed-in-aspect-of-lw-comunity-bonding%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Problem%20noticed%20in%20aspect%20of%20LW%20comunity%20bonding%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqDAFjJiP4LP5ZLMh%2Fproblem-noticed-in-aspect-of-lw-comunity-bonding", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpqDAFjJiP4LP5ZLMh%2Fproblem-noticed-in-aspect-of-lw-comunity-bonding", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 259, "htmlBody": "<p>&nbsp;</p>\n<p>I have noticed that given how much I identify as a rationalist, how much I have in common with the community here, how important I consider it, etc. I have surprisingly little instant in group identification with community members compared to other online communities. There seem to be an aspect of social involvement that LW does bad at. And there is one thing lacking that to me seems the obvious first suspect; the lack of of-topic unstructured chatter.</p>\n<p>What I do when I feel that I identify with some continuity online is in fact not usually the thing the community is ABOUT. Instead, it's the things that grow out of the sides; forum games, members art projects, photo share threads, fanworks. I can speculate on why this happens this is so, but it dosn't seem very useful at the moment, I'm not highly confident on any specific theory, and most will probably find it fairly obvious anyway.</p>\n<p>LW, however, has no real room for this. Even in the discussion section, things that are not reasonably on topic will be punished with negative karma. Now, this is obviously needed, but one must still recognize there IS a prise to being so structured and focused on a single goal when humans naturally tend not to be. Look for third options.</p>\n<p>Now, I have a specific solution in mind, but I'm going to hold of on proposing it and see if you come up with something better before I post my idea.</p>\n<p>&nbsp;</p>\n<p>EDIT: My suggestion has now been added in the comments, please check it out.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pqDAFjJiP4LP5ZLMh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 25, "extendedScore": null, "score": 6.987824559931274e-07, "legacy": true, "legacyId": "6628", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 37, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T00:56:48.785Z", "modifiedAt": null, "url": null, "title": "What Should I Do?", "slug": "what-should-i-do", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:20.690Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4Mfrr5mhRw2KpYE7b/what-should-i-do", "pageUrlRelative": "/posts/4Mfrr5mhRw2KpYE7b/what-should-i-do", "linkUrl": "https://www.lesswrong.com/posts/4Mfrr5mhRw2KpYE7b/what-should-i-do", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20Should%20I%20Do%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20Should%20I%20Do%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Mfrr5mhRw2KpYE7b%2Fwhat-should-i-do%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20Should%20I%20Do%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Mfrr5mhRw2KpYE7b%2Fwhat-should-i-do", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4Mfrr5mhRw2KpYE7b%2Fwhat-should-i-do", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 417, "htmlBody": "<p>I have been having some difficulty deciding what to do with my life. I'm not really ashamed or surprised, because the problem seems extremely difficult and worth getting right. I still don't really know. Here are some of my options, though I wouldn't be surprised if what I end up doing is not on the list. I thought I would share to elicit advice, to give some context to some of my <a href=\"/lw/541/details_of_taskforces_or_cooperate_now/\">recent remarks</a>, and maybe to provide comparison for people in similar situations.</p>\n<p><strong>1. Research</strong></p>\n<p>I could do research in a university, or in a private research lab. Many fields have at least a few questions that seem important and interesting.</p>\n<p><em>A. Theoretical Computer Science</em>. I could work on collaborative learning, recommendation and reputation systems, distributed protocols, or anything else that might assist collaboration in the future.&nbsp;</p>\n<p><em>B. AI / Computational Cognitive Neuroscience</em>. I could work on algorithms for inference and planning, to increase the probability that we develop comprehensible or human-like AI before something horrible happens (like developing incomprehensible strong AI).</p>\n<p><em>C. Neuroscience</em>. I know almost nothing about this field, but technology for measuring and interfacing with the brain appears to be important and developing rapidly. I don't know how hard it would be to start working in the field, but I suspect that the connection to computer science is strong enough at MIT that it wouldn't be impossible.</p>\n<p><strong>2. Start a company</strong></p>\n<p>This seems way harder, but I am sufficiently arrogant and risk-neutral that I consider it a reasonable option. In particular, this is what I would do if I decided that making money as efficiently as possible and giving it away</p>\n<p><em>A. Tech company.</em> If I had to guess based on the currently available evidence, I would guess that this is the way to maximize my expected earnings.</p>\n<p><em>B. Online Education.</em> I would like to take a shot at designing materials for online education of smart, significantly underserved, high school students.</p>\n<p><strong>3. Cooperate with Other Rationalists</strong></p>\n<p><em>A. Work for a rational charity</em>. Self-explanatory. Probably worse than earning a lot of money and giving away.</p>\n<p><em>B. Start a rational charity</em>. Probably worse than supporting an existing charity.</p>\n<p><em>C. Work for a rational start-up</em>. Can't really arrange this one; but optimistically it could happen if you were prepared (someone else does 2).</p>\n<p><strong>4. Be a Hobbyist</strong></p>\n<p>I could also simply try and earn a living as quickly as possible (rather than making as much excess as possible, or having a more structured way of doing good) and do work on the side. I don't think this is a good idea.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4Mfrr5mhRw2KpYE7b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 6.988038160107542e-07, "legacy": true, "legacyId": "6630", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I have been having some difficulty deciding what to do with my life. I'm not really ashamed or surprised, because the problem seems extremely difficult and worth getting right. I still don't really know. Here are some of my options, though I wouldn't be surprised if what I end up doing is not on the list. I thought I would share to elicit advice, to give some context to some of my <a href=\"/lw/541/details_of_taskforces_or_cooperate_now/\">recent remarks</a>, and maybe to provide comparison for people in similar situations.</p>\n<p><strong id=\"1__Research\">1. Research</strong></p>\n<p>I could do research in a university, or in a private research lab. Many fields have at least a few questions that seem important and interesting.</p>\n<p><em>A. Theoretical Computer Science</em>. I could work on collaborative learning, recommendation and reputation systems, distributed protocols, or anything else that might assist collaboration in the future.&nbsp;</p>\n<p><em>B. AI / Computational Cognitive Neuroscience</em>. I could work on algorithms for inference and planning, to increase the probability that we develop comprehensible or human-like AI before something horrible happens (like developing incomprehensible strong AI).</p>\n<p><em>C. Neuroscience</em>. I know almost nothing about this field, but technology for measuring and interfacing with the brain appears to be important and developing rapidly. I don't know how hard it would be to start working in the field, but I suspect that the connection to computer science is strong enough at MIT that it wouldn't be impossible.</p>\n<p><strong id=\"2__Start_a_company\">2. Start a company</strong></p>\n<p>This seems way harder, but I am sufficiently arrogant and risk-neutral that I consider it a reasonable option. In particular, this is what I would do if I decided that making money as efficiently as possible and giving it away</p>\n<p><em>A. Tech company.</em> If I had to guess based on the currently available evidence, I would guess that this is the way to maximize my expected earnings.</p>\n<p><em>B. Online Education.</em> I would like to take a shot at designing materials for online education of smart, significantly underserved, high school students.</p>\n<p><strong id=\"3__Cooperate_with_Other_Rationalists\">3. Cooperate with Other Rationalists</strong></p>\n<p><em>A. Work for a rational charity</em>. Self-explanatory. Probably worse than earning a lot of money and giving away.</p>\n<p><em>B. Start a rational charity</em>. Probably worse than supporting an existing charity.</p>\n<p><em>C. Work for a rational start-up</em>. Can't really arrange this one; but optimistically it could happen if you were prepared (someone else does 2).</p>\n<p><strong id=\"4__Be_a_Hobbyist\">4. Be a Hobbyist</strong></p>\n<p>I could also simply try and earn a living as quickly as possible (rather than making as much excess as possible, or having a more structured way of doing good) and do work on the side. I don't think this is a good idea.</p>", "sections": [{"title": "1. Research", "anchor": "1__Research", "level": 1}, {"title": "2. Start a company", "anchor": "2__Start_a_company", "level": 1}, {"title": "3. Cooperate with Other Rationalists", "anchor": "3__Cooperate_with_Other_Rationalists", "level": 1}, {"title": "4. Be a Hobbyist", "anchor": "4__Be_a_Hobbyist", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "31 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["2ypea6pY9NbxK8Mav"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T04:43:52.962Z", "modifiedAt": null, "url": null, "title": "April 10 2011 Southern California Meetup", "slug": "april-10-2011-southern-california-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.704Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/F6BwMcCHhn9o26CjX/april-10-2011-southern-california-meetup", "pageUrlRelative": "/posts/F6BwMcCHhn9o26CjX/april-10-2011-southern-california-meetup", "linkUrl": "https://www.lesswrong.com/posts/F6BwMcCHhn9o26CjX/april-10-2011-southern-california-meetup", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20April%2010%202011%20Southern%20California%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AApril%2010%202011%20Southern%20California%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF6BwMcCHhn9o26CjX%2Fapril-10-2011-southern-california-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=April%2010%202011%20Southern%20California%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF6BwMcCHhn9o26CjX%2Fapril-10-2011-southern-california-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FF6BwMcCHhn9o26CjX%2Fapril-10-2011-southern-california-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 145, "htmlBody": "<p><a id=\"more\"></a>There will be a LessWrong meetup for <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong_meetup_groups#Southern_California\">Southern California</a> on Sunday April 10th from 2:00PM to 8:00PM and we will probably linger later. Feel free to come for all or part of the time.&nbsp; The location is being kindly provided by the Harvey Mudd <a href=\"http://www.hmc.edu/studentlife1/activities1/studentorgs1/futuretech.html\">A.I. &amp; Future Technology Club</a> in the <a title=\"google map to location on campus\" href=\"http://maps.google.com/maps?q=Platt+Campus+Center&amp;hl=en&amp;cd=1&amp;sll=34.106401,-117.709799&amp;sspn=0.071946,0.071946&amp;ie=UTF8&amp;view=map&amp;hnear=&amp;ll=34.101215,-117.702198&amp;spn=0.028926,0.084543&amp;z=14\">Platt Campus Center</a> of Harvey Mudd College.</p>\n<p>For travel planning purposes, the meetup is happening about 10 blocks north of the <a title=\"nearest train station\" href=\"http://www.metrolinktrains.com/stations/detail.php?id=90&amp;line=sb\">Claremont Metrolink Station</a>, which connects to the hub at LA Union Station.&nbsp; Train schedules can be searched <a title=\"google train search\" href=\"http://maps.google.com/maps?f=d&amp;source=s_d&amp;saddr=&amp;daddr=Harvey+Mudd+College,+Claremont,+CA&amp;hl=en&amp;geocode=&amp;mra=ls&amp;dirflg=r&amp;ttype=dep&amp;date=09%2F25%2F10&amp;time=1:00pm&amp;noexp=0&amp;noal=0&amp;sort=&amp;sll=34.100505,-117.712369&amp;sspn=0.01457,0.031414&amp;ie=UTF8&amp;ll=34.100434,-117.711339&amp;spn=0.01457,0.031414&amp;z=15&amp;start=0\">here</a>.&nbsp; Also there should be car pooling opportunities in the comments.</p>\n<p>As more meetups have happened attendance has been increasing.&nbsp; If you want to make sure to see future announcements so you don't miss a meetup, you can sign up for the <a href=\"http://groups.google.com/group/LW-SoCal-Announce\">mailing list</a>.</p>\n<p>See you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "F6BwMcCHhn9o26CjX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 8, "extendedScore": null, "score": 6.988670905310286e-07, "legacy": true, "legacyId": "6637", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T05:29:37.492Z", "modifiedAt": null, "url": null, "title": "Comic endorsing Bayesian statistics", "slug": "comic-endorsing-bayesian-statistics", "viewCount": null, "lastCommentedAt": "2017-06-17T04:21:03.310Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "grouchymusicologist", "createdAt": "2009-03-20T04:17:27.196Z", "isAdmin": false, "displayName": "grouchymusicologist"}, "userId": "KYP2e7SEoKnM8ddjr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CBk75dggRyHehc9Qt/comic-endorsing-bayesian-statistics", "pageUrlRelative": "/posts/CBk75dggRyHehc9Qt/comic-endorsing-bayesian-statistics", "linkUrl": "https://www.lesswrong.com/posts/CBk75dggRyHehc9Qt/comic-endorsing-bayesian-statistics", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Comic%20endorsing%20Bayesian%20statistics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComic%20endorsing%20Bayesian%20statistics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCBk75dggRyHehc9Qt%2Fcomic-endorsing-bayesian-statistics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Comic%20endorsing%20Bayesian%20statistics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCBk75dggRyHehc9Qt%2Fcomic-endorsing-bayesian-statistics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCBk75dggRyHehc9Qt%2Fcomic-endorsing-bayesian-statistics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 15, "htmlBody": "<p>Well, that might be editorializing on my part, but <a href=\"http://xkcd.com/882/\">you'll see what I mean</a> ...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CBk75dggRyHehc9Qt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 6.988798381487316e-07, "legacy": true, "legacyId": "6638", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T15:13:20.053Z", "modifiedAt": null, "url": null, "title": "First Waco, Texas LW Meetup, 4/09, 1PM", "slug": "first-waco-texas-lw-meetup-4-09-1pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:58.909Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/SwJY7CjsS5NdatqsZ/first-waco-texas-lw-meetup-4-09-1pm", "pageUrlRelative": "/posts/SwJY7CjsS5NdatqsZ/first-waco-texas-lw-meetup-4-09-1pm", "linkUrl": "https://www.lesswrong.com/posts/SwJY7CjsS5NdatqsZ/first-waco-texas-lw-meetup-4-09-1pm", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%20Waco%2C%20Texas%20LW%20Meetup%2C%204%2F09%2C%201PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%20Waco%2C%20Texas%20LW%20Meetup%2C%204%2F09%2C%201PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSwJY7CjsS5NdatqsZ%2Ffirst-waco-texas-lw-meetup-4-09-1pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%20Waco%2C%20Texas%20LW%20Meetup%2C%204%2F09%2C%201PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSwJY7CjsS5NdatqsZ%2Ffirst-waco-texas-lw-meetup-4-09-1pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FSwJY7CjsS5NdatqsZ%2Ffirst-waco-texas-lw-meetup-4-09-1pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 288, "htmlBody": "<p><a id=\"more\"></a>Date: Saturday, April 9</p>\n<p>Time: 1PM</p>\n<p>Location: <a href=\"http://www.commongroundswaco.com/\">Common Grounds</a>&nbsp;Coffeehouse, <a href=\"http://maps.google.com/maps/place?hl=en&amp;safe=images&amp;um=1&amp;ie=UTF-8&amp;q=waco,tx+common+grounds&amp;fb=1&amp;gl=us&amp;hq=common+grounds&amp;hnear=Waco,+TX&amp;cid=8160807412985378584\">IH-35 and&nbsp;S 8th Street</a>&nbsp;(east side of interstate).&nbsp; (If you can't find parking behind the place, use the parking garage [<strong>free on weekends</strong>] just a short distance down the street.)</p>\n<p>Well, I'm going through with it!&nbsp; We'll have our first Texas LW meetup.&nbsp; No other known Waco LWers, but it's not a bad drive (~90 minutes) from Austin, Dallas/Fort Worth, or Bryan/College Station.</p>\n<p>I will be the guy in the blue blazer with a Less Wrong sign.&nbsp; I have no idea what the turnout will be, but I'll stay until at least 5pm, so come on by if you can.</p>\n<p><del>The website reports an all-day 100 Cameras event, but this shouldn't interfere.</del></p>\n<p><strong>Edit:</strong> Looks like that was an old notice for the Saturday two weeks before this, so there is no interfering event to worry about.</p>\n<p><strong>Edit2: </strong>I've set up the <a href=\"http://www.meetup.com/Waco-LessWrong-Rationalist-Group/\">Waco Meetup Group</a> with this event shown.&nbsp; (And promoted it on Craigslist.)</p>\n<p><strong>REPORT: </strong>Success!&nbsp; Vaniver, NMJablonski, his wife, Clippy's humanoid robot, and I showed up.&nbsp; We talked about various rationality issues: the potential for the upcoming boot camp, the heritability of personality traits and intelligence, the inefficiencies and lost purposes in the economy today, and of course, string theory.&nbsp; At the end, we helped Clippy decide whether he should go to Rationalist Boot Camp (if he's accepted) by doing a probability-weighted CBA, which Vaniver helped coordinate very well.</p>\n<p><a href=\"http://i35.photobucket.com/albums/d187/SilasX/WacoMeetup.jpg\">Here</a> is a picture of us at the meetup: from left to right: Vaniver, me, Laura (NMJablonski's wife), and NMJablonski. Clippy's robot did not want to be in it.&nbsp; (I tried to upload it to this site, but even after resizing it down to the limit it wouldn't accept.)</p>\n<p>We're planning to have another Texas meetup in Austin in two weeks.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "SwJY7CjsS5NdatqsZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 22, "extendedScore": null, "score": 6.99042544879435e-07, "legacy": true, "legacyId": "6645", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 56, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T16:20:21.315Z", "modifiedAt": null, "url": null, "title": "Ottawa LW Meetup Saturday April 16th", "slug": "ottawa-lw-meetup-saturday-april-16th", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:09.338Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Cyan", "createdAt": "2009-02-27T22:31:08.528Z", "isAdmin": false, "displayName": "Cyan"}, "userId": "eGtDNuhj58ehX9Wgf", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Ts8dmEJRgCMu8C5cr/ottawa-lw-meetup-saturday-april-16th", "pageUrlRelative": "/posts/Ts8dmEJRgCMu8C5cr/ottawa-lw-meetup-saturday-april-16th", "linkUrl": "https://www.lesswrong.com/posts/Ts8dmEJRgCMu8C5cr/ottawa-lw-meetup-saturday-april-16th", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ottawa%20LW%20Meetup%20Saturday%20April%2016th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOttawa%20LW%20Meetup%20Saturday%20April%2016th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTs8dmEJRgCMu8C5cr%2Fottawa-lw-meetup-saturday-april-16th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ottawa%20LW%20Meetup%20Saturday%20April%2016th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTs8dmEJRgCMu8C5cr%2Fottawa-lw-meetup-saturday-april-16th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTs8dmEJRgCMu8C5cr%2Fottawa-lw-meetup-saturday-april-16th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 224, "htmlBody": "<p><a id=\"more\"></a></p>\n<p>My trip to New York City provided the spur I needed to get the LW Ottawa<sup>1</sup> Chapter off the ground. My&nbsp;aspiration for the group&nbsp;is to provide a social milieu for improving thought patterns/processes and&nbsp;for&nbsp;providing feedback on&nbsp;setting goals, planning tactics and strategies,&nbsp;and&nbsp;tracking progress. I also&nbsp;intend to incorporate&nbsp;random fun -- while I was in NYC,&nbsp;a stunt class event was pre-empted by the 6th Annual NYC Pillow Fight Day, and how awesome is that?</p>\n<p>Location:&nbsp;349 Preston St. The meeting will be held in a small sitting area to the right of the security station in the lobby. The lobby is reachable&nbsp;through the Starbucks.</p>\n<p>Time: Saturday, April 16th, 1:00pm. I commit to being there until <del>3:00pm</del> 4:00pm.</p>\n<p><sup>1</sup> That's Ottawa, Ontario, Canada.&nbsp;My apologies to any Ottawans&nbsp;located&nbsp;in Ohio, Illinois, Wisconsin, and/or Kansas.</p>\n<p>Update:&nbsp;I'm really pleased with how our first meeting went. XFrequentist, Swimmer963, wiresnips, wmiles, and I attended (wmiles was a late arrival due to previous plans). We introduced ourselves and then did an impromptu goal-setting/mutual help exercise in which we described (i) our skills and abilities and (ii) our aspirations and goals. Then we went around the table to see what resources we had to help each other, with an eye to crossing out the easy stuff so we can focus on the tough stuff. We actually didn't finish before I had to go, so we'll take it up again next time.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Ts8dmEJRgCMu8C5cr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 12, "extendedScore": null, "score": 6.990609567778847e-07, "legacy": true, "legacyId": "6646", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T17:14:54.975Z", "modifiedAt": null, "url": null, "title": "Edinburgh Lesswrong meetup", "slug": "edinburgh-lesswrong-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:18.986Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Elias_Kunnas", "createdAt": "2010-06-01T14:05:45.901Z", "isAdmin": false, "displayName": "Elias_Kunnas"}, "userId": "mwGJBaWGMHZKzvnSd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/K6XCGffR5hvvXLXuL/edinburgh-lesswrong-meetup", "pageUrlRelative": "/posts/K6XCGffR5hvvXLXuL/edinburgh-lesswrong-meetup", "linkUrl": "https://www.lesswrong.com/posts/K6XCGffR5hvvXLXuL/edinburgh-lesswrong-meetup", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Edinburgh%20Lesswrong%20meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEdinburgh%20Lesswrong%20meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK6XCGffR5hvvXLXuL%2Fedinburgh-lesswrong-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Edinburgh%20Lesswrong%20meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK6XCGffR5hvvXLXuL%2Fedinburgh-lesswrong-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FK6XCGffR5hvvXLXuL%2Fedinburgh-lesswrong-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 73, "htmlBody": "<p><a href=\"/lw/43s/starting_a_lw_meetup_is_easy/\">According to statistics</a>, Edinburgh has a reasonable number of LW readers.&nbsp;Currently no Edinburgh meetups exist for Less Wrong so we might as well arbitrarily set one in the near future and see if it could work out (if there are enough people who are interested in a meetup here).</p>\n<p>Date/time: Saturday 16th of April at 2:00pm.</p>\n<p>Place: A pub called the&nbsp;<a href=\"http://maps.google.co.uk/maps?channel=cs&amp;ie=UTF8&amp;q=auld+hoose&amp;fb=1&amp;gl=uk&amp;hq=auld+hoose&amp;hnear=Edinburgh&amp;cid=0,0,13163354907392914601&amp;t=h&amp;z=15&amp;iwloc=A\">Auld Hoose</a>.</p>\n<p>I would be holding a sign with \"Less Wrong\" written on it.</p>\n<p>EDIT: definite time/place.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "K6XCGffR5hvvXLXuL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 2, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "6647", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T18:00:22.669Z", "modifiedAt": null, "url": null, "title": "Edinburgh LW Meetup Saturday April 16th", "slug": "edinburgh-lw-meetup-saturday-april-16th", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:33.023Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "sark", "createdAt": "2010-01-20T20:18:10.889Z", "isAdmin": false, "displayName": "sark"}, "userId": "cJYNhyCitpdzsZqeP", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kLPbwwpJeQHphGr8a/edinburgh-lw-meetup-saturday-april-16th", "pageUrlRelative": "/posts/kLPbwwpJeQHphGr8a/edinburgh-lw-meetup-saturday-april-16th", "linkUrl": "https://www.lesswrong.com/posts/kLPbwwpJeQHphGr8a/edinburgh-lw-meetup-saturday-april-16th", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Edinburgh%20LW%20Meetup%20Saturday%20April%2016th&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEdinburgh%20LW%20Meetup%20Saturday%20April%2016th%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkLPbwwpJeQHphGr8a%2Fedinburgh-lw-meetup-saturday-april-16th%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Edinburgh%20LW%20Meetup%20Saturday%20April%2016th%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkLPbwwpJeQHphGr8a%2Fedinburgh-lw-meetup-saturday-april-16th", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkLPbwwpJeQHphGr8a%2Fedinburgh-lw-meetup-saturday-april-16th", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 82, "htmlBody": "<p><a href=\"/lw/43s/starting_a_lw_meetup_is_easy/\"><a id=\"more\"></a>According to statistics</a>, Edinburgh has a reasonable number of LW readers.&nbsp;Currently no Edinburgh meetups exist for Less Wrong so we might as well arbitrarily set one in the near future and see if it could work out (if there are enough people who are interested in a meetup here).</p>\n<p>Date/time: Saturday 16th of April at 2:00pm.</p>\n<p>Place: A pub called the&nbsp;<a href=\"http://maps.google.co.uk/maps?channel=cs&amp;ie=UTF8&amp;q=auld+hoose&amp;fb=1&amp;gl=uk&amp;hq=auld+hoose&amp;hnear=Edinburgh&amp;cid=0,0,13163354907392914601&amp;t=h&amp;z=15&amp;iwloc=A\">Auld Hoose</a>.</p>\n<p>I would be holding a sign with \"Less Wrong\" written on it.</p>\n<p>EDIT: definite time/place.</p>\n<p>EDIT2: moved to main site (and changed article author :p)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kLPbwwpJeQHphGr8a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 11, "extendedScore": null, "score": 6.990891199791379e-07, "legacy": true, "legacyId": "6648", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["d28mWBMrFt8nwpXLp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T19:06:53.526Z", "modifiedAt": null, "url": null, "title": "Cryptanalysis as Epistemology? (paging cryptonerds)", "slug": "cryptanalysis-as-epistemology-paging-cryptonerds", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:34.185Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "SilasBarta", "createdAt": "2009-03-01T00:03:34.864Z", "isAdmin": false, "displayName": "SilasBarta"}, "userId": "zDPSZfarhLM7Gehug", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jZZYAk3P6Xg8YW4Lm/cryptanalysis-as-epistemology-paging-cryptonerds", "pageUrlRelative": "/posts/jZZYAk3P6Xg8YW4Lm/cryptanalysis-as-epistemology-paging-cryptonerds", "linkUrl": "https://www.lesswrong.com/posts/jZZYAk3P6Xg8YW4Lm/cryptanalysis-as-epistemology-paging-cryptonerds", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryptanalysis%20as%20Epistemology%3F%20(paging%20cryptonerds)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryptanalysis%20as%20Epistemology%3F%20(paging%20cryptonerds)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjZZYAk3P6Xg8YW4Lm%2Fcryptanalysis-as-epistemology-paging-cryptonerds%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryptanalysis%20as%20Epistemology%3F%20(paging%20cryptonerds)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjZZYAk3P6Xg8YW4Lm%2Fcryptanalysis-as-epistemology-paging-cryptonerds", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjZZYAk3P6Xg8YW4Lm%2Fcryptanalysis-as-epistemology-paging-cryptonerds", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 137, "htmlBody": "<p><strong>Short version: </strong>Why can't <a href=\"http://en.wikipedia.org/wiki/Cryptanalysis\">cryptanalysis</a> methods be carried over to science, which looks like a trivial problem by comparison, since nature doesn't intelligently remove patterns from our observations?&nbsp; Or are these methods already carried over?</p>\r\n<p><strong>Long version: </strong>Okay, I was going to spell this all out with a lot of text, but it started ballooning, so I'm just going to put it in chart form.</p>\r\n<p>Here is what I see as the <strong>mapping from cryptography to science</strong> (or epistemology in general).&nbsp; I want to know what goes in the \"???\" spot, and why it hasn't been used for any natural phenomenon <em>less </em>complex than the most complex broken cipher.&nbsp; (Sorry, couldn't figure out how to center it.)</p>\r\n<p>&nbsp;<img style=\"vertical-align: baseline;\" src=\"http://images.lesswrong.com/t3_54q_1.png?v=6fa67b61910ef10ec4fe5313432db337\" alt=\"\" width=\"327\" height=\"461\" /></p>\r\n<p><strong>EDIT:</strong> Removed \"(cipher known)\" requirement on 2nd- and 3rd-to-last rows because the scientific analog can be searching for either natural laws or constants.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MhHM6Rx2b4F8tHTQk": 2, "xgpBASEThXPuKRhbS": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jZZYAk3P6Xg8YW4Lm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 17, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "6650", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T20:48:22.143Z", "modifiedAt": null, "url": null, "title": "My favorite philosophers", "slug": "my-favorite-philosophers", "viewCount": null, "lastCommentedAt": "2021-12-19T22:22:53.338Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PMoa6f4aACHfefwBY/my-favorite-philosophers", "pageUrlRelative": "/posts/PMoa6f4aACHfefwBY/my-favorite-philosophers", "linkUrl": "https://www.lesswrong.com/posts/PMoa6f4aACHfefwBY/my-favorite-philosophers", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20My%20favorite%20philosophers&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMy%20favorite%20philosophers%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPMoa6f4aACHfefwBY%2Fmy-favorite-philosophers%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=My%20favorite%20philosophers%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPMoa6f4aACHfefwBY%2Fmy-favorite-philosophers", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPMoa6f4aACHfefwBY%2Fmy-favorite-philosophers", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 566, "htmlBody": "<p>Those interested in philosophy might wonder: Who are the favorite philosophers of someone (like me) who has a <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">very low opinion of philosophy</a>?</p>\n<p>Well, ask no longer. Here are some of <a href=\"http://commonsenseatheism.com/?p=14621\">my favorite philosophers</a>:</p>\n<p>&nbsp;</p>\n<ul>\n<li><strong><a href=\"http://commonsenseatheism.com/?p=13052\">Eliezer Yudkowsky</a></strong> (independent) only does philosophy because he needs to solve philosophical problems to build Friendly AI. As a philosophy outsider, he has managed &ndash; mostly on his own &ndash; to solve a great many philosophical problems correctly. There is, simply put, no philosopher with whom I agree more often. My one major complaint is that he does not write academic-style articles, citing the relevant research and speaking the same language as others and so on. On the other hand, this is partly <em>why</em> he has made so much fast progress. Academic papers are clear and crisp and well-footnoted and thus <em>generous to their readers</em>, but as a result they take a lot of effort to write. If I could fuse the minds of Yudkowsky and Bostrom, that person would be an even better philosopher. Luckily, those two minds seem to be slowly fusing on their own. (Yudkowsky is tugging Bostrom his way, and Bostrom is tugging Yudkowsky <em>his</em> way.)</li>\n<li><strong><a href=\"http://www.nickbostrom.com/\">Nick Bostrom</a></strong> (Oxford) is one of today&rsquo;s most important philosophers. This is not due to Kripkean superintelligence or Einsteinian revolutionary insights &ndash; though, Bostrom is no slouch in intellect or insight &ndash; but because he has devoted himself to working on <em>the most important problems</em>. Oddly enough, these were problems that (at the time) nobody else was working on very seriously: existential risks to humanity.</li>\n<li><strong><a href=\"http://en.wikipedia.org/wiki/Noam_Chomsky\">Noam Chomsky</a></strong> (MIT) is an interdisciplinary genius. The most important linguist of the 20th century, he is also one of the founders of cognitive science, a major geopolitical theorist, a philosopher, and one of the most productive social activists in history. He embodies his philosophy more successfully than any other philosopher I know. Though he holds different philosophical positions than I do, in many ways his views are like mine but with an extra dose of skepticism about everything.</li>\n<li><strong><a href=\"http://www.rci.rutgers.edu/~stich/\">Stephen Stich</a></strong> (Rutgers) is one of the &ldquo;guardians&rdquo; of good philosophy, arguing against unproductive analytic practices like heavy appeal to intuition, and working so vigorously at the border of science and philosophy that he played a founding role in the rise of experimental philosophy. He has also done a great job of mentoring younger philosophers, preparing them to go to war for productive, scientific philosophy in a land where most philosophers are still doing the pre-Quinean kind of philosophy.</li>\n<li><strong><a href=\"http://en.wikipedia.org/wiki/Hilary_Kornblith\">Hilary Kornblith</a></strong> (Massachusetts, Amherst) is a leading proponent of naturalized epistemology. He is also a leading critic of conceptual analysis, and thus another &ldquo;guardian.&rdquo;</li>\n<li><strong><a href=\"http://www.faculty.ucr.edu/~eschwitz/\">Eric Schwitzgebel</a></strong> (UC Riverside) is another guardian of good philosophy, and spends much of his time chastising those philosophers who have way more faith in their powers of intuition and introspection than contemporary cognitive science should allow.</li>\n<li><strong><a href=\"http://philosophy.fsu.edu/People/Faculty/Michael-Bishop\">Michael Bishop</a></strong> (Florida State) is another guardian, and was a student of Stitch. He doesn&rsquo;t just chastise philosophers for continuing to use failed methods, but offers a productive alternative grounded in the latest cognitive science and experimental psychology: what he calls &ldquo;strategic reliabilism.&rdquo; For him, epistemology shouldn&rsquo;t be concerned with a conceptual analysis of knowledge terms, but with getting at true belief. Unfortunately, this isn&rsquo;t yet obvious to most of the rest of his profession.</li>\n</ul>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PMoa6f4aACHfefwBY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 10, "extendedScore": null, "score": 2.4e-05, "legacy": true, "legacyId": "6651", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FwiPfF8Woe5JrzqEu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T22:13:11.024Z", "modifiedAt": null, "url": null, "title": "Interest in video-conference discussion about sequences and/or virtual meetups?", "slug": "interest-in-video-conference-discussion-about-sequences-and", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:21.671Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jwhendy", "createdAt": "2011-01-04T19:53:21.160Z", "isAdmin": false, "displayName": "jwhendy"}, "userId": "ZaJctSZkCvg7qvSEC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/krvQb6uFeYCKXB5Aa/interest-in-video-conference-discussion-about-sequences-and", "pageUrlRelative": "/posts/krvQb6uFeYCKXB5Aa/interest-in-video-conference-discussion-about-sequences-and", "linkUrl": "https://www.lesswrong.com/posts/krvQb6uFeYCKXB5Aa/interest-in-video-conference-discussion-about-sequences-and", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Interest%20in%20video-conference%20discussion%20about%20sequences%20and%2For%20virtual%20meetups%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AInterest%20in%20video-conference%20discussion%20about%20sequences%20and%2For%20virtual%20meetups%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkrvQb6uFeYCKXB5Aa%2Finterest-in-video-conference-discussion-about-sequences-and%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Interest%20in%20video-conference%20discussion%20about%20sequences%20and%2For%20virtual%20meetups%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkrvQb6uFeYCKXB5Aa%2Finterest-in-video-conference-discussion-about-sequences-and", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkrvQb6uFeYCKXB5Aa%2Finterest-in-video-conference-discussion-about-sequences-and", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 463, "htmlBody": "<p><strong>Update:</strong>&nbsp;We're up to 9 participants. Per <a href=\"/r/discussion/lw/54t/interest_in_videoconference_discussion_about/3usq\">jsalvatier's suggestion</a>, I have created a <a href=\"http://groups.google.com/group/lesswrong-virtual-meetups\">Google Group</a>&nbsp;for this. It looks like we have 8-9 total, and the move toward finalizing groups and dates/times is now at the Google Group thread <a href=\"Planning discussion thread on g-groups is now [HERE](http://groups.google.com/group/lesswrong-virtual-meetups/browse_thread/thread/412a0ccb8cd7d197)\">HERE</a>.</p>\n<p>I plan to ask if I may take meeting minutes for whatever group I end up in and report back on how it goes. If we have multiple groups, we could all combine notes afterward and give a summary. Perhaps interest will grow in this type of activity.</p>\n<p>---</p>\n<p>There's been a decent amount of talk lately about <a href=\"/lw/4zs/philosophy_a_diseased_discipline/3slj\">whether or not people have read the sequences</a>, <a href=\"/r/discussion/lw/51j/reading_the_sequences_before_starting_to_post/\">the costs and benefits of reading the sequences before posting</a>,&nbsp;<a href=\"/r/discussion/lw/4pt/bring_back_the_sequences/\">bringing back the sequences</a>, <a href=\"/r/discussion/lw/50h/hpmor_audio_book_pilot/3swv\">other formats of \"sequence-intake,\"</a> and&nbsp;<a href=\"/r/discussion/lw/53f/sequence_posts_exercises/\">potential exercises coming down the pipes</a>.</p>\n<p>In other words, it seems that many are still interested in the sequences.</p>\n<p>I happen to be <a href=\"/lw/4zs/philosophy_a_diseased_discipline/3sm0\">1 out of about 19</a>&nbsp;who has not read the sequences. (Gasp!) I'm working on remedying that.</p>\n<p>Something else that's been frequently discussed as of late is the <a href=\"/r/discussion/lw/544/problem_noticed_in_aspect_of_lw_comunity_bonding/\">importance</a>&nbsp; <a href=\"/r/discussion/lw/53p/rationality_community_and_death/\">of</a>&nbsp; <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3u77\">community</a>&nbsp;(and the <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3u7c\">desire/need</a> for <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/3txt\">it</a>).</p>\n<p>Well, something occurred to me that might be of interest: combining interest in the sequences <em>with</em>&nbsp;the need for community. I'm inquiring about interest to have video (or audio) online conferences about the sequences, particularly for \"n00bs\" like myself who may not have been through the sequences. I'm in the midst of <a href=\"http://wiki.lesswrong.com/wiki/Map_and_Territory_(sequence)\">Map &amp; Territory</a> myself and am currently working though the <a href=\"http://yudkowsky.net/rational/bayes\">Intro to Bayes</a>.</p>\n<p>Is anyone in a situation where they'd like to read a chunk of these and then have an online discussion? No one seems to be near enough to <a href=\"/lw/3om/meetup_organizing_query_a_rally_for_minnesotans/\">meetup in Minnesota</a>, so perhaps the \"online\" route might work for others physically isolated from LWers.</p>\n<p>I can see some hangups for this: bandwidth, moderating/getting off-topic, law-of-diminishing-returns, etc. I'm thinking a group of 3-5 per virtual discussion might be best to start. Skype or some other protocol (iChat, jabber, etc.) should work for most people.</p>\n<p>Lastly, while my initial thought was to have some post-processing discussion regarding specific sequences... I could also see this as being a neat idea for those with no meetup groups near them, like myself. I thoroughly enjoy discussing with others here, and suspect that even were the discussions not to be explicitly on rationality, it would be very enjoyable to \"meet\" others here, hear about their lives, share about mine, and discuss, say, goals in life, how we're applying rationality to daily life, etc.</p>\n<p>Pretty much anything could go -- start a discussion post for a virtual meetup on a particular topic, see how many are interested in the comment thread, and then perhaps divide people into groups of 3-5 based on availability, time zone, etc.</p>\n<p>So, what's the interest in this?</p>\n<p>Obviously, also share critiques, pitfalls, objections, or whatever else comes to mind!</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "krvQb6uFeYCKXB5Aa", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 18, "extendedScore": null, "score": 6.991596177701955e-07, "legacy": true, "legacyId": "6653", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 33, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EauwsXht4jrjTTE9m", "WXgEQZL2yYmhHjKmn", "SoadQym38wGBDJ7AH", "pqDAFjJiP4LP5ZLMh", "G5tWzsvJFbh4H7Aqd", "usvpySq366ajNoaLW"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-06T23:50:51.766Z", "modifiedAt": null, "url": null, "title": "Bayesian Epistemology vs Popper", "slug": "bayesian-epistemology-vs-popper", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.347Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curi", "createdAt": "2010-11-14T23:20:06.334Z", "isAdmin": false, "displayName": "curi"}, "userId": "MTDagWBSe2QtC7Qoy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YewDsZEMryWTv5Fxf/bayesian-epistemology-vs-popper", "pageUrlRelative": "/posts/YewDsZEMryWTv5Fxf/bayesian-epistemology-vs-popper", "linkUrl": "https://www.lesswrong.com/posts/YewDsZEMryWTv5Fxf/bayesian-epistemology-vs-popper", "postedAtFormatted": "Wednesday, April 6th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Bayesian%20Epistemology%20vs%20Popper&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABayesian%20Epistemology%20vs%20Popper%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYewDsZEMryWTv5Fxf%2Fbayesian-epistemology-vs-popper%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Bayesian%20Epistemology%20vs%20Popper%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYewDsZEMryWTv5Fxf%2Fbayesian-epistemology-vs-popper", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYewDsZEMryWTv5Fxf%2Fbayesian-epistemology-vs-popper", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 782, "htmlBody": "<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>I was directed to this book (http://www-biba.inrialpes.fr/Jaynes/prob.html) in conversation here:</p>\n<p>http://lesswrong.com/lw/3ox/bayesianism_versus_critical_rationalism/3ug7?context=1#3ug7</p>\n<p>I was told it had a proof of Bayesian epistemology in the first two chapters. One of the things we were discussing is Popper's epistemology.</p>\n<p>Here are those chapters:</p>\n<p>http://www-biba.inrialpes.fr/Jaynes/cc01p.pdf</p>\n<p>http://www-biba.inrialpes.fr/Jaynes/cc02m.pdf</p>\n<p>I have not found any proof here that Bayesian epistemology is correct. There is not even an attempt to prove it. Various things are assumed in the first chapter. In the second chapter, some things are proven given those assumptions.</p>\n<p>Some first chapter assumptions are incorrect or unargued. It begins with an example with a policeman, and says his conclusion is not a logical deduction because the evidence is logically consistent with his conclusion being false. I agree so far. Next it says \"we will grant that it had a certain degree of validity\". But I will not grant that. Popper's epistemology explains that *this is a mistake* (and Jaynes makes no attempt at all to address Popper's arguments). In any case, simply assuming his readers will grant his substantive claims is no way to argue.</p>\n<p>The next sentences blithely assert that we all reason in this way. Jaynes' is basically presenting the issues of this kind of reasoning as his topic. This simply ignores Popper and makes no attempt to prove Jaynes' approach is correct.</p>\n<p>Jaynes goes on to give syllogisms, which he calls \"weaker\" than deduction, which he acknowledges are not deductively correct. And then he just says we use that kind of reasoning all the time. That sort of assertion only appeals to the already converted. Jaynes starts with arguments which appeal to the *intuition* of his readers, not on arguments which could persuade someone who disagreed with him (that is, good rational arguments). Later when he gets into more mathematical stuff which doesn't (directly) rest on appeals to intution, it does rest on the ideas he (supposedly) established early on with his appeals to intuition.</p>\n<p>The outline of the approach here is to quickly gloss over substantive philosophical assumptions, never provide serious arguments for them, take them as common sense, do not detail them, and then later provide arguments which are rigorous *given the assumptions glossed over earlier*. This is a mistake.</p>\n<p>So we get, e.g., a section on Boolean Algebra which says it will state previous ideas more formally. This briefly acknowledges that the rigorous parts depend on the non-rigorous parts. Also the very important problem of carefully detailing how the mathematical objects discussed correspond to the real world things they are supposed to help us understand does not receive adequate attention.</p>\n<p>Chapter 2 begins by saying we've now formulated our problem and the rest is just math. What I take from that is that the early assumptions won't be revisted but simply used as premises. So the rest is pointless if those early assumptions are mistaken, and Bayesian Epistemology cannot be proven in this way to anyone who doesn't grant the assumptions (such as a Popperian).</p>\n<p>Moving on to Popper, Jaynes is ignorant of the topic and unscholarly. He writes:</p>\n<p>http://www-biba.inrialpes.fr/Jaynes/crefsv.pdf</p>\n<p>&gt; Karl Popper is famous mostly through making a career out of the doctrine that theories may not be proved true, only false</p>\n<p>This is pure fiction. Popper is a fallibilist and said (repeatedly) that theories cannot be proved false (or anything else).</p>\n<p>It's important to criticize unscholarly books promoting myths about rival philosophers rather than addressing their actual arguments. That's a major flaw not just in a particular paragraph but in the author's way of thinking. It's especially relevant in this case since the author of the books tries to tell us about how to think.</p>\n<p>Note that Yudkowsky made a similar unscholarly mistake, about the same rival philosopher, here:</p>\n<p>http://yudkowsky.net/rational/bayes</p>\n<p>&gt; Previously, the most popular philosophy of science was probably Karl Popper's falsificationism - this is the old philosophy that the Bayesian revolution is currently dethroning. &nbsp;Karl Popper's idea that theories can be definitely falsified, but never definitely confirmed</p>\n<p>Popper's philosophy is not falsificationism, it was never the most popular, and it is fallibilist: it says ideas cannot be definitely falsified. It's bad to make this kind of mistake about what a rival's basic claims are when claiming to be dethroning him. The correct method of dethroning a rival philosophy involves understanding what it does say and criticizing that.</p>\n<p>If Bayesians wish to challenge Popper they should learn his ideas and address his arguments. For example he questioned the concept of positive support for ideas. Part of this argument involves asking the questions: 'What is support?' (This is not asking for its essential nature or a perfect definition, just to explain clearly and precisely what the support idea actually says) and 'What is the difference between \"X supports Y\" and \"X is consistent with Y\"?' If anyone has the answer, please tell me.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YewDsZEMryWTv5Fxf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": -3, "extendedScore": null, "score": -5e-06, "legacy": true, "legacyId": "6654", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 228, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": -3, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T04:37:37.980Z", "modifiedAt": null, "url": null, "title": "Random advice: Teenage U.S. LW-ers should probably be taking more AP exams", "slug": "random-advice-teenage-u-s-lw-ers-should-probably-be-taking", "viewCount": null, "lastCommentedAt": "2022-03-22T21:49:20.126Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "HonoreDB", "createdAt": "2010-11-18T19:42:02.810Z", "isAdmin": false, "displayName": "HonoreDB"}, "userId": "7eyYSfGvgCur6pXmk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WbfiPPLvGdQ8jbs7T/random-advice-teenage-u-s-lw-ers-should-probably-be-taking", "pageUrlRelative": "/posts/WbfiPPLvGdQ8jbs7T/random-advice-teenage-u-s-lw-ers-should-probably-be-taking", "linkUrl": "https://www.lesswrong.com/posts/WbfiPPLvGdQ8jbs7T/random-advice-teenage-u-s-lw-ers-should-probably-be-taking", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Random%20advice%3A%20Teenage%20U.S.%20LW-ers%20should%20probably%20be%20taking%20more%20AP%20exams&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARandom%20advice%3A%20Teenage%20U.S.%20LW-ers%20should%20probably%20be%20taking%20more%20AP%20exams%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWbfiPPLvGdQ8jbs7T%2Frandom-advice-teenage-u-s-lw-ers-should-probably-be-taking%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Random%20advice%3A%20Teenage%20U.S.%20LW-ers%20should%20probably%20be%20taking%20more%20AP%20exams%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWbfiPPLvGdQ8jbs7T%2Frandom-advice-teenage-u-s-lw-ers-should-probably-be-taking", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWbfiPPLvGdQ8jbs7T%2Frandom-advice-teenage-u-s-lw-ers-should-probably-be-taking", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 754, "htmlBody": "<p>If you're a smart young teenager who plans on attending college, consider taking lots of AP Exams.<a id=\"more\"></a></p>\n<p>Advanced Placement Exams are a suite of standardized tests created by the College Board, the same entity that administers the SAT and related tests. &nbsp;There are currently 34 of them, ranging from Art History to Environmental Science to Microeconomics to three flavors of Physics.</p>\n<p>High school students are generally given a limited opportunity to take AP Classes. &nbsp;If you're in a good school and get good grades, you might get the chance to take as many as six by your senior year. &nbsp;However, if you're able to pay a small fee, you can take any of these tests at the end of any school year. Any school that administers AP Exams is required (I think) to allow you to take them, regardless of whether you've taken the course or are even enrolled in the school, and you can probably find a school within a few hours that offers any given exam. &nbsp;Colleges will treat a high score on the test the same whether or not you've taken the formal course.</p>\n<p><strong>When applying to a college, if your academic transcript contains, say, twelve passed AP Exams, it will look twice as impressive as that of a high-school valedictorian.</strong> &nbsp;You'll have proven in a very direct and comprehensible way that you are good at academics, that you have taken initiative, and that you are willing to work within the system to appear remarkable. &nbsp;You'll get into more colleges and get more merit-based scholarship offers.</p>\n<p>Furthermore, you'll have an advantage in negotiating the college bureaucracy once you're in. &nbsp;Some colleges will let you apply all of your AP exams directly as course credit, which means you can enter as a sophomore if you have enough. &nbsp;This not only shortens the time necessary to get your degree, but gets you access to the advanced classes with high-quality professors faster. &nbsp;Most will at least let you use some of your tests in lieu of some of the general education requirements: e.g. if you've gotten a 4+ score on both Spanish Language and Spanish Literature, you probably never have to study a language again if you don't want to.</p>\n<p>To figure out whether this will work for you, go to the <a href=\"http://apcentral.collegeboard.com/apc/public/courses/teachers_corner/index.html\">College Board's Teacher's Guide</a> site. &nbsp;For each subject that even vaguely interests you, download an old test or a practice exam (you may need to identify yourself as a teacher when creating a login account; this is never a lie). You may find that you are already qualified to take several exams, and nearly qualified for many others! &nbsp;This despite your school (if you have one) claiming that you need to wait three more years and sit through nine months of classroom instruction first.</p>\n<p>Tips:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Make sure you schedule your exams well in advance. &nbsp;Schools can change the deadline for registration at any time, and they can't warn you if they don't know who you are.</li>\n<li>You don't need to \"teach to the test\" when engaging in self-study. &nbsp;One method is to take a quick look at the curriculum at the beginning of the year, check one or two of the recommended books out of a library, then follow your own bliss. &nbsp;A month or so before the test, take a practice test, and if necessary do some cramming on the bits you've missed. &nbsp;An afternoon or three with a teacher or professional in the subject can be useful in filling in the gaps, especially with regard to jargon.</li>\n<li>&lt;EDIT&gt;Per the comments, don't bite on this bullet point; its claims are overconfident.&lt;/EDIT&gt; &nbsp;If you're a voracious reader of fiction and a decent test-taker, you can walk into the English Language and English Literature exams with no preparation and get a perfect score. &nbsp;I don't know of any others that don't require at least a little prep--you can be a self-taught expert in a subject and still not know the College Board-approved jargon.</li>\n<li>In written essays, be warned: there are slightly silly quantity-over-quality grading guidelines. &nbsp;Know them ahead of time. &nbsp;Almost every essay requires two or three independent arguments or examples. &nbsp;It's much better to have two bad arguments than one good one. &nbsp;You'll often want to go in having a few different \"case studies\" that you know the details of.</li>\n</ul>\n<div>Good luck, and have fun! &nbsp;If you're a nerd, and your high school education is boring you, something is wrong, and it's worth fighting the power a bit to fix it.</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fH8jPjHF2R27sRTTG": 1, "fF9GEdWXKJ3z73TmB": 1, "fkABsGCJZ6y9qConW": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WbfiPPLvGdQ8jbs7T", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 25, "baseScore": 34, "extendedScore": null, "score": 6.992668498892386e-07, "legacy": true, "legacyId": "6660", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 23, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T06:42:38.957Z", "modifiedAt": null, "url": null, "title": "Popperian Decision making", "slug": "popperian-decision-making", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:02.111Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curi", "createdAt": "2010-11-14T23:20:06.334Z", "isAdmin": false, "displayName": "curi"}, "userId": "MTDagWBSe2QtC7Qoy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pnWuuWte49hur28a6/popperian-decision-making", "pageUrlRelative": "/posts/pnWuuWte49hur28a6/popperian-decision-making", "linkUrl": "https://www.lesswrong.com/posts/pnWuuWte49hur28a6/popperian-decision-making", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Popperian%20Decision%20making&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APopperian%20Decision%20making%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpnWuuWte49hur28a6%2Fpopperian-decision-making%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Popperian%20Decision%20making%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpnWuuWte49hur28a6%2Fpopperian-decision-making", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpnWuuWte49hur28a6%2Fpopperian-decision-making", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1971, "htmlBody": "<p>Branching from:&nbsp;http://lesswrong.com/lw/54u/bayesian_epistemology_vs_popper/3uta?context=4</p>\n<p>The question is: how do you make decisions without justifying decisions, and without foundations?</p>\n<p>If you can do that, I claim the regress problem is solved. Whereas induction, for example, is refuted by the regress problem (no, arbitrary foundations or circular arguments are not solutions).</p>\n<p>OK stepping back a bit, and explaining less briefly:</p>\n<p>&nbsp;</p>\n<p>Infinite regresses are nasty problems for epistemologies.</p>\n<p>All justificationist epistemologies have an infinite regress.</p>\n<p>That means they are false. They don't work. End of story.</p>\n<p>There's options of course. Don't want a regress? No problem. Have an arbitrary foundation. Have an unjustified proposition. Have a circular argument. Or have something else even sillier.</p>\n<p>The regress goes like this, and the details of the justification don't matter.</p>\n<p>If you want to justify a theory, T0, you have to justify it with another theory, T1. Then T1 needs justify by T2. Which needs justifying by T3. Forever. And if T25 turns out wrong, then T24 loses it's justification. And with T24 unjustified, T23 loses its justification. And it cascades all the way back to the start.</p>\n<p>I'll give one more example. Consider probabilistic justification. You assign T0 a probability, say 99.999%. Never mind how or why, the probability people aren't big on explanations like that. Just do your best. It doesn't matter. Moving on, what we have to wonder if that 99.999% figure is correct. If it's not correct then it could be anything such at 90% or 1% or whatever. So it better be correct. So we better justify that it's a good theory. How? Simple. We'll use our whim to assign it a probability of 99.99999%. OK! Now we're getting somewhere. I put a lot of 9s so we're almost certain to be correct! Except, what if I had that figure wrong? If it's wrong it could be anything such as 2% or 0.0001%. Uh oh. I better justify my second probability estimate. How? Well we're trying to defend this probabilistic justification method. Let's not give up yet and do something totally differently, instead we'll give it another probability. How about 80%? OK! Next I ask: is that 80% figure correct? If it's not correct, the probability could be anything, such as 5%. So we better justify it. So it goes on and on forever. Now there's two problems. First it goes forever, and you can't ever stop, you've got an infinite regress. Second, suppose you stopped have some very large but finite number of steps. Then the probability the first theory is correct is arbitrarily small. Because remember that at each step we didn't even have a guarantee, only a high probability. And if you roll the dice a lot of times, even with very good odds, eventually you lose. And you only have to lose once for the whole thing to fail.</p>\n<p>OK so regresses are a nasty problem. They totally ruin all justificationist epistemologies. That's basically every epistemology anyone cares about except skepticism and Popperian epistemology. And forget about skepticism, that's more of an anti-epistemology than an epistemology: skepticism consists of giving up on knowledge.</p>\n<p>Now we'll take a look at Popper and Deutsch's solution. In my words, with minor improvements.</p>\n<p>Regresses all go away if we drop justification. Don't justify anything, ever. Simple.</p>\n<p>But justification had a purpose.</p>\n<p>The purpose of justification is to sort out good ideas from bad ideas. How do we know which ideas are any good? Which should we believe are true? Which should we act on?</p>\n<p>BTW that's the same general problem that induction was trying to address. And induction is false. So that's another reason we need a solution to this issue.</p>\n<p>The method of addressing this issue has several steps, so try to follow along.</p>\n<p>Step 1) You can suggest any ideas you want. There's no rules, just anything you have the slightest suspicion might be useful. The source of the ideas, and the method of coming up with them, doesn't matter to anything. This part is easy.</p>\n<p>Step 2) You can criticize any idea you want. There's no rules again. If you don't understand it, that's a criticism -- it should have been easier to understand. If you find it confusing, that's a criticism -- it should have been clearer. If you think you see something wrong with it, that's a criticism -- it shouldn't have been wrong it that way, *or* it should have included an explanation so you wouldn't make a mistaken criticism. This step is easy too.</p>\n<p>Step 3) All criticized ideas are rejected. They're flawed. They're not good enough. Let's do better. This is easy too. Only the *exact* ideas criticized are rejected. Any idea with at least one difference is deemed a new idea. It's OK to suggest new ideas which are similar to old ideas (in fact it's a good idea: when you find something wrong with an idea you should try to work out a way to change it so it won't have that flaw anymore).</p>\n<p>Step 4) If we have exactly one idea remaining to address some problem or question, and no one wants to revisit the previous steps at this time, then we're done for now (you can always change your mind and go back to the previous steps later if you want to). Use that idea. Why? Because it's the only one. It has no rivals, no known alternatives. It stands alone as the only non-refuted idea. We have sorted out the good ideas from the bad -- as best we know how -- and come to a definite answer, so use that answer. This step is easy too!</p>\n<p>Step 5) What if we have a different number of ideas left over which is not exactly one? We'll divide that into two cases:</p>\n<p>Case 1) What if we have two or more ideas? This one is easy. There is a particular criticism you can use to refute all the remaining theories. It's the same every time so there's not much to remember. It goes like this: idea A ought to tell me why B and C and D are wrong. If it doesn't, it could be better! So that's a flaw. Bye bye A. On to idea B: if B is so great, why hasn't it explained to me what's wrong with A, C and D? Sorry B, you didn't answer all my questions, you're not good enough. Then we come to idea C and we complain that it should have been more help and it wasn't. And D is gone too since it didn't settle the matter either. And that's it. Each idea should have settled the matter by giving us criticisms of all its rivals. They didn't. So they lose. So whenever there is a stalemate or a tie with two or more ideas then they all fail.</p>\n<p>Case 2) What if we have zero ideas? This is crucial because case one always turns into this! The answer comes in two main parts. The first part is: think of more ideas. I know, I know, that sounds hard. What if you get stuck? But the second part makes it easier. And you can use the second part over and over and it keeps making it easier every time. So you just use the second part until it's easy enough, then you think of more ideas when you can. And that's all there is to it.</p>\n<p>OK so the second part is this: be less ambitious. You might worry: but what about advanced science with its cutting edge breakthroughs? Well, this part is optional. If you can wait for an answer, don't do it. If there's no hurry, then work on the other steps more. Make more guesses and think of more criticisms and thus learn more and improve your knowledge. It might not be easy, but hey, the problem we were looking at is how to sort out good ideas from bad ideas. If you want to solve hard problems then it's not easy. Sorry. But you've got a method, just keep at it.</p>\n<p>But if you have a decision to make then you need an answer now so you can make your decision. So in that case, if you actually want to reach a state of having exactly one theory which you can use now, then the trick is when you get stuck be less ambitious. I think how you can see how that would work in general terms. Basically if human knowledge isn't good enough to give you an answer of a certain quality right now, then your choices are either to work on it more and not have an answer now, or accept a lower quality answer. You can see why there isn't really any way around that. There's no magic way to always get a top quality answer now. If you want a cure for cancer, well I can't tell you how to come up with one in the next five minutes, sorry.</p>\n<p>This is a bit vague so far. How does lowering your standards address the problem. So what you do is propose a new idea like this, \"I need to do something, so I will do...\" and then you put whatever you want (idea A, idea B, some combination, whatever).</p>\n<p>This new idea is not refuted by any of the existing criticisms. So now you have one idea, it isn't refuted, and you might be done. If you're happy with it, great. But you might not be. Maybe you see something wrong with it, or you have another proposal. That's fine; just go back to the first three steps and do them more. Then you'll get to step 4 or 5 again.</p>\n<p>What if we get back here? What do we do the second time? The third time? We simply get less ambitious each time. The harder a time we're having, the less we should expect. And so we can start criticizing any ideas that aim too high.</p>\n<p>BTW it's explained on my website here, including an example:</p>\n<p>http://fallibleideas.com/avoiding-coercion</p>\n<p>Read that essay, keeping in mind what what I've been saying, and hopefully everything will click. Just bear in mind that when it talks about cooperation between people, and disagreements between people, and coming up with solutions for people -- when it discusses ideas in two or more separate minds -- everything applies exactly the same if the two or more conflicting ideas are all in the same mind.</p>\n<p>What if you get real stuck? Well why not do the first thing that pops into your head? You don't want to? Why not? Got a criticism of it? It's better than nothing, right? No? If it's not better than nothing, do nothing! You think it's silly or dumb? Well so what? If it's the best idea you have then it doesn't matter if it's dumb. You can't magically instantly become super smart. You have to use your best idea even if you'd like to have better ideas.</p>\n<p>Now you may be wondering whether this approach is truth-seeking. It is, but it doesn't always find the truth immediately. If you want a resolution to a question immediately then its quality cannot exceed today's knowledge (plus whatever you can learn in the time allotted). It can't do better than the best that is known how to do. But as far as long term progress, the truth seeking came in those first three steps. You come up with ideas. You criticize those ideas. Thereby you eliminate flaws. Every time you find a mistake and point it out you are making progress towards the truth. That's how we approach the truth: not by justifying but by identify mistakes and learning better. This is evolution, it's the solution to Paley's problem, it's discussed in BoI and on my Fallible Ideas website. And it's not too hard to understand: improve stuff, keep at it, and you get closer to the truth. Mistake correcting -- criticism -- is a truth-seeking method. That's where the truth-seeking comes from.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pnWuuWte49hur28a6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": -4, "extendedScore": null, "score": 6.993017262115419e-07, "legacy": true, "legacyId": "6661", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 101, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T08:11:14.351Z", "modifiedAt": null, "url": null, "title": "reply to benelliott about Popper issues", "slug": "reply-to-benelliott-about-popper-issues", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.001Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curi", "createdAt": "2010-11-14T23:20:06.334Z", "isAdmin": false, "displayName": "curi"}, "userId": "MTDagWBSe2QtC7Qoy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Mmb2j2u69iDwNHCFb/reply-to-benelliott-about-popper-issues", "pageUrlRelative": "/posts/Mmb2j2u69iDwNHCFb/reply-to-benelliott-about-popper-issues", "linkUrl": "https://www.lesswrong.com/posts/Mmb2j2u69iDwNHCFb/reply-to-benelliott-about-popper-issues", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20reply%20to%20benelliott%20about%20Popper%20issues&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Areply%20to%20benelliott%20about%20Popper%20issues%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMmb2j2u69iDwNHCFb%2Freply-to-benelliott-about-popper-issues%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=reply%20to%20benelliott%20about%20Popper%20issues%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMmb2j2u69iDwNHCFb%2Freply-to-benelliott-about-popper-issues", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMmb2j2u69iDwNHCFb%2Freply-to-benelliott-about-popper-issues", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2667, "htmlBody": "<p>This is a discussion page because I got the message \"Comment too long\". Apparently the same formatting magic doesn't work here for quotes :( &nbsp;It is a reply to:</p>\n<p>http://lesswrong.com/lw/3ox/bayesianism_versus_critical_rationalism/3ulv</p>\n<p>&nbsp;</p>\n<p>&gt; &gt; You can conjecture Bayes' theorem. You can also conjecture all the rest, however some things (such as induction, justificationism, foundationalism) contradict Popper's epistemology. So at least one of them has a mistake to fix. Fixing that may or may not lead to drastic changes, abandonment of the main ideas, etc</p>\n<p>&gt; Fully agreed. In principle, if Popper's epistemology is of the second, self-modifying type, there would be nothing wrong with drastic changes. One could argue that something like that is exactly how I arrived at my current beliefs, I wasn't born a Bayesian.</p>\n<p>OK great.</p>\n<p>If the changes were large enough, to important parts (for example if it lost the ability to self-modify) I wouldn't want to call it Popper's epistemology anymore (unless maybe the changes were made very gradually, with Popper's ideas being valued the whole time, and still valued at the end). It would be departing from his tradition too much, so it would be something else. A minor issue in some ways, but tradition matters.</p>\n<p>&gt; I can also see some ways to make induction and foundationalism easer to swallow.</p>\n<p>&gt; A discussion post sounds about right for this, if enough people like it you might consider moving it to the main site.</p>\n<p>104 comments later it's at 0 karma. There is interest, but not so much liking. I don't think the main site is the right place for me ;-)</p>\n<p>&gt; &gt; I think you are claiming that seeing a white swan is positive support for the assertion that all swans are white. (If not, please clarify).</p>\n<p>&gt; This is precisely what I am saying.</p>\n<p>Based on what you say later, I'm not sure if you mean this in the same way I meant it. I meant: it is positive support for \"all swans are white\" *over* all theories which assert \"all swans are black\" (I disagree with that claim). If it doesn't support them *more than those other theories* then I regard it as vaccuous. I don't believe the math you offered meets this challenge over supporting \"all swans are white\" more than various opposites of it. I'm not sure if you intended it to.</p>\n<p>&gt; &gt; If so, this gets into important issues. Popper disputed the idea of positive support. The criticism of the concept begins by considering: what is support? And in particular, what is the difference between \"X supports Y\" and \"X is consistent with Y\"?</p>\n<p>&gt; The beauty of Bayes is how it answers these questions. To distinguish between the two statements we express them each in terms of probabilities.</p>\n<p>&gt; \"X is consistent with Y\" is not really a Bayesian way of putting things, I can see two ways of interpreting it. One is as P(X&amp;Y) &gt; 0, meaning it is at least theoretically possible that both X and Y are true. The other is that P(X|Y) is reasonably large, i.e. that X is plausible if we assume Y.</p>\n<p>Consistent means \"doesn't contradict\". It's the first one. Plausible is definitely not what I wanted.</p>\n<p>&gt; \"X supports Y\" means P(Y|X) &gt; P(Y), X supports Y if and only if Y becomes more plausible when we learn of X. Bayes tells us that this is equivalent to P(X|Y) &gt; P(X), i.e. if Y would suggest that X is more likely that we might think otherwise then X is support of Y.</p>\n<p>This is true but fairly vaccous, in my view. I don't want to argue over what counts as significant. If you like it, shrug. It is important that, e.g., we reject ideas refuted by evidence. But I don't think this addresses the major problems in epistemology which come after we decide to reject things which are refuted by evidence.</p>\n<p>The reason it doesn't is there's always infinitely many things supported by any evidence, in this sense. Infinitely many things which make wildly different predictions about the future, but identical predictions about whatever our evidence covers. If Y is 10 white swans, and X is \"all swans are white\" then X is supported, by your statement. But also supported are infinitely many different theories claiming that all swans are black, and that you hallucinated. You saw exactly what you would see if any of those theories were true, so they get as much support as anything else. There is nothing (in the concept of support) to differentiate between \"all swans are white\" and those other theories.</p>\n<p>If you do add something else to differentiate, I will say the support concept is useless. The new thing does all the work. And further, the support concept is frequently abused. I have had people tell me that \"all swans are black, but tomorrow you will hallucinated 10 white swans\" is supported less by seeing 10 white swans tomorrow than \"all swans are white\" is, even though they made identical predictions (and asserted them with 100% probability, and would both have been definitely refuted by anything else). That kind of stuff is just wrong. I don't know if you think that kind of thing or not. What you said here does clearly disown it, nor advocate it. But that's the kind of thing that concerns me.</p>\n<p>&gt; Suppose we make X the statement \"the first swan I see today is white\" and Y the statement \"all swans are white\". P(X|Y) is very close to 1, P(X|~Y) is less than 1 so P(X|Y) &gt; P(X), so seeing a white swan offers support for the view that all swans are white. Very, very weak support, but support nonetheless.</p>\n<p>The problem I have is that it's not supported over infinitely many rivals. So how is that really support? It's useless. The only stuff not being supported is that which contradicts the evidence (like, literally contradicts, with no hallucination claims. e.g. a theory that predicts you will think you saw a green swan tomororw. but then you don't, just the white ones. that one is refuted). The inconsistent theories are refuted. The theories which make probabalistic predictions are partially supported. And the theories that say \"screw probability, 100% every time\" for all predictions get maximally supported, and between them support does not differentiate. (BTW I think it's ironic that I score better on support when I just stick 100% in front of every prediction in all theories I mention, while you score lower by putting in other numbers, and so your support concept discourages ever making predictions with under 100% confidence).</p>\n<p>&gt; (The above is not meant to be condescending, I apologise if you know all of it already).</p>\n<p>It is not condescending. I think (following Popper) that explaining things is important and that nothing is obvious, and that communication is difficult enough without people refusing go over the \"basics\" in order to better understand each other. Of course this is a case where Popper's idea is not unique. Other people have said similar. But this idea, and others, are integrated into his epistemology closely. There's also *far more detail and precision* available, to explain *why* this stuff is true (e.g. lengthy theories about the nature of communication, also integrated into his epistemology). I don't think ideas about interpretting people's writing in kind ways, and miscommunication being a major hurdle, are so closely integrated with Bayesian approaches with are more math focussed and don't integrate so nicely with explanations.</p>\n<p>My reply about support is basic stuff too, to my eye. But maybe not yours. I don't know. I expect not, since if it was you could have addressed it in advance. Oh well. It doesn't matter. Reply as you will. No doubt I'm also failing to address in advance something you regard as important.</p>\n<p>&gt; &gt; To show they are correct. Popper's epistemology is different: ideas never have any positive support, confirmation, verification, justification, high probability, etc...</p>\n<p>&gt; This is a very tough bullet to bite.</p>\n<p>Yes it is tough. Because this stuff has been integral to the Western philosophy tradition since Aristotle until Popper. That's a long time. It became common sense, intuitive, etc...</p>\n<p>&gt; &gt; How do we decide which idea is better than the others? We can differentiate ideas by criticism. When we see a mistake in an idea, we criticize it (criticism = explaining a mistake/flaw). That refutes the idea. We should act on or use non-refuted ideas in preference over refuted ideas.</p>\n<p>&gt; One thing I don't like about this is the whole 'one strike and you're out' feel of it. It's very boolean,</p>\n<p>Hmm. FYI that is my emphasis more than Popper's. I think it simplifies the theory a bit to regard all changes to theories as new theories. Keep in mind you can always invent a new theory with one thing changed. So the ways it matters have some limits, it's party just a terminology thing (terminolgoy has meaning, and some is better than others. Mine is chosen with Popperian considerations in mind. A lot of Popper's is chosen with considerations in mind of talking with his critics). Popper sometimes emphasized that it's important not to give up on theories too easily, but to look for ways to improve them when they are criticized. I agree with that. So, the \"one strike you're out\" way of expressing this is misleading, and isn't *substantially* implied in my statements (b/c of the possibility of creating new and similar theories). Other terminologies have different problems.</p>\n<p>&gt; the real world isn't usually so crisp. Even a correct theory will sometimes have some evidence pointing against it, and in policy debates almost every suggestion will have some kind of downside.</p>\n<p>This is a substantive, not terminological, disagreement, I believe. I think it's one of the *advantages* of my terminology that it helped highlight this disagreement.</p>\n<p>Note the idea that evidence \"points\" is the support idea.</p>\n<p>In the Popperian scheme of things, evidence does not point. It contradicts, or it doesn't (given some interpretation and explanation, which are often more important than the evidence itself). That's it. Evidence can thus be used in criticisms, but is not itself inherently a criticism or argument.</p>\n<p>So let me rephrase what you were saying. \"Even a correct theory will sometimes have critical arguments against it\".</p>\n<p>Part of the Popperian view is that if an idea has one false aspect, it is false. There is a sense in which any flaw must be decisive. We can't just go around admitting mistakes into our ideas on purpose.</p>\n<p>One way to explain the issue is: for each criticism, consider it. Judge if it's right or wrong. Do your best and act on the consequence. If you think the criticism is correct, you absolutely must reject the idea it criticizes. If you don't, then you can regard the theory as not having any *true* critical arguments against it, so that's fine.</p>\n<p>When you reject an idea for having one false part, you can try to form a new theory to rescue the parts you still value. This runs into dangers of arbitrarily rescuing everything in an ad hoc way. There's two answers to that. The first is: who cares? Popperian epistemology is not about laying out rules to prevent you from thinking badly. It's about offering advice to help you think better. We don't really care very much if you find a way to game the system and do something dumb, such as making a series of 200 ad hoc and silly arguments to try to defend a theory you are attached to. All we'll do is criticize you for it. And we think that is good enough: there are criticisms of bad methodologies, but no formal rules that definitively ban them. Now the second answer, which Deutsch presents in The Fabric of Reality, is that when you modify theories you often ruin their explanation. If you don't, then the modification is OK, it's good to consider this new theory, it's worth considering. But if the explanation is ruined, that puts an end to trying to rescue it (unless you can come up with a good idea for a new way to modify it that wont' ruin the explanation).</p>\n<p>This concept of ruining explanations is important and not simple. Reading the book would be great (it is polished! edited!) but I'll try to explain it briefly. This example is actually from his other book, _The Beginning of Infinity_ chapter 1. We'll start with a bad theory: the seasons are caused by Persephone's imprisonment, for 6 months of the year, in the underworld (via her mother Demeter's magic powers which she uses to express her emotions). This theory has a bad explanation in the first place, so it can be easily rescued when it's emprically contradicted. For example this theory predicts the seasons will be the same all over the globe, at the same time. That's false. But you can modify the theory very easily to account for the empirical data. You can say that Demeter only cares about the area where she lives. She makes it cold when Persephone is gone, and hot when she's present. The cold or hot has to go somewhere, so she puts it far away. So, the theory is saved by an ad hoc modification. It's no worse than before. Its substantive content was \"Demeter's emotions and magic account for the seasons\". And when the facts change, that explanation remains in tact. This is a warning against bad explanations (which can be criticized directly for being bad explanations, so there's no big problem here).</p>\n<p>But when you have a good explanation, such as the real explanation for the seasons, based on the Earth orbitting the sun, and the axis being tilted, and so on, ad hoc modifications cause bigger problems. Suppose we found out the seasons are the same all around the world at the same time. That would refute the axis tilt theory of seasons. You could try to save it, but it's hard. If you added magic you would be ruining the axis tilt *explantion* and resorting to a very different explanation. I can't think of any way to save the axis tilt theory from the observation that the whole world has the same seasons as the same time, without contradicting or replacing its explanation. So that's why ad hoc modifications sometimes fail (for good explanatory theories only). In the cases where there is not a failure of this type -- if there is a way to keep a good explanation and still account for new data -- then that new theory is genuinely worth consideration (and if there is some thing wrong with it, you can criticize it).</p>\n<p>&gt; There is also the worry that there could be more than one non-refuted idea, which makes it a bit difficult to make decisions.</p>\n<p>Yes I know. This is an important problem. I regard it as solved. For discussion of this problem, go to:</p>\n<p>http://lesswrong.com/r/discussion/lw/551/popperian_decision_making/</p>\n<p>&gt; Bayesianism, on the other hand, when combined with expected utility theory, is perfect for making decisions.</p>\n<p>Bayesianism works when you assume a bunch of stuff (e.g. some evidence), and you set up a clean example, and you choose an issue it's good at handling. I don't think it is very helpful in a lot of real world cases. Certaintly it helps in some. I regard Bayes' theorem itself as \"how not to get probability wrong\". That matters to a good amount of stuff. But hard real world scenarios usually have rival explanations of the proper interpretation of the available evidence, they have fallible evidence that is in doubt, they have often many different arguments that are hard to assign any numbers to, and so on. Using solomonoff induction is assign numbers, for example, doesn't work in practice as far as i know (e.g. people don't actually compute the numbers for dozens of political arugments using it). Another assumption being made is *what is a desirable (high utility) outcome* -- Bayesianism doesn't help you figure that out, it just lets you assume it (I see that as entrenching bias and subjectivism in reagards to morality -- we *can* make objective criticisms of moral values).</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Mmb2j2u69iDwNHCFb", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": -3, "extendedScore": null, "score": 6.993264423684845e-07, "legacy": true, "legacyId": "6662", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 189, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T10:39:00.843Z", "modifiedAt": null, "url": null, "title": "96 Bad Links in the Sequences", "slug": "96-bad-links-in-the-sequences", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:37.206Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/5wLDhMCn2p3mMnC6g/96-bad-links-in-the-sequences", "pageUrlRelative": "/posts/5wLDhMCn2p3mMnC6g/96-bad-links-in-the-sequences", "linkUrl": "https://www.lesswrong.com/posts/5wLDhMCn2p3mMnC6g/96-bad-links-in-the-sequences", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%2096%20Bad%20Links%20in%20the%20Sequences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A96%20Bad%20Links%20in%20the%20Sequences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5wLDhMCn2p3mMnC6g%2F96-bad-links-in-the-sequences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=96%20Bad%20Links%20in%20the%20Sequences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5wLDhMCn2p3mMnC6g%2F96-bad-links-in-the-sequences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F5wLDhMCn2p3mMnC6g%2F96-bad-links-in-the-sequences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 359, "htmlBody": "<p>I've been scraping data from the sequences recently, where by sequences I mean all of Eliezer's <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">posts</a> up to and including&nbsp;<a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a>. I've been doing this mostly to get some fun data out and maybe some more useful things like the <a href=\"/lw/4pt/bring_back_the_sequences/\">Bring Back the Sequences</a> project, but one of the things I found is that there is breakage from the move from OB (and OB's subsequent reorganization) that remains unfixed.</p>\n<p>In particular, 96 links either give 404s (not found), used to link to a comment but now only link to the main article, or link under the summary fold for no apparent reason. To avoid overloading this article, I have posted the list on piratepad here:</p>\n<p><a href=\"http://piratepad.net/ep/pad/view/ro.eyxCVZYMZeO/latest\">http://piratepad.net/ep/pad/view/ro.eyxCVZYMZeO/latest</a></p>\n<p>Note that I have only checked links that went to overcomingbias.com. This is not necessarily a complete list.</p>\n<p>Some of these can be fixed by anyone with editing rights, but the ones pointing to comments can be fixed only by Eliezer or someone who knows what comment was meant to be linked. Alternatively, someone can go through the archive.org WayBack machine, figure out which comments were linked to, then find them in the equivalent LessWrong page, and finally provide the corrected link. I may modify the scraper to do this if someone is willing to make the substitution.</p>\n<p>Also, a bunch of links (not in the above list) direct the user to OvercomingBias.com only to be redirected back to LessWrong. While this doesn't actually cause any breakage, it's a pity to be burdening OB's server for no real reason. I can produce a list of these if needed.</p>\n<p>If I have managed to attract the attention of anyone with editorial rights, I would really appreciate it if you could help me out by removing certain formatting inconsistencies that greatly slow down and complicate my scraper. I can offer more details on demand, but these links to OB are near the top of the list.</p>\n<p>I should be back with more interesting data soon. If you have any particular data-mineable queries about the sequences, let me know.</p>\n<p><em>[Edit: The 4 links that point to a #comments fragment are actually processed correctly. That leaves 92 to be fixed.]</em></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "5wLDhMCn2p3mMnC6g", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": 51, "extendedScore": null, "score": 0.0005264750054754617, "legacy": true, "legacyId": "6665", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 34, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 27, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["LqjKP255fPRY7aMzw", "WXgEQZL2yYmhHjKmn"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T10:44:28.446Z", "modifiedAt": null, "url": null, "title": "Meta: Karma and lesswrong mainstream positions", "slug": "meta-karma-and-lesswrong-mainstream-positions", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.011Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "FAWS", "createdAt": "2010-01-09T18:58:38.832Z", "isAdmin": false, "displayName": "FAWS"}, "userId": "a7Neq3q2DbWrbo6B6", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Qxusjvsq8LqRSeuWK/meta-karma-and-lesswrong-mainstream-positions", "pageUrlRelative": "/posts/Qxusjvsq8LqRSeuWK/meta-karma-and-lesswrong-mainstream-positions", "linkUrl": "https://www.lesswrong.com/posts/Qxusjvsq8LqRSeuWK/meta-karma-and-lesswrong-mainstream-positions", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20Karma%20and%20lesswrong%20mainstream%20positions&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20Karma%20and%20lesswrong%20mainstream%20positions%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQxusjvsq8LqRSeuWK%2Fmeta-karma-and-lesswrong-mainstream-positions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20Karma%20and%20lesswrong%20mainstream%20positions%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQxusjvsq8LqRSeuWK%2Fmeta-karma-and-lesswrong-mainstream-positions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQxusjvsq8LqRSeuWK%2Fmeta-karma-and-lesswrong-mainstream-positions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p>My impression is that critiques of lesswrong mainstream positions and arguments for contrary positions are received well and achieve high karma scores when they are of very high quality. Similarly posts and comments that take lesswrong mainstream positions will still be voted down if they are of very low quality. But in between there seems to be a gulf: Moderately low quality mainstream comments will stay at 0 to -1 karma while contra-mainstream comments of&nbsp;(apparently) similar quality score solidly negative karma, moderately high quality mainstream comments achieve good positive karma while similar quality contra-mainstream comments stay at 0 to 2.&nbsp;</p>\n<p>Do you share my impression? And if this is the case, should we try to do something about it?&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Qxusjvsq8LqRSeuWK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 17, "extendedScore": null, "score": 6.993691977886783e-07, "legacy": true, "legacyId": "6666", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T11:50:23.101Z", "modifiedAt": null, "url": null, "title": "Lesswrong Meetup in Barcelona?", "slug": "lesswrong-meetup-in-barcelona", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.979Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raw_Power", "createdAt": "2010-09-10T23:59:43.621Z", "isAdmin": false, "displayName": "Raw_Power"}, "userId": "kwSqcED9qTanFyNWG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ew9i3Srda4go7zKvv/lesswrong-meetup-in-barcelona", "pageUrlRelative": "/posts/ew9i3Srda4go7zKvv/lesswrong-meetup-in-barcelona", "linkUrl": "https://www.lesswrong.com/posts/ew9i3Srda4go7zKvv/lesswrong-meetup-in-barcelona", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Lesswrong%20Meetup%20in%20Barcelona%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALesswrong%20Meetup%20in%20Barcelona%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Few9i3Srda4go7zKvv%2Flesswrong-meetup-in-barcelona%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Lesswrong%20Meetup%20in%20Barcelona%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Few9i3Srda4go7zKvv%2Flesswrong-meetup-in-barcelona", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Few9i3Srda4go7zKvv%2Flesswrong-meetup-in-barcelona", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 87, "htmlBody": "<p>Perhaps the Spaniard and/or Catalan tropers, and those others who simply feel like visiting this wonderful city that is <a href=\"http://en.wikipedia.org/wiki/Barcelona\">Barcelona</a>, could meet here during Semana Santa, the Spanish Spring Break, which lasts from April 15 to April 24. We could decide on a date within that interval. I'm not trying to compete with Paris or anything, but it's really one of the most convenient times in the year for such an event to take place.</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Holy_Week_in_Spain\">Don't expect any Ku Klux Klan lookalikes though, Catalonia just doesn't do that.</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ew9i3Srda4go7zKvv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 10, "extendedScore": null, "score": 6.993875896076948e-07, "legacy": true, "legacyId": "6604", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T13:16:27.013Z", "modifiedAt": null, "url": null, "title": "The AV referendum and rationality", "slug": "the-av-referendum-and-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:47.558Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "ZPYHpHAxKoETuFrXa", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ztcnZ23ezgrt9fYBY/the-av-referendum-and-rationality", "pageUrlRelative": "/posts/ztcnZ23ezgrt9fYBY/the-av-referendum-and-rationality", "linkUrl": "https://www.lesswrong.com/posts/ztcnZ23ezgrt9fYBY/the-av-referendum-and-rationality", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20AV%20referendum%20and%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20AV%20referendum%20and%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FztcnZ23ezgrt9fYBY%2Fthe-av-referendum-and-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20AV%20referendum%20and%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FztcnZ23ezgrt9fYBY%2Fthe-av-referendum-and-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FztcnZ23ezgrt9fYBY%2Fthe-av-referendum-and-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 627, "htmlBody": "<p>I know 'Politics is the mind-killer' and I'm prepared for downvotes here, but thought this would be worth pointing out.<br />In the UK at the moment we're preparing for a referendum, on May 5, on whether to switch our voting system for General Elections from First Past The Post (FPTP) to the Alternative Vote (AV). I see this not as a question of politics (the fact that it crosses normal party lines tends to suggest I'm right) but as a question of information theory and cybernetics. Once it's seen in that light, the answer becomes obvious.<br />Unfortunately, the only real coverage this has received in the media has been along group identity lines. Both sides claim the Nazis would benefit from a vote for the other side, and other than that the No campaign's line has been pretty much \"There's a black man in this leaflet but not this other one, therefore the Yes campaign are racist!\" or \"Nick Clegg likes AV and you don't like Nick Clegg, therefore you don't like AV!\"<br />Meanwhile the Yes campaign has been little better, its main campaign consisting of \"MPs don't like AV and you don't like MPs, so vote Yes!\" and \"Stephen Fry likes AV, and you like Stephen Fry, so vote Yes!\"<br /><br />It would be quite understandable, with debate like that, if the average British LessWronger were to think that the matter was just a matter of normal mammalian status politics, on a par with the riots last year over whether to call something a 'graduate tax' or 'tuition fees'. But in this case, there is a substantial difference, and an obvious rational choice.<br /><br />Assuming, for the moment, that we're agreed that representative democracy of some form is a reasonable system of government, one of the main advantages of that system is that it has to be somewhat responsive to the citizenry - voters put information into the system at election time, and that information determines the makeup of the government.<br /><br />Assuming we think that a good thing, we want to maximise the amount of information each voter can put into the system. The more information put in, the more accurately the government can respond to the will of the people.<br /><br />Now, with First Past The Post, the system is that in each constituency, the candidate with the largest number of votes gets elected, and all the candidate cares about is his/her majority over the candidate with the next-largest number of votes. This means that in all but a very small number of cases, the only votes that 'count' in any important sense are those for the first and second-placed candidate. That means each voter gets to influence the government at a bitrate of one bit every five years. Not great.<br /><br />With AV, on the other hand, voters rank candidates, and then the candidate with the lowest number of first preferences gets knocked out and their votes redistributed to the voters' second preferences. This process is repeated until one candidate has over 50% of expressed preferences.<br /><br />This *vastly* increases your ability to put information into the system. In my constituency, for example, last time there were eight candidates. Assuming I used all my preferences (and I would, to ensure the Christian Party were firmly at the bottom) that would give me 8! different possible rankings - roughly sixteen bits of information I could put into the system, rather than one.<br /><br />Clearly, the rational thing to do in this case is to vote yes, to increase the effectiveness of the democratic system. Unless I'm missing something, in which case I'm sure the comments will say...</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ztcnZ23ezgrt9fYBY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": 11, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "6667", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 68, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T14:36:42.190Z", "modifiedAt": null, "url": null, "title": "Building on existing human motivations", "slug": "building-on-existing-human-motivations", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:20.343Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W49hRXMb6FvQN6Bpj/building-on-existing-human-motivations", "pageUrlRelative": "/posts/W49hRXMb6FvQN6Bpj/building-on-existing-human-motivations", "linkUrl": "https://www.lesswrong.com/posts/W49hRXMb6FvQN6Bpj/building-on-existing-human-motivations", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Building%20on%20existing%20human%20motivations&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABuilding%20on%20existing%20human%20motivations%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW49hRXMb6FvQN6Bpj%2Fbuilding-on-existing-human-motivations%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Building%20on%20existing%20human%20motivations%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW49hRXMb6FvQN6Bpj%2Fbuilding-on-existing-human-motivations", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW49hRXMb6FvQN6Bpj%2Fbuilding-on-existing-human-motivations", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 151, "htmlBody": "<p><a href=\"http://www.conversationmarketing.com/2011/01/marketing-dungeons-dragons-2011.htm\">A marketer explains what he learned from D&amp;D</a>.</p>\n<p>In particular, that killing monsters, taking their stuff, and telling the tale are basic human pleasures, and successful marketing builds on such stuff-- and that playing the good guy is more satisfying than playing the bad guy.</p>\n<p>On the other hand (this is me, not the article), it doesn't seem to be as satisfying to be a good guy who finds an undramatic solution than to be a combative good guy. I count the sort of non-violence that gets you killed as combative goodguyism.</p>\n<p>Would it help to personify irrationality as a monster? I don't think so, though I do think we come close to personifying death as a monster, and in fact there's a parable somewhere portraying death as a dragon.</p>\n<p>I was never a serious gamer, but I do have pleasant memories of actually finding a use for the druid spell that creates a forest.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W49hRXMb6FvQN6Bpj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 6.994340029216154e-07, "legacy": true, "legacyId": "6668", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T15:34:38.846Z", "modifiedAt": null, "url": null, "title": "Autism and Lesswrong", "slug": "autism-and-lesswrong", "viewCount": null, "lastCommentedAt": "2017-06-17T04:32:04.678Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "CuSithBell", "createdAt": "2011-01-31T04:08:19.058Z", "isAdmin": false, "displayName": "CuSithBell"}, "userId": "tMhtGHqCXw7guA7tR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/puGJmSGfndEsw3x7h/autism-and-lesswrong", "pageUrlRelative": "/posts/puGJmSGfndEsw3x7h/autism-and-lesswrong", "linkUrl": "https://www.lesswrong.com/posts/puGJmSGfndEsw3x7h/autism-and-lesswrong", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Autism%20and%20Lesswrong&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAutism%20and%20Lesswrong%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpuGJmSGfndEsw3x7h%2Fautism-and-lesswrong%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Autism%20and%20Lesswrong%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpuGJmSGfndEsw3x7h%2Fautism-and-lesswrong", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpuGJmSGfndEsw3x7h%2Fautism-and-lesswrong", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 60, "htmlBody": "<p>I am turning over in my head an idea for a discussion post. This preliminary post has two main purposes:</p>\n<p><ol>\n<li>Do we have statistics for where lesswrong readers / posters lie on the Autism spectrum?&nbsp;</li>\n<li>What are your thoughts on the relationship (if any) between lesswrong and autism (and, perhaps, between rationality and autism)?&nbsp;</li>\n</ol>\n<div>Can you help me out?</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"k9pXZBsM8wMRwwK4J": 1, "izp6eeJJEg9v5zcur": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "puGJmSGfndEsw3x7h", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 6.99450174321763e-07, "legacy": true, "legacyId": "6669", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 29, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T17:56:51.168Z", "modifiedAt": null, "url": null, "title": "What are you working on? April 2011", "slug": "what-are-you-working-on-april-2011", "viewCount": null, "lastCommentedAt": "2011-04-20T09:09:22.760Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/zGLqyaQPj5EWjNLxq/what-are-you-working-on-april-2011", "pageUrlRelative": "/posts/zGLqyaQPj5EWjNLxq/what-are-you-working-on-april-2011", "linkUrl": "https://www.lesswrong.com/posts/zGLqyaQPj5EWjNLxq/what-are-you-working-on-april-2011", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20are%20you%20working%20on%3F%20April%202011&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20are%20you%20working%20on%3F%20April%202011%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzGLqyaQPj5EWjNLxq%2Fwhat-are-you-working-on-april-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20are%20you%20working%20on%3F%20April%202011%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzGLqyaQPj5EWjNLxq%2Fwhat-are-you-working-on-april-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FzGLqyaQPj5EWjNLxq%2Fwhat-are-you-working-on-april-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 113, "htmlBody": "<p>The is the second 'What are you working on?' thread. The last one is <a href=\"/lw/4nt/what_are_you_working_on/\">here</a>. So here's the question:</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; padding-left: 300px; \"><em style=\"font-style: italic; \">What are you working on?&nbsp;</em></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; \">Here are some guidelines</p>\n<ul style=\"margin-top: 10px; margin-right: 2em; margin-bottom: 10px; margin-left: 2em; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; list-style-type: disc; list-style-position: outside; list-style-image: initial; \">\n<li>Focus on projects that you have recently made progress on, not projects that you're thinking about doing but haven't started, those are for a different thread.&nbsp;</li>\n<li>Why this project and not others? Mention reasons why you're doing the project and/or why others should contribute to your project (if applicable).</li>\n<li>Talk about your goals for the project.</li>\n<li>Any kind of project is fair game: personal improvement, research project, art project, whatever.</li>\n<li><strong style=\"font-weight: bold; \">Link to your work if it's linkable</strong></li>\n</ul>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "zGLqyaQPj5EWjNLxq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 6.994898645815673e-07, "legacy": true, "legacyId": "6671", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 61, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["Cq4KKE4Xg6xdeoSJZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T18:34:08.805Z", "modifiedAt": null, "url": null, "title": "[LINK] Ethical Pick-Up Artistry (Clarisse Thorn)", "slug": "link-ethical-pick-up-artistry-clarisse-thorn", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:02.185Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KenChen", "createdAt": "2011-02-16T18:02:23.420Z", "isAdmin": false, "displayName": "KenChen"}, "userId": "Tay9Y5o7ehACBHeqc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/hDwwPwZmPmgqxeDFn/link-ethical-pick-up-artistry-clarisse-thorn", "pageUrlRelative": "/posts/hDwwPwZmPmgqxeDFn/link-ethical-pick-up-artistry-clarisse-thorn", "linkUrl": "https://www.lesswrong.com/posts/hDwwPwZmPmgqxeDFn/link-ethical-pick-up-artistry-clarisse-thorn", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%5BLINK%5D%20Ethical%20Pick-Up%20Artistry%20(Clarisse%20Thorn)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%5BLINK%5D%20Ethical%20Pick-Up%20Artistry%20(Clarisse%20Thorn)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDwwPwZmPmgqxeDFn%2Flink-ethical-pick-up-artistry-clarisse-thorn%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%5BLINK%5D%20Ethical%20Pick-Up%20Artistry%20(Clarisse%20Thorn)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDwwPwZmPmgqxeDFn%2Flink-ethical-pick-up-artistry-clarisse-thorn", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FhDwwPwZmPmgqxeDFn%2Flink-ethical-pick-up-artistry-clarisse-thorn", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 204, "htmlBody": "<p>Clarisse Thorn recently posted a useful article about <a href=\"http://clarissethorn.com/blog/2011/03/23/ethical-pick-up-artistry/\">Ethical Pick-Up Artistry</a>, bringing up a few basic critiques of traditional PUA and suggesting a few alternatives.</p>\n<blockquote>\n<p>Here&rsquo;s the thing: the current pickup artist subculture has a monopoly on <strong>effective</strong> advice for how to break down social interactions and talk to women. Not all of it works, but enough of it works that it draws guys in. As a pickup artist instructor once told me, &ldquo;When I first found the community I was horrified by how sleazy and gross it is, but I had never had a girlfriend and I told myself: dude, if you don&rsquo;t learn this stuff you&rsquo;re gonna die alone.&rdquo;</p>\n<p>I&rsquo;ve theorized that maybe feminists should provide good pickup advice, in an attempt to counterbalance some of the awfulness of the existing community. In the meantime, however, I figure the next best thing to do is to provide a list of less-misogynistic pickup artist instructors and sites, and a few very basic critiques.</p>\n</blockquote>\n<p><del>A proposal to formalize this</del> Not the same thing, but a discussion on forming a community to practice social artistry in general <a href=\"/lw/298/more_art_less_stink_taking_the_pu_out_of_pua/\">has been brought up on LW before</a>, but I'm not personally aware of anything coming out of that.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "hDwwPwZmPmgqxeDFn", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 28, "baseScore": 25, "extendedScore": null, "score": 5.3e-05, "legacy": true, "legacyId": "6672", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 18, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 115, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RZrw9wpEWEwWRTzLk"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T19:27:40.562Z", "modifiedAt": null, "url": null, "title": "A potential problem with using  Solomonoff induction as a prior", "slug": "a-potential-problem-with-using-solomonoff-induction-as-a", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.581Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JoshuaZ", "createdAt": "2010-04-05T04:07:01.214Z", "isAdmin": false, "displayName": "JoshuaZ"}, "userId": "fmTiLqp6mmXeLjwfN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/GZwCWnbtLBmji9A2i/a-potential-problem-with-using-solomonoff-induction-as-a", "pageUrlRelative": "/posts/GZwCWnbtLBmji9A2i/a-potential-problem-with-using-solomonoff-induction-as-a", "linkUrl": "https://www.lesswrong.com/posts/GZwCWnbtLBmji9A2i/a-potential-problem-with-using-solomonoff-induction-as-a", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20potential%20problem%20with%20using%20%20Solomonoff%20induction%20as%20a%20prior&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20potential%20problem%20with%20using%20%20Solomonoff%20induction%20as%20a%20prior%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZwCWnbtLBmji9A2i%2Fa-potential-problem-with-using-solomonoff-induction-as-a%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20potential%20problem%20with%20using%20%20Solomonoff%20induction%20as%20a%20prior%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZwCWnbtLBmji9A2i%2Fa-potential-problem-with-using-solomonoff-induction-as-a", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FGZwCWnbtLBmji9A2i%2Fa-potential-problem-with-using-solomonoff-induction-as-a", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 251, "htmlBody": "<p>There's a problem that has occurred to me that I haven't seen discussed anywhere: I don't think people actually wants to assign zero probability to all hypotheses which are not Turing computable. Consider the following hypothetical: we come up with a theory of everything that seems to explain all the laws of physics but there's a single open parameter (say the fine structure constant). We compute a large number of digits of this constant, and someone notices that when expressed in base 2, the nth digit seems to be 1 iff the nth Turing machine halts on the blank tape for some fairly natural ordering of all Turing machines. If we confirm this for a large number of digits (not necessarily consecutive digits- obviously some of the 0s won't be confirmable) shouldn't we consider the hypothesis the digits really are given by this simple but non-computable function? But if our priors assign zero probability to all non-computable hypotheses then this hypothesis must always be stuck with zero probability.</p>\n<p>If the universe is finite we could approximate this function with a function which was instead \"Halts within K\" steps where K is some large number, but intutively this seems like a more complicated hypothesis than the original one.</p>\n<p>I'm not sure what is a reasonable prior in this sort of context that handles this sort of thing. We don't want an uncountable set of priors. It might make sense to use something like hypotheses which are describable in Peano arithmetic or something like that.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"bTeiZr6YAEaSPQTC8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "GZwCWnbtLBmji9A2i", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 18, "extendedScore": null, "score": 6.995152159106368e-07, "legacy": true, "legacyId": "6674", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 13, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T21:09:20.244Z", "modifiedAt": null, "url": null, "title": "Only submit Meetups when you've declared a place and time", "slug": "only-submit-meetups-when-you-ve-declared-a-place-and-time", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.277Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eliezer_Yudkowsky", "createdAt": "2009-02-23T21:58:56.739Z", "isAdmin": false, "displayName": "Eliezer Yudkowsky"}, "userId": "nmk3nLpQE89dMRzzN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/go6JKYGpdivFPEQPL/only-submit-meetups-when-you-ve-declared-a-place-and-time", "pageUrlRelative": "/posts/go6JKYGpdivFPEQPL/only-submit-meetups-when-you-ve-declared-a-place-and-time", "linkUrl": "https://www.lesswrong.com/posts/go6JKYGpdivFPEQPL/only-submit-meetups-when-you-ve-declared-a-place-and-time", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Only%20submit%20Meetups%20when%20you've%20declared%20a%20place%20and%20time&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOnly%20submit%20Meetups%20when%20you've%20declared%20a%20place%20and%20time%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgo6JKYGpdivFPEQPL%2Fonly-submit-meetups-when-you-ve-declared-a-place-and-time%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Only%20submit%20Meetups%20when%20you've%20declared%20a%20place%20and%20time%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgo6JKYGpdivFPEQPL%2Fonly-submit-meetups-when-you-ve-declared-a-place-and-time", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fgo6JKYGpdivFPEQPL%2Fonly-submit-meetups-when-you-ve-declared-a-place-and-time", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 23, "htmlBody": "<p>Don't submit meetups to the main section of LW until you've picked a place and committed to being there at a particular time.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "go6JKYGpdivFPEQPL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 26, "extendedScore": null, "score": 6.995435943933963e-07, "legacy": true, "legacyId": "6675", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T21:20:04.645Z", "modifiedAt": null, "url": null, "title": "LessWrongers at Eastercon, 22-25 April?", "slug": "lesswrongers-at-eastercon-22-25-april", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:20.837Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RichardKennaway", "createdAt": "2009-03-09T13:46:28.196Z", "isAdmin": false, "displayName": "RichardKennaway"}, "userId": "unnmqpwtrwhyDt6q5", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8FoeZatK4x8sKqDv6/lesswrongers-at-eastercon-22-25-april", "pageUrlRelative": "/posts/8FoeZatK4x8sKqDv6/lesswrongers-at-eastercon-22-25-april", "linkUrl": "https://www.lesswrong.com/posts/8FoeZatK4x8sKqDv6/lesswrongers-at-eastercon-22-25-april", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20LessWrongers%20at%20Eastercon%2C%2022-25%20April%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALessWrongers%20at%20Eastercon%2C%2022-25%20April%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8FoeZatK4x8sKqDv6%2Flesswrongers-at-eastercon-22-25-april%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=LessWrongers%20at%20Eastercon%2C%2022-25%20April%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8FoeZatK4x8sKqDv6%2Flesswrongers-at-eastercon-22-25-april", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8FoeZatK4x8sKqDv6%2Flesswrongers-at-eastercon-22-25-april", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 88, "htmlBody": "<p><a id=\"more\"></a>Given that LessWrong readers tend to read science fiction, I wonder if any of us will be at this year's <a href=\"http://www.illustrious.org.uk/\">Eastercon</a>&nbsp;in Birmingham (UK), 22-25 April? I will be, from Friday afternoon until some time on Monday afternoon. Anyone else? Anyone wants to say hello, I look like <a href=\"http://www2.cmp.uea.ac.uk/~jrk/Pics/rk2010.jpg\">this</a>.</p>\n<p>ETA: Moved to main forum per custom, although this isn't quite a formal meetup arrangement. For one thing, the convention hasn't published a programme yet, so it isn't possible to schedule anything more definite than \"some time over the Easter weekend\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8FoeZatK4x8sKqDv6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 6.995465925497791e-07, "legacy": true, "legacyId": "6652", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T22:46:53.648Z", "modifiedAt": null, "url": null, "title": "Spaniard Lesswrongers, Unite!", "slug": "spaniard-lesswrongers-unite", "viewCount": null, "lastCommentedAt": "2018-11-08T03:21:38.032Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raw_Power", "createdAt": "2010-09-10T23:59:43.621Z", "isAdmin": false, "displayName": "Raw_Power"}, "userId": "kwSqcED9qTanFyNWG", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7Hf2MmvWMuzgy8qZ6/spaniard-lesswrongers-unite", "pageUrlRelative": "/posts/7Hf2MmvWMuzgy8qZ6/spaniard-lesswrongers-unite", "linkUrl": "https://www.lesswrong.com/posts/7Hf2MmvWMuzgy8qZ6/spaniard-lesswrongers-unite", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Spaniard%20Lesswrongers%2C%20Unite!&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpaniard%20Lesswrongers%2C%20Unite!%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Hf2MmvWMuzgy8qZ6%2Fspaniard-lesswrongers-unite%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Spaniard%20Lesswrongers%2C%20Unite!%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Hf2MmvWMuzgy8qZ6%2Fspaniard-lesswrongers-unite", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7Hf2MmvWMuzgy8qZ6%2Fspaniard-lesswrongers-unite", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 185, "htmlBody": "<p>Por favor contesten en la secci&oacute;n de comentarios si son Espa&ntilde;oles o residentes en Espa&ntilde;a. La idea es entrar en comunicaci&oacute;n, y poder discutir problemas de racionalidad propios de Espa&ntilde;a. Que &eacute;sta p&aacute;gina es muy EEUU-c&eacute;ntrica y aqu&iacute; tenemos problemas end&eacute;micos.</p>\n<p>&nbsp;</p>\n<p>Nota: Los hispanoamericanos tambi&eacute;n son los bienvenidos, anque solo sea por el idioma.</p>\n<p>Nota 2: Los dem&aacute;s hispanohablantes y residentes en Espa&ntilde;a tambi&eacute;n est&aacute;n bienvenidos: disculpad mi falta de imaginaci&oacute;n al asumir que no habr&iacute;a. De hecho, que venga cualquier Lesswronger que quiera, ya nos las arreglaremos para compaginar idiomas.</p>\n<p>&nbsp;</p>\n<p>Translation: Pease answer in the Comments section if you happen to be Spaniards or resident in Spain. The point of this thread is to establish contact, and be able to discuss rationality problems that are endemic to Spain. This site can sometimes feel far too US-Centric.</p>\n<p>&nbsp;</p>\n<p>Note: Latin Americans are welcome to join us, if only because we share a language.</p>\n<p>Note 2: Other residents of Spain, heck, any other lesswrongers are welcome. Sorry for assuming you wouldn't be there: I wansn't being exclusive, it's just that I wasn't expecting you. I forget Barcelona is a very cosmopolitan city.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7Hf2MmvWMuzgy8qZ6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 4, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6676", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-07T23:18:40.772Z", "modifiedAt": null, "url": null, "title": "Failure Modes sometimes correspond to Game Mechanics", "slug": "failure-modes-sometimes-correspond-to-game-mechanics", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:25.165Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Johnicholas", "createdAt": "2009-02-27T15:01:52.708Z", "isAdmin": false, "displayName": "Johnicholas"}, "userId": "kBvTXutfPytNtzPyD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WopDQ8WxyxSnPNZtd/failure-modes-sometimes-correspond-to-game-mechanics", "pageUrlRelative": "/posts/WopDQ8WxyxSnPNZtd/failure-modes-sometimes-correspond-to-game-mechanics", "linkUrl": "https://www.lesswrong.com/posts/WopDQ8WxyxSnPNZtd/failure-modes-sometimes-correspond-to-game-mechanics", "postedAtFormatted": "Thursday, April 7th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Failure%20Modes%20sometimes%20correspond%20to%20Game%20Mechanics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFailure%20Modes%20sometimes%20correspond%20to%20Game%20Mechanics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWopDQ8WxyxSnPNZtd%2Ffailure-modes-sometimes-correspond-to-game-mechanics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Failure%20Modes%20sometimes%20correspond%20to%20Game%20Mechanics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWopDQ8WxyxSnPNZtd%2Ffailure-modes-sometimes-correspond-to-game-mechanics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWopDQ8WxyxSnPNZtd%2Ffailure-modes-sometimes-correspond-to-game-mechanics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1223, "htmlBody": "<p>If you want to carry a brimming cup of coffee without spilling it, you may want to \"change\" your goal to instead primarily concentrate on humming. This is an example of a general pattern. It sometimes helps to focus on a nearby artificial goal rather than your actual goal. Let me call that strategy \"gamification\". There is a business strategy, also named \"gamification\", of adding game mechanics to a website in order to achieve various business goals. This is related but different. Here I'm referring to a strategy for problem solvers.</p>\n<p>We sometimes fail, and sometimes one failure is very similar to another failure. That is, there are characteristic ways that we fail. One of the primary ways that we can improve is to learn our failure modes and create external structures (pieces of paper, software tools) that check, protect against, or head off those forms of failure.</p>\n<p>For example, imagine this plan of checklist improvement:</p>\n<ol>\n<li>Change your normal way of working to include an explicit checklist (that starts empty).</li>\n<li>When you make a mistake:<ol>\n<li>Analyze what went wrong</li>\n<li>Try to generalize the particular incident to a category</li>\n<li>Add an item to your checklist.</li>\n</ol></li>\n</ol>\n<p>This is very simple and generic, but it is reasonable to believe that if you carefully and diligently followed this plan, your reliability would go up (with diminishing returns because your errors are also your opportunities for improvement). &nbsp;I have not read Mayo, but her \"error-theoretic\" philosophy of science might be applicable here.</p>\n<p>We can try to build a correspondence between failure modes, and game mechanics that attempt to cope for that failure mode.</p>\n<p><a id=\"more\"></a></p>\n<h3>Failure modes and their corresponding game mechanics</h3>\n<ul>\n<li>Overwhelmedness and Boredom/Apathy</li>\n</ul>\n<p>In Mihaly Csikszentmihalyi's flow diagram with axes of challenge versus mastery, flow appears when both the task challenge (or difficulty) and the individual's mastery of (or skill in) the task is high. If challenge is too high, you may feel overwhelmed and fail to make progress. An artificial, very easy goal may help. If the challenge is too low, you may feel bored or apathetic, and fail to make progress. An artificial, more difficult goal may help. Quests (see WorldOfWarcraft or almost any fantasy RPG) and Achievements &nbsp;are game mechanics that fit this general pattern of GoalSetting; easy achievements (see AchievementUnlocked) correspond to the overwhelmedness failure mode, and difficult achievements (see Nethack conducts) correspond to the boredom/apathy failure mode.&nbsp;</p>\n<ul>\n<li>Failures of balance.</li>\n</ul>\n<p>Sometimes it can be hard to maintain a good balance among multiple activities. For example, it is important to notice new good ideas. However, I tend to spend too much time pursuing novelty, and not enough time working on the best idea that I've found so far. &nbsp;There is a tradition of browser games (see KingdomOfLoathing) that enforce a kind of balance using a virtual currency of 'turns'. You accumulate turns slowly in real time, and essentially every action within the game uses up turns. This enforces not spending too much time playing the game (and increases the percieved value of the game via forced artificial scarcity, of course). If I gave myself 'explore dollars' for doing non-exploration (so-called exploit) tasks, and charged myself for doing exploration tasks (like reading arXiv or wikipedia), I could enforce a balance. If I were also prone to the opposite problem (\"A few months in the lab can often save whole hours in the library.\"), then I might use two currencies; exploring costs explore points but rewards with exploit points, and exploiting costs exploit points but rewards with explore ponts. (Virtual currencies are ubiquitous in games, and they can be used for many purposes; I expect to find them able to be placed accross from many different failure modes.)</p>\n<ul>\n<li>Lapsing from a habit</li>\n</ul>\n<p>I might fail by lapsing from a good habit, of exercise, practice or measurement. A chaining appointment mechanic might help prevent that. For example, Farmville has a mechanic where players plant crops, but cannot harvest them until a longish real-time interval later (e.g. 24 hours), and ripe crops rot if they are not harvested. DontBreakTheChain is &nbsp;(see http://dontbreakthechain.com/) might be an even better correspondence. Sometimes people refine the chain mechanic with a Mario-style \"two hit point\" mechanic. (Mario is either big or small. If he is damaged while big, he becomes small. If he is damaged while small, he loses.) That is, a one-day break in the chain is recoverable, so long as it is only one day, and followed by \"sufficiently many\" consecutive successful days.</p>\n<ul>\n<li>DistractedByContextSwitch and YakShaving</li>\n</ul>\n<p>There are various failure modes regarding the subgoal stack. On the one hand, there is a distraction failure mode when I switch contexts to achieve some subgoal, but become distracted, and forget, at least for a while, to pop the stack and return to my original goal. On the other hand, YakShaving is following your goal/subgoal stack too rigidly and too deeply. In either case, it may be valuable to keep your entire current goal/subgoal stack in a nearby external memory device (for example index cards or a todolist tool). Many games have a UI component that displays the next step of the the current quest. I don't know of a game with a UI component intended to prevent YakShaving, but it is comprehensible - simply display the top of the stack as well as the bottom.</p>\n<ul>\n<li>Deadline-sensitive work style</li>\n</ul>\n<p>There are failure modes associated with deadline-sensitive rates of working. People tend to work differently when they percieve time pressure than when they do not percieve time pressure. You might call this failure mode Parkinson's Law when you're thinking of the pressured work as more efficient, HalfAssedCompletion when you're thinking of the pressured work as lowered quality, or DeadlineBrinksmanship when you're thinking of the tendency for all tasks, no matter how much slack they have, to have the same risk of crossing the deadline.&nbsp;</p>\n<p>This can make scheduling and planning (which are already difficult) even more difficult. For example, a planner may prefer announcing an optimistic schedule, because they think that even with inevitable slippage, the optimistic schedule will be completed faster than a schedule conservative enough to avoid slippage.</p>\n<p>Of course many games have timed goals, and the pomodoro technique and other forms of timeboxing are standard productivity concepts. The only refinement that this \"game mechanic\" suggests is making the countdown more visible and salient.</p>\n<h3>Conclusion</h3>\n<ul>\n<li>accumulating an explicit repository of failure modes can be valuable</li>\n<li>game mechanics often correspond to failure modes</li>\n<li>explicitly structuring your work habits with game mechanics can be fun, and perhaps productive.</li>\n</ul>\n<h3>Future work</h3>\n<p>There is an indecisiveness failure mode that I think of as \"BuridansAss\". The parable is that the ass is as hungry is it is thirsty and is exactly positioned between water and food, and so dies without choosing. In my case, it is more cyclical - when I am trying to work on one thing, working on some other thing seems more valuable or more enjoyable. I don't know of a game mechanic corresponding to this failure mode.</p>\n<p>Another failure mode I've noticed is \"Blub\" (see Paul Graham's essay). This is when I see something I don't understand at all, and instead of paying it closer attention and/or storing it away carefully, I ignore it.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"mmfk47obrNKhN6waD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WopDQ8WxyxSnPNZtd", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 22, "baseScore": 25, "extendedScore": null, "score": 6.995797028134323e-07, "legacy": true, "legacyId": "6678", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>If you want to carry a brimming cup of coffee without spilling it, you may want to \"change\" your goal to instead primarily concentrate on humming. This is an example of a general pattern. It sometimes helps to focus on a nearby artificial goal rather than your actual goal. Let me call that strategy \"gamification\". There is a business strategy, also named \"gamification\", of adding game mechanics to a website in order to achieve various business goals. This is related but different. Here I'm referring to a strategy for problem solvers.</p>\n<p>We sometimes fail, and sometimes one failure is very similar to another failure. That is, there are characteristic ways that we fail. One of the primary ways that we can improve is to learn our failure modes and create external structures (pieces of paper, software tools) that check, protect against, or head off those forms of failure.</p>\n<p>For example, imagine this plan of checklist improvement:</p>\n<ol>\n<li>Change your normal way of working to include an explicit checklist (that starts empty).</li>\n<li>When you make a mistake:<ol>\n<li>Analyze what went wrong</li>\n<li>Try to generalize the particular incident to a category</li>\n<li>Add an item to your checklist.</li>\n</ol></li>\n</ol>\n<p>This is very simple and generic, but it is reasonable to believe that if you carefully and diligently followed this plan, your reliability would go up (with diminishing returns because your errors are also your opportunities for improvement). &nbsp;I have not read Mayo, but her \"error-theoretic\" philosophy of science might be applicable here.</p>\n<p>We can try to build a correspondence between failure modes, and game mechanics that attempt to cope for that failure mode.</p>\n<p><a id=\"more\"></a></p>\n<h3 id=\"Failure_modes_and_their_corresponding_game_mechanics\">Failure modes and their corresponding game mechanics</h3>\n<ul>\n<li>Overwhelmedness and Boredom/Apathy</li>\n</ul>\n<p>In Mihaly Csikszentmihalyi's flow diagram with axes of challenge versus mastery, flow appears when both the task challenge (or difficulty) and the individual's mastery of (or skill in) the task is high. If challenge is too high, you may feel overwhelmed and fail to make progress. An artificial, very easy goal may help. If the challenge is too low, you may feel bored or apathetic, and fail to make progress. An artificial, more difficult goal may help. Quests (see WorldOfWarcraft or almost any fantasy RPG) and Achievements &nbsp;are game mechanics that fit this general pattern of GoalSetting; easy achievements (see AchievementUnlocked) correspond to the overwhelmedness failure mode, and difficult achievements (see Nethack conducts) correspond to the boredom/apathy failure mode.&nbsp;</p>\n<ul>\n<li>Failures of balance.</li>\n</ul>\n<p>Sometimes it can be hard to maintain a good balance among multiple activities. For example, it is important to notice new good ideas. However, I tend to spend too much time pursuing novelty, and not enough time working on the best idea that I've found so far. &nbsp;There is a tradition of browser games (see KingdomOfLoathing) that enforce a kind of balance using a virtual currency of 'turns'. You accumulate turns slowly in real time, and essentially every action within the game uses up turns. This enforces not spending too much time playing the game (and increases the percieved value of the game via forced artificial scarcity, of course). If I gave myself 'explore dollars' for doing non-exploration (so-called exploit) tasks, and charged myself for doing exploration tasks (like reading arXiv or wikipedia), I could enforce a balance. If I were also prone to the opposite problem (\"A few months in the lab can often save whole hours in the library.\"), then I might use two currencies; exploring costs explore points but rewards with exploit points, and exploiting costs exploit points but rewards with explore ponts. (Virtual currencies are ubiquitous in games, and they can be used for many purposes; I expect to find them able to be placed accross from many different failure modes.)</p>\n<ul>\n<li>Lapsing from a habit</li>\n</ul>\n<p>I might fail by lapsing from a good habit, of exercise, practice or measurement. A chaining appointment mechanic might help prevent that. For example, Farmville has a mechanic where players plant crops, but cannot harvest them until a longish real-time interval later (e.g. 24 hours), and ripe crops rot if they are not harvested. DontBreakTheChain is &nbsp;(see http://dontbreakthechain.com/) might be an even better correspondence. Sometimes people refine the chain mechanic with a Mario-style \"two hit point\" mechanic. (Mario is either big or small. If he is damaged while big, he becomes small. If he is damaged while small, he loses.) That is, a one-day break in the chain is recoverable, so long as it is only one day, and followed by \"sufficiently many\" consecutive successful days.</p>\n<ul>\n<li>DistractedByContextSwitch and YakShaving</li>\n</ul>\n<p>There are various failure modes regarding the subgoal stack. On the one hand, there is a distraction failure mode when I switch contexts to achieve some subgoal, but become distracted, and forget, at least for a while, to pop the stack and return to my original goal. On the other hand, YakShaving is following your goal/subgoal stack too rigidly and too deeply. In either case, it may be valuable to keep your entire current goal/subgoal stack in a nearby external memory device (for example index cards or a todolist tool). Many games have a UI component that displays the next step of the the current quest. I don't know of a game with a UI component intended to prevent YakShaving, but it is comprehensible - simply display the top of the stack as well as the bottom.</p>\n<ul>\n<li>Deadline-sensitive work style</li>\n</ul>\n<p>There are failure modes associated with deadline-sensitive rates of working. People tend to work differently when they percieve time pressure than when they do not percieve time pressure. You might call this failure mode Parkinson's Law when you're thinking of the pressured work as more efficient, HalfAssedCompletion when you're thinking of the pressured work as lowered quality, or DeadlineBrinksmanship when you're thinking of the tendency for all tasks, no matter how much slack they have, to have the same risk of crossing the deadline.&nbsp;</p>\n<p>This can make scheduling and planning (which are already difficult) even more difficult. For example, a planner may prefer announcing an optimistic schedule, because they think that even with inevitable slippage, the optimistic schedule will be completed faster than a schedule conservative enough to avoid slippage.</p>\n<p>Of course many games have timed goals, and the pomodoro technique and other forms of timeboxing are standard productivity concepts. The only refinement that this \"game mechanic\" suggests is making the countdown more visible and salient.</p>\n<h3 id=\"Conclusion\">Conclusion</h3>\n<ul>\n<li>accumulating an explicit repository of failure modes can be valuable</li>\n<li>game mechanics often correspond to failure modes</li>\n<li>explicitly structuring your work habits with game mechanics can be fun, and perhaps productive.</li>\n</ul>\n<h3 id=\"Future_work\">Future work</h3>\n<p>There is an indecisiveness failure mode that I think of as \"BuridansAss\". The parable is that the ass is as hungry is it is thirsty and is exactly positioned between water and food, and so dies without choosing. In my case, it is more cyclical - when I am trying to work on one thing, working on some other thing seems more valuable or more enjoyable. I don't know of a game mechanic corresponding to this failure mode.</p>\n<p>Another failure mode I've noticed is \"Blub\" (see Paul Graham's essay). This is when I see something I don't understand at all, and instead of paying it closer attention and/or storing it away carefully, I ignore it.</p>", "sections": [{"title": "Failure modes and their corresponding game mechanics", "anchor": "Failure_modes_and_their_corresponding_game_mechanics", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Future work", "anchor": "Future_work", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "16 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-08T00:08:03.607Z", "modifiedAt": null, "url": null, "title": "Help re:Less Wrong Meetup please?", "slug": "help-re-less-wrong-meetup-please", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:20.984Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Goobahman", "createdAt": "2011-01-13T05:09:28.962Z", "isAdmin": false, "displayName": "Goobahman"}, "userId": "cidN68rGuy4wwnvFp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aa8weBC6ajvirjLrB/help-re-less-wrong-meetup-please", "pageUrlRelative": "/posts/aa8weBC6ajvirjLrB/help-re-less-wrong-meetup-please", "linkUrl": "https://www.lesswrong.com/posts/aa8weBC6ajvirjLrB/help-re-less-wrong-meetup-please", "postedAtFormatted": "Friday, April 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Help%20re%3ALess%20Wrong%20Meetup%20please%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHelp%20re%3ALess%20Wrong%20Meetup%20please%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Faa8weBC6ajvirjLrB%2Fhelp-re-less-wrong-meetup-please%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Help%20re%3ALess%20Wrong%20Meetup%20please%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Faa8weBC6ajvirjLrB%2Fhelp-re-less-wrong-meetup-please", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Faa8weBC6ajvirjLrB%2Fhelp-re-less-wrong-meetup-please", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 153, "htmlBody": "<p>Hi Everyone,</p>\r\n<p>I've been conducting a LW meetup in West Sydney. had 3 somewhat succesful sessions. Covered the following topics:</p>\r\n<p>1. What is rationality? Who uses it? Why be less wrong?</p>\r\n<p>2. Map and Territroy</p>\r\n<p>3. Belief: functions, proper and imporper and other things pertaining.</p>\r\n<p>I'm wondering what would be a good topic for the next session, so any suggestions would be much appreciated. I'm finding whilst people enjoy the conversations for the most part, they find it hard to make it applicable and marry it back to real life situations.</p>\r\n<p>Any ideas on how I can help communicate that what we study and do at the meet up is relevant and applicable in their day to day lives? And what would be a good topic to do this on?</p>\r\n<p>I get the feeling this will require people to sort of open up and share themselves with the group. Any good ways of cultivating that type of environment?</p>\r\n<p>&nbsp;</p>\r\n<p>Thanks in advance.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aa8weBC6ajvirjLrB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 6.99593489245596e-07, "legacy": true, "legacyId": "6679", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-08T02:41:49.558Z", "modifiedAt": null, "url": null, "title": "Meta: How should LW account deletion work?", "slug": "meta-how-should-lw-account-deletion-work", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:25.849Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "matt", "createdAt": "2009-02-24T03:21:23.753Z", "isAdmin": false, "displayName": "matt"}, "userId": "PXCeXYzvwEeqqitqH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KzdkdfJTtmBwWmz6i/meta-how-should-lw-account-deletion-work", "pageUrlRelative": "/posts/KzdkdfJTtmBwWmz6i/meta-how-should-lw-account-deletion-work", "linkUrl": "https://www.lesswrong.com/posts/KzdkdfJTtmBwWmz6i/meta-how-should-lw-account-deletion-work", "postedAtFormatted": "Friday, April 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20How%20should%20LW%20account%20deletion%20work%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20How%20should%20LW%20account%20deletion%20work%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKzdkdfJTtmBwWmz6i%2Fmeta-how-should-lw-account-deletion-work%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20How%20should%20LW%20account%20deletion%20work%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKzdkdfJTtmBwWmz6i%2Fmeta-how-should-lw-account-deletion-work", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKzdkdfJTtmBwWmz6i%2Fmeta-how-should-lw-account-deletion-work", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p>At&nbsp;2011-04-08 LW user account deletion is broken. We (Trike) will fix it&hellip; but how should it work?</p>\n<p><strong>Options: &nbsp;</strong></p>\n<ol>\n<li>Easy complete deletion: At the click of a button you can remove your account, all of your posts, and all of your comments. It's just <em>that easy</em> to scrub your activity from the site.</li>\n<li>Delete = Disable account: The account deletion process removes your ability to log in and your user page. Your posts and comments remain. (You get warned that you're about to lose the ability to change anything you've previously posted and that your username will continue to be associated with your previous account activity.) Actually deleting everything requires you to do it manually.</li>\n</ol>\n<div>I favour 2 (Delete = Disable account). Poking a hole into all of the conversations you've been a part of should be hard - it reduces the quality of the site's archive.</div>\n<div>I've made three comments below: \"VOTE: Easy complete deletion\", \"VOTE:&nbsp;Delete = Disable account\", and \"VOTE: Karma balance\". What do y'reckon?</div>\n<div><br /></div>\n<div>(Detail - Under the&nbsp;Delete = Disable account option:&nbsp;Your username would continue to be unavailable to others. Your user account page would be replaced with a \"User account deleted\" page. Your old account activity would remain and link back to the \"Account deleted\" page.)</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KzdkdfJTtmBwWmz6i", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 6.996364217353267e-07, "legacy": true, "legacyId": "6687", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 50, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-08T17:13:52.387Z", "modifiedAt": null, "url": null, "title": "What is wrong with \"Traditional Rationality\"?", "slug": "what-is-wrong-with-traditional-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.906Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Perplexed", "createdAt": "2010-07-22T02:17:37.444Z", "isAdmin": false, "displayName": "Perplexed"}, "userId": "jj9aBsS9xsGPWKq3n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WeQv9LSCj9nYXoTwJ/what-is-wrong-with-traditional-rationality", "pageUrlRelative": "/posts/WeQv9LSCj9nYXoTwJ/what-is-wrong-with-traditional-rationality", "linkUrl": "https://www.lesswrong.com/posts/WeQv9LSCj9nYXoTwJ/what-is-wrong-with-traditional-rationality", "postedAtFormatted": "Friday, April 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20What%20is%20wrong%20with%20%22Traditional%20Rationality%22%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhat%20is%20wrong%20with%20%22Traditional%20Rationality%22%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWeQv9LSCj9nYXoTwJ%2Fwhat-is-wrong-with-traditional-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=What%20is%20wrong%20with%20%22Traditional%20Rationality%22%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWeQv9LSCj9nYXoTwJ%2Fwhat-is-wrong-with-traditional-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWeQv9LSCj9nYXoTwJ%2Fwhat-is-wrong-with-traditional-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 231, "htmlBody": "<p>In <a title=\"LessWrong wiki\" href=\"http://wiki.lesswrong.com/wiki/Traditional_rationality\">several places in the sequences</a>, Eliezer writes condescendingly about \"Traditional Rationality\".&nbsp; The impression given is that Traditional Rationality was OK in its day, but that today we have better varieties of rationality available.</p>\n<p>That is fine, except that it is unclear to me just what the traditional kind of rationality included, and it is also unclear just what it failed to include.&nbsp; In <a href=\"/lw/k1/no_one_can_exempt_you_from_rationalitys_laws/\">one essay</a>, Eliezer seems to be saying that Traditional Rationality was too concerned with process, whereas it should have been concerned with <em>winning</em>.&nbsp; In other passages, it seems that the missing ingredient in the traditional version was Bayesianism (a la Jaynes).&nbsp; Or sometimes, the missing ingredient seems to be an understanding of biases (a la Kahneman and Tversky).</p>\n<p>In <a href=\"/lw/iy/my_wild_and_reckless_youth/\">this essay</a>, Eliezer laments that being a traditional rationalist was not enough to keep him from devising a Mysterious Answer to a mysterious question.&nbsp; That puzzles me because I would have thought that traditional ideas from Peirce, Popper, and Korzybski would have been sufficient to avoid that error.&nbsp; So apparently I fail to understand either what a Mysterious Answer is or just how weak the traditional form of rationality actually is.</p>\n<p>Can anyone help to clarify this?&nbsp; By \"Traditional Rationality\", does Eliezer mean to designate a particular collection of ideas, or does he use it more loosely to indicate any thinking that is not quite up to his level?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WeQv9LSCj9nYXoTwJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 27, "extendedScore": null, "score": 5.4e-05, "legacy": true, "legacyId": "6692", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 97, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eY45uCCX7DdwJ4Jha", "DwtYPRuCxpXTrzG9m"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-08T18:09:06.954Z", "modifiedAt": null, "url": null, "title": "Profile of Eric Schadt", "slug": "profile-of-eric-schadt", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.923Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/t5XZwygSFW6HpTfgf/profile-of-eric-schadt", "pageUrlRelative": "/posts/t5XZwygSFW6HpTfgf/profile-of-eric-schadt", "linkUrl": "https://www.lesswrong.com/posts/t5XZwygSFW6HpTfgf/profile-of-eric-schadt", "postedAtFormatted": "Friday, April 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Profile%20of%20Eric%20Schadt&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AProfile%20of%20Eric%20Schadt%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft5XZwygSFW6HpTfgf%2Fprofile-of-eric-schadt%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Profile%20of%20Eric%20Schadt%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft5XZwygSFW6HpTfgf%2Fprofile-of-eric-schadt", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Ft5XZwygSFW6HpTfgf%2Fprofile-of-eric-schadt", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<p>This <a href=\"http://www.esquire.com/print-this/eric-schadt-0411?page=all\">article</a> leaves me with a very mixed impression-- it's excessively gosh-wow, but it matches my beliefs that things are generally more complex than they look, and this is especially true about biology.</p>\n<p>Schadt doesn't seem to have much web presence, which makes it harder to judge anything about what he's doing.</p>\n<p>His background was very intellectually deprived-- he's ended up doing serious biology (or at least in high-status jobs in the field) through a combination of moderately good luck and extremely high drive. It leaves me wondering how much talent just gets lost.</p>\n<p>ETA: I forgot to mention that the reason I posted is that if Schadt is right that biological systems are extremely complex, that it isn't feasible to develop drugs based on counteracting the effects of single genes, but that this complexity can be met by people doing networked science, then it's very important.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "t5XZwygSFW6HpTfgf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 3, "extendedScore": null, "score": 6.998954270517983e-07, "legacy": true, "legacyId": "6693", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-08T20:48:23.889Z", "modifiedAt": null, "url": null, "title": "Are Functional languages the future of programming?", "slug": "are-functional-languages-the-future-of-programming", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.228Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jsalvatier", "createdAt": "2009-03-02T09:27:42.415Z", "isAdmin": false, "displayName": "jsalvatier"}, "userId": "r5LffMcjHLHZXtvKt", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jLaW3tS68NWQ3yQzL/are-functional-languages-the-future-of-programming", "pageUrlRelative": "/posts/jLaW3tS68NWQ3yQzL/are-functional-languages-the-future-of-programming", "linkUrl": "https://www.lesswrong.com/posts/jLaW3tS68NWQ3yQzL/are-functional-languages-the-future-of-programming", "postedAtFormatted": "Friday, April 8th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Are%20Functional%20languages%20the%20future%20of%20programming%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAre%20Functional%20languages%20the%20future%20of%20programming%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLaW3tS68NWQ3yQzL%2Fare-functional-languages-the-future-of-programming%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Are%20Functional%20languages%20the%20future%20of%20programming%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLaW3tS68NWQ3yQzL%2Fare-functional-languages-the-future-of-programming", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjLaW3tS68NWQ3yQzL%2Fare-functional-languages-the-future-of-programming", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 328, "htmlBody": "<p>Because I have been <a href=\"/lw/55b/what_are_you_working_on_april_2011/3v7q\">learning</a> about Type Theory, I have become much more aware of and interested in <a href=\"http://en.wikipedia.org/wiki/Functional_programming\">Functional Programming</a>.&nbsp;</p>\n<p>If you are unfamiliar with functional programming, <a href=\"http://book.realworldhaskell.org/read/\">Real World Haskell</a> <a href=\"http://book.realworldhaskell.org/read/why-functional-programming-why-haskell.html\">describes</a>&nbsp;functional programming like this:&nbsp;</p>\n<blockquote>\n<p>In Haskell [and other functional languages], we de-emphasise code that modifies data. Instead, we focus on functions that take immutable values as input and produce new values as output. Given the same inputs, these functions always return the same results. This is a core idea behind functional programming.&nbsp;</p>\n<p>Along with not modifying data, our Haskell functions usually don't talk to the external world; we call these functions pure. We make a strong distinction between pure code and the parts of our programs that read or write files, communicate over network connections, or make robot arms move. This makes it easier to organize, reason about, and test our programs.</p>\n</blockquote>\n<p>Because of this functional languages have a number of interesting differences with traditional programming. In functional programming:</p>\n<p>&nbsp;</p>\n<ul>\n<li>Programming is lot more like math. Programs are often elegant and terse.</li>\n<li>It is much easier to reason about programs, including proving things about them (termination, lack of errors etc.). This means compilers have much more room to automatically optimize a program, automatically parallelizing code, merging repeated operations etc.</li>\n<li>Static typing helps (and requires) you find and correct a large fraction of trivial bugs without running the program.</li>\n<li>Pure code means doing things with side effects (like I/O) requires significantly more thought to start to understand, but also makes side effects more explicit.</li>\n<li>Program evaluation is defined much more directly on the syntax of the language.&nbsp;</li>\n</ul>\n<div>After having learned and experimented a bit with functional languages, it seems like they are the future of programming languages. It is my impression that functional languages are more popular among LWers than among programmers in general. Do other LWers share my assessment? Are there other things about functional languages I should be aware of?</div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jLaW3tS68NWQ3yQzL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 9, "extendedScore": null, "score": 6.999396594493565e-07, "legacy": true, "legacyId": "6694", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T00:11:39.708Z", "modifiedAt": null, "url": null, "title": "New FAI paper: 'Learning What to Value' by Daniel Dewey", "slug": "new-fai-paper-learning-what-to-value-by-daniel-dewey", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:39.203Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/KEmXavQt8sCrLKCJm/new-fai-paper-learning-what-to-value-by-daniel-dewey", "pageUrlRelative": "/posts/KEmXavQt8sCrLKCJm/new-fai-paper-learning-what-to-value-by-daniel-dewey", "linkUrl": "https://www.lesswrong.com/posts/KEmXavQt8sCrLKCJm/new-fai-paper-learning-what-to-value-by-daniel-dewey", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20FAI%20paper%3A%20'Learning%20What%20to%20Value'%20by%20Daniel%20Dewey&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20FAI%20paper%3A%20'Learning%20What%20to%20Value'%20by%20Daniel%20Dewey%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKEmXavQt8sCrLKCJm%2Fnew-fai-paper-learning-what-to-value-by-daniel-dewey%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20FAI%20paper%3A%20'Learning%20What%20to%20Value'%20by%20Daniel%20Dewey%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKEmXavQt8sCrLKCJm%2Fnew-fai-paper-learning-what-to-value-by-daniel-dewey", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FKEmXavQt8sCrLKCJm%2Fnew-fai-paper-learning-what-to-value-by-daniel-dewey", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 121, "htmlBody": "<p><a href=\"http://www.danieldewey.net/\">Daniel Dewey</a>, '<a href=\"http://www.danieldewey.net/dewey-learning-what-to-value.pdf\">Learning What to Value</a>'</p>\n<p><em>Abstract</em>: I.J. Good's theory of an \"intelligence explosion\" predicts that ultraintelligent agents will undergo a process of repeated self-improvement. In the wake of such an event, how well our values are fulfilled will depend on whether these ultraintelligent agents continue to act desirably and as intended. We examine several design approaches, based on AIXI, that could be used to create ultraintelligent agents. In each case, we analyze the design conditions required for a successful, well-behaved ultraintelligent agent to be created. Our main contribution is an examination of value-learners, agents that learn a utility function from experience. We conclude that the design conditions on value-learners are in some ways less demanding than those on other design approaches.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "KEmXavQt8sCrLKCJm", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 18, "extendedScore": null, "score": 6.999967374314829e-07, "legacy": true, "legacyId": "6696", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T02:50:32.851Z", "modifiedAt": null, "url": null, "title": "Human errors, human values", "slug": "human-errors-human-values", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:36.218Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uHrAy4yvuyzKPdRF7/human-errors-human-values", "pageUrlRelative": "/posts/uHrAy4yvuyzKPdRF7/human-errors-human-values", "linkUrl": "https://www.lesswrong.com/posts/uHrAy4yvuyzKPdRF7/human-errors-human-values", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Human%20errors%2C%20human%20values&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHuman%20errors%2C%20human%20values%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuHrAy4yvuyzKPdRF7%2Fhuman-errors-human-values%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Human%20errors%2C%20human%20values%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuHrAy4yvuyzKPdRF7%2Fhuman-errors-human-values", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuHrAy4yvuyzKPdRF7%2Fhuman-errors-human-values", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 357, "htmlBody": "<h3>The trolley problem</h3>\n<p>In 2009, a pair of computer scientists published a paper enabling computers to <a href=\"http://www.livescience.com/5729-robots-ethical-decisions.html\">behave like humans&nbsp;on the trolley problem</a> (PDF&nbsp;<a href=\"http://centria.fct.unl.pt/~lmp/publications/online-papers/epia07-morals.pdf\">here</a>). &nbsp;They developed&nbsp;a logic that a computer could use to justify not pushing one person onto the tracks in order to save five other people.&nbsp;&nbsp;They described this feat as showing \"how moral decisions can be drawn computationally&nbsp;by using prospective logic programs.\"</p>\n<p>I would describe it as devoting a lot of time and effort to cripple a reasoning system by encoding human irrationality into its logic.</p>\n<p>Which view is correct?</p>\n<h3>Dust specks</h3>\n<p>Eliezer <a href=\"/lw/kn/torture_vs_dust_specks/\">argued</a>&nbsp;that we should prefer 1 person being tortured for 50 years over 3^^^3 people each once getting a barely-noticeable dust speck in their eyes.&nbsp; Most people choose the many dust specks over the torture.&nbsp; Some people argued that \"human values\" includes having a utility aggregation function that rounds tiny (absolute value) utilities to zero, thus giving the \"dust specks\" answer.&nbsp; No, Eliezer said; this was an error in human reasoning.&nbsp; Is it an error, or a value?</p>\n<h3>Sex vs. punishment</h3>\n<p>In <a href=\"/lw/4x9/crime_and_punishment/\">Crime and punishment</a>, I argued that people <em>want</em>&nbsp;to punish criminals, even if there is a painless, less-costly way to prevent crime. &nbsp;This means that people <em>value</em>&nbsp;punishing criminals. &nbsp;This value may have evolved to accomplish the social goal of reducing crime. &nbsp;Most readers agreed that, since we can deduce this underlying reason, and accomplish it more effectively through reasoning, preferring to punish criminals is an error in judgement.</p>\n<p>Most people <em>want</em>&nbsp;to have sex. &nbsp;This value evolved to accomplish the goal of reproducing. &nbsp;Since we can deduce this underlying reason, and accomplish it more efficiently than by going out to bars every evening for ten years, is this desire for sex an error in judgement that we should erase?</p>\n<h3>The problem for Friendly AI</h3>\n<p>Until you come up with a procedure for determining, in general, when something is a value and when it is an error, there is no point in trying to design artificial intelligences that encode human \"values\".</p>\n<p>(P.S. - I think that necessary, but not sufficient, preconditions for developing such a procedure, are to agree that only utilitarian ethics are valid, and to agree on an aggregation function.)</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ouT6wKhACJRouGokM": 1, "nSHiKwWyMZFdZg5qt": 1, "ZTRNmvQGgoYiymYnq": 1, "sYm3HiWcfZvrGu3ui": 1, "LMFBzsJaCRADQqw3F": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uHrAy4yvuyzKPdRF7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 43, "baseScore": 41, "extendedScore": null, "score": 0.000127, "legacy": true, "legacyId": "6683", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<h3 id=\"The_trolley_problem\">The trolley problem</h3>\n<p>In 2009, a pair of computer scientists published a paper enabling computers to <a href=\"http://www.livescience.com/5729-robots-ethical-decisions.html\">behave like humans&nbsp;on the trolley problem</a> (PDF&nbsp;<a href=\"http://centria.fct.unl.pt/~lmp/publications/online-papers/epia07-morals.pdf\">here</a>). &nbsp;They developed&nbsp;a logic that a computer could use to justify not pushing one person onto the tracks in order to save five other people.&nbsp;&nbsp;They described this feat as showing \"how moral decisions can be drawn computationally&nbsp;by using prospective logic programs.\"</p>\n<p>I would describe it as devoting a lot of time and effort to cripple a reasoning system by encoding human irrationality into its logic.</p>\n<p>Which view is correct?</p>\n<h3 id=\"Dust_specks\">Dust specks</h3>\n<p>Eliezer <a href=\"/lw/kn/torture_vs_dust_specks/\">argued</a>&nbsp;that we should prefer 1 person being tortured for 50 years over 3^^^3 people each once getting a barely-noticeable dust speck in their eyes.&nbsp; Most people choose the many dust specks over the torture.&nbsp; Some people argued that \"human values\" includes having a utility aggregation function that rounds tiny (absolute value) utilities to zero, thus giving the \"dust specks\" answer.&nbsp; No, Eliezer said; this was an error in human reasoning.&nbsp; Is it an error, or a value?</p>\n<h3 id=\"Sex_vs__punishment\">Sex vs. punishment</h3>\n<p>In <a href=\"/lw/4x9/crime_and_punishment/\">Crime and punishment</a>, I argued that people <em>want</em>&nbsp;to punish criminals, even if there is a painless, less-costly way to prevent crime. &nbsp;This means that people <em>value</em>&nbsp;punishing criminals. &nbsp;This value may have evolved to accomplish the social goal of reducing crime. &nbsp;Most readers agreed that, since we can deduce this underlying reason, and accomplish it more effectively through reasoning, preferring to punish criminals is an error in judgement.</p>\n<p>Most people <em>want</em>&nbsp;to have sex. &nbsp;This value evolved to accomplish the goal of reproducing. &nbsp;Since we can deduce this underlying reason, and accomplish it more efficiently than by going out to bars every evening for ten years, is this desire for sex an error in judgement that we should erase?</p>\n<h3 id=\"The_problem_for_Friendly_AI\">The problem for Friendly AI</h3>\n<p>Until you come up with a procedure for determining, in general, when something is a value and when it is an error, there is no point in trying to design artificial intelligences that encode human \"values\".</p>\n<p>(P.S. - I think that necessary, but not sufficient, preconditions for developing such a procedure, are to agree that only utilitarian ethics are valid, and to agree on an aggregation function.)</p>", "sections": [{"title": "The trolley problem", "anchor": "The_trolley_problem", "level": 1}, {"title": "Dust specks", "anchor": "Dust_specks", "level": 1}, {"title": "Sex vs. punishment", "anchor": "Sex_vs__punishment", "level": 1}, {"title": "The problem for Friendly AI", "anchor": "The_problem_for_Friendly_AI", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "138 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 138, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["3wYTFWY3LKQCnAptN", "SCXaRKGhQPkJCMmpm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T03:09:21.934Z", "modifiedAt": null, "url": null, "title": "Mammography problem from 'Intro to Bayes' in my own words/picture", "slug": "mammography-problem-from-intro-to-bayes-in-my-own-words", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.451Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jwhendy", "createdAt": "2011-01-04T19:53:21.160Z", "isAdmin": false, "displayName": "jwhendy"}, "userId": "ZaJctSZkCvg7qvSEC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4NM4xA6pTYTZ3fEqN/mammography-problem-from-intro-to-bayes-in-my-own-words", "pageUrlRelative": "/posts/4NM4xA6pTYTZ3fEqN/mammography-problem-from-intro-to-bayes-in-my-own-words", "linkUrl": "https://www.lesswrong.com/posts/4NM4xA6pTYTZ3fEqN/mammography-problem-from-intro-to-bayes-in-my-own-words", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Mammography%20problem%20from%20'Intro%20to%20Bayes'%20in%20my%20own%20words%2Fpicture&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMammography%20problem%20from%20'Intro%20to%20Bayes'%20in%20my%20own%20words%2Fpicture%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4NM4xA6pTYTZ3fEqN%2Fmammography-problem-from-intro-to-bayes-in-my-own-words%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Mammography%20problem%20from%20'Intro%20to%20Bayes'%20in%20my%20own%20words%2Fpicture%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4NM4xA6pTYTZ3fEqN%2Fmammography-problem-from-intro-to-bayes-in-my-own-words", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4NM4xA6pTYTZ3fEqN%2Fmammography-problem-from-intro-to-bayes-in-my-own-words", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 302, "htmlBody": "<p>I've been reading through the sequences, and am currently working through the <a href=\"http://yudkowsky.net/rational/bayes\">Intro to Bayes' Theorem</a> (by the fact that I'm reading the Intro to Bayes (finally), you can tell that I'm pretty early in the process). It's been quite thought provoking. I'm finally getting questions right more reliably, and wanted to share one of the visualization tools that helped me, at least. There are many \"applets\" strewn about, written in Java, that help one to visualize what the various probability components are doing. In the mammography example, at least, an the idea of a <a href=\"http://en.wikipedia.org/wiki/Sieve\">sieve</a>&nbsp;popped into my head as a neat way to think about what the test is doing.</p>\n<p>I'm planning to take fairly extensive notes (more about that in a soon-to-come post), but thought I'd share a little \"re-write\" of that problem with a graphic in case it's of any use, and also in case I've blundered in my understanding. Re-writing things in my own words helps <a href=\"/lw/3n2/my_story_owning_ones_reasons/\">make them my own</a>&nbsp;--&nbsp;I realize that this is probably going to come across as <em>really, really, incredibly, simplistic,</em>&nbsp;but it's where I'm at!</p>\n<p>In case it's not intuitive... it's <em>supposed</em>&nbsp;to show 100% of women broken into their measured partitions of 1% with cancer and 99% without. Those respective groups are then \"sifted,\" and the known reliability of the sieve for each of those groups is used to determine p(cancer|test+).</p>\n<p>I'm open to aesthetic critiques as well -- I enjoy <a href=\"/lw/4z2/inverse_speed/3t0b\">making things like this</a> and knowing how intuitive it is to look at is helpful. It didn't turn out how my mind visualized it, but I figured it was decent enough for a start.</p>\n<p>This was made using <a href=\"http://www.gnu.org/software/emacs/\">emacs</a> <a href=\"http://orgmode.org/\">org-mode</a>, <a href=\"http://www.latex-project.org/\">LaTeX</a>, and <a href=\"http://www.texample.net/tikz/\">Ti<em>k</em>Z</a>.</p>\n<p><strong>Update:</strong>&nbsp;per some comments, I tried to make things more clear in a redo. The original picture shown is <a href=\"http://i.imgur.com/ONplZ.png\">HERE</a>.</p>\n<p>----- Click for bigger picture or download -----</p>\n<p><a href=\"http://i.imgur.com/uquxZ.png\"><img style=\"vertical-align: top;\" src=\"http://i.imgur.com/uquxZ.png\" alt=\"\" width=\"100%\" /></a>&nbsp;</p>\n<p><a href=\"http://i.imgur.com/SKB1s.png\"><img style=\"vertical-align: top;\" src=\"http://i.imgur.com/SKB1s.png\" alt=\"\" width=\"100%\" /></a>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4NM4xA6pTYTZ3fEqN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 5, "extendedScore": null, "score": 7.000464046258179e-07, "legacy": true, "legacyId": "6699", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["g3RwsGofS6FE5nBsG"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T14:59:45.094Z", "modifiedAt": null, "url": null, "title": "Trusting Yourself (Formally)", "slug": "trusting-yourself-formally", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.867Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/pufmm4k48BwxY6QdP/trusting-yourself-formally", "pageUrlRelative": "/posts/pufmm4k48BwxY6QdP/trusting-yourself-formally", "linkUrl": "https://www.lesswrong.com/posts/pufmm4k48BwxY6QdP/trusting-yourself-formally", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Trusting%20Yourself%20(Formally)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ATrusting%20Yourself%20(Formally)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpufmm4k48BwxY6QdP%2Ftrusting-yourself-formally%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Trusting%20Yourself%20(Formally)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpufmm4k48BwxY6QdP%2Ftrusting-yourself-formally", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fpufmm4k48BwxY6QdP%2Ftrusting-yourself-formally", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 644, "htmlBody": "<p>Suppose I am a self-modifying AI reasoning about my own behavior (or about the behavior of another AI I am designing).&nbsp;</p>\n<p>To a human, it seems like it is very important that we trust our own deductions. That is, humans seem to believe \"things I believe are probably true.\" Thus a human would not self-modify to stop acting on their beliefs. How do we formalize this sort of trust?</p>\n<p>For simplicity say I exist in a fixed environment without uncertainty whose description I know (including my own existence in it). The only sort of statements I care about are mathematical statements: any property of our environment can be expressed as a purely mathematical statement. In order to act intelligently in this environment, I have a mathematical deduction engine which proves mathematical statements; my decisions are informed by the output of my deduction engine.</p>\n<p>I am considering replacing my deduction engine with a psuedo-random statement evaluator in order to save energy (after all, I need energy for many purposes). Why shouldn't I do it? You might hope that the deduction engine would be able to tell me that my deduction engine is useful; that my deduction engine isn't just a psuedo-random statement evaluator. But an important property of mathematical deduction is the second incompleteness theorem: no reasonable proof system X can prove that X doesn't prove false statements. In fact the situation is more dire: if X ever proves a statement of the form \"X wouldn't prove Y if Y weren't true\" then X <a href=\"http://yudkowsky.net/rational/lobs-theorem\">must also prove Y itself</a>.</p>\n<p>My question is: what sort of confidence in its own reasoning can a consistent thinker actually have? I know that an agent sure of its own correctness will start believing everything. But what about an agent who is <a href=\"/r/discussion/lw/534/where_does_uncertainty_come_from/\">99% confident</a> of its own correctness? What does Lob's theorem look like when applied to probabilistic beliefs?</p>\n<p>For example, suppose the algorithm X believes itself to be well-calibrated in the following sense. For any statement A and any probability p and any time T, consider the statements S1 = \"At time T, X believes A with probability p,\" and S2 = \"At time T, X believes A with probability p, <em>and A is really true</em>.\" We say that X believes itself to be well-calibrated about A at time T if, for all p, the probability X assigns to S2 is exactly p times the probability X assigns to S1.</p>\n<p>Lob's theorem says that this sort of belief in well-calibration is impossible if X is capable of carrying out complicated reasoning: X would infer with probability 1 that \"At time T, if X believes A with probability 1 then A is true.\" If X believes this for a large enough time T then X can apply the inferences in Lob's theorem and arrive at belief in A with probability 1 (I think).</p>\n<p>Now what if X believes itself to be well-calibrated only with probability 99%, in the following sense. Define S1 and S2 as before. What if, for all p, the probability X assigns to S2 is between (p+0.01) and (p-0.01) times the probability X assigns to S1? Does this lead to contradictory beliefs? Is this a strong enough belief to ensure that X will keep itself running and invest effort in improving its performance?</p>\n<p>Of course given that we don't have any grasp of probabilistic reasoning about mathematics, maybe thinking about this issue is premature. But I would like to understand what probabilistic reasoning might look like in interesting cases to get more of a handle on the general problem.</p>\n<p>Are there other good ways for X to believe in its own well-calibration? For example, in my description there is no explicit statement \"X is well calibrated\" which X can reason about, only particular special cases. Should there be such a statement? My description seems like it has many potential shortcomings, but I don't see anything better.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "pufmm4k48BwxY6QdP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 13, "extendedScore": null, "score": 7.00245016135742e-07, "legacy": true, "legacyId": "6703", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["MQiuhw6faHte9xcBS"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T15:26:35.422Z", "modifiedAt": null, "url": null, "title": "Complexity and halting", "slug": "complexity-and-halting", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.327Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "QJcy5NDAd8HTiZYQq", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MwKovuoyJbbRhNxsh/complexity-and-halting", "pageUrlRelative": "/posts/MwKovuoyJbbRhNxsh/complexity-and-halting", "linkUrl": "https://www.lesswrong.com/posts/MwKovuoyJbbRhNxsh/complexity-and-halting", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Complexity%20and%20halting&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AComplexity%20and%20halting%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMwKovuoyJbbRhNxsh%2Fcomplexity-and-halting%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Complexity%20and%20halting%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMwKovuoyJbbRhNxsh%2Fcomplexity-and-halting", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMwKovuoyJbbRhNxsh%2Fcomplexity-and-halting", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 32, "htmlBody": "<p>This is a short math question. &nbsp;Say I have an oracle that computes Kolmogorov complexity. &nbsp;Is there an algorithm that consults this oracle that will determine whether a given Turing machine halts?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MwKovuoyJbbRhNxsh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 9, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "6704", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T17:59:00.780Z", "modifiedAt": null, "url": null, "title": "Gamification and rationality training", "slug": "gamification-and-rationality-training", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.152Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psy-Kosh", "createdAt": "2009-03-01T19:34:52.148Z", "isAdmin": false, "displayName": "Psy-Kosh"}, "userId": "CtHmuQzjA7Y7LnSss", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZhjqpQxPCnuthYqNo/gamification-and-rationality-training", "pageUrlRelative": "/posts/ZhjqpQxPCnuthYqNo/gamification-and-rationality-training", "linkUrl": "https://www.lesswrong.com/posts/ZhjqpQxPCnuthYqNo/gamification-and-rationality-training", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Gamification%20and%20rationality%20training&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AGamification%20and%20rationality%20training%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZhjqpQxPCnuthYqNo%2Fgamification-and-rationality-training%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Gamification%20and%20rationality%20training%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZhjqpQxPCnuthYqNo%2Fgamification-and-rationality-training", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZhjqpQxPCnuthYqNo%2Fgamification-and-rationality-training", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>Watch <a href=\"http://www.escapistmagazine.com/videos/view/extra-credits/2985-Gamification\">this</a>&nbsp;Extra Credits and take note especially of the end, where they're offering consultation to educators and doctors re making educational stuff and other useful stuff more like games. (Incidentally, the people that make Extra Credits all work in or have been around in the game industry)</p>\n<p>I figured I'll email them and going to point them to LW, see if they're willing to give any insights re rationality training. Especially in light of the fact that the subject of games for teaching rationality has come here up before.</p>\n<p>Hey, maybe we'll learn something about how to learn something about how to be Less Wrong.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZhjqpQxPCnuthYqNo", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 16, "extendedScore": null, "score": 7.002951502516149e-07, "legacy": true, "legacyId": "6705", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-09T19:08:12.446Z", "modifiedAt": null, "url": null, "title": "The Neuroscience of Desire", "slug": "the-neuroscience-of-desire", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:03.974Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/48DTJkBH58JbBNSFH/the-neuroscience-of-desire", "pageUrlRelative": "/posts/48DTJkBH58JbBNSFH/the-neuroscience-of-desire", "linkUrl": "https://www.lesswrong.com/posts/48DTJkBH58JbBNSFH/the-neuroscience-of-desire", "postedAtFormatted": "Saturday, April 9th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Neuroscience%20of%20Desire&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Neuroscience%20of%20Desire%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F48DTJkBH58JbBNSFH%2Fthe-neuroscience-of-desire%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Neuroscience%20of%20Desire%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F48DTJkBH58JbBNSFH%2Fthe-neuroscience-of-desire", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F48DTJkBH58JbBNSFH%2Fthe-neuroscience-of-desire", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2954, "htmlBody": "<blockquote>\n<p>Who knows what I want to do? Who knows what anyone wants to do? How can you be sure about something like that? Isn&rsquo;t it all a question of brain chemistry, signals going back and forth, electrical energy in the cortex? How do you know whether something is really what you want to do or just some kind of nerve impulse in the brain? Some minor little activity takes place somewhere in this unimportant place in one of the brain hemispheres and suddenly I want to go to Montana or I don&rsquo;t want to go to Montana.</p>\n</blockquote>\n<p align=\"right\">- Don DeLillo, <em><a href=\"http://www.amazon.com/White-Noise-Penguin-Classics-Deluxe/dp/0143105981/\">White Noise</a></em></p>\n<p>Winning at life&nbsp;<a href=\"/lw/31/what_do_we_mean_by_rationality/\">means</a>&nbsp;achieving your goals&nbsp;<span style=\"color: #3e3c3c; font-family: verdana, serif; font-size: 13px;\">&mdash;</span>&nbsp;that is, satisfying your desires. As such,&nbsp;it will help to understand how our desires work<em>.</em>&nbsp;(I was tempted to title this article&nbsp;<a href=\"/lw/ld/the_hidden_complexity_of_wishes/\">The Hidden Complexity of Wishes</a>: Science Edition!)</p>\n<p>Previously, I <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">introduced</a> readers to the neuroscience of emotion (<a href=\"http://en.wikipedia.org/wiki/Affective_neuroscience\">affective neuroscience</a>), and explained that the reward system in the brain has three major components: liking, wanting, and learning. That post&nbsp;discussed 'liking' or <em>pleasure</em>. Today we discuss 'wanting' or <em>desire</em>.</p>\n<p>&nbsp;</p>\n<h4 style=\"font-size: 14px; color: black; float: none;\">The birth of neuroeconomics</h4>\n<p>Much work has been done on the affective neuroscience of desire,<sup>1</sup>&nbsp;but I am less interested with desire as an&nbsp;<em>emotion</em>&nbsp;than I am with desire as a&nbsp;<em>cause of decisions under uncertainty</em>. This latter aspect of desire is mostly studied by neuroeconomics,<sup>2</sup>&nbsp;not affective neuroscience.</p>\n<p>From about 1880-1960, <a href=\"http://en.wikipedia.org/wiki/Neoclassical_economics\">neoclassical economics</a> proposed simple, axiomatic models of human choice-making focused on the idea that agents make rational decisions aimed at maximizing expected utility. In the 1950s and 60s, however, economists discovered some paradoxes of human behavior that violated the axioms of these models.<sup>3</sup> In the 70s and 80s, psychology launched an even broader attack on these models. For example, while economists assumed that choices among objects should not depend on how they are described ('descriptive invariance'), psychologists discovered powerful <a href=\"http://en.wikipedia.org/wiki/Framing_effect_(psychology)\">framing effects</a>.<sup>4</sup></p>\n<p>In response, the field of <a href=\"http://en.wikipedia.org/wiki/Behavioral_economics\">behavioral economics</a> began to offer models of human choice-making that fit the experimental data better than simple models of neoclassical economics did.<sup>5&nbsp;</sup>Behavioral economists often proposed models that could be thought of as information-processing algorithms, so neuroscientists began looking for evidence of these algorithms in the human brain, and <a href=\"http://en.wikipedia.org/wiki/Neuroeconomics\">neuroeconomics</a> was born.</p>\n<p>(Warning: the rest of this post assumes some familiarity with <a href=\"http://www.introecon.com/\">microeconomics</a>.)</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h3>Valuation and choice in the brain</h3>\n<p>Despite their differences, models of decision-making from neoclassical economics,<sup>6</sup> behavioral economics,<sup>7</sup> and even computer science<sup>8</sup> share a common conclusion:</p>\n<blockquote>\n<p>Decision makers integrate the various dimensions of an option into a single measure of its idiosyncratic subjective value and then choose the option that is most valuable. Comparisons between different kinds of options rely on this abstract measure of subjective value, a kind of 'common currency' for choice. That humans can infact compare apples to oranges when they buy fruit is evidence for this abstract common scale.<sup>9</sup></p>\n</blockquote>\n<p>Though economists tend to claim only that agents act 'as if' they use the axioms of economic theory to make decisions,<sup>10</sup> there is now surprising evidence that subjective value and economic choice are encoded by particular neurons in the brain.<sup>11</sup></p>\n<p>More than a dozen studies show that the subjective utility of different goods or actions are encoded on a common scale by the ventromedial prefrontal cortex and the striatum in primates (including humans),<sup>12</sup> as is temporal discounting.<sup>13</sup> Moreover, the brain tracks forecasted and experienced value, probably for the purpose of learning.<sup>14</sup> Researchers have also shown how modulation of a common value signal could account for loss aversion and ambiguity aversion,<sup>15</sup> two psychological discoveries that had threatened standard economic models of decision-making. Finally, subjective value is learned via iterative updating (after experience) in dopaminergic neurons.<sup>16</sup></p>\n<p>Once a common-currency valuation of goods and actions has been performed, how is a choice made between them? Evidence implicates (at least) the lateral prefrontal and parietal cortex in a process that includes neurons encoding probabilistic reasoning.<sup>17</sup>&nbsp;Interestingly, while valuation structures encode absolute (and thus transitive) subjective value, choice-making structures \"rescale these absolute values so as to maximize the differences between the available options before choice is attempted,\"<sup>18</sup> perhaps via a normalization mechanism like the one discovered in the visual cortex.<sup>19</sup></p>\n<p>Beyond these basic conclusions, many open questions and controversies remain.<sup>20</sup> The hottest debate today concerns whether different valuation systems encode inconsistent values for the same actions (leading to different conclusions on which action to take),<sup>21</sup> or whether different valuation systems contribute to the same final valuation process (leading to a single, unambiguous conclusion on which action to take).<sup>22</sup> I think this race is too close to call, though I lean toward the latter model due to the persuasive case made for it by Glimcher (2010).</p>\n<p>Despite these open questions, 15 years of neuroeconomics research suggests an impressive <a href=\"/lw/on/reductionism/\">reduction</a> from economics to psychology to neuroscience may be possible, resulting in something like this<sup>23</sup>:</p>\n<p><img src=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/neuroeconomics-reduction.png\" alt=\"\" align=\"center\" /></p>\n<p>&nbsp;</p>\n<h3>Self-help</h3>\n<p>With this basic framework in place, what can the neuroscience of desire tell us about <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">how to win at life</a>?</p>\n<ol>\n<li>Wanting is different than liking, and <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">we don't <em>only</em>&nbsp;want happiness or pleasure</a>.<sup>24</sup> Thus, the perfect hedonist might not be fully satisfied. Pay attention to all your desires, not just your desires for pleasure.</li>\n<li>In particular, you should subject yourself to <em>novel and challenging activities</em> regularly throughout your life. Doing so keeps your dopamine (motivation) system flowing, because novel and challenging circumstances drive you to act and find solutions, which in turn leads to greater satisfaction than do 'lazy' pleasures like sleeping and eating.<sup>25</sup></li>\n<li>In particular, doing novel and challenging activities with your significant other will help you experience satisfaction together, and improve bonding and intimacy.<sup>26</sup></li>\n<li>Your brain generates reward signals when experienced value surpasses forecasted value.<sup>14</sup> So: lower your expectations and your brain will be pleasantly surprised when things go well. Things going perfectly according to plan is not the norm, so don't treat it as if it is.</li>\n<li>Many of the neurons involved in valuation and choice have stochastic features, meaning that when the subjective utility of two or more options are similar (represented in the brain by neurons with similar firing rates), we sometimes choose to do something <em>other</em>&nbsp;than the action that has the most subjective utility.<sup>27</sup> In other words, we sometimes fail to do what we most want to do, even if standard biases and faults (<a href=\"/lw/1sm/akrasia_tactics_review/\">akrasia</a>, etc.) are considered to be <em>part</em>&nbsp;of the valuation equation. So don't beat yourself up if you have a hard time choosing between options of roughly equal subjective utility, or if you feel you've chosen an option that does not have the greatest subject utility.</li>\n</ol>\n<p>The neuroscience of desire is progressing rapidly, and I have no doubt that we will know much more about it in another five years. In the meantime, it has already produced useful results.</p>\n<p>And the neuroscience of <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">pleasure</a> and desire is not only relevant to self-help, of course. In later posts, I will examine the implications of recent brain research for <a href=\"/lw/43v/the_urgent_metaethics_of_friendly_artificial/\">meta-ethics</a> and for <a href=\"http://intelligence.org/ourresearch/publications/what-is-friendly-ai.html\">Friendly AI</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup>&nbsp;Berridge (2007); Leyton (2009).</small></p>\n<p><small><sup>2</sup>&nbsp;Good overviews of neuroeconomics include: Glimcher (2010, 2009); Glimcher et al. (2008); Kable &amp; Glimcher (2009); Glimcher &amp; Rustichini (2004); Camerer et al (2005); Sanfey et al (2006); Politser (2008); Montague (2007). Berns (2005) is an overview from a self-help perspective.</small></p>\n<p><small><sup>3</sup> Most famously, the <a href=\"http://en.wikipedia.org/wiki/Allais_paradox\">Allais Paradox</a>&nbsp;(Allais, 1953) and the <a href=\"http://en.wikipedia.org/wiki/Ellsberg_paradox\">Ellsberg paradox</a>&nbsp;(Ellsberg, 1961). Eliezer <a href=\"/lw/my/the_allais_paradox/\">wrote</a> <a href=\"/lw/mz/zut_allais/\">three</a> <a href=\"/lw/n1/allais_malaise/\">posts</a> on the Allais paradox.</small></p>\n<p><small><sup>4</sup> Tversky &amp; Kahneman (1981).</small></p>\n<p><small><sup>5</sup> The most famous example is <a href=\"http://en.wikipedia.org/wiki/Prospect_theory\">Prospect Theory</a> (Kahneman &amp; Tversky, 1979).</small></p>\n<p><small><sup>6</sup> von Neumann &amp; Morgenstern (1944).</small></p>\n<p><small><sup>7</sup>&nbsp;Kahneman &amp; Tversky (1979).</small></p>\n<p><small><sup>8</sup> Sutton &amp; Barto (1998).</small></p>\n<p><small><sup>9</sup>&nbsp;Kable &amp; Glimcher (2009).</small></p>\n<p><small><sup>10</sup> Friedman (1953);&nbsp;Gul &amp; Pesendorfer (2008).</small></p>\n<p><small><sup>11</sup>&nbsp;Kable &amp; Glimcher (2009) is a good overview, as are sections 2 and 3 of Glimcher (2010).</small></p>\n<p><small><sup>12</sup> Kable &amp; Glimcher (2009);&nbsp;Padoa-Schioppa &amp; Assad (2006, 2008); Takahashi et al. (2009); Lau &amp; Glimcher (2008); Samejima et al. (2005); Plassmann et al. (2007); Hare et al. (2008); Hare et al. (2009).</small></p>\n<p><small><sup>13</sup>&nbsp;Kable &amp; Glimcher (2007); Louie &amp; Glimcher (2010).</small></p>\n<p><small><sup>14</sup>&nbsp;Rutledge et al. (2010); Delgado (2007); Knutson &amp; Cooper (2005); O&rsquo;Doherty (2004).</small></p>\n<p><small><sup>15</sup>&nbsp;Fox &amp; Poldrack (2008); Tom et al. (2007); Levy et al. (2007); Levy et al. (2010).</small></p>\n<p><small><sup>16</sup> Niv &amp; Montague (2009); Schultz et al. (1997);&nbsp;Tobler et al. (2003, 2005); Waelti et al. (2001); Bayer &amp; Glimcher (2005); Fiorillo et al. (2003, 2008); Kobayashi &amp; Schultz (2008); Roesch et al. (2007); D'Ardenne et al. (2008); Zaghloul et al. (2009); Pessiglione e tal. (2006).&nbsp;</small></p>\n<p><small><sup>17</sup> For technical reasons, most of this work has been done on the <a href=\"http://en.wikipedia.org/wiki/Saccade\">saccadic-control system</a>: Glimcher &amp; Sparks (1992); Basso &amp; Wurtz (1998); Dorris &amp; Munoz (1998); Platt &amp; Glimcher (1999); Yang &amp; Shadlen (2007); Dorris &amp; Glimcher (2004); Sugrue et al. (2004); Shadlen &amp; Newsome (2001); Churchland et al. (2008); Kiani et al. (2008); Wang (2008); Kable &amp; Glimcher (2007); Yu &amp; Dayan (2005). But Glimcher (2010) provides some reasons to think these results will generalize.</small></p>\n<p><small><sup>18</sup> Kable &amp; Glimcher (2009).</small></p>\n<p><small><sup>19</sup> Heeger (1992).</small></p>\n<p><small><sup>20</sup>&nbsp;See Kable &amp; Glimcher (2009), and the final chapter of Glimcher (2010). Neuroeconomists are also beginning to model how game-theoretic calculations occur in the brain:&nbsp;Fehr &amp; Camerer (2007); Lee (2008); Montague &amp; Lohrenz (2007); Singer &amp; Fehr (2005).</small></p>\n<p><small><sup>21</sup>&nbsp;Balleine et al. (2008); Bossaerts et al. (2009); Daw et al. (2005); Dayan and Balleine (2002); Rangel et al. (2008).</small></p>\n<p><small><sup>22</sup>&nbsp;Glimcher (2009); Levy et al. (2010).</small></p>\n<p><small><sup>23</sup> Figure 16.1 from Glimcher (2010).</small></p>\n<p><small><sup>24</sup> Smith et al. (2009).</small></p>\n<p><small><sup>25</sup>&nbsp;Berns (2005) provides a popular-level overview of the evidence, here. Some of the relevant research papers include: Berns et al. (2001); Benjamin et al. (1996); Kempermann et al. (1997).</small></p>\n<p><small><sup>26</sup>&nbsp;Aron et al. (2000, 2003).</small></p>\n<p><small><sup>27</sup> See chapters 9 and 10 of Glimcher (2010).</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Allais (1953). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Allais-Le-comportement-de-lhomme-rationnel-devant-le-risque.pdf\">Le comportement de l&rsquo;homme rationnel devant le risque: critique des postulats et axiomes de l&rsquo;&eacute;cole Am&eacute;ricaine</a>. <em>Econometrica, 21</em>: 503-546.</small></p>\n<p><small>Aron, Norman, Aron, McKenna, &amp; Heyman (2000). Couples shared participation in novel and arousing activities and experienced relationship quality. <em>Journal of Personality and Social Psychology, 78</em>: 273-283.</small></p>\n<p><small>Aron, Norman, Aron, &amp; Lewandowski (2003). Shared participation in self- expanding activities: Positive effects on experienced marital quality. In Noller &amp; Feeney (eds.), <em>Marital interaction</em> (pp. 177-196). Cambridge University Press.</small></p>\n<p><small>Balleine, Daw, &amp; O&rsquo;Doherty (2009). Multiple forms of value learning and the function of dopamine. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 367-387). Academic Press.</small></p>\n<p><small>Basso &amp; Wurtz (1998).&nbsp;Modulation of neuronal activity in superior colliculus by changes in target probability. <em>Journal of Neuroscience, 18</em>: 7519&ndash;7534.</small></p>\n<p><small>Bayer &amp; Glimcher (2005).&nbsp;Midbrain dopamine neurons encodea quantitative reward prediction error signal. <em>Neuron, 47</em>: 129&ndash;141.</small></p>\n<p><small>Benjamin, Li, Patterson, Greenberg, Murphy, &amp; Hamer (1996). Population and familial association between the D4 dopamine receptor gene and measures of novelty seeking. <em>Nature Genetics, 12</em>: 81-84.</small></p>\n<p><small>Berns (2005). <em><a href=\"http://www.amazon.com/Satisfaction-Science-Finding-True-Fulfillment/dp/B001063KJQ/\">Satisfaction: the science of finding true fulfillment</a></em>.&nbsp;Henry Holt and Co.</small></p>\n<p><small>Berns, McClure, Pagnoni, &amp; Montague (2001). Predictability modulates human brain response to reward. <em>Journal of Neuroscience, 21</em>: 2793-2798.</small></p>\n<p><small>Berridge (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-The-debate-over-dopamines-role-in-reward-the-case-for-incentive-salience.pdf\">The debate over dopamine's role in reward: the case for incentive salience</a>.&nbsp;<em style=\"font-style: italic;\">Psychopharmacology, 191</em>: 391-431.</small></p>\n<p><small>Bossaerts,&nbsp;, Preuschoff, &amp; Hsu (2009). The neurobiological foundations of valuation in human decision-making under uncertainty.&nbsp;In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.),&nbsp;<em>Neuroeconomics: Decision Making and the Brain</em>&nbsp;(pp. 353&ndash;365). Academic Press.</small></p>\n<p><small>Camerer, Loewenstein, &amp; Prelec (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Camerer-Neuroeconomics-how-neuroscience-can-inform-economics.pdf\">Neuroeconomics: how neuroscience can inform economics</a>.&nbsp;<em>Journal of Economic Literature, 43</em>: 9&ndash;64.</small></p>\n<p><small>Churchland, Kiani, &amp; Shadlen (2008). Decision-making with multiple alternatives. <em>Nature Neuroscience, 11</em>: 693&ndash;702.</small></p>\n<p><small>D'Ardenne,&nbsp;McClure, Nystrom, &amp; Cohen (2008). BOLD responses re\ufb02ecting dopaminergic signals in the human Ventral Tegmental Area. <em>Science, 319</em>: 1264&ndash;1267.</small></p>\n<p><small>Daw,&nbsp;Niv, &amp; Dayan (2005). Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control. <em>Nature Neuroscience, 8</em>: 1704&ndash;1711.</small></p>\n<p><small>Dayan and Balleine (2002).&nbsp;Reward, motivation, and reinforcement learning. <em>Neuron, 36</em>: 285&ndash;298.</small></p>\n<p><small>Delgado (2007).&nbsp;Reward-related responses in the human striatum. <em>Annals of the New York Academy of Sciences, 1104</em>: 70&ndash;88.</small></p>\n<p><small>Dorris &amp; Munoz (1998).&nbsp;Saccadic probability in\ufb02uences motorpreparation signals and time to saccadic initiation. <em>Journal of Neuroscience, 18</em>: 7015&ndash;7026.</small></p>\n<p><small>Dorris &amp; Glimcher (2004).&nbsp;Activity in posterior parietal cortex is correlated with the relative subjective desirability of action. <em>Neuron 44</em>: 365&ndash;378.</small></p>\n<p><small>Ellsberg (1961). Risk, Ambiguity, and the Savage Axioms. <em>Quarterly Journal of Economics, 75(4)</em>: 643&ndash;669.</small></p>\n<p><small>Fehr &amp; Camerer (2007).&nbsp;Social neuroeconomics: The neural circuitry of social preferences. <em>Trends in Cognitive Science, 11</em>: 419&ndash;427.</small></p>\n<p><small>Fiorillo, Tobler, &amp; Schultz (2003). Discrete coding of reward probability and uncertainty by dopamine neurons. <em>Science, 299</em>: 1898&ndash;1902.</small></p>\n<p><small>Fiorillo, Newsome, &amp; Schultz (2008). The temporal precision of reward prediction in dopamine neurons. <em>Nature Neuroscience, 11</em>: 966&ndash;973.</small></p>\n<p><small>Fox &amp; Poldrack (2008).&nbsp;Prospect theory and the brain. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 145-173). Academic Press.</small></p>\n<p><small>Friedman (1953). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Friedman-The-methodology-of-positive-economics.pdf\">The methodology of positive economics</a>. In Friedman, <em>Essays in Positive Economics</em>. Chicago Press.</small></p>\n<p><small>Glimcher (2009). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/Tommasi_13_Ch13.pdf\">Neuroscience, Psychology, and Economic Behavior: The Emerging Field of Neuroeconomics</a>. In: Tommasi, Peterson, &amp; Nadel (eds.), <em>Cognitive Biology: Evolutionary and Developemental Perspectives on Mind, Brain, and Behavior</em> (pp. 261-287).&nbsp;MIT Press.</small></p>\n<p><small>Glimcher (2009).&nbsp;<a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/CH032.pdf\">Choice: Towards a Standard Back-pocket Model</a>. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 503-521). Academic Press.</small></p>\n<p><small>Glimcher (2010). <em><a href=\"http://www.amazon.com/dp/0199744254/\">Foundations of Neuroeconomic Analaysis</a></em>. Oxford University Press.</small></p>\n<p><small>Glimcher &amp; Sparks (1992).&nbsp;Movement selection in advance of action in the superior colliculus. <em>Nature, 355</em>: 542&ndash;545.</small></p>\n<p><small>Glimcher &amp; Rustichini (2004).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Glimcher-Neuroeconomics-the-consilience-of-brain-and-decision.pdf\">Neuroeconomics: the consilience of brain and decision</a>.&nbsp;<em>Science, 306</em>: 447&ndash;452.</small></p>\n<p><small>Glimcher,&nbsp;Camerer, Fehr, &amp; Poldrack (2008). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/CH001.pdf\">Introduction: A Brief History of Neuroeconomics</a>. In Glimcher,&nbsp;Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em>&nbsp;(pp. 1-12). Academic Press.</small></p>\n<p><small>Gul &amp; Pesendorfer (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Gul-The-case-for-mindless-economics.pdf\">The case for mindless economics</a>. In Caplan &amp; Schotter (eds.), <em>The Foundations of Positive and Normative Economics</em> (pp. 3&ndash;41). Oxford University Press.</small></p>\n<p><small>Hare, O&rsquo;Doherty, Camerer, Schultz, &amp; Rangel (2008). Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors. <em>Journal of Neuroscience, 28</em>: 5623&ndash;5630.</small></p>\n<p><small>Hare, Camerer, &amp; Rangel (2009). Self-control in decisionmaking involves modulation of the vmPFC valuation system. <em>Science, 324</em>: 646&ndash;648.</small></p>\n<p><small>Heeger (1992).&nbsp;Normalization of cell responses in cat striate cortex. <em>Visual Neuroscience, 9</em>: 181&ndash;197.</small></p>\n<p><small>Kable &amp; Glimcher (2007).&nbsp;The neural correlates of subjective value during intertemporal choice. <em>Nature Neuroscience, 10</em>: 1625&ndash;1633.</small></p>\n<p><small>Kable &amp; Glimcher (2009).&nbsp;<a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/kable_glimcher2009.pdf\">The Neurobiology of Decision: Consensus and Controversy</a>. <em>Neuron, 63</em>: 733-745.</small></p>\n<p><small>Kahneman &amp; Tversky (1979). Prospect Theory: An Analysis of Decision under Risk. <em>Econometrica, XLVII</em>: 263-291.</small></p>\n<p><small>Kempermann, Kuhn, &amp; Gage (1997). More hippocampal neurons in adult mice living in an enriched environment. <em>Nature, 386</em>: 493-495.</small></p>\n<p><small>Kiani,&nbsp;Hanks, &amp; Shadlen (2008). Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment. <em>Journal of Neuroscience, 28</em>: 3017&ndash;3029.</small></p>\n<p><small>Knutson &amp; Cooper (2005).&nbsp;Functional magnetic resonance imaging of reward prediction. <em>Current Opinions in Neurology, 18</em>: 411&ndash;417.</small></p>\n<p><small>Kobayashi &amp; Schultz (2008).&nbsp;In\ufb02uence of reward delays on responses of dopamine neurons. <em>Journal of Neuroscience, 28</em>: 7837&ndash;7846.</small></p>\n<p><small>Lau &amp; Glimcher (2008).&nbsp;Value representations in the primate striatum during matching behavior. <em>Neuron, 58</em>: 451&ndash;463.</small></p>\n<p><small>Lee (2008).&nbsp;Game theory and neural basis of social decision making. <em>Nature Neuroscience, 11</em>: 404&ndash;409.</small></p>\n<p><small>Levy, Rustichini &amp; Glimcher (2007). A single system represents subjective value under both risky and ambiguous decision-making in humans. In <em>37th Annual Society for Neuroscience Meeting</em>, San Diego, California.</small></p>\n<p><small>Levy,&nbsp;Snell, Nelson, Rustichini, &amp; Glimcher (2010). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/levy_glimcher2010.pdf\">Neural Representation of Subjective Value Under Risk and Ambiguity</a>. <em>Journal of Neurophysiology, 103</em>: 1036-1047.</small></p>\n<p><small>Leyton (2009). The neurobiology of desire: Dopamine and the regulation of mood and motivational states in humans.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 222-243). Oxford University Press.</small></p>\n<p><small>Louie &amp; Glimcher (2010).&nbsp;<a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/Louie_Glimcher_2010.pdf\">Separating value from choice: delay discounting activity in the lateral intraparietal area</a>. <em>Journal of Neuroscience, 30(16)</em>: 5498-5507.</small></p>\n<p><small>Montague (2007).&nbsp;<em><a href=\"http://www.amazon.com/Your-Brain-Almost-Perfect-Decisions/dp/B001A5Q3WS/\">Your brain is (almost) perfect: How we make decisions</a></em>. Plume.</small></p>\n<p><small>Montague &amp; Lohrenz (2007).&nbsp;To detect and correct: Norm violations and their enforcement. <em>Neuron, 56</em>: 14&ndash;18.</small></p>\n<p><small>Niv &amp; Montague (2008).&nbsp;Theoretical and empirical studies oflearning. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 331-351). Academic Press.</small></p>\n<p><small>O&rsquo;Doherty (2004).&nbsp;Reward representations and reward-related learning in the human brain: insights from neuroimaging. <em>Current Opinions in Neurobiology, 14</em>: 769&ndash;776.</small></p>\n<p><small>Padoa-Schioppa &amp; Assad (2006).&nbsp;Neurons in the orbitofrontalcortex encode economic value. <em>Nature, 441</em>: 223&ndash;226.</small></p>\n<p><small>Padoa-Schioppa &amp; Assad (2008). The representation of economic value in the orbitofrontal cortex is invariant for changes of menu. <em>Nature Neuroscience 11</em>: 95&ndash;102.</small></p>\n<p><small>Pessiglione,&nbsp;Seymour, Flandin, Dolan, &amp; Frith (2006). Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans. <em>Nature, 442</em>: 1042&ndash;1045.</small></p>\n<p><small>Plassmann, O&rsquo;Doherty, &amp; Rangel (2007). Orbitofrontal cortex encodes willingness to pay in everyday economic transactions. <em>Journal of Neuroscience, 27</em>: 9984&ndash;9988.</small></p>\n<p><small>Platt &amp; Glimcher (1999).&nbsp;Neural correlates of decision variables in parietal cortex. <em>Nature, 400</em>: 233&ndash;238.</small></p>\n<p><small>Politser (2008).&nbsp;<em><a href=\"http://www.amazon.com/Neuroeconomics-Guide-Science-Making-Choices/dp/0195305825/\">Neuroeconomics: a guide to the new science of making choices</a></em>. Oxford University Press.</small></p>\n<p><small>Rangel,&nbsp;Camerer, &amp; Montague (2008). A framework for studying the neurobiology of value-based decision making. <em>Nature Reviews Neuroscience, 9</em>: 545&ndash;556</small></p>\n<p><small>Roesch, Calu, &amp; Schoenbaum (2007). Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards. <em>Nature Neuroscience, 10</em>: 1615&ndash;1624.</small></p>\n<p><small>Rutledge, Dean, Caplin, &amp; Glimcher (2010). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/Rutledge_Dean_Caplin2010.pdf\">Testing the reward prediction error hypothesis with an axiomatic model</a>. <em>Journal of Neuroscience, 30(40)</em>: 13525-13536.</small></p>\n<p><small>Samejima, Ueda, Doya &amp; Kimura (2005). Representation ofaction-speci\ufb01c reward values in the striatum. <em>Science, 310</em>: 1337&ndash;1340.</small></p>\n<p><small>Sanfey, Loewenstein, McClure, &amp; Cohen (2006).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sanfey-Neuroeconomics-cross-currents-in-research-on-decision-making.pdf\">Neuroeconomics: cross-currents in research on decision-making</a>.&nbsp;<em>Trends in Cognitive Science, 10</em>: 108&ndash;116.</small></p>\n<p><small>Schultz,&nbsp;Dayan, &amp; Montague (1997). A neural substrate of prediction and reward. <em>Science, 275</em>: 1593&ndash;1599.</small></p>\n<p><small>Shadlen &amp; Newsome (2001).&nbsp;Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey. <em>Journal of Neurophysiology, 86</em>: 1916&ndash;1936.</small></p>\n<p><small>Singer &amp; Fehr (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Singer-Fehr-The-neuroeconomics-of-mind-reading-and-empathy.pdf\">The neuroeconomics of mind reading and empathy</a>. <em>American Economic Review, 95</em>:&nbsp;340&ndash;345.</small></p>\n<p><small>Smith, Mahler, Pecina, &amp; Berridge (2009). Hedonic hotspots: generating sensory pleasure in the brain. In Kringelbach &amp; Berridge (eds.), <em>Pleasures of the brain</em> (pp. 27-49). Oxford University Press.</small></p>\n<p><small>Sugrue,&nbsp;Corrado, &amp; Newsome (2004). Matching behavior and the representation of value in the parietal cortex. <em>Science, 304</em>: 1782&ndash;1787.</small></p>\n<p><small>Sutton &amp; Barto (1998). <em><a href=\"http://www.amazon.com/dp/0262193981/\">Reinforcement Learning: An Introduction</a></em>. MIT Press.</small></p>\n<p><small>Takahashi, Roesch, Stalnaker, Haney, Calu, Taylor, Burke, &amp; Schoenbaum (2009). The orbitofrontal cortex andventral tegmental area are necessary for learning from unexpected outcomes. <em>Neuron, 62</em>: 269&ndash;280.</small></p>\n<p><small>Tobler,&nbsp;Dickinson, &amp; Schultz (2003). Coding of predicted reward omission by dopamine neurons in a conditioned inhibition paradigm. <em>Journal of Neuroscience, 23</em>: 10402&ndash;10410.</small></p>\n<p><small>Tobler, Fiorillo, &amp; Schultz (2005). Adaptive coding of rewardvalue by dopamine neurons. <em>Science, 307</em>: 1642&ndash;1645.</small></p>\n<p><small>Tom,&nbsp;Fox, Trepel &amp; Poldrack (2007). The neural basis of loss aversion in decision-making under risk. <em>Science, 315</em>: 515&ndash;518.</small></p>\n<p><small>Tversky &amp; Kahneman (1981). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Tversky-Kahneman-The-framing-of-decisions-and-the-psychology-of-choice.pdf\">The framing of decisions and the psychology of choice</a>. <em>Science, 211(4481)</em>: 453&ndash;458.</small></p>\n<p><small>von Neumann &amp; Morgenstern (1944).&nbsp;<em><a href=\"http://www.amazon.com/dp/0691130612/\">Theory of Games and Economic Behavior</a></em>. Princeton University Press.</small></p>\n<p><small>Waelti,&nbsp;Dickinson, &amp; Schultz (2001). Dopamine responses comply with basic assumptions of formal learning theory. <em>Nature, 412</em>: 43&ndash;48.</small></p>\n<p><small>Wang (2008).&nbsp;Decision making in recurrent neuronal circuits. <em>Neuron, 60</em>: 215&ndash;234.</small></p>\n<p><small>Yang &amp; Shadlen (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Yang-Probabilistic-reasoning-by-neurons.pdf\">Probabilistic reasoning by neurons</a>. <em>Nature, 447</em>: 1075&ndash;1080.</small></p>\n<p><small>Yu &amp; Dayan (2005).&nbsp;Uncertainty, neuromodulation and attention. <em>Neuron, 46</em>: 681&ndash;692.</small></p>\n<p><small>Zaghloul,&nbsp;Blanco, Weidemann, McGill, Jaggi, Baltuch, &amp; Kahana (2009). Human substantia nigra neurons encode unexpected \ufb01nancial rewards. <em>Science, 323</em>: 1496&ndash;1499.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"Wi3EopKJ2aNdtxSWg": 1, "xexCWMyds6QLWognu": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "48DTJkBH58JbBNSFH", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 62, "baseScore": 69, "extendedScore": null, "score": 0.000142, "legacy": true, "legacyId": "6451", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 69, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<blockquote>\n<p>Who knows what I want to do? Who knows what anyone wants to do? How can you be sure about something like that? Isn\u2019t it all a question of brain chemistry, signals going back and forth, electrical energy in the cortex? How do you know whether something is really what you want to do or just some kind of nerve impulse in the brain? Some minor little activity takes place somewhere in this unimportant place in one of the brain hemispheres and suddenly I want to go to Montana or I don\u2019t want to go to Montana.</p>\n</blockquote>\n<p align=\"right\">- Don DeLillo, <em><a href=\"http://www.amazon.com/White-Noise-Penguin-Classics-Deluxe/dp/0143105981/\">White Noise</a></em></p>\n<p>Winning at life&nbsp;<a href=\"/lw/31/what_do_we_mean_by_rationality/\">means</a>&nbsp;achieving your goals&nbsp;<span style=\"color: #3e3c3c; font-family: verdana, serif; font-size: 13px;\">\u2014</span>&nbsp;that is, satisfying your desires. As such,&nbsp;it will help to understand how our desires work<em>.</em>&nbsp;(I was tempted to title this article&nbsp;<a href=\"/lw/ld/the_hidden_complexity_of_wishes/\">The Hidden Complexity of Wishes</a>: Science Edition!)</p>\n<p>Previously, I <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">introduced</a> readers to the neuroscience of emotion (<a href=\"http://en.wikipedia.org/wiki/Affective_neuroscience\">affective neuroscience</a>), and explained that the reward system in the brain has three major components: liking, wanting, and learning. That post&nbsp;discussed 'liking' or <em>pleasure</em>. Today we discuss 'wanting' or <em>desire</em>.</p>\n<p>&nbsp;</p>\n<h4 style=\"font-size: 14px; color: black; float: none;\" id=\"The_birth_of_neuroeconomics\">The birth of neuroeconomics</h4>\n<p>Much work has been done on the affective neuroscience of desire,<sup>1</sup>&nbsp;but I am less interested with desire as an&nbsp;<em>emotion</em>&nbsp;than I am with desire as a&nbsp;<em>cause of decisions under uncertainty</em>. This latter aspect of desire is mostly studied by neuroeconomics,<sup>2</sup>&nbsp;not affective neuroscience.</p>\n<p>From about 1880-1960, <a href=\"http://en.wikipedia.org/wiki/Neoclassical_economics\">neoclassical economics</a> proposed simple, axiomatic models of human choice-making focused on the idea that agents make rational decisions aimed at maximizing expected utility. In the 1950s and 60s, however, economists discovered some paradoxes of human behavior that violated the axioms of these models.<sup>3</sup> In the 70s and 80s, psychology launched an even broader attack on these models. For example, while economists assumed that choices among objects should not depend on how they are described ('descriptive invariance'), psychologists discovered powerful <a href=\"http://en.wikipedia.org/wiki/Framing_effect_(psychology)\">framing effects</a>.<sup>4</sup></p>\n<p>In response, the field of <a href=\"http://en.wikipedia.org/wiki/Behavioral_economics\">behavioral economics</a> began to offer models of human choice-making that fit the experimental data better than simple models of neoclassical economics did.<sup>5&nbsp;</sup>Behavioral economists often proposed models that could be thought of as information-processing algorithms, so neuroscientists began looking for evidence of these algorithms in the human brain, and <a href=\"http://en.wikipedia.org/wiki/Neuroeconomics\">neuroeconomics</a> was born.</p>\n<p>(Warning: the rest of this post assumes some familiarity with <a href=\"http://www.introecon.com/\">microeconomics</a>.)</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h3 id=\"Valuation_and_choice_in_the_brain\">Valuation and choice in the brain</h3>\n<p>Despite their differences, models of decision-making from neoclassical economics,<sup>6</sup> behavioral economics,<sup>7</sup> and even computer science<sup>8</sup> share a common conclusion:</p>\n<blockquote>\n<p>Decision makers integrate the various dimensions of an option into a single measure of its idiosyncratic subjective value and then choose the option that is most valuable. Comparisons between different kinds of options rely on this abstract measure of subjective value, a kind of 'common currency' for choice. That humans can infact compare apples to oranges when they buy fruit is evidence for this abstract common scale.<sup>9</sup></p>\n</blockquote>\n<p>Though economists tend to claim only that agents act 'as if' they use the axioms of economic theory to make decisions,<sup>10</sup> there is now surprising evidence that subjective value and economic choice are encoded by particular neurons in the brain.<sup>11</sup></p>\n<p>More than a dozen studies show that the subjective utility of different goods or actions are encoded on a common scale by the ventromedial prefrontal cortex and the striatum in primates (including humans),<sup>12</sup> as is temporal discounting.<sup>13</sup> Moreover, the brain tracks forecasted and experienced value, probably for the purpose of learning.<sup>14</sup> Researchers have also shown how modulation of a common value signal could account for loss aversion and ambiguity aversion,<sup>15</sup> two psychological discoveries that had threatened standard economic models of decision-making. Finally, subjective value is learned via iterative updating (after experience) in dopaminergic neurons.<sup>16</sup></p>\n<p>Once a common-currency valuation of goods and actions has been performed, how is a choice made between them? Evidence implicates (at least) the lateral prefrontal and parietal cortex in a process that includes neurons encoding probabilistic reasoning.<sup>17</sup>&nbsp;Interestingly, while valuation structures encode absolute (and thus transitive) subjective value, choice-making structures \"rescale these absolute values so as to maximize the differences between the available options before choice is attempted,\"<sup>18</sup> perhaps via a normalization mechanism like the one discovered in the visual cortex.<sup>19</sup></p>\n<p>Beyond these basic conclusions, many open questions and controversies remain.<sup>20</sup> The hottest debate today concerns whether different valuation systems encode inconsistent values for the same actions (leading to different conclusions on which action to take),<sup>21</sup> or whether different valuation systems contribute to the same final valuation process (leading to a single, unambiguous conclusion on which action to take).<sup>22</sup> I think this race is too close to call, though I lean toward the latter model due to the persuasive case made for it by Glimcher (2010).</p>\n<p>Despite these open questions, 15 years of neuroeconomics research suggests an impressive <a href=\"/lw/on/reductionism/\">reduction</a> from economics to psychology to neuroscience may be possible, resulting in something like this<sup>23</sup>:</p>\n<p><img src=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/neuroeconomics-reduction.png\" alt=\"\" align=\"center\"></p>\n<p>&nbsp;</p>\n<h3 id=\"Self_help\">Self-help</h3>\n<p>With this basic framework in place, what can the neuroscience of desire tell us about <a href=\"http://wiki.lesswrong.com/wiki/The_Science_of_Winning_at_Life\">how to win at life</a>?</p>\n<ol>\n<li>Wanting is different than liking, and <a href=\"/lw/lb/not_for_the_sake_of_happiness_alone/\">we don't <em>only</em>&nbsp;want happiness or pleasure</a>.<sup>24</sup> Thus, the perfect hedonist might not be fully satisfied. Pay attention to all your desires, not just your desires for pleasure.</li>\n<li>In particular, you should subject yourself to <em>novel and challenging activities</em> regularly throughout your life. Doing so keeps your dopamine (motivation) system flowing, because novel and challenging circumstances drive you to act and find solutions, which in turn leads to greater satisfaction than do 'lazy' pleasures like sleeping and eating.<sup>25</sup></li>\n<li>In particular, doing novel and challenging activities with your significant other will help you experience satisfaction together, and improve bonding and intimacy.<sup>26</sup></li>\n<li>Your brain generates reward signals when experienced value surpasses forecasted value.<sup>14</sup> So: lower your expectations and your brain will be pleasantly surprised when things go well. Things going perfectly according to plan is not the norm, so don't treat it as if it is.</li>\n<li>Many of the neurons involved in valuation and choice have stochastic features, meaning that when the subjective utility of two or more options are similar (represented in the brain by neurons with similar firing rates), we sometimes choose to do something <em>other</em>&nbsp;than the action that has the most subjective utility.<sup>27</sup> In other words, we sometimes fail to do what we most want to do, even if standard biases and faults (<a href=\"/lw/1sm/akrasia_tactics_review/\">akrasia</a>, etc.) are considered to be <em>part</em>&nbsp;of the valuation equation. So don't beat yourself up if you have a hard time choosing between options of roughly equal subjective utility, or if you feel you've chosen an option that does not have the greatest subject utility.</li>\n</ol>\n<p>The neuroscience of desire is progressing rapidly, and I have no doubt that we will know much more about it in another five years. In the meantime, it has already produced useful results.</p>\n<p>And the neuroscience of <a href=\"/lw/4yq/the_neuroscience_of_pleasure/\">pleasure</a> and desire is not only relevant to self-help, of course. In later posts, I will examine the implications of recent brain research for <a href=\"/lw/43v/the_urgent_metaethics_of_friendly_artificial/\">meta-ethics</a> and for <a href=\"http://intelligence.org/ourresearch/publications/what-is-friendly-ai.html\">Friendly AI</a>.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup>&nbsp;Berridge (2007); Leyton (2009).</small></p>\n<p><small><sup>2</sup>&nbsp;Good overviews of neuroeconomics include: Glimcher (2010, 2009); Glimcher et al. (2008); Kable &amp; Glimcher (2009); Glimcher &amp; Rustichini (2004); Camerer et al (2005); Sanfey et al (2006); Politser (2008); Montague (2007). Berns (2005) is an overview from a self-help perspective.</small></p>\n<p><small><sup>3</sup> Most famously, the <a href=\"http://en.wikipedia.org/wiki/Allais_paradox\">Allais Paradox</a>&nbsp;(Allais, 1953) and the <a href=\"http://en.wikipedia.org/wiki/Ellsberg_paradox\">Ellsberg paradox</a>&nbsp;(Ellsberg, 1961). Eliezer <a href=\"/lw/my/the_allais_paradox/\">wrote</a> <a href=\"/lw/mz/zut_allais/\">three</a> <a href=\"/lw/n1/allais_malaise/\">posts</a> on the Allais paradox.</small></p>\n<p><small><sup>4</sup> Tversky &amp; Kahneman (1981).</small></p>\n<p><small><sup>5</sup> The most famous example is <a href=\"http://en.wikipedia.org/wiki/Prospect_theory\">Prospect Theory</a> (Kahneman &amp; Tversky, 1979).</small></p>\n<p><small><sup>6</sup> von Neumann &amp; Morgenstern (1944).</small></p>\n<p><small><sup>7</sup>&nbsp;Kahneman &amp; Tversky (1979).</small></p>\n<p><small><sup>8</sup> Sutton &amp; Barto (1998).</small></p>\n<p><small><sup>9</sup>&nbsp;Kable &amp; Glimcher (2009).</small></p>\n<p><small><sup>10</sup> Friedman (1953);&nbsp;Gul &amp; Pesendorfer (2008).</small></p>\n<p><small><sup>11</sup>&nbsp;Kable &amp; Glimcher (2009) is a good overview, as are sections 2 and 3 of Glimcher (2010).</small></p>\n<p><small><sup>12</sup> Kable &amp; Glimcher (2009);&nbsp;Padoa-Schioppa &amp; Assad (2006, 2008); Takahashi et al. (2009); Lau &amp; Glimcher (2008); Samejima et al. (2005); Plassmann et al. (2007); Hare et al. (2008); Hare et al. (2009).</small></p>\n<p><small><sup>13</sup>&nbsp;Kable &amp; Glimcher (2007); Louie &amp; Glimcher (2010).</small></p>\n<p><small><sup>14</sup>&nbsp;Rutledge et al. (2010); Delgado (2007); Knutson &amp; Cooper (2005); O\u2019Doherty (2004).</small></p>\n<p><small><sup>15</sup>&nbsp;Fox &amp; Poldrack (2008); Tom et al. (2007); Levy et al. (2007); Levy et al. (2010).</small></p>\n<p><small><sup>16</sup> Niv &amp; Montague (2009); Schultz et al. (1997);&nbsp;Tobler et al. (2003, 2005); Waelti et al. (2001); Bayer &amp; Glimcher (2005); Fiorillo et al. (2003, 2008); Kobayashi &amp; Schultz (2008); Roesch et al. (2007); D'Ardenne et al. (2008); Zaghloul et al. (2009); Pessiglione e tal. (2006).&nbsp;</small></p>\n<p><small><sup>17</sup> For technical reasons, most of this work has been done on the <a href=\"http://en.wikipedia.org/wiki/Saccade\">saccadic-control system</a>: Glimcher &amp; Sparks (1992); Basso &amp; Wurtz (1998); Dorris &amp; Munoz (1998); Platt &amp; Glimcher (1999); Yang &amp; Shadlen (2007); Dorris &amp; Glimcher (2004); Sugrue et al. (2004); Shadlen &amp; Newsome (2001); Churchland et al. (2008); Kiani et al. (2008); Wang (2008); Kable &amp; Glimcher (2007); Yu &amp; Dayan (2005). But Glimcher (2010) provides some reasons to think these results will generalize.</small></p>\n<p><small><sup>18</sup> Kable &amp; Glimcher (2009).</small></p>\n<p><small><sup>19</sup> Heeger (1992).</small></p>\n<p><small><sup>20</sup>&nbsp;See Kable &amp; Glimcher (2009), and the final chapter of Glimcher (2010). Neuroeconomists are also beginning to model how game-theoretic calculations occur in the brain:&nbsp;Fehr &amp; Camerer (2007); Lee (2008); Montague &amp; Lohrenz (2007); Singer &amp; Fehr (2005).</small></p>\n<p><small><sup>21</sup>&nbsp;Balleine et al. (2008); Bossaerts et al. (2009); Daw et al. (2005); Dayan and Balleine (2002); Rangel et al. (2008).</small></p>\n<p><small><sup>22</sup>&nbsp;Glimcher (2009); Levy et al. (2010).</small></p>\n<p><small><sup>23</sup> Figure 16.1 from Glimcher (2010).</small></p>\n<p><small><sup>24</sup> Smith et al. (2009).</small></p>\n<p><small><sup>25</sup>&nbsp;Berns (2005) provides a popular-level overview of the evidence, here. Some of the relevant research papers include: Berns et al. (2001); Benjamin et al. (1996); Kempermann et al. (1997).</small></p>\n<p><small><sup>26</sup>&nbsp;Aron et al. (2000, 2003).</small></p>\n<p><small><sup>27</sup> See chapters 9 and 10 of Glimcher (2010).</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Allais (1953). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Allais-Le-comportement-de-lhomme-rationnel-devant-le-risque.pdf\">Le comportement de l\u2019homme rationnel devant le risque: critique des postulats et axiomes de l\u2019\u00e9cole Am\u00e9ricaine</a>. <em>Econometrica, 21</em>: 503-546.</small></p>\n<p><small>Aron, Norman, Aron, McKenna, &amp; Heyman (2000). Couples shared participation in novel and arousing activities and experienced relationship quality. <em>Journal of Personality and Social Psychology, 78</em>: 273-283.</small></p>\n<p><small>Aron, Norman, Aron, &amp; Lewandowski (2003). Shared participation in self- expanding activities: Positive effects on experienced marital quality. In Noller &amp; Feeney (eds.), <em>Marital interaction</em> (pp. 177-196). Cambridge University Press.</small></p>\n<p><small>Balleine, Daw, &amp; O\u2019Doherty (2009). Multiple forms of value learning and the function of dopamine. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 367-387). Academic Press.</small></p>\n<p><small>Basso &amp; Wurtz (1998).&nbsp;Modulation of neuronal activity in superior colliculus by changes in target probability. <em>Journal of Neuroscience, 18</em>: 7519\u20137534.</small></p>\n<p><small>Bayer &amp; Glimcher (2005).&nbsp;Midbrain dopamine neurons encodea quantitative reward prediction error signal. <em>Neuron, 47</em>: 129\u2013141.</small></p>\n<p><small>Benjamin, Li, Patterson, Greenberg, Murphy, &amp; Hamer (1996). Population and familial association between the D4 dopamine receptor gene and measures of novelty seeking. <em>Nature Genetics, 12</em>: 81-84.</small></p>\n<p><small>Berns (2005). <em><a href=\"http://www.amazon.com/Satisfaction-Science-Finding-True-Fulfillment/dp/B001063KJQ/\">Satisfaction: the science of finding true fulfillment</a></em>.&nbsp;Henry Holt and Co.</small></p>\n<p><small>Berns, McClure, Pagnoni, &amp; Montague (2001). Predictability modulates human brain response to reward. <em>Journal of Neuroscience, 21</em>: 2793-2798.</small></p>\n<p><small>Berridge (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Berridge-The-debate-over-dopamines-role-in-reward-the-case-for-incentive-salience.pdf\">The debate over dopamine's role in reward: the case for incentive salience</a>.&nbsp;<em style=\"font-style: italic;\">Psychopharmacology, 191</em>: 391-431.</small></p>\n<p><small>Bossaerts,&nbsp;, Preuschoff, &amp; Hsu (2009). The neurobiological foundations of valuation in human decision-making under uncertainty.&nbsp;In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.),&nbsp;<em>Neuroeconomics: Decision Making and the Brain</em>&nbsp;(pp. 353\u2013365). Academic Press.</small></p>\n<p><small>Camerer, Loewenstein, &amp; Prelec (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Camerer-Neuroeconomics-how-neuroscience-can-inform-economics.pdf\">Neuroeconomics: how neuroscience can inform economics</a>.&nbsp;<em>Journal of Economic Literature, 43</em>: 9\u201364.</small></p>\n<p><small>Churchland, Kiani, &amp; Shadlen (2008). Decision-making with multiple alternatives. <em>Nature Neuroscience, 11</em>: 693\u2013702.</small></p>\n<p><small>D'Ardenne,&nbsp;McClure, Nystrom, &amp; Cohen (2008). BOLD responses re\ufb02ecting dopaminergic signals in the human Ventral Tegmental Area. <em>Science, 319</em>: 1264\u20131267.</small></p>\n<p><small>Daw,&nbsp;Niv, &amp; Dayan (2005). Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control. <em>Nature Neuroscience, 8</em>: 1704\u20131711.</small></p>\n<p><small>Dayan and Balleine (2002).&nbsp;Reward, motivation, and reinforcement learning. <em>Neuron, 36</em>: 285\u2013298.</small></p>\n<p><small>Delgado (2007).&nbsp;Reward-related responses in the human striatum. <em>Annals of the New York Academy of Sciences, 1104</em>: 70\u201388.</small></p>\n<p><small>Dorris &amp; Munoz (1998).&nbsp;Saccadic probability in\ufb02uences motorpreparation signals and time to saccadic initiation. <em>Journal of Neuroscience, 18</em>: 7015\u20137026.</small></p>\n<p><small>Dorris &amp; Glimcher (2004).&nbsp;Activity in posterior parietal cortex is correlated with the relative subjective desirability of action. <em>Neuron 44</em>: 365\u2013378.</small></p>\n<p><small>Ellsberg (1961). Risk, Ambiguity, and the Savage Axioms. <em>Quarterly Journal of Economics, 75(4)</em>: 643\u2013669.</small></p>\n<p><small>Fehr &amp; Camerer (2007).&nbsp;Social neuroeconomics: The neural circuitry of social preferences. <em>Trends in Cognitive Science, 11</em>: 419\u2013427.</small></p>\n<p><small>Fiorillo, Tobler, &amp; Schultz (2003). Discrete coding of reward probability and uncertainty by dopamine neurons. <em>Science, 299</em>: 1898\u20131902.</small></p>\n<p><small>Fiorillo, Newsome, &amp; Schultz (2008). The temporal precision of reward prediction in dopamine neurons. <em>Nature Neuroscience, 11</em>: 966\u2013973.</small></p>\n<p><small>Fox &amp; Poldrack (2008).&nbsp;Prospect theory and the brain. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 145-173). Academic Press.</small></p>\n<p><small>Friedman (1953). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Friedman-The-methodology-of-positive-economics.pdf\">The methodology of positive economics</a>. In Friedman, <em>Essays in Positive Economics</em>. Chicago Press.</small></p>\n<p><small>Glimcher (2009). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/Tommasi_13_Ch13.pdf\">Neuroscience, Psychology, and Economic Behavior: The Emerging Field of Neuroeconomics</a>. In: Tommasi, Peterson, &amp; Nadel (eds.), <em>Cognitive Biology: Evolutionary and Developemental Perspectives on Mind, Brain, and Behavior</em> (pp. 261-287).&nbsp;MIT Press.</small></p>\n<p><small>Glimcher (2009).&nbsp;<a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/CH032.pdf\">Choice: Towards a Standard Back-pocket Model</a>. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 503-521). Academic Press.</small></p>\n<p><small>Glimcher (2010). <em><a href=\"http://www.amazon.com/dp/0199744254/\">Foundations of Neuroeconomic Analaysis</a></em>. Oxford University Press.</small></p>\n<p><small>Glimcher &amp; Sparks (1992).&nbsp;Movement selection in advance of action in the superior colliculus. <em>Nature, 355</em>: 542\u2013545.</small></p>\n<p><small>Glimcher &amp; Rustichini (2004).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Glimcher-Neuroeconomics-the-consilience-of-brain-and-decision.pdf\">Neuroeconomics: the consilience of brain and decision</a>.&nbsp;<em>Science, 306</em>: 447\u2013452.</small></p>\n<p><small>Glimcher,&nbsp;Camerer, Fehr, &amp; Poldrack (2008). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/CH001.pdf\">Introduction: A Brief History of Neuroeconomics</a>. In Glimcher,&nbsp;Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em>&nbsp;(pp. 1-12). Academic Press.</small></p>\n<p><small>Gul &amp; Pesendorfer (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Gul-The-case-for-mindless-economics.pdf\">The case for mindless economics</a>. In Caplan &amp; Schotter (eds.), <em>The Foundations of Positive and Normative Economics</em> (pp. 3\u201341). Oxford University Press.</small></p>\n<p><small>Hare, O\u2019Doherty, Camerer, Schultz, &amp; Rangel (2008). Dissociating the role of the orbitofrontal cortex and the striatum in the computation of goal values and prediction errors. <em>Journal of Neuroscience, 28</em>: 5623\u20135630.</small></p>\n<p><small>Hare, Camerer, &amp; Rangel (2009). Self-control in decisionmaking involves modulation of the vmPFC valuation system. <em>Science, 324</em>: 646\u2013648.</small></p>\n<p><small>Heeger (1992).&nbsp;Normalization of cell responses in cat striate cortex. <em>Visual Neuroscience, 9</em>: 181\u2013197.</small></p>\n<p><small>Kable &amp; Glimcher (2007).&nbsp;The neural correlates of subjective value during intertemporal choice. <em>Nature Neuroscience, 10</em>: 1625\u20131633.</small></p>\n<p><small>Kable &amp; Glimcher (2009).&nbsp;<a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/kable_glimcher2009.pdf\">The Neurobiology of Decision: Consensus and Controversy</a>. <em>Neuron, 63</em>: 733-745.</small></p>\n<p><small>Kahneman &amp; Tversky (1979). Prospect Theory: An Analysis of Decision under Risk. <em>Econometrica, XLVII</em>: 263-291.</small></p>\n<p><small>Kempermann, Kuhn, &amp; Gage (1997). More hippocampal neurons in adult mice living in an enriched environment. <em>Nature, 386</em>: 493-495.</small></p>\n<p><small>Kiani,&nbsp;Hanks, &amp; Shadlen (2008). Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment. <em>Journal of Neuroscience, 28</em>: 3017\u20133029.</small></p>\n<p><small>Knutson &amp; Cooper (2005).&nbsp;Functional magnetic resonance imaging of reward prediction. <em>Current Opinions in Neurology, 18</em>: 411\u2013417.</small></p>\n<p><small>Kobayashi &amp; Schultz (2008).&nbsp;In\ufb02uence of reward delays on responses of dopamine neurons. <em>Journal of Neuroscience, 28</em>: 7837\u20137846.</small></p>\n<p><small>Lau &amp; Glimcher (2008).&nbsp;Value representations in the primate striatum during matching behavior. <em>Neuron, 58</em>: 451\u2013463.</small></p>\n<p><small>Lee (2008).&nbsp;Game theory and neural basis of social decision making. <em>Nature Neuroscience, 11</em>: 404\u2013409.</small></p>\n<p><small>Levy, Rustichini &amp; Glimcher (2007). A single system represents subjective value under both risky and ambiguous decision-making in humans. In <em>37th Annual Society for Neuroscience Meeting</em>, San Diego, California.</small></p>\n<p><small>Levy,&nbsp;Snell, Nelson, Rustichini, &amp; Glimcher (2010). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/levy_glimcher2010.pdf\">Neural Representation of Subjective Value Under Risk and Ambiguity</a>. <em>Journal of Neurophysiology, 103</em>: 1036-1047.</small></p>\n<p><small>Leyton (2009). The neurobiology of desire: Dopamine and the regulation of mood and motivational states in humans.&nbsp;In Kringelbach &amp; Berridge (eds.),&nbsp;<em style=\"font-style: italic;\">Pleasures of the brain</em>&nbsp;(pp. 222-243). Oxford University Press.</small></p>\n<p><small>Louie &amp; Glimcher (2010).&nbsp;<a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/Louie_Glimcher_2010.pdf\">Separating value from choice: delay discounting activity in the lateral intraparietal area</a>. <em>Journal of Neuroscience, 30(16)</em>: 5498-5507.</small></p>\n<p><small>Montague (2007).&nbsp;<em><a href=\"http://www.amazon.com/Your-Brain-Almost-Perfect-Decisions/dp/B001A5Q3WS/\">Your brain is (almost) perfect: How we make decisions</a></em>. Plume.</small></p>\n<p><small>Montague &amp; Lohrenz (2007).&nbsp;To detect and correct: Norm violations and their enforcement. <em>Neuron, 56</em>: 14\u201318.</small></p>\n<p><small>Niv &amp; Montague (2008).&nbsp;Theoretical and empirical studies oflearning. In Glimcher, Camerer, Fehr, &amp; Poldrack (eds.), <em>Neuroeconomics: Decision Making and the Brain</em> (pp. 331-351). Academic Press.</small></p>\n<p><small>O\u2019Doherty (2004).&nbsp;Reward representations and reward-related learning in the human brain: insights from neuroimaging. <em>Current Opinions in Neurobiology, 14</em>: 769\u2013776.</small></p>\n<p><small>Padoa-Schioppa &amp; Assad (2006).&nbsp;Neurons in the orbitofrontalcortex encode economic value. <em>Nature, 441</em>: 223\u2013226.</small></p>\n<p><small>Padoa-Schioppa &amp; Assad (2008). The representation of economic value in the orbitofrontal cortex is invariant for changes of menu. <em>Nature Neuroscience 11</em>: 95\u2013102.</small></p>\n<p><small>Pessiglione,&nbsp;Seymour, Flandin, Dolan, &amp; Frith (2006). Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans. <em>Nature, 442</em>: 1042\u20131045.</small></p>\n<p><small>Plassmann, O\u2019Doherty, &amp; Rangel (2007). Orbitofrontal cortex encodes willingness to pay in everyday economic transactions. <em>Journal of Neuroscience, 27</em>: 9984\u20139988.</small></p>\n<p><small>Platt &amp; Glimcher (1999).&nbsp;Neural correlates of decision variables in parietal cortex. <em>Nature, 400</em>: 233\u2013238.</small></p>\n<p><small>Politser (2008).&nbsp;<em><a href=\"http://www.amazon.com/Neuroeconomics-Guide-Science-Making-Choices/dp/0195305825/\">Neuroeconomics: a guide to the new science of making choices</a></em>. Oxford University Press.</small></p>\n<p><small>Rangel,&nbsp;Camerer, &amp; Montague (2008). A framework for studying the neurobiology of value-based decision making. <em>Nature Reviews Neuroscience, 9</em>: 545\u2013556</small></p>\n<p><small>Roesch, Calu, &amp; Schoenbaum (2007). Dopamine neurons encode the better option in rats deciding between differently delayed or sized rewards. <em>Nature Neuroscience, 10</em>: 1615\u20131624.</small></p>\n<p><small>Rutledge, Dean, Caplin, &amp; Glimcher (2010). <a href=\"http://www.cns.nyu.edu/~glimcher/PUBLICATIONS/abstracts/Rutledge_Dean_Caplin2010.pdf\">Testing the reward prediction error hypothesis with an axiomatic model</a>. <em>Journal of Neuroscience, 30(40)</em>: 13525-13536.</small></p>\n<p><small>Samejima, Ueda, Doya &amp; Kimura (2005). Representation ofaction-speci\ufb01c reward values in the striatum. <em>Science, 310</em>: 1337\u20131340.</small></p>\n<p><small>Sanfey, Loewenstein, McClure, &amp; Cohen (2006).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sanfey-Neuroeconomics-cross-currents-in-research-on-decision-making.pdf\">Neuroeconomics: cross-currents in research on decision-making</a>.&nbsp;<em>Trends in Cognitive Science, 10</em>: 108\u2013116.</small></p>\n<p><small>Schultz,&nbsp;Dayan, &amp; Montague (1997). A neural substrate of prediction and reward. <em>Science, 275</em>: 1593\u20131599.</small></p>\n<p><small>Shadlen &amp; Newsome (2001).&nbsp;Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey. <em>Journal of Neurophysiology, 86</em>: 1916\u20131936.</small></p>\n<p><small>Singer &amp; Fehr (2005).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Singer-Fehr-The-neuroeconomics-of-mind-reading-and-empathy.pdf\">The neuroeconomics of mind reading and empathy</a>. <em>American Economic Review, 95</em>:&nbsp;340\u2013345.</small></p>\n<p><small>Smith, Mahler, Pecina, &amp; Berridge (2009). Hedonic hotspots: generating sensory pleasure in the brain. In Kringelbach &amp; Berridge (eds.), <em>Pleasures of the brain</em> (pp. 27-49). Oxford University Press.</small></p>\n<p><small>Sugrue,&nbsp;Corrado, &amp; Newsome (2004). Matching behavior and the representation of value in the parietal cortex. <em>Science, 304</em>: 1782\u20131787.</small></p>\n<p><small>Sutton &amp; Barto (1998). <em><a href=\"http://www.amazon.com/dp/0262193981/\">Reinforcement Learning: An Introduction</a></em>. MIT Press.</small></p>\n<p><small>Takahashi, Roesch, Stalnaker, Haney, Calu, Taylor, Burke, &amp; Schoenbaum (2009). The orbitofrontal cortex andventral tegmental area are necessary for learning from unexpected outcomes. <em>Neuron, 62</em>: 269\u2013280.</small></p>\n<p><small>Tobler,&nbsp;Dickinson, &amp; Schultz (2003). Coding of predicted reward omission by dopamine neurons in a conditioned inhibition paradigm. <em>Journal of Neuroscience, 23</em>: 10402\u201310410.</small></p>\n<p><small>Tobler, Fiorillo, &amp; Schultz (2005). Adaptive coding of rewardvalue by dopamine neurons. <em>Science, 307</em>: 1642\u20131645.</small></p>\n<p><small>Tom,&nbsp;Fox, Trepel &amp; Poldrack (2007). The neural basis of loss aversion in decision-making under risk. <em>Science, 315</em>: 515\u2013518.</small></p>\n<p><small>Tversky &amp; Kahneman (1981). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Tversky-Kahneman-The-framing-of-decisions-and-the-psychology-of-choice.pdf\">The framing of decisions and the psychology of choice</a>. <em>Science, 211(4481)</em>: 453\u2013458.</small></p>\n<p><small>von Neumann &amp; Morgenstern (1944).&nbsp;<em><a href=\"http://www.amazon.com/dp/0691130612/\">Theory of Games and Economic Behavior</a></em>. Princeton University Press.</small></p>\n<p><small>Waelti,&nbsp;Dickinson, &amp; Schultz (2001). Dopamine responses comply with basic assumptions of formal learning theory. <em>Nature, 412</em>: 43\u201348.</small></p>\n<p><small>Wang (2008).&nbsp;Decision making in recurrent neuronal circuits. <em>Neuron, 60</em>: 215\u2013234.</small></p>\n<p><small>Yang &amp; Shadlen (2007).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Yang-Probabilistic-reasoning-by-neurons.pdf\">Probabilistic reasoning by neurons</a>. <em>Nature, 447</em>: 1075\u20131080.</small></p>\n<p><small>Yu &amp; Dayan (2005).&nbsp;Uncertainty, neuromodulation and attention. <em>Neuron, 46</em>: 681\u2013692.</small></p>\n<p><small>Zaghloul,&nbsp;Blanco, Weidemann, McGill, Jaggi, Baltuch, &amp; Kahana (2009). Human substantia nigra neurons encode unexpected \ufb01nancial rewards. <em>Science, 323</em>: 1496\u20131499.</small></p>", "sections": [{"title": "The birth of neuroeconomics", "anchor": "The_birth_of_neuroeconomics", "level": 2}, {"title": "Valuation and choice in the brain", "anchor": "Valuation_and_choice_in_the_brain", "level": 1}, {"title": "Self-help", "anchor": "Self_help", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 2}, {"title": "References", "anchor": "References", "level": 2}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "30 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv", "4ARaTpNX62uaL86j6", "zThWT5Zvifo5qYaca", "tPqQdLCuxanjhoaNs", "synsRtBKDeAFuo7e3", "rRmisKb45dN7DK4BW", "TKdpSzmcezNbfmGAy", "zJZvoiwydJ5zvzTHK", "zNcLnqHF5rvrTsQJx", "knpAQ4F3gmguxy39z"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T00:02:53.215Z", "modifiedAt": null, "url": null, "title": "Self-modification, morality, and drugs", "slug": "self-modification-morality-and-drugs", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.373Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "fubarobfusco", "createdAt": "2010-09-26T23:03:54.946Z", "isAdmin": false, "displayName": "fubarobfusco"}, "userId": "ikCc3sp9Zguwdqipb", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/XcyCqYaFGuQ2Bb5PA/self-modification-morality-and-drugs", "pageUrlRelative": "/posts/XcyCqYaFGuQ2Bb5PA/self-modification-morality-and-drugs", "linkUrl": "https://www.lesswrong.com/posts/XcyCqYaFGuQ2Bb5PA/self-modification-morality-and-drugs", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Self-modification%2C%20morality%2C%20and%20drugs&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASelf-modification%2C%20morality%2C%20and%20drugs%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXcyCqYaFGuQ2Bb5PA%2Fself-modification-morality-and-drugs%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Self-modification%2C%20morality%2C%20and%20drugs%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXcyCqYaFGuQ2Bb5PA%2Fself-modification-morality-and-drugs", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FXcyCqYaFGuQ2Bb5PA%2Fself-modification-morality-and-drugs", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 738, "htmlBody": "<p>No, not psychoactive drugs: allergy drugs.</p>\n<p>This is my attempt to come to grips with the idea of self-modification. I'm interested to know of any flaws folks might spot in this analogy or reasoning.</p>\n<p>Gandhi wouldn't take a pill that would make him want to kill people. That is to say, a person whose conscious conclusions agree with their moral impulses wouldn't self-modify in such a way that they no longer care about morally significant things. But, what about morally <em>insignificant</em>&nbsp;things? Specifically, is <em>willingness to self-modify about X</em> a good guide to whether X is morally significant?</p>\n<p>A person with untreated pollen allergies cares about pollen; they have to. In order to have a coherent thought without sneezing in the middle of it, they have to avoid inhaling pollen. They may even perceive pollen as a personal enemy, something that attacks them and makes them feel miserable. But they would gladly take a drug that makes them <em>not care about pollen,</em>&nbsp;by turning off or weakening their immune system's response to it. That's what allergy drugs are for.</p>\n<p>But a sane person would not shut off their <em>entire</em> immune system, including responses to pathogens that are <em>actually</em> attacking their body. Even if giving themselves an immune deficiency would stop their allergies, a sane allergy sufferer wouldn't do it; they know that the immune system is there for a reason, to defend against actual attacks, even if their particular immune system is erroneously sensitive to pollen as well as to pathogens.</p>\n<p>My job involves maintaining computer systems. Like other folks in this sort of job, my team use an automated monitoring system that will send us an alert (by pager or SMS), waking us up at night if necessary, if something goes wrong with the systems. We want to receive significant alerts, and not receive false positives. We regularly modify the monitoring system to prevent false positives, because we don't like being woken up at night for no good reason. But we wouldn't want to turn off the monitoring system entirely; we actually want to receive true alerts, and we will take action to refine our monitoring system to deliver more accurate, more timely true alerts &mdash; because we would like to improve our systems to make them fail less often. We want to <em>win</em>, and false positives or negatives detract from winning.</p>\n<p>Similarly, there are times when we conclude that our moral impulses are incorrect: that they are firing off \"bad! evil! sinful!\" or \"good! virtuous! beneficent!\" alerts about things that are not actually bad or good; or that they are failing to fire for things which are. Performing the requisite Bayesian update is quite difficult: training yourself to <em>feel</em>&nbsp;that donating to an ineffective charity is not at all praiseworthy, or that it can be morally preferable to work for money and donate it, than to volunteer; altering the thoughts that come unbidden to mind when you think of eating meat, in accordance with a decision that vegetarianism is or is not morally preferable; and so on.</p>\n<p>A sane allergy sufferer wants to update his or her immune system to make it stop having false positives, but doesn't want to turn it off entirely; and may want to upgrade its response sometimes, too. A sane system administrator wants to update his or her monitoring tools to make them stop having false positives, but doesn't want to turn it off entirely; and sometimes will program new alerts to avoid false negatives. There is a <em>fact of the matter</em>&nbsp;of whether a particular particle is innocuous pollen or a dangerous pathogen; there is a <em>fact of the matter</em>&nbsp;of whether a text message alert coincides with a down web server; and this fact of the matter <em>explains exactly why</em>&nbsp;we would or wouldn't want to alter our immune system or our servers' monitoring system.</p>\n<p>The same may apply to our moral impulses: to decide that something is morally significant is, if we are consistent, equivalent to deciding that we would not self-modify to avoid noticing that significance; to decide that it is morally significant is equivalent to deciding that we would self-modify to notice it more reliably.</p>\n<p><strong>EDIT:</strong>&nbsp;Thanks for the responses. After mulling this over and consulting the Sequences, it seems that the kind of self-modification I'm talking about above is summed up by the training of System 1 by System 2 discussed <a title=\"waaay back here\" href=\"/lw/go/why_truth_and/\">waaaaay back here</a>. Self-modification for FAI purposes is a level above this. I am only an egg.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2, "xHjy88N2uJvGdgzfw": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "XcyCqYaFGuQ2Bb5PA", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 24, "extendedScore": null, "score": 5e-05, "legacy": true, "legacyId": "6707", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 24, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 5, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["YshRbqZHYFoEMqFAu"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T02:35:22.802Z", "modifiedAt": null, "url": null, "title": "Separate morality from free will", "slug": "separate-morality-from-free-will", "viewCount": null, "lastCommentedAt": "2017-06-17T04:19:37.883Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NPa4coCaqKJFviEEX/separate-morality-from-free-will", "pageUrlRelative": "/posts/NPa4coCaqKJFviEEX/separate-morality-from-free-will", "linkUrl": "https://www.lesswrong.com/posts/NPa4coCaqKJFviEEX/separate-morality-from-free-will", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Separate%20morality%20from%20free%20will&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASeparate%20morality%20from%20free%20will%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNPa4coCaqKJFviEEX%2Fseparate-morality-from-free-will%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Separate%20morality%20from%20free%20will%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNPa4coCaqKJFviEEX%2Fseparate-morality-from-free-will", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNPa4coCaqKJFviEEX%2Fseparate-morality-from-free-will", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1462, "htmlBody": "<p>[I made significant edits when moving this to the main page - so if you read it in Discussion, it's different now. &nbsp;It's clearer about the distinction between two different meanings of \"free\", and why linking one meaning of \"free\" with morality implies a focus on an otherworldly soul.]</p>\n<p>It was funny to me that many people thought <a href=\"/lw/4x9/crime_and_punishment/\">Crime and Punishment</a> was advocating outcome-based justice. &nbsp;If you read the post carefully, nothing in it <em>advocates</em>&nbsp;outcome-based justice. &nbsp;I only wanted to show how people think, so I could write this post.</p>\n<p>Talking about morality causes much confusion, because most philosophers - and most people - do&nbsp;<em style=\"font-style: italic; \">not have a distinct concept of morality</em>. &nbsp;At best, they have just one word that composes two different concepts. &nbsp;At worst, their \"morality\" doesn't contain any new primitive concepts at all; it's just a macro: a shorthand for a combination of other ideas.</p>\n<p>I think - and have, for as long as I can remember - that morality is about doing the right thing. &nbsp;But this is&nbsp;<em>not</em>&nbsp;what most people think morality is about!</p>\n<p><a id=\"more\"></a></p>\n<h3>Free will and morality</h3>\n<p>Kant&nbsp;<a href=\"http://www.prometheus-journal.com/2009/02/morality-rationality-and-freedom-kant%E2%80%99s-argument-for-free-will/\">argued</a>&nbsp;that the existence of morality implies the existence of free will.&nbsp; Roughly:&nbsp; If you don't have free will, you can't be moral, because you can't be responsible for your actions.<sup>1</sup></p>\n<p>The Stanford Encyclopedia of Philosophy&nbsp;<a href=\"http://plato.stanford.edu/entries/freewill/\">says</a>: \"Most philosophers suppose that the concept of free will is very closely connected to the concept of moral responsibility. Acting with free will, on such views, is just to satisfy the metaphysical requirement on being responsible for one's action.\" &nbsp;(\"Free will\" in this context refers to a mysterious philosophical phenomenological concept related to consciousness - not to whether someone pointed a gun at the agent's head.)</p>\n<p>I was thrown for a loop when I first came across people saying that morality has something to do with free will. &nbsp;If morality is about <em>doing the right thing</em>, then free will has nothing to do with it. &nbsp;Yet we find Kant, and others, going on about how choices can be moral only if they are free.</p>\n<p>The pervasive attitudes I described in&nbsp;<a href=\"/lw/4x9/crime_and_punishment/\">Crime and Punishment</a>&nbsp;threw me for the exact same loop. &nbsp;Committing a crime is, generally, regarded as immoral. &nbsp;(I am not claiming that it <em>is</em>&nbsp;immoral. &nbsp;I'm talking descriptively about general beliefs.) &nbsp;Yet people see the <em>practical</em> question of&nbsp;whether the criminal is likely to commit the same crime again, as being in conflict with the \"moral\" question of whether the criminal had free will. &nbsp;If you have no free will, they say, you can do the wrong thing, and be moral; or you can do the right thing, and not be moral.</p>\n<p>The only way this can make sense, is if morality does&nbsp;<em>not mean doing the right thing</em>. &nbsp;I need the term \"morality\" to mean a set of values, so that I can talk to people about values without confusing both of us. &nbsp;But Kant and company say that, without free will, implementing a set of values is not moral behavior. &nbsp;For them, the question of what is moral is not merely the question of what values to choose (although that may be part of it). &nbsp;So what <em>is</em>&nbsp;this morality thing?</p>\n<h3>Don't judge my body - judge my soul</h3>\n<div>\n<p>My theory #1: &nbsp;Most people think that being moral means acting in a way that will earn you credit with God.</p>\n<p>When theory #1 holds, \"being moral\" is shorthand for \"acting in your own long-term self-interest\". &nbsp;Which is pretty much the opposite of what we usually pretend being moral means.</p>\n<div style=\"margin-bottom: 1em; \">(Finding a person who believes free will is needed for morality, and also that one should be moral&nbsp;even if neither God nor the community could observe, does not disprove that theory #1 is a valid characterization of the logic behind linking morals and free will. &nbsp;The world is full of illogical people. &nbsp;My impression, however, is that the people who insist that free will is needed for morality are the same people who insist that religion is needed for morality. &nbsp;This makes sense, if religion is needed to provide an observer to provide credit.)</div>\n<p>My less-catchy but more-general theory #2, which includes #1 as a special case: &nbsp;Most people conceive of morality in a way that assumes soul-body duality. &nbsp;This also includes people who don't believe in a God who rewards and punishes in the afterlife, but still believe in a soul that can be virtuous or unvirtuous independent of how virtuous the body it is encased in is.</p>\n</div>\n<div>When you see (philosophical) free will being made a precondition for moral behavior, it means that the speaker is not concerned with doing the right thing. &nbsp;They are concerned with winning transcendent virtue points for their soul.</div>\n<h3>Moral behavior is intentional, but need not be free</h3>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \">I think both sides agree that morality has to do with intentions. &nbsp;You can't be moral unintentionally. &nbsp;That's because morality is (again, AFAIK we all agree) a property of a cognitive agent, not a property of the agent and its environment. &nbsp;Something that an agent doesn't know about its environment has no impact on whether we judge that agent's actions to be moral.&nbsp; Knowing the agent's intentions helps us know if this is an agent that we can expect to do the right thing in the future. &nbsp;But computers, machines, even thermostats, can have intentions ascribed to them. &nbsp;To decide how we should be disposed towards these agents, we don't need to worry about the phenomenological status of these intentions, or whether there are quantum doohickeys in their innards giving them free will. &nbsp;Just about what they're likely to do.</div>\n</div>\n<div>If people were concerned with doing the right thing, and getting credit for it in this world, they would only need to ask about an agent's intentions. &nbsp;They would care whether Jim's actions were free in the \"no one pointed a gun at him and made him do it\" sense, because if Joe made Jim do it, then Joe should be given the credit or blame. &nbsp;But they wouldn't need to ask whether Jim's intentions were free in the \"free will vs. determinism\" or \"free will vs. brain deficiency\" sense. &nbsp;Having an inoperable brain condition would not affect how we used a person's actions to predict whether they were likely to do similar things in the future - they're still going to have the brain condition. &nbsp;We only change our credit assignment due to a brain condition if we are trying to assign credit to the &nbsp;<em>non-physical</em>&nbsp;part of a person (their soul).</div>\n<div>(At this point I should also mention theory #3: &nbsp;Most people fail to distinguish between \"done with philosophical free will\" and \"intentional\". &nbsp;They thus worry about philosophical free will when they mean to worry about intention.)<sup>2</sup></div>\n<h3>Why we should separate the concepts of \"morality\" and \"free will\"</h3>\n<div>\n<div>The majority opinion of what a word means is, by definition, the descriptively correct usage of the word.&nbsp; I'm not arguing that the majority usage is descriptively wrong.&nbsp; I'm arguing that it's prescriptively wrong, for these reasons:</div>\n</div>\n<div>\n<ul>\n<li>It isn't&nbsp; <em>parsimonious</em>.&nbsp; It confuses the question of figuring out what values are good, and what behaviors are good, with the philosophical problem of free will.&nbsp; Each of these problems is difficult enough on its own!</li>\n<li>It is&nbsp; <em>inconsistent</em>&nbsp; with our other definitions. &nbsp;People map questions about what is right and wrong onto questions about morality.&nbsp; They will get garbage out of their thinking if that concept, internally, is about something different.&nbsp; They end up believing there are no objective morals - not necessarily because they've thought it through logically, but because their conflicting definitions make them incapable of coherent thought on the subject.</li>\n<li>It implies that morality is impossible without free will.&nbsp; Since a lot of people on LW don't believe in free will, they would conclude that they don't believe in morality if they subscribed to Kant's view.</li>\n<li>When questions of blame and credit take center stage, people lose the capacity to think about values. &nbsp;This is demonstrated by some Christians who talk a lot about morality, but<em>&nbsp;</em>assume, without even noticing they're doing it,&nbsp;that \"moral\" is a macro for \"God said do this\". &nbsp;They failed to notice that they had encoded two concepts into one word, and never got past the first concept.</li>\n</ul>\nFor morality to be about&nbsp; <em>oughtness</em>, so that we are able to reason about values, we need to divorce it completely from free will.&nbsp; Free will is still an interesting and possibly important problem.&nbsp; But we shouldn't mix it in together with the already-difficult-enough problem of what actions and values are moral.<br /></div>\n<div><br /></div>\n<div>\n<p>1. I am making the most-favorable re-interpretation.&nbsp; Kant's argument is worse, as it takes a nonsensical detour from morality, through rationality, back to free will.</p>\n<p>2. This is the preferred theory under, um, Goetz's Cognitive Razor: &nbsp;Prefer the explanation for someone's behavior that supposes the least internal complexity of them.</p>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 2, "5f5c37ee1b5cdee568cfb1b8": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NPa4coCaqKJFviEEX", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 8, "extendedScore": null, "score": 1.7e-05, "legacy": true, "legacyId": "6402", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>[I made significant edits when moving this to the main page - so if you read it in Discussion, it's different now. &nbsp;It's clearer about the distinction between two different meanings of \"free\", and why linking one meaning of \"free\" with morality implies a focus on an otherworldly soul.]</p>\n<p>It was funny to me that many people thought <a href=\"/lw/4x9/crime_and_punishment/\">Crime and Punishment</a> was advocating outcome-based justice. &nbsp;If you read the post carefully, nothing in it <em>advocates</em>&nbsp;outcome-based justice. &nbsp;I only wanted to show how people think, so I could write this post.</p>\n<p>Talking about morality causes much confusion, because most philosophers - and most people - do&nbsp;<em style=\"font-style: italic; \">not have a distinct concept of morality</em>. &nbsp;At best, they have just one word that composes two different concepts. &nbsp;At worst, their \"morality\" doesn't contain any new primitive concepts at all; it's just a macro: a shorthand for a combination of other ideas.</p>\n<p>I think - and have, for as long as I can remember - that morality is about doing the right thing. &nbsp;But this is&nbsp;<em>not</em>&nbsp;what most people think morality is about!</p>\n<p><a id=\"more\"></a></p>\n<h3 id=\"Free_will_and_morality\">Free will and morality</h3>\n<p>Kant&nbsp;<a href=\"http://www.prometheus-journal.com/2009/02/morality-rationality-and-freedom-kant%E2%80%99s-argument-for-free-will/\">argued</a>&nbsp;that the existence of morality implies the existence of free will.&nbsp; Roughly:&nbsp; If you don't have free will, you can't be moral, because you can't be responsible for your actions.<sup>1</sup></p>\n<p>The Stanford Encyclopedia of Philosophy&nbsp;<a href=\"http://plato.stanford.edu/entries/freewill/\">says</a>: \"Most philosophers suppose that the concept of free will is very closely connected to the concept of moral responsibility. Acting with free will, on such views, is just to satisfy the metaphysical requirement on being responsible for one's action.\" &nbsp;(\"Free will\" in this context refers to a mysterious philosophical phenomenological concept related to consciousness - not to whether someone pointed a gun at the agent's head.)</p>\n<p>I was thrown for a loop when I first came across people saying that morality has something to do with free will. &nbsp;If morality is about <em>doing the right thing</em>, then free will has nothing to do with it. &nbsp;Yet we find Kant, and others, going on about how choices can be moral only if they are free.</p>\n<p>The pervasive attitudes I described in&nbsp;<a href=\"/lw/4x9/crime_and_punishment/\">Crime and Punishment</a>&nbsp;threw me for the exact same loop. &nbsp;Committing a crime is, generally, regarded as immoral. &nbsp;(I am not claiming that it <em>is</em>&nbsp;immoral. &nbsp;I'm talking descriptively about general beliefs.) &nbsp;Yet people see the <em>practical</em> question of&nbsp;whether the criminal is likely to commit the same crime again, as being in conflict with the \"moral\" question of whether the criminal had free will. &nbsp;If you have no free will, they say, you can do the wrong thing, and be moral; or you can do the right thing, and not be moral.</p>\n<p>The only way this can make sense, is if morality does&nbsp;<em>not mean doing the right thing</em>. &nbsp;I need the term \"morality\" to mean a set of values, so that I can talk to people about values without confusing both of us. &nbsp;But Kant and company say that, without free will, implementing a set of values is not moral behavior. &nbsp;For them, the question of what is moral is not merely the question of what values to choose (although that may be part of it). &nbsp;So what <em>is</em>&nbsp;this morality thing?</p>\n<h3 id=\"Don_t_judge_my_body___judge_my_soul\">Don't judge my body - judge my soul</h3>\n<div>\n<p>My theory #1: &nbsp;Most people think that being moral means acting in a way that will earn you credit with God.</p>\n<p>When theory #1 holds, \"being moral\" is shorthand for \"acting in your own long-term self-interest\". &nbsp;Which is pretty much the opposite of what we usually pretend being moral means.</p>\n<div style=\"margin-bottom: 1em; \">(Finding a person who believes free will is needed for morality, and also that one should be moral&nbsp;even if neither God nor the community could observe, does not disprove that theory #1 is a valid characterization of the logic behind linking morals and free will. &nbsp;The world is full of illogical people. &nbsp;My impression, however, is that the people who insist that free will is needed for morality are the same people who insist that religion is needed for morality. &nbsp;This makes sense, if religion is needed to provide an observer to provide credit.)</div>\n<p>My less-catchy but more-general theory #2, which includes #1 as a special case: &nbsp;Most people conceive of morality in a way that assumes soul-body duality. &nbsp;This also includes people who don't believe in a God who rewards and punishes in the afterlife, but still believe in a soul that can be virtuous or unvirtuous independent of how virtuous the body it is encased in is.</p>\n</div>\n<div>When you see (philosophical) free will being made a precondition for moral behavior, it means that the speaker is not concerned with doing the right thing. &nbsp;They are concerned with winning transcendent virtue points for their soul.</div>\n<h3 id=\"Moral_behavior_is_intentional__but_need_not_be_free\">Moral behavior is intentional, but need not be free</h3>\n<div style=\"margin-bottom: 1em; \">\n<div style=\"margin-bottom: 1em; \">I think both sides agree that morality has to do with intentions. &nbsp;You can't be moral unintentionally. &nbsp;That's because morality is (again, AFAIK we all agree) a property of a cognitive agent, not a property of the agent and its environment. &nbsp;Something that an agent doesn't know about its environment has no impact on whether we judge that agent's actions to be moral.&nbsp; Knowing the agent's intentions helps us know if this is an agent that we can expect to do the right thing in the future. &nbsp;But computers, machines, even thermostats, can have intentions ascribed to them. &nbsp;To decide how we should be disposed towards these agents, we don't need to worry about the phenomenological status of these intentions, or whether there are quantum doohickeys in their innards giving them free will. &nbsp;Just about what they're likely to do.</div>\n</div>\n<div>If people were concerned with doing the right thing, and getting credit for it in this world, they would only need to ask about an agent's intentions. &nbsp;They would care whether Jim's actions were free in the \"no one pointed a gun at him and made him do it\" sense, because if Joe made Jim do it, then Joe should be given the credit or blame. &nbsp;But they wouldn't need to ask whether Jim's intentions were free in the \"free will vs. determinism\" or \"free will vs. brain deficiency\" sense. &nbsp;Having an inoperable brain condition would not affect how we used a person's actions to predict whether they were likely to do similar things in the future - they're still going to have the brain condition. &nbsp;We only change our credit assignment due to a brain condition if we are trying to assign credit to the &nbsp;<em>non-physical</em>&nbsp;part of a person (their soul).</div>\n<div>(At this point I should also mention theory #3: &nbsp;Most people fail to distinguish between \"done with philosophical free will\" and \"intentional\". &nbsp;They thus worry about philosophical free will when they mean to worry about intention.)<sup>2</sup></div>\n<h3 id=\"Why_we_should_separate_the_concepts_of__morality__and__free_will_\">Why we should separate the concepts of \"morality\" and \"free will\"</h3>\n<div>\n<div>The majority opinion of what a word means is, by definition, the descriptively correct usage of the word.&nbsp; I'm not arguing that the majority usage is descriptively wrong.&nbsp; I'm arguing that it's prescriptively wrong, for these reasons:</div>\n</div>\n<div>\n<ul>\n<li>It isn't&nbsp; <em>parsimonious</em>.&nbsp; It confuses the question of figuring out what values are good, and what behaviors are good, with the philosophical problem of free will.&nbsp; Each of these problems is difficult enough on its own!</li>\n<li>It is&nbsp; <em>inconsistent</em>&nbsp; with our other definitions. &nbsp;People map questions about what is right and wrong onto questions about morality.&nbsp; They will get garbage out of their thinking if that concept, internally, is about something different.&nbsp; They end up believing there are no objective morals - not necessarily because they've thought it through logically, but because their conflicting definitions make them incapable of coherent thought on the subject.</li>\n<li>It implies that morality is impossible without free will.&nbsp; Since a lot of people on LW don't believe in free will, they would conclude that they don't believe in morality if they subscribed to Kant's view.</li>\n<li>When questions of blame and credit take center stage, people lose the capacity to think about values. &nbsp;This is demonstrated by some Christians who talk a lot about morality, but<em>&nbsp;</em>assume, without even noticing they're doing it,&nbsp;that \"moral\" is a macro for \"God said do this\". &nbsp;They failed to notice that they had encoded two concepts into one word, and never got past the first concept.</li>\n</ul>\nFor morality to be about&nbsp; <em>oughtness</em>, so that we are able to reason about values, we need to divorce it completely from free will.&nbsp; Free will is still an interesting and possibly important problem.&nbsp; But we shouldn't mix it in together with the already-difficult-enough problem of what actions and values are moral.<br></div>\n<div><br></div>\n<div>\n<p>1. I am making the most-favorable re-interpretation.&nbsp; Kant's argument is worse, as it takes a nonsensical detour from morality, through rationality, back to free will.</p>\n<p>2. This is the preferred theory under, um, Goetz's Cognitive Razor: &nbsp;Prefer the explanation for someone's behavior that supposes the least internal complexity of them.</p>\n</div>", "sections": [{"title": "Free will and morality", "anchor": "Free_will_and_morality", "level": 1}, {"title": "Don't judge my body - judge my soul", "anchor": "Don_t_judge_my_body___judge_my_soul", "level": 1}, {"title": "Moral behavior is intentional, but need not be free", "anchor": "Moral_behavior_is_intentional__but_need_not_be_free", "level": 1}, {"title": "Why we should separate the concepts of \"morality\" and \"free will\"", "anchor": "Why_we_should_separate_the_concepts_of__morality__and__free_will_", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "85 comments"}], "headingsCount": 6}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 85, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SCXaRKGhQPkJCMmpm"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T10:18:28.936Z", "modifiedAt": null, "url": null, "title": "Do people think in a Bayesian or Popperian way?", "slug": "do-people-think-in-a-bayesian-or-popperian-way-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:25.463Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curi", "createdAt": "2010-11-14T23:20:06.334Z", "isAdmin": false, "displayName": "curi"}, "userId": "MTDagWBSe2QtC7Qoy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Byi6Gfb5EEW97fTNw/do-people-think-in-a-bayesian-or-popperian-way-0", "pageUrlRelative": "/posts/Byi6Gfb5EEW97fTNw/do-people-think-in-a-bayesian-or-popperian-way-0", "linkUrl": "https://www.lesswrong.com/posts/Byi6Gfb5EEW97fTNw/do-people-think-in-a-bayesian-or-popperian-way-0", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20people%20think%20in%20a%20Bayesian%20or%20Popperian%20way%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20people%20think%20in%20a%20Bayesian%20or%20Popperian%20way%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FByi6Gfb5EEW97fTNw%2Fdo-people-think-in-a-bayesian-or-popperian-way-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20people%20think%20in%20a%20Bayesian%20or%20Popperian%20way%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FByi6Gfb5EEW97fTNw%2Fdo-people-think-in-a-bayesian-or-popperian-way-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FByi6Gfb5EEW97fTNw%2Fdo-people-think-in-a-bayesian-or-popperian-way-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1014, "htmlBody": "<div>\n<div>People think A&amp;B is more likely than A alone, if you ask the right question. That's not very Bayesian; as far as you Bayesians can tell it's really quite stupid.</div>\n<div>Is that maybe evidence that Bayesianism is faililng to model how people actually thinking?</div>\n<div>Popperian philosophy can make sense of this (without hating on everyone! it's not good to hate on people when there's better options available). It explains it like this: people like explanations. When you say \"A happened because B happened\" it sounds to them like a pretty good explanatory theory which makes sense. When you say \"A alone\" they don't see any explanation and they read it as \"A happened for no apparent reason\" which is a bad explanation, so they score it worse.</div>\n<div>To concretize this, you could use A = economic collapse and B = nuclear war.</div>\n<div>People are looking for good explanations. They are thinking in a Popperian fashion.</div>\n<div>Isn't it weird how you guys talk about all these biases which basically consist of people not thinking in the way you think they should, but when someone says \"hey, actually they think in this way Popper worked out\" you think that's crazy cause the Bayesian model must be correct? Why did you find all these counter examples to your own theory and then never notice they mean your theory is wrong? In the cases where people don't think in a Popperian way, Popper explains why (mostly b/c of the justificationist tradition informing many mistakes since Aristotle)</div>\n<div>More examples, from http://wiki.lesswrong.com/wiki/Bias</div>\n<blockquote>\n<div>Scope Insensitivity - The human brain can't represent large quantities: an environmental measure that will save 200,000 birds doesn't conjure anywhere near a hundred times the emotional impact and willingness-to-pay of a measure that would save 2,000 birds.</div>\n</blockquote>\n<div>Changing the number does not change most of the explanations involved, such as why helping birds is good, what the person can afford to spare, how much charity it takes the person to feel altruistic enough (or moral enough, involved enough, helpful enough, whatever), etc... Since the major explanatory factors they were considering don't change in proportion to the number of birds, their answer doesn't change proportionally either.</div>\n<blockquote>\n<div>Correspondence Bias, also known as the fundamental attribution error, refers to the tendency to attribute the behavior of others to intrinsic dispositions, while excusing one's own behavior as the result of circumstance.</div>\n</blockquote>\n<div>This happens because people usually know the explanations/excuses for why they did stuff, but they don't know them for others. And they have more reason to think of them for themselves.</div>\n<blockquote>\n<div>Confirmation bias, or Positive Bias is the tendency to look for evidence that confirms a hypothesis, rather than disconfirming evidence.</div>\n</blockquote>\n<div>People do this because of the justificationist tradition, dating back to Aristotle, which Bayesian epistemology is part of, and which Popper rejected. This is a way people really don't think in the Popperian way -- but they could and should.</div>\n<blockquote>\n<div>Planning Fallacy - We tend to plan envisioning that everything will go as expected. Even assuming that such an estimate is accurate conditional on everything going as expected, things will not go as expected. As a result, we routinely see outcomes worse then the ex ante worst case scenario.</div>\n</blockquote>\n<div>This is also caused by the justificationist tradition, which Bayesian epistemology is part of. It's not fallibilist enough. This is a way people really don't think in the Popperian way -- but they could and should.</div>\n<div>Well, that's part of the issue. The other part is they come up with a good explanation of what will happen, and they go with that. That part of their thinking fits what Popper said people do. The problem is not enough criticism, which is from the popularity of justificationism.</div>\n<blockquote>\n<div>Do We Believe Everything We're Told? - Some experiments on priming suggest that mere exposure to a view is enough to get one to passively accept it, at least until it is specifically rejected.</div>\n</blockquote>\n<div>That's very Popperian. The Popperian way is that you can make conjectures however you want, and you only reject them if there's a criticism. No criticism, no rejection. This contrasts with the justificationist approach in which ideas are required to (impossibly) have positive support, and the focus is on positive support not criticism (thus causing, e.g., Confirmation Bias)</div>\n<blockquote>\n<div>Illusion of Transparency - Everyone knows what their own words mean, but experiments have confirmed that we systematically overestimate how much sense we are making to others.</div>\n</blockquote>\n<div>This one is off topic but there's several things I wanted to say. First, people don't always know what their own words mean. People talking about tricky concepts like God, qualia, or consciousness often can't explain what they mean by the words if asked. Sometimes people even use words without knowing the definition, they just heard it in a similar circumstance another time or something.</div>\n<div>The reason others don't understand us, often, is because of the nature of communication. To communicate what has to happen is the other person creates knoweldge of what idea(s) you are trying to express to him. That means he has to make guesses about what you are saying and use criticisms to improve those guesses (e.g. by ruling stuff out incompatible with the words he heard you use). In this way Popperian epistemology lets us understand communication, and why it's so hard.</div>\n<blockquote>\n<div>Evaluability - It's difficult for humans to evaluate an option except in comparison to other options. Poor decisions result when a poor category for comparison is used. Includes an application for cheap gift-shopping.</div>\n</blockquote>\n<div>It's because they are trying to come up with a good explanation of what to buy. And \"this one is better than this other one\" is a pretty simple and easily available kind of explanation to create.</div>\n<blockquote>\n<div>The Allais Paradox (and subsequent followups) - Offered choices between gambles, people make decision-theoretically inconsistent decisions.</div>\n</blockquote>\n<div>How do you know that kind of thing and still think people reason in a Bayesian way? They don't. They just guess at what to gamble, and the quality of the guesses is limited by what criticisms they use. If they dont' know much math then they don't subject their guesses to much mathematical criticism. Hence this mistake.</div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Byi6Gfb5EEW97fTNw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 35, "baseScore": -31, "extendedScore": null, "score": 7.00569191005815e-07, "legacy": true, "legacyId": "6710", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T14:45:51.090Z", "modifiedAt": null, "url": null, "title": "Reasons for SIAI to not publish in mainstream journals", "slug": "reasons-for-siai-to-not-publish-in-mainstream-journals", "viewCount": null, "lastCommentedAt": "2017-06-17T04:27:06.990Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cKD85YRn7fy95WkmN/reasons-for-siai-to-not-publish-in-mainstream-journals", "pageUrlRelative": "/posts/cKD85YRn7fy95WkmN/reasons-for-siai-to-not-publish-in-mainstream-journals", "linkUrl": "https://www.lesswrong.com/posts/cKD85YRn7fy95WkmN/reasons-for-siai-to-not-publish-in-mainstream-journals", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Reasons%20for%20SIAI%20to%20not%20publish%20in%20mainstream%20journals&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AReasons%20for%20SIAI%20to%20not%20publish%20in%20mainstream%20journals%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcKD85YRn7fy95WkmN%2Freasons-for-siai-to-not-publish-in-mainstream-journals%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Reasons%20for%20SIAI%20to%20not%20publish%20in%20mainstream%20journals%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcKD85YRn7fy95WkmN%2Freasons-for-siai-to-not-publish-in-mainstream-journals", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcKD85YRn7fy95WkmN%2Freasons-for-siai-to-not-publish-in-mainstream-journals", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 158, "htmlBody": "<p>Recently, I <a href=\"/lw/4r1/how_siai_could_publish_in_mainstream_cognitive/\">gave</a> some reasons for SIAI to begin publishing in mainstream journals, and outlined how it could be done.</p>\n<p>I've recently been made aware of some pretty good reasons for SIAI to <em>not</em>&nbsp;publish in mainstream journals, so here they are:</p>\n<p><ol>\n<li>Articles published to websites (e.g. <a href=\"http://yudkowsky.net/\">Yudkowsky's work</a>, <a href=\"http://www.nickbostrom.com/\">Bostrom's pre-prints</a>) seem to have gotten more attention, and had more positive impact, than their in-journal counterparts.</li>\n<li>Articles in mainstream journals take a relatively large amount of time, money, and expertise to produce.</li>\n<li>Articles in mainstream journals must jump through lots of hoops - journals' aversion to novelty, reviewer bias, etc.</li>\n<li>It is easier to simply collaborate with (and greatly influence) established mainstream academics who have already jumped through mainstream academia's many hoops (as Carl Shulman has been doing, for example).</li>\n</ol>\n<div>I still think there are strong reasons to publish articles in standard academic <em>form</em>&nbsp;(for readability purposes), but I've recently updated hugely toward SIAI <em>not</em>&nbsp;publishing in mainstream journals.</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cKD85YRn7fy95WkmN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 20, "extendedScore": null, "score": 4.5e-05, "legacy": true, "legacyId": "6712", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["4oWXnodxAu4WgHnrd"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T15:53:34.159Z", "modifiedAt": null, "url": null, "title": "Meaning of the word \"the\"", "slug": "meaning-of-the-word-the", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.528Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Perplexed", "createdAt": "2010-07-22T02:17:37.444Z", "isAdmin": false, "displayName": "Perplexed"}, "userId": "jj9aBsS9xsGPWKq3n", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wSCwRqF7bZGMePFiv/meaning-of-the-word-the", "pageUrlRelative": "/posts/wSCwRqF7bZGMePFiv/meaning-of-the-word-the", "linkUrl": "https://www.lesswrong.com/posts/wSCwRqF7bZGMePFiv/meaning-of-the-word-the", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meaning%20of%20the%20word%20%22the%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeaning%20of%20the%20word%20%22the%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwSCwRqF7bZGMePFiv%2Fmeaning-of-the-word-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meaning%20of%20the%20word%20%22the%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwSCwRqF7bZGMePFiv%2Fmeaning-of-the-word-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FwSCwRqF7bZGMePFiv%2Fmeaning-of-the-word-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 103, "htmlBody": "<p>I need some help tracking down a quotation.&nbsp; I'm pretty sure that it was an early 20th century philosopher - perhaps Russell.&nbsp; He was explaining that modern philosophy no longer tries to find the meaning of life.&nbsp; Post-Witgenstein, it has narrowed its ambitions and now seeks only to discover the meaning of words.&nbsp; He goes on to explain why even this is likely to prove difficult.&nbsp; And then (here is the part I like) he wryly comments that in spite of the difficulties, there has been some progress in working out the meaning of the word \"the\".</p>\n<p>Does that ring a bell for anyone?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wSCwRqF7bZGMePFiv", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 7.006629868659902e-07, "legacy": true, "legacyId": "6713", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T21:23:21.805Z", "modifiedAt": null, "url": null, "title": "Availability bias- please help me find a study", "slug": "availability-bias-please-help-me-find-a-study", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.934Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Vaniver", "createdAt": "2010-10-25T01:59:05.641Z", "isAdmin": true, "displayName": "Vaniver"}, "userId": "fD4ATtTkdQJ4aSpGH", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/v55nTqrjrskpPtnbz/availability-bias-please-help-me-find-a-study", "pageUrlRelative": "/posts/v55nTqrjrskpPtnbz/availability-bias-please-help-me-find-a-study", "linkUrl": "https://www.lesswrong.com/posts/v55nTqrjrskpPtnbz/availability-bias-please-help-me-find-a-study", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Availability%20bias-%20please%20help%20me%20find%20a%20study&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAvailability%20bias-%20please%20help%20me%20find%20a%20study%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv55nTqrjrskpPtnbz%2Favailability-bias-please-help-me-find-a-study%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Availability%20bias-%20please%20help%20me%20find%20a%20study%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv55nTqrjrskpPtnbz%2Favailability-bias-please-help-me-find-a-study", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fv55nTqrjrskpPtnbz%2Favailability-bias-please-help-me-find-a-study", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 155, "htmlBody": "<p>So, the ancient example of availability bias is \"are there more words with 'r' in the first letter or third letter?\" Supposedly, most people say \"first\" when in fact the answer is \"third.\"</p>\n<p>However, I remember reading somewhere recently (I believe on Less Wrong in the last month, probably in a comment?) that this is actually a pretty bad example, as people get it right for a sizable number of letters / the results aren't reliably replicated. Is that the case, and more importantly, where can I find studies that state that (or the opposite)?</p>\n<p>The best I've been able to find is <a href=\"http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6X09-46P4R4X-1J&amp;_user=10&amp;_coverDate=05%2F31%2F1998&amp;_rdoc=1&amp;_fmt=high&amp;_orig=gateway&amp;_origin=gateway&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_rerunOrigin=scholar.google&amp;_acct=C000050221&amp;_version=1&amp;_urlVersion=0&amp;_userid=10&amp;md5=129c18ae5d197f81de06ff4efb70719a&amp;searchtype=a\">this study</a>, which compares 1st letter and 2nd letter frequencies, finding that people are good at estimating those. While it challenges some implications of the earlier finding, it doesn't contradict it. Anyone already familiar with the literature able to point me at something more relevant, or is that the best study out there now?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb19c": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "v55nTqrjrskpPtnbz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.007553228651957e-07, "legacy": true, "legacyId": "6714", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T21:43:11.585Z", "modifiedAt": null, "url": null, "title": "Need help searching for a quote", "slug": "need-help-searching-for-a-quote", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:23.561Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "bfq5YorFxpih9j6nL", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jWZ3fu7i395ntwt4H/need-help-searching-for-a-quote", "pageUrlRelative": "/posts/jWZ3fu7i395ntwt4H/need-help-searching-for-a-quote", "linkUrl": "https://www.lesswrong.com/posts/jWZ3fu7i395ntwt4H/need-help-searching-for-a-quote", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Need%20help%20searching%20for%20a%20quote&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANeed%20help%20searching%20for%20a%20quote%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjWZ3fu7i395ntwt4H%2Fneed-help-searching-for-a-quote%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Need%20help%20searching%20for%20a%20quote%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjWZ3fu7i395ntwt4H%2Fneed-help-searching-for-a-quote", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjWZ3fu7i395ntwt4H%2Fneed-help-searching-for-a-quote", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 163, "htmlBody": "<p>Hey,</p>\n<p>I'm trying to find a quote that I recall seeing in the sequences. It was a post by Eliezer, and near the end he made a statement to the effect that 'We don't always know what is right, but you should <em>never</em>&nbsp;physically harm someone in the course of a dispute. Argumentation is an acceptable answer, but killing is not.'</p>\n<p>I am writing a paper about that claim, and any help finding the particular quote would be incredibly useful. I suspect that it's somewhere in the 'Politics is a Mind-Killer' sub-sequence, though I haven't found it there yet.</p>\n<p>Does anyone know what I'm talking about? Thanks for the help in advance.</p>\n<p>-Michael</p>\n<p><strong>UPDATE: The quote was <a href=\"/lw/lo/uncritical_supercriticality/\">found</a>:</strong></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 16px; \"><em>\"And it is triple ultra forbidden to respond to criticism with violence.&nbsp; There are a very few injunctions in the human art of rationality that have no ifs, ands, buts, or escape clauses.&nbsp; This is one of them.&nbsp; Bad argument gets counterargument.&nbsp; Does not get bullet.&nbsp; Never.&nbsp; Never ever never for ever.\"</em></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jWZ3fu7i395ntwt4H", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.007608754625514e-07, "legacy": true, "legacyId": "6715", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["NCefvet6X3Sd4wrPc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T23:43:42.376Z", "modifiedAt": null, "url": null, "title": "test", "slug": "test-23", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NancyLebovitz", "createdAt": "2009-03-24T11:25:00.619Z", "isAdmin": false, "displayName": "NancyLebovitz"}, "userId": "oxTHYnSBbLZP9F25d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/abMEWxoDLux4FZ4bF/test-23", "pageUrlRelative": "/posts/abMEWxoDLux4FZ4bF/test-23", "linkUrl": "https://www.lesswrong.com/posts/abMEWxoDLux4FZ4bF/test-23", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20test&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Atest%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FabMEWxoDLux4FZ4bF%2Ftest-23%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=test%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FabMEWxoDLux4FZ4bF%2Ftest-23", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FabMEWxoDLux4FZ4bF%2Ftest-23", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p>test</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "abMEWxoDLux4FZ4bF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 1e-06, "legacy": true, "legacyId": "6719", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-10T23:49:55.337Z", "modifiedAt": null, "url": null, "title": "How I applied useful concepts from the personal growth seminar \"est\" and MBTI ", "slug": "how-i-applied-useful-concepts-from-the-personal-growth", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.495Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "suecochran", "createdAt": "2011-04-09T22:05:01.963Z", "isAdmin": false, "displayName": "suecochran"}, "userId": "nvYET9iPrLXHoFoe4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Q8ZmznoR52sc3rTay/how-i-applied-useful-concepts-from-the-personal-growth", "pageUrlRelative": "/posts/Q8ZmznoR52sc3rTay/how-i-applied-useful-concepts-from-the-personal-growth", "linkUrl": "https://www.lesswrong.com/posts/Q8ZmznoR52sc3rTay/how-i-applied-useful-concepts-from-the-personal-growth", "postedAtFormatted": "Sunday, April 10th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20I%20applied%20useful%20concepts%20from%20the%20personal%20growth%20seminar%20%22est%22%20and%20MBTI%20&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20I%20applied%20useful%20concepts%20from%20the%20personal%20growth%20seminar%20%22est%22%20and%20MBTI%20%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ8ZmznoR52sc3rTay%2Fhow-i-applied-useful-concepts-from-the-personal-growth%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20I%20applied%20useful%20concepts%20from%20the%20personal%20growth%20seminar%20%22est%22%20and%20MBTI%20%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ8ZmznoR52sc3rTay%2Fhow-i-applied-useful-concepts-from-the-personal-growth", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQ8ZmznoR52sc3rTay%2Fhow-i-applied-useful-concepts-from-the-personal-growth", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1650, "htmlBody": "<p>I have encountered personally in conversations, and also observed in the media over the past couple of decades, a great deal of skepticism, scorn, and ridicule, if not merely indifference or dismissal, from many people in reaction to the est <a id=\"FALINK_1_0_0\" class=\"FAAdLink\" href=\"/lw/56k/sharing_how_i_applied_useful_concepts_from_the/\">training</a>, which I completed in 1983, and the Myers-Briggs Type Indicator tool, which I first took in 1993 or 1994. I would like to share some concrete examples from my own life where information and perspective that I gained from these two sources have improved my life, both in my own way of conceptualizing and approaching things, and also in my relationships with others. I do this with the hope and intention of showing that est and MBTI have positive value, and encouraging people to explore these and other tools for personal growth.</p>\n<p>One important insight that I gained from the est training is an understanding and the experience that I am not my opinions, and my opinions are not me. Opinions are neutral things, and they may be something I hold, or agree with, but I can separate my self from them, and I can discuss them, and I can change or discard them, but I am still the same \"me\". I am not more or less \"myself\" in relation to what I think or believe. Before I did the est training, whenever someone would question an opinion I held, I felt personally attacked. I identified my self with my opinion or belief. My emotional response to attack, like for many other people, is to defend and/or to retreat, so when I perceived of my \"self\" being \"attacked\", I gave in to the standard fight or <a id=\"FALINK_3_0_2\" class=\"FAAdLink\" href=\"/lw/56k/sharing_how_i_applied_useful_concepts_from_the/\">flight</a> response, and therefore I did not get the opportunity to explore the opinion in question to see if the person who questioned me had some important new information or a perspective that I had not previously considered. It is not that I always remember this or that it is my first response, but once I notice myself responding in the old way, I can then take that <a id=\"FALINK_2_0_1\" class=\"FAAdLink\" href=\"/lw/56k/sharing_how_i_applied_useful_concepts_from_the/\">step</a> back and remember the separation between self and opinion. That choice is now available to me, where it wasn't before. When I find myself in conversations with another person or people who disagree with me, my response now is to draw them out, to ask them about what they believe and why they believe it. I regard myself as if I were a reporter on a fact-finding mission. I step back and I do not feel attacked. I learn sometimes from this, and other times I do not, but I no longer feel attacked, and I find that I can more easily become friends with people even if we have disagreements. That was not the case for me prior to doing est.</p>\n<p>Another valuable tool that I got from est and still use in my life is the ability to accept responsibility without attaching blame to it, even if someone is trying to heap blame upon me. This is similar to what I said above about basically not identifying my self with what I think. I do not have to feel or think of myself as a \"bad person\" because I made a mistake. I have come to the belief that guilt is an emotion that I need not wallow in. If I feel guilt about doing or not doing something, saying or not saying something, I take that feeling of guilt as a sign that I either need to take some action to rectify the situation, and/or I need to apologize to someone about it, and/or I need to learn from the situation so that hopefully I will not repeat it, and then forgive myself, and move on. Hanging on to guilt is something I see many people doing, and it not only holds them up and blocks them off from taking action, they often pull that feeling in and create a scenario or self-definition that involves beating themselves up about it, or they wallow around in feeling guilty in a way that serves as a self-indulgent excuse for not improving things. \"I'm so awful, I'm such a screw-up, I can't do anything right.\" That kind of negative self-esteem can affect a person for their entire life if they allow it to. There are many ways to come to these realizations, and I make no claim that est is some kind of \"cure-all\". One of the characters on the tv show \"SOAP\" called est \"The McDonald's of Psychiatry\". That's amusing, but it denigrates a very useful and powerful experience. I believe in an eclectic approach to life. I look at many things, explore many ideas and experiences, and I take what works and leave the rest. est is only one of many helpful experiences I have had in my 49 years.</p>\n<p>I took the Myers-Briggs Personality Index at a science fiction convention in the early years of my marriage, when I was living in Alexandria, VA, in 1993 and 1994. It was given as part of a panel, and I also took it again when I read \"Do What You Are\", which is a book about finding employment/a profession based on your MBTI personality type. The basics, if you have not encountered MBTI before are: There are 4 \"continuums\" in how people tend to interact with the world. Most people use both sides of each continuum, but are most comfortable on one side. The traits are Extrovert/Introvert, Sensing/Intuiting, Thinking/Feeling, and Judging/Perceiving. (The use of these words in the MBTI context is not exactly the same as their dictionary definitions). I am a strong ENFP. My husband was an ISTP. Understanding the differences between how we approached the world was very helpful to me in learning why we were so different about socializing with other people, and about our communication style with each other. As an \"I\", John (as they put it in the book), \"got his batteries charged\" by mostly being alone. I, as an \"E\", got mine charged by being with other people. We went to conventions and parties, but he often wanted to leave well before I felt ready to go. Once we had two cars, we would each take our own to events. Even though I felt it wasted gas, it gave him the opportunity to \"flee\" once he had had enough of being with others, while I could then come home at my leisure, and neither of us had to give up on what made us happier and more comfortable. It also explained why he would not always respond immediately to a question. \"I \"people tend to figure out in their own mind first what they want to say before they say anything aloud. \"E\" people often start talking right away, and as they speak, what they think becomes clearer to them. This is also a very useful data point for teachers. If they know about it, they can realize that the \"I\" kids need more time to come up with their answers, while the \"E\" kids put their hands in the air more immediately. They can then allow the \"I\" kids the time they need to respond to questions without thinking they are not good students, or are not as intelligent or knowledgeable as they \"E\" kids are.</p>\n<p>My boyfriend is an ENTJ. The source of some of the friction in our relationship became clear to me after I asked him to find out his Myers-Briggs type, which he had never done before. Gerry often asks me to give him a list of what I want to do in the course of my day, and how much time things will take. These are reasonable requests. However, the rub comes from the fact that as a \"J\", he is uncomfortable not knowing the answer to these things. I, as a \"P\", am uncomfortable stating these things in advance, in nailing things down. I prefer to leave things open-ended. He regarded what I said as more concrete, whereas I regarded it more as a guideline, but not a definite plan or promise. In addition, I have always had a hard time judging how long things will take, and as a person with ADD, I also get distracted easily, so it was making me upset when he would come home and ask me what I'd gotten done, and then he would get upset when I hadn't done what I had said I wanted to, or if things took longer than I said they would. Understanding the differences in our types has helped me to understand more about why this has been an area of friction. That leaves room for us to discuss it without feeling the need to blame each other for our preferred method of dealing with things. I feel clearer about stating goals for the day, but not necessarily promising to do specific things, and working on figuring out how to allocate enough time for things. He understands that just because I tell him what I would like to do, it is not necessarily what I will end up doing. It's still a work in progress.</p>\n<p>I want to be clear that I am not talking about using the types as excuses to get out of doing things, or for taking what other people feel is \"too long\" to get things done. It's merely another \"tool in my tool box\" that helps me to process how I and my loved ones function, and to figure out how to improve.</p>\n<p>I am curious to know how other people feel about their experiences, if they have done a personal growth seminar such as est and/or taken the MBTI, if they feel that they have also taken tools from those experiences that have had an ongoing positive impact on their lives and relationships. I look forward to hearing what people have to say in response to this article.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Q8ZmznoR52sc3rTay", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 5, "extendedScore": null, "score": 7.007963634149355e-07, "legacy": true, "legacyId": "6720", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HDfN7g3iPs5Fs3qX7"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T00:24:03.033Z", "modifiedAt": null, "url": null, "title": "Do meetups really have to go on the front page?", "slug": "do-meetups-really-have-to-go-on-the-front-page", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.620Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/CFQbHMZmuQEeCyXc9/do-meetups-really-have-to-go-on-the-front-page", "pageUrlRelative": "/posts/CFQbHMZmuQEeCyXc9/do-meetups-really-have-to-go-on-the-front-page", "linkUrl": "https://www.lesswrong.com/posts/CFQbHMZmuQEeCyXc9/do-meetups-really-have-to-go-on-the-front-page", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Do%20meetups%20really%20have%20to%20go%20on%20the%20front%20page%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADo%20meetups%20really%20have%20to%20go%20on%20the%20front%20page%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCFQbHMZmuQEeCyXc9%2Fdo-meetups-really-have-to-go-on-the-front-page%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Do%20meetups%20really%20have%20to%20go%20on%20the%20front%20page%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCFQbHMZmuQEeCyXc9%2Fdo-meetups-really-have-to-go-on-the-front-page", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FCFQbHMZmuQEeCyXc9%2Fdo-meetups-really-have-to-go-on-the-front-page", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 97, "htmlBody": "<p>I've been browsing LessWrong less often as of late, and I believe that one of the reasons is because I don't want to get all excited all over a new insightful LW post, only to discover that it's a meetup in a city that I'm not even in.</p>\n<p>And for newbies to the site in particular, they're not going to see all the awesomeness of this site if they simply look at the frontpage and think it's a community just for meetups.</p>\n<p>I'm sure meetup discussions can go somewhere prominent. Maybe a separate section can be devoted to them.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "CFQbHMZmuQEeCyXc9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 36, "extendedScore": null, "score": 7.008059208832043e-07, "legacy": true, "legacyId": "6721", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 28, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 54, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T00:40:54.267Z", "modifiedAt": null, "url": null, "title": "How would you respond to the Philpapers \"What are your Philosophical Positions\" Survey?", "slug": "how-would-you-respond-to-the-philpapers-what-are-your", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:30.582Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/EwSaRk7FyvJkiQ2A5/how-would-you-respond-to-the-philpapers-what-are-your", "pageUrlRelative": "/posts/EwSaRk7FyvJkiQ2A5/how-would-you-respond-to-the-philpapers-what-are-your", "linkUrl": "https://www.lesswrong.com/posts/EwSaRk7FyvJkiQ2A5/how-would-you-respond-to-the-philpapers-what-are-your", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20would%20you%20respond%20to%20the%20Philpapers%20%22What%20are%20your%20Philosophical%20Positions%22%20Survey%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20would%20you%20respond%20to%20the%20Philpapers%20%22What%20are%20your%20Philosophical%20Positions%22%20Survey%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEwSaRk7FyvJkiQ2A5%2Fhow-would-you-respond-to-the-philpapers-what-are-your%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20would%20you%20respond%20to%20the%20Philpapers%20%22What%20are%20your%20Philosophical%20Positions%22%20Survey%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEwSaRk7FyvJkiQ2A5%2Fhow-would-you-respond-to-the-philpapers-what-are-your", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEwSaRk7FyvJkiQ2A5%2Fhow-would-you-respond-to-the-philpapers-what-are-your", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 273, "htmlBody": "<p>The questions are at&nbsp;<a href=\"http://philpapers.org/surveys/oquestions.html\">http://philpapers.org/surveys/oquestions.html</a>.&nbsp;The correlations can be intensely interesting to those who understand philosophical jargon (http://philpapers.org/surveys/linear_most.pl) - it doesn't take too long to look them up as you go - and I actually found it to be a fun way to learn new philosophy. I know that there was a LW thread about this several months ago, but it didn't have a section for people here to respond to the survey. I would be very interested to see how people here would respond.</p>\n<p>I'll repost the questions here:</p>\n<p>===</p>\n<p>Original Survey Questions | PhilPapers Surveys</p>\n<p>A priori knowledge: yes or no?</p>\n<p>Abstract objects: Platonism or nominalism?</p>\n<p>Aesthetic value: objective or subjective?</p>\n<p>Analytic-synthetic distinction: yes or no?</p>\n<p>Epistemic justification: internalism or externalism?</p>\n<p>External world: idealism, skepticism, or non-skeptical realism?</p>\n<p>Free will: compatibilism, libertarianism, or no free will?</p>\n<p>God: theism or atheism?</p>\n<p>Knowledge: empiricism or rationalism?</p>\n<p>Knowledge claims: contextualism, relativism, or invariantism?</p>\n<p>Laws of nature: Humean or non-Humean?</p>\n<p>Logic: classical or non-classical?</p>\n<p>Mental content: internalism or externalism?</p>\n<p>Meta-ethics: moral realism or moral anti-realism?</p>\n<p>Metaphilosophy: naturalism or non-naturalism?</p>\n<p>Mind: physicalism or non-physicalism?</p>\n<p>Moral judgment: cognitivism or non-cognitivism?</p>\n<p>Moral motivation: internalism or externalism?</p>\n<p>Newcomb's problem: one box or two boxes?</p>\n<p>Normative ethics: deontology, consequentialism, or virtue ethics?</p>\n<p>Perceptual experience: disjunctivism, qualia theory, representationalism, or sense-datum theory?</p>\n<p>Personal identity: biological view, psychological view, or further-fact view?</p>\n<p>Politics: communitarianism, egalitarianism, or libertarianism?</p>\n<p>Proper names: Fregean or Millian?</p>\n<p>Science: scientific realism or scientific anti-realism?</p>\n<p>Teletransporter (new matter): survival or death?</p>\n<p>Time: A-theory or B-theory?</p>\n<p>Trolley problem (five straight ahead, one on side track, turn requires switching, what ought one do?): switch or don't switch?</p>\n<p>Truth: correspondence, deflationary, or epistemic?</p>\n<p>Zombies: inconceivable, conceivable but not metaphysically possible, or metaphysically possible?</p>\n<p>===</p>\n<p>And... which of the following philosophers do you identify with?</p>\n<p>The philosophers available to choose from for the \"which philosophers do you identify with?\" question were:</p>\n<p>&nbsp;</p>\n<p>Anscombe</p>\n<p>Aquinas</p>\n<p>Aristotle</p>\n<p>Augustine</p>\n<p>Berkeley</p>\n<p>Carnap</p>\n<p>Davidson</p>\n<p>Descartes</p>\n<p>Frege</p>\n<p>Hegel</p>\n<p>Heidegger</p>\n<p>Hobbes</p>\n<p>Hume</p>\n<p>Husserl</p>\n<p>Kant</p>\n<p>Kierkegaard</p>\n<p>Leibniz</p>\n<p>Lewis</p>\n<p>Locke</p>\n<p>Marx</p>\n<p>Mill</p>\n<p>Moore</p>\n<p>Nietzsche</p>\n<p>Plato</p>\n<p>Quine</p>\n<p>Rawls</p>\n<p>Rousseau</p>\n<p>Russell</p>\n<p>Socrates</p>\n<p>Spinoza</p>\n<p>Wittgenstein</p>\n<div><br /></div>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "EwSaRk7FyvJkiQ2A5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 14, "extendedScore": null, "score": 2.6e-05, "legacy": true, "legacyId": "6722", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 15, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 42, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 2, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T07:08:42.530Z", "modifiedAt": null, "url": null, "title": "David Deutsch on How To Think About The Future", "slug": "david-deutsch-on-how-to-think-about-the-future", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:51.488Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curi", "createdAt": "2010-11-14T23:20:06.334Z", "isAdmin": false, "displayName": "curi"}, "userId": "MTDagWBSe2QtC7Qoy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tTnKWe7wZ8warcrBw/david-deutsch-on-how-to-think-about-the-future", "pageUrlRelative": "/posts/tTnKWe7wZ8warcrBw/david-deutsch-on-how-to-think-about-the-future", "linkUrl": "https://www.lesswrong.com/posts/tTnKWe7wZ8warcrBw/david-deutsch-on-how-to-think-about-the-future", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20David%20Deutsch%20on%20How%20To%20Think%20About%20The%20Future&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADavid%20Deutsch%20on%20How%20To%20Think%20About%20The%20Future%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtTnKWe7wZ8warcrBw%2Fdavid-deutsch-on-how-to-think-about-the-future%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=David%20Deutsch%20on%20How%20To%20Think%20About%20The%20Future%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtTnKWe7wZ8warcrBw%2Fdavid-deutsch-on-how-to-think-about-the-future", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtTnKWe7wZ8warcrBw%2Fdavid-deutsch-on-how-to-think-about-the-future", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 30, "htmlBody": "<p>http://vimeo.com/22099396</p>\n<p>What do people think of this, from a Bayesian perspective?</p>\n<p>It is a talk given to the Oxford Transhumanists. Their previous speaker was Eliezer Yudkowsky. Audio version and past talks here:&nbsp;http://groupspaces.com/oxfordtranshumanists/pages/past-talks</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tTnKWe7wZ8warcrBw", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 1, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "6706", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 199, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T09:03:08.907Z", "modifiedAt": null, "url": null, "title": "Link Sharing Thread - April '11", "slug": "link-sharing-thread-april-11", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:07.037Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Alexandros", "createdAt": "2009-04-21T11:07:48.256Z", "isAdmin": false, "displayName": "Alexandros"}, "userId": "GQ6FJrTSW7qWeuQDD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qM7tkbPjbYqDRrLzS/link-sharing-thread-april-11", "pageUrlRelative": "/posts/qM7tkbPjbYqDRrLzS/link-sharing-thread-april-11", "linkUrl": "https://www.lesswrong.com/posts/qM7tkbPjbYqDRrLzS/link-sharing-thread-april-11", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%20Sharing%20Thread%20-%20April%20'11&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%20Sharing%20Thread%20-%20April%20'11%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqM7tkbPjbYqDRrLzS%2Flink-sharing-thread-april-11%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%20Sharing%20Thread%20-%20April%20'11%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqM7tkbPjbYqDRrLzS%2Flink-sharing-thread-april-11", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqM7tkbPjbYqDRrLzS%2Flink-sharing-thread-april-11", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 44, "htmlBody": "<p>Sharing interesting links via the discussion section seems to have too much overhead. I suspect we all find things that are quite interesting but don't bother to share them on LW. This is an experiment to see if a dedicated thread can work better.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"ABG8vt87eW4FFA6gD": 1, "GQyPQcdEQF4zXhJBq": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qM7tkbPjbYqDRrLzS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 21, "baseScore": 31, "extendedScore": null, "score": 7.009513203997659e-07, "legacy": true, "legacyId": "6731", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 88, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T10:13:08.381Z", "modifiedAt": null, "url": null, "title": "Requesting armchair analysis of Google's strategy", "slug": "requesting-armchair-analysis-of-google-s-strategy", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/2Bsirex4m6jwPJwqS/requesting-armchair-analysis-of-google-s-strategy", "pageUrlRelative": "/posts/2Bsirex4m6jwPJwqS/requesting-armchair-analysis-of-google-s-strategy", "linkUrl": "https://www.lesswrong.com/posts/2Bsirex4m6jwPJwqS/requesting-armchair-analysis-of-google-s-strategy", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Requesting%20armchair%20analysis%20of%20Google's%20strategy&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARequesting%20armchair%20analysis%20of%20Google's%20strategy%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Bsirex4m6jwPJwqS%2Frequesting-armchair-analysis-of-google-s-strategy%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Requesting%20armchair%20analysis%20of%20Google's%20strategy%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Bsirex4m6jwPJwqS%2Frequesting-armchair-analysis-of-google-s-strategy", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F2Bsirex4m6jwPJwqS%2Frequesting-armchair-analysis-of-google-s-strategy", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>(Disclaimer: I've been working at Google for about a month now. This post is on my behalf, not my employer's. Also it will not contain any secret information.)</p>\n<p>Larry Page, one of the original founders of Google, recently came back as CEO and immediately declared that the company should focus on social stuff. This caused a lot of internet commentary, <a href=\"http://cdixon.org/2011/04/10/googles-social-strategy/\">here's a typical example</a>. And&nbsp;<a href=\"http://abovethecrowd.com/2011/03/24/freight-train-that-is-android/\">here's another example</a>&nbsp;from before then. (Do read them, they're nice in a way.) As you can see, every armchair analyst paints a nice and clear picture of what's happening, and&nbsp;<em>all those pictures are different</em>.&nbsp;Eventually someone will end up right and beat their chest saying I told you so, and others will end up wrong and quietly forget that they ever said anything. We ought to do better.</p>\n<p>Q1: what do you believe about Google's devious plans and their market reality?</p>\n<p>Q2: why do you believe what you believe?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "2Bsirex4m6jwPJwqS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6732", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T14:25:35.165Z", "modifiedAt": null, "url": null, "title": "Raleigh/Durham/Chapel Hill Meetup", "slug": "raleigh-durham-chapel-hill-meetup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.835Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "soundchaser", "createdAt": "2010-10-28T13:44:11.926Z", "isAdmin": false, "displayName": "soundchaser"}, "userId": "KvDayWE4gJta2ysFY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/LabscJRexH5vmwDy8/raleigh-durham-chapel-hill-meetup", "pageUrlRelative": "/posts/LabscJRexH5vmwDy8/raleigh-durham-chapel-hill-meetup", "linkUrl": "https://www.lesswrong.com/posts/LabscJRexH5vmwDy8/raleigh-durham-chapel-hill-meetup", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Raleigh%2FDurham%2FChapel%20Hill%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARaleigh%2FDurham%2FChapel%20Hill%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLabscJRexH5vmwDy8%2Fraleigh-durham-chapel-hill-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Raleigh%2FDurham%2FChapel%20Hill%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLabscJRexH5vmwDy8%2Fraleigh-durham-chapel-hill-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FLabscJRexH5vmwDy8%2Fraleigh-durham-chapel-hill-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 98, "htmlBody": "<p>This post's primary intent is to gauge interest and try to find a possible meeting place.</p>\n<p>I will commit to showing up at whatever place we decide on, but I am usually only around during the week. (Though given enough time in advance I could plan for one on the weekend)</p>\n<p>The RTP area has three research universities and a fairly large population when taken as a total of the three cities, so hopefully we have enough people. I can also post fliers in several departments at North Carolina State University if people think there would be benefit in that.&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "LabscJRexH5vmwDy8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 7, "extendedScore": null, "score": 7.01041662230969e-07, "legacy": true, "legacyId": "6733", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T15:25:56.262Z", "modifiedAt": "2021-11-21T21:37:04.308Z", "url": null, "title": "The Absolute Self-Selection Assumption", "slug": "the-absolute-self-selection-assumption", "viewCount": null, "lastCommentedAt": "2021-11-21T21:37:04.013Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QmWNbCRMgRBcMK6RK/the-absolute-self-selection-assumption", "pageUrlRelative": "/posts/QmWNbCRMgRBcMK6RK/the-absolute-self-selection-assumption", "linkUrl": "https://www.lesswrong.com/posts/QmWNbCRMgRBcMK6RK/the-absolute-self-selection-assumption", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Absolute%20Self-Selection%20Assumption&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Absolute%20Self-Selection%20Assumption%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQmWNbCRMgRBcMK6RK%2Fthe-absolute-self-selection-assumption%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Absolute%20Self-Selection%20Assumption%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQmWNbCRMgRBcMK6RK%2Fthe-absolute-self-selection-assumption", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQmWNbCRMgRBcMK6RK%2Fthe-absolute-self-selection-assumption", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2175, "htmlBody": "<p>There are many confused discussions of anthropic reasoning, both on LW and in surprisingly mainstream literature. In this article I will discuss<a href=\"http://fennetic.net/irc/finney.org/~hal/udassa/\"> UDASSA</a>, a framework for anthropic reasoning due to Wei Dai. This framework has serious shortcomings, but at present it is the only one I know which produces reasonable answers to reasonable questions; at the moment it is the only framework which I would feel comfortable using to make a real decision.</p><p>I will discuss 3 problems:</p><p>1. In an infinite universe, there are infinitely many copies of you (infinitely many of which are Boltzmann brains). How do you assign a measure to the copies of yourself when the uniform distribution is unavailable? Do you rule out spatially or temporally infinite universes for this reason?</p><p>2. Naive anthropics ignore the substrate on which a simulation is running and count how many instances of a simulated experience exist (or how many distinct versions of that experience exist). These beliefs are inconsistent with basic intuitions about conscious experience, so we have to abandon something intuitive.</p><p>3. The Born probabilities seem mysterious. They can be explained (as well as any law of physics can be explained) by UDASSA.</p><p><strong>Why Anthropic Reasoning?</strong></p><p>When I am trying to act in my own self-interest, I do not know with certainty the consequences of any particular decision. I compare probability distributions over outcomes: an action may lead to one outcome with probability 1/2, and a different outcome with probability 1/2. My brain has preferences between probability distributions built into it.</p><p>My brain is not built with the machinery to decide between different universes each of which contains many simulations I care about. My brain can't even really grasp the notion of different copies of me, except by first converting to the language of probability distributions. If I am facing the prospect of being copied, the only way I can grapple with it is by reasoning \"I have a 50% chance of remaining me, and a 50% chance of becoming my copy.\" After thinking in this way, I can hope to intelligently trade-off one copy's preferences against the other's using the same machinery which allows me to make decisions with uncertain outcomes.</p><p>In order to perform this reasoning in general, I need a better framework for anthropic reasoning. What I want is a probability distribution over all possible experiences (or \"observer-moments\"), so that I can use my existing preferences to make intelligent decisions in a universe with more than one observer I care about.</p><p>I am going to leave many questions unresolved. I don't understand continuity of experience or identity, so I am simply not going to try to be selfish (I don't know how). I don't understand what constitutes conscious experience, so I am not going to try and explain it. I have to rely on a complexity prior, which involves an unacceptable arbitrary choice of a notion of complexity.</p><p><strong>The Absolute Self-Selection Assumption</strong></p><p>A thinker using Solomonoff induction searches for the simplest explanation for its own experiences. It eventually learns that the simplest explanation for its experiences is the description of an external lawful universe in which its sense organs are embedded and a description of that embedding.</p><p>As humans using Solomonoff induction, we go on to argue that this external lawful universe is real, and that our conscious experience is a consequence of the existence of certain substructure in that universe. The absolute self-selection assumption discards this additional step. Rather than supposing that the probability of a certain universe depends on the complexity of that universe, it takes as a primitive object a probability distribution over possible experiences.</p><p>By the same reasoning that led a normal Solomonoff inductor to accept the existence of an external universe as the best explanation for its experiences, the least complex description of your conscious experience is the description of an external lawful universe and directions for finding the substructure embodying your experience within that substructure.</p><p>This requires specifying a notion of complexity. I will choose a universal computable distribution over strings for now, to mimic conventional Solomonoff induction as closely as possible (and because I know nothing better). The resulting theory is called UDASSA, for Universal Distribution + ASSA.</p><p><strong>Recovering Intuitive Anthropics</strong></p><p>Suppose I create a perfect copy of myself. Intuitively, I would like to weight the two copies equally. Similarly, my anthropic notion of \"probability of an experience\" should match up with my intuitive notion of probability. Fortunately, UDASSA recovers intuitive anthropics in intuitive situations.</p><p>The shortest description of me is a pair (U, x), where U is a description of my universe and x is a description of where to find me in that universe. If there are two copies of me in the universe, then the experience of each can be described in the same way: (U, x1) and (U, x2) are descriptions of approximately equal complexity, so I weight the experience of each copy equally. The total experience of my copies is weighted twice as much as the total experience of an uncopied individual.</p><p>Part of x is a description of how to navigate the randomness of the universe. For example, if the last (truly random) coin I saw flipped came up heads, then in order to specify my experiences you need to specify the result of that coin flip. An equal number of equally complex descriptions point to the version of me who saw heads and the version of me who saw tails.</p><p><strong>Problem #1: Infinite Cosmologies</strong></p><p>Modern physics is consistent with infinite universes. An infinite universe contains infinitely many observers (infinitely many of which share all of your experiences so far), and it is no longer sensible to talk about the \"uniform distribution\" over all of them. You could imagine taking a limit over larger and larger volumes, but there is no particular reason to suspect such a limit would converge in a meaningful sense. One solution that <a href=\"http://arxiv.org/abs/1009.4698\">has been suggested</a> is to choose an arbitrary but very large volume of spacetime, and to use a uniform distribution over observers within it.  Another solution is to conclude that infinite universes can't exist. Both of these explanations are unsatisfactory.</p><p>UDASSA provides a different solution. The probability of an experience depends exponentially on the complexity of specifying it. Just existing in an infinite universe with a short description does not guarantee that you yourself have a short description; you need to specify a position within that infinite universe. For example, if your experiences occur 34908172349823478132239471230912349726323948123123991230 steps after some naturally specified time 0, then the (somewhat lengthy) description of that time is necessary to describe your experiences. Thus the total measure of all observer-moments within a universe is finite.</p><p><strong>Problem #2: Splitting Simulations</strong></p><br><p>Consider a computer which is 2 atoms thick running a simulation of you. Suppose this computer can be divided down the middle into two 1 atom thick computers which would both run the same simulation independently. We are faced with an unfortunate dichotomy: either the 2 atom thick simulation has the same weight as two 1 atom thick simulations put together, or it doesn't.</p><p>In the first case, we have to accept that some computer simulations count for more, even if they are running the same simulation (or we have to de-duplicate the set of all experiences, which leads to serious problems with Boltzmann brains). In this case, we are faced with the problem of comparing different substrates, and it seems impossible not to make arbitrary choices.</p><p>In the second case, we have to accept that the operation of dividing the 2 atom thick computer has moral value, which is even worse. Where exactly does the transition occur? What if each layer of the 2 atom thick computer can run independently before splitting? Is physical contact really significant? What about computers that aren't physically coherent? What two 1 atom thick computers periodically synchronize themselves and self-destruct if they aren't synchronized: does this synchronization effectively destroy one of the copies? I know of no way to accept this possibility without extremely counter-intuitive consequences.</p><p>UDASSA implies that simulations on the 2 atom thick computer count for twice as much as simulations on the 1 atom thick computer, because they are easier to specify. Given a description of one of the 1 atom thick computers, then there are two descriptions of equal complexity that point to the simulation running on the 2 atom thick computer: one description pointing to each layer of the 2 atom thick computer. When a 2 atom thick computer splits, the total number of descriptions pointing to the experience it is simulating doesn't change.</p><p><strong>Problem #3: The Born Probabilities</strong></p><p>A quantum mechanical state can be described as a linear combination of \"classical\" configurations. For some reason we appear to experience ourselves as being in one of these classical configurations with probability proportional the coefficient of that configuration <em>squared</em>. These probabilities are called the Born probabilities, and are sometimes described either as a serious problem for MWI or as an unresolved mystery of the universe.</p><p>What happens if we apply UDASSA to a quantum universe? For one, the existence of an observer within the universe doesn't say anything about conscious experience. We need to specify an algorithm for extracting a description of that observer from a description of the universe.</p><p>Consider the randomized algorithm A: compute the state of the universe at time t, then sample a classical configuration with probability proportional to its squared inner product with the universal wavefunction.</p><p>Consider the randomized algorithm B: compute the state of the universe at time t, then sample a classical configuration with probability proportional to its inner product with the universal wavefunction.</p><p>Using either A or B, we can describe a single experience by specifying a random seed, and picking out that experience within the classical configuration output by A or B using that random seed. If this is the shortest explanation of an experience, the probability of an experience is proportional to the number of random seeds which produce classical configurations containing it.</p><p>The universe as we know it is typical for an output of A but completely improbable as an output of B. For example, the observed behavior of stars is consistent with almost all observations weighted according to algorithm A, but with almost no observations weighted according to algorithm B. Algorithm A constitutes an immensely better description of our experiences, in the same sense that quantum mechanics constitutes an immensely better description of our experiences than classical physics.</p><p>You could also imagine an algorithm C, which uses the same selection as algorithm B to point to the Everett branch containing a physicist about to do an experiment, but then uses algorithm A to describe the experiences of the physicist after doing that experiment. This is a horribly complex way to specify an experience, however, for exactly the same reason that a Solomonoff inductor places very low probability on the laws of physics suddenly changing for just this one experiment.</p><p>Of course this leaves open the question of \"why the Born probabilities and not some other rule?\" Algorithm B is a valid way of specifying observers, though they would look exactly as foreign as observes with different rules of physics (Wei Dai has suggested that the structures specified by algorithm B are not even self-aware as justification for the Born rule). The fact that we are described by algorithm A rather than B is no more or less mysterious than the fact that the laws of physics are like <em>so</em> instead of some other way.</p><p>In the same way that we can retroactively justify our laws of physics by appealing to their elegance and simplicity (in a sense we don't yet really understand) I suspect that we can justify selection according to algorithm A rather than algorithm B. In an infinite universe, algorithm B doesn't even work (because the sum of the inner products of the universal wavefunction with the classical configurations is infinite) and even in a finite universe algorithm B necessarily involves the additional step of normalizing the probability distribution or else producing nonsense. Moreover, algorithm A is a nicer mathematical object than algorithm B when the evolution of the wavefunction is unitary, and so the same considerations that suggest elegant laws of physics suggest algorithm A over B (or some other alternative).</p><p>Note that this is <em>not</em> the core of my explanation of the Born probabilities; in UDASSA, choosing a selection procedure is just as important as describing the universe, and so some explicit sort of observer selection is a necessary part of the laws of physics. We predict the Born rule to hold in the future because it has held in the past, just like we expect the laws of physics to hold in the future because they have held in the past.</p><p>In summary, if you use Solomonoff induction to predict what you will see next based on everything you have seen so far, your predictions about the future will be consistent with the Born probabilities. You only get in trouble when you use Solomonoff induction to predict what the universe contains, and then get bogged down in the question \"Given that the universe contains all of these observers, which one should I expect to be <em>me</em>?\"</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QmWNbCRMgRBcMK6RK", "schemaVersion": 1, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 49, "baseScore": 72, "extendedScore": null, "score": 0.000135, "legacy": true, "legacyId": "6734", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": "", "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 72, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>There are many confused discussions of anthropic reasoning, both on LW and in surprisingly mainstream literature. In this article I will discuss<a href=\"http://fennetic.net/irc/finney.org/~hal/udassa/\"> UDASSA</a>, a framework for anthropic reasoning due to Wei Dai. This framework has serious shortcomings, but at present it is the only one I know which produces reasonable answers to reasonable questions; at the moment it is the only framework which I would feel comfortable using to make a real decision.</p><p>I will discuss 3 problems:</p><p>1. In an infinite universe, there are infinitely many copies of you (infinitely many of which are Boltzmann brains). How do you assign a measure to the copies of yourself when the uniform distribution is unavailable? Do you rule out spatially or temporally infinite universes for this reason?</p><p>2. Naive anthropics ignore the substrate on which a simulation is running and count how many instances of a simulated experience exist (or how many distinct versions of that experience exist). These beliefs are inconsistent with basic intuitions about conscious experience, so we have to abandon something intuitive.</p><p>3. The Born probabilities seem mysterious. They can be explained (as well as any law of physics can be explained) by UDASSA.</p><p><strong id=\"Why_Anthropic_Reasoning_\">Why Anthropic Reasoning?</strong></p><p>When I am trying to act in my own self-interest, I do not know with certainty the consequences of any particular decision. I compare probability distributions over outcomes: an action may lead to one outcome with probability 1/2, and a different outcome with probability 1/2. My brain has preferences between probability distributions built into it.</p><p>My brain is not built with the machinery to decide between different universes each of which contains many simulations I care about. My brain can't even really grasp the notion of different copies of me, except by first converting to the language of probability distributions. If I am facing the prospect of being copied, the only way I can grapple with it is by reasoning \"I have a 50% chance of remaining me, and a 50% chance of becoming my copy.\" After thinking in this way, I can hope to intelligently trade-off one copy's preferences against the other's using the same machinery which allows me to make decisions with uncertain outcomes.</p><p>In order to perform this reasoning in general, I need a better framework for anthropic reasoning. What I want is a probability distribution over all possible experiences (or \"observer-moments\"), so that I can use my existing preferences to make intelligent decisions in a universe with more than one observer I care about.</p><p>I am going to leave many questions unresolved. I don't understand continuity of experience or identity, so I am simply not going to try to be selfish (I don't know how). I don't understand what constitutes conscious experience, so I am not going to try and explain it. I have to rely on a complexity prior, which involves an unacceptable arbitrary choice of a notion of complexity.</p><p><strong id=\"The_Absolute_Self_Selection_Assumption\">The Absolute Self-Selection Assumption</strong></p><p>A thinker using Solomonoff induction searches for the simplest explanation for its own experiences. It eventually learns that the simplest explanation for its experiences is the description of an external lawful universe in which its sense organs are embedded and a description of that embedding.</p><p>As humans using Solomonoff induction, we go on to argue that this external lawful universe is real, and that our conscious experience is a consequence of the existence of certain substructure in that universe. The absolute self-selection assumption discards this additional step. Rather than supposing that the probability of a certain universe depends on the complexity of that universe, it takes as a primitive object a probability distribution over possible experiences.</p><p>By the same reasoning that led a normal Solomonoff inductor to accept the existence of an external universe as the best explanation for its experiences, the least complex description of your conscious experience is the description of an external lawful universe and directions for finding the substructure embodying your experience within that substructure.</p><p>This requires specifying a notion of complexity. I will choose a universal computable distribution over strings for now, to mimic conventional Solomonoff induction as closely as possible (and because I know nothing better). The resulting theory is called UDASSA, for Universal Distribution + ASSA.</p><p><strong id=\"Recovering_Intuitive_Anthropics\">Recovering Intuitive Anthropics</strong></p><p>Suppose I create a perfect copy of myself. Intuitively, I would like to weight the two copies equally. Similarly, my anthropic notion of \"probability of an experience\" should match up with my intuitive notion of probability. Fortunately, UDASSA recovers intuitive anthropics in intuitive situations.</p><p>The shortest description of me is a pair (U, x), where U is a description of my universe and x is a description of where to find me in that universe. If there are two copies of me in the universe, then the experience of each can be described in the same way: (U, x1) and (U, x2) are descriptions of approximately equal complexity, so I weight the experience of each copy equally. The total experience of my copies is weighted twice as much as the total experience of an uncopied individual.</p><p>Part of x is a description of how to navigate the randomness of the universe. For example, if the last (truly random) coin I saw flipped came up heads, then in order to specify my experiences you need to specify the result of that coin flip. An equal number of equally complex descriptions point to the version of me who saw heads and the version of me who saw tails.</p><p><strong id=\"Problem__1__Infinite_Cosmologies\">Problem #1: Infinite Cosmologies</strong></p><p>Modern physics is consistent with infinite universes. An infinite universe contains infinitely many observers (infinitely many of which share all of your experiences so far), and it is no longer sensible to talk about the \"uniform distribution\" over all of them. You could imagine taking a limit over larger and larger volumes, but there is no particular reason to suspect such a limit would converge in a meaningful sense. One solution that <a href=\"http://arxiv.org/abs/1009.4698\">has been suggested</a> is to choose an arbitrary but very large volume of spacetime, and to use a uniform distribution over observers within it.  Another solution is to conclude that infinite universes can't exist. Both of these explanations are unsatisfactory.</p><p>UDASSA provides a different solution. The probability of an experience depends exponentially on the complexity of specifying it. Just existing in an infinite universe with a short description does not guarantee that you yourself have a short description; you need to specify a position within that infinite universe. For example, if your experiences occur 34908172349823478132239471230912349726323948123123991230 steps after some naturally specified time 0, then the (somewhat lengthy) description of that time is necessary to describe your experiences. Thus the total measure of all observer-moments within a universe is finite.</p><p><strong id=\"Problem__2__Splitting_Simulations\">Problem #2: Splitting Simulations</strong></p><br><p>Consider a computer which is 2 atoms thick running a simulation of you. Suppose this computer can be divided down the middle into two 1 atom thick computers which would both run the same simulation independently. We are faced with an unfortunate dichotomy: either the 2 atom thick simulation has the same weight as two 1 atom thick simulations put together, or it doesn't.</p><p>In the first case, we have to accept that some computer simulations count for more, even if they are running the same simulation (or we have to de-duplicate the set of all experiences, which leads to serious problems with Boltzmann brains). In this case, we are faced with the problem of comparing different substrates, and it seems impossible not to make arbitrary choices.</p><p>In the second case, we have to accept that the operation of dividing the 2 atom thick computer has moral value, which is even worse. Where exactly does the transition occur? What if each layer of the 2 atom thick computer can run independently before splitting? Is physical contact really significant? What about computers that aren't physically coherent? What two 1 atom thick computers periodically synchronize themselves and self-destruct if they aren't synchronized: does this synchronization effectively destroy one of the copies? I know of no way to accept this possibility without extremely counter-intuitive consequences.</p><p>UDASSA implies that simulations on the 2 atom thick computer count for twice as much as simulations on the 1 atom thick computer, because they are easier to specify. Given a description of one of the 1 atom thick computers, then there are two descriptions of equal complexity that point to the simulation running on the 2 atom thick computer: one description pointing to each layer of the 2 atom thick computer. When a 2 atom thick computer splits, the total number of descriptions pointing to the experience it is simulating doesn't change.</p><p><strong id=\"Problem__3__The_Born_Probabilities\">Problem #3: The Born Probabilities</strong></p><p>A quantum mechanical state can be described as a linear combination of \"classical\" configurations. For some reason we appear to experience ourselves as being in one of these classical configurations with probability proportional the coefficient of that configuration <em>squared</em>. These probabilities are called the Born probabilities, and are sometimes described either as a serious problem for MWI or as an unresolved mystery of the universe.</p><p>What happens if we apply UDASSA to a quantum universe? For one, the existence of an observer within the universe doesn't say anything about conscious experience. We need to specify an algorithm for extracting a description of that observer from a description of the universe.</p><p>Consider the randomized algorithm A: compute the state of the universe at time t, then sample a classical configuration with probability proportional to its squared inner product with the universal wavefunction.</p><p>Consider the randomized algorithm B: compute the state of the universe at time t, then sample a classical configuration with probability proportional to its inner product with the universal wavefunction.</p><p>Using either A or B, we can describe a single experience by specifying a random seed, and picking out that experience within the classical configuration output by A or B using that random seed. If this is the shortest explanation of an experience, the probability of an experience is proportional to the number of random seeds which produce classical configurations containing it.</p><p>The universe as we know it is typical for an output of A but completely improbable as an output of B. For example, the observed behavior of stars is consistent with almost all observations weighted according to algorithm A, but with almost no observations weighted according to algorithm B. Algorithm A constitutes an immensely better description of our experiences, in the same sense that quantum mechanics constitutes an immensely better description of our experiences than classical physics.</p><p>You could also imagine an algorithm C, which uses the same selection as algorithm B to point to the Everett branch containing a physicist about to do an experiment, but then uses algorithm A to describe the experiences of the physicist after doing that experiment. This is a horribly complex way to specify an experience, however, for exactly the same reason that a Solomonoff inductor places very low probability on the laws of physics suddenly changing for just this one experiment.</p><p>Of course this leaves open the question of \"why the Born probabilities and not some other rule?\" Algorithm B is a valid way of specifying observers, though they would look exactly as foreign as observes with different rules of physics (Wei Dai has suggested that the structures specified by algorithm B are not even self-aware as justification for the Born rule). The fact that we are described by algorithm A rather than B is no more or less mysterious than the fact that the laws of physics are like <em>so</em> instead of some other way.</p><p>In the same way that we can retroactively justify our laws of physics by appealing to their elegance and simplicity (in a sense we don't yet really understand) I suspect that we can justify selection according to algorithm A rather than algorithm B. In an infinite universe, algorithm B doesn't even work (because the sum of the inner products of the universal wavefunction with the classical configurations is infinite) and even in a finite universe algorithm B necessarily involves the additional step of normalizing the probability distribution or else producing nonsense. Moreover, algorithm A is a nicer mathematical object than algorithm B when the evolution of the wavefunction is unitary, and so the same considerations that suggest elegant laws of physics suggest algorithm A over B (or some other alternative).</p><p>Note that this is <em>not</em> the core of my explanation of the Born probabilities; in UDASSA, choosing a selection procedure is just as important as describing the universe, and so some explicit sort of observer selection is a necessary part of the laws of physics. We predict the Born rule to hold in the future because it has held in the past, just like we expect the laws of physics to hold in the future because they have held in the past.</p><p>In summary, if you use Solomonoff induction to predict what you will see next based on everything you have seen so far, your predictions about the future will be consistent with the Born probabilities. You only get in trouble when you use Solomonoff induction to predict what the universe contains, and then get bogged down in the question \"Given that the universe contains all of these observers, which one should I expect to be <em>me</em>?\"</p>", "sections": [{"title": "Why Anthropic Reasoning?", "anchor": "Why_Anthropic_Reasoning_", "level": 1}, {"title": "The Absolute Self-Selection Assumption", "anchor": "The_Absolute_Self_Selection_Assumption", "level": 1}, {"title": "Recovering Intuitive Anthropics", "anchor": "Recovering_Intuitive_Anthropics", "level": 1}, {"title": "Problem #1: Infinite Cosmologies", "anchor": "Problem__1__Infinite_Cosmologies", "level": 1}, {"title": "Problem #2: Splitting Simulations", "anchor": "Problem__2__Splitting_Simulations", "level": 1}, {"title": "Problem #3: The Born Probabilities", "anchor": "Problem__3__The_Born_Probabilities", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "45 comments"}], "headingsCount": 8}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 45, "af": false, "version": "1.1.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 18, "afExtendedScore": null, "afCommentCount": 1, "afLastCommentedAt": "2021-11-21T21:37:03.621Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T15:52:51.731Z", "modifiedAt": null, "url": null, "title": "Rational Communication", "slug": "rational-communication-0", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:53.766Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6zneWtAMnB7c88kJY/rational-communication-0", "pageUrlRelative": "/posts/6zneWtAMnB7c88kJY/rational-communication-0", "linkUrl": "https://www.lesswrong.com/posts/6zneWtAMnB7c88kJY/rational-communication-0", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Rational%20Communication&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARational%20Communication%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6zneWtAMnB7c88kJY%2Frational-communication-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Rational%20Communication%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6zneWtAMnB7c88kJY%2Frational-communication-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6zneWtAMnB7c88kJY%2Frational-communication-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 490, "htmlBody": "<p>Hopefully LW trains its readers to be aware of personal failures of rationality and to correct them over time.</p>\n<p>Whenever a small group (all the way down to 2) of rationalists communicate, they should make an equal effort to be aware of failures of their collective rationality (I definitely have failed at this so far in life). In particular: time is valuable, and you can hope to actually learn things from other people. Here are some remarks about communication intended to help you optimize (as opposed to communication intended to help you be happy).</p>\n<p>1. Communicate information precisely. I have strong beliefs that contradict the beliefs of other rationalists. I need a better way to express precisely what the disagreement is and my confidence in my beliefs, particularly with people I don't know well. Right now I feel like I have no hope of correctly updating on the beliefs of others or sharing information in a productive way. To this end, I think making precise testable claims about the future and backing them up with probability estimates (as a regular feature of discussion) would be a good idea, even when your probability estimates are horribly miscalibrated. This would help me much more quickly learn about my own miscalibration, evaluate the miscalibration of others, and at least have a definite scale to make precise communication possible.</p>\n<p>2. Communicate preferences precisely. Groupmembers often have strong preferences which they fail to coordinate well. I think groups I have been in would have done better if they consistently used any precise semantics for expressing preferences; for example, assigning monetary values or using some other fixed reference commodity. A bigger problem is that statements of preference carry way to much additional meaning in normal communication. I'm not sure how to divorce statements of preference from this other meaning, but its worth thinking about.</p>\n<p>3. Explicitly think about the point of communication. There are important things to talk about, and the marginal benefits of spending 10 minutes on one topic versus another can be quite different. There are a lot of free moments in a day, and I think this calculus is worth spending some of them on. I would like to start directing my conversations towards high value topics much more reliably, especially in conversations with rationalists. This may involve doing things like making explicit notes to structure my conversation.&nbsp;</p>\n<p>4. Talking about procedure is OK. Improving your rationality is worth spending time on, and I think improving the quality of your communication and a community's ability to communicate is worth spending time. Entertain some discussion of process without feeling irresponsible for not moving forward on the meat of whatever issue you are discussing. Perhaps make rational communication the meat of discussion more often.</p>\n<p>5. Acquire a lot of data. The effectiveness of strategies for communication or group rationality is a really easy thing to gather data on, at least in principle. Share data (doing this effectively requires improvements in communication).</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6zneWtAMnB7c88kJY", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 14, "baseScore": 15, "extendedScore": null, "score": 7.010661191196319e-07, "legacy": true, "legacyId": "6736", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T16:57:34.198Z", "modifiedAt": null, "url": null, "title": "Controls and bias", "slug": "controls-and-bias", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.909Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "a363", "createdAt": "2011-03-08T09:10:56.345Z", "isAdmin": false, "displayName": "a363"}, "userId": "FWkN8hDaphg5mwEsr", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/iWCFpL4vYcy55YkH6/controls-and-bias", "pageUrlRelative": "/posts/iWCFpL4vYcy55YkH6/controls-and-bias", "linkUrl": "https://www.lesswrong.com/posts/iWCFpL4vYcy55YkH6/controls-and-bias", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Controls%20and%20bias&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AControls%20and%20bias%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWCFpL4vYcy55YkH6%2Fcontrols-and-bias%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Controls%20and%20bias%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWCFpL4vYcy55YkH6%2Fcontrols-and-bias", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FiWCFpL4vYcy55YkH6%2Fcontrols-and-bias", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<div>I'm confused...</div>\n<div><br /></div>\n<div>If a group of people, from prehistory, believe something to be true (having X will make you feel Y) and that belief affects their behaviour (when they get X, they feel Y - like a placebo - although some who do get X do not feel Y - but they are the minority), then when scientific studies are conducted (by rational members of the same group) into the effects of X on behaviour Y, &nbsp;it should yield results that X is strongly correlated with Y (there is no control group, everyone is exposed to the same belief and social pressure that reinforces that belief).</div>\n<div><br /></div>\n<div>What will a rational member of that group conclude about the effects of x on y? How can you rationally correct for bias if there is no control?</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "iWCFpL4vYcy55YkH6", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.010842527965813e-07, "legacy": true, "legacyId": "6737", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T17:01:59.047Z", "modifiedAt": null, "url": null, "title": "New Less Wrong Feature: Rerunning The Sequences", "slug": "new-less-wrong-feature-rerunning-the-sequences", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.060Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7XPZQddvD2RBEMdQq/new-less-wrong-feature-rerunning-the-sequences", "pageUrlRelative": "/posts/7XPZQddvD2RBEMdQq/new-less-wrong-feature-rerunning-the-sequences", "linkUrl": "https://www.lesswrong.com/posts/7XPZQddvD2RBEMdQq/new-less-wrong-feature-rerunning-the-sequences", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20New%20Less%20Wrong%20Feature%3A%20Rerunning%20The%20Sequences&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANew%20Less%20Wrong%20Feature%3A%20Rerunning%20The%20Sequences%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7XPZQddvD2RBEMdQq%2Fnew-less-wrong-feature-rerunning-the-sequences%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=New%20Less%20Wrong%20Feature%3A%20Rerunning%20The%20Sequences%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7XPZQddvD2RBEMdQq%2Fnew-less-wrong-feature-rerunning-the-sequences", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7XPZQddvD2RBEMdQq%2Fnew-less-wrong-feature-rerunning-the-sequences", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1036, "htmlBody": "<p><em>Coauthored by <a href=\"/user/Alexandros\">Alexandros</a> and <a href=\"/user/Unnamed\">Unnamed</a></em><br /><br />The suggestion to <a href=\"/r/discussion/lw/4pt/bring_back_the_sequences/\">bring back the sequences</a> in a format that is more similar to new blog posts was well received, so the two of us have been working to figure out how to make it happen, taking into account the feedback received on that thread.&nbsp; We've come up with a plan that is ready to be put into action right away, and are presenting it here for further feedback before getting started.&nbsp; Let us know what you think &ndash; both whether it's worth doing, and what specific changes could be made to improve on what we have so far.<br /><br />The plan is to have a regular &ldquo;Rerunning the Sequences&rdquo; feature in the discussion section, with one post each day linking to one of Eliezer's old posts.&nbsp; We will go through all of Eliezer's posts in order, minus open threads, administrivia, and quotes threads, following the list <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">here</a>.&nbsp; Starting with \"The Martial Art of Rationality\" and finishing with \"Practical Advice Backed By Deep Theories\", we count 702 qualifying posts (with help from <a href=\"/r/discussion/lw/555/96_bad_links_in_the_sequences/\">Alexandros's scraper</a>), so almost two years' worth of continuous posting.<br /><br />The new post isn't meant to contain original content, so it will follow a standard template (a draft of which is included at the bottom of this post).&nbsp; The template includes a one paragraph summary of the article (extracted from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">wiki</a>), a brief explanation of how it's part of the sequence reruns, relevant links, and a standardized format for the title and tags.<br /><br />Like the rationality quotes threads, this is designed to be implemented by the community rather than by software.&nbsp; It will only work if people are interested and participating.&nbsp; Someone will need to make the new post each day, and a lot of the time it will need to be someone other than us two.&nbsp; We'll post an html version of the template with instructions to make it easy for anyone to make a post with just copy, paste, and a few quick edits.&nbsp; The other way that we'll need folks to contribute, besides making the posts, is by writing summaries of the posts.&nbsp; The LW <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">wiki</a> already has a lot of post summaries, including the first 28 posts, but many posts still lack summaries.&nbsp; Things will work more smoothly if those summaries get written in advance and added to the wiki before we get to them. <br /><br />The main purpose of the Rerunning the Sequences series is to make it easier for people to read or re-read the sequences by putting them in a convenient format that's more like reading new blog posts.&nbsp;&nbsp; Hopefully, this project will also be complementary to other sequence-related projects.&nbsp; As we go through the old sequence posts, some people may be inspired to <a href=\"/r/discussion/lw/4pt/bring_back_the_sequences/3nci\">write condensed versions</a> of them, <a href=\"/r/discussion/lw/53f/sequence_posts_exercises/\">create exercises</a> for them, or even just to add better summaries to the wiki.&nbsp; And perhaps Eliezer will finally be able to get the karma he deserves for his pre-LW posts.<br /><br />Another advantage of the sequence reruns series is that it creates a focal point for discussion of the material in the sequences.&nbsp; It's much easier to have discussions about old posts when a lot of people are reading the same post at the same time.&nbsp; We've gone back and forth on where this discussion should take place: on the original post or on the new post.&nbsp; The comments will be about the content of the original post, so it sort of makes sense for them to go there, and that will help keep all of the discussion about that post in one place.&nbsp; On the other hand, this is a fresh discussion taking place a few years after the original posts, and commenting on the new post would keep everything in the discussion section so that the main page &ldquo;recent comments&rdquo; feed doesn't get flooded with discussion of old posts.&nbsp; Right now the template is written to have comments go on the new post rather than the original post, but this could go either way.&nbsp; There's a <a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/3wje\">poll</a> on this in the comments; we should decide one way or the other, since haphazardly splitting the discussion between the two places is the worst option.<br /><br />So, what do you think?&nbsp; Does it make sense to put these new posts in the discussion section?&nbsp; To do the whole Yudkowsky oeuvre rather than specific sequences?&nbsp; To have one post per day?&nbsp; Do you have a better name than &ldquo;Rerunning The Sequences&rdquo; (tag: sequence_reruns, title: [SEQ RERUN])?&nbsp; Does the post template look okay?&nbsp; Try to make comments actionable (polls are recommended) so that we can make changes over the next few days and then get started (assuming that there aren't major objections to the whole project).<br /><br />Unless there are major objections, we'll try to get everything ironed out and start with the first post next Monday (4/18).</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">Template</span></p>\n<p>Title: [SEQ RERUN] Why truth? And...<br /><br />Today's post, <a href=\"/lw/go/why_truth_and/\">Why truth? And...</a> was originally published on November 26, 2006.&nbsp; A summary (taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>):</p>\n<blockquote>Why should we seek truth? Pure curiosity is an emotion, but not therefore irrational. Instrumental value is another reason, with the advantage of giving an outside verification criterion. A third reason is conceiving of truth as a moral duty, but this might invite moralizing about \"proper\" modes of thinking that don't work. Still, we need to figure out how to think properly. That means avoiding biases, for which see the next post.</blockquote>\n<p><br />Discuss here. [???]<br /><br /><em>This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.&nbsp; The previous post was <a href=\"/r/discussion/\">The Martial Art of Rationality</a>, and you can use the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a> to follow the rest of the series.<br /><br />Sequence reruns are a community-driven effort.&nbsp; You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. See <a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/\">here</a> for more details.</em><br /><br />Tags: sequence_reruns</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1, "JMD7LTXTisBzGAfhX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7XPZQddvD2RBEMdQq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 36, "baseScore": 49, "extendedScore": null, "score": 7.01085489832319e-07, "legacy": true, "legacyId": "6689", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 33, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 46, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["WXgEQZL2yYmhHjKmn", "5wLDhMCn2p3mMnC6g", "SoadQym38wGBDJ7AH", "YshRbqZHYFoEMqFAu", "7XPZQddvD2RBEMdQq"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T22:02:50.097Z", "modifiedAt": null, "url": null, "title": "Map & Territory as PDF and org-mode file (& explanation)", "slug": "map-and-territory-as-pdf-and-org-mode-file-and-explanation", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jwhendy", "createdAt": "2011-01-04T19:53:21.160Z", "isAdmin": false, "displayName": "jwhendy"}, "userId": "ZaJctSZkCvg7qvSEC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WQQQL9QFB3sASD7Ky/map-and-territory-as-pdf-and-org-mode-file-and-explanation", "pageUrlRelative": "/posts/WQQQL9QFB3sASD7Ky/map-and-territory-as-pdf-and-org-mode-file-and-explanation", "linkUrl": "https://www.lesswrong.com/posts/WQQQL9QFB3sASD7Ky/map-and-territory-as-pdf-and-org-mode-file-and-explanation", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Map%20%26%20Territory%20as%20PDF%20and%20org-mode%20file%20(%26%20explanation)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMap%20%26%20Territory%20as%20PDF%20and%20org-mode%20file%20(%26%20explanation)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQQQL9QFB3sASD7Ky%2Fmap-and-territory-as-pdf-and-org-mode-file-and-explanation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Map%20%26%20Territory%20as%20PDF%20and%20org-mode%20file%20(%26%20explanation)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQQQL9QFB3sASD7Ky%2Fmap-and-territory-as-pdf-and-org-mode-file-and-explanation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQQQL9QFB3sASD7Ky%2Fmap-and-territory-as-pdf-and-org-mode-file-and-explanation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1033, "htmlBody": "<p>Sequences have been coming up a lot lately (<a href=\"/lw/4zs/philosophy_a_diseased_discipline/3slj\">have you read them</a>?, <a href=\"/r/discussion/lw/51j/reading_the_sequences_before_starting_to_post/\">pre-posting reqs</a>, <a href=\"/r/discussion/lw/4pt/bring_back_the_sequences/\">re-runs</a>, and <a href=\"/\">exercises</a>). I received <em>fantastic</em>&nbsp;feedback to a recent <a href=\"/r/discussion/lw/53h/recent_deconvert_saturated_by_religious_community/\">request for advice</a>, and the top suggestion that really solidified for me was to finish reading a set quantity of my <a href=\"http://technologeekery.blogspot.com/2010/07/truth-seeker-challenge.html\">book list</a>&nbsp;and finish my \"<a href=\"http://technologeekery.blogspot.com/2011/01/post-series-my-cumulative-case-index.html\">statement of non-belief</a>\" in order to have a conversation defuser concerning my deconversion.</p>\n<p>In any case, I decided that before I read those books, I want to read the <a href=\"http://wiki.lesswrong.com/wiki/Sequences#Core_Sequences\">core sequences</a> as well as <a href=\"http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind\">How to Actually Change Your Mind</a>. That's a healthy workload up ahead. I've actually read many of these here and there, but want to read systematically... and take notes.</p>\n<p>Which brings me to my main point. I've been using emacs <a href=\"http://orgmode.org/\">org-mode</a>&nbsp;as my information manager (home and work) for some time now. I found it as a replacement to <a href=\"http://www.tiddlywiki.com/\">TiddlyWiki</a>&nbsp;(which I still consider a close second) and <em>it absolutely rocks</em>. I primarily use it for intellectual property related notes at work, but my knowledge of it has advanced to using it to <a href=\"http://i.imgur.com/gdBFy.png\">collect and plot data</a>, <a href=\"https://sites.google.com/site/jwhendytank/home/FHTM_Analysis_Aug-2010.pdf\">write reports</a>, track todos, and even track my time. It's a phenomenal program that has helped me with planning and information management a ton.</p>\n<p>I've already used this to record notes on reading <a href=\"http://technologeekery.blogspot.com/2010/07/what-do-i-take-notes-with.html\">before</a>, and I decided that I was going to use it for my notes on the sequences. As a result, I need to grab the articles and get them into org-mode. I did this pretty \"kludgily\" (wget plus a hand-tailored bash script that uses sed to transform the html back into characters and italics/bold into org-mode markup language). As a result, I now have org-mode files for all of Map &amp; Territory. I thought I'd post on why I would even do this as well as to generate any discussion on whether or not this is useful for future sequences (I'll be going through those as well and will likely repeat the process).</p>\n<p>&nbsp;</p>\n<p><strong>Why in the world would you do this?</strong></p>\n<p>Well, first of all, it's really not that time-intensive. The bash script takes care of almost everything. The real time killer was the Intro to Bayes which had an insane amount of monospace tags for all the math. I think each article maybe took me 10min to download and clean up. Here's what we're working with after cleanup:</p>\n<p>All articles shown collapsed (click to enlarge):</p>\n<p><a href=\"http://i.imgur.com/euk19.png\"><img style=\"vertical-align: middle;\" src=\"http://i.imgur.com/euk19.png\" alt=\"\" width=\"400\" /></a></p>\n<p>And with What do We Mean By Rationality? expanded:</p>\n<p><a href=\"http://i.imgur.com/bj2Xa.png\"><img style=\"vertical-align: middle;\" src=\"http://i.imgur.com/bj2Xa.png\" alt=\"\" width=\"400\" /></a></p>\n<p>&nbsp;</p>\n<p>Looks like something out of the 1970s? <a href=\"http://en.wikipedia.org/wiki/Emacs\">Probably because it is</a>. You get used to looking at plain text, trust me :)</p>\n<p>I'll be using this for notes, and many of you surely have systems for this already. One thing I like about org-mode that I find unique is that <em>the notes and the text are in the same medium.</em>&nbsp;When I read \"real books\" (the paper kind), I <em>hate</em>&nbsp;retyping quotes I want in my notes while I fiddle with holding the darned thing open on my lap as I type into the keyboard. Now, I can either copy/paste the quote into notes at the end of a file, or insert them inline where I want to say something. For example:</p>\n<p>An inline note</p>\n<p>Notes at the end:</p>\n<p>&nbsp;</p>\n<p>In both cases, these notes are in their own \"headlines\" (shown by the preceding asterisks), which gives me some additional control over the text underneath them (more on that later).</p>\n<p>What else? Well, for this particular article, I started a timer when I began reading and stopped it when I finished. This gives me something like this:</p>\n<p>See the \"Clock:...\" line? When I'm done with this sequence, I'll have a fully filled out clock report with all the articles and the time it took me to get through them here:</p>\n<p>&nbsp;</p>\n<p>That report is auto-generated, so whenever I clock in and out of a headline, I can update it and get the new summary.</p>\n<p>&nbsp;</p>\n<p>I can also give myself todos. One thing that kills me about LW is browser tab self-destruction. I'll want to get through a couple posts and suddenly I have 20 tabs open with so many morsels of intellectual stimulation that I just don't want to go to bed until I've read them all, for fear of never finding them again. Not so anymore. Note all the little purple [Fn:#]s in the above pictures. I've translated all the hyperlinks into org-mode footnotes. If I'm reading along and come across one and want to know where it was going, I just press a key stroke and it transports me there. Here's a split emacs screen showing that:</p>\n<p>In the top frame my cursor is on [Fn:3], I pressed Control-C twice and get teleported down to the Footnotes section and see it's a link to The Simple Truth. Great. No worries. Read that. What about [Fn:4] to The Conjunction Fallacy? Hmmm, seems important, but I really want to stay on task. Let's make a todo. Teleport down to the footnotes, copy the link, and add a todo:</p>\n<p>&nbsp;</p>\n<p>Org-mode comes in with a built in filter to show you just your todos. You can add <em>any number of org files</em>&nbsp;to something called your \"agenda list\" and it will search through all of them and scrape out all the todos and present them to you. <em>That's</em>&nbsp;helpful. As an aside, I used to keep notes separate from todos because the notes were generally for longer term storage/reference, but the todos needed to be recalled and acted on. Unfortunately, separating them like this can separate the todo from its context, which means that if you keep notes and todos in separate programs, you needed to duplicate your notes in each place to recall what in the world that todo was about. Well, in org-mode, you can just add it right there and call it up at any time like so:</p>\n<p>&nbsp;</p>\n<p>The bottom pane is the agenda view, which is showing me all todos for my Map &amp; Territory org-mode file. As I add more, they'll show up. I can also add deadlines (shown under the todo headline in the top pane) to create goals for myself one when to get them done. I'm hoping that integrating org-mode into my reading will help keep me more on track rather than getting me lost in tab-land, fixated on reading stuff just because it was linked to.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WQQQL9QFB3sASD7Ky", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6738", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["EauwsXht4jrjTTE9m", "WXgEQZL2yYmhHjKmn", "fnTHrfFz5TMW8c9R2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T22:58:03.869Z", "modifiedAt": null, "url": null, "title": "Anthropics makes sense with shorter people", "slug": "anthropics-makes-sense-with-shorter-people", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:00.898Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "KatjaGrace", "createdAt": "2009-02-27T14:15:22.378Z", "isAdmin": false, "displayName": "KatjaGrace"}, "userId": "jRRYAy2mQAHy2Mq3f", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uiK8XqjvgbTepcKud/anthropics-makes-sense-with-shorter-people", "pageUrlRelative": "/posts/uiK8XqjvgbTepcKud/anthropics-makes-sense-with-shorter-people", "linkUrl": "https://www.lesswrong.com/posts/uiK8XqjvgbTepcKud/anthropics-makes-sense-with-shorter-people", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Anthropics%20makes%20sense%20with%20shorter%20people&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAnthropics%20makes%20sense%20with%20shorter%20people%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuiK8XqjvgbTepcKud%2Fanthropics-makes-sense-with-shorter-people%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Anthropics%20makes%20sense%20with%20shorter%20people%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuiK8XqjvgbTepcKud%2Fanthropics-makes-sense-with-shorter-people", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuiK8XqjvgbTepcKud%2Fanthropics-makes-sense-with-shorter-people", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 970, "htmlBody": "<p>Reproduced from <a href=\"http://meteuphoric.wordpress.com/2011/04/10/person-moments-make-sense-of-anthropics/\">Meteuphoric</a> by request.</p>\n<p>Often people think that various forms of anthropic reasoning require you to change your beliefs in ways other than conditionalizing on evidence. This is false, at least in the cases I know of. I shall talk about <a href=\"http://www.univ.ox.ac.uk/whos_who/academic_staff/fellows_1/frank_arntzenius\">Frank Arntzenius</a>' paper Some Problems for Conditionalization and Reflection&nbsp;<span style=\"color: #333333; font-family: Georgia, 'Bitstream Charter', serif; font-size: 14px; line-height: 22px;\">[<a style=\"font-family: Georgia, 'Bitstream Charter', serif; font-style: inherit; font-weight: inherit; outline-width: 0px; outline-style: initial; outline-color: initial; vertical-align: baseline; color: #0060ff; line-height: 1.7; padding: 0px; margin: 0px; border: 0px initial initial;\" href=\"http://www.jstor.org/pss/3655783\">gated</a>]</span>&nbsp;because it explains the issue well, though I believe his current views agree with mine.</p>\n<p>He presents five thought experiments: Two Roads to Shangri La, The Prisoner, John Collins's Prisoner, <a href=\"http://en.wikipedia.org/wiki/Sleeping_Beauty_problem\">Sleeping Beauty</a>&nbsp;and Duplication. In each of them, it seems the (arguably) correct answer violates van Fraassen's reflection principle, which basically says that if you expect to believe something in the future without having been e.g. hit over the head between now and then, you should believe it now. For instance the thirder position in Sleeping Beauty seems to violate this principle because before the experiment Beauty believes there is a fifty percent chance of heads, and that when she wakes up she will think there is a thirty three percent chance. Arntzenius argued that these seemingly correct answers really are the correct ones, and claimed that they violate the reflection principle because credences can evolve in two ways other than by conditionalization.</p>\n<p>First he said credences can shift, for instance through time. I know that tomorrow I will have a higher credence in it being Monday than I do today, and yet it would not be rational for me to increase my credence in it being Monday now on this basis. They can also 'spread out'. For instance if you know you are in Fairfax today, and that tomorrow a perfect replica of your brain experiencing Fairfax will be made and placed in a vat in Canberra, tomorrow your credence will go from being concentrated in Fairfax to being spread between there and Canberra. This is despite no damage having been done to your own brain. As Arntzenius pointed out, such an evolution of credence looks like quite the opposite of conditionalization, since conditionalization consists of striking out possibilities that your information excludes - it never opens up new possibilities.</p>\n<p>I agree that beliefs should evolve in these two ways. However they are both really conditionalization, just obscured. They make sense as conditionalization when you think of them as carried out by different momentary agents, based on the information they infer from their connections to other momentary agents with certain beliefs (e.g. an immediately past self).</p>\n<p>Normal cases can be considered this way quite easily. Knowing that you are the momentary agent that followed a few seconds after an agent who knew a certain set of facts about the objective world, and who is (you assume) completely trustworthy, means you can simply update the same prior with those same facts and come to the same conclusion. That is, you don't really have to do anything. You can treat a stream of moments as a single agent. This is what we usually do.</p>\n<p>However sometimes being connected in a certain way to another agent does not make everything that is true for them true for you. Most obviously, if they are a past self and know it is 12 o clock, your connection via being their one second later self means you should exclude worlds where you are not at time 12:00:01. You have still learned from your known relationship to that agent and conditionalized, but you have not learned that what is true of them is true of you, because it isn't. This is the first way Arntzenius mentioned that credences seem to evolve through time not by by conditionalization.</p>\n<p>The second way occurs when one person-moment is at location X, and another person moment has a certain connection to the person at X, but there is more than one possible connection of that sort. For instance when two later people both remember being an earlier person because the earlier person was replicated in some futuristic fashion. Then while the earlier person moment could condition on their exact location, the later one must condition on being in one of several locations connected that way to the earlier person's location, so their credence spreads over more possibilities than that of the earlier self. If you call one of these later momentary agents the same person as the earlier one, and say they are conditionalizing, it seems they are doing it wrong. But considered as three different momentary people learning from their connections they are just conditionalizing as usual.</p>\n<p>What exactly the later momentary people should believe is a <a href=\"http://meteuphoric.wordpress.com/anthropic-principles\">matter of debate</a>, but I think that can be framed entirely as a question of what their state spaces and priors look like.</p>\n<p>Momentary humans almost always pass lots of information from one to the next, chronologically along chains of memory through non-duplicated people, knowing their approximate distance from one another. So most of the time they can treat themselves as single units who just have to update on any information coming from outside, as I explained. But conditionalization is not specific to these particular biological constructions; and when it is applied to information gained through other connections between agents, the resulting time series of beliefs within one human will end up looking different to that in a chain with no unusual extra connections.</p>\n<p>This view also suggests that having cognitive defects, such as memory loss, should not excuse anyone from having credences, as for instance Arntzenius argued it should in his paper <a href=\"http://courses.cit.cornell.edu/jdv55/teaching/184/arntzenius%20-%20reflections%20on%20sleeping%20beauty.pdf\">Reflections on Sleeping Beauty</a>: \"in the face of forced irrational changes in one's degrees of belief one might do best simply to jettison them altogether\". There is nothing special about credences derived from beliefs of a past agent you identify with. They are just another source of information. If the connection to other momentary agents is different to usual, for instance through forced memory loss, update on it as usual.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PbShukhzpLsWpGXkM": 3}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uiK8XqjvgbTepcKud", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 34, "baseScore": 46, "extendedScore": null, "score": 9.1e-05, "legacy": true, "legacyId": "6740", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 46, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 6, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-11T23:09:30.287Z", "modifiedAt": null, "url": null, "title": "Student meetups", "slug": "student-meetups", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.298Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Mycroft65536", "createdAt": "2009-03-14T03:04:26.898Z", "isAdmin": false, "displayName": "Mycroft65536"}, "userId": "dKGL3eRH8Xcvrig7b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/MdKPy4xoDzDi6fJTJ/student-meetups", "pageUrlRelative": "/posts/MdKPy4xoDzDi6fJTJ/student-meetups", "linkUrl": "https://www.lesswrong.com/posts/MdKPy4xoDzDi6fJTJ/student-meetups", "postedAtFormatted": "Monday, April 11th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Student%20meetups&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AStudent%20meetups%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMdKPy4xoDzDi6fJTJ%2Fstudent-meetups%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Student%20meetups%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMdKPy4xoDzDi6fJTJ%2Fstudent-meetups", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FMdKPy4xoDzDi6fJTJ%2Fstudent-meetups", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 54, "htmlBody": "<p>There have been a rush of meetups being formed the last few weeks. I'm curious if any of them have been student groups at schools. I'd like to talk to anyone who's organizing a meetup at school, or attending a meetup at a school, or attending school and would like to have a meetup.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "MdKPy4xoDzDi6fJTJ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 7.011884996997259e-07, "legacy": true, "legacyId": "6741", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 6, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T01:02:08.375Z", "modifiedAt": null, "url": null, "title": "Virgin Galactic hiring full time astronauts [link]", "slug": "virgin-galactic-hiring-full-time-astronauts-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:24.751Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/As5urCgEhL44jnPJx/virgin-galactic-hiring-full-time-astronauts-link", "pageUrlRelative": "/posts/As5urCgEhL44jnPJx/virgin-galactic-hiring-full-time-astronauts-link", "linkUrl": "https://www.lesswrong.com/posts/As5urCgEhL44jnPJx/virgin-galactic-hiring-full-time-astronauts-link", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Virgin%20Galactic%20hiring%20full%20time%20astronauts%20%5Blink%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVirgin%20Galactic%20hiring%20full%20time%20astronauts%20%5Blink%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAs5urCgEhL44jnPJx%2Fvirgin-galactic-hiring-full-time-astronauts-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Virgin%20Galactic%20hiring%20full%20time%20astronauts%20%5Blink%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAs5urCgEhL44jnPJx%2Fvirgin-galactic-hiring-full-time-astronauts-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAs5urCgEhL44jnPJx%2Fvirgin-galactic-hiring-full-time-astronauts-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://careers.virgin.com/search/1921/\">http://careers.virgin.com/search/1921/</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "As5urCgEhL44jnPJx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 13, "baseScore": -14, "extendedScore": null, "score": -2.7e-05, "legacy": true, "legacyId": "6743", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T01:24:21.227Z", "modifiedAt": null, "url": null, "title": "It is OK to publicly make a mistake and change your mind", "slug": "it-is-ok-to-publicly-make-a-mistake-and-change-your-mind", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.605Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "JGWeissman", "createdAt": "2009-04-01T04:43:56.740Z", "isAdmin": false, "displayName": "JGWeissman"}, "userId": "Mw8rsM7m7E8nnEFEp", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QmqP8FeQix5ebseyF/it-is-ok-to-publicly-make-a-mistake-and-change-your-mind", "pageUrlRelative": "/posts/QmqP8FeQix5ebseyF/it-is-ok-to-publicly-make-a-mistake-and-change-your-mind", "linkUrl": "https://www.lesswrong.com/posts/QmqP8FeQix5ebseyF/it-is-ok-to-publicly-make-a-mistake-and-change-your-mind", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20It%20is%20OK%20to%20publicly%20make%20a%20mistake%20and%20change%20your%20mind&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIt%20is%20OK%20to%20publicly%20make%20a%20mistake%20and%20change%20your%20mind%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQmqP8FeQix5ebseyF%2Fit-is-ok-to-publicly-make-a-mistake-and-change-your-mind%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=It%20is%20OK%20to%20publicly%20make%20a%20mistake%20and%20change%20your%20mind%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQmqP8FeQix5ebseyF%2Fit-is-ok-to-publicly-make-a-mistake-and-change-your-mind", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQmqP8FeQix5ebseyF%2Fit-is-ok-to-publicly-make-a-mistake-and-change-your-mind", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 229, "htmlBody": "<p>At a recent meetup, we tried having a structured discussion in which we would all choose to talk about a belief that influences our behavior, talk about something we protect, or talk about a mistake we once made and have corrected. And it seemed that people thought it would require exceptional bravery to choose to talk about one's mistake. Elsewhere on Less Wrong, people are concerned about retaining the ability to edit a comment expressing a position they later reconsider and think is wrong.</p>\n<p>My first reaction to all of this is that we need a group norm so that it doesn't require bravery to admit a mistake, or to leave a record of previously held positions. My second reaction is that we do in fact have such a norm. Comments expressing a change in position, that accept counter arguments and refutations, get up voted. Old comments reflecting the old wrong position are generally not down voted for being wrong. The problem is not how we treat people that make mistakes, but that people have inaccurate anticipations of how we will react.</p>\n<p>So, to everyone who is worried about this, I want to say: It's OK. You can admit your mistakes. You can make a mistake and change your mind. We, the community, will applaud your growth, celebrate your new strength, and leave your mistake in the past where it belongs.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"wzgcQCrwKfETcBpR9": 2, "moeYqrcakMgXnQNyF": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QmqP8FeQix5ebseyF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 74, "baseScore": 89, "extendedScore": null, "score": 0.000176, "legacy": true, "legacyId": "6744", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 89, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T01:55:42.680Z", "modifiedAt": null, "url": null, "title": "We are not living in a simulation", "slug": "we-are-not-living-in-a-simulation-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:28.997Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dfranke", "createdAt": "2009-02-27T18:51:11.645Z", "isAdmin": false, "displayName": "dfranke"}, "userId": "kqWQye46c5bMBS4RS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/QnSgnKQvpv74cmgFx/we-are-not-living-in-a-simulation-0", "pageUrlRelative": "/posts/QnSgnKQvpv74cmgFx/we-are-not-living-in-a-simulation-0", "linkUrl": "https://www.lesswrong.com/posts/QnSgnKQvpv74cmgFx/we-are-not-living-in-a-simulation-0", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20We%20are%20not%20living%20in%20a%20simulation&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWe%20are%20not%20living%20in%20a%20simulation%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQnSgnKQvpv74cmgFx%2Fwe-are-not-living-in-a-simulation-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=We%20are%20not%20living%20in%20a%20simulation%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQnSgnKQvpv74cmgFx%2Fwe-are-not-living-in-a-simulation-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FQnSgnKQvpv74cmgFx%2Fwe-are-not-living-in-a-simulation-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2227, "htmlBody": "<p>The aim of this post is to challenge Nick Bostrom's <a href=\"http://www.simulation-argument.com/simulation.html\">simulation argument</a> by attacking the premise of substrate-independence. Quoting Bostrom in full, this premise is explained as follows:</p>\n<blockquote>\n<p>A common assumption in the philosophy of mind is that of substrate-independence. The idea is that mental states can supervene on any of a broad class of physical substrates. Provided a system implements the right sort of computational structures and processes, it can be associated with conscious experiences. It is not an essential property of consciousness that it is implemented on carbon-based biological neural networks inside a cranium: silicon-based processors inside a computer could in principle do the trick as well.</p>\n<p>Arguments for this thesis have been given in the literature, and although it is not entirely uncontroversial, we shall here take it as a given.</p>\n<p>The argument we shall present does not, however, depend on any very strong version of functionalism or computationalism. For example, we need not assume that the thesis of substrate-independence is necessarily true (either analytically or metaphysically) -- just that, in fact, a computer running a suitable program would be conscious. Moreover, we need not assume that in order to create a mind on a computer it would be sufficient to program it in such a way that it behaves like a human in all situations, including passing the Turing test etc. We need only the weaker assumption that it would suffice for the generation of subjective experiences that the computational processes of a human brain are structurally replicated in suitably fine-grained detail, such as on the level of individual synapses. This attenuated version of substrate-independence is quite widely accepted.</p>\n<p>Neurotransmitters, nerve growth factors, and other chemicals that are smaller than a synapse clearly play a role in human cognition and learning. The substrate-independence thesis is not that the effects of these chemicals are small or irrelevant, but rather that they affect subjective experience only via their direct or indirect influence on computational activities. For example, if there can be no difference in subjective experience without there also being a difference in synaptic discharges, then the requisite detail of simulation is at the synaptic level (or higher).</p>\n</blockquote>\n<p>I contend that this premise, in even its weakest formulation, is utterly, unsalvageably false.</p>\n<p>Since Bostrom never precisely defines what a \"simulator\" is, I will apply the following working definition: a simulator is a physical device which assists a human (or posthuman) observer with deriving information about the states and behavior of a hypothetical physical system. A simulator is \"perfect\" if it can respond to any query about the state of any point or volume of simulated spacetime with an answer that is correct according to some formal mathematical model of the laws of physics, with both the query and the response encoded in a language that it is easily comprehensible to the simulator's [post]human operator. We can now formulate the substrate independence hypothesis as follows: any perfect simulator of a conscious being experiences the same qualia as that being.</p>\n<p>Let us make a couple observations about these definitions. First: if the motivation for our hypothetical post-Singularity civilization to simulate our universe is to study it, then any perfect simulator should provide them with everything necessary toward that end. Second: the substrate independence hypothesis as I have defined it is much weaker than any version which Bostrom proposes, for any device which perfectly simulates a human must necessarily be able to answer queries about the state of the human's brain, such as what synapses are firing at what time, as well as any other structural question right down to the Planck level.</p>\n<p>Much of the ground I am about to cover has been tread in the past by John Searle. I will explain later in this post where it is that I differ with him.</p>\n<p>Let's consider a \"hello universe\" example of a perfect simulator. Suppose an essentially Newtonian universe in which matter is homogeneous at all sufficiently small scales; i.e., there are either no quanta, or quanta simply behave like billiard balls. Gravity obeys the familiar inverse-square law. The only objects in this universe are two large spheres orbiting each other. Since the two-body problem has an easy closed-form solution, it is hypothetically straightforward to program a Turing machine to act as a perfect simulator of this universe, and furthermore an ordinary present-day PC can be an adequate stand-in for a Turing machine so long as we don't ask it to make its answers precise to more decimal places than fit in memory. It would pose no difficulty to actually implement this simulator.</p>\n<p>If you ran this simulator with Jupiter-sized spheres, it would reason perfectly about the gravitational effects of those spheres. Yet, the computer would not actually produce any more gravity than it would while powered off. You would not be sucked toward your CPU and have your body smeared evenly across its surface. In order for that happen, the simulator would have to mimic the simulated system in physical form, not merely computational rules. That is, it would have to actually have two enormous spheres inside of it. Such a machine could still be a \"simulator\" in the sense that I've defined the term &mdash; but in colloquial usage, we would stop calling this a simulator and instead call it the real thing.</p>\n<p>This observation is an instance of a general principle that ought be very, very obvious: reasoning about a physical phenomenon is not the same as causing a physical phenomenon. You cannot create new territory by sketching a map of it, no matter how much detail you include in your map.</p>\n<p>Qualia are physical phenomena. I dearly wish that this statement were uncontroversial. However, if you don't agree with it, then you can reject the simulation argument on far simpler grounds: if experiencing qualia requires a \"nonphysical\" \"soul\" or whatnot (I don't know how to make sense out of either of those words), then there is no reason to suppose that any man-made simulator is imbued with a soul and therefore no reason to suppose that it would be conscious. However, provided that you agree that qualia are physical phenomena, then to suppose that they are any kind of exception to the principle I've just stated is simply bizarre magical thinking. A simulator which reasons perfectly about a human being, even including correctly determining what qualia a human would experience, does not necessarily experience those qualia, any more than a simulator that reasons perfectly about high gravity necessarily produces high gravity.</p>\n<p>Hence, the type of qualia that a simulator actually produces (if any) depends crucially on the actual physical form of that simulator. A machine which walks the way a human walks must have the form of a human leg. A machine which grips the way a human grips must have the form of a human hand. And a machine which experiences the way a human experiences must have the form of a human brain.</p>\n<p>For an example of my claim, let us suppose like Bostrom does that a simulation which correctly models brain activity down to the level of individual synaptic discharges is sufficient in order model all the essential features of human consciousness. What does that tell us about what would be required in order to build an artificial human? Here is one design that would work: first, write a computer program, running on (sufficiently fast) conventional hardware, which correctly simulates synaptic activity in a human brain. Then, assemble millions of tiny spark plugs, one per dendrite, into the physical configuration of a human brain. Run a cable from the computer to the spark plug array, and have the program fire the spark plugs in the same sequence that it predicts that synapses would occur in a biological human brain. As these firings occurred, the array would experience human-like qualia. The same qualia would <em>not</em> result if the simulator merely computed what plugs ought to fire without actually firing them.</p>\n<p>Alternatively, what if granularity right down to the Planck level turned out to be necessary? In that case, the only way to build an artificial brain would to be to actually build, particle-for-particle, a brain &mdash; since due to speed-of-light limitations, no other design could possibly model everything it needed to model in real time.</p>\n<p>I think that actual requisite granularity is probably somewhere in between. The spark plug design seems too crude to work, while Planck-level correspondence is certainly overkill, because otherwise, the tiniest fluctuation in our surrounding environment, such as a .01 degree change in room temperature, would have a profound impact on our mental state.</p>\n<p>Now, from here on is where I depart from Searle if I have not already. Consider the following questions:</p>\n<ol>\n<li><a href=\"/lw/np/disputing_definitions/\">If a tree falls in the forest </a>and nobody hears it, does it make an acoustic vibration?</li>\n<li>If a tree falls in the forest and nobody hears it, does it make an auditory sensation?</li>\n<li>If a tree falls in the forest and nobody hears it, does it make a sound?</li>\n<li>Can the <a href=\"http://vonneumann.cog.jhu.edu/faculty/smolensky/050.326-626/Foundations%20Readings%20PDFs/Searle-1980.pdf\">Chinese Room</a> (.pdf link) pass a Turing test administered in Chinese?</li>\n<li>Does the Chinese Room experience the same qualia that a Chinese-speaking human would experience when replying to a letter written in Chinese?</li>\n<li>Does the Chinese Room understand Chinese?</li>\n<li>Is the Chinese Room intelligent?</li>\n<li>Does the Chinese Room think?</li>\n</ol>\n<p>Here is the answer key:</p>\n<ol>\n<li>Yes.</li>\n<li>No.</li>\n<li>What do you mean?</li>\n<li>Yes.</li>\n<li>No.</li>\n<li>What do you mean?</li>\n<li>What do you mean?</li>\n<li>What do you mean?</li>\n</ol> <ol> </ol>\n<p>The problem with Searle is his lack of any clear answer to \"What do you mean?\". Most technically-minded people, myself included, think of 6&ndash;8 as all meaning something similar to 4. Personally, I think of them as meaning something even weaker than 4, and have no objection to describing, e.g., Google, or even a Bayesian spam filter, as \"intelligent\". Searle seems to want them to mean the same as 5, or maybe some conjunction of 4 and 5. But in counterintuitive edge cases like the Chinese Room, they don't mean anything at all until you assign definitions to them.</p>\n<p>I am not certain whether or not Searle would agree with my belief that it is possible for a Turing machine to correctly answer questions about what qualia a human is experiencing, given a complete physical description of that human. If he takes the negative position on this, then this is a serious disagreement that goes beyond semantics, but I cannot tell that he has ever committed himself to either stance.</p>\n<p>Now, there remains a possible argument that might seem to save the simulation hypothesis even in the absence of substrate-independence. \"Okay,\" you say, \"you've persuaded me that a human-simulator built of silicon chips would not experience the same qualia as the human it simulates. But you can't tell me that it doesn't experience <em>any</em> qualia. For all you or I know, a lump of coal experiences qualia of <em>some</em> sort. So, let's say you're in fact living in a simulation implemented in silicon. You're experiencing qualia, but those qualia are all wrong compared to what you as a carbon-based bag of meat ought to be experiencing. How would you know anything is wrong? How, other than by life experience, do you know what the <em>right</em> qualia for a bag of meat actually are?\"</p>\n<p>The answer is that I know my qualia are right because they make sense. Qualia are not pure \"outputs\": they feed back on the rest of the world. If I step outside on a scorching summer day, then I feel hot, and this unpleasant quale <em>causes</em> me to go back inside, and I am able to understand and articulate this cause and effect. If my qualia were actually those of a computer chip, then rather than feeling hot I would feel purple (or rather, some quale that no human language can describe), and if you asked me why I went back indoors even though I don't have any particular objection to purple and the weather is not nearly severe enough to pose any serious threat to my health, I wouldn't be able to answer you or in any way connect my qualia to my actions.</p>\n<p>So, I think I have now established that to any extent we can be said to be living in a simulation, the simulator must physically incorporate a human brain. I have not precluded the possibility of a simulation in the vein of \"The Matrix\", with a brain-in-a-vat being fed artificial sensory inputs. I think this kind of simulation is indeed possible in principle. However, nothing claimed in Bostrom's simulation argument would suggest that it is at all likely.</p>\n<p><strong>ETA:</strong> A question that I've put to Sideways can be similarly put to many other commenters on this thread.&nbsp; \"Similar in number\", i.e., two apples, two oranges, etc., is, similarly to \"embodying the same computation\", an abstract concept which can be realized by a wide variety of physical media.&nbsp; Yet, if I replaced the two hemispheres of your brain with two apples, clearly you would become quite ill, even though similarity in number has been preserved.&nbsp; If you believe that \"embodying the same computation\" is somehow a privileged concept in this regard -- that if I replaced your brain with something else embodying the same computation that you would feel yourself to be unharmed -- what is your justification for believing this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "QnSgnKQvpv74cmgFx", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 52, "baseScore": -14, "extendedScore": null, "score": -1.6e-05, "legacy": true, "legacyId": "6746", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 218, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["7X2j8HAkWdmMoS8PE"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T02:02:33.923Z", "modifiedAt": null, "url": null, "title": "Modeling sleep patterns", "slug": "modeling-sleep-patterns", "viewCount": null, "lastCommentedAt": "2020-06-04T06:21:45.957Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "pdf23ds", "createdAt": "2009-03-09T04:29:16.252Z", "isAdmin": false, "displayName": "pdf23ds"}, "userId": "Kqp6LJYaojxnwgEZm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/THrcKicMkpHMbrDBQ/modeling-sleep-patterns", "pageUrlRelative": "/posts/THrcKicMkpHMbrDBQ/modeling-sleep-patterns", "linkUrl": "https://www.lesswrong.com/posts/THrcKicMkpHMbrDBQ/modeling-sleep-patterns", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Modeling%20sleep%20patterns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AModeling%20sleep%20patterns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTHrcKicMkpHMbrDBQ%2Fmodeling-sleep-patterns%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Modeling%20sleep%20patterns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTHrcKicMkpHMbrDBQ%2Fmodeling-sleep-patterns", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTHrcKicMkpHMbrDBQ%2Fmodeling-sleep-patterns", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 353, "htmlBody": "<p>My sleep is unpredictable. Not in a technical sense, but a colloquial one. To be literal, I have no idea how to predict my sleep. I just as often sleep through the day as I do through the night. My sleep itself, as far as a sleep study can tell, is normal. I can vaguely say, 60% confidence, if I'm likely to fall asleep in a given 3-4 hour period, and occasionally I will be fairly sure, 80% confidence, 6-10 hours beforehand, of a 1-2 hour period. I can similarly predict the length of my sleep (which is relatively normal--generally distributed 7, 8, 9.5, 13 hours at .1, .4, .6, .9).</p>\n<p>My sleep is seriously disturbed. Without understanding the process behind my sleep, without being able to predict it days beforehand and understand the variables behind it, I find it impossible to wake up at a consistent time every day (+/- 8 hours), despite years of trying, which makes it extremely hard to hold down a job, or do dozens of other normal things. There could be a profession that I could make my sleep work with, but I'm still searching for it.</p>\n<p>So I ask you readers: Is there some sort of pattern detecting <strong>thing,</strong> whose name perhaps includes something like \"markov\" or \"kolmogorov\" or \"bayesian\", that could automatically take a time series data and predict the next values based on an unknown, complex model?</p>\n<p>So, I could like enter the times I go to sleep and wake up, and when I have caffeine or I exercise, and maybe other things, and it would puzzle out how my sleep works and forecast my next few sleep cycles?</p>\n<p>To have an accurate tool like that would transform my life.</p>\n<p>\"Hidden Markov models\" comes to mind, but at first glance I don't see how a sleep model would count as a Markov process, given that you have to factor in sleep debt, time of day (because of sunlight), and perhaps other variables. But then I know nothing about HMMs.</p>\n<p>&nbsp;</p>\n<p>Also, this is my first post. Is this the sort of thing that goes better in LessWrong or Less Wrong Discussion?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "THrcKicMkpHMbrDBQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 15, "extendedScore": null, "score": 7.01237014929777e-07, "legacy": true, "legacyId": "6745", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 10, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 49, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T08:46:25.853Z", "modifiedAt": null, "url": null, "title": "On Debates with Trolls", "slug": "on-debates-with-trolls", "viewCount": null, "lastCommentedAt": "2017-06-17T04:09:29.756Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "prase", "createdAt": "2009-02-28T10:00:10.260Z", "isAdmin": false, "displayName": "prase"}, "userId": "WAP32wvmNt9QdutSu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ZxdK6rTf3bRbgNy6N/on-debates-with-trolls", "pageUrlRelative": "/posts/ZxdK6rTf3bRbgNy6N/on-debates-with-trolls", "linkUrl": "https://www.lesswrong.com/posts/ZxdK6rTf3bRbgNy6N/on-debates-with-trolls", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20On%20Debates%20with%20Trolls&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOn%20Debates%20with%20Trolls%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxdK6rTf3bRbgNy6N%2Fon-debates-with-trolls%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=On%20Debates%20with%20Trolls%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxdK6rTf3bRbgNy6N%2Fon-debates-with-trolls", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZxdK6rTf3bRbgNy6N%2Fon-debates-with-trolls", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1026, "htmlBody": "<p>One of the best achievements of the LessWrong community is our high standard of discussion. More than anywhere else, people here are actively trying to interpret others charitatively, argue to the point, not use provocative or rude language, apologise for inadvertent offenses while not being overtly prone to take offense themselves, avoid their own biases and fallacies instead seeking them in others, and most importantly, find the truth instead of winning the argument. Maybe the greatest attribute of this approach is its infectivity - I have observed several newcomers to change their discussing habits for better in few weeks. However, not everybody is susceptible to the LW standards and our attitude produces somewhat bizarre results when confronted with genuine trolls.</p>\n<p>Recent posts about epistemology<sup>1</sup> have all generated large number of replies; in fact, the discussions were among the largest in the last few months. People have commented there (yes, I too am guilty) even if it was clear that the author of the posts doesn't actually react to our arguments. After he was rude and had admitted to do it on purpose. After commiting several fallacies, after generating an unreasonable amount of text of mediocre to low quality, after saying that he is neither trying to convince anyone nor he is willing to learn anything nor he aims for agreement. In short, perhaps all symptoms of trolling were present, and still, people were repeatedly patiently explaining what's wrong with the author's position. Which reaction is, I must admit, sort of amazing - but on the other hand, it is hard to deny that the whole discussion was detrimental to the quality of LW content and was mostly a waste of time.</p>\n<p>So, here is the question: why didn't we apply the <em>don't feed the troll</em> meme, as would probably happen much sooner on most forums? I have several hypotheses on that.</p>\n<p><em>1. We are unable to recognise trolls for lack of training.</em> The first hypothesis is quite improbable, given that the concerned troll was downvoted to oblivion<sup>2</sup>, but still possible. There are not many trolls on LW and perhaps it is difficult to believe that someone is actively seeking that sort of confrontation. I have never understood the psychology of trolls - I try to avoid combative arguments instinctively and find it hard to imagine why somebody would intentionally try to create one. Perhaps a manifestation of the <a href=\"http://wiki.lesswrong.com/wiki/Typical_mind_fallacy\">typical mind fallacy</a> combines with <a href=\"http://wiki.lesswrong.com/wiki/Compartmentalization\">compartmentalisation</a> here: although we consciously know that there are trolls out there (as this is hard to ignore), when meeting one our instict tells us that the person cannot be so much different from us.</p>\n<p><em>2. We are unwilling to deal with trolls.</em> The second theory is that although we know that a person isn't sincere, we cherish our standards of discussion so strongly that we still try to respond kindly and maintain a civil debate, or at least one side of the debate. If it is the case, it is not automatically a bad policy. Our rationality is limited and we always operate under the threat of self-serving biases. Some quasi-deontological rule of kindness in debates, even if it is an overkill, may be useful in the same way presumption of innocence is useful in justice.</p>\n<p><em>3. Sunken costs.</em> Once the debate has started, our initial investments feel binding. It is unsettling to quit an argument admitting that it was completely useless and we have lost an hour of our life for nothing. Sunken costs fallacy is well known and widespread, there is no reason to expect we are immune.</p>\n<p><em>4. Best rebuttal contest.</em> An interesting fact is that not only the number of replies was fairly large, but also lot of replies were strongly upvoted. It leads me to suspect that those replies weren't in fact aimed at the opponent in the discussion, but rather intended to impress the fellow LessWrongers. Once the motivation is not \"I want to convince my interlocutor\" but rather \"I can craft an extraordinarily elegant counter-argument which until now didn't appear\", the attitude of the opponent doesn't matter. The debate becomes an exercise in arguing, a potentially useful practice maybe, but with many associated dangers.</p>\n<p><em>5. Trollish arguments are fun.</em> I include this possibility mainly for completeness since I don't much believe that significant number of LW users enjoy pointless arguments. But still, there is something <em>fascinating</em> in fallacious arguments. They are frustrating to follow, for sure, especially for a rationalist, but I cannot entirely leave out of consideration the appeal of seeing biases and fallacies in real life, as opposed to mere reading about them in a Kahneman and Tversky paper.</p>\n<p>Whatever of the above hypotheses is correct, or even if none of them is correct, I don't doubt that on reflection most of us would prefer to have less irrational discussions. The karma system works somehow, but slowly, and cannot prevent the trollish discussions from gaining momentum if people continue in their present voting patterns. One of the problems lies in upvoting the rebuttals which gives additional motivation for people to participate. There seem to be two main strategies of voting: \"I want to see more/less of this\" and \"this deserves more/less karma than it presently has\". The first strategy seems marginally better for dealing with trolls, but both strategies should work better when applied <em>in context</em>. Even a brilliant reply should not be upvoted when placed in an irrational debate: first, it is mostly wasting of resources, and more, we certainly want to see less irrational debates. I don't endorse downvoting good replies, if only because the troll could interpret it as support for his cause. But leaving them on zero seems to be a correct policy.</p>\n<p>&nbsp;</p>\n<hr />\n<p><sup>1</sup> I am not going to link to them because I don't want to generate more traffic there; one of those posts figures already on the 4th place when you Google <em>lesswrong epistemology</em>. Neither I write down the precise topic or the name of the author explicitly, which I hope decreases the probability of his appearing here.</p>\n<p><sup>2</sup> In fact, the downvoting, even if massive, came relatively late, with the person in question being able to post on the main site after several days.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"izp6eeJJEg9v5zcur": 1, "MXcpQvaPGtXpB6vkM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ZxdK6rTf3bRbgNy6N", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 27, "baseScore": 31, "extendedScore": null, "score": 7.013502563880997e-07, "legacy": true, "legacyId": "6752", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 22, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 251, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T09:56:12.564Z", "modifiedAt": null, "url": null, "title": "\"Is there a God\" for noobs (followup)", "slug": "is-there-a-god-for-noobs-followup", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:25.208Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "loup-vaillant", "createdAt": "2011-03-23T10:39:25.887Z", "isAdmin": false, "displayName": "loup-vaillant"}, "userId": "wdoZti3BcPbJXsZ66", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/AkGmLnqgC9AHfkvB4/is-there-a-god-for-noobs-followup", "pageUrlRelative": "/posts/AkGmLnqgC9AHfkvB4/is-there-a-god-for-noobs-followup", "linkUrl": "https://www.lesswrong.com/posts/AkGmLnqgC9AHfkvB4/is-there-a-god-for-noobs-followup", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22Is%20there%20a%20God%22%20for%20noobs%20(followup)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22Is%20there%20a%20God%22%20for%20noobs%20(followup)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAkGmLnqgC9AHfkvB4%2Fis-there-a-god-for-noobs-followup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22Is%20there%20a%20God%22%20for%20noobs%20(followup)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAkGmLnqgC9AHfkvB4%2Fis-there-a-god-for-noobs-followup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAkGmLnqgC9AHfkvB4%2Fis-there-a-god-for-noobs-followup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 174, "htmlBody": "<p>After having <a href=\"/r/discussion/lw/4xv/is_there_a_god_for_noobs/\">submitted it here</a>, I <a title=\"Beliefs, Respect, and Facts\" href=\"http://www.loup-vaillant.fr/articles/beliefs-respect-and-facts\">published my essay</a> on my web site, then submitted it to reddit (<a href=\"http://www.reddit.com/r/religion/comments/gmsry/belief_respect_and_facts/\">on r/religion</a> and <a href=\"http://www.reddit.com/r/atheism/comments/gmt1h/belief_respect_and_facts/\">on r/atheism</a> respectively). While I was very pleased by Less Wrong (your feedback were quite informative), reddit was quite&hellip; disappointing.</p>\n<ul>\n<li>\n<p>On <a href=\"http://www.reddit.com/r/atheism/\">r/atheism</a>, my essay was ignored into oblivion in less than an hour. I guess there's just too much activity there, and I got lost in the flood. There's <a href=\"http://www.reddit.com/r/atheism/comments/gmt1h/belief_respect_and_facts/c1opwyd\">one comment</a> though, which lead me to seriously question my use of the word \"universal\". I feel that \"truth is universal\", though accurate, doesn't sound obvious enough. And I'd like to avoid <a title=\"The simple truth\" href=\"http://yudkowsky.net/rational/the-simple-truth\">this heavy dependency</a>.</p>\n</li>\n<li>\n<p>On <a href=\"http://www.reddit.com/r/religion/\">r/religion</a>, my essay is still in the front page. There are a few votes (5 ups besides my own, and 2 or 3 downs). No comments at all. I guess there's too little activity here.</p>\n</li>\n</ul>\n<p>Overall, I'm now confident this essay is now good enough for my family to read.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "AkGmLnqgC9AHfkvB4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 5, "extendedScore": null, "score": 7.01369825130432e-07, "legacy": true, "legacyId": "6754", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["9pgTYotjWhmAqoCyc"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T13:12:05.935Z", "modifiedAt": null, "url": null, "title": "NEW TIME: Sydney Less Wrong meetup, 23/4, 3PM", "slug": "new-time-sydney-less-wrong-meetup-23-4-3pm", "viewCount": null, "lastCommentedAt": "2017-06-17T04:13:58.446Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "meta_ark", "createdAt": "2010-04-19T06:37:46.947Z", "isAdmin": false, "displayName": "meta_ark"}, "userId": "MwEhbZkqEFKfMLnDd", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/fJ8q5PyANCAWPTkaq/new-time-sydney-less-wrong-meetup-23-4-3pm", "pageUrlRelative": "/posts/fJ8q5PyANCAWPTkaq/new-time-sydney-less-wrong-meetup-23-4-3pm", "linkUrl": "https://www.lesswrong.com/posts/fJ8q5PyANCAWPTkaq/new-time-sydney-less-wrong-meetup-23-4-3pm", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20NEW%20TIME%3A%20Sydney%20Less%20Wrong%20meetup%2C%2023%2F4%2C%203PM&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANEW%20TIME%3A%20Sydney%20Less%20Wrong%20meetup%2C%2023%2F4%2C%203PM%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJ8q5PyANCAWPTkaq%2Fnew-time-sydney-less-wrong-meetup-23-4-3pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=NEW%20TIME%3A%20Sydney%20Less%20Wrong%20meetup%2C%2023%2F4%2C%203PM%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJ8q5PyANCAWPTkaq%2Fnew-time-sydney-less-wrong-meetup-23-4-3pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FfJ8q5PyANCAWPTkaq%2Fnew-time-sydney-less-wrong-meetup-23-4-3pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 97, "htmlBody": "<p><a id=\"more\"></a>Hi everyone! There was an attempt for a Sydney (Australia) Less Wrong meetup a while ago, which failed, which was sad. So I'm starting a new one!</p>\n<p>I'll definitely be at the meetup for three hours, regardless of who else is able to make it. So this is definitely going ahead, no matter what.</p>\n<p><strong>Place: </strong>James Squire Bar&nbsp;(22 The Promenade, King Street Wharf)</p>\n<p><strong>Date: </strong>Saturday, 23rd of April</p>\n<p><strong>Time: </strong>3PM - 6PM (note new time)</p>\n<p>I'll have a Less Wrong sign on the table and will probably be working on a uni assignment or reading Godel, Escher, Bach.</p>\n<p>Hope to see you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "fJ8q5PyANCAWPTkaq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 10, "extendedScore": null, "score": 7.014247657424302e-07, "legacy": true, "legacyId": "6755", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T16:55:22.827Z", "modifiedAt": null, "url": null, "title": "The Singularity as Religion (yes/no links)", "slug": "the-singularity-as-religion-yes-no-links", "viewCount": null, "lastCommentedAt": "2017-06-17T04:11:57.110Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4T69myHErLYbwKWJ8/the-singularity-as-religion-yes-no-links", "pageUrlRelative": "/posts/4T69myHErLYbwKWJ8/the-singularity-as-religion-yes-no-links", "linkUrl": "https://www.lesswrong.com/posts/4T69myHErLYbwKWJ8/the-singularity-as-religion-yes-no-links", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Singularity%20as%20Religion%20(yes%2Fno%20links)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Singularity%20as%20Religion%20(yes%2Fno%20links)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4T69myHErLYbwKWJ8%2Fthe-singularity-as-religion-yes-no-links%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Singularity%20as%20Religion%20(yes%2Fno%20links)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4T69myHErLYbwKWJ8%2Fthe-singularity-as-religion-yes-no-links", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4T69myHErLYbwKWJ8%2Fthe-singularity-as-religion-yes-no-links", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 70, "htmlBody": "<p>\n<ul>\n<li><a href=\"http://www.religiondispatches.org/archive/culture/4456/the_cult_of_kurzweil%3A_will_robots_save_our_souls/\">The Cult of Kurzweil</a></li>\n<li><a href=\"http://camelswithhammers.com/2011/04/11/the-singularity-as-religion/\">The Singularity as Religion</a></li>\n<li><a href=\"http://www.acceleratingfuture.com/steven/?p=21\">Rapture of the Nerds, Not</a></li>\n</ul>\n<div>My own opinion is that it's not worth much to argue over the boundaries around a vague term like 'religion,' and of course the question should not be 'Does the Singularity hypothesis share some features with religious hypotheses' but instead 'Is the Singularity hypothesis plausible, and what are its likely consequences?'</div>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4T69myHErLYbwKWJ8", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 15, "extendedScore": null, "score": 7.014873982088631e-07, "legacy": true, "legacyId": "6757", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 88, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T17:04:58.460Z", "modifiedAt": null, "url": null, "title": "Language, intelligence, rationality", "slug": "language-intelligence-rationality", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.996Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ccryPbdxLJ9vu4xP5/language-intelligence-rationality", "pageUrlRelative": "/posts/ccryPbdxLJ9vu4xP5/language-intelligence-rationality", "linkUrl": "https://www.lesswrong.com/posts/ccryPbdxLJ9vu4xP5/language-intelligence-rationality", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Language%2C%20intelligence%2C%20rationality&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALanguage%2C%20intelligence%2C%20rationality%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FccryPbdxLJ9vu4xP5%2Flanguage-intelligence-rationality%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Language%2C%20intelligence%2C%20rationality%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FccryPbdxLJ9vu4xP5%2Flanguage-intelligence-rationality", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FccryPbdxLJ9vu4xP5%2Flanguage-intelligence-rationality", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 123, "htmlBody": "<p>Rationality requires intelligence, and the kind of intelligence that we use (for communication, progress, FAI, etc.) runs on language.</p>\n<p>It seems that the place we should start is optimizing language for intelligence and rationality. One of SIAI's <a href=\"http://intelligence.org/research/researchareas\">proposals</a>&nbsp;includes using <a href=\"http://www.lojban.org/tiki/la+lojban.+mo\">Lojban</a>&nbsp;to interface between humans and an FAI. And of course, I should hope the programming language used to build a FAI would be \"rational\". But it would seem to me that the human-generated priors, correct epistemic rationality, decision theory, metaethics, etc. all depend on using a language that sufficiently rigorously maps to our territory.</p>\n<p>Are \"naturally evolved\" languages such as English sufficient, with EY-style taboos and neologisms? Or are they sick to the core?</p>\n<p>Please forgive and point me towards previous discussion or sequences about this topic.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ccryPbdxLJ9vu4xP5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 4, "extendedScore": null, "score": 7.014900895872007e-07, "legacy": true, "legacyId": "6758", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 57, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T18:34:40.515Z", "modifiedAt": null, "url": null, "title": "Meta: Meetup Section of the Site", "slug": "meta-meetup-section-of-the-site", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.519Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spencer_Sleep", "createdAt": "2011-02-11T08:03:53.049Z", "isAdmin": false, "displayName": "Spencer_Sleep"}, "userId": "xAjAXuvj2czWZix2v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eEHaBBspvgE33kwot/meta-meetup-section-of-the-site", "pageUrlRelative": "/posts/eEHaBBspvgE33kwot/meta-meetup-section-of-the-site", "linkUrl": "https://www.lesswrong.com/posts/eEHaBBspvgE33kwot/meta-meetup-section-of-the-site", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meta%3A%20Meetup%20Section%20of%20the%20Site&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeta%3A%20Meetup%20Section%20of%20the%20Site%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeEHaBBspvgE33kwot%2Fmeta-meetup-section-of-the-site%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meta%3A%20Meetup%20Section%20of%20the%20Site%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeEHaBBspvgE33kwot%2Fmeta-meetup-section-of-the-site", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeEHaBBspvgE33kwot%2Fmeta-meetup-section-of-the-site", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 411, "htmlBody": "<p>Recently there has been an explosion in the number of posts about meetups. I think this is a great thing, as it seems to me like one of the best uses of this site would be to facilitate the formation of rationality groups. &nbsp;The problem with this is that they're starting to take over the main page, to the extent that currently upon going to the main page&nbsp;they are all one sees without scrolling down.</p>\n<p>To solve this (perhaps trivial) problem, and more importantly to make the posts themselves more effective, I propose the creation of a section of this site devoted to the creation of and discussion about meetups/meetup groups. &nbsp;I realize the wiki catalogue of groups exists, but I have 2 problems with it. First of all, it is fairly out of the way. &nbsp;Fewer people use the wiki than the main site, and not everyone who uses the wiki reads all the links on the right side. I know I don't. &nbsp;I only found the meetup page because I am one of the organizers of the Toronto group, and I did a Google search of lesswrong looking for posts about meetups. Secondly, the wiki format (compared to the blog post format) is far less conducive to discussion, and gives no priority to newer posts, something we would want for a meetup section to make it easier to start a group. &nbsp;It also gives no way for people to indicate if they are going to be attending a meeting, something that is useful if the venue requires a reservation.</p>\n<p>As an organizer, I want to posting on the main page about each meetup, so that we keep getting new members. That being said, I don't want to clog up the main part of the site with posts that only apply to 10 people, most of whom already know everything the post is going to say. &nbsp;The only compromise I can think of is a section of the site devoted to meetups. &nbsp;I am by no means a website designer, so I don't know if this is the best solution or if there is something simpler and more&nbsp;efficient&nbsp;I am overlooking.&nbsp;</p>\n<p>This post is aimed mainly at the moderators, as they are the ones who would have to implement anything we come up with, but input from everyone is appreciated. &nbsp;Let me know if you think this is the best idea since sliced bread, or if (far more likely) you think it's highly unnecessary.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eEHaBBspvgE33kwot", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 6, "extendedScore": null, "score": 7.01515254449516e-07, "legacy": true, "legacyId": "6759", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T20:43:18.571Z", "modifiedAt": null, "url": null, "title": "Toronto Meetup", "slug": "toronto-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spencer_Sleep", "createdAt": "2011-02-11T08:03:53.049Z", "isAdmin": false, "displayName": "Spencer_Sleep"}, "userId": "xAjAXuvj2czWZix2v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/W5ABpERKGKWxPPNPy/toronto-meetup", "pageUrlRelative": "/posts/W5ABpERKGKWxPPNPy/toronto-meetup", "linkUrl": "https://www.lesswrong.com/posts/W5ABpERKGKWxPPNPy/toronto-meetup", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toronto%20Meetup&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToronto%20Meetup%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW5ABpERKGKWxPPNPy%2Ftoronto-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toronto%20Meetup%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW5ABpERKGKWxPPNPy%2Ftoronto-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FW5ABpERKGKWxPPNPy%2Ftoronto-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": null, "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "W5ABpERKGKWxPPNPy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 1, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6760", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": null, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T21:16:05.906Z", "modifiedAt": null, "url": null, "title": "Toronto Meetup, Apr 14 8pm", "slug": "toronto-meetup-apr-14-8pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.975Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Spencer_Sleep", "createdAt": "2011-02-11T08:03:53.049Z", "isAdmin": false, "displayName": "Spencer_Sleep"}, "userId": "xAjAXuvj2czWZix2v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4snu962eB34RygrPK/toronto-meetup-apr-14-8pm", "pageUrlRelative": "/posts/4snu962eB34RygrPK/toronto-meetup-apr-14-8pm", "linkUrl": "https://www.lesswrong.com/posts/4snu962eB34RygrPK/toronto-meetup-apr-14-8pm", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Toronto%20Meetup%2C%20Apr%2014%208pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AToronto%20Meetup%2C%20Apr%2014%208pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4snu962eB34RygrPK%2Ftoronto-meetup-apr-14-8pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Toronto%20Meetup%2C%20Apr%2014%208pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4snu962eB34RygrPK%2Ftoronto-meetup-apr-14-8pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4snu962eB34RygrPK%2Ftoronto-meetup-apr-14-8pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 210, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong style=\"font-weight: bold;\"><a id=\"more\"></a>When</strong>: &nbsp;Thursday, April 14th, 20:00</span></p>\n<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"><strong style=\"font-weight: bold;\">Where</strong>: The Bedford Academy, 36 Prince Arthur Avenue</span></p>\n<p>&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Hi everyone,</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px; font-family: Arial, Helvetica, sans-serif; line-height: 19px;\">Same plan as the last meetup. &nbsp;The reservation is under my name (Spencer Sleep) this time, as last time they put the name down as \"Less Wrong\" (first name and surname) and got angry at me when they found out that wasn't a real person (even though I told them it was a discussion group when making the reservation). &nbsp;We will hopefully be upstairs, as that was a nice quiet place last time, but there is a party of 100 people up there from 16:00 until an unspecified time, so our reservation is for \"the quietest area of the bar\".&nbsp;</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\"><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19px;\">We may do some rationality games/exercises if people are interested. &nbsp;I will prepare something small (probably along the lines of <a href=\"http://wiki.lesswrong.com/wiki/Paranoid_debating\">paranoid debating</a>) and if it works out well, we can try something more involved in later meetups.</span></span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">As always, newcomers are <em>ex</em><span style=\"font-family: Arial, Helvetica, sans-serif;\"><span style=\"line-height: 19px;\"><em>tremely</em> welcome. &nbsp;All we ask for in someone at our meetups is that they be willing to listen and learn, and we're pretty lax about the former, and have no way of measuring the latter, so please feel free to join us, no matter your age/rationality experience/any other thing that would sway you to not do so.</span></span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">See you there.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4snu962eB34RygrPK", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 5, "extendedScore": null, "score": 7.015605444411616e-07, "legacy": true, "legacyId": "6761", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T21:24:46.417Z", "modifiedAt": null, "url": null, "title": "Is Cryonics Possible for Theists?", "slug": "is-cryonics-possible-for-theists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:39.744Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WtMiCBNcpPr4X8fgQ/is-cryonics-possible-for-theists", "pageUrlRelative": "/posts/WtMiCBNcpPr4X8fgQ/is-cryonics-possible-for-theists", "linkUrl": "https://www.lesswrong.com/posts/WtMiCBNcpPr4X8fgQ/is-cryonics-possible-for-theists", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Is%20Cryonics%20Possible%20for%20Theists%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIs%20Cryonics%20Possible%20for%20Theists%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWtMiCBNcpPr4X8fgQ%2Fis-cryonics-possible-for-theists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Is%20Cryonics%20Possible%20for%20Theists%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWtMiCBNcpPr4X8fgQ%2Fis-cryonics-possible-for-theists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWtMiCBNcpPr4X8fgQ%2Fis-cryonics-possible-for-theists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 334, "htmlBody": "<p>I expect to have a conversation soon with my parents about cryonics. My parents are both professional scientists, but are vaguely religious. They certainly aren't fundamentalists; they are pro-choice, pro-gay rights, think \"intelligent design\" is nuts, etc. My father is less religious than my mother, the best description I can give is probably Deism. Doesn't believe in miracles, prayer, etc, but considers an afterlife likely. My mother is slightly more religious: in the past, she's prayed for help and things have worked out (positive bias). However, even she is far more skeptical than most theists. I remember one conversation as a kid in which she that she thought Jesus' resurrection was a metaphor. One one occasion, when I was in middle school, I asked her why she believed in God, and she replied that it was the only good explanation she could come up with for why there was good and evil in the world. She once quoted John Lennon, I think, talking about God as simply a personification of Good. She also believes in an afterlife.</p>\n<p>Both of them I think would be very reluctant to engage in an open discussion about religion. In addition, both are intelligent enough, and have heard enough arguments, to make it enormously difficult to get them to change their minds, especially since the idea of an afterlife is a comforting thought for their own grandparents.</p>\n<p>I would like to, if possible, avoid the discussion of religion, and instead simply persuade them to sign up for cryonics, without trying to force them to give up their belief in an afterlife. I've spent some time thinking about this, and have come up with some arguments. I do not want my parents to die. If there is any way I can be more persuasive, I have to find it, and I have to try it. So I am appealing to the collective brainstorming power of LW. If there is any argument you can think of that I can use, let me know.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WtMiCBNcpPr4X8fgQ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 10, "baseScore": 12, "extendedScore": null, "score": 7.015629785475188e-07, "legacy": true, "legacyId": "6762", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 31, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-12T21:37:03.402Z", "modifiedAt": null, "url": null, "title": "Philip Zimbardo (Stanford Prison Experiment) answers questions on Reddit (Link)", "slug": "philip-zimbardo-stanford-prison-experiment-answers-questions", "viewCount": null, "lastCommentedAt": "2017-06-17T04:07:00.945Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "dKh37HuFy8kYSBodm", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/DyceqdJY9vArTtARr/philip-zimbardo-stanford-prison-experiment-answers-questions", "pageUrlRelative": "/posts/DyceqdJY9vArTtARr/philip-zimbardo-stanford-prison-experiment-answers-questions", "linkUrl": "https://www.lesswrong.com/posts/DyceqdJY9vArTtARr/philip-zimbardo-stanford-prison-experiment-answers-questions", "postedAtFormatted": "Tuesday, April 12th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Philip%20Zimbardo%20(Stanford%20Prison%20Experiment)%20answers%20questions%20on%20Reddit%20(Link)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APhilip%20Zimbardo%20(Stanford%20Prison%20Experiment)%20answers%20questions%20on%20Reddit%20(Link)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDyceqdJY9vArTtARr%2Fphilip-zimbardo-stanford-prison-experiment-answers-questions%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Philip%20Zimbardo%20(Stanford%20Prison%20Experiment)%20answers%20questions%20on%20Reddit%20(Link)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDyceqdJY9vArTtARr%2Fphilip-zimbardo-stanford-prison-experiment-answers-questions", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FDyceqdJY9vArTtARr%2Fphilip-zimbardo-stanford-prison-experiment-answers-questions", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 132, "htmlBody": "<p>In March, a user on Reddit emailed psychologist <a href=\"http://en.wikipedia.org/wiki/Philip_Zimbardo\">Philip Zimbardo</a> (leader of the <a href=\"http://en.wikipedia.org/wiki/Stanford_prison_experiment\">Stanford Prison Experiment</a>) to arrange an \"IAmA\" interview. Zimbardo agreed to answer the top 5 questions from <a href=\"http://www.reddit.com/r/IAmA/comments/fuhkk/request_update_philip_zimbardo_of_stanford/\">this thread</a>. Yesterday his answers were posted <a href=\"http://www.reddit.com/r/IAmA/comments/gnshs/per_request_philip_zimbardo_stanford_prison/\">here</a>.</p>\n<p>The chosen questions touched on research ethics, what he originally expected to learn from the experiment, the role of psychoactive drugs in society, reading recommendations and more.</p>\n<p>After responding, Zimbardo posed a question of his own to Reddit:</p>\n<blockquote>\n<p>I ask you: Is it good that the Milgram and Zimbardo studies were  done, or wrong? Should they be allowed to be replicated with  interesting variations (such as female guards and prisoners) if  institutional guidelines are imposed and followed? Or is it better for  society not to know about the nature of the \"dark side\" of human nature?</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "DyceqdJY9vArTtARr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.015664250023185e-07, "legacy": true, "legacyId": "6763", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 14, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T02:12:55.140Z", "modifiedAt": null, "url": null, "title": "Occam's Razor, Complexity of Verbal Descriptions, and Core Concepts", "slug": "occam-s-razor-complexity-of-verbal-descriptions-and-core", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.279Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TCB", "createdAt": "2011-04-08T14:26:43.879Z", "isAdmin": false, "displayName": "TCB"}, "userId": "jnkMgqqpeSTyCAj92", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cdARDojcT8uj2sfef/occam-s-razor-complexity-of-verbal-descriptions-and-core", "pageUrlRelative": "/posts/cdARDojcT8uj2sfef/occam-s-razor-complexity-of-verbal-descriptions-and-core", "linkUrl": "https://www.lesswrong.com/posts/cdARDojcT8uj2sfef/occam-s-razor-complexity-of-verbal-descriptions-and-core", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Occam's%20Razor%2C%20Complexity%20of%20Verbal%20Descriptions%2C%20and%20Core%20Concepts&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOccam's%20Razor%2C%20Complexity%20of%20Verbal%20Descriptions%2C%20and%20Core%20Concepts%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcdARDojcT8uj2sfef%2Foccam-s-razor-complexity-of-verbal-descriptions-and-core%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Occam's%20Razor%2C%20Complexity%20of%20Verbal%20Descriptions%2C%20and%20Core%20Concepts%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcdARDojcT8uj2sfef%2Foccam-s-razor-complexity-of-verbal-descriptions-and-core", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcdARDojcT8uj2sfef%2Foccam-s-razor-complexity-of-verbal-descriptions-and-core", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 907, "htmlBody": "<p>Occam's razor, as it is popularly known, states that \"the simplest answer is most likely to be correct\"<sup>1</sup>.&nbsp; It has been noted in other discussion threads that the phrase \"simplest description\" is somewhat misleading, and that it actually means something along the lines of \"description that is easiest to express concisely using natural language\".&nbsp; Occam's razor typically comes into play when we are trying to explain some observed phenomenon, or, in terms of model-building, when we are trying to come up with a model for our observations.&nbsp; The verbal complexity of a new model will depend on the models that already exist in the observer's mind, since, as humans, we express new ideas in terms of concepts with which we are already familiar.</p>\n<p>Thus, when applied to natural language, Occam's razor encourages descriptions that are most in line with the observer's existing worldview, and discourages descriptions that seem implausible given the observer's current worldview<sup></sup>.&nbsp; Since our worldviews are typically very accurate<sup>2</sup>, this makes sense as a heuristic.</p>\n<p>As an example, if a ship sank in the ocean, a simple explanation would be \"a storm destroyed it\", and a complicated explanation would be \"a green scaly sea-dragon with three horns destroyed it\".&nbsp; The first description is simple because we frequently experience storms, and so we have a word for them, whereas most of us never experience green scaly sea-dragons with three horns, and so we have to describe them explicitly.&nbsp; If the opposite were the case, we'd have some word for the dragons (maybe they'd be called \"blicks\"), and we would have to describe storms explicitly.&nbsp; Then the descriptions above could be reworded as \"rain falling from the sky, accompanied by strong gusts of wind and possibly gigantic electrical discharges, destroyed the ship\" and \"a blick destroyed the ship\", respectively.</p>\n<p>What I'm getting at is that different explanations will have different complexities for different people; the complexity of a description to a person will depend on that person's collection of life-experiences, and everyone has a different set of life-experiences.&nbsp; This leads to an interesting question: are there universally easy-to-describe concepts?&nbsp; (By universally I mean cross-culturally.)&nbsp; It seems reasonable to claim that a concept C is easy-to-describe for a culture if that culture's language contains a word that means C; it should be a fairly common word and everyone in the culture should know what it means.</p>\n<p>So are there concepts that every language has a word for?&nbsp; Apparently, yes.&nbsp; In fact, the linguist Morris Swadesh came up with exactly such a <a href=\"http://en.wikipedia.org/wiki/Swadesh_list\">list</a> of core vocabulary terms.&nbsp; Unsurprisingly from an information theoretic perspective, the English versions of the words on this list are extremely short: most are one syllable, and the consonant clusters are small.</p>\n<p>Presumably, if you wanted to communicate an idea to someone from a very different culture, and you could express that idea in terms of the core concepts, then you could explain your idea to that person.&nbsp; (Such an expression would likely require symbolism/metaphor/simile, but these are valid ways of expressing ideas.)&nbsp; Alternatively, imagine trying to explain a complicated idea to a small child; this would probably involve expressing the concept in terms of more concrete, fundamental ideas and objects.</p>\n<p>Where does this core vocabulary come from?&nbsp; Is it just that these are the only concepts that basically all humans will be familiar with?&nbsp; Or is there a deeper explanation, like an a priori encoding of these concepts in our brains?</p>\n<p>I bring all of this up because it is relevant to the question of whether we could communicate with an artificial intelligence if we built one, and whether this AI would understand the world similarly to how we do (I consider the latter a prerequisite for the former).&nbsp; Presumably an AI would reason about and attempt to model its environment, and presumably it would prefer models with simpler descriptions, if only because such models would be more computationally efficient to reason with.&nbsp; But an AI might have a different definition of \"simple description\" than we do as humans, and therefore it might come up with very different explanations and understandings of the world, or at the very least a different hierarchy of concepts.&nbsp; This would make communication between humans and AIs difficult.</p>\n<p>If we encoded the core vocabulary a priori in the AI's mind as some kind of basis of atomic concepts, would the AI develop an understanding of the world that was more in line with ours than it would if we didn't?&nbsp; And would this make it easier for us to communicate intellectually with the AI?</p>\n<p>&nbsp;</p>\n<p><sup>1</sup>&nbsp; Note that Occam's razor does not say that the simplest answer is actually correct; it just gives us a distribution over models.&nbsp; If we want to build a model, we'll be considering <em>p(model|data)</em>, which by Bayes' rule is equal to <em>p(data|model)p(model)/p(data)</em>.&nbsp; Occam's razor is one way of specifying <em>p(model)</em>.&nbsp; Apologies if this footnote is obvious, but I see this misinterpretation all over the place on the internet.</p>\n<p><sup>2</sup>&nbsp; This may seem like a bold statement, but I'm talking about in terms of every-day life sort of things.&nbsp; If you blindfolded me and put me in front of a random tree during summer, in my general geographic region, and asked me what it looked like, I could give you a description of that tree and it would probably be very similar to the actual thing.&nbsp; This is because my worldview about trees is very accurate, i.e. my internal model of trees has very good predictive power.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cdARDojcT8uj2sfef", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 11, "baseScore": 8, "extendedScore": null, "score": 7.01643835949354e-07, "legacy": true, "legacyId": "6764", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T02:32:10.550Z", "modifiedAt": null, "url": null, "title": "Best videos inspiring first interest in rationality or the singularity", "slug": "best-videos-inspiring-first-interest-in-rationality-or-the", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:28.926Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Academian", "createdAt": "2010-03-08T09:49:25.099Z", "isAdmin": false, "displayName": "Academian"}, "userId": "AbLN9sR8PDACCXKp7", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qnLiQ3i3opNGDZ9Nr/best-videos-inspiring-first-interest-in-rationality-or-the", "pageUrlRelative": "/posts/qnLiQ3i3opNGDZ9Nr/best-videos-inspiring-first-interest-in-rationality-or-the", "linkUrl": "https://www.lesswrong.com/posts/qnLiQ3i3opNGDZ9Nr/best-videos-inspiring-first-interest-in-rationality-or-the", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Best%20videos%20inspiring%20first%20interest%20in%20rationality%20or%20the%20singularity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABest%20videos%20inspiring%20first%20interest%20in%20rationality%20or%20the%20singularity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqnLiQ3i3opNGDZ9Nr%2Fbest-videos-inspiring-first-interest-in-rationality-or-the%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Best%20videos%20inspiring%20first%20interest%20in%20rationality%20or%20the%20singularity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqnLiQ3i3opNGDZ9Nr%2Fbest-videos-inspiring-first-interest-in-rationality-or-the", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqnLiQ3i3opNGDZ9Nr%2Fbest-videos-inspiring-first-interest-in-rationality-or-the", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 524, "htmlBody": "<!-- Best videos inspiring first interest in rationality or the singularity -->\n<p>When faced with a decision that might be <em>really important</em> &mdash; if say, the life of a loved one may be at risk &mdash; many people, though unfortunately not all, are moved to a sense of responsibility whereby they suddenly care more about <em>being right</em> than about <em>looking right</em>, <em>feeling right</em>, or even <em>feeling good</em>. It's when we have <a href=\"/lw/nb/something_to_protect/\">something to protect</a> that many of us are most motivated to transcend our usual desires to \"win the debate\", \"uphold our beliefs\", or \"have faith\", and instead actually try to <em>become right</em> ... to have the best shot we can at saving the day with the decisions we make.</p>\n<p>The upcoming technological singularity &mdash; an event where the lives of <em>all</em> our loved ones may or may not hang in the balance &mdash; is for many people a great inspiration to become more rational. Also, most of us want to convince others to be more rational, and videos are a powerful way to reach people, so I want to know:</p>\n<p><strong>What do you think is the online video that best inspires a <em>strong initial interest</em> in rationality or the singularity?</strong></p>\n<p><strong>Please upvote each comment</strong> that contains a video that you <strong>approve for this purpose</strong>, not just your favorite; I want to use <a href=\"http://en.wikipedia.org/wiki/Approval_voting\">approval voting</a> here so we get a robust ordering on the videos. Also to this end, please post at most <strong>one video per comment</strong>.</p>\n<p>If you don't already have a favorite but want one, a place to start looking is the <a href=\"http://vimeo.com/siai/videos/sort:oldest/format:detail\">Singularity Summit videos at vimeo.com</a>. Vimeo allows you to like/dislike videos, so that's another way you can donate information.</p>\n<p>Some things to consider when voting:</p>\n<ul>\n<li><strong>Public appeal</strong> --- is this a video you'd want sent out on a mailing list to a bunch of <em>random but educated people?</em> (We want people in positions of intellectual or political influence to promote rationality.) </li>\n<li><strong>First exposure</strong> --- if this is someone's first exposure to thinking about rationality or the singularity, will it keep their interest? </li>\n<li><strong>Video quality</strong> --- is the camerawork respectable, or does it make people want to stop watching? </li>\n<li><strong>Speaker personality</strong> --- will people be annoyed at the speaker and lose attention, or be inspired? </li>\n<li><strong>OMG factor</strong> --- does the video have enough punchlines that make people say \"oh my gosh I want to be more rational\"? </li>\n</ul>\n<p>I will periodically update this post with a list of links and their ratings, so we all have an easily accessible source of high-quality presentations we can send to our friends and colleauges to inspire rationality :)</p>\n<hr />\n<p>List of videos; last updated April 17, 2011.</p>\n<ol>\n<li>(11 points since April 13, 2011; <a href=\"/lw/57x/best_videos_inspiring_first_interest_in/3x42\">vote here</a>) <a href=\"http://www.youtube.com/watch?v=T69TOuqaqXI\">Open-Mindedness, by QualiaSoup.</a> &nbsp;</li>\n<li>(3 points since April 14, 2011; <a href=\"/lw/57x/best_videos_inspiring_first_interest_in/3xgv\">vote here</a>) <a href=\"https://www.youtube.com/watch?v=ymafX3V2CGk\">What is the Singularity?</a> &nbsp;</li>\n<li>(3 points since April 13, 2011; <a href=\"/lw/57x/best_videos_inspiring_first_interest_in/3xct\">vote here</a>) <a href=\"http://www.youtube.com/watch?v=jyjNXdEGjO4\">Why didn't anybody tell me?</a> &nbsp;</li>\n<li>(2 points since April 13, 2011; <a href=\"/lw/57x/best_videos_inspiring_first_interest_in/3x60\">vote here</a>) <a href=\"http://www.youtube.com/watch?v=BIT3TYnQJQc&amp;feature=youtu.be&amp;hd=1\">Reaching the stars is easy...</a> &nbsp;</li>\n<li>(2 points since April 13, 2011; <a href=\"/lw/57x/best_videos_inspiring_first_interest_in/3x7u\">vote here</a>) <a href=\"http://www.youtube.com/watch?v=hVimVzgtD6w\">Hans Rosling: No more boring data: TEDTalks</a> &nbsp;</li>\n<li>(1 points since April 15, 2011; <a href=\"/lw/57x/best_videos_inspiring_first_interest_in/3xus\">vote here</a>) <a href=\"http://www.youtube.com/watch?v=iloTS0wU9qM&amp;feature=youtu.be\">What is \"rationality\"?</a> <!-- <br>&nbsp;<br>\n<li>( points since ; <a href=\"\">vote here</a>)<a href=\"\"></a> --> </li>\n</ol>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qnLiQ3i3opNGDZ9Nr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 6, "extendedScore": null, "score": 7.016492402455743e-07, "legacy": true, "legacyId": "6765", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 25, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SGR4GxFK7KmW7ckCB"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T06:43:59.373Z", "modifiedAt": null, "url": null, "title": "When is it ever rational to enter a sweepstakes where you may have a 1/10,000 chance of winning?", "slug": "when-is-it-ever-rational-to-enter-a-sweepstakes-where-you", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.909Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "InquilineKea", "createdAt": "2009-04-05T01:28:23.707Z", "isAdmin": false, "displayName": "InquilineKea"}, "userId": "5EqbEvWexa5jGAs3G", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/4AX48ZdLtegfMDxaq/when-is-it-ever-rational-to-enter-a-sweepstakes-where-you", "pageUrlRelative": "/posts/4AX48ZdLtegfMDxaq/when-is-it-ever-rational-to-enter-a-sweepstakes-where-you", "linkUrl": "https://www.lesswrong.com/posts/4AX48ZdLtegfMDxaq/when-is-it-ever-rational-to-enter-a-sweepstakes-where-you", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20When%20is%20it%20ever%20rational%20to%20enter%20a%20sweepstakes%20where%20you%20may%20have%20a%201%2F10%2C000%20chance%20of%20winning%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AWhen%20is%20it%20ever%20rational%20to%20enter%20a%20sweepstakes%20where%20you%20may%20have%20a%201%2F10%2C000%20chance%20of%20winning%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4AX48ZdLtegfMDxaq%2Fwhen-is-it-ever-rational-to-enter-a-sweepstakes-where-you%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=When%20is%20it%20ever%20rational%20to%20enter%20a%20sweepstakes%20where%20you%20may%20have%20a%201%2F10%2C000%20chance%20of%20winning%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4AX48ZdLtegfMDxaq%2Fwhen-is-it-ever-rational-to-enter-a-sweepstakes-where-you", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F4AX48ZdLtegfMDxaq%2Fwhen-is-it-ever-rational-to-enter-a-sweepstakes-where-you", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 136, "htmlBody": "<div>It may be free to enter the sweepstakes, but it costs time to enter the sweepstakes. So the time is the first part of the cost. Then you may also have monitoring costs as well (if you monitor the progress of the sweepstakes, which may also cost valuable time).&nbsp;</div>\n<div>But at the same time, there are other sweepstakes where the time it takes to enter is virtually 0. This could result in additional time costs if it results in increased spam, however (which may not come with most sweepstakes, but which may come with some).&nbsp;</div>\n<div>And, of course, you have to factor in the expected gain if you entered, say, 1000 sweepstakes in your life. Eventually, you get to the point where you may have a decent probability of winning something big by entering so many of them</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "4AX48ZdLtegfMDxaq", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 1, "extendedScore": null, "score": 7.017199169416326e-07, "legacy": true, "legacyId": "6771", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 16, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T08:32:12.059Z", "modifiedAt": null, "url": null, "title": "Melbourne Meetup May 6th, 6pm", "slug": "melbourne-meetup-may-6th-6pm", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:52.320Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Patrick", "createdAt": "2009-02-27T08:09:44.663Z", "isAdmin": false, "displayName": "Patrick"}, "userId": "KC7mjSorWj2XsdL3v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qaLK6bzdDWQMw5LTZ/melbourne-meetup-may-6th-6pm", "pageUrlRelative": "/posts/qaLK6bzdDWQMw5LTZ/melbourne-meetup-may-6th-6pm", "linkUrl": "https://www.lesswrong.com/posts/qaLK6bzdDWQMw5LTZ/melbourne-meetup-may-6th-6pm", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Melbourne%20Meetup%20May%206th%2C%206pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMelbourne%20Meetup%20May%206th%2C%206pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqaLK6bzdDWQMw5LTZ%2Fmelbourne-meetup-may-6th-6pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Melbourne%20Meetup%20May%206th%2C%206pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqaLK6bzdDWQMw5LTZ%2Fmelbourne-meetup-may-6th-6pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqaLK6bzdDWQMw5LTZ%2Fmelbourne-meetup-may-6th-6pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 41, "htmlBody": "<p><strong>Where:</strong> <a href=\"http://maps.google.com/maps?q=55%20Walsh%20St%2C%20West%20Melbourne%2C%20Australia\">55 Walsh St, West Melbourne, Australia</a></p>\n<p><strong>When</strong>: Friday May 6th, 6pm</p>\n<p>We'll be discussing hacks for improving one's intelligence and energy levels (e.g. meditation, nootropics, paleo diet). If you know any tricks, or would like to learn some, come to the meetup!</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qaLK6bzdDWQMw5LTZ", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 4, "extendedScore": null, "score": 7.017502925696611e-07, "legacy": true, "legacyId": "6773", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T12:46:40.017Z", "modifiedAt": null, "url": null, "title": "Eight questions for computationalists", "slug": "eight-questions-for-computationalists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:06:09.907Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dfranke", "createdAt": "2009-02-27T18:51:11.645Z", "isAdmin": false, "displayName": "dfranke"}, "userId": "kqWQye46c5bMBS4RS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/JsWd7jkeYWELtuHZc/eight-questions-for-computationalists", "pageUrlRelative": "/posts/JsWd7jkeYWELtuHZc/eight-questions-for-computationalists", "linkUrl": "https://www.lesswrong.com/posts/JsWd7jkeYWELtuHZc/eight-questions-for-computationalists", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Eight%20questions%20for%20computationalists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEight%20questions%20for%20computationalists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJsWd7jkeYWELtuHZc%2Feight-questions-for-computationalists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Eight%20questions%20for%20computationalists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJsWd7jkeYWELtuHZc%2Feight-questions-for-computationalists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FJsWd7jkeYWELtuHZc%2Feight-questions-for-computationalists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 443, "htmlBody": "<p>&nbsp;</p>\n<p>This post is a followup to \"<a href=\"/lw/57e/we_are_not_living_in_a_simulation/\">We are not living in a simulation</a>\" and intended to help me (and you) better understand the claims of those who took a computationalist position in that thread.&nbsp; The questions below are aimed at you if you think the following statement both a) makes sense, and b) is true:</p>\n<p><strong>\"Consciousness is really just computation\"</strong></p>\n<p>I've made it no secret that I think this statement is hogwash, but I've done my best to make these questions as non-leading as possible: you should be able to answer them without having to dismantle them first. Of course, I could be wrong, and \"the question is confused\" is always a valid answer. So is \"I don't know\".</p>\n<ol>\n<li>As it is used in the sentence \"consciousness is really just computation\", is computation:<br />a) Something that an abstract machine does, as in \"No oracle Turing machine can compute a decision to its own halting problem\"?<br />b) Something that a concrete machine does, as in \"My calculator computed 2+2\"?<br />c) Or, is this distinction nonsensical or irrelevant?</li>\n<li>If you answered \"a\" or \"c\" to question 1: is there any particular model, or particular class of models, of computation, such as Turing machines, register machines, lambda calculus, etc., that needs to be used in order to explain what makes us conscious? Or, is any Turing-equivalent model equally valid?</li>\n<li>If you answered \"b\" or \"c\" to question 1: unpack what \"the machine computed 2+2\" means. What is that saying about the physical state of the machine before, during, and after the computation?</li>\n<li>Are you able to make any sense of the concept of \"computing red\"? If so, what does this mean?</li>\n<li>As far as consciousness goes, what matters in a computation: functions, or algorithms? That is, does any computation that give the same outputs for the same inputs feel the same from the inside (this is the \"functions\" answer), or do the intermediate steps matter (this is the \"algorithms\" answer)?</li>\n<li>Would an <em>axiomatization</em> (as opposed to a complete exposition of the implications of these axioms) of a Theory of Everything that can explain consciousness include definitions of any computational devices, such as \"and gate\"?</li>\n<li>Would an axiomatization of a Theory of Everything that can explain consciousness mention qualia?</li>\n<li>Are all computations in some sense conscious, or only certain kinds?</li>\n</ol>\n<p>ETA: By the way, I probably won't engage right away with individual commenters on this thread except to answer requests for clarification.&nbsp; In a few days I'll write another post analyzing the points that are brought up.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "JsWd7jkeYWELtuHZc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 22, "extendedScore": null, "score": 7.018217319512464e-07, "legacy": true, "legacyId": "6775", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 89, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QnSgnKQvpv74cmgFx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T15:01:04.703Z", "modifiedAt": null, "url": null, "title": "Econtalk with Andresen on BitCoin (some interest here) - link", "slug": "econtalk-with-andresen-on-bitcoin-some-interest-here-link", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.333Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/sDXsDcYnSu27ehKD7/econtalk-with-andresen-on-bitcoin-some-interest-here-link", "pageUrlRelative": "/posts/sDXsDcYnSu27ehKD7/econtalk-with-andresen-on-bitcoin-some-interest-here-link", "linkUrl": "https://www.lesswrong.com/posts/sDXsDcYnSu27ehKD7/econtalk-with-andresen-on-bitcoin-some-interest-here-link", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Econtalk%20with%20Andresen%20on%20BitCoin%20(some%20interest%20here)%20-%20link&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AEcontalk%20with%20Andresen%20on%20BitCoin%20(some%20interest%20here)%20-%20link%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsDXsDcYnSu27ehKD7%2Fecontalk-with-andresen-on-bitcoin-some-interest-here-link%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Econtalk%20with%20Andresen%20on%20BitCoin%20(some%20interest%20here)%20-%20link%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsDXsDcYnSu27ehKD7%2Fecontalk-with-andresen-on-bitcoin-some-interest-here-link", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FsDXsDcYnSu27ehKD7%2Fecontalk-with-andresen-on-bitcoin-some-interest-here-link", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1, "htmlBody": "<p><a href=\"http://www.econtalk.org/archives/2011/04/andresen_on_bit.html\">http://www.econtalk.org/archives/2011/04/andresen_on_bit.html</a></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "sDXsDcYnSu27ehKD7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6776", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T16:17:49.897Z", "modifiedAt": null, "url": null, "title": "Hunger can make you stupid", "slug": "hunger-can-make-you-stupid", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.408Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Tc4Q3ja7YGjeTXbag/hunger-can-make-you-stupid", "pageUrlRelative": "/posts/Tc4Q3ja7YGjeTXbag/hunger-can-make-you-stupid", "linkUrl": "https://www.lesswrong.com/posts/Tc4Q3ja7YGjeTXbag/hunger-can-make-you-stupid", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Hunger%20can%20make%20you%20stupid&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHunger%20can%20make%20you%20stupid%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTc4Q3ja7YGjeTXbag%2Fhunger-can-make-you-stupid%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Hunger%20can%20make%20you%20stupid%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTc4Q3ja7YGjeTXbag%2Fhunger-can-make-you-stupid", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTc4Q3ja7YGjeTXbag%2Fhunger-can-make-you-stupid", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 186, "htmlBody": "<p>When I originally wrote <a href=\"/r/discussion/lw/4le/when_to_scream_error/\">\"When to scream 'Error!'\"</a>, I was mainly thinking of bad patterns of thought or bad problem-solving strategies as being the source of the error. Since then, I've come to realize that my own most common source of stupidity is because I've neglected some comfort. I may be hungry without consciously paying attention to it, dehydrated because I've been living on coffee for too long, or simply have a headache and need to take an Ibuprofen -- as a result, I don't think well, get irritated at the fact that I'm not thinking well, and generally begin a death spiral if I don't realize why.</p>\n<p>In hindsight, it feels obvious that I should take care of the physiological needs that I can because they're likely preventing me from thinking straight. However, I've failed to do this on numerous occasions and so thought it worth mentioning.</p>\n<p>In summary: Whenever you're <a href=\"/r/discussion/lw/4le/when_to_scream_error/\">screaming \"Error\"</a>, I suggest you stop and figure out whether you're hungry, thirsty, tired, or hurting before trying to find a problem in your thinking itself, especially if you're not usually good at noticing such things.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Tc4Q3ja7YGjeTXbag", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 15, "extendedScore": null, "score": 7.018810246024243e-07, "legacy": true, "legacyId": "6777", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 11, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["bWGzEgMw34jHH586F"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T17:09:19.488Z", "modifiedAt": null, "url": null, "title": "Harry Potter and the Methods of Rationality Podcast", "slug": "harry-potter-and-the-methods-of-rationality-podcast", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.692Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rdJPrCyxSNrGPHgoN/harry-potter-and-the-methods-of-rationality-podcast", "pageUrlRelative": "/posts/rdJPrCyxSNrGPHgoN/harry-potter-and-the-methods-of-rationality-podcast", "linkUrl": "https://www.lesswrong.com/posts/rdJPrCyxSNrGPHgoN/harry-potter-and-the-methods-of-rationality-podcast", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20Podcast&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHarry%20Potter%20and%20the%20Methods%20of%20Rationality%20Podcast%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrdJPrCyxSNrGPHgoN%2Fharry-potter-and-the-methods-of-rationality-podcast%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Harry%20Potter%20and%20the%20Methods%20of%20Rationality%20Podcast%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrdJPrCyxSNrGPHgoN%2Fharry-potter-and-the-methods-of-rationality-podcast", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrdJPrCyxSNrGPHgoN%2Fharry-potter-and-the-methods-of-rationality-podcast", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 53, "htmlBody": "<p><span style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; line-height: 14px;\">Have you ever thought &ldquo;I&rsquo;d love to read Harry Potter and the Methods of Rationality, but I just don&rsquo;t have the spare time. I wish it was available in audio format.&rdquo; Fret no more! I present to you the HPMoR Podcast! First chapter out now, and another one added every Wednesday.<br /><a style=\"cursor: pointer; color: #3b5998; text-decoration: underline;\" rel=\"nofollow\" href=\"http://itunes.apple.com/us/podcast/harry-potter-methods-rationality/id431784580\" target=\"_blank\"></a></span></p>\n<p><span style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif; font-size: 11px; line-height: 14px;\"><a style=\"cursor: pointer; color: #3b5998; text-decoration: underline;\" rel=\"nofollow\" href=\"http://itunes.apple.com/us/podcast/harry-potter-methods-rationality/id431784580\" target=\"_blank\"><span>http://itunes.apple.com/us/pod</span><span>cast/harry-potter-methods-rati</span>onality/id431784580</a></span></p>\n<p><span style=\"font-family: 'lucida grande', tahoma, verdana, arial, sans-serif;\"><span style=\"font-size: 11px; line-height: 14px;\"><br /></span></span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"GBpwq8cWvaeRoE9X5": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rdJPrCyxSNrGPHgoN", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 40, "baseScore": 44, "extendedScore": null, "score": 0.000148, "legacy": true, "legacyId": "6778", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 40, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T18:31:25.887Z", "modifiedAt": null, "url": null, "title": "Link: Forbes blog post on Cryonics", "slug": "link-forbes-blog-post-on-cryonics", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lsparrish", "createdAt": "2010-06-30T19:05:11.515Z", "isAdmin": false, "displayName": "lsparrish"}, "userId": "xgc8giekPig6tYf2X", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/kEQF9JbDey2kQa4rz/link-forbes-blog-post-on-cryonics", "pageUrlRelative": "/posts/kEQF9JbDey2kQa4rz/link-forbes-blog-post-on-cryonics", "linkUrl": "https://www.lesswrong.com/posts/kEQF9JbDey2kQa4rz/link-forbes-blog-post-on-cryonics", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Forbes%20blog%20post%20on%20Cryonics&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Forbes%20blog%20post%20on%20Cryonics%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEQF9JbDey2kQa4rz%2Flink-forbes-blog-post-on-cryonics%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Forbes%20blog%20post%20on%20Cryonics%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEQF9JbDey2kQa4rz%2Flink-forbes-blog-post-on-cryonics", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FkEQF9JbDey2kQa4rz%2Flink-forbes-blog-post-on-cryonics", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 22, "htmlBody": "<p>Alex Knapp, who self-describes as a transhumanism skeptic, is blogging on the topic for Forbes. His most <a href=\"http://blogs.forbes.com/alexknapp/2011/04/12/alcors-cryonics-case-descriptions/\">recent article</a> is about Cryonics.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "kEQF9JbDey2kQa4rz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 7, "extendedScore": null, "score": 7.019185424946959e-07, "legacy": true, "legacyId": "6779", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T19:20:55.243Z", "modifiedAt": null, "url": null, "title": "Central Pennsylvania meetup?", "slug": "central-pennsylvania-meetup", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": null, "userId": "oFp6JLn8z9uxgdPp8", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/yh9piZYJoFv97XbYM/central-pennsylvania-meetup", "pageUrlRelative": "/posts/yh9piZYJoFv97XbYM/central-pennsylvania-meetup", "linkUrl": "https://www.lesswrong.com/posts/yh9piZYJoFv97XbYM/central-pennsylvania-meetup", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Central%20Pennsylvania%20meetup%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACentral%20Pennsylvania%20meetup%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyh9piZYJoFv97XbYM%2Fcentral-pennsylvania-meetup%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Central%20Pennsylvania%20meetup%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyh9piZYJoFv97XbYM%2Fcentral-pennsylvania-meetup", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fyh9piZYJoFv97XbYM%2Fcentral-pennsylvania-meetup", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 39, "htmlBody": "<p>I currently live at the Pennsylvania State University, which is located in the relatively small city of <a href=\"http://en.wikipedia.org/wiki/State_College,_Pennsylvania\">State College</a>, PA. Are there any LessWrongers/rationalists in State College or nearby in Centre Country who might be interested in a meetup?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "yh9piZYJoFv97XbYM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 4, "extendedScore": null, "score": 7.019324411103916e-07, "legacy": true, "legacyId": "6780", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T19:45:10.934Z", "modifiedAt": null, "url": null, "title": "How not to be a Na\u00efve Computationalist", "slug": "how-not-to-be-a-naive-computationalist", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:48.695Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "diegocaleiro", "createdAt": "2009-07-27T10:36:18.861Z", "isAdmin": false, "displayName": "diegocaleiro"}, "userId": "6tTwQ8Rdp2uhK5NL3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/HLadQZ6FqTTjnYpoB/how-not-to-be-a-naive-computationalist", "pageUrlRelative": "/posts/HLadQZ6FqTTjnYpoB/how-not-to-be-a-naive-computationalist", "linkUrl": "https://www.lesswrong.com/posts/HLadQZ6FqTTjnYpoB/how-not-to-be-a-naive-computationalist", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20not%20to%20be%20a%20Na%C3%AFve%20Computationalist&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20not%20to%20be%20a%20Na%C3%AFve%20Computationalist%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLadQZ6FqTTjnYpoB%2Fhow-not-to-be-a-naive-computationalist%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20not%20to%20be%20a%20Na%C3%AFve%20Computationalist%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLadQZ6FqTTjnYpoB%2Fhow-not-to-be-a-naive-computationalist", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FHLadQZ6FqTTjnYpoB%2Fhow-not-to-be-a-naive-computationalist", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 675, "htmlBody": "<p>Meta-Proposal of which this entry is a subset:</p>\n<p>The <strong>Shortcut Reading Series</strong> is a series of less wrong posts that should say what are the minimal readings, as opposed to the normal curriculum, that one ought to read to grasp most of the state of the art conceptions of humans about a particular topic. Time is finite, there is only so much one person can read and thus we need to find the geodesic path to epistemic enlightenment and show it to Less Wrong readers.</p>\n<p>Exemplar:</p>\n<p>&ldquo;How not to be a Na&iuml;ve Computationalist&rdquo;, the <strong>Shortcut Reading Series </strong> post in philosophy of mind and language:</p>\n<p>This post&rsquo;s <em>raison d&rsquo;etre</em> is to be a guide for the minimal amount of philosophy of language and mind necessary for someone who ends up thinking the world <em>and</em> the mind are computable (such as Tegmark, Yudkowsky, Hofstadter, Dennett and many of yourselves) The desired feature which they have achieved, and you soon will, is to be able to state reasons, debugg opponents and understand different paradigms, as opposed to just thinking that it&rsquo;s 0 and 1&rsquo;s all the way down and not being able to say why.</p>\n<p>This post is <em>not</em> about Continental/Historical Philosophy, about that there have been recommendations in <a href=\"/lw/3gu/the_best_textbooks_on_every_subject\">http://lesswrong.com/lw/3gu/the_best_textbooks_on_every_subject/</a></p>\n<p>The order is designed.</p>\n<p>What is <em>sine qua non</em>, absolutely necessary, is in <strong>bold</strong> and OR means you only have to read one, the second one being more awesome and complex.</p>\n<p>Language and Mind:</p>\n<ul>\n<li><strong>37 Ways words can be Wrong - Yudkowsky</strong></li>\n<li><strong>Darwin Dangerous Idea Chapters 3,5, 11, 12 and 14 - Daniel Dennett</strong></li>\n<li>On Denoting - Bertrand Russell</li>\n<li>On What There Is - Quine</li>\n<li>Two Dogmas of Empiricism - Quine</li>\n<li><a href=\"http://uspfiloanalitica.googlegroups.com/web/Naming+and+Necessity+%28Saul+Kripke%29.pdf?gda=OM04jF0AAACxY9vtt80_Eoc5nvqIVwz175PQJuPTrBuBx1KDOyPsv28EIiRgvpFIdUtDSOAXMdvQiOpUpA44RKeO3Hq2LZFjAFL0F1PSQ6AApbiBfb572OU2_747KStNgkfeVUa7Znk\">Namind and Necessity </a>- Kripke <em>OR</em> <a href=\"http://consc.net/papers/twodim.html\">Two Dimensional Semantics</a> - David Chalmers</li>\n<li><a href=\"http://uspfiloanalitica.googlegroups.com/web/IS+PERSONAL+IDENTITY+WHAT+MATTERS+%28Parfit%29.pdf?gda=xH7KUGUAAACxY9vtt80_Eoc5nvqIVwz1SrVJGmujo21ZzWCUZeyIT_1pTF0kkXH0LwuUCGHMLaD_Xbul_77J5BjqCwuNd7LQkq10Hen6mJVcDGpt2QOMNxyfxYhtaHnOp4Mq0MGarrsa7WIsd6qHDhllGPdGMn_4\">&ldquo;Is Personal Identity What Matters?&rdquo;</a> - Derek Parfit</li>\n<li>Breakdown of Will - Part Two (don&rsquo;t read part 3) George Ainslie</li>\n<li><strong><a href=\"http://www.nyu.edu/gsas/dept/philo/faculty/block/papers/Abridged%20BBS.htm\">Concepts of Consciousness</a></strong> <strong>2003 - Ned Block</strong></li>\n<li>Attitudes <em>de dicto </em>and <em>de se </em>- David Lewis- Phil Papers 1</li>\n<li><strong>General Semantics - David Lewis - Phil Papers 1</strong></li>\n<li>The Stuff of Thought, Chapter 3 &ldquo;Fifty Thousand Innate Concepts&rdquo; - Steve Pinker</li>\n<li><strong><a title=\"If its in russian, use google chrome\" href=\"http://scilib.narod.ru/Biology/Dennett/IS/index.html\">Beyond Belief</a> - Daniel Dennett </strong><em>in Intentional Stance</em></li>\n<li><strong><a href=\"http://consc.net/papers/belief.html\">The Content and Epistemology of Phenomenal Belief</a></strong> <strong>- David Chalmers</strong></li>\n<li><strong>Quining Qualia OR I Am a Strange Loop OR Consciousness Explained - Dan &amp; Doug</strong></li>\n<li><strong><a href=\"http://plato.stanford.edu/entries/intentionality/\">Intentionality</a></strong> <strong>- Pierre Jacob - Stanford Encyclopedia Phil</strong></li>\n<li><strong>Philosophy in the Flesh - Lakoff &nbsp;&amp; Johnson - Chap 3,4, 12, 21,24 and 25.&nbsp;</strong></li>\n</ul>\n<p>What you cannot find here you probably will on Google or Library.nu (if anyone has a link to <a href=\"http://scilib.narod.ru/Biology/Dennett/IS/index.html\">Beyond Belief</a>&nbsp;(EDIT: Found it!), post it, it is the only hard to find one)</p>\n<p>Congratulations, you are now officially free from the Na&iuml;ve philosophical computationalism that underlies part of the Less Wrong Community. Your computationalism is now wise and well informed.</p>\n<p>Feel free now to delve into some interesting computational proposals such as</p>\n<ul>\n<li><a href=\"http://www.biolbull.org/cgi/content/abstract/215/3/216\">Consciousness as Integrated Information</a> - Giulio Tononi</li>\n<li>What is Thought - Eric Baum</li>\n<li>Good and Real - Gary Drescher</li>\n<li><a href=\"http://arxiv.org/PS_cache/arxiv/pdf/0704/0704.0646v2.pdf\">The Mathematical Universe Hipothesis</a> - Max Tegmark</li>\n</ul>\n<hr />\n<p style=\"padding-left: 30px;\"><em>Dealing with complexity is an inefficient and unnecessary waste of time, attention and mental energy. There is never any justification for things being complex when they could be simple.</em> - <strong>Edward de Bono</strong></p>\n<p>There are many realms and domains in which the quote above should not be praised. But I think I have all philosophy majors with me when I say that there must be a simpler way to get to the knowledge level we reach upon graduation.</p>\n<p>Finally, having wasted substantial amounts of time reading those <em>parts that should not be read</em> of philosophy, and not intending to do the same mistake in other areas, I ask you to publish a selection of readings in your area of expertise, <em><a href=\"http://wiki.lesswrong.com/wiki/Sequences\">The Sequences</a></em> are a major rationality shortcut, and we need more of that kind.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 1, "EdDGrAxYcrXnKkDca": 1, "GLykb6NukBeBQtDvQ": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "HLadQZ6FqTTjnYpoB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 38, "extendedScore": null, "score": 7.019391180724357e-07, "legacy": true, "legacyId": "6781", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["xg3hXCYQPJkwHyik2"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-13T23:56:42.000Z", "modifiedAt": null, "url": null, "title": "David Marr on two types of information-processing problems", "slug": "david-marr-on-two-types-of-information-processing-problems", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:26.795Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "nhamann", "createdAt": "2009-10-15T04:19:24.675Z", "isAdmin": false, "displayName": "nhamann"}, "userId": "t6Fcfj7hMxrdJraSD", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gsYqvLDWrQNBnNtAL/david-marr-on-two-types-of-information-processing-problems", "pageUrlRelative": "/posts/gsYqvLDWrQNBnNtAL/david-marr-on-two-types-of-information-processing-problems", "linkUrl": "https://www.lesswrong.com/posts/gsYqvLDWrQNBnNtAL/david-marr-on-two-types-of-information-processing-problems", "postedAtFormatted": "Wednesday, April 13th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20David%20Marr%20on%20two%20types%20of%20information-processing%20problems&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADavid%20Marr%20on%20two%20types%20of%20information-processing%20problems%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgsYqvLDWrQNBnNtAL%2Fdavid-marr-on-two-types-of-information-processing-problems%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=David%20Marr%20on%20two%20types%20of%20information-processing%20problems%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgsYqvLDWrQNBnNtAL%2Fdavid-marr-on-two-types-of-information-processing-problems", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgsYqvLDWrQNBnNtAL%2Fdavid-marr-on-two-types-of-information-processing-problems", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 574, "htmlBody": "<p>I found an essay written by <a href=\"http://en.wikipedia.org/wiki/David_Marr_(neuroscientist)\">David Marr</a>&nbsp;called <a href=\"http://www.syntheticguru.com/doc/marr.pdf\">Artificial Intelligence -- a personal view</a>&nbsp;that I thought was fairly insightful. Marr first discusses how information processing problems are generally solved:</p>\n<blockquote>\n<p>The solution to an information processing problem divides naturally into two&nbsp;parts. In the first, the underlying nature of a particular computation is characterized,&nbsp;and its basis in the physical world is understood. One can think of this part as an&nbsp;abstract formulation of <em>what</em> is being computed and <em>why</em>, and I shall refer to it as&nbsp;the \"theory\" of a computation.&nbsp;The second part consists of particular algorithms&nbsp;for implementing a computation, and so it specifies <em>how.</em></p>\n</blockquote>\n<p>This is reminiscent of Marr's <a href=\"http://en.wikipedia.org/wiki/David_Marr_(neuroscientist)#Levels_of_analysis\">three levels of analysis</a>.</p>\n<p>Next, Marr draws a distinction between a Type 1 information processing problem and a Type 2 problem. A Type 1 problem has a solution that naturally divides along lines mentioned above: first one can formulate the computational theory behind it, and then one devises an algorithm to implement the computation. Marr proposes, however, that there is a class of problems that doesn't fit this description:</p>\n<blockquote>\n<p>The fly in the ointment is that while many problems of biological information&nbsp;processing have a Type 1 theory, there is no reason why they should all have.&nbsp;This can happen when a problem is solved by the simultaneous action of a considerable number of processes, <em>whose interaction is its own simplest description,&nbsp;</em>and I shall refer to such a situation as a Type 2 theory. One promising candidate&nbsp;for a Type 2 theory is the problem of predicting how a protein will fold. A large&nbsp;number of influences act on a large polypeptide chain as it flaps and flails in a&nbsp;medium. At each moment only a few of the possible interactions will be important,&nbsp;but the importance of those few is decisive. Attempts to construct a simplified&nbsp;theory must ignore some interactions; but if most interactions are crucial at some&nbsp;stage during the folding, a simplified theory will prove inadequate.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>More discussion about Type 1 and Type 2 problems follows, but I'm not going to summarize it. It well-worth reading, however. I did think this critique of the GOFAI program was pretty sharp for having been formulated in 1977:</p>\n<blockquote>\n<p>For very&nbsp;advanced problems like story-understanding, current research is often purely&nbsp;exploratory. That is to say, in these areas our knowledge is so poor that we cannot&nbsp;even begin to formulate the appropriate questions, let alone solve them</p>\n<p>...</p>\n<p>Most of the history of A.I. (now fully 16 years old) has consisted of exploratory&nbsp;studies. Some of the best-known are Slagle's [24] symbolic integration program,&nbsp;Weizenbaum's [30] Eliza program, Evans\" [4] analogy program, Raphaers [19]&nbsp;SIR, Quillian's [18] semantic nets and Winograd's [32] Shrdlu. All of these programs have (in retrospect) the property that they are either too simple to be&nbsp;interesting Type 1 theories, or very complex yet perform too poorly to be taken&nbsp;seriously as a Type 2 theory</p>\n<p>...&nbsp;</p>\n<p>And yet many things have been learnt from these experiences--mostly negative things (the first 20&nbsp;obvious ideas about how intelligence might work are too simple or wrong)...&nbsp;The mistakes made in the field lay not in having carried out such&nbsp;studies--they formed an essential part of its development--but consisted mainly&nbsp;in failures of judgement about their value, since it is now clear that few of the&nbsp;early studies themselves formulated any solvable problems.</p>\n</blockquote>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>If we accept this taxonomy, then where does Friendliness fit in? My hunch is that it's a Type 2 problem. If this is so, what Type 1 problems can be focused on in the present?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gsYqvLDWrQNBnNtAL", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 7, "extendedScore": null, "score": 1.4e-05, "legacy": true, "legacyId": "6782", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T00:18:46.695Z", "modifiedAt": null, "url": null, "title": "Levels of Action", "slug": "levels-of-action", "viewCount": null, "lastCommentedAt": "2017-06-17T04:34:38.850Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "alyssavance", "createdAt": "2009-10-07T20:08:31.887Z", "isAdmin": false, "displayName": "alyssavance"}, "userId": "zQSAWAS5tnqtzp55N", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/guDcrPqLsnhEjrPZj/levels-of-action", "pageUrlRelative": "/posts/guDcrPqLsnhEjrPZj/levels-of-action", "linkUrl": "https://www.lesswrong.com/posts/guDcrPqLsnhEjrPZj/levels-of-action", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Levels%20of%20Action&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALevels%20of%20Action%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FguDcrPqLsnhEjrPZj%2Flevels-of-action%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Levels%20of%20Action%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FguDcrPqLsnhEjrPZj%2Flevels-of-action", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FguDcrPqLsnhEjrPZj%2Flevels-of-action", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2808, "htmlBody": "<p>One of the most useful concepts I have learned recently is the distinction between actions which <em>directly</em> improve the world, and actions which <em>indirectly</em> improve the world.</p>\n<p>Suppose that you go onto <a href=\"http://mturk.amazon.com\">Mechanical Turk</a>, open an account, and spend a hundred hours transcribing audio. At current market rates, you'd get paid around $100 for your labor. By taking this action, you have made yourself $100 wealthier. This is an example of what I'd call a Level 1 or object-level action: something that directly moves the world from a less desirable state into a more desirable state.</p>\n<p>On the other hand, suppose you take a typing class, which teaches you to type twice as fast. On the object level, this doesn't move the world into a better state- nothing about the world has changed, other than you. However, the typing class can still be very useful, because <em>every</em> Level 1 project you tackle later which involves typing will go better- you'll be able to do it more efficiently, and you'll get a higher return on your time. This is what I'd call a Level 2 or meta-level action, because it doesn't make the world better directly - it makes the world better indirectly, by improving the effectiveness of Level 1 actions. There are also Level 3 (meta-meta-level) actions, Level 4 (meta-meta-meta-level actions), and so on.</p>\n<p><a id=\"more\"></a></p>\n<p>The most important difference between Level 1 and Level 2 actions is that Level 1 actions tend to be <em>additive</em>, while Level 2 actions tend to be <em>multiplicative</em>. If you do ten hours of work at McDonald's, you'll get paid ten times as much as if you did one hour; the benefits of the hours add together. However, if you take ten typing classes, each one of which improves your ability by 20%, you'll be 1.2^10 = 6.2 times better at the end than at the beginning: the benefits of the classes multiply (assuming independence).</p>\n<p>One result is that spending time on Level 2 actions can have a much greater return than spending time on Level 1 actions. If your labor is worth $20 an hour, and you can't change that, then the amount of money you can earn in a year has a fairly hard upper bound- no matter how you slice it, there are only 168 hours in a week. If you spend that year trying to increase the value of your labor, on the other hand, the upper bound on your performance is both a lot higher (because you can then make more money every year for the next three decades), and a lot more fuzzy. It's a lot more fuzzy because, while everyone has the same number of hours in a week, how effective Level 2 actions are depends a lot on your intelligence, what methods you use, and lots of other stuff. Most Americans spend too little time on higher-level actions, like <a href=\"/lw/2p5/humans_are_not_automatically_strategic/\">being strategic</a> - doing a quick analysis of what your goals are, and which Level 1 or Level 2 actions would best accomplish those goals. Witness the hordes of lawyers who spend thirty years on the Level 1 action of working at a law firm, three years on the Level 2 action of getting a law degree, and three minutes on the Level 3 action of deciding what to do after college. (Being strategic is one level up from whichever actions you're being strategic about.)</p>\n<p>It is also possible to have the opposite problem, of under-valuing Level 1, and I suspect that quite a few people in the nerdier communities do. People sometimes fall into the trap of noticing that the higher levels are (when applied properly) far more useful on the margin than Level 1, and then reacting by giving <a href=\"/lw/lm/affective_death_spirals/\">blind praise</a> to the meta level at the expense of the object level. One cultural example is the ancient Greeks- who, though they were good thinkers for their day, didn't invent science. Science involved <a href=\"/lw/3wh/science_do_it_yourself/\">actually going out and looking at the world</a>, and that was manual labor and manual labor was for slaves. The ultimate extreme of this is Aristotle, who got philosophy off to an unfortunate beginning by <a href=\"http://www.paulgraham.com/philosophy.html\">starting his Metaphysics</a> with the assumption that the most noble knowledge would be the most useless.</p>\n<p>The problem there is that, because Level 2 actions are multiplicative and not additive, you still need at least some Level 1 actions to multiply by. It doesn't matter how high the value of one's labor is, if one never actually goes out and does labor. A very large number, multiplied by zero, is still zero. If one <em>just</em> does Level 2 actions, without any Level 1 actions, it is a failure to do something instead of nothing. Taking only meta-level actions accomplishes less, in the end, than the ten-year-old who just mowed the neighbor's lawn for a dollar.</p>\n<p>On a societal level, one can run into this problem even more easily, because having a large society allows one to build up more meta-levels. For the most part, people's day-to-day labor is made up of Level 1 actions- the stuff that directly improves the world. Engineering technology that helps improve people's productivity is then a Level 2 action. Doing science that helps with engineering is then a Level 3 action (meta-meta), and doing math that helps with science is a Level 4 action (meta-meta-meta). In order for working on Level 4 to be effective, there have to be three steps chaining back to Level 1: in this example, from math to science, from science to engineering, and from engineering to productivity. If any one of these steps fails - if the math isn't useful for science, if the science is in a different field than the engineering, or if the engineered devices aren't used effectively - then working on Level 4 won't accomplish anything.</p>\n<p>Going meta can be very powerful, for the reasons outlined above- <em>each</em> action taken on Level N + 1 makes it easier to do <em>lots</em> of things on Level N. The invention of science, which is almost always Level 2 or higher, changed the world and created modern civilization, and science can still <a href=\"/lw/3wh/science_do_it_yourself/\">radically improve your life</a> today. However, in order for the higher levels to be useful <em>within a specific project</em>, that project has to incorporate all the steps from the meta level back down to the object level, and this becomes much more difficult with each meta level added. The Manhattan Project managed to pull it off with two meta-levels- science to engineering and engineering to real-world effects- but the Manhattan Project had dozens of world-class scientists and hundreds of top-notch engineers working on it. Attempting too many meta levels without having the infrastructure to support the attempt will wind up like <a href=\"http://news.ycombinator.com/item?id=1366236\">filing an IPO for a one-man beer pong business</a>.</p>\n<p>How should we counter this, while still getting the benefits of the higher levels? One suggestion that gets talked about a lot is simply to always do something directly useful - <em>do something instead of nothing</em>, which is the first step towards accomplishing any goal. On the small scale, we are all familiar with this. If you take the garbage out, the garbage can becomes empty; if you don't, the room starts to stink. If you do the dishes, you have clean dishes to eat off of; if not, you wind up eating off of dirty dishes or a table. If you go and buy food, you have lots of food to eat; if not, you go hungry, or pay a lot for food at a restaurant.</p>\n<p>I think that, collectively, we are all living in a world that's isomorphic to a pigsty house, where no one ever does the dishes and no one ever takes out the trash. We're doing better now than we have in the past. But the world of today is nothing, compared to the shining, sparkling utopia that <em>could</em> exist if people simply did more things, using the decision algorithms that they already know how to execute. So many things <a href=\"/lw/64/helpless_individuals/\"></a>; to name one particular field, there are many examples of science which is <a href=\"/lw/64/helpless_individuals/\">obviously ridiculously underfunded</a>. Yet, in all these cases, with the exception of a tiny handful of part-time volunteers, nothing ever gets done.</p>\n<p>It is, of course, also important to choose effective actions, in addition to simply choosing to act. Preventing existential risk is a more important goal by far than coming up with a more effective way to do biotech research. However, the first and most important step is to just do <em>something instead of nothing</em>. If, at the end of the day, what you <em>actually wind up doing</em> is nothing instead of X, it doesn't <em>matter</em> that there are ten other things you could do which would be a hundred times more effective than X. Those don't show up on the bottom line. Your final score is still zero, instead of at least being positive.</p>\n<p>Even if we consciously agree that doing X could be useful and is unlikely to result in serious harm, I strongly suspect that there are <em>still</em> barriers to acting: unconscious ones. Most of the machinery of our brain operates below the level of deliberate reasoning. While typing this sentence, I remembered to breathe oxygen, match the words I was thinking to the motions of my hands (so as to make them appear on the screen), remain sitting upright, blink every so often, look around to make sure my stuff hadn't gotten lost, and move around a bit so my legs don't go numb, all without paying any deliberate attention at all. Yet, each of these things are quite difficult to do, in the sense that it would be a lot of work to build a robot that can do them. Just as we frequently breathe without noticing, I think we all refrain from doing useful things, out of unjustified fear, without noticing. Why is that?</p>\n<p>My current guess is that it's because of the increasing institutionalization of society, which is caused by economic growth. When your tribe is made up of a hundred people, you can model each person in high detail when you interact with them - taking into account their personality, their strengths and weaknesses, their past interactions with you, and so on. However, in a corporation with a hundred thousand people, the CEO doesn't have time to construct complex models of each worker, and yet he must ensure that all the workers cooperate effectively. How does he do that? By making each worker simple to model - by constructing a set of rules which governs each worker's behavior, and constrains them to behave in simple, easily understandable ways. The net effect of this is that large institutions <a href=\"http://www.paulgraham.com/boss.html\">train people to be afraid of</a> taking actions they aren't explicitly told to take, because that would make life more complicated for the managers.</p>\n<p>One possible solution to this is to lower your <em>general level of inhibition</em>, by practicing doing things that you feel inhibited about. Studies have shown that there is a significant positive correlation between <a href=\"http://marginalrevolution.com/marginalrevolution/2006/09/i_didnt_believe.html\">alcohol use</a>, and income in life. Why would that be? Drinking alcohol doesn't make you smarter. Nor does it make you work harder, or become more skilled, or gain additional knowledge. I think the reason is that alcohol is <em>disinhibitory</em>. People do things while drunk that they wouldn't do otherwise, and even though a lot of them are stupid and destructive, some of them are useful (like meeting new people). And the world counts the good things and forgets about the bad things, like how everyone forgot about George W. Bush being <a href=\"http://www.pensitoreview.com/2008/04/21/bush-torture-scandal-yale/\">branded with a coat hanger</a> by his fraternity.</p>\n<p>There is also a very interesting way, which I highly recommend, of getting both the benefits of Level 1 and Level 2 actions. One does this by going out and doing Level 1 things that one <em>hasn't done before</em> - for, to paraphrase Eliezer, if you want to find a <em>better</em> route to work, you must necessarily explore a <em>different</em> route to work.</p>\n<p>Ordinarily, going to the grocery store is a Level 1 action. But what if you've never been to a grocery store? Then, going to the store is actually both a Level 1 and a Level 2 action. By going to the grocery store, you acquire food. And you also learn lots of useful things about how grocery stores work, which will help you on all of your subsequent trips.</p>\n<p>The downside of this is that, when you consider things purely as Level 1 actions, it might be less worthwhile to do something new than something you're already familiar with. If you've never ridden a bus before, it might be faster to walk than to take the risk of getting lost. But, in most cases, this tends not to be a very big deal. If you do it badly, it's no biggie, you can just try again later when you're more skilled.</p>\n<p>In the ancestral environment, the range of skills one could acquire was <a href=\"/lw/oq/savanna_poets/\">fairly limited</a>. Hence, we humans evolved to employ a two-part strategy: try new things during your childhood, and then when you mature (at age 14 or so), forget about trying new things, and concentrate only on Level 1 actions. Now that the range of possible skills is so much larger, this is terribly suboptimal- but humans have this thing about continuing to do stuff, like eating chocolate, that has long since <a href=\"/lw/l0/adaptationexecuters_not_fitnessmaximizers/\">lost its utility</a>.</p>\n<p>The key benefit of doing lots of new, unfamiliar Level 1 actions is that world is an extremely complicated place, and as a general rule, no matter how much you read and learn about something (Level 2 actions), there's <em>always</em> some sort of surprise when you actually go and do it; something that the authors of the stuff you read didn't notice, or forgot to write down. In computer programming, we have the general principle of humility regarding bugs: even if you can't think of anything you did wrong when writing software, you had better go and test it before releasing it, because the odds are pretty darn good that you made a mistake <em>somewhere</em>. The analogous principle is, never assume that you can do something (even if it seems simple) unless you've actually done it before, because there will probably be some sort of hidden surprise.</p>\n<p>And the more things you've done before, the fewer hidden surprises there will be. The counterpart point is that if you <em>do</em> go out and do things that you haven't done before, you'll be able to pass over mostly-invisible barriers that other people will mysteriously smack into. Suppose you try to construct a ten-step plan, where each of the ten steps is something seemingly simple, but is still something that you haven't done before. Will it work? Probably not. Even if the probability of success on each step is 90%, the probability of the whole plan working is only 0.9^10 = 0.35. You can go over each and every one of the steps, analyze them, figure out that they're very likely to succeed individually- and still fail, because without a <em>strong</em> assurance of success on each step, executing <em>all</em> of them in the proper sequence becomes very unlikely.</p>\n<p>On the other hand, if you have lots of experience doing something Level 1, you can understand it well enough to actually make the probability of failure arbitrarily small, not just smallish-seeming. How narrow or wide your probability distribution is for X is a function of how much information you have about X. And doing X offers the possibility of gaining <em>arbitrarily complete</em> information about X, not just the sort of information that one can communicate effectively in words. I think the evidence is fairly conclusive that someone who hasn't experienced, for example, love, war, or torture can't really have complete information about it, because there are parts of the brain which are only wired to receive information directly from the external environment. (Of course, the reverse is also true, which is why people who don't read a lot can be very capable in their domains of expertise, but still terrible at abstract thought.)</p>\n<p>Making the probability of failure arbitrarily small, then, allows you to construct long chains of sequential events which will work reliably. An average human can take a step forward ten thousand times in a row without falling down once, because they (the mostly subconscious systems in their brain that handle movement) understand it so well. And, once a particular chain of Level 1 events has become reliable enough, you can then use it as a building block to construct new, higher-level chains of Level 1 events, which is itself a Level 2 action. This is how society can accomplish extremely complicated things, like taking a company public, with any reliability at all- by having people build larger chains out of smaller building blocks that they already understand, and can execute many times without slipping up.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"xexCWMyds6QLWognu": 1, "fF9GEdWXKJ3z73TmB": 1, "PDJ6KqJBRzvKPfuS3": 1, "AHK82ypfxF45rqh9D": 1, "DHZhAxgE5edGxxh8d": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "guDcrPqLsnhEjrPZj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "neutral", "cancelled": false, "isUnvote": false}], "voteCount": 132, "baseScore": 168, "extendedScore": null, "score": 0.000317, "legacy": true, "legacyId": "6784", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 169, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 47, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["PBRWb2Em5SNeWYwwB", "XrzQW69HpidzvBxGr", "K82evF2iRAiRWwvyn", "f42BHX7rMw2dyFJfT", "kQzs8MFbBxdYhe3hK", "XPErvb8m9FapXCjhA"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 8, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T00:58:40.264Z", "modifiedAt": null, "url": null, "title": "Arational quotes", "slug": "arational-quotes", "viewCount": null, "lastCommentedAt": "2017-06-17T04:20:31.536Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dr_Manhattan", "createdAt": "2010-12-16T13:46:11.412Z", "isAdmin": false, "displayName": "Dr_Manhattan"}, "userId": "rhNqxRkdTL5KSCuJk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cEZdqbe3bfH8jMZY9/arational-quotes", "pageUrlRelative": "/posts/cEZdqbe3bfH8jMZY9/arational-quotes", "linkUrl": "https://www.lesswrong.com/posts/cEZdqbe3bfH8jMZY9/arational-quotes", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Arational%20quotes&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AArational%20quotes%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcEZdqbe3bfH8jMZY9%2Farational-quotes%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Arational%20quotes%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcEZdqbe3bfH8jMZY9%2Farational-quotes", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcEZdqbe3bfH8jMZY9%2Farational-quotes", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>Jacobi, an eminent algebraist, was fond of saying: &ldquo;<em>Invert</em>, <em>always Invert</em>&rdquo;</p>\n<p>- Charlie Munger</p>\n<p>So based on the above and the regular \"rationality quotes\" feature I figured why not try a thread for quotes that are not rational? Obviously <a href=\"/lw/lw/reversed_stupidity_is_not_intelligence/\">we do not plain stupidity</a>, but I think quotes that appeal on first listen would qualify. As a side benefit of analyzing specific errors this might serve as an inoculation from rhetoric. &nbsp;</p>\n<p>I am using \"arational\" rather than irrational to highlight this distinction.</p>\n<p>PS. Please feel free to reply with meta comments on whether this is a valuable idea.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cEZdqbe3bfH8jMZY9", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 1, "extendedScore": null, "score": 7.020273081670474e-07, "legacy": true, "legacyId": "6785", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 53, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["qNZM3EGoE5ZeMdCRt"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T06:12:05.618Z", "modifiedAt": null, "url": null, "title": "G\u00f6del and Bayes: quick question", "slug": "goedel-and-bayes-quick-question", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:28.457Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "hairyfigment", "createdAt": "2010-10-14T22:12:59.035Z", "isAdmin": false, "displayName": "hairyfigment"}, "userId": "NesjW63eueLsbKrCY", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/3e2Lju7BtiN6ndr84/goedel-and-bayes-quick-question", "pageUrlRelative": "/posts/3e2Lju7BtiN6ndr84/goedel-and-bayes-quick-question", "linkUrl": "https://www.lesswrong.com/posts/3e2Lju7BtiN6ndr84/goedel-and-bayes-quick-question", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20G%C3%B6del%20and%20Bayes%3A%20quick%20question&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AG%C3%B6del%20and%20Bayes%3A%20quick%20question%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3e2Lju7BtiN6ndr84%2Fgoedel-and-bayes-quick-question%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=G%C3%B6del%20and%20Bayes%3A%20quick%20question%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3e2Lju7BtiN6ndr84%2Fgoedel-and-bayes-quick-question", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F3e2Lju7BtiN6ndr84%2Fgoedel-and-bayes-quick-question", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 427, "htmlBody": "<p>Kurt G&ouml;del showed that we could write within a system of arithmetic the statement, \"This statement has no proof within the system,\" in such a way that we couldn't dismiss it as meaningless. This proved that if the system (or part of it) could prove the logical consistency of the whole, it would thereby contradict itself. We nevertheless think arithmetic does not contradict itself because it never has.</p>\n<p>From what I understand we could write a version of the G&ouml;del statement for the axioms of probability theory, or even for the system that consists of those axioms plus our current best guess at P(axioms' self-consistency). Edit: or not. According to the comments the Incompleteness Theorem does not apply until you have a stronger set of assumptions than the minimum you need for probability theory. So let's say you possess the current source code of an AGI running on known hardware. It's just now reached the point where it could pass the test of commenting extensively on LW without detection. (Though I guess we shouldn't yet assume this will continue once the AI encounters certain questions.) For some reason it tries to truthfully answer any meaningful question. (So nobody mention the <a title=\"and AI\" href=\"/lw/4rx/singularity_and_friendly_ai_in_the_dominant_ai/\">Riemann hypothesis</a>. We may want the AI to stay in this form for a while.) Whenever an internal process ends in a Jaynes-style error message that indicates a contradiction, the AI takes this as strong evidence of a contradiction in the relevant assumptions. Now <a title=\"random link\" href=\"http://www.haibane.info/2008/04/13/proving-godel/\">according to my understanding</a> we can take the source code and ask about a statement which says, \"The program will never call this statement true.\" Happily the AI can respond by calling the statement \"likely enough given the evidence.\" So far so good.</p>\n<p>So, can we or can't we write a mathematically meaningful statement Q saying, \"The program will never say 'P(Q)&ge;0.5'\"? What about, \"The program will never call 'P(Q)&ge;0.5' true (or logically imply it)\"? How does the AI respond to questions about variations of these statements?</p>\n<p>It seems as if we could form a similar question by modifying the Halting-Oracle Killer program to refute more possible responses to the question of its run-time, assuming the AI will know this simpler program's source code. Though it feels like a slightly different problem because we'd have to address a lot of possible responses directly &ndash; with the previous examples, if the AI doesn't kill us in one sense or another, we can go on to ask for clarification. Or we can say the AI wants to clarify any response that evades the question.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"AJDHQ4mFnsNbBzPhT": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "3e2Lju7BtiN6ndr84", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 2, "extendedScore": null, "score": 7.021153624309066e-07, "legacy": true, "legacyId": "6792", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 36, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["K45SaBaB3D7o9xpAs"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T06:12:37.620Z", "modifiedAt": null, "url": null, "title": "Might whole brain emulation require quantum-level emulation?", "slug": "might-whole-brain-emulation-require-quantum-level-emulation", "viewCount": null, "lastCommentedAt": "2017-06-17T04:00:51.312Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mtv98d726qJgag3X2/might-whole-brain-emulation-require-quantum-level-emulation", "pageUrlRelative": "/posts/mtv98d726qJgag3X2/might-whole-brain-emulation-require-quantum-level-emulation", "linkUrl": "https://www.lesswrong.com/posts/mtv98d726qJgag3X2/might-whole-brain-emulation-require-quantum-level-emulation", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Might%20whole%20brain%20emulation%20require%20quantum-level%20emulation%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMight%20whole%20brain%20emulation%20require%20quantum-level%20emulation%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmtv98d726qJgag3X2%2Fmight-whole-brain-emulation-require-quantum-level-emulation%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Might%20whole%20brain%20emulation%20require%20quantum-level%20emulation%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmtv98d726qJgag3X2%2Fmight-whole-brain-emulation-require-quantum-level-emulation", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fmtv98d726qJgag3X2%2Fmight-whole-brain-emulation-require-quantum-level-emulation", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 144, "htmlBody": "<p>Most experts seem to think that <a href=\"http://www.philosophy.ox.ac.uk/__data/assets/pdf_file/0019/3853/brain-emulation-roadmap-report.pdf\">whole brain emulation</a> will not require emulation down to the quantum level, but perhaps at the level of atoms or even molecules, either of which is far more computationally tractable than quantum-level brain emulation. Those who think quantum-level emulation will be required for whole brain emulation are often considered to be cranks.</p>\n<p>However, it is worth noting that a few biological processes - including photosynthesis - have <a href=\"http://www.youtube.com/watch?v=wcXSpXyZVuY\">recently been found</a>&nbsp;[excellent video lecture] to depend on the particularities of quantum phenomena. This lends no support to Penrose's views on quantum phenomena and the brain, but it may not be so crankish after all to suppose that whole brain emulation may require emulation down to the quantum level.</p>\n<p>Thoughts?</p>\n<p>&nbsp;</p>\n<p>Links:</p>\n<p>On photosynthesis, see <a href=\"http://www.cchem.berkeley.edu/grfgrp/publications/index.html\">Fleming's papers</a> on the topic.</p>\n<p><a href=\"http://www.physics.uci.edu/~tritz/Publications/RITZ2004.pdf\">Here</a> is the quantum bird navigation paper.</p>\n<p><a href=\"http://www.nature.com/news/2006/061204/full/news061204-10.html\">Here</a> is some coverage on Turin's controversial theory of quantum smell.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"5f5c37ee1b5cdee568cfb2b1": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mtv98d726qJgag3X2", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 17, "extendedScore": null, "score": 3.5e-05, "legacy": true, "legacyId": "6793", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 17, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 15, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T12:29:45.271Z", "modifiedAt": null, "url": null, "title": "Specific Fiction Discusion (April 2011)", "slug": "specific-fiction-discusion-april-2011", "viewCount": null, "lastCommentedAt": "2017-06-17T04:04:21.456Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Armok_GoB", "createdAt": "2010-04-17T10:02:06.399Z", "isAdmin": false, "displayName": "Armok_GoB"}, "userId": "7ndq2gZSo6zJELxAJ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/difixkcKWe76bsCAE/specific-fiction-discusion-april-2011", "pageUrlRelative": "/posts/difixkcKWe76bsCAE/specific-fiction-discusion-april-2011", "linkUrl": "https://www.lesswrong.com/posts/difixkcKWe76bsCAE/specific-fiction-discusion-april-2011", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Specific%20Fiction%20Discusion%20(April%202011)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASpecific%20Fiction%20Discusion%20(April%202011)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdifixkcKWe76bsCAE%2Fspecific-fiction-discusion-april-2011%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Specific%20Fiction%20Discusion%20(April%202011)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdifixkcKWe76bsCAE%2Fspecific-fiction-discusion-april-2011", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FdifixkcKWe76bsCAE%2Fspecific-fiction-discusion-april-2011", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 292, "htmlBody": "<p>Seeing some recent comments on my links comment, I think this thread might be warranted.</p>\n<p>This is a thread for discussing specific works of fiction; books, movies, TV shows, webcomics, fanfictions, whatever. It's purpose is to provide a rationality perspective on shows that are not necessarily aimed at rationalists (but by the correlation of target audience I predict many of them might be anyway...)</p>\n<p>To keep this organized, please follow these guidlines when posting; Top level coments shuld with NO exception (I'll make a single meta comment where discussion about this thread itself can go) fit into one of the following templates:</p>\n<p>For a single work, the top level comment should consist of the full title, a link to where the work can be found online if applicable, and the TV tropes page for it OR a short description ONLY if there is no TV tropes page for it.</p>\n<p>For certain authors that have written a lot of books popular on LW, such as for example Vernor Vinge, discussion of each one might tend to dominate the thread, therefore there should be one post for ALL the works of such authors, and they can be made entire own threads if discussion grows to big for that. The format for these comments is: Authors name, link to their wikipedia page (or homepage if they don't have a wikipedia page), and a short bibliography to make it easier to avoid making separate top level comments for their books.</p>\n<p>Also, pleas refrain from discussing things written by Eliezer or otherwise already having a discussion space on LW, for similar reasons you should avoid discussing a certain institute and because it'd be redundant.</p>\n<p>If this thread grows large and popular, I'm thinking this might become a monthly thing, hence the (April) part.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "difixkcKWe76bsCAE", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 10, "extendedScore": null, "score": 7.022213532481404e-07, "legacy": true, "legacyId": "6798", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 162, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T13:15:55.175Z", "modifiedAt": null, "url": null, "title": "Three consistent positions for computationalists", "slug": "three-consistent-positions-for-computationalists", "viewCount": null, "lastCommentedAt": "2017-06-17T04:35:30.443Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "dfranke", "createdAt": "2009-02-27T18:51:11.645Z", "isAdmin": false, "displayName": "dfranke"}, "userId": "kqWQye46c5bMBS4RS", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rEQmyCZHtdsXwq3xh/three-consistent-positions-for-computationalists", "pageUrlRelative": "/posts/rEQmyCZHtdsXwq3xh/three-consistent-positions-for-computationalists", "linkUrl": "https://www.lesswrong.com/posts/rEQmyCZHtdsXwq3xh/three-consistent-positions-for-computationalists", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Three%20consistent%20positions%20for%20computationalists&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThree%20consistent%20positions%20for%20computationalists%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrEQmyCZHtdsXwq3xh%2Fthree-consistent-positions-for-computationalists%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Three%20consistent%20positions%20for%20computationalists%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrEQmyCZHtdsXwq3xh%2Fthree-consistent-positions-for-computationalists", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrEQmyCZHtdsXwq3xh%2Fthree-consistent-positions-for-computationalists", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1121, "htmlBody": "<p>Yesterday, as a followup to <a href=\"/lw/57e/we_are_not_living_in_a_simulation\">We are not living in a simulation</a>, I posted <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/\">Eight questions for computationalists</a> in order to obtain a better idea of what exactly my computationalist critics were arguing.&nbsp; These were the questions I asked:</p>\n<blockquote><ol>\n<li>As it is used in the sentence \"consciousness is really just computation\", is computation:<br />a) Something that an abstract machine does, as in \"No oracle Turing machine can compute a decision to its own halting problem\"?<br />b) Something that a concrete machine does, as in \"My calculator computed 2+2\"?<br />c) Or, is this distinction nonsensical or irrelevant?</li>\n<li>If you answered \"a\" or \"c\" to question 1: is there any particular model, or particular class of models, of computation, such as Turing machines, register machines, lambda calculus, etc., that needs to be used in order to explain what makes us conscious? Or, is any Turing-equivalent model equally valid?</li>\n<li>If you answered \"b\" or \"c\" to question 1: unpack what \"the machine computed 2+2\" means. What is that saying about the physical state of the machine before, during, and after the computation?</li>\n<li>Are you able to make any sense of the concept of \"computing red\"? If so, what does this mean?</li>\n<li>As far as consciousness goes, what matters in a computation: functions, or algorithms? That is, does any computation that give the same outputs for the same inputs feel the same from the inside (this is the \"functions\" answer), or do the intermediate steps matter (this is the \"algorithms\" answer)?</li>\n<li>Would an <em>axiomatization</em> (as opposed to a complete exposition of the implications of these axioms) of a Theory of Everything that can explain consciousness include definitions of any computational devices, such as \"and gate\"?</li>\n<li>Would an axiomatization of a Theory of Everything that can explain consciousness mention qualia?</li>\n<li>Are all computations in some sense conscious, or only certain kinds?</li>\n</ol></blockquote>\n<p>I got some interesting answers to these questions, and from them I can extract three distinct positions that seem consistent to me.</p>\n<p><strong>Consistent Position #1: Qualia skepticism<br /></strong></p>\n<p>Perplexed asserted this position in <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x97\">no uncertain terms</a>.&nbsp; Here's my unpacking of it:</p>\n<p>\"Qualia do not exist. The things that you're confused about and are mistaking for qualia can be made clear to you using an argument phrased in terms of computation.&nbsp; When you talk about consciousness, I think I can understand your meaning, but you aren't referring to anything fundamental or particularly well defined: it's an <a href=\"/lw/tc/unnatural_categories/\">unnatural category</a>.\"</p>\n<p>The <em>internal</em> logic of the qualia skeptic's position makes sense to me, and I can't really respond to it other than by expressing personal incredulity. To me, the empirical evidence in support of the existence of qualia is so clear and so immediate that I can't figure out what you're not seeing so that I can point to it.&nbsp; However, I shouldn't need to bring you to your senses (literally!) on this in order to convince you to reject Bostrom's simulation argument, albeit on grounds completely different than any I've argued so far.&nbsp; If you don't buy that there's anything fundamental behind consciousness, then you also shouldn't buy Bostrom's anthropic reasoning in which he conjures up the reference class of \"observers with human-type experiences\"; elsewhere he refers to \"conscious experience\" and \"subjective experience\" without implication that he means anything more specific. That's taking an unnatural category and invoking it <a href=\"/lw/td/magical_categories/\">magically</a>. In the statement that we are something selected with uniform probability from that group, how do you make sense of \"are\"?</p>\n<p><strong>Consistent Position #2: Computation is implicit in physics</strong></p>\n<p>This position is my best attempt at a synthesis of what <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x88\">TheOtherDave</a>, <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x75\">lessdazed</a>, and <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x6y\">prase</a> are getting at. It's compatible with position #1, but neither one entails the other.</p>\n<p>To understand this position, it is helpful, but not necessary, to define the laws of physics in terms of something like a cellular automaton. Each application of the automaton's update rule can be understood as a primitive operation in a computation. When you apply the update rule repeatedly on cells nearby each other, you're building up a more complex computation. So, \"consciousness is just computation\" is equivalent in meaning, essentially, to \"consciousness is just physics\".</p>\n<p>This position more-or-less necessitates answering \"algorithms\" to question #5, or if not that then at least something similar to <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x6t\">RobinZ's answer</a>. If you say \"functions\" then you at least need to explain how to reify the concepts of \"input\" and \"output\". You can pull this off by saying that the update rules are the functions, the inputs are the state before the rule application, and the outputs are the state afterward. Any other answer probably means you're taking something closer or identical to position #3 which I'll address next. <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3xaw\">This comment</a> by peterdjones and his followups to it provide a (Searlesque) intuition pump showing other reasons why a \"functions\" reply is problematic.</p>\n<p>I have no objection to this position. However, it does not imply substrate independence, and strongly suggests its negation. If your algorithmic primitives are defined at the level of individual update-rule applications, then any change whatsoever to an object's physical structure is a change to the algorithm that it embodies. If you accept position #2 while rejecting position #1, then you may actually be making the same argument that I am, merely in different vocabulary.</p>\n<p><strong>Consistent Position #3: Computation is reified by physics</strong></p>\n<p>I was both shocked and pleased to see <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x6w\">zaph's answer to question #6</a>, because it bites a bullet that I never believed anyone would bite: that there is actually something fundamental in the laws of physics which defines and reifies the concept of computation in a substrate-independent fashion. I can't find any inconsistency in this, but I think we have good reason to consider it <em>extremely</em> implausible. In the language of physics which is familiar to us and has served us well &mdash; the language whose vocabulary consists of things like \"particle\" and \"force\" and \"Hilbert space\" &mdash; the Kolmogorov complexity of a definition of an equivalence relation which tells us that an AND gate implemented in a MOSFET is equivalent to an AND gate implemented in a neuron is equivalent to an AND gate implemented in <a href=\"http://xkcd.com/505\">desert rocks</a>, but is not equivalent to an OR gate implemented in any of those media &mdash; is <em>enormous</em>. Therefore, Solomonoff induction tells us that we should assign vanishingly low probability to such a hypothesis.</p>\n<p>&nbsp;</p>\n<p>I hope that I've fairly represented the views of at least a majority of computationalists on LW. If you think there's another position available, or if you're one of the people I've called out by name and you think I've pigeonholed you incorrectly, please explain yourself.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rEQmyCZHtdsXwq3xh", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 18, "baseScore": 7, "extendedScore": null, "score": 7.022341889740325e-07, "legacy": true, "legacyId": "6786", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Yesterday, as a followup to <a href=\"/lw/57e/we_are_not_living_in_a_simulation\">We are not living in a simulation</a>, I posted <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/\">Eight questions for computationalists</a> in order to obtain a better idea of what exactly my computationalist critics were arguing.&nbsp; These were the questions I asked:</p>\n<blockquote><ol>\n<li>As it is used in the sentence \"consciousness is really just computation\", is computation:<br>a) Something that an abstract machine does, as in \"No oracle Turing machine can compute a decision to its own halting problem\"?<br>b) Something that a concrete machine does, as in \"My calculator computed 2+2\"?<br>c) Or, is this distinction nonsensical or irrelevant?</li>\n<li>If you answered \"a\" or \"c\" to question 1: is there any particular model, or particular class of models, of computation, such as Turing machines, register machines, lambda calculus, etc., that needs to be used in order to explain what makes us conscious? Or, is any Turing-equivalent model equally valid?</li>\n<li>If you answered \"b\" or \"c\" to question 1: unpack what \"the machine computed 2+2\" means. What is that saying about the physical state of the machine before, during, and after the computation?</li>\n<li>Are you able to make any sense of the concept of \"computing red\"? If so, what does this mean?</li>\n<li>As far as consciousness goes, what matters in a computation: functions, or algorithms? That is, does any computation that give the same outputs for the same inputs feel the same from the inside (this is the \"functions\" answer), or do the intermediate steps matter (this is the \"algorithms\" answer)?</li>\n<li>Would an <em>axiomatization</em> (as opposed to a complete exposition of the implications of these axioms) of a Theory of Everything that can explain consciousness include definitions of any computational devices, such as \"and gate\"?</li>\n<li>Would an axiomatization of a Theory of Everything that can explain consciousness mention qualia?</li>\n<li>Are all computations in some sense conscious, or only certain kinds?</li>\n</ol></blockquote>\n<p>I got some interesting answers to these questions, and from them I can extract three distinct positions that seem consistent to me.</p>\n<p><strong id=\"Consistent_Position__1__Qualia_skepticism\">Consistent Position #1: Qualia skepticism<br></strong></p>\n<p>Perplexed asserted this position in <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x97\">no uncertain terms</a>.&nbsp; Here's my unpacking of it:</p>\n<p>\"Qualia do not exist. The things that you're confused about and are mistaking for qualia can be made clear to you using an argument phrased in terms of computation.&nbsp; When you talk about consciousness, I think I can understand your meaning, but you aren't referring to anything fundamental or particularly well defined: it's an <a href=\"/lw/tc/unnatural_categories/\">unnatural category</a>.\"</p>\n<p>The <em>internal</em> logic of the qualia skeptic's position makes sense to me, and I can't really respond to it other than by expressing personal incredulity. To me, the empirical evidence in support of the existence of qualia is so clear and so immediate that I can't figure out what you're not seeing so that I can point to it.&nbsp; However, I shouldn't need to bring you to your senses (literally!) on this in order to convince you to reject Bostrom's simulation argument, albeit on grounds completely different than any I've argued so far.&nbsp; If you don't buy that there's anything fundamental behind consciousness, then you also shouldn't buy Bostrom's anthropic reasoning in which he conjures up the reference class of \"observers with human-type experiences\"; elsewhere he refers to \"conscious experience\" and \"subjective experience\" without implication that he means anything more specific. That's taking an unnatural category and invoking it <a href=\"/lw/td/magical_categories/\">magically</a>. In the statement that we are something selected with uniform probability from that group, how do you make sense of \"are\"?</p>\n<p><strong id=\"Consistent_Position__2__Computation_is_implicit_in_physics\">Consistent Position #2: Computation is implicit in physics</strong></p>\n<p>This position is my best attempt at a synthesis of what <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x88\">TheOtherDave</a>, <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x75\">lessdazed</a>, and <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x6y\">prase</a> are getting at. It's compatible with position #1, but neither one entails the other.</p>\n<p>To understand this position, it is helpful, but not necessary, to define the laws of physics in terms of something like a cellular automaton. Each application of the automaton's update rule can be understood as a primitive operation in a computation. When you apply the update rule repeatedly on cells nearby each other, you're building up a more complex computation. So, \"consciousness is just computation\" is equivalent in meaning, essentially, to \"consciousness is just physics\".</p>\n<p>This position more-or-less necessitates answering \"algorithms\" to question #5, or if not that then at least something similar to <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x6t\">RobinZ's answer</a>. If you say \"functions\" then you at least need to explain how to reify the concepts of \"input\" and \"output\". You can pull this off by saying that the update rules are the functions, the inputs are the state before the rule application, and the outputs are the state afterward. Any other answer probably means you're taking something closer or identical to position #3 which I'll address next. <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3xaw\">This comment</a> by peterdjones and his followups to it provide a (Searlesque) intuition pump showing other reasons why a \"functions\" reply is problematic.</p>\n<p>I have no objection to this position. However, it does not imply substrate independence, and strongly suggests its negation. If your algorithmic primitives are defined at the level of individual update-rule applications, then any change whatsoever to an object's physical structure is a change to the algorithm that it embodies. If you accept position #2 while rejecting position #1, then you may actually be making the same argument that I am, merely in different vocabulary.</p>\n<p><strong id=\"Consistent_Position__3__Computation_is_reified_by_physics\">Consistent Position #3: Computation is reified by physics</strong></p>\n<p>I was both shocked and pleased to see <a href=\"/r/discussion/lw/587/eight_questions_for_computationalists/3x6w\">zaph's answer to question #6</a>, because it bites a bullet that I never believed anyone would bite: that there is actually something fundamental in the laws of physics which defines and reifies the concept of computation in a substrate-independent fashion. I can't find any inconsistency in this, but I think we have good reason to consider it <em>extremely</em> implausible. In the language of physics which is familiar to us and has served us well \u2014 the language whose vocabulary consists of things like \"particle\" and \"force\" and \"Hilbert space\" \u2014 the Kolmogorov complexity of a definition of an equivalence relation which tells us that an AND gate implemented in a MOSFET is equivalent to an AND gate implemented in a neuron is equivalent to an AND gate implemented in <a href=\"http://xkcd.com/505\">desert rocks</a>, but is not equivalent to an OR gate implemented in any of those media \u2014 is <em>enormous</em>. Therefore, Solomonoff induction tells us that we should assign vanishingly low probability to such a hypothesis.</p>\n<p>&nbsp;</p>\n<p>I hope that I've fairly represented the views of at least a majority of computationalists on LW. If you think there's another position available, or if you're one of the people I've called out by name and you think I've pigeonholed you incorrectly, please explain yourself.</p>", "sections": [{"title": "Consistent Position #1: Qualia skepticism", "anchor": "Consistent_Position__1__Qualia_skepticism", "level": 1}, {"title": "Consistent Position #2: Computation is implicit in physics", "anchor": "Consistent_Position__2__Computation_is_implicit_in_physics", "level": 1}, {"title": "Consistent Position #3: Computation is reified by physics", "anchor": "Consistent_Position__3__Computation_is_reified_by_physics", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "183 comments"}], "headingsCount": 5}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 183, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["QnSgnKQvpv74cmgFx", "JsWd7jkeYWELtuHZc", "XeHYXXTGRuDrhk5XL", "PoDAyQMWEXBBBEJ5P"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T13:50:36.445Z", "modifiedAt": null, "url": null, "title": "Book reviews", "slug": "book-reviews", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:30.764Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PhilGoetz", "createdAt": "2009-03-01T05:11:37.246Z", "isAdmin": false, "displayName": "PhilGoetz"}, "userId": "BvoQtwkppeooDTDmh", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/6GAmcS9wBhtcfjDLF/book-reviews", "pageUrlRelative": "/posts/6GAmcS9wBhtcfjDLF/book-reviews", "linkUrl": "https://www.lesswrong.com/posts/6GAmcS9wBhtcfjDLF/book-reviews", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Book%20reviews&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABook%20reviews%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6GAmcS9wBhtcfjDLF%2Fbook-reviews%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Book%20reviews%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6GAmcS9wBhtcfjDLF%2Fbook-reviews", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F6GAmcS9wBhtcfjDLF%2Fbook-reviews", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 125, "htmlBody": "<p>I'd like to see book reviews of books of interest to LW. &nbsp;Some suggestions:</p>\n<ul>\n<li>Dan Ariely (2010). &nbsp;The Upside of Irrationality: The unexpected benefits of defying logic at work and at home.</li>\n<li>Sam Harris (2010). &nbsp;The Moral Landscape: How science can determine human values.</li>\n<li>Dan Ariely (2009). &nbsp;Predictably Irrational: The Hidden Forces That Shape Our Decisions.</li>\n<li><span style=\"font-family: arial, sans-serif; font-size: 13px; \">Timothy Harris (2010). &nbsp;The Science of Liberty: Democracy, Reason, and the Laws of Nature.</span></li>\n<li>Joel Garreau (2005). &nbsp;Radical Evolution. &nbsp;Book about genetic mods, intelligence enhancement, and the singularity.</li>\n</ul>\n<p>ADDED:&nbsp; I don't mean I'd like to see reviews in this thread.&nbsp; I'd like each review to have its own thread.&nbsp; In discussion or on the \"new\" page is up to you.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "6GAmcS9wBhtcfjDLF", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 4, "baseScore": 7, "extendedScore": null, "score": 7.022439379464803e-07, "legacy": true, "legacyId": "6799", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 3, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T16:14:21.224Z", "modifiedAt": null, "url": null, "title": "Link: Why and how to debate charitably", "slug": "link-why-and-how-to-debate-charitably", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:27.870Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/eBR5aeDwDHfiqE96e/link-why-and-how-to-debate-charitably", "pageUrlRelative": "/posts/eBR5aeDwDHfiqE96e/link-why-and-how-to-debate-charitably", "linkUrl": "https://www.lesswrong.com/posts/eBR5aeDwDHfiqE96e/link-why-and-how-to-debate-charitably", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Link%3A%20Why%20and%20how%20to%20debate%20charitably&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALink%3A%20Why%20and%20how%20to%20debate%20charitably%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeBR5aeDwDHfiqE96e%2Flink-why-and-how-to-debate-charitably%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Link%3A%20Why%20and%20how%20to%20debate%20charitably%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeBR5aeDwDHfiqE96e%2Flink-why-and-how-to-debate-charitably", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FeBR5aeDwDHfiqE96e%2Flink-why-and-how-to-debate-charitably", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 495, "htmlBody": "<p>Even though this was written by a current Less Wrong poster (hi, pdf23ds!), I don't think it has been posted here: <span style=\"text-decoration: underline;\">Why and how to debate charitably</span> (<span style=\"text-decoration: underline;\">pg. 2</span>, <span style=\"text-decoration: underline;\">comments</span>). <em>(Edit: The original pdf23ds.net site has sadly been lost to entropy &ndash; Less Wrong poster MichaelBishop found <a title=\"Why and How to Debate Charitably\" href=\"http://commonsenseatheism.com/?p=15703\">a repost on commonsenseatheism.com</a>. He also provides <a title=\"Why and How to Debate Charitably (summary)\" href=\"http://permut.wordpress.com/2009/09/29/why-and-how-to-debate-charitably/\">this summary version</a>.)</em></p>\n<p>I was linked to this article from a webcomic forum which had a low-key flamewar smouldering in the \"Serious Business\" section. (I will not link to it here; if you can tell from the description which forum it is, I would thank you not to link it either.) Three things struck me about it:</p>\n<ol>\n<li>I have been operating under similar rules for years, with great success.</li>\n<li>The participants in the flamewar on the forum where it was posted were <em>not</em>&nbsp;operating under these rules.</li>\n<li>Less Wrong posters generally <em>do</em>&nbsp;operate under these rules, at least here.</li>\n</ol>\n<p>The list of rules is on pg. 2 - a good example is the rule titled \"You cannot read minds\":</p>\n<blockquote>\n<p>As soon as you find someone espousing seemingly contradictory positions, you should immediately suspect yourself of being mistaken as to their intent. Even if it seems obvious to you that the person has a certain intent in their message, if you want to engage them, you must respond being open to the possibility that where you see contradictions (or, for that matter, insults), none were intended. While you keep in mind what the person&rsquo;s contradictory position seems to be, raise your standards some, and ask questions so that the person must state the position more explicitly&mdash;this way, you can make sure whether they actually hold it. If you still have problems, keep raising your standards, and asking more specific questions, until the person starts making sense to you.</p>\n<p>If part of their position is unclear or ambiguous to you, say that explicitly. Being willing to show uncertainty is an excellent way to defuse the person&rsquo;s, and your own, defensiveness. It also helps them to more easily understand which aspects of their position they are not making clear enough.</p>\n<p>The less their position makes sense to you, the more you should rely on interrogative phrase and the less on declarative. Questions defuse defensiveness and are much more pointed and communicative than statements, because they force you to think more about the person&rsquo;s arguments, and to really articulate what it about their position you most need clarification on. They help to keep the discussion moving, and help you to stop arguing past each other. Phrase the questions sincerely, and use as much of the person&rsquo;s own reasoning (putting in the best light) as you can. This requires that you have a pretty good grasp on what the person is arguing&mdash;try to understand their position as well as you can. If it&rsquo;s simply not coherent enough, the case may be hopeless.</p>\n</blockquote>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "eBR5aeDwDHfiqE96e", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 18, "extendedScore": null, "score": 7.022846188507508e-07, "legacy": true, "legacyId": "6801", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 14, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 12, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T16:20:53.424Z", "modifiedAt": null, "url": null, "title": "The Bias You Didn't Expect", "slug": "the-bias-you-didn-t-expect", "viewCount": null, "lastCommentedAt": "2019-05-10T01:36:58.438Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psychohistorian", "createdAt": "2009-04-05T18:10:22.976Z", "isAdmin": false, "displayName": "Psychohistorian"}, "userId": "mAQgf4N8jv2jTMK5B", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/L8dB6yoMEWofoeDNt/the-bias-you-didn-t-expect", "pageUrlRelative": "/posts/L8dB6yoMEWofoeDNt/the-bias-you-didn-t-expect", "linkUrl": "https://www.lesswrong.com/posts/L8dB6yoMEWofoeDNt/the-bias-you-didn-t-expect", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20Bias%20You%20Didn't%20Expect&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20Bias%20You%20Didn't%20Expect%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL8dB6yoMEWofoeDNt%2Fthe-bias-you-didn-t-expect%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20Bias%20You%20Didn't%20Expect%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL8dB6yoMEWofoeDNt%2Fthe-bias-you-didn-t-expect", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FL8dB6yoMEWofoeDNt%2Fthe-bias-you-didn-t-expect", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 573, "htmlBody": "<p><span style=\"font-family: Arial, Helvetica, sans-serif; line-height: 19px;\"> </span></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">There are few places where society values rational, objective decision making as much as it values it in judges. While there is a rather cynical discipline called&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://en.wikipedia.org/wiki/Legal_realism\">legal realism</a>&nbsp;that says the law is really based on quirks of individual psychology, \"what the judge had for breakfast,\" there's a broad social belief that the decision of judges are unbiased. And where they aren't unbiased, they're biased for Big, Important, Bad reasons, like&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://www.freakonomics.com/2008/01/30/can-bail-bond-dealers-reduce-discrimination-a-guest-post/\">racism</a>&nbsp;or classism or politics.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">It turns out that legal realism is totally wrong. It's not what the judge had for breakfast. It's&nbsp;<em style=\"font-style: italic;\">how recently</em>&nbsp;the judge had breakfast. A&nbsp;<a style=\"color: #6a8a6b; text-decoration: underline;\" href=\"http://www.pnas.org/content/early/2011/03/29/1018033108\">a new study</a>&nbsp;(<a href=\"http://www.miller-mccune.com/legal-affairs/judges-decisions-more-lenient-after-lunch-30179/\">media coverage</a>) on Israeli judges shows that, when making parole decisions, they grant about 65% after meal breaks, and almost all the way down to 0% right before breaks and at the end of the day (i.e. as far from the last break as possible). There's a relatively linear decline between the two points.<a id=\"more\"></a></p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">Think about this for a moment. A tremendously important decision, determining whether a person will go free or spend years in jail, appears to be substantially determined by an arbitrary factor. Also, note that we don't know if it's the lack of food, the anticipation of a break, or some other factor that is responsible for this.&nbsp;More interestingly, we don't know where the optimal result occurred. It's probably not the near 0% at the end of each work period. But is it the post-break high of 65%? Or were judges being too nice? We know there was bias, but we still don't know when bias occurred.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">There are at least two lessons from this. The little, obvious one is to be aware of one's own physical limitations. Avoid making big decisions when tired or hungry - though this doesn't mean you should try to make decisions right after eating. For particularly important decisions, consider contemplating them at different times, if you can. Think about one thing Monday morning, then Wednesday afternoon, then Saturday evening, going only to the point of getting an overall feel for an answer, and not to the point of really making a solid conclusion. Take notes, and then compare them. This may not work perfectly, but it may help you realize inconsistencies, which could help. For big questions, the wisdom of crowds may be helpful - unless it's been a while since most of the crowd had breakfast.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">The bigger lesson is one of humility. This provides rather stark evidence that our decisions are not under our control to the extent we believe. We can be influenced by factors we don't even suspect. Even knowing we have been biased, we may still be unable to identify what the correct answer was. While using formal rules and logic may be one of the best approaches to minimizing such errors, even formal rules can fail when applied by biased agents. The biggest, most condemnable biases - like racism - are in some ways less dangerous, because we know we need to look out for them. It's the bias you don't even suspect that can get you. The authors of the study think they basically got lucky with these results - if the effect had been to make decisions arbitrary rather than to increase rejections, this would not have shown up.</p>\n<p style=\"margin-top: 0px; margin-right: 0px; margin-bottom: 1em; margin-left: 0px;\">When those charged with making impartial decisions that control people's lives are subject to arbitrary forces they never suspected, it shows how important it is and much more we can do to be less wrong.&nbsp;</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"4R8JYu4QF2FqzJxE5": 1, "YTCrHWYHAsAD74EHo": 1, "FkzScn5byCs9PxGsA": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "L8dB6yoMEWofoeDNt", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 101, "baseScore": 131, "extendedScore": null, "score": 0.000247, "legacy": true, "legacyId": "6802", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 131, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 92, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 7, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T18:38:03.459Z", "modifiedAt": null, "url": null, "title": "First Phoenix, AZ Less Wrong Meetup 4/17 from 12-2pm", "slug": "first-phoenix-az-less-wrong-meetup-4-17-from-12-2pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:29.326Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Danny_Hintze", "createdAt": "2010-12-04T23:01:40.826Z", "isAdmin": false, "displayName": "Danny_Hintze"}, "userId": "2fHm6t2WFDMPShg5b", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/d7SKdhmaKNGwRTY3i/first-phoenix-az-less-wrong-meetup-4-17-from-12-2pm", "pageUrlRelative": "/posts/d7SKdhmaKNGwRTY3i/first-phoenix-az-less-wrong-meetup-4-17-from-12-2pm", "linkUrl": "https://www.lesswrong.com/posts/d7SKdhmaKNGwRTY3i/first-phoenix-az-less-wrong-meetup-4-17-from-12-2pm", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%20Phoenix%2C%20AZ%20Less%20Wrong%20Meetup%204%2F17%20from%2012-2pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%20Phoenix%2C%20AZ%20Less%20Wrong%20Meetup%204%2F17%20from%2012-2pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd7SKdhmaKNGwRTY3i%2Ffirst-phoenix-az-less-wrong-meetup-4-17-from-12-2pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%20Phoenix%2C%20AZ%20Less%20Wrong%20Meetup%204%2F17%20from%2012-2pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd7SKdhmaKNGwRTY3i%2Ffirst-phoenix-az-less-wrong-meetup-4-17-from-12-2pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fd7SKdhmaKNGwRTY3i%2Ffirst-phoenix-az-less-wrong-meetup-4-17-from-12-2pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 156, "htmlBody": "<p><a id=\"more\"></a>Many of my friends and I are frequent readers of Less Wrong and aspiring rationalists, and we'd like to get to know anyone else in the area who is interested in getting together to make the world a little brighter. Absolutely anyone is welcome! (Even if you want to make the world darker, that certainly makes for some interesting discussion!).&nbsp;</p>\n<p>I will be at a table near the&nbsp;Starbucks&nbsp;in the ASU Memorial Union from 12 to 2 pm. I'll probably be wearing a bright orange shirt, will have a Less Wrong sign of some kind, and will likely be reading some economics.&nbsp;</p>\n<p>There are many places in the MU where we can get food and drinks, and also plenty of places to sit and talk.&nbsp;</p>\n<p>The address is&nbsp;<span style=\"border-collapse: collapse; font-family: arial, sans-serif; line-height: 15px; -webkit-border-horizontal-spacing: 2px; -webkit-border-vertical-spacing: 2px;\">1290 S Normal Ave,&nbsp;</span><span style=\"border-collapse: collapse; font-family: arial, sans-serif; line-height: 15px; -webkit-border-horizontal-spacing: 2px; -webkit-border-vertical-spacing: 2px;\">Tempe, AZ 85281, and&nbsp;<a title=\"here\" href=\"http://maps.google.com/maps/mm?ie=UTF8&amp;hl=en&amp;ll=33.417866,-111.934124&amp;spn=0.003739,0.005466&amp;z=18\">here</a>&nbsp;is a map centered on it. Parking in the ASU garages is free on Sundays.&nbsp;</span></p>\n<p><span style=\"border-collapse: collapse; font-family: arial, sans-serif; line-height: 15px; -webkit-border-horizontal-spacing: 2px; -webkit-border-vertical-spacing: 2px;\">My phone number is 602-501-9420, feel free to call or text me.&nbsp;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "d7SKdhmaKNGwRTY3i", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 7, "extendedScore": null, "score": 7.023250154162761e-07, "legacy": true, "legacyId": "6803", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T18:56:55.856Z", "modifiedAt": null, "url": null, "title": "Confused about the doomsday argument, please help", "slug": "confused-about-the-doomsday-argument-please-help", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:28.535Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "cousin_it", "createdAt": "2009-03-26T19:57:07.970Z", "isAdmin": false, "displayName": "cousin_it"}, "userId": "Ht6GLzmaxbXmR6fgy", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/ovLnz3STzDyJ8XTaB/confused-about-the-doomsday-argument-please-help", "pageUrlRelative": "/posts/ovLnz3STzDyJ8XTaB/confused-about-the-doomsday-argument-please-help", "linkUrl": "https://www.lesswrong.com/posts/ovLnz3STzDyJ8XTaB/confused-about-the-doomsday-argument-please-help", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Confused%20about%20the%20doomsday%20argument%2C%20please%20help&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AConfused%20about%20the%20doomsday%20argument%2C%20please%20help%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FovLnz3STzDyJ8XTaB%2Fconfused-about-the-doomsday-argument-please-help%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Confused%20about%20the%20doomsday%20argument%2C%20please%20help%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FovLnz3STzDyJ8XTaB%2Fconfused-about-the-doomsday-argument-please-help", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FovLnz3STzDyJ8XTaB%2Fconfused-about-the-doomsday-argument-please-help", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 199, "htmlBody": "<p>The <a href=\"http://en.wikipedia.org/wiki/Doomsday_argument\">doomsday argument</a> says I have only a 10% chance of being within the first 10% of humans ever born, which gives nonzero information about when humanity will end. The argument has some problems with the choice of reference class; my favorite formulation (invented by me, I'm not sure if it's well-known) is to use the recursive reference class of \"all people who are considering the doomsday argument with regard to humanity\". But this is not the issue I want to discuss right now.</p>\n<p>Imagine your prior says the universe can contain 10, 1000 or 1000000 humans, with probability arbitrarily assigned to these three options. Then you learn that you're the 50th human ever born. As far as I can understand, after receiving this information you're certain to be among the first 10% of humans ever born, because it's true in every possible universe where you receive such information. Also learning your index doesn't seem to tell you very much about the date of the doomsday: it doesn't change the relative probabilities of doomsday dates that are consistent with your existence. (This last sentence is true for any prior, not just the one I gave.) Is there something I'm missing?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "ovLnz3STzDyJ8XTaB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 11, "extendedScore": null, "score": 2.1e-05, "legacy": true, "legacyId": "6804", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T19:55:04.308Z", "modifiedAt": null, "url": null, "title": "Brief Query- An Idea", "slug": "brief-query-an-idea", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.097Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Carinthium", "createdAt": "2010-11-10T22:28:58.091Z", "isAdmin": false, "displayName": "Carinthium"}, "userId": "DL8CRWfXPCHYqQsv4", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/BSTCFQMqxoyRKCpY7/brief-query-an-idea", "pageUrlRelative": "/posts/BSTCFQMqxoyRKCpY7/brief-query-an-idea", "linkUrl": "https://www.lesswrong.com/posts/BSTCFQMqxoyRKCpY7/brief-query-an-idea", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Brief%20Query-%20An%20Idea&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABrief%20Query-%20An%20Idea%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBSTCFQMqxoyRKCpY7%2Fbrief-query-an-idea%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Brief%20Query-%20An%20Idea%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBSTCFQMqxoyRKCpY7%2Fbrief-query-an-idea", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FBSTCFQMqxoyRKCpY7%2Fbrief-query-an-idea", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 179, "htmlBody": "<p>I had an idea- has it been done before, and if not shouldn't somebody try to do it? I live in Melbourne where LWers aren't organised, but perhaps the New York branch or some other group could try this? (IF it hasn't been done, that is-&nbsp;I haven't seen in mentioned, which is why I'm checking)</p>\n<p><strong>Idea:</strong></p>\n<p>-Recruit a non-rationalist scientist (or better group of scientists) either by persuading friends or perhaps getting some money together to pay somebody (or finding a helpful volenteer) or perhaps several.</p>\n<p>-Have THEM come up with a series of tests to test rationalists relative to a control group.</p>\n<p>If 'sucessful' (in the sense of a significant difference between rationalists and non-rationalists, the result we on LW would presumably predict), it would provide enough evidence to justify a formal test (there would likely be a few weaknesses, such as recruiting friends of rationalists), which could then (again, assuming such&nbsp;a result) persuade scientists to become rationalists (benefits should be obvious on a bit of thought)&nbsp;and generate publicity. If a 'failure' or indecisive, it justifies a serious reevaluation of site methodology.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "BSTCFQMqxoyRKCpY7", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 14, "extendedScore": null, "score": 7.023466665148468e-07, "legacy": true, "legacyId": "6805", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 11, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-14T22:41:11.657Z", "modifiedAt": null, "url": null, "title": "Say More, Justify Less", "slug": "say-more-justify-less", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:58.304Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "paulfchristiano", "createdAt": "2010-07-28T17:04:08.586Z", "isAdmin": false, "displayName": "paulfchristiano"}, "userId": "gb44edJjXhte8DA3A", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/8vycE3jL6jtHrqyGr/say-more-justify-less", "pageUrlRelative": "/posts/8vycE3jL6jtHrqyGr/say-more-justify-less", "linkUrl": "https://www.lesswrong.com/posts/8vycE3jL6jtHrqyGr/say-more-justify-less", "postedAtFormatted": "Thursday, April 14th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Say%20More%2C%20Justify%20Less&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASay%20More%2C%20Justify%20Less%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8vycE3jL6jtHrqyGr%2Fsay-more-justify-less%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Say%20More%2C%20Justify%20Less%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8vycE3jL6jtHrqyGr%2Fsay-more-justify-less", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F8vycE3jL6jtHrqyGr%2Fsay-more-justify-less", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2206, "htmlBody": "<p><strong>Related to:</strong> <a href=\"/lw/36/rational_me_or_we/\">Rational Me or We</a>?<br /><br />Human brains reach decisions using complicated, often opaque, mechanisms. Rational behavior requires learning about systematic failures of these mechanisms, but also requires learning to effectively use judgments for which our brains provide no communicable justification. If we cannot trust our brains just because we don't understand them, our beliefs will be too slow to follow reality. This is a critically important lesson for individual rationality, but there is an even more important analog for collective rationality.<br /><br /><a href=\"http://en.wikipedia.org/wiki/Aumann%27s_agreement_theorem\">Aumann's agreement theorem</a> provides conditions under which rationalists cannot agree to disagree. This result is often cited to justify protracted arguments regarding contentious facts. These arguments generally proceed as an exchange of well-specified evidence and reasoned justification. Aumann's agreement theorem says nothing about the effectiveness of such exchanges, and in my experience such arguments almost always end either quickly or unsuccessfully. <br /><br />Why don't rational arguments end well? Sometimes our beliefs depend on a few pieces of easily identified evidence, but often they depend on the balance of a large quantity of (potentially forgotten) evidence colored by our experience and aggregated using intuition. Sometimes our beliefs depend on simple easily articulated deductions, but often they depend on subtle inferences we don't consciously understand. Arguments fail because the real sources of our beliefs cannot be easily communicated, or even well understood. If we rely only on reasoning and evidence that can be communicated in clean and conclusive arguments, our beliefs will be too slow to follow reality.<br /><br />Why can't we reach agreement by updating on the beliefs of others, as per Aumann's theorem? Why do we need to describe how we arrived at our beliefs, instead of simply stating them? In fact in ordinary conversation no one even tries to use Aumann-style negotiation, and from my perspective this seems completely rational. Even when talking to people whose rationality I trust, assuming common knowledge of rationality or honesty is never close to accurate; if we abandon skepticism we can expect to be consistently wrong (even when we aren't deliberately manipulated). <br /><br />The real sources of our belief are hard to communicate and we aren't sufficiently perfect rationalists to use Aumann agreement: if we want to reach rational consensus, we need to do some work. <a id=\"more\"></a><br /><br />In what cases <em>should</em> we be able to agree? I am not surprised, for example, that Robin Hanson and Eliezer Yudkowsky <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">cannot reconcile their beliefs</a> about the future of AIs / emulations: there is little available evidence regarding the reliability of anyone's predictions about the distant future. But when an organization or society is repeatedly faced with questions about the near future it is possible to learn which individual's beliefs are trustworthy, and to reach rational consensus, without relying on perfect rationality. I believe that this problem should be a priority for a rational organization. <br /><strong><br />First: How?</strong><br /><br />A. Commit to precise predictions. <br /><br />Individuals should commit to predictions about everything which matters to the organization and is amenable to prediction. Estimate quantitative measures of the success of a program, of demand for a service, of future revenue, of future income from donations, of relevant political changes, etc.. Make predictions quickly and publicly, update on the predictions of others, and experiment with trusting different intuitions. <br /><br />B. Track prediction quality.<br /><br />Minimally, we would like the beliefs of an organization to be as good as the beliefs of its best member. Don't just have members state predictions: measure their success as well. Use scoring rules to distribute trust to the most trustworthy agents. Record-keeping doesn't need to be inefficient; make it fast, cultivate an atmosphere of keeping score and committing to errors, and build a record which can help individuals improve their own calibration and learn how they should be updating on the beliefs of others. Incentivize accurate prediction. Concentrate authority where it has been empirically effective, or where trusted group members predict it to be effective. <br /><br />Require predictors to stake part of their reputation on predictions. The best scheme I know is Hanson's market scoring rule, which rewards or punishes predictors based on their contribution to the collective probability estimate. When predictors need incentives, real or play money can be used to incentivize accuracy. When predictors are rationally interested in the success of the group, purely artificial reputation systems may be enough. In any case, disagreement is still possible. But if disagreements are frequent and pronounced and there is any difference in prediction quality, the difference will rapidly manifest itself in a difference of reputation (and if there is no difference, then by convexity an average of the two disagreeing predictors will outperform either and this fact will rapidly become common knowledge).<br /><br />C. Chain prediction mechanisms to obtain faster feedback.<br /><br />When an expensive prediction mechanism is available, use a cheaper prediction mechanism to predict the output of the expensive mechanism. This can provide more rapid feedback, and allow accurate predictions for much broader classes of events. For example:<br /><br />If I want to estimate the success of an advertising campaign or interface design choice, implementing it and then measuring the success of the overall program is expensive. Carefully implemented focus groups or A/B tests can predict the ultimate success of a choice; once the predictive power of such tests is established, the results of those tests can be predicted instead of the eventual success of the project. This may provide much faster feedback. Continuing recursively, we may learn that certain individuals are good at predicting the outcome of a focus group or A/B test. Peers can then predict the prediction of these individuals. This gives even faster feedback, and can free up time for that individual. Since the attention of people with accurate beliefs and good planning skills is very important, this is an important consideration.<br /><br />D. Substitute testable assertions.<br /><br />Sometimes we are interested in vague or otherwise problematic assertions, such as \"In a year, you'll regret this decision.\" When its important, choose related precise statements that are amenable to formal prediction. Some examples:<br /><br />Choose a trusted observer and a future time, and bet about the judgment of that observer in hindsight. For example, rather than betting on whether \"50% of humans will use social networks regularly in 10 years\", choose a knowledgable arbiter, offer them a moderate incentive to cooperate, and bet on whether they would agree with the statement \"50% of humans use social networks regularly\" in 10 years. <br /><br />Imagine a possible outcome with precisely defined observable consequences, and make bets conditional on the realization of that outcome. For example, maybe it will only be clear whether or not the building is structurally sound if someone conducts a formal investigation. Then instead of betting on \"The building foundation meets this standard\", bet on \"If the building foundation is formally investigated, it will be found to meet this standard.\"<br /><br />Find other concrete markers--polls, surveys, price movements, financial outcomes, etc.--that corellate with the event in question and predict them instead. <br /><br />E. Put a price on ideas. <br /><br />The success of a proposed change--whether a new program, or a structural change--can be predicted as well as anything else. Such predictions can be used to estimate the value (in money, play money, reputation) of a new proposal and reward or penalize individuals for their contribution. This may incentivize members if that is needed, but more importantly it allows the organization to intelligently trade-off the time required to dismiss or test bad changes against the benefit of good changes. The judgment of whoever implements change can provide the feedback needed to train correct predictions about the value of a proposed change (see C above); allowing more organization members to engage in such predictions can conserve the time and attention of authority.&nbsp; <br /><br />Once such predictions are accurate, ideas can be aggregated (as natural language proposals) automatically, and most proposals can be discarded without explicit discussion or significant time investment. Serious deliberation is only necessary for the ideas which are predicted to be most likely to be worth considering. <br /><strong><br />Second: Technical facts.</strong><br /><br />A. <a href=\"http://en.wikipedia.org/wiki/Scoring_rule\">Proper scoring rules. </a><br /><br />A scoring rule takes as arguments a predicted probability distribution and an actual outcome and outputs a score. A scoring rule is proper if honestly reporting your best estimate of the real probability distribution maximizes your expected score. A typical scoring rule with desirable properties is the logarithm of the probability assigned by the distribution to the actual outcome. A score of 0 is attained by exactly predicting the result. A score of log n is attained by the uniform distribution over n outcomes. Other scoring rules may be appropriate, depending on the consequences of an incorrect prediction. <br /><br />B. <a href=\"http://hanson.gmu.edu/mktscore.pdf\">Market scoring rules.</a><br /><br />A scoring rule evaluates the quality of a single prediction. Robin Hanson has proposed market scoring rules to evaluate several individual's contributions to a collective probability distribution. A market scoring rule works as follows: the collective probability distribution is initialized to a reasonable estimate, and any group member can modify the collective estimate at any time. When the prediction is resolved, each person who changed the probability distribution is rewarded or punished by the difference between the score associated to the probability distribution which they proposed and the score associated to the probability distribution which they replaced. Market scoring rules can be simulated with a prediction market with an automated market maker (an artificial market participant who always offers to buy/sell at a price determined by the history of trades).<br /><br />C. <a href=\"http://www.cs.princeton.edu/~arora/pubs/MWsurvey.pdf\">Multiplicative Weights</a> / Exp3<br /><br />When consulting a group of experts (or choosing from among several possible strategies) a mathematically robust strategy is given by multiplicative weights (or Exp3): choose an advisor at random with probability proportional to a quantitative estimate of their reputation, and adjust the reputation of each expert by an amount proportional to the impact of that expert's advice on your expected performance. This technique does about as well as the best expert, neglecting rare extremely bad or extremely good outcomes. <br /><strong><br />Third: Why Bother?</strong><br /><br />How important is rational agreement? Why can't we use traditional organizational designs to make decisions in the absence of consensus, or arrive at consensus by more traditional mechanisms? My belief is that traditional structures do not result in rational behavior, in the same way that relying exclusively on human intuition does not result in rational behavior. Traditional organizations rely too extensively on the beliefs of upper management, they cannot make important decisions or implement change quickly because of a lack of elite attention, they fail to aggregate information about their own behavior, they fail to match the best beliefs of their constituents about important questions of fact, and they fail to encourage or select for rational behavior among their constituents. The sources my belief are complicated and hard to explain. Here are some words which might help others arrive at similar conclusions: <br /><br />I do not consider the non-adaptation of modern organizations compelling evidence because I have little faith in their rational behavior (circularly). I do not consider the non-adaptation of managers compelling evidence because I have little faith in the ability of most individuals to enact significant change, especially in the face of considerable organizational and social inertia. I do not consider anything from the academic literature in this field relevant, because it appears to suffer from persistently irrational methodology and general uselessness. I believe that intelligence and rationality vary remarkably even among elites, and do not accept the weak efficient market hypothesis applied to entrepreneurial endeavors because it seems to be obviously false. I have excellent evidence for the collective irrationality of society as a whole, and of historical institutions. I believe that I have little similar evidence for modern corporations only because I know more about history (and the details of most modern corporations are opaque to me). From my limited evidence, modern corporations do also behave irrationality: they fail to even hold collective beliefs on critical questions, their decisions are determined by artifacts of their authority structure, and they remain successful despite the existence of significant corrections to their behavior (I know two or three case studies, none of which I should discuss publicly; I only have any evidence at all because of indirect connections to management). If I abandon typical arguments for the efficacy of modern corporations, the sum of evidence against it is compelling. I put considerable weight on the beliefs of Robin Hanson, who has said many true and uncommon things and really does seem to update on the beliefs of others.<br /><br />But I think the best argument is: I am willing to stake a lot of money on the belief that rational organizations, in the sense I describe, can consistently out-compete traditional organizations. Is anyone interested in betting against me?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "8vycE3jL6jtHrqyGr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 20, "baseScore": 27, "extendedScore": null, "score": 7.023933728339999e-07, "legacy": true, "legacyId": "6806", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 26, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["w9kwayt5SWqBQe8Nx"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-15T01:02:12.625Z", "modifiedAt": null, "url": null, "title": "How You Make Judgments: The Elephant and its Rider", "slug": "how-you-make-judgments-the-elephant-and-its-rider", "viewCount": null, "lastCommentedAt": "2017-06-17T04:16:02.716Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/du395YvCnQXBPSJax/how-you-make-judgments-the-elephant-and-its-rider", "pageUrlRelative": "/posts/du395YvCnQXBPSJax/how-you-make-judgments-the-elephant-and-its-rider", "linkUrl": "https://www.lesswrong.com/posts/du395YvCnQXBPSJax/how-you-make-judgments-the-elephant-and-its-rider", "postedAtFormatted": "Friday, April 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20You%20Make%20Judgments%3A%20The%20Elephant%20and%20its%20Rider&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20You%20Make%20Judgments%3A%20The%20Elephant%20and%20its%20Rider%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdu395YvCnQXBPSJax%2Fhow-you-make-judgments-the-elephant-and-its-rider%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20You%20Make%20Judgments%3A%20The%20Elephant%20and%20its%20Rider%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdu395YvCnQXBPSJax%2Fhow-you-make-judgments-the-elephant-and-its-rider", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fdu395YvCnQXBPSJax%2Fhow-you-make-judgments-the-elephant-and-its-rider", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 4037, "htmlBody": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>Whether you're doing science or philosophy, flirting or playing music, the first and most important tool you are using is your <em>mind</em>. To use your tool well, it will help to know how it works. Today we explore how your mind makes judgments.</p>\n<p>From Plato to Freud, many have remarked that humans seem to have more than one mind.<sup>1</sup>&nbsp;Today, detailed 'dual-process' models are being tested by psychologists and neuroscientists:</p>\n<blockquote>\n<p>Since the 1970s&nbsp;<em style=\"font-style: italic;\">dual-process</em>&nbsp;theories have been developed [to explain] various aspects of human psychology... Typically, one of the processes is characterized as fast, effortless, automatic, nonconscious, inflexible, heavily contextualized, and undemanding of working memory, and the other as slow, effortful, controlled, conscious, flexible, decontextualized, and demanding of working memory.<sup>2</sup></p>\n</blockquote>\n<p>Dual-process theories for reasoning,<sup>3</sup> learning and memory,<sup>4</sup>&nbsp;decision-making,<sup>5</sup>&nbsp;belief,<sup>6</sup>&nbsp;and social cognition<sup>7</sup> are now widely accepted to be correct to some degree,<sup>8</sup> with researchers currently working out the details.<sup>9</sup>&nbsp;Dual-process theories even seem to be appropriate for some nonhuman primates.<sup>10</sup></p>\n<p>Naturally, some have wondered if there might be a \"grand unifying dual-process theory that can incorporate them all.\"<sup>11</sup> We might call such theories&nbsp;<em>dual-system</em>&nbsp;theories of mind,<sup>12</sup> and several have been proposed.<sup>13</sup> Such unified theories face problems, though. 'Type 1' (fast, nonconscious) processes probably involve many nonconscious architectures,<sup>14</sup> and brain imaging studies show a wide variety of brain systems at work at different times when subjects engage in 'type 2' (slow, conscious) processes.<sup>15</sup></p>\n<p>Still, perhaps there is a sense in which one 'mind' relies mostly on type 1 processes, and a second 'mind' relies mostly on type 2 processes. One suggestion is that Mind 1 is evolutionarily old and thus shared with other animals, while Mind 2 is recently evolved and particularly developed in humans. (But not <em>fully unique</em>&nbsp;to humans, because some animals do seem to exhibit a distinction between stimulus-controlled and higher-order controlled behavior.<sup>16</sup>) But this theory faces problems.&nbsp;A standard motivation for dual-process theories of reasoning is the conflict between cognitive biases (from type 1 processes) and logical reasoning (type 2 processes).<sup>17</sup> For example, logic and <a href=\"http://en.wikipedia.org/wiki/Belief_bias\">belief bias</a> often conflict.<sup>18</sup> But both logic and belief bias can be located in the pre-frontal cortex, an evolutionarily <em>new</em> system.<sup>19&nbsp;</sup>So either Mind 1 is not entirely old, or Mind 2 is not entirely composed of type 2 processes.</p>\n<p>We won't try to untangle these mysteries here. Instead, we'll focus on one of the most successful dual-process theories: Kahneman and Frederick's dual-process theory of judgment.<sup>20</sup></p>\n<p><a id=\"more\"></a></p>\n<h4><br /></h4>\n<h4>Attribute substitution</h4>\n<p>Kahneman and Frederick propose an \"attribute-substitution model of heuristic judgment\" which claims that judgments result from both type 1 and type 2 processes.<sup>21</sup> The authors explain:</p>\n<blockquote>\n<p>The early research on judgment heuristics was guided by a simple and general hypothesis: When confronted with a difficult question, people may answer an easier one instead and are often unaware of the substitution. A person who is asked \"What proportion of long-distance relationships break up within a year?\" may answer as if she had been asked \"Do instances of failed long-distance relationships come readily to mind?\" This would be an application of the availability heuristic. A professor who has heard a candidate&rsquo;s job talk and now considers the question \"How likely is it that this candidate could be tenured in our department?\" may answer the much easier question: \"How impressive was the talk?\" This would be an example of one form of the representativeness heuristic.<sup>22</sup></p>\n</blockquote>\n<p>Next: what is attribute substitution?</p>\n<blockquote>\n<p>...whenever the aspect of the judgmental object that one intends to judge (the <em>target attribute</em>) is less readily assessed than a related property that yields a plausible answer (the <em>heuristic attribute</em>), individuals may unwittingly substitute the simpler assessment.<sup>22</sup></p>\n</blockquote>\n<p>For example, one study<sup>23</sup> asked subjects two questions among many others: \"How happy are you with your life in general?\" and \"How many dates did you have last month?\" In this order, the correlation between the two questions was negligible. If the dating question was asked first, however, the correlation was .66. The question about dating frequency seems to evoke \"an evaluation of one's romantic satisfaction\" that \"lingers to become the heuristic attribute when the global happiness question is subsequently encountered.\"<sup>22</sup></p>\n<p>Or, consider a question in another study: \"If a sphere were dropped into an open cube, such that it just fit (the diameter of the sphere is the same as the interior width of the cube), what proportion of the volume of the cube would the sphere occupy?\"<sup>24</sup>&nbsp;The target attribute (the volumetric relation between cube and sphere) is difficult to assess intuitively, and it appears that subjects sought out an easier-to-assess heuristic attribute instead, substituting the question \"If a <em>circle</em>&nbsp;were drawn inside a <em>square</em>, what proportion of the <em>area</em>&nbsp;of the square does the circle occupy?\" The mean estimate for the 'sphere inside cube' problem was 74%, almost identical to the mean estimate of the 'circle inside square' problem (77%) but far larger than the correct answer for the 'sphere inside cube' problem (52%).</p>\n<p>Attribution substitutions like this save on processing power but introduce systematic biases into our judgment.<sup>25</sup></p>\n<p>Some attributes are always candidates for the heuristic role in attribute substitution because they play roles in daily perception and cognition and are thus always accessible: cognitive fluency, causal propensity, surprisingness, mood, and affective valence.<sup>26</sup> Less prevalent attributes can become accessible for substitution if recently evoked or primed.<sup>27</sup>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Supervision of intuitive judgments</h4>\n<p>Intuitive judgments, say Kahneman and Frederick, arise from processes like attribute substitution, of which we are unaware. They \"bubble up\" from the unconscious, after which many of them are evaluated and either endorsed or rejected by type 2 processes.</p>\n<p>You can feel the tension<sup>28</sup> between type 1 and type 2 processes in your own judgment when you try the <a href=\"http://en.wikipedia.org/wiki/Stroop_effect\">Stroop task</a>.&nbsp;Name the color of a list of colored words and you will find that you pause a bit when the word you see names a different color than the color it is written in, like this: <span style=\"color:red\">green</span>. Your unconscious, intuitive judgment uses an availability heuristic to suggest the word 'green' is shown in green, but your conscious type 2 processes quickly correct the unconscious judgment and conclude that it is written in red. You have no such momentary difficulty naming the color of this word: <span style=\"color:blue\">blue</span>.</p>\n<p>In many cases, type 2 processes have no trouble correcting the judgments of type 1 processes.<sup>29</sup> But because type 2 processes are slow, they can be interrupted by time pressure.<sup>30</sup>&nbsp;On the other hand, biased attribute substitution can sometimes be prevented if subjects are alerted to the possible evaluation contamination in advance.<sup>31</sup> (This finding justifies a great deal of material on Less Wrong, which alerts you to many <a href=\"http://wiki.lesswrong.com/wiki/Bias\">cognitive biases</a> - that is, possible sources of evaluation contamination.)</p>\n<p>Often, type 2 processes fail to correct intuitive judgments, as demonstrated time and again in the heuristics and biases literature.<sup>32</sup>&nbsp;And even when type 2 processes correct intuitive judgments, the <em>feeling</em>&nbsp;that the intuitive judgments is correct may remain. Consider the famous&nbsp;<a href=\"/lw/jj/conjunction_controversy_or_how_they_nail_it_down/\">Linda problem</a>. Knowledge of probability theory does not extinguish the&nbsp;<em style=\"font-style: italic;\">feeling</em>&nbsp;(from type 1 processes) that Linda must be a feminist bank teller. As Stephen Jay Gould put it:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>I know [the right answer], yet a little homunculus in my head continues to jump up and down, shouting at me, \"But she can&rsquo;t&nbsp;<em style=\"font-style: italic;\">just</em>&nbsp;be a bank teller; read the description!\"<sup>33</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<h4>Conclusion</h4>\n<p>Kahneman and Frederick's dual-process theory appears to be successful in explaining a wide range of otherwise puzzling phenomena in human judgment.<sup>34</sup>&nbsp;The big picture of all this is described well by Jonathan Haidt, who imagines his conscious mind as a rider upon an elephant:</p>\n<blockquote>\n<p>I'm holding the reins in my hands, and by pulling one way or the other I can tell the elephant to turn, to stop, or to go. I can direct things, but only when the elephant doesn't have desires of his own. When the elephant really wants to do something, I'm no match for him.</p>\n<p>...The controlled system [can be] seen as an advisor. It's a rider placed on the elephant's back to help the elephant make better choices. The rider can see farther into the future, and the rider can learn valuable information by talking to other riders or by reading maps, but the rider cannot order the elephant around against its will...</p>\n<p>...The elephant, in contrast, is everything else. The elephant includes gut feelings, visceral reactions, emotions, and intuitions that comprise much of the automatic system. The elephant and the rider each have their own intelligence, and when they work together well they enable the unique brilliance of human beings. But they don't always work together well.<sup>35</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/5bw/your_evolved_intuitions/\">Your Evolved Intuitions</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">Philosophy: A Diseased Discipline</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4>Notes</h4>\n<p><small><sup>1</sup> Plato divided the soul into three parts: reason, spirit, and appetite (Annas 1981, ch. 5). Descartes held that humans operate on unconscious mechanical processes we share with animals, but that humans' additional capacities for rational thought separate us from the animals (Cottingham 1992). Leibniz said that animals are guided by inductive reasoning, which also guides 'three-fourths' of human reasoning, but that humans can also partake in 'true reasoning'&nbsp;<span style=\"color: #3e3c3c; font-family: verdana, serif; font-size: 13px; line-height: 13px;\">&mdash;</span>&nbsp;logic and mathematics (Leibniz 1714/1989, p. 208; Leibniz 1702/1989, pp. 188-191). Many thinkers, most famously Freud, have drawn a division between conscious and unconscious thinking (Whyte 1978). For a more detailed survey, see Frankish &amp; Evans (2009). Multiple-process theories of mind stand in contrast to monistic theories of mind, for example:&nbsp;Johnson-Laird (1983);&nbsp;Braine (1990); Rips (1994). Note that dual-process theories of mind need not conflict with massively modular view of human cognition like Barrett &amp; Kurzban (2006) or Tooby &amp; Cosmides (1992): see Mercier &amp; Sperber (2009). Finally, note that dual-process theories sit comfortably with current research on situated cognition: Smith &amp; Semin (2004).</small></p>\n<p><small><sup>2</sup>&nbsp;Frankish &amp; Evans (2009).</small></p>\n<p><small><sup>3</sup>&nbsp;Evans (1989, 2006, 2007); Evans &amp; Over (1996); Sloman (1996, 2002); Stanovich (1999, 2004, 2009); Smolensky (1988); Carruthers (2002, 2006, 2009); Lieberman (2003; 2009); Gilbert (1999).</small></p>\n<p><small><sup>4</sup>&nbsp;Sun et al. (2009); Eichenbaum &amp; Cohen (2001); Carruthers (2006); Sherry &amp; Schacter (1987); Berry &amp; Dienes (1993); Reber (1993); Sun (2001).</small></p>\n<p><small><sup>5</sup>&nbsp;Kahneman &amp; Frederick (2002, 2005).</small></p>\n<p><small><sup>6</sup> Dennett (1978, ch. 16; 1991); Cohen (1992); Frankish (2004); Verscheuren et al. (2005).</small></p>\n<p><small><sup>7</sup>&nbsp;Smith &amp; Collins (2009); Bargh (2006); Strack &amp; Deutsch (2004).</small><span style=\"font-size: 11px;\">&nbsp;</span></p>\n<p><small><sup>8</sup> Evans (2008); Evans &amp; Frankish (2009). Or as Carruthers (2009) puts it, \"Dual-system theories of human reasoning are now quite widely accepted, at least in outline.\"</small></p>\n<p><small><sup>9</sup>&nbsp;One such detail is: When and to what extent does System 2 intervene in System 1 processes? See: Evans (2006); Stanovich (1999); De Neys (2006); Evans &amp; Curtis-Holmes (2005); Finucane et al. (2000); Newstead et al. (1992); Evans et al. (1994); Daniel &amp; Klaczynski (2006); Vadenoncoeur &amp; Markovits (1999); Thompson (2009). Other important open questions are explored in Fazio &amp; Olson (2003); Nosek (2007); Saunders (2009). For an accessible overview of the field, see Evans (2010).</small></p>\n<p><small><sup>10</sup>&nbsp;Call &amp; Tomasello (2005).</small></p>\n<p><small><sup>11</sup> Evans (2009).</small></p>\n<p><small><sup>12</sup> Dual-process and dual-system theories of the mind suggest multiple cognitive <em>architectures</em>, and should not be confused with theories of multiple <em>modes</em>&nbsp;of processing, or two kinds of <em>cognitive style</em>. One example of the latter is the supposed distinction between Eastern and Western thinking (Nisbett et al. 2001).&nbsp;Dual-process and dual-system theories of the mind should also be distinguished from theories that posit a <em>continuum</em>&nbsp;between one form of thinking and another (e.g. Hammond 1996; Newstead 2000; Osman 2004), since this suggests there are not separate cognitive architectures at work.</small></p>\n<p><small><sup>13</sup>&nbsp;Evans (2003); Stanovich (1999, 2009); Evans &amp; Over (1996); Smith &amp; DeCoster (2000); Wilson (2002).</small></p>\n<p><small><sup>14</sup> Evans (2008, 2009); Stanovich (2004); Wilson (2002).</small></p>\n<p><small><sup>15</sup> Goel (2007).</small></p>\n<p><small><sup>16</sup> Toates (2004, 2006).</small></p>\n<p><small><sup>17</sup> Evans (1989); Evans &amp; Over (1996); Kahneman &amp; Frederick (2002); Klaczynski &amp; Cottrell (2004); Sloman (1996); Stanovich (2004).</small></p>\n<p><small><sup>18</sup> Evans et al. (1983); Klauer et al. (2000).</small></p>\n<p><small><sup>19</sup>&nbsp;Evans (2009); Goel &amp; Dolan (2003).</small></p>\n<p><small><sup>20</sup> Those who prefer video lectures to reading may enjoy a 2008 lecture on judgment and intuition, to which Kahneman contributed: <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35259&amp;state=maximize#a_icb_pagecontent698262\">1</a>, <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35265&amp;state=maximize#a_icb_pagecontent698262\">2</a>, <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35267&amp;state=maximize#a_icb_pagecontent698262\">3</a>, <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35268&amp;state=maximize#a_icb_pagecontent698262\">4</a>.</small></p>\n<p><small><sup>21</sup> They use the terms 'system 1' and 'system 2' instead of 'type 1' and 'type 2'. Their theory is outlined in Kahneman &amp; Frederick (2002, 2005).</small></p>\n<p><small><sup>22</sup>&nbsp;Kahneman &amp; Frederick (2005).</small></p>\n<p><small><sup>23</sup> Strack et al. (1988).</small></p>\n<p><small><sup>24</sup> Frederick &amp; Nelson (2007).</small></p>\n<p><small><sup>25</sup> Cognitive biases particularly involved in attribute substitution include the <a href=\"http://wiki.lesswrong.com/wiki/Availability_heuristic\">availability heuristic</a> (Lichtenstein et al. 1978; Schwarz et al. 1991;&nbsp;Schwarz &amp; Vaughn 2002), the <a href=\"http://wiki.lesswrong.com/wiki/Representativeness_heuristic\">representativeness heuristic</a> (Kahneman &amp; Tversky 1973; Tversky &amp; Kahneman 1982; Bar-Hillel &amp; Neter 1993; Agnolia 1991), and the <a href=\"/lw/lg/the_affect_heuristic/\">affect heuristic</a> (Slovic et al. 2002; Finucane et al. 2000).</small></p>\n<p><small><sup>26</sup> Cognitive fluency: Jacoby &amp; Dallas (1981); Schwarz &amp; Vaughn (2002); Tversky &amp; Kahneman (1973). Causal propensity: Michotte (1963); Kahneman &amp; Varey (1990). Surprisingness: Kahneman &amp; Miller (1986). Mood: Schwarz &amp; Clore (1983). Affective valence: Bargh (1997); Cacioppo et al. (1993); Kahneman et al. (1999); Slovic et al. (2002); Zajonc (1980, 1997).</small></p>\n<p><small><sup>27</sup>&nbsp;Bargh et al. (1986); Higgins &amp; Brendl (1995). Note also that attributes must be mapped across dimensions on a common scale, and we understand to some degree the mechanism that does this: Kahneman &amp; Frederick (2005);&nbsp;Ganzach and Krantz (1990); Stevens (1975).</small></p>\n<p><small><sup>28</sup>&nbsp;Also see De Neys et al. (2010).</small></p>\n<p><small><sup>29</sup> Gilbert (1989).</small></p>\n<p><small><sup>30</sup>&nbsp;Finucane et al. (2000).</small></p>\n<p><small><sup>31</sup>&nbsp;Schwarz &amp; Clore (1983);&nbsp;Schwarz (1996).</small></p>\n<p><small><sup>32</sup>&nbsp;Gilovich et al. (2002); Kahneman et al. (1982); Pohl (2005); Gilovich (1993); Hastie &amp; Dawes (2009).</small></p>\n<p><small><sup>33</sup> Gould (1991), p. 469.</small></p>\n<p><small><sup>34</sup>&nbsp;See the overview in Kahneman &amp; Frederick (2005).</small></p>\n<p><small><sup>35</sup> Haidt (2006), pp. 4, 17.</small></p>\n<p><small>&nbsp;</small></p>\n<h4>References</h4>\n<p><small>Agnolia (1991).&nbsp;Development of judgmental heuristics and logical reasoning: Training counteracts the representativeness heuristic. <em>Cognitive Development, 6</em>: 195&ndash;217.</small></p>\n<p><small>Annas (1981). <em><a href=\"http://www.amazon.com/dp/0198274297/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">An introduction to Plato's republic</a></em>. Oxford University Press.</small></p>\n<p><small>Bar-Hillel &amp; Neter (1993).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Bar-Hillel-how-alike-is-it-versus-how-likely-is-it.pdf\">How alike is it versus how likely is it: A disjunction fallacy in probability judgments</a>. <em>Journal of Personality and Social Psychology, 41</em>: 671&ndash;680.</small></p>\n<p><small>Bargh (1997).&nbsp;The automaticity of everyday life. <em>Advances in social cognition, 10</em>. Erlbaum.</small></p>\n<p><small>Bargh,&nbsp;Bond, Lombardi, &amp; Tota (1986). The additive nature of chronic and temporary sources of construct accessibility. <em>Journal of Personality and Social Psychology, 50(5)</em>: 869&ndash;878.</small></p>\n<p><small>Bargh (2006). <em><a href=\"http://www.amazon.com/dp/184169472X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Social psychology and the unconscious</a></em>. Psychology Press.</small></p>\n<p><small>Barrett &amp; Kurzban (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Barrett-Kurzban-modularity-in-cognition-framing-the-debate.pdf\">Modularity in cognition: Framing the debate</a>. <em>Psychological Review, 113</em>: 628-647.</small></p>\n<p><small>Berry &amp; Dienes (1993). <em><a href=\"http://www.amazon.com/dp/0863772234/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Implicit learning</a></em>. Erlbaum.</small></p>\n<p><small>Braine (1990). The 'natural logic' approach to reasoning. In Overton (ed.), <em>Reasoning, necessity and logic: Developmental perspectives</em>. Psychology Press.</small></p>\n<p><small>Cacioppo, Priester, &amp; Berntson (1993). Rudimentary determinants of attitudes: II. Arm flexion and extension have differential effects on attitudes. <em>Journal of Personality and Social Psychology, 65</em>: 5&ndash;17.</small></p>\n<p><small>Call &amp; Tomasello (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Call-Tomasello-Reasoning-and-Thinking-in-Nonhuman-Primates.pdf\">Reasoning and thinking in nonhuman primates</a>. In Holyoak &amp; Morrison (eds.), The Cambridge Handbook of Thinking and Reasoning (pp. 607-632). Cambridge University Press.</small></p>\n<p><small>Carruthers (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Carruthers-The-cognitive-functions-of-language.pdf\">The cognitive functions of language</a>. <em>Behavioral and Brain Sciences, 25</em>: 657-719.</small></p>\n<p><small>Carruthers (2006). <em><a href=\"http://www.amazon.com/dp/0199207070/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The architecture of the mind</a></em>. Oxford University Press.</small></p>\n<p><small>Carruthers (2009). An architecture for dual reasoning.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 109-128). Oxford University Press.</small></p>\n<p><small>Cohen (1992). <em><a href=\"http://www.amazon.com/dp/0198236042/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">An essay on belief and acceptance</a></em>. Oxford University Press.</small></p>\n<p><small>Cottingham (1992). Cartesian dualism: Theology, metaphysics, and science. In Cottingham (ed.), <em>The Cambridge companion to Descartes</em>&nbsp;(pp. 236-257). Cambridge University Press.</small></p>\n<p><small>Daniel &amp; Klaczynski (2006). Developmental and individual differences in conditional reasoning: Effects of logic instructions and alternative antecedents. <em>Child Development, 77</em>: 339-354.</small></p>\n<p><small>De Neys, Moyens, &amp; Vansteenwegen (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/De-Neys-Feeling-were-biased-autonomic-arousal-and-reasoning-conflict.pdf\">Feeling we're biased: Autonomic arousal and reasoning conflict</a>. <em>Cognitive, affective, and behavioral neuroscience, 10(2)</em>: 208-216.</small></p>\n<p><small>Dennett (1978). <em><a href=\"http://www.amazon.com/dp/0262540371/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Brainstorms: Philosophical essays on mind and psychology</a></em>. MIT Press.</small></p>\n<p><small>Dennett (1991). Two contrasts: Folk craft versus folk science and belief versus opinion. In Greenwood (ed.), <em>The future of folk psychology: Intentionality and cognitive science</em>&nbsp;(pp. 135-148). Cambridge University Press.</small></p>\n<p><small>De Neys (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/De-Neys-Dual-processing-in-reasoning.pdf\">Dual processing in reasoning: Two systems but one reasoner</a>. <em>Psychological Science, 17</em>: 428-433.</small></p>\n<p><small>Eichenbaum &amp; Cohen (2001). <em><a href=\"http://www.amazon.com/dp/0195178041/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">From conditioning to conscious reflection: Memory systems of the brain</a></em>. Oxford University Press.</small></p>\n<p><small>Evans (1989). <em><a href=\"http://www.amazon.com/dp/0863771564/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Bias in human reasoning: Causes and consequences</a></em>. Erlbaum.</small></p>\n<p><small>Evans (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Evans-In-two-minds-Dual-process-accounts-of-reasoning.pdf\">In two minds: Dual-process accounts of reasoning</a>. <em>Trends in Cognitive Sciences, 7</em>: 454-459.</small></p>\n<p><small>Evans (2006). The heuristic-analytic theory of reasoning: Extension and evaluation. <em>Psychonomic Bulletin and Review, 13</em>: 378-395.</small></p>\n<p><small>Evans (2007). <em><a href=\"http://www.amazon.com/dp/1841696609/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Hypothetical Thinking: Dual processes in reasoning and judgment</a></em>. Psychology Press.</small></p>\n<p><small>Evans (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Evans-dual-processing-accounts-of-reasoning-judgment-and-social-cognition.pdf\">Dual-processing accounts of reasoning, judgment and social cognition</a>. <em>Annual Review of Psychology, 59</em>: 255-278.</small></p>\n<p><small>Evans (2009). How many dual-process theories do we need? One, two, or many?&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 33-54). Oxford University Press.</small></p>\n<p><small>Evans (2010). <em><a href=\"http://www.amazon.com/Thinking-Twice-Two-minds-brain/dp/0199547297/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Thinking Twice: Two minds in one brain</a></em>. Oxford University Press.</small></p>\n<p><small>Evans &amp; Over (1996). <em><a href=\"http://www.amazon.com/dp/0863774385/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rationality and Reasoning</a></em>. Psychology Press.</small></p>\n<p><small>Evans &amp; Frankish, eds. (2009).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/dp/0199230161/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">In Two Minds: Dual Processes and Beyond</a></em>. Oxford University Press.</small></p>\n<p><small>Evans &amp; Curtis-Holmes (2005). Rapid responding increases belief bias: Evidence for the dual-process theory of reasoning. <em>Thinking &amp; Reasoning, 11</em>: 382-389.</small></p>\n<p><small>Evans, Barston, &amp; Pollard (1983). On the conflict between logic and belief in syllogistic reasoning.&nbsp;<em style=\"font-style: italic;\">Memory &amp; Cognition, 11</em>: 295-306.</small></p>\n<p><small>Evans, Newstead, Allen, &amp; Pollard (1994). Debiasing by instruction: The case of belief bias. <em>European Journal of Cognitive Psychology, 6</em>: 263-285.</small></p>\n<p><small>Fazio &amp; Olson (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Fazio-Olson-Implicit-measures-in-social-cognition-research-Their-meaning-and-uses.pdf\">Implicit measures in social cognition research: Their meaning and uses</a>. <em>Annual Review of Psychology, 54</em>: 297-327.</small></p>\n<p><small>Finucane, Alhakami, Slovic, &amp; Johnson (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Finucane-The-affect-heuristic-in-judgments-of-risks-and-benefits.pdf\">The affect heuristic in judgments of risks and benefits</a>. <em>Journal of Behavioral Decision Making, 13</em>: 1-17.</small></p>\n<p><small>Frankish (2004). <em><a href=\"http://www.amazon.com/dp/0521038111/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Mind and Supermind</a></em>. Cambridge University Press.</small></p>\n<p><small>Frankish &amp; Evans (2009). <a href=\"http://fds.oup.com/www.oup.com/pdf/13/9780199230167_chapter1.pdf\">The duality of mind: An historical perspective</a>. In Evans &amp; Franklin (eds.), <em>In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 1-29). Oxford University Press.</small></p>\n<p><small>Frederick &amp; Nelson (2007). Attribute substitution in the estimation of volumetric relationships: Psychophysical phenomena underscore judgmental heuristics. Manuscript in preparation. Massachusetts Institute of Technology.</small></p>\n<p><small>Ganzach and Krantz (1990).&nbsp;The psychology of moderate prediction: I. Experience with multiple determination. <em>Organizational Behavior and Human Decision Processes, 47</em>: 177&ndash;204.</small></p>\n<p><small>Gilbert (1989).&nbsp;Thinking lightly about others: Automatic components of the social inference process. In Uleman &amp; Bargh (eds.), <em>Unintended thought</em> (pp. 189&ndash;211). Guilford Press.</small></p>\n<p><small>Gilbert (1999). What the mind's not.&nbsp;In Chaiken &amp; Trope (eds.), <em>Dual-process theories in social psychology</em> (pp. 3&ndash;11 ). Guilford Press.</small></p>\n<p><small>Gilovich (1993). <em><a href=\"http://www.amazon.com/How-Know-What-Isnt-Fallibility/dp/0029117062/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">How we know what isn't so</a></em>. Free Press.</small></p>\n<p><small>Gilovich, Griffin, &amp; Kahneman, eds. (2002). <em><a href=\"http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Heuristics and biases: the psychology of intuitive judgment</a></em>. Cambridge University Press.</small></p>\n<p><small>Goel (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Goel-Cognitive-neuroscience-of-deductive-reasoning.pdf\">Cognitive neuroscience of deductive reasoning</a>. In Holyoak &amp; Morrison (eds.), <em>The Cambridge Handbook of Thinking and Reasoning</em>&nbsp;(pp. 475-492). Cambridge University Press.</small></p>\n<p><small>Goel &amp; Dolan (2003). <a href=\"/Explaining modulation of reasoning by belief\">Explaining modulation of reasoning by belief</a>. <em>Cognition, 87</em>: B11-B22.</small></p>\n<p><small>Gould (1991).&nbsp;<em><a href=\"http://www.amazon.com/Bully-Brontosaurus-Reflections-Natural-History/dp/039330857X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Bully for brontosaurus. Reflections in natural history</a></em>. Norton.</small></p>\n<p><small>Hammond (1996). <em><a href=\"http://www.amazon.com/dp/0195143272/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Human judgment and social policy</a></em>. Oxford University Press.</small></p>\n<p><small>Haidt (2006). <em><a href=\"http://www.amazon.com/Happiness-Hypothesis-Finding-Modern-Ancient/dp/0465028020/\">The happiness hypothesis: Finding modern truth in ancient wisdom</a></em>. Basic Books.</small></p>\n<p><small>Hastie &amp; Dawes, eds. (2009). <em><a href=\"http://www.amazon.com/Rational-Choice-Uncertain-World-Psychology/dp/1412959039/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rational Choice in an Uncertain World, 2nd ed</a></em>. Sage.</small></p>\n<p><small>Higgins &amp; Brendl (1995).&nbsp;Accessibility and applicability: Some 'activation rules' influencing judgment. <em>Journal of Experimental Social Psychology, 31</em>: 218&ndash;243.</small></p>\n<p><small>Jacoby &amp; Dallas (1981).&nbsp;On the relationship between autobiographical memory and perceptual learning. <em>Journal of Experimental Psychology: General, 3</em>: 306&ndash;340.</small></p>\n<p><small>Johnson-Laird (1983). <em><a href=\"http://www.amazon.com/dp/0674568826/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Mental Models</a></em>. Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Tversky (1973).&nbsp;On the psychology of prediction. <em>Psychological Review, 80</em>: 237&ndash;251.</small></p>\n<p><small>Kahneman et al. (1999).&nbsp;Economic preferences or attitude expressions? An analysis of dollar responses to public issues. <em>Journal of Risk and Uncertainty, 19</em>: 203&ndash;235.</small></p>\n<p><small>Kahneman &amp; Frederick (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-Frederick-Representativeness-revisited.pdf\">Representativeness revisited: Attribute substitution in intuitive judgment</a>. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and biases: The psychology of intuitive judgment</em>&nbsp;(pp. 49-81). Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Frederick (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-A-model-of-heuristic-judgment.pdf\">A model of heuristic judgment</a>. In Holyoak &amp; Morrison (eds.), <em>The Cambridge Handbook of Thinking and Reasoning</em>&nbsp;(pp. 267-294). Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Miller (1986).&nbsp;Norm theory: Comparing reality with its alternatives. <em>Psychological Review, 93</em>: 136&ndash;153.</small></p>\n<p><small>Kahneman &amp; Varey (1990).&nbsp;Propensities and counterfactuals: The loser that almost won. <em>Journal of Personality and Social Psychology, 59(6)</em>: 1101&ndash;1110.</small></p>\n<p><small>Klaczynski &amp; Cottrell (2004). A dual-process approach to cognitive development: The case of children's understanding of sunk cost decisions. <em>Thinking and Reasoning, 10</em>: 147-174.</small></p>\n<p><small>Kahneman, Slovic, &amp; Tversky, eds. (1982). <em><a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Judgment under uncertainty: Heuristics and biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Klauer, Musch, &amp; Naumer (2000). On belief bias in syllogistic reasoning. <em>Psychological Review, 107</em>: 852-884.</small></p>\n<p><small>Leibniz (1702/1989). <a href=\"http://books.google.com/books?id=1xEeAt6FUl8C&amp;lpg=PA186&amp;ots=MPXnzo4svz&amp;dq=%22Letter%20to%20Queen%20Sophie%20Charlotte%20of%20Prussia%2C%20on%20what%20is%20independent%20of%20sense%20and%20matter%22&amp;pg=PA186#v=onepage&amp;q&amp;f=false\">Letter to Queen Sophie Charlotte of Prussia, on what is independent of sense and matter</a>.&nbsp;In Leibniz,&nbsp;<em>Philosophical essays</em>&nbsp;(pp. 186-192). Hackett.</small></p>\n<p><small>Leibniz (1714/1989). <a href=\"http://www.earlymoderntexts.com/pdf/leibpng.pdf\">Principles of nature and grace, based on reason</a>. In Leibniz, <em>Philosophical essays</em>&nbsp;(pp. 206-213). Hackett.</small></p>\n<p><small>Lichtenstein, Slovic, Fischhoff, Layman, &amp; Combs (1978). Judged Frequency of Lethal Events. <em>Journal of Experimental Psychology: Human Learning and Memory, 4(6)</em>: 551-578.</small></p>\n<p><small>Lieberman (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Lieberman-Reflective-and-reflexive-judgment-processes.pdf\">Reflective and reflexive judgment processes: A social cognitive neuroscience approach</a>. In Forgas, Williams, &amp; von Hippel (eds.), <em>Social judgments: Implicit and explicit processes</em>&nbsp;(pp. 44-67). Cambridge University Press.</small></p>\n<p><small>Lieberman (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Lieberman-What-zombies-cant-do.pdf\">What zombies can't do: A social cognitive neuroscience approach to the irreducibility of reflective consciousness</a>.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 293-316). Oxford University Press.</small></p>\n<p><small>Mercier &amp; Sperber (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Mercier-Sperber-Intuitive-and-reflective-inferences.pdf\">Intuitive and reflective inferences</a>. In&nbsp;Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 149-170). Oxford University Press.</small></p>\n<p><small>Michotte (1963). <em><a href=\"http://www.amazon.com/Perception-Causality-Michotte/dp/B0010FZ3YW/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The perception of causality</a></em>. Basic Books.</small></p>\n<p><small>Newstead (2000). Are there two different types of thinking? <em>Behavioral and Brain Sciences, 23</em>: 690-691.</small></p>\n<p><small>Newstead, Pollard, &amp; Evans (1992). The source of belief bias effects in syllogistic reasoning. <em>Cognition, 45</em>: 257-284.</small></p>\n<p><small>Nisbett, Peng, Choi, &amp; Norenzayan (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Nisbett-Culture-and-systems-of-thought-Holistic-vs-analytic-cognition.pdf\">Culture and systems of thought: Holistic vs analytic cognition</a>. <em>Psychological Review, 108</em>: 291-310.</small></p>\n<p><small>Nosek (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Nosek-Implicit-Explicit-relations.pdf\">Implicit-explicit relations</a>. <em>Current Directions in Psychological Science, 16</em>: 65-69.</small></p>\n<p><small>Osman (2004). An evaluation of dual-process theories of reasoning. <em>Psychonomic Bulletin and Review, 11</em>: 988-1010.</small></p>\n<p><small>Pohl, ed. (2005). <em><a href=\"http://www.amazon.com/Cognitive-Illusions-Handbook-Fallacies-Judgement/dp/1841693510/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Cognitive illusions: a handbook on fallacies and biases in thinking, judgment and memory</a></em>. Psychology Press.</small></p>\n<p><small>Reber (1993). <em><a href=\"http://www.amazon.com/dp/019510658X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Implicit learning and tacit knowledge</a></em>. Oxford University Press.</small></p>\n<p><small>Rips (1994). <em><a href=\"http://www.amazon.com/dp/0262181533/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The psychology of proof: Deductive reasoning in human thinking</a></em>. MIT Press.</small></p>\n<p><small>Saunders (2009). Reason and intuition in the moral life: A dual-process account of moral justification.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 335-354). Oxford University Press.</small></p>\n<p><small>Schwarz, Bless, Strack, Klumpp, Rittenauer-Schatka, &amp; Simons (1991). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/schwarz-ease-of-retrieval-as-information.pdf\">Ease of retrieval as information: Another look at the availability heuristic</a>.<em> Journal of Personality and Social Psychology, 61</em>: 195&ndash;202.</small></p>\n<p><small>Schwarz &amp; Clore (1983).&nbsp;Mood, misattribution, and judgments of well-being: Informative and directive functions of affective states. <em>Journal of Personality and Social Psychology, 45(3)</em>: 513&ndash;523.</small></p>\n<p><small>Schwarz (1996).&nbsp;<a href=\"http://www.amazon.com/Cognition-Communication-Judgmental-Conversation-Distinguished/dp/080582314X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Cognition and communication: Judgmental biases, research methods, and the logic of conversation</a>. Erlbaum.</small></p>\n<p><small>Schwarz &amp; Vaughn (2002). The availability heuristic revisited: Ease of recall and content of recall as distinct sources of information. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics &amp; biases: The psychology of intuitive judgment</em> (pp. 103&ndash;119). Cambridge University Press.</small></p>\n<p><small>Sherry &amp; Schacter (1987). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Sherry-Shacter-the-evolution-of-multiple-memory-systems.pdf\">The evolution of multiple memory systems</a>. <em>Psychological Review, 94</em>: 439-454.</small></p>\n<p><small>Sloman (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sloman-The-empirical-case-for-two-systems-of-reasoning.pdf\">The empirical case for two systems of reasoning</a>. <em>Psychological Bulletin, 119</em>: 1-23.</small></p>\n<p><small>Sloman (2002).&nbsp;Two systems of reasoning. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and Biases: The Psychology of Intuitive Judgment</em>. Cambridge University Press.</small></p>\n<p><small>Slovic, Finucane, Peters, &amp; MacGregor (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Slovic-Rational-actors-or-rational-fools.pdf\">Rational Actors or Rational Fools: Implications of the Affect Heuristic for Behavioral Economics</a>. <em>Journal of Socio-Economics, 31</em>: 329-342.</small></p>\n<p><small>Smith &amp; Collins (2009). Dual-process models: A social psychological perspective.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em>In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 197-216). Oxford University Press.</small></p>\n<p><small>Smith &amp; DeCoster (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Smith-DeCoster-Dual-process-models-in-social-and-cognitive-psychology.pdf\">Dual-process models in social and cognitive psychology</a>: Conceptual integration and links to underlying memory systems. <em>Personality and Social Psychology Review, 4</em>: 108-131.</small></p>\n<p><small>Smith &amp; Semin (2004). Socially situated cognition: Cognition in its social context. <em>Advances in experimental social psychology, 36</em>: 53-117.</small></p>\n<p><small>Smolensky (1988). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Smolensky-on-the-proper-treatment-of-connectionism.pdf\">On the proper treatment of connectionism</a>. <em>Behavioral and Brain Sciences, 11</em>: 1-23.</small></p>\n<p><small>Stanovich (1999). <em><a href=\"http://www.amazon.com/0805824723/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Who is rational? Studies of individual differences in reasoning</a></em>. Psychology Press.</small></p>\n<p><small>Stanovich (2004). <em><a href=\"http://www.amazon.com/0226771253/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The robot's rebellion: Finding meaning in the age of Darwin</a></em>. Chicago University Press.</small></p>\n<p><small>Stanovich (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Stanovich-Distinguishing-the-reflective-algorithmic-and-autonomous-minds.pdf\">Distinguishing the reflective, algorithmic, and autonomous minds: Is it time for a tri-process theory?</a>&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 55-88). Oxford University Press.</small></p>\n<p><small>Strack &amp; Deutsch (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Strack-Deutsch-Reflective-and-impulsive-determinants-of-social-behavior.pdf\">Reflective and impulsive determinants of social behavior</a>. <em>Personality and Social Psychology Review, 8</em>: 220-247.</small></p>\n<p><small>Strack, Martin, &amp; Schwarz (1988).&nbsp;Priming and communication: The social determinants of information use in judgments of life satisfaction. <em>European Journal of Social Psychology, 1</em>: 429&ndash;442.</small></p>\n<p><small>Stevens (1975).&nbsp;<em><a href=\"http://www.amazon.com/Psychophysics-Introduction-Perceptual-Neural-Prospects/dp/0887386431/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Psychophysics: Introduction to its perceptual, neural, and social prospects</a></em>. Wiley.</small></p>\n<p><small>Sun (2001). <em><a href=\"http://www.amazon.com/dp/0805838805/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Duality of mind: A bottom-up approach towards cognition</a></em>. Psychology Press.</small></p>\n<p><small>Sun, Lane, &amp; Mathews (2009). The two systems of learning: An architectural perspective.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 239-262). Oxford University Press.</small></p>\n<p><small>Toates (2004). 'In two minds' - consideration of evolutionary precursors permits a more integrative theory. <em>Trends in Cognitive Sciences, 8</em>: 57.</small></p>\n<p><small>Toates (2006). A model of the heirarchy of behaviour, cognition, and consciousness. <em>Consciousness and Cognition, 15</em>: 75-118.</small></p>\n<p><small>Thompson (2009). Dual-process theories: A metacognitive perspective.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 171-195). Oxford University Press.</small></p>\n<p><small>Tooby &amp; Cosmides (1992). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Tooby-Cosmides-The-psychological-foundations-of-culture.pdf\">The psychological foundations of culture</a>. In Barkow, Cosmides, &amp; Tooby (eds.), <em>The Adapted Mind</em>&nbsp;(pp. 19-136). Oxford University Press.</small></p>\n<p><small>Tversky &amp; Kahneman (1973).&nbsp;Availability: a heuristic for judging frequency and&nbsp;probability. <em>Cognitive Psychology, 5(2)</em>: 207&ndash;232.</small></p>\n<p><small>Tversky &amp; Kahneman (1982).&nbsp;Judgments of and by representativeness. In Kahneman, Slovic, &amp; Tversky (eds.), <em>Judgment under uncertainty: Heuristics and biases</em> (pp. 84&ndash;98). Cambridge University Press.</small></p>\n<p><small>Vadenoncoeur &amp; Markovits (1999). The effect of instructions and information retrieval on accepting the premises in a conditional reasoning task. <em>Thinking &amp; Reasoning, 5</em>: 97-113.</small></p>\n<p><small>Verscheuren, Schaeken, &amp; d'Ydewalle (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Verschueren-A-dual-process-specification-of-causal-conditional-reasoning.pdf\">A dual-process specification of causal conditional reasoning</a>. <em>Thinking &amp; Reasoning, 11</em>: 239-278.</small></p>\n<p><small>Whyte (1978). <em><a href=\"http://www.amazon.com/dp/0861873092/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The unconscious before Freud</a></em>. St. Martin's Press.</small></p>\n<p><small>Wilson (2002). <em><a href=\"http://www.amazon.com/dp/0674013824/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Strangers to ourselves: Discovering the adaptive unconscious</a></em>. Belknap Press.</small></p>\n<p><small>Zajonc (1980).&nbsp;Feeling and thinking: Preferences need no inferences. <em>American Psychologist, 35(2)</em>: 151&ndash;175.</small></p>\n<p><small>Zajonc (1997).&nbsp;Emotions. In Gilbert, Fiske, &amp; Lindzey (eds.), <em>Handbook of social psychology</em> (4th ed., pp. 591&ndash;632). Oxford University Press.</small></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DLskYNGdAGDFpxBF8": 2, "Ng8Gice9KNkncxqcj": 2, "4R8JYu4QF2FqzJxE5": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "du395YvCnQXBPSJax", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 56, "baseScore": 61, "extendedScore": null, "score": 0.000123, "legacy": true, "legacyId": "6589", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": "yFvZa9wkv5JoqhM8F", "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": "your-evolved-intuitions", "canonicalPrevPostSlug": "philosophy-a-diseased-discipline", "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 61, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p><small>Part of the sequence: <a href=\"http://wiki.lesswrong.com/wiki/Rationality_and_Philosophy\">Rationality and Philosophy</a></small></p>\n<p>Whether you're doing science or philosophy, flirting or playing music, the first and most important tool you are using is your <em>mind</em>. To use your tool well, it will help to know how it works. Today we explore how your mind makes judgments.</p>\n<p>From Plato to Freud, many have remarked that humans seem to have more than one mind.<sup>1</sup>&nbsp;Today, detailed 'dual-process' models are being tested by psychologists and neuroscientists:</p>\n<blockquote>\n<p>Since the 1970s&nbsp;<em style=\"font-style: italic;\">dual-process</em>&nbsp;theories have been developed [to explain] various aspects of human psychology... Typically, one of the processes is characterized as fast, effortless, automatic, nonconscious, inflexible, heavily contextualized, and undemanding of working memory, and the other as slow, effortful, controlled, conscious, flexible, decontextualized, and demanding of working memory.<sup>2</sup></p>\n</blockquote>\n<p>Dual-process theories for reasoning,<sup>3</sup> learning and memory,<sup>4</sup>&nbsp;decision-making,<sup>5</sup>&nbsp;belief,<sup>6</sup>&nbsp;and social cognition<sup>7</sup> are now widely accepted to be correct to some degree,<sup>8</sup> with researchers currently working out the details.<sup>9</sup>&nbsp;Dual-process theories even seem to be appropriate for some nonhuman primates.<sup>10</sup></p>\n<p>Naturally, some have wondered if there might be a \"grand unifying dual-process theory that can incorporate them all.\"<sup>11</sup> We might call such theories&nbsp;<em>dual-system</em>&nbsp;theories of mind,<sup>12</sup> and several have been proposed.<sup>13</sup> Such unified theories face problems, though. 'Type 1' (fast, nonconscious) processes probably involve many nonconscious architectures,<sup>14</sup> and brain imaging studies show a wide variety of brain systems at work at different times when subjects engage in 'type 2' (slow, conscious) processes.<sup>15</sup></p>\n<p>Still, perhaps there is a sense in which one 'mind' relies mostly on type 1 processes, and a second 'mind' relies mostly on type 2 processes. One suggestion is that Mind 1 is evolutionarily old and thus shared with other animals, while Mind 2 is recently evolved and particularly developed in humans. (But not <em>fully unique</em>&nbsp;to humans, because some animals do seem to exhibit a distinction between stimulus-controlled and higher-order controlled behavior.<sup>16</sup>) But this theory faces problems.&nbsp;A standard motivation for dual-process theories of reasoning is the conflict between cognitive biases (from type 1 processes) and logical reasoning (type 2 processes).<sup>17</sup> For example, logic and <a href=\"http://en.wikipedia.org/wiki/Belief_bias\">belief bias</a> often conflict.<sup>18</sup> But both logic and belief bias can be located in the pre-frontal cortex, an evolutionarily <em>new</em> system.<sup>19&nbsp;</sup>So either Mind 1 is not entirely old, or Mind 2 is not entirely composed of type 2 processes.</p>\n<p>We won't try to untangle these mysteries here. Instead, we'll focus on one of the most successful dual-process theories: Kahneman and Frederick's dual-process theory of judgment.<sup>20</sup></p>\n<p><a id=\"more\"></a></p>\n<h4><br></h4>\n<h4 id=\"Attribute_substitution\">Attribute substitution</h4>\n<p>Kahneman and Frederick propose an \"attribute-substitution model of heuristic judgment\" which claims that judgments result from both type 1 and type 2 processes.<sup>21</sup> The authors explain:</p>\n<blockquote>\n<p>The early research on judgment heuristics was guided by a simple and general hypothesis: When confronted with a difficult question, people may answer an easier one instead and are often unaware of the substitution. A person who is asked \"What proportion of long-distance relationships break up within a year?\" may answer as if she had been asked \"Do instances of failed long-distance relationships come readily to mind?\" This would be an application of the availability heuristic. A professor who has heard a candidate\u2019s job talk and now considers the question \"How likely is it that this candidate could be tenured in our department?\" may answer the much easier question: \"How impressive was the talk?\" This would be an example of one form of the representativeness heuristic.<sup>22</sup></p>\n</blockquote>\n<p>Next: what is attribute substitution?</p>\n<blockquote>\n<p>...whenever the aspect of the judgmental object that one intends to judge (the <em>target attribute</em>) is less readily assessed than a related property that yields a plausible answer (the <em>heuristic attribute</em>), individuals may unwittingly substitute the simpler assessment.<sup>22</sup></p>\n</blockquote>\n<p>For example, one study<sup>23</sup> asked subjects two questions among many others: \"How happy are you with your life in general?\" and \"How many dates did you have last month?\" In this order, the correlation between the two questions was negligible. If the dating question was asked first, however, the correlation was .66. The question about dating frequency seems to evoke \"an evaluation of one's romantic satisfaction\" that \"lingers to become the heuristic attribute when the global happiness question is subsequently encountered.\"<sup>22</sup></p>\n<p>Or, consider a question in another study: \"If a sphere were dropped into an open cube, such that it just fit (the diameter of the sphere is the same as the interior width of the cube), what proportion of the volume of the cube would the sphere occupy?\"<sup>24</sup>&nbsp;The target attribute (the volumetric relation between cube and sphere) is difficult to assess intuitively, and it appears that subjects sought out an easier-to-assess heuristic attribute instead, substituting the question \"If a <em>circle</em>&nbsp;were drawn inside a <em>square</em>, what proportion of the <em>area</em>&nbsp;of the square does the circle occupy?\" The mean estimate for the 'sphere inside cube' problem was 74%, almost identical to the mean estimate of the 'circle inside square' problem (77%) but far larger than the correct answer for the 'sphere inside cube' problem (52%).</p>\n<p>Attribution substitutions like this save on processing power but introduce systematic biases into our judgment.<sup>25</sup></p>\n<p>Some attributes are always candidates for the heuristic role in attribute substitution because they play roles in daily perception and cognition and are thus always accessible: cognitive fluency, causal propensity, surprisingness, mood, and affective valence.<sup>26</sup> Less prevalent attributes can become accessible for substitution if recently evoked or primed.<sup>27</sup>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Supervision_of_intuitive_judgments\">Supervision of intuitive judgments</h4>\n<p>Intuitive judgments, say Kahneman and Frederick, arise from processes like attribute substitution, of which we are unaware. They \"bubble up\" from the unconscious, after which many of them are evaluated and either endorsed or rejected by type 2 processes.</p>\n<p>You can feel the tension<sup>28</sup> between type 1 and type 2 processes in your own judgment when you try the <a href=\"http://en.wikipedia.org/wiki/Stroop_effect\">Stroop task</a>.&nbsp;Name the color of a list of colored words and you will find that you pause a bit when the word you see names a different color than the color it is written in, like this: <span style=\"color:red\">green</span>. Your unconscious, intuitive judgment uses an availability heuristic to suggest the word 'green' is shown in green, but your conscious type 2 processes quickly correct the unconscious judgment and conclude that it is written in red. You have no such momentary difficulty naming the color of this word: <span style=\"color:blue\">blue</span>.</p>\n<p>In many cases, type 2 processes have no trouble correcting the judgments of type 1 processes.<sup>29</sup> But because type 2 processes are slow, they can be interrupted by time pressure.<sup>30</sup>&nbsp;On the other hand, biased attribute substitution can sometimes be prevented if subjects are alerted to the possible evaluation contamination in advance.<sup>31</sup> (This finding justifies a great deal of material on Less Wrong, which alerts you to many <a href=\"http://wiki.lesswrong.com/wiki/Bias\">cognitive biases</a> - that is, possible sources of evaluation contamination.)</p>\n<p>Often, type 2 processes fail to correct intuitive judgments, as demonstrated time and again in the heuristics and biases literature.<sup>32</sup>&nbsp;And even when type 2 processes correct intuitive judgments, the <em>feeling</em>&nbsp;that the intuitive judgments is correct may remain. Consider the famous&nbsp;<a href=\"/lw/jj/conjunction_controversy_or_how_they_nail_it_down/\">Linda problem</a>. Knowledge of probability theory does not extinguish the&nbsp;<em style=\"font-style: italic;\">feeling</em>&nbsp;(from type 1 processes) that Linda must be a feminist bank teller. As Stephen Jay Gould put it:</p>\n<blockquote style=\"border-left-width: 2px; border-left-style: solid; border-left-color: #336699; padding-left: 4px; margin-top: 5px; margin-bottom: 5px; margin-left: 5px; margin-right: 15px;\">\n<p>I know [the right answer], yet a little homunculus in my head continues to jump up and down, shouting at me, \"But she can\u2019t&nbsp;<em style=\"font-style: italic;\">just</em>&nbsp;be a bank teller; read the description!\"<sup>33</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<h4 id=\"Conclusion\">Conclusion</h4>\n<p>Kahneman and Frederick's dual-process theory appears to be successful in explaining a wide range of otherwise puzzling phenomena in human judgment.<sup>34</sup>&nbsp;The big picture of all this is described well by Jonathan Haidt, who imagines his conscious mind as a rider upon an elephant:</p>\n<blockquote>\n<p>I'm holding the reins in my hands, and by pulling one way or the other I can tell the elephant to turn, to stop, or to go. I can direct things, but only when the elephant doesn't have desires of his own. When the elephant really wants to do something, I'm no match for him.</p>\n<p>...The controlled system [can be] seen as an advisor. It's a rider placed on the elephant's back to help the elephant make better choices. The rider can see farther into the future, and the rider can learn valuable information by talking to other riders or by reading maps, but the rider cannot order the elephant around against its will...</p>\n<p>...The elephant, in contrast, is everything else. The elephant includes gut feelings, visceral reactions, emotions, and intuitions that comprise much of the automatic system. The elephant and the rider each have their own intelligence, and when they work together well they enable the unique brilliance of human beings. But they don't always work together well.<sup>35</sup></p>\n</blockquote>\n<p>&nbsp;</p>\n<p align=\"right\">Next post: <a href=\"/lw/5bw/your_evolved_intuitions/\">Your Evolved Intuitions</a></p>\n<p align=\"right\">Previous post: <a href=\"/lw/4zs/philosophy_a_diseased_discipline/\">Philosophy: A Diseased Discipline</a></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<h4 id=\"Notes\">Notes</h4>\n<p><small><sup>1</sup> Plato divided the soul into three parts: reason, spirit, and appetite (Annas 1981, ch. 5). Descartes held that humans operate on unconscious mechanical processes we share with animals, but that humans' additional capacities for rational thought separate us from the animals (Cottingham 1992). Leibniz said that animals are guided by inductive reasoning, which also guides 'three-fourths' of human reasoning, but that humans can also partake in 'true reasoning'&nbsp;<span style=\"color: #3e3c3c; font-family: verdana, serif; font-size: 13px; line-height: 13px;\">\u2014</span>&nbsp;logic and mathematics (Leibniz 1714/1989, p. 208; Leibniz 1702/1989, pp. 188-191). Many thinkers, most famously Freud, have drawn a division between conscious and unconscious thinking (Whyte 1978). For a more detailed survey, see Frankish &amp; Evans (2009). Multiple-process theories of mind stand in contrast to monistic theories of mind, for example:&nbsp;Johnson-Laird (1983);&nbsp;Braine (1990); Rips (1994). Note that dual-process theories of mind need not conflict with massively modular view of human cognition like Barrett &amp; Kurzban (2006) or Tooby &amp; Cosmides (1992): see Mercier &amp; Sperber (2009). Finally, note that dual-process theories sit comfortably with current research on situated cognition: Smith &amp; Semin (2004).</small></p>\n<p><small><sup>2</sup>&nbsp;Frankish &amp; Evans (2009).</small></p>\n<p><small><sup>3</sup>&nbsp;Evans (1989, 2006, 2007); Evans &amp; Over (1996); Sloman (1996, 2002); Stanovich (1999, 2004, 2009); Smolensky (1988); Carruthers (2002, 2006, 2009); Lieberman (2003; 2009); Gilbert (1999).</small></p>\n<p><small><sup>4</sup>&nbsp;Sun et al. (2009); Eichenbaum &amp; Cohen (2001); Carruthers (2006); Sherry &amp; Schacter (1987); Berry &amp; Dienes (1993); Reber (1993); Sun (2001).</small></p>\n<p><small><sup>5</sup>&nbsp;Kahneman &amp; Frederick (2002, 2005).</small></p>\n<p><small><sup>6</sup> Dennett (1978, ch. 16; 1991); Cohen (1992); Frankish (2004); Verscheuren et al. (2005).</small></p>\n<p><small><sup>7</sup>&nbsp;Smith &amp; Collins (2009); Bargh (2006); Strack &amp; Deutsch (2004).</small><span style=\"font-size: 11px;\">&nbsp;</span></p>\n<p><small><sup>8</sup> Evans (2008); Evans &amp; Frankish (2009). Or as Carruthers (2009) puts it, \"Dual-system theories of human reasoning are now quite widely accepted, at least in outline.\"</small></p>\n<p><small><sup>9</sup>&nbsp;One such detail is: When and to what extent does System 2 intervene in System 1 processes? See: Evans (2006); Stanovich (1999); De Neys (2006); Evans &amp; Curtis-Holmes (2005); Finucane et al. (2000); Newstead et al. (1992); Evans et al. (1994); Daniel &amp; Klaczynski (2006); Vadenoncoeur &amp; Markovits (1999); Thompson (2009). Other important open questions are explored in Fazio &amp; Olson (2003); Nosek (2007); Saunders (2009). For an accessible overview of the field, see Evans (2010).</small></p>\n<p><small><sup>10</sup>&nbsp;Call &amp; Tomasello (2005).</small></p>\n<p><small><sup>11</sup> Evans (2009).</small></p>\n<p><small><sup>12</sup> Dual-process and dual-system theories of the mind suggest multiple cognitive <em>architectures</em>, and should not be confused with theories of multiple <em>modes</em>&nbsp;of processing, or two kinds of <em>cognitive style</em>. One example of the latter is the supposed distinction between Eastern and Western thinking (Nisbett et al. 2001).&nbsp;Dual-process and dual-system theories of the mind should also be distinguished from theories that posit a <em>continuum</em>&nbsp;between one form of thinking and another (e.g. Hammond 1996; Newstead 2000; Osman 2004), since this suggests there are not separate cognitive architectures at work.</small></p>\n<p><small><sup>13</sup>&nbsp;Evans (2003); Stanovich (1999, 2009); Evans &amp; Over (1996); Smith &amp; DeCoster (2000); Wilson (2002).</small></p>\n<p><small><sup>14</sup> Evans (2008, 2009); Stanovich (2004); Wilson (2002).</small></p>\n<p><small><sup>15</sup> Goel (2007).</small></p>\n<p><small><sup>16</sup> Toates (2004, 2006).</small></p>\n<p><small><sup>17</sup> Evans (1989); Evans &amp; Over (1996); Kahneman &amp; Frederick (2002); Klaczynski &amp; Cottrell (2004); Sloman (1996); Stanovich (2004).</small></p>\n<p><small><sup>18</sup> Evans et al. (1983); Klauer et al. (2000).</small></p>\n<p><small><sup>19</sup>&nbsp;Evans (2009); Goel &amp; Dolan (2003).</small></p>\n<p><small><sup>20</sup> Those who prefer video lectures to reading may enjoy a 2008 lecture on judgment and intuition, to which Kahneman contributed: <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35259&amp;state=maximize#a_icb_pagecontent698262\">1</a>, <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35265&amp;state=maximize#a_icb_pagecontent698262\">2</a>, <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35267&amp;state=maximize#a_icb_pagecontent698262\">3</a>, <a href=\"http://isites.harvard.edu/icb/icb.do?keyword=k69509&amp;pageid=icb.page334500&amp;pageContentId=icb.pagecontent698262&amp;view=watch.do&amp;viewParam_entry=35268&amp;state=maximize#a_icb_pagecontent698262\">4</a>.</small></p>\n<p><small><sup>21</sup> They use the terms 'system 1' and 'system 2' instead of 'type 1' and 'type 2'. Their theory is outlined in Kahneman &amp; Frederick (2002, 2005).</small></p>\n<p><small><sup>22</sup>&nbsp;Kahneman &amp; Frederick (2005).</small></p>\n<p><small><sup>23</sup> Strack et al. (1988).</small></p>\n<p><small><sup>24</sup> Frederick &amp; Nelson (2007).</small></p>\n<p><small><sup>25</sup> Cognitive biases particularly involved in attribute substitution include the <a href=\"http://wiki.lesswrong.com/wiki/Availability_heuristic\">availability heuristic</a> (Lichtenstein et al. 1978; Schwarz et al. 1991;&nbsp;Schwarz &amp; Vaughn 2002), the <a href=\"http://wiki.lesswrong.com/wiki/Representativeness_heuristic\">representativeness heuristic</a> (Kahneman &amp; Tversky 1973; Tversky &amp; Kahneman 1982; Bar-Hillel &amp; Neter 1993; Agnolia 1991), and the <a href=\"/lw/lg/the_affect_heuristic/\">affect heuristic</a> (Slovic et al. 2002; Finucane et al. 2000).</small></p>\n<p><small><sup>26</sup> Cognitive fluency: Jacoby &amp; Dallas (1981); Schwarz &amp; Vaughn (2002); Tversky &amp; Kahneman (1973). Causal propensity: Michotte (1963); Kahneman &amp; Varey (1990). Surprisingness: Kahneman &amp; Miller (1986). Mood: Schwarz &amp; Clore (1983). Affective valence: Bargh (1997); Cacioppo et al. (1993); Kahneman et al. (1999); Slovic et al. (2002); Zajonc (1980, 1997).</small></p>\n<p><small><sup>27</sup>&nbsp;Bargh et al. (1986); Higgins &amp; Brendl (1995). Note also that attributes must be mapped across dimensions on a common scale, and we understand to some degree the mechanism that does this: Kahneman &amp; Frederick (2005);&nbsp;Ganzach and Krantz (1990); Stevens (1975).</small></p>\n<p><small><sup>28</sup>&nbsp;Also see De Neys et al. (2010).</small></p>\n<p><small><sup>29</sup> Gilbert (1989).</small></p>\n<p><small><sup>30</sup>&nbsp;Finucane et al. (2000).</small></p>\n<p><small><sup>31</sup>&nbsp;Schwarz &amp; Clore (1983);&nbsp;Schwarz (1996).</small></p>\n<p><small><sup>32</sup>&nbsp;Gilovich et al. (2002); Kahneman et al. (1982); Pohl (2005); Gilovich (1993); Hastie &amp; Dawes (2009).</small></p>\n<p><small><sup>33</sup> Gould (1991), p. 469.</small></p>\n<p><small><sup>34</sup>&nbsp;See the overview in Kahneman &amp; Frederick (2005).</small></p>\n<p><small><sup>35</sup> Haidt (2006), pp. 4, 17.</small></p>\n<p><small>&nbsp;</small></p>\n<h4 id=\"References\">References</h4>\n<p><small>Agnolia (1991).&nbsp;Development of judgmental heuristics and logical reasoning: Training counteracts the representativeness heuristic. <em>Cognitive Development, 6</em>: 195\u2013217.</small></p>\n<p><small>Annas (1981). <em><a href=\"http://www.amazon.com/dp/0198274297/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">An introduction to Plato's republic</a></em>. Oxford University Press.</small></p>\n<p><small>Bar-Hillel &amp; Neter (1993).&nbsp;<a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Bar-Hillel-how-alike-is-it-versus-how-likely-is-it.pdf\">How alike is it versus how likely is it: A disjunction fallacy in probability judgments</a>. <em>Journal of Personality and Social Psychology, 41</em>: 671\u2013680.</small></p>\n<p><small>Bargh (1997).&nbsp;The automaticity of everyday life. <em>Advances in social cognition, 10</em>. Erlbaum.</small></p>\n<p><small>Bargh,&nbsp;Bond, Lombardi, &amp; Tota (1986). The additive nature of chronic and temporary sources of construct accessibility. <em>Journal of Personality and Social Psychology, 50(5)</em>: 869\u2013878.</small></p>\n<p><small>Bargh (2006). <em><a href=\"http://www.amazon.com/dp/184169472X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Social psychology and the unconscious</a></em>. Psychology Press.</small></p>\n<p><small>Barrett &amp; Kurzban (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Barrett-Kurzban-modularity-in-cognition-framing-the-debate.pdf\">Modularity in cognition: Framing the debate</a>. <em>Psychological Review, 113</em>: 628-647.</small></p>\n<p><small>Berry &amp; Dienes (1993). <em><a href=\"http://www.amazon.com/dp/0863772234/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Implicit learning</a></em>. Erlbaum.</small></p>\n<p><small>Braine (1990). The 'natural logic' approach to reasoning. In Overton (ed.), <em>Reasoning, necessity and logic: Developmental perspectives</em>. Psychology Press.</small></p>\n<p><small>Cacioppo, Priester, &amp; Berntson (1993). Rudimentary determinants of attitudes: II. Arm flexion and extension have differential effects on attitudes. <em>Journal of Personality and Social Psychology, 65</em>: 5\u201317.</small></p>\n<p><small>Call &amp; Tomasello (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Call-Tomasello-Reasoning-and-Thinking-in-Nonhuman-Primates.pdf\">Reasoning and thinking in nonhuman primates</a>. In Holyoak &amp; Morrison (eds.), The Cambridge Handbook of Thinking and Reasoning (pp. 607-632). Cambridge University Press.</small></p>\n<p><small>Carruthers (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Carruthers-The-cognitive-functions-of-language.pdf\">The cognitive functions of language</a>. <em>Behavioral and Brain Sciences, 25</em>: 657-719.</small></p>\n<p><small>Carruthers (2006). <em><a href=\"http://www.amazon.com/dp/0199207070/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The architecture of the mind</a></em>. Oxford University Press.</small></p>\n<p><small>Carruthers (2009). An architecture for dual reasoning.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 109-128). Oxford University Press.</small></p>\n<p><small>Cohen (1992). <em><a href=\"http://www.amazon.com/dp/0198236042/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">An essay on belief and acceptance</a></em>. Oxford University Press.</small></p>\n<p><small>Cottingham (1992). Cartesian dualism: Theology, metaphysics, and science. In Cottingham (ed.), <em>The Cambridge companion to Descartes</em>&nbsp;(pp. 236-257). Cambridge University Press.</small></p>\n<p><small>Daniel &amp; Klaczynski (2006). Developmental and individual differences in conditional reasoning: Effects of logic instructions and alternative antecedents. <em>Child Development, 77</em>: 339-354.</small></p>\n<p><small>De Neys, Moyens, &amp; Vansteenwegen (2010). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/De-Neys-Feeling-were-biased-autonomic-arousal-and-reasoning-conflict.pdf\">Feeling we're biased: Autonomic arousal and reasoning conflict</a>. <em>Cognitive, affective, and behavioral neuroscience, 10(2)</em>: 208-216.</small></p>\n<p><small>Dennett (1978). <em><a href=\"http://www.amazon.com/dp/0262540371/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Brainstorms: Philosophical essays on mind and psychology</a></em>. MIT Press.</small></p>\n<p><small>Dennett (1991). Two contrasts: Folk craft versus folk science and belief versus opinion. In Greenwood (ed.), <em>The future of folk psychology: Intentionality and cognitive science</em>&nbsp;(pp. 135-148). Cambridge University Press.</small></p>\n<p><small>De Neys (2006). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/De-Neys-Dual-processing-in-reasoning.pdf\">Dual processing in reasoning: Two systems but one reasoner</a>. <em>Psychological Science, 17</em>: 428-433.</small></p>\n<p><small>Eichenbaum &amp; Cohen (2001). <em><a href=\"http://www.amazon.com/dp/0195178041/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">From conditioning to conscious reflection: Memory systems of the brain</a></em>. Oxford University Press.</small></p>\n<p><small>Evans (1989). <em><a href=\"http://www.amazon.com/dp/0863771564/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Bias in human reasoning: Causes and consequences</a></em>. Erlbaum.</small></p>\n<p><small>Evans (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Evans-In-two-minds-Dual-process-accounts-of-reasoning.pdf\">In two minds: Dual-process accounts of reasoning</a>. <em>Trends in Cognitive Sciences, 7</em>: 454-459.</small></p>\n<p><small>Evans (2006). The heuristic-analytic theory of reasoning: Extension and evaluation. <em>Psychonomic Bulletin and Review, 13</em>: 378-395.</small></p>\n<p><small>Evans (2007). <em><a href=\"http://www.amazon.com/dp/1841696609/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Hypothetical Thinking: Dual processes in reasoning and judgment</a></em>. Psychology Press.</small></p>\n<p><small>Evans (2008). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Evans-dual-processing-accounts-of-reasoning-judgment-and-social-cognition.pdf\">Dual-processing accounts of reasoning, judgment and social cognition</a>. <em>Annual Review of Psychology, 59</em>: 255-278.</small></p>\n<p><small>Evans (2009). How many dual-process theories do we need? One, two, or many?&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 33-54). Oxford University Press.</small></p>\n<p><small>Evans (2010). <em><a href=\"http://www.amazon.com/Thinking-Twice-Two-minds-brain/dp/0199547297/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Thinking Twice: Two minds in one brain</a></em>. Oxford University Press.</small></p>\n<p><small>Evans &amp; Over (1996). <em><a href=\"http://www.amazon.com/dp/0863774385/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rationality and Reasoning</a></em>. Psychology Press.</small></p>\n<p><small>Evans &amp; Frankish, eds. (2009).&nbsp;<em style=\"font-style: italic;\"><a href=\"http://www.amazon.com/dp/0199230161/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">In Two Minds: Dual Processes and Beyond</a></em>. Oxford University Press.</small></p>\n<p><small>Evans &amp; Curtis-Holmes (2005). Rapid responding increases belief bias: Evidence for the dual-process theory of reasoning. <em>Thinking &amp; Reasoning, 11</em>: 382-389.</small></p>\n<p><small>Evans, Barston, &amp; Pollard (1983). On the conflict between logic and belief in syllogistic reasoning.&nbsp;<em style=\"font-style: italic;\">Memory &amp; Cognition, 11</em>: 295-306.</small></p>\n<p><small>Evans, Newstead, Allen, &amp; Pollard (1994). Debiasing by instruction: The case of belief bias. <em>European Journal of Cognitive Psychology, 6</em>: 263-285.</small></p>\n<p><small>Fazio &amp; Olson (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Fazio-Olson-Implicit-measures-in-social-cognition-research-Their-meaning-and-uses.pdf\">Implicit measures in social cognition research: Their meaning and uses</a>. <em>Annual Review of Psychology, 54</em>: 297-327.</small></p>\n<p><small>Finucane, Alhakami, Slovic, &amp; Johnson (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Finucane-The-affect-heuristic-in-judgments-of-risks-and-benefits.pdf\">The affect heuristic in judgments of risks and benefits</a>. <em>Journal of Behavioral Decision Making, 13</em>: 1-17.</small></p>\n<p><small>Frankish (2004). <em><a href=\"http://www.amazon.com/dp/0521038111/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Mind and Supermind</a></em>. Cambridge University Press.</small></p>\n<p><small>Frankish &amp; Evans (2009). <a href=\"http://fds.oup.com/www.oup.com/pdf/13/9780199230167_chapter1.pdf\">The duality of mind: An historical perspective</a>. In Evans &amp; Franklin (eds.), <em>In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 1-29). Oxford University Press.</small></p>\n<p><small>Frederick &amp; Nelson (2007). Attribute substitution in the estimation of volumetric relationships: Psychophysical phenomena underscore judgmental heuristics. Manuscript in preparation. Massachusetts Institute of Technology.</small></p>\n<p><small>Ganzach and Krantz (1990).&nbsp;The psychology of moderate prediction: I. Experience with multiple determination. <em>Organizational Behavior and Human Decision Processes, 47</em>: 177\u2013204.</small></p>\n<p><small>Gilbert (1989).&nbsp;Thinking lightly about others: Automatic components of the social inference process. In Uleman &amp; Bargh (eds.), <em>Unintended thought</em> (pp. 189\u2013211). Guilford Press.</small></p>\n<p><small>Gilbert (1999). What the mind's not.&nbsp;In Chaiken &amp; Trope (eds.), <em>Dual-process theories in social psychology</em> (pp. 3\u201311 ). Guilford Press.</small></p>\n<p><small>Gilovich (1993). <em><a href=\"http://www.amazon.com/How-Know-What-Isnt-Fallibility/dp/0029117062/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">How we know what isn't so</a></em>. Free Press.</small></p>\n<p><small>Gilovich, Griffin, &amp; Kahneman, eds. (2002). <em><a href=\"http://www.amazon.com/Heuristics-Biases-Psychology-Intuitive-Judgment/dp/0521796792/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Heuristics and biases: the psychology of intuitive judgment</a></em>. Cambridge University Press.</small></p>\n<p><small>Goel (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Goel-Cognitive-neuroscience-of-deductive-reasoning.pdf\">Cognitive neuroscience of deductive reasoning</a>. In Holyoak &amp; Morrison (eds.), <em>The Cambridge Handbook of Thinking and Reasoning</em>&nbsp;(pp. 475-492). Cambridge University Press.</small></p>\n<p><small>Goel &amp; Dolan (2003). <a href=\"/Explaining modulation of reasoning by belief\">Explaining modulation of reasoning by belief</a>. <em>Cognition, 87</em>: B11-B22.</small></p>\n<p><small>Gould (1991).&nbsp;<em><a href=\"http://www.amazon.com/Bully-Brontosaurus-Reflections-Natural-History/dp/039330857X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Bully for brontosaurus. Reflections in natural history</a></em>. Norton.</small></p>\n<p><small>Hammond (1996). <em><a href=\"http://www.amazon.com/dp/0195143272/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Human judgment and social policy</a></em>. Oxford University Press.</small></p>\n<p><small>Haidt (2006). <em><a href=\"http://www.amazon.com/Happiness-Hypothesis-Finding-Modern-Ancient/dp/0465028020/\">The happiness hypothesis: Finding modern truth in ancient wisdom</a></em>. Basic Books.</small></p>\n<p><small>Hastie &amp; Dawes, eds. (2009). <em><a href=\"http://www.amazon.com/Rational-Choice-Uncertain-World-Psychology/dp/1412959039/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Rational Choice in an Uncertain World, 2nd ed</a></em>. Sage.</small></p>\n<p><small>Higgins &amp; Brendl (1995).&nbsp;Accessibility and applicability: Some 'activation rules' influencing judgment. <em>Journal of Experimental Social Psychology, 31</em>: 218\u2013243.</small></p>\n<p><small>Jacoby &amp; Dallas (1981).&nbsp;On the relationship between autobiographical memory and perceptual learning. <em>Journal of Experimental Psychology: General, 3</em>: 306\u2013340.</small></p>\n<p><small>Johnson-Laird (1983). <em><a href=\"http://www.amazon.com/dp/0674568826/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Mental Models</a></em>. Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Tversky (1973).&nbsp;On the psychology of prediction. <em>Psychological Review, 80</em>: 237\u2013251.</small></p>\n<p><small>Kahneman et al. (1999).&nbsp;Economic preferences or attitude expressions? An analysis of dollar responses to public issues. <em>Journal of Risk and Uncertainty, 19</em>: 203\u2013235.</small></p>\n<p><small>Kahneman &amp; Frederick (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-Frederick-Representativeness-revisited.pdf\">Representativeness revisited: Attribute substitution in intuitive judgment</a>. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and biases: The psychology of intuitive judgment</em>&nbsp;(pp. 49-81). Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Frederick (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Kahneman-A-model-of-heuristic-judgment.pdf\">A model of heuristic judgment</a>. In Holyoak &amp; Morrison (eds.), <em>The Cambridge Handbook of Thinking and Reasoning</em>&nbsp;(pp. 267-294). Cambridge University Press.</small></p>\n<p><small>Kahneman &amp; Miller (1986).&nbsp;Norm theory: Comparing reality with its alternatives. <em>Psychological Review, 93</em>: 136\u2013153.</small></p>\n<p><small>Kahneman &amp; Varey (1990).&nbsp;Propensities and counterfactuals: The loser that almost won. <em>Journal of Personality and Social Psychology, 59(6)</em>: 1101\u20131110.</small></p>\n<p><small>Klaczynski &amp; Cottrell (2004). A dual-process approach to cognitive development: The case of children's understanding of sunk cost decisions. <em>Thinking and Reasoning, 10</em>: 147-174.</small></p>\n<p><small>Kahneman, Slovic, &amp; Tversky, eds. (1982). <em><a href=\"http://www.amazon.com/Judgment-under-Uncertainty-Heuristics-Biases/dp/0521284147/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Judgment under uncertainty: Heuristics and biases</a></em>. Cambridge University Press.</small></p>\n<p><small>Klauer, Musch, &amp; Naumer (2000). On belief bias in syllogistic reasoning. <em>Psychological Review, 107</em>: 852-884.</small></p>\n<p><small>Leibniz (1702/1989). <a href=\"http://books.google.com/books?id=1xEeAt6FUl8C&amp;lpg=PA186&amp;ots=MPXnzo4svz&amp;dq=%22Letter%20to%20Queen%20Sophie%20Charlotte%20of%20Prussia%2C%20on%20what%20is%20independent%20of%20sense%20and%20matter%22&amp;pg=PA186#v=onepage&amp;q&amp;f=false\">Letter to Queen Sophie Charlotte of Prussia, on what is independent of sense and matter</a>.&nbsp;In Leibniz,&nbsp;<em>Philosophical essays</em>&nbsp;(pp. 186-192). Hackett.</small></p>\n<p><small>Leibniz (1714/1989). <a href=\"http://www.earlymoderntexts.com/pdf/leibpng.pdf\">Principles of nature and grace, based on reason</a>. In Leibniz, <em>Philosophical essays</em>&nbsp;(pp. 206-213). Hackett.</small></p>\n<p><small>Lichtenstein, Slovic, Fischhoff, Layman, &amp; Combs (1978). Judged Frequency of Lethal Events. <em>Journal of Experimental Psychology: Human Learning and Memory, 4(6)</em>: 551-578.</small></p>\n<p><small>Lieberman (2003). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Lieberman-Reflective-and-reflexive-judgment-processes.pdf\">Reflective and reflexive judgment processes: A social cognitive neuroscience approach</a>. In Forgas, Williams, &amp; von Hippel (eds.), <em>Social judgments: Implicit and explicit processes</em>&nbsp;(pp. 44-67). Cambridge University Press.</small></p>\n<p><small>Lieberman (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Lieberman-What-zombies-cant-do.pdf\">What zombies can't do: A social cognitive neuroscience approach to the irreducibility of reflective consciousness</a>.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 293-316). Oxford University Press.</small></p>\n<p><small>Mercier &amp; Sperber (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Mercier-Sperber-Intuitive-and-reflective-inferences.pdf\">Intuitive and reflective inferences</a>. In&nbsp;Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 149-170). Oxford University Press.</small></p>\n<p><small>Michotte (1963). <em><a href=\"http://www.amazon.com/Perception-Causality-Michotte/dp/B0010FZ3YW/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The perception of causality</a></em>. Basic Books.</small></p>\n<p><small>Newstead (2000). Are there two different types of thinking? <em>Behavioral and Brain Sciences, 23</em>: 690-691.</small></p>\n<p><small>Newstead, Pollard, &amp; Evans (1992). The source of belief bias effects in syllogistic reasoning. <em>Cognition, 45</em>: 257-284.</small></p>\n<p><small>Nisbett, Peng, Choi, &amp; Norenzayan (2001). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Nisbett-Culture-and-systems-of-thought-Holistic-vs-analytic-cognition.pdf\">Culture and systems of thought: Holistic vs analytic cognition</a>. <em>Psychological Review, 108</em>: 291-310.</small></p>\n<p><small>Nosek (2007). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Nosek-Implicit-Explicit-relations.pdf\">Implicit-explicit relations</a>. <em>Current Directions in Psychological Science, 16</em>: 65-69.</small></p>\n<p><small>Osman (2004). An evaluation of dual-process theories of reasoning. <em>Psychonomic Bulletin and Review, 11</em>: 988-1010.</small></p>\n<p><small>Pohl, ed. (2005). <em><a href=\"http://www.amazon.com/Cognitive-Illusions-Handbook-Fallacies-Judgement/dp/1841693510/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Cognitive illusions: a handbook on fallacies and biases in thinking, judgment and memory</a></em>. Psychology Press.</small></p>\n<p><small>Reber (1993). <em><a href=\"http://www.amazon.com/dp/019510658X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Implicit learning and tacit knowledge</a></em>. Oxford University Press.</small></p>\n<p><small>Rips (1994). <em><a href=\"http://www.amazon.com/dp/0262181533/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The psychology of proof: Deductive reasoning in human thinking</a></em>. MIT Press.</small></p>\n<p><small>Saunders (2009). Reason and intuition in the moral life: A dual-process account of moral justification.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 335-354). Oxford University Press.</small></p>\n<p><small>Schwarz, Bless, Strack, Klumpp, Rittenauer-Schatka, &amp; Simons (1991). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/schwarz-ease-of-retrieval-as-information.pdf\">Ease of retrieval as information: Another look at the availability heuristic</a>.<em> Journal of Personality and Social Psychology, 61</em>: 195\u2013202.</small></p>\n<p><small>Schwarz &amp; Clore (1983).&nbsp;Mood, misattribution, and judgments of well-being: Informative and directive functions of affective states. <em>Journal of Personality and Social Psychology, 45(3)</em>: 513\u2013523.</small></p>\n<p><small>Schwarz (1996).&nbsp;<a href=\"http://www.amazon.com/Cognition-Communication-Judgmental-Conversation-Distinguished/dp/080582314X/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Cognition and communication: Judgmental biases, research methods, and the logic of conversation</a>. Erlbaum.</small></p>\n<p><small>Schwarz &amp; Vaughn (2002). The availability heuristic revisited: Ease of recall and content of recall as distinct sources of information. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics &amp; biases: The psychology of intuitive judgment</em> (pp. 103\u2013119). Cambridge University Press.</small></p>\n<p><small>Sherry &amp; Schacter (1987). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Sherry-Shacter-the-evolution-of-multiple-memory-systems.pdf\">The evolution of multiple memory systems</a>. <em>Psychological Review, 94</em>: 439-454.</small></p>\n<p><small>Sloman (1996). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/03/Sloman-The-empirical-case-for-two-systems-of-reasoning.pdf\">The empirical case for two systems of reasoning</a>. <em>Psychological Bulletin, 119</em>: 1-23.</small></p>\n<p><small>Sloman (2002).&nbsp;Two systems of reasoning. In Gilovich, Griffin, &amp; Kahneman (eds.), <em>Heuristics and Biases: The Psychology of Intuitive Judgment</em>. Cambridge University Press.</small></p>\n<p><small>Slovic, Finucane, Peters, &amp; MacGregor (2002). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Slovic-Rational-actors-or-rational-fools.pdf\">Rational Actors or Rational Fools: Implications of the Affect Heuristic for Behavioral Economics</a>. <em>Journal of Socio-Economics, 31</em>: 329-342.</small></p>\n<p><small>Smith &amp; Collins (2009). Dual-process models: A social psychological perspective.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em>In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 197-216). Oxford University Press.</small></p>\n<p><small>Smith &amp; DeCoster (2000). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Smith-DeCoster-Dual-process-models-in-social-and-cognitive-psychology.pdf\">Dual-process models in social and cognitive psychology</a>: Conceptual integration and links to underlying memory systems. <em>Personality and Social Psychology Review, 4</em>: 108-131.</small></p>\n<p><small>Smith &amp; Semin (2004). Socially situated cognition: Cognition in its social context. <em>Advances in experimental social psychology, 36</em>: 53-117.</small></p>\n<p><small>Smolensky (1988). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Smolensky-on-the-proper-treatment-of-connectionism.pdf\">On the proper treatment of connectionism</a>. <em>Behavioral and Brain Sciences, 11</em>: 1-23.</small></p>\n<p><small>Stanovich (1999). <em><a href=\"http://www.amazon.com/0805824723/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Who is rational? Studies of individual differences in reasoning</a></em>. Psychology Press.</small></p>\n<p><small>Stanovich (2004). <em><a href=\"http://www.amazon.com/0226771253/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The robot's rebellion: Finding meaning in the age of Darwin</a></em>. Chicago University Press.</small></p>\n<p><small>Stanovich (2009). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Stanovich-Distinguishing-the-reflective-algorithmic-and-autonomous-minds.pdf\">Distinguishing the reflective, algorithmic, and autonomous minds: Is it time for a tri-process theory?</a>&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 55-88). Oxford University Press.</small></p>\n<p><small>Strack &amp; Deutsch (2004). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Strack-Deutsch-Reflective-and-impulsive-determinants-of-social-behavior.pdf\">Reflective and impulsive determinants of social behavior</a>. <em>Personality and Social Psychology Review, 8</em>: 220-247.</small></p>\n<p><small>Strack, Martin, &amp; Schwarz (1988).&nbsp;Priming and communication: The social determinants of information use in judgments of life satisfaction. <em>European Journal of Social Psychology, 1</em>: 429\u2013442.</small></p>\n<p><small>Stevens (1975).&nbsp;<em><a href=\"http://www.amazon.com/Psychophysics-Introduction-Perceptual-Neural-Prospects/dp/0887386431/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Psychophysics: Introduction to its perceptual, neural, and social prospects</a></em>. Wiley.</small></p>\n<p><small>Sun (2001). <em><a href=\"http://www.amazon.com/dp/0805838805/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Duality of mind: A bottom-up approach towards cognition</a></em>. Psychology Press.</small></p>\n<p><small>Sun, Lane, &amp; Mathews (2009). The two systems of learning: An architectural perspective.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 239-262). Oxford University Press.</small></p>\n<p><small>Toates (2004). 'In two minds' - consideration of evolutionary precursors permits a more integrative theory. <em>Trends in Cognitive Sciences, 8</em>: 57.</small></p>\n<p><small>Toates (2006). A model of the heirarchy of behaviour, cognition, and consciousness. <em>Consciousness and Cognition, 15</em>: 75-118.</small></p>\n<p><small>Thompson (2009). Dual-process theories: A metacognitive perspective.&nbsp;In Evans &amp; Franklin (eds.),&nbsp;<em style=\"font-style: italic;\">In Two Minds: Dual Processes and Beyond</em>&nbsp;(pp. 171-195). Oxford University Press.</small></p>\n<p><small>Tooby &amp; Cosmides (1992). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Tooby-Cosmides-The-psychological-foundations-of-culture.pdf\">The psychological foundations of culture</a>. In Barkow, Cosmides, &amp; Tooby (eds.), <em>The Adapted Mind</em>&nbsp;(pp. 19-136). Oxford University Press.</small></p>\n<p><small>Tversky &amp; Kahneman (1973).&nbsp;Availability: a heuristic for judging frequency and&nbsp;probability. <em>Cognitive Psychology, 5(2)</em>: 207\u2013232.</small></p>\n<p><small>Tversky &amp; Kahneman (1982).&nbsp;Judgments of and by representativeness. In Kahneman, Slovic, &amp; Tversky (eds.), <em>Judgment under uncertainty: Heuristics and biases</em> (pp. 84\u201398). Cambridge University Press.</small></p>\n<p><small>Vadenoncoeur &amp; Markovits (1999). The effect of instructions and information retrieval on accepting the premises in a conditional reasoning task. <em>Thinking &amp; Reasoning, 5</em>: 97-113.</small></p>\n<p><small>Verscheuren, Schaeken, &amp; d'Ydewalle (2005). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/04/Verschueren-A-dual-process-specification-of-causal-conditional-reasoning.pdf\">A dual-process specification of causal conditional reasoning</a>. <em>Thinking &amp; Reasoning, 11</em>: 239-278.</small></p>\n<p><small>Whyte (1978). <em><a href=\"http://www.amazon.com/dp/0861873092/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">The unconscious before Freud</a></em>. St. Martin's Press.</small></p>\n<p><small>Wilson (2002). <em><a href=\"http://www.amazon.com/dp/0674013824/ref=as_li_ss_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0321928423&amp;linkCode=as2&amp;tag=lesswrong-20\">Strangers to ourselves: Discovering the adaptive unconscious</a></em>. Belknap Press.</small></p>\n<p><small>Zajonc (1980).&nbsp;Feeling and thinking: Preferences need no inferences. <em>American Psychologist, 35(2)</em>: 151\u2013175.</small></p>\n<p><small>Zajonc (1997).&nbsp;Emotions. In Gilbert, Fiske, &amp; Lindzey (eds.), <em>Handbook of social psychology</em> (4th ed., pp. 591\u2013632). Oxford University Press.</small></p>", "sections": [{"title": "Attribute substitution", "anchor": "Attribute_substitution", "level": 1}, {"title": "Supervision of intuitive judgments", "anchor": "Supervision_of_intuitive_judgments", "level": 1}, {"title": "Conclusion", "anchor": "Conclusion", "level": 1}, {"title": "Notes", "anchor": "Notes", "level": 1}, {"title": "References", "anchor": "References", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "19 comments"}], "headingsCount": 7}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 19, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["cXzTpSiCrNGzeoRAz", "WTS4ZbEwvKrcrnaaN", "FwiPfF8Woe5JrzqEu", "Kow8xRzpfkoY7pa69"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-15T03:54:32.787Z", "modifiedAt": null, "url": null, "title": "First Triangle LW Meetup 5/4 7pm (Raleigh/Durham/Chapel Hill)", "slug": "first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:49.574Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Z6baaAwf3QihNxAju/first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0", "pageUrlRelative": "/posts/Z6baaAwf3QihNxAju/first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0", "linkUrl": "https://www.lesswrong.com/posts/Z6baaAwf3QihNxAju/first-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0", "postedAtFormatted": "Friday, April 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20First%20Triangle%20LW%20Meetup%205%2F4%207pm%20(Raleigh%2FDurham%2FChapel%20Hill)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFirst%20Triangle%20LW%20Meetup%205%2F4%207pm%20(Raleigh%2FDurham%2FChapel%20Hill)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6baaAwf3QihNxAju%2Ffirst-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=First%20Triangle%20LW%20Meetup%205%2F4%207pm%20(Raleigh%2FDurham%2FChapel%20Hill)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6baaAwf3QihNxAju%2Ffirst-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FZ6baaAwf3QihNxAju%2Ffirst-triangle-lw-meetup-5-4-7pm-raleigh-durham-chapel-hill-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 134, "htmlBody": "<p><a id=\"more\"></a></p>\n<p>When: Wednesday, May 4th at 7:00 pm</p>\n<p>Where: <a href=\"http://maps.google.com/maps?ie=UTF8&amp;q=morrisville+outlet+mall&amp;fb=1&amp;gl=us&amp;hq=outlet+mall&amp;hnear=Morrisville,+NC&amp;cid=0,0,14550008319969595142&amp;ll=35.861544,-78.819855&amp;spn=0.008521,0.016512&amp;z=17\">Morrisville Outlet Mall Food Court</a>&nbsp;&nbsp;I'll be wearing a Lego evolution shirt and may or may not have a LW sign.</p>\n<p><a href=\"https://docs.google.com/document/d/1mePaq-mH-4LGG8oFhM3pti9I2eM86_Yrxm1MrlqdTJc/edit?hl=en\">This Google doc</a>&nbsp;contains some preliminary notes as well as my phone number. &nbsp;I imagine this meeting will consist of introductions and some meta stuff about future meetups. &nbsp;We have seven people that can attend, including the number three LW poster, Alicorn. &nbsp;Hopefully there are even more LWers in the area,&nbsp;or at least rationalists that we can reach out to; it certainly seems&nbsp;like&nbsp;there should be, being the \"Research Triangle\" and all. And feel free to join us if you're not officially inside the Triangle, of course. &nbsp;If there are a bunch of people in Greensboro or Charlotte, we can probably move the venue further West.</p>\n<p>Hope to see you there!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Z6baaAwf3QihNxAju", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 5, "baseScore": 6, "extendedScore": null, "score": 7.024814885673548e-07, "legacy": true, "legacyId": "6809", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-15T04:48:10.113Z", "modifiedAt": null, "url": null, "title": "DC Meetup: Last Discussion Thread", "slug": "dc-meetup-last-discussion-thread", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:29.413Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "atucker", "createdAt": "2010-08-07T03:49:28.822Z", "isAdmin": false, "displayName": "atucker"}, "userId": "hJiWvoMeXCqB3gTMx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rSY6ZCaaNaoQ5iZei/dc-meetup-last-discussion-thread", "pageUrlRelative": "/posts/rSY6ZCaaNaoQ5iZei/dc-meetup-last-discussion-thread", "linkUrl": "https://www.lesswrong.com/posts/rSY6ZCaaNaoQ5iZei/dc-meetup-last-discussion-thread", "postedAtFormatted": "Friday, April 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20DC%20Meetup%3A%20Last%20Discussion%20Thread&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ADC%20Meetup%3A%20Last%20Discussion%20Thread%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrSY6ZCaaNaoQ5iZei%2Fdc-meetup-last-discussion-thread%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=DC%20Meetup%3A%20Last%20Discussion%20Thread%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrSY6ZCaaNaoQ5iZei%2Fdc-meetup-last-discussion-thread", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrSY6ZCaaNaoQ5iZei%2Fdc-meetup-last-discussion-thread", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 133, "htmlBody": "<p><strong>Followup to:</strong> <a href=\"/lw/53u/dc_meetup_discussion/\">this</a> and <a href=\"/lw/520/baltimore_meetup_410_1pm/3tao\">this</a></p>\n<p>I'm going to be in Cambridge for the next week or so, so I'm posting things now to make sure that we can get the ball rolling.</p>\n<p>There's going to be DC meetups on May 1st and May 15th. 2 PM - 8 PM, unless anyone objects.</p>\n<p>There was discussion about whether to meet in Bethesda or NW DC. I propose that we just try a meetup in both, May 1st in Bethesda and May 15th in NW DC.</p>\n<p>Some questions I have:</p>\n<ul>\n<li>Any suggestions on what I should look for in a venue?</li>\n<li>Anything you want me to ask the Cambridge meetup group?</li>\n</ul>\n<p>I have some preliminary things to talk about in mind, but if you guys could think about a few topics too, it would be helpful.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rSY6ZCaaNaoQ5iZei", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 3, "baseScore": 5, "extendedScore": null, "score": 7.024965692500005e-07, "legacy": true, "legacyId": "6811", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 2, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["aHhtMsf5kX8LDTQJZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-15T19:00:48.008Z", "modifiedAt": null, "url": null, "title": "How Many of Me Are There?", "slug": "how-many-of-me-are-there", "viewCount": null, "lastCommentedAt": "2021-10-27T08:00:47.978Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Eneasz", "createdAt": "2009-05-28T03:21:56.432Z", "isAdmin": false, "displayName": "Eneasz"}, "userId": "Jyi2HnDc3iADHodiK", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/tgYdvLEfHcC7tni9b/how-many-of-me-are-there", "pageUrlRelative": "/posts/tgYdvLEfHcC7tni9b/how-many-of-me-are-there", "linkUrl": "https://www.lesswrong.com/posts/tgYdvLEfHcC7tni9b/how-many-of-me-are-there", "postedAtFormatted": "Friday, April 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20How%20Many%20of%20Me%20Are%20There%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AHow%20Many%20of%20Me%20Are%20There%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtgYdvLEfHcC7tni9b%2Fhow-many-of-me-are-there%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=How%20Many%20of%20Me%20Are%20There%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtgYdvLEfHcC7tni9b%2Fhow-many-of-me-are-there", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FtgYdvLEfHcC7tni9b%2Fhow-many-of-me-are-there", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 494, "htmlBody": "<p>This post is not about many worlds. It is somewhat disjointed, but builds to a single point.</p>\n<p>If an AI was asked today how many human individuals populate this planet, it may not return a number the several-billions range. In fact I&rsquo;d be willing to bet it&rsquo;d return a number in the tens of thousands, with the caveat that the individuals vary wildly in measure.</p>\n<p>I agree with Robin Hanson that if two instances of me exist, and one is terminated, I didn&rsquo;t die, I <a href=\"http://www.overcomingbias.com/2009/11/philosophy-kills.html\">simply got smaller.</a></p>\n<p>In 1995 Robert Sapolsky wrote in <a href=\"http://discovermagazine.com/1995/nov/egoboundariesort586\">Ego Boundaries</a> &ldquo;My students usually come with ego boundaries like exoskeletons. [&hellip;] They want their rituals newly minted and shared horizontally within their age group, not vertically over time,&rdquo; whereas in older societies &ldquo;needs transcend individual rights to a bounded ego, and people in traditional communities are named and raised as successive incarnations. In such societies, Abraham always lives 900 years--he simply finds a new body to inhabit now and then. &rdquo;</p>\n<p>Ego boundaries may be more rigid now, but that doesn&rsquo;t make people more unique. If anything, people have become more like each other. Memes are powerful shapers of <a href=\"http://web.media.mit.edu/~push/ExaminingSOM.html\">mental agents</a>, and as technology allows memes to breed and compete more freely the most viral ones spread through the species.</p>\n<p>Acausal trade allows for amazing efficiencies, not merely on a <a href=\"/lw/4sh/how_i_lost_100_pounds_using_tdt/\">personal level</a> but also via nationalism and religion. People executing strong acausal trading routines will out-compete those who don&rsquo;t.</p>\n<p><a href=\"/lw/15z/ingredients_of_timeless_decision_theory/\">Timeless Decision Theory</a> proscribes making decisions as if choosing the outcome for all actors sufficiently like yourself across all worlds. As competition narrows the field of memeplexes to a handful of powerful and virulent ubermemes, and those memeplexes influence the structure and strength of individual&rsquo;s mental agents in similar ways, people become more like each other. In so doing they are choosing *as if* a single entity more and more effectively. To an outside observer, there may be very little to differentiate two such humans from each other.</p>\n<p>Therefore it may be wrong to think of oneself as a singular person. I am not just me &ndash; I am also effectively everyone who is sufficiently like me. It&rsquo;s been argued that there are only <a href=\"http://us.penguingroup.com/static/html/blogs/seven-stories-rule-world-matt-haig\">seven</a> <a href=\"http://www.ipl.org/div/farq/plotFARQ.html\">stories</a>, and every story can be thought of as an elaboration of one of these. It seems likely there are only a few thousand differentiable people, and everyone is simply one of these with some flare.</p>\n<p>If we think of people in these terms, certain behaviors make more sense. Home-schooling is looked down on because institutional schools are about <a href=\"http://www.overcomingbias.com/2009/12/school-is-propaganda.html\">making other people into us</a>. Suicide is considered more sinful than killing outsiders because suicide *always* reduces the size of the Meta-Person that the suicidee belonged to. Argument and rhetoric isn&rsquo;t just a complete waste of your free time, it&rsquo;s also an attempt to make Meta-Me larger, and Meta-SomeoneElse smaller. Art finally makes sense.</p>\n<p>Added Bonus: You no longer have to <a href=\"/lw/43t/youre_in_newcombs_box/\">have many children to exist</a>. You can instead work on enlarging your Meta-Self&rsquo;s measure.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"tgJoX7PGDDh2vJNqT": 3, "PbShukhzpLsWpGXkM": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "tgYdvLEfHcC7tni9b", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 30, "baseScore": 18, "extendedScore": null, "score": 3.3e-05, "legacy": true, "legacyId": "6823", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 43, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["scwoBEju75C45W5n3", "szfxvS8nsxTgJLBHs", "4MYYr8YmN2fonASCi"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 1, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-15T19:02:02.230Z", "modifiedAt": null, "url": null, "title": "Cryonics: convincing my parents", "slug": "cryonics-convincing-my-parents", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:22.137Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Axel", "createdAt": "2010-11-03T17:32:46.091Z", "isAdmin": false, "displayName": "Axel"}, "userId": "vi498nAvek8eWuMWx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/a76HPuriR2Z5SPsaj/cryonics-convincing-my-parents", "pageUrlRelative": "/posts/a76HPuriR2Z5SPsaj/cryonics-convincing-my-parents", "linkUrl": "https://www.lesswrong.com/posts/a76HPuriR2Z5SPsaj/cryonics-convincing-my-parents", "postedAtFormatted": "Friday, April 15th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cryonics%3A%20convincing%20my%20parents&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACryonics%3A%20convincing%20my%20parents%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa76HPuriR2Z5SPsaj%2Fcryonics-convincing-my-parents%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cryonics%3A%20convincing%20my%20parents%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa76HPuriR2Z5SPsaj%2Fcryonics-convincing-my-parents", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fa76HPuriR2Z5SPsaj%2Fcryonics-convincing-my-parents", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 237, "htmlBody": "<p><!--[if gte mso 9]><xml> <w:WordDocument> <w:View>Normal</w:View> <w:Zoom>0</w:Zoom> <w:DoNotOptimizeForBrowser /> </w:WordDocument> </xml><![endif]--></p>\n<p class=\"MsoNormal\">I'm currently trying to convince my parents to sign up for cryonics.</p>\n<p class=\"MsoNormal\">The problem is that they are completely opposed to the any form of life extension and/or immortality (and that&rsquo;s without even mentioning something as \"strange\" as cryonics). Unfortunately, being their child, I have the intrinsic property that I can never know more about life then they do. The only thing they will believe are scientific studies from respectable scientists (a respectable scientist being someone who only says what they want to hear and is not me)</p>\n<p class=\"MsoNormal\">I have the arguments I gathered from Less Wrong and the <a href=\"http://www.alcor.org/Library/\">Alcor Librar</a><a href=\"http://www.alcor.org/Library/\" target=\"_blank\">y</a>. I&rsquo;m focusing on my mother since my dad is impossible to convince without her support.<br />Her argument is that when you live for a very long time/forever wars are almost guaranteed to occur at least once in your lifetime and she doesn&rsquo;t want to live through those. I asked her when, given that we could perfectly predict the future, we would know a war would break out tomorrow she would commit suicide today. Her answer was yes, as she couldn&rsquo;t bear losing any of us and doesn&rsquo;t want experience a war. I pointed out how I would feel if she died but she just dismissed the entire thing as crazy.<span>&nbsp;&nbsp;&nbsp; </span></p>\n<p class=\"MsoNormal\">My parents aren&rsquo;t religious at all, so that&rsquo;s one less bridge to cross but for all the rest I would greatly appreciate anything that might help convince them.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "a76HPuriR2Z5SPsaj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 9, "extendedScore": null, "score": 2e-05, "legacy": true, "legacyId": "6824", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 22, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-16T01:06:23.475Z", "modifiedAt": null, "url": null, "title": "Offense versus harm minimization", "slug": "offense-versus-harm-minimization", "viewCount": null, "lastCommentedAt": "2017-06-17T04:30:34.223Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Yvain", "createdAt": "2009-02-28T15:53:46.032Z", "isAdmin": false, "displayName": "Scott Alexander"}, "userId": "XgYW5s8njaYrtyP7q", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/9thqSN8HDLM3LTxK5/offense-versus-harm-minimization", "pageUrlRelative": "/posts/9thqSN8HDLM3LTxK5/offense-versus-harm-minimization", "linkUrl": "https://www.lesswrong.com/posts/9thqSN8HDLM3LTxK5/offense-versus-harm-minimization", "postedAtFormatted": "Saturday, April 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Offense%20versus%20harm%20minimization&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AOffense%20versus%20harm%20minimization%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9thqSN8HDLM3LTxK5%2Foffense-versus-harm-minimization%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Offense%20versus%20harm%20minimization%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9thqSN8HDLM3LTxK5%2Foffense-versus-harm-minimization", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F9thqSN8HDLM3LTxK5%2Foffense-versus-harm-minimization", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 2613, "htmlBody": "<p>Imagine that one night, an alien prankster secretly implants electrodes into the brains of an entire country - let's say Britain. The next day, everyone in Britain discovers that pictures of salmon suddenly give them jolts of painful psychic distress. Every time they see a picture of a salmon, or they hear about someone photographing a salmon, or they even contemplate taking such a picture themselves, they get a feeling of wrongness that ruins their entire day.<br /><br />I think most decent people would be willing to go to some trouble to avoid taking pictures of salmon if British people politely asked this favor of them. If someone deliberately took lots of salmon photos and waved them in the Brits' faces, I think it would be fair to say ey isn't a nice person. And if the British government banned salmon photography, and refused to allow salmon pictures into the country, well, maybe not everyone would agree but I think most people would at least be able to understand and sympathize with the reasons for such a law.<br /><br />So why don't most people extend the same sympathy they would give Brits who don't like pictures of salmon, to Muslims who don't like pictures of Mohammed?</p>\n<p><a id=\"more\"></a><br /><strong>SHOULD EVERYBODY DRAW MOHAMMED?</strong><br /><br />I first<sup>1</sup> started thinking along these lines when I heard about <a href=\"http://en.wikipedia.org/wiki/Everybody_Draw_Mohammed_Day\">Everybody Draw Mohammed Day</a>, and revisited the issue recently after discovering <a href=\"http://www.reddit.com/r/mohammadpics/\">http://www.reddit.com/r/mohammadpics/</a>. <br /><br />I have to admit, I find these funny. I want to like them. But my attempts to think of reasons why this is totally different from showing pictures of salmon to British people fail:<br /><br />&bull; You could argue Brits did not choose to have their abnormal sensitivity to salmon while Muslims might be considered to be choosing their sensitivity to Mohammed. But this requires a libertarian free will. Further, I see little difference between how a Muslim \"chooses\" to get upset at disrespect to Mohammed, and how a Westerner might \"choose\" to get upset if you called eir mother a whore. Even though the anger isn't being caused by alien technology, it doesn't feel like a \"choice\" and it's more than just a passing whim. And if tomorrow I tried to \"choose\" to become angry every time someone showed me a picture of a salmon, I couldn't do it - I could pretend to be angry, but I couldn't make myself feel genuine rage.<br /><br />&bull; Muslims' sensitivity to Mohammed is based on a falsehood; Islam is a false religion and Mohammed is too dead to care how anyone depicts him. I agree with this statement, but I don't think it licenses me to cause psychic pain to Muslims. I couldn't go around to mosques and punch Muslims in the face, shouting \"Your religion is false, so you deserve it!\".<br /><br />&bull; It is necessary to draw pictures of Mohammed to show Muslims that violence and terrorism are inappropriate responses. I think the logic here is that a few people drew pictures of Mohammed, some radicals sent out death threats and burned embassies, and now we need to draw more pictures of Mohammed to convince Muslims not to do this. But it sounds pretty stupid when you put it in exactly those words. Say a random Christian kicked a Muslim in the face, and a few other Muslims got really angry, blew the whole thing out of proportion, and killed him and his entire family. This would be an inappropriately strong response, and certainly you could be upset about it, but the proper response wouldn't be to go kicking random Muslims in the face. They didn't do it, and they probably don't even approve. But drawing pictures of Mohammed offends many Muslims, not just the ones who send death threats.<br /><br />&bull; The slippery slope argument: if we allow Muslims' concerns to prevent us from drawing pictures of Mohammed, sooner or later we'll have to accept every two-bit group with a ridiculous superstition and we'll never be able to get anything done. I take this more seriously than the previous three arguments, but I've <a href=\"/lw/24o/eight_short_studies_on_excuses/\">previously argued</a> that granting large established religions special rights is relatively immune to slippery-slope. And anyway, drawing pictures of Mohammed is such an unusual thing to do that we can stop doing it without giving up our right to keep doing something else that's actually useful if the situation comes up later.<br /><br />None of these excuses really does it for me. So my provisional conclusion is that yes, people who draw pictures of Mohammed where Muslims can see them are bad people in the same way that people who go around showing photos of salmon to Brits are bad people.<br /><br />So the big question is: why is this so controversial in the Mohammed example, when it seems so obvious in the salmon example?<br /><br /><strong>A BLAME-BASED CONCEPT OF OFFENSE<br /></strong><br />I think several features of the salmon example trigger consequentialist moral reasoning, in which the goal is to figure out how to satisfy as many people's preferences as possible; several contrasting features of the Mohammed case trigger deontological moral reasoning, in which the goal is to figure out who is a good person or a bad person and to assign status and blame appropriately. These two forms of reasoning give different results in the two different cases.<br /><br />The word that comes up a lot in discussions of this sort of issue is \"offensive\". When someone draws Mohammed, it is considered offensive to Muslims. When someone writes a story where all the sympathetic and interesting characters are male, it is considered offensive to women.<br /><br />For me, the word \"offensive\" brings up connotations of \"It was morally wrong to say this, and you are either inexcusably ignorant of this fact or deliberately malicious. You must immediately apologize, and it is up to the group you have offended to decide whether they accept your apology or whether they want to punish you in some well-deserved way.\"</p>\n<p>This means that ever admitting you were offensive is a huge status hit implying you are some combination of callous, ignorant, and racist. Sometimes people may be willing to take this status hit, especially if upon reflection they believe they really were in the wrong, but since most people's actions seem reasonable to themselves they will not be willing to accept a narrative where they're the villain.<br /><br />More likely, they will try to advance an alternative interpretation, in which their actions were not legitimately offensive or in which they have the \"right\" to take such actions. Such an interpretation may cast the offended party as a villain, trying to gain power and control by pretending to be offended, or unduly restricting the free speech of others.<br /><br />The controversy over drawing Mohammed has several factors that predispose to this sort of interpretation. There is already a history of misunderstanding and some enmity between Muslims and non-Muslims. Muslims' status as a minority makes ideas of \"political correctness\" readily primed and available, making people likely to <a href=\"/lw/13k/missing_the_trees_for_the_forest/\">miss the trees for the forest</a>. Muslims are often of a different race than Christians, so conflicts with them risk tarring a person with the deeply insulting label of \"racist\". And because there are reports of Muslims rioting and hurting other people because of Mohammed drawings, they are easy to villainize.</p>\n<p>This risks embroiling everyone in an unproductive argument about whether an action was \"legitimately offensive\" or not, with much status riding on the result.</p>\n<p><strong>A CONSEQUENTIALIST CONCEPT OF HARM MINIMIZATION</strong><br /><br />The British salmon example, on the other hand, was designed to avoid the idea of \"offense\" and trigger consequentialist notions of harm minimization<sup>2</sup>.<br /><br />The example specifically refers to the displeasure that salmon cause the British as \"psychic pain\", priming ideas about whether it is acceptable to cause pain to another person. The British are described as politely asking us to avoid salmon photography as a favor to them, putting themselves in a low status position rather than demanding we respect their status. British are white and first world, so it's hard to think of this as a political correctness issue and wade into that particular quagmire. And because the whole salmon problem is the result of an alien prankster, there's no easily available narrative in which the British are at fault.</p>\n<p>A consequentialist reasoner would consider how much disutility it causes not to be able to use pictures of salmon where the British might see them, then consider how much disutility it causes the British to see pictures of salmon, and if the latter outweighed the former, they'd stop with the salmon pictures. There's an argument to be made about slippery slope, but in this case the slope doesn't seem too slippery and other cases can be evaluated on their merits.<br /><br />And a consequentialist British person, when considering how to convince a foreigner to stop using pictures of salmon, would try to phrase eir request in a way that minimizes the chances that the foreigner gets upset and confrontational, and maximizes the chances that they actually stop with the salmon. <br /><br />If the foreigner refused to stop with the salmon pictures, the British person would try to shame and discredit the foreigner into doing so only if ey thought it would work better than any less confrontational method, and only if the chance of it successfully stopping the offending behavior was great enough that it outweighted the amount of bad feelings and confrontation it would cause.</p>\n<p>This is a healthier and potentially more successful method of resolving offensive actions.<br /><br /><strong>OFFENSE AND TYPICAL MIND</strong> <strong>FALLACY</strong><br /><br />I post on a forum where a bunch of regulars recently denounced the culture of verbal abuse. The abusers, for their part, said that the victims were making mountains out of molehills: exaggerating some good-natured teasing in order to look holier-than-thou.<br /><br />I was friends with some of victims and with some abusers; neither side were majority bad people, and it surprised me that people would view requests to stop verbal abuse as a Machiavellian ploy.<br /><br />Not to say that asking for verbal abuse to stop can't be a Machiavellian ploy. In fact, as far as Machiavellian ploys go, it's a pretty good one - take something your political enemies do, pretend to be deeply offended by it, and then act upset until your enemies are forced to stop, inconveniencing them and gaining you sympathy. A conspiracy such is this is not impossible, but why is it so often the first possibility people jump to?<br /><br />I think it has to do with something I heard one of the abusers say: \"I would never get upset over something little like that.\"<br /><br />I know him and he is telling the truth. When someone is verbally confrontational with him, he takes it in stride or laughs it off, because that's the kind of guy he is.<br /><br />I am of Jewish background. I've had someone use an anti-Semitic slur on me exactly once. My reaction was the same mix of confusion and amusement I'd feel if someone tried a vintage Shakespearean insult. And yet I also know of Jews who have been devastated by anti-Semitic slurs, to the point where they've stopped going to school because someone in school taunted them. These people may differ from me in terms of Jewish identity, extraversion, demographics, social status, anxiety, neurogenetics, and some hard-to-define factor we might as well just call \"thin skin\". <br /><br />The point is, if <a href=\"/lw/dr/generalizing_from_one_example/\">I use my own reactions to model theirs</a>, I will fail, miserably. I will try to connect their reaction to the most plausible situation in which my mind would generate the same reaction in the same situation - in which I am not really upset but am pretending to be so for Machiavellian motives.<br /><br />In the case of anti-Semitism, it's easy to see factors - like a history of suffering from past prejudice - that make other people's responses differ from mine. It's less obvious why someone else might differ in their response to being called ugly, or stupid, or just being told to fuck off - but if these differences really exist, they might explain why people just can't agree about offensive actions.<br /><br />A thick-skinned person just can't model a person with thinner skin all that well. And so when the latter gets upset over some insult, the thick-skinned person calls them \"unreasonable\", or assumes that they're making it up in order to gain sympathy. My friends in the online forum couldn't believe anyone could really be so sensitive as to find their comments abusive, and so they ended up doing some serious mental damage.<br /><br /><strong>SUMMARY</strong><br /><br />Consequentialism suggests a specific course of action for both victims of offense and people performing potentially offensive actions. The victim should judge whether ey believes the offense causes more pain to em than it does benefit to the offender; if so, ey should nonjudgmentally request the offender stop while applying the Principle of Charity to the offender, and if ey wants the maximum chance of the offense stopping, ey should resist the urge to demand an apology or do anything else that could potentially turn it into a status game. <br /><br />The offender, for eir part, should stop offending as soon as ey realizes that the amount of pain eir actions cause is greater than the amount of annoyance it would take to avoid the offending action, even if ey can't understand why it would cause any pain at all. If ey wishes, ey may choose to apologize even though no apology was demanded.<br /><br />If the offender refuses, the victim should only then consider \"punishment\" by trying to shame the offender and make em appear low status, and only if ey thinks this has a real chance of stopping the offending behavior either in this case or in the future. Like all attempts to deliberately harm another person, this course of action requires of the victim exceptional certainty that ey is in the right.<br /><br />Although people pretending to be offended for personal gain is a real problem, it is less common in reality than it is in people's imaginations. If a person appears to suffer from an action of yours which you find completely innocuous, you should consider the possibility that eir mind is different from yours before rejecting eir suffering as feigned.</p>\n<p>&nbsp;</p>\n<p><strong>FOOTNOTES</strong></p>\n<p><strong>1)</strong> Thanks to Kaj Sotala, Vladimir Nesov, and kovacsa-whose-LW-name-I-don't-know for originally encouraging me to turn the original essay into an LW post.</p>\n<p><strong>2)</strong> The deontological notion of offense doesn't really supervene on an idea of pain to other people. If two white people, talking where no black people could possibly overhear them, make a racist joke about black people, that is still \"offensive\", because racism is wrong no matter what. A consequentialist notion of offense could better ground such examples by theorizing that whites telling racist jokes to other whites creates a climate in which racism is considered acceptable, which eventually will end up hurting someone directly. Or it could decide not to, if it decided the link was too tenuous and hokey - but now any disagreement on the matter is honest disagreement about empirical facts and not philosophical disagreement about who's a bad person.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"nSHiKwWyMZFdZg5qt": 1, "NSMKfa8emSbGNXRKD": 1, "MXcpQvaPGtXpB6vkM": 1, "gHCNhqxuJq2bZ2akb": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "9thqSN8HDLM3LTxK5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 104, "baseScore": 83, "extendedScore": null, "score": 0.00017, "legacy": true, "legacyId": "6822", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 83, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 429, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["gFMH3Cqw4XxwL69iy", "MtNnFg4uN32YPoKNa", "baTWMegR42PAsH9qJ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-16T06:45:54.847Z", "modifiedAt": null, "url": null, "title": "wireless-heading, value drift and so on", "slug": "wireless-heading-value-drift-and-so-on", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.081Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "h-H", "createdAt": "2010-01-20T16:15:08.891Z", "isAdmin": false, "displayName": "h-H"}, "userId": "gtYfE7wvJFDrTYutu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TF2Aki8ApbHbf7gyM/wireless-heading-value-drift-and-so-on", "pageUrlRelative": "/posts/TF2Aki8ApbHbf7gyM/wireless-heading-value-drift-and-so-on", "linkUrl": "https://www.lesswrong.com/posts/TF2Aki8ApbHbf7gyM/wireless-heading-value-drift-and-so-on", "postedAtFormatted": "Saturday, April 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20wireless-heading%2C%20value%20drift%20and%20so%20on&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0Awireless-heading%2C%20value%20drift%20and%20so%20on%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTF2Aki8ApbHbf7gyM%2Fwireless-heading-value-drift-and-so-on%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=wireless-heading%2C%20value%20drift%20and%20so%20on%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTF2Aki8ApbHbf7gyM%2Fwireless-heading-value-drift-and-so-on", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTF2Aki8ApbHbf7gyM%2Fwireless-heading-value-drift-and-so-on", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 304, "htmlBody": "<p>A typical image of the wire-head is that of a guy with his brain connected via a wire thingy to a computer, living in a continuous state of pleasure, sort of like being drugged up for life.</p>\n<p>What I mean by wireless heading-which is not such an elegant term but anyway- is the idea of little to no value drift. Clippy is usually brought up as a most dangerous AI that we should avoid creating at all costs, yet what's the point of creating copies of us and tile the universe with them? how is that different than what clippy does?</p>\n<p>by 'us' I mean beings who share our intuitive understanding or can agree with us on things like morality or joy or not being bored etc.</p>\n<p>Shouldn't we focus on engineered/controlled value drift rather than preventing it entirely? is that possible to program into an AI? somehow I don't think so. It seems to me that the whole premise of a single benevolent AI depends to a large extent on the similarity of basic human drives, supposedly we're so close to each other it's not a big deal to prevent value drift.</p>\n<p>but once we get really close to the singularity all sorts of technologies will cause humanity to 'fracture' into so many different groups, that inevitably there will be some groups with what we might call 'alien minds', minds so different than most baseline humans as they are now that there wouldn't be much hope of convincing them to 'rejoin the fold' and not create an AI of their own. for all we know they might even have an easier time creating an AI that's friendly to them than it is for baseline humans to do the same, considering this a black swan event-or one that is impossible to predict when it will happen-what to do?</p>\n<p>discuss.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TF2Aki8ApbHbf7gyM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": -6, "extendedScore": null, "score": -3e-06, "legacy": true, "legacyId": "6829", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": -1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 7, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-16T11:43:06.959Z", "modifiedAt": null, "url": null, "title": "Friendly to who?", "slug": "friendly-to-who", "viewCount": null, "lastCommentedAt": "2017-06-17T04:03:33.104Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "TimFreeman", "createdAt": "2011-04-12T22:58:16.873Z", "isAdmin": false, "displayName": "TimFreeman"}, "userId": "AAP7Amn8h8BhWCjjC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/b9f3xfFvtRtBF3XuB/friendly-to-who", "pageUrlRelative": "/posts/b9f3xfFvtRtBF3XuB/friendly-to-who", "linkUrl": "https://www.lesswrong.com/posts/b9f3xfFvtRtBF3XuB/friendly-to-who", "postedAtFormatted": "Saturday, April 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Friendly%20to%20who%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AFriendly%20to%20who%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb9f3xfFvtRtBF3XuB%2Ffriendly-to-who%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Friendly%20to%20who%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb9f3xfFvtRtBF3XuB%2Ffriendly-to-who", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fb9f3xfFvtRtBF3XuB%2Ffriendly-to-who", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 980, "htmlBody": "<p>At<br />&nbsp;&nbsp; http://lesswrong.com/lw/ru/the_bedrock_of_fairness/ldy<br />Eliezer mentions two challenges he often gets, \"Friendly to who?\" and \"Oh, so you get to say what 'Friendly' means.\"&nbsp; At the moment I see only one true answer to these questions, which I give below.&nbsp; If you can propose alternatives in the comments, please do.</p>\n<p>I suspect morality is in practice a multiplayer game, so talking about it needs multiple people to be involved.&nbsp; Therefore, let's imagine a dialogue between A and B.</p>\n<p>A: Okay, so you're interested in Friendly AI.&nbsp; Who will it be Friendly toward?</p>\n<p>B: Obviously the people who participate in making the system will decide how to program it, so they will decide who it is Friendly toward.</p>\n<p>A: So the people who make the system decide what \"Friendly\" means?</p>\n<p>B: Yes.</p>\n<p>A: Then they could decide that it will be Friendly only toward them, or toward White people.&nbsp; Aren't that sort of selfishness or racism immoral?</p>\n<p>B: I can try to answer questions about the world, so if you can define morality so I can do experiments to discover what is moral and what is immoral, I can try to guess the results of those experiments and report them.&nbsp; What do you mean by morality?</p>\n<p>A: I don't know.&nbsp; If it doesn't mean anything, why do people talk about morality so much?</p>\n<p>B: People often profess beliefs to label themselves as members of a group.&nbsp; So far as I can tell, the belief that some things are moral and other things are not is one of those beliefs.&nbsp; I don't have any other explanation for why people talk so much about something that isn't subject to experimentation.</p>\n<p>A: So if that's what morality is, then it's fundamentally meaningless unless I'm planning out what lies to tell in order to get positive regard from a potential ingroup, or better yet I manage to somehow deceive myself so I can truthfully conform to the consensus morality of my desired ingroup.&nbsp; If that's all it is, there's no constraint on how a Friendly AI works, right?&nbsp; Maybe you'll build it and it will be only be Friendly toward B.</p>\n<p>B: No, because I can't do it by myself.&nbsp; Suppose I approach you and say \"I'm going to make a Friendly AI that lets me control it and doesn't care about anyone else's preference.\"&nbsp; Would you help me?</p>\n<p>A: Obviously not.</p>\n<p>B: Nobody else would either, so the only way I can unilaterally run the world with an FAI is to create it by myself, and I'm not up to that.&nbsp; There are a few other proposed notions of Friendlyness that are nonviable for similar reasons. For example, if I approached you and said \"I'm going to make a Friendly AI that treats everyone fairly, but I don't want to let anybody inspect how it works.\" Would you help me?</p>\n<p>A: No, because I wouldn't trust you.&nbsp; I'd assume that you plan to really make it Friendly only toward yourself, lie about it, and then drop the lie once the FAI had enough power that you didn't need the lie any more.</p>\n<p>B: Right.&nbsp; Here's an ethical system that fails another way: \"I'll make an FAI that cares about every human equally, no matter what they do.\"&nbsp; To keep it simple, let's assume that engineering humans to have strange desires for the purpose of manipulating the FAI is not possible.&nbsp; Would you help me build that?</p>\n<p>A: Well, it fits with my intuitive notion of morality, but it's not clear what incentive I have to help.&nbsp; If you succeed, I seem to win equally at the end whether I help you or not.&nbsp; Why bother?</p>\n<p>B: Right.&nbsp; There are several possible fixes for that.&nbsp; Perhaps if I don't get your help, I won't succeed, and the alternative is that someone else builds it poorly and your quality of life decreases dramatically.&nbsp; That gives you an incentive to help.</p>\n<p>A: Not much of one.&nbsp; You'll surely need a lot of help, and maybe if all those other people help I won't have to.&nbsp; Everyone would make the same decision and nobody would help.</p>\n<p>B: Right.&nbsp; I could solve that problem by paying helpers like you money, if I had enough money.&nbsp; Another option would be to tilt the Friendlyness in the direction of helpers in proportion to how much they help me.</p>\n<p>A: But isn't tilting the Friendlyness unfair?</p>\n<p>B: Depends.&nbsp; Do you want things to be fair?</p>\n<p>A: Yes, for some intuitive notion of \"fairness\" I can't easily describe.&nbsp;</p>\n<p>B: So if the AI cares what you want, that will cause it to figure out what you mean by \"fair\" and tend to make it happen, with that tendency increasing as it tilts more in your favor, right?</p>\n<p>A: I suppose so.&nbsp; No matter what I want, if the AI cares enough about me, it will give me more of what I want, including fairness.&nbsp;</p>\n<p>B: Yes, that's the best idea I have right now.&nbsp; Here's another alternative: What would happen if we only took action when there's a consensus about how to weight the fairness?</p>\n<p>A: Well, 4% of the population are sociopaths.&nbsp; They, and perhaps others, would make ridiculous demands and prevent any consensus.&nbsp; Then we'd be waiting forever to build this thing and someone else who doesn't care about consensus would move while we're dithering and make us irrelevant.&nbsp; Thus we'll have to take action and do something reasonable without having a consensus about what that is.&nbsp; Since we can't wait for a consensus, maybe it makes sense to proceed now.&nbsp; So how about it?&nbsp; Do you need help yet?</p>\n<p>B: Nope, I don't know how to make it.</p>\n<p>A: Damn.&nbsp; Hmm, do you think you'll figure it out before everybody else?</p>\n<p>B: Probably not.&nbsp; There are a lot of everybody else.&nbsp; In particular, business organizations that optimize for profit have a lot of power and have fundamentally inhuman value systems.&nbsp; I don't see how I can take action before all of them.</p>\n<p>A: Me either.&nbsp; We are so screwed.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "b9f3xfFvtRtBF3XuB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 15, "baseScore": 4, "extendedScore": null, "score": 7.030183298496876e-07, "legacy": true, "legacyId": "6833", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 38, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-16T17:21:02.159Z", "modifiedAt": null, "url": null, "title": "Sequence Exercise: first 3 posts from \"A Human's Guide to Words\"", "slug": "sequence-exercise-first-3-posts-from-a-human-s-guide-to", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:24.776Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Normal_Anomaly", "createdAt": "2010-11-14T03:31:54.691Z", "isAdmin": false, "displayName": "Normal_Anomaly"}, "userId": "WgGYj5bqcZKsFNG6F", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/N8tkXCG4YxQEXzNy4/sequence-exercise-first-3-posts-from-a-human-s-guide-to", "pageUrlRelative": "/posts/N8tkXCG4YxQEXzNy4/sequence-exercise-first-3-posts-from-a-human-s-guide-to", "linkUrl": "https://www.lesswrong.com/posts/N8tkXCG4YxQEXzNy4/sequence-exercise-first-3-posts-from-a-human-s-guide-to", "postedAtFormatted": "Saturday, April 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sequence%20Exercise%3A%20first%203%20posts%20from%20%22A%20Human's%20Guide%20to%20Words%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASequence%20Exercise%3A%20first%203%20posts%20from%20%22A%20Human's%20Guide%20to%20Words%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8tkXCG4YxQEXzNy4%2Fsequence-exercise-first-3-posts-from-a-human-s-guide-to%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sequence%20Exercise%3A%20first%203%20posts%20from%20%22A%20Human's%20Guide%20to%20Words%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8tkXCG4YxQEXzNy4%2Fsequence-exercise-first-3-posts-from-a-human-s-guide-to", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FN8tkXCG4YxQEXzNy4%2Fsequence-exercise-first-3-posts-from-a-human-s-guide-to", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 405, "htmlBody": "<p>&nbsp;Folktheory, RobinZ, and I are designing exercises to go with the sequences. Here&rsquo;s my first one. Please make suggestions as to how this could be improved or augmented and what to do the same/differently in future exercises. My current plan is to do more from the sequence \"A Human's Guide to Words.\" This post will be edited to in response to suggestions.</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\"><strong>Exercise for &ldquo;<a href=\"/lw/ne/the_parable_of_the_dagger\">The Parable of the Dagger</a>,\" \"<a href=\"/lw/nf/the_parable_of_hemlock\">The Parable of Hemlock</a>,\" and \"<a href=\"/lw/ng/words_as_hidden_inferences\">Words as Hidden Inferences</a>&rdquo;</strong></p>\n<p class=\"MsoNormal\">This exercise is meant to be worked on a computer. You can fill it out either in your head or by copying the text into a word processor. Please do not read ahead of where you are working. Where applicable, answers are posted in rot13.</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">1. List several properties which are common to crows. Here&rsquo;s <a href=\"http://www.google.com/imgres?imgurl=http://www.freepsychicnetwork.com/Animal_Spirit_Guide/images/crow.jpg&amp;imgrefurl=http://www.freepsychicnetwork.com/Animal_Spirit_Guide/months1.php&amp;usg=__Q1vM8-HjlR0Y7_2eAwzzUhUyQso=&amp;h=350&amp;w=315&amp;sz=114&amp;hl=en&amp;start=0&amp;zoom=1&amp;tbnid=hmAY62MWTpayCM:&amp;tbnh=137&amp;tbnw=144&amp;ei=er6YTdv2D5KSgQf7ja3PCA&amp;prev=/images%3Fq%3Dcrow%26um%3D1%26hl%3Den%26biw%3D1143%26bih%3D733%26tbs%3Disch:1&amp;um=1&amp;itbs=1&amp;iact=hc&amp;vpx=570&amp;vpy=389&amp;dur=2643&amp;hovh=237&amp;hovw=213&amp;tx=132&amp;ty=219&amp;oei=er6YTdv2D5KSgQf7ja3PCA&amp;page=1&amp;ndsp=24&amp;ved=1t:429,r:21,s:0\">a picture of one</a> to help you out:</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">______________________<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>______________________<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">&nbsp;______________________<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>______________________<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">______________________<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>______________________<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">Some of the characteristics you may have put down are &ldquo;black,&rdquo; &ldquo;bird,&rdquo;<span>&nbsp; </span>&ldquo;can fly,&rdquo; and &ldquo;caws.&rdquo;</p>\n<p class=\"MsoNormal\">People in the time of Aristotle believed things were logically 100% certain to have all the properties that were part of their definition. For instance, they said they could be 100% certain that Socrates was mortal because humans are mortal \"by definition.\"</p>\n<p class=\"MsoNormal\">Now, thinking like an Aristotelian and using those four characteristics, is that bird in the linked picture a crow?</p>\n<p class=\"MsoNormal\">Answer: Lbh pna&rsquo;g fnl jurgure vg vf be abg. Lbh unira&rsquo;g frra vg syl be urneq vg pnj.</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">2. Now, suppose I (assume I&rsquo;m completely trustworthy) were to tell you that there is a crow behind that door. If your brain worked like Aristotle thought, you would be certain that it had all the properties listed above. Think of two ways that you could be wrong.</p>\n<p class=\"MsoNormal\">Some possible answers:</p>\n<p class=\"MsoNormal\">Gur pebj pbhyq or n ungpuyvat, jvgubhg erq srnguref be gur novyvgl gb syl.</p>\n<p class=\"MsoNormal\">Vg pbhyq or na nyovab.</p>\n<p class=\"MsoNormal\">Vg pbhyq or obea zhgr.</p>\n<p class=\"MsoNormal\">&nbsp;</p>\n<p class=\"MsoNormal\">If you were able to think of any of those answers, that shows you weren&rsquo;t really certain. The fact that answers exist shows that it would be incorrect to be certain. If you were, and you looked behind the door and saw an albino crow, you either would have denied it was a crow, and been wrong, or you wouldn&rsquo;t have been able to believe it was white. Assigning something zero probability means you can never update your beliefs no matter how much evidence you see.</p>\n<p class=\"MsoNormal\">Saying an object belongs in a category does not force it to conform to the attributes of the category.</p>\n<p>&nbsp;</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DWWZwkxTJs4d5WrcX": 1, "FtT2T9bRbECCGYxrL": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "N8tkXCG4YxQEXzNy4", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 37, "baseScore": 43, "extendedScore": null, "score": 8.7e-05, "legacy": true, "legacyId": "6834", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 43, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 18, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["hQxYBfu2LPc9Ydo6w", "bcM5ft8jvsffsZZ4Y", "3nxs2WYDGzJbzcLMp"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-16T22:26:41.600Z", "modifiedAt": null, "url": null, "title": "\"High Value\" Karma vs \"Regular\" (i.e. Quirrell Points)", "slug": "high-value-karma-vs-regular-i-e-quirrell-points", "viewCount": null, "lastCommentedAt": "2017-06-17T03:59:58.534Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Raemon", "createdAt": "2010-09-09T02:09:20.629Z", "isAdmin": true, "displayName": "Raemon"}, "userId": "r38pkCm7wF4M44MDQ", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/wb9vudKMxQsAugan5/high-value-karma-vs-regular-i-e-quirrell-points", "pageUrlRelative": "/posts/wb9vudKMxQsAugan5/high-value-karma-vs-regular-i-e-quirrell-points", "linkUrl": "https://www.lesswrong.com/posts/wb9vudKMxQsAugan5/high-value-karma-vs-regular-i-e-quirrell-points", "postedAtFormatted": "Saturday, April 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20%22High%20Value%22%20Karma%20vs%20%22Regular%22%20(i.e.%20Quirrell%20Points)&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0A%22High%20Value%22%20Karma%20vs%20%22Regular%22%20(i.e.%20Quirrell%20Points)%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwb9vudKMxQsAugan5%2Fhigh-value-karma-vs-regular-i-e-quirrell-points%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=%22High%20Value%22%20Karma%20vs%20%22Regular%22%20(i.e.%20Quirrell%20Points)%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwb9vudKMxQsAugan5%2Fhigh-value-karma-vs-regular-i-e-quirrell-points", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fwb9vudKMxQsAugan5%2Fhigh-value-karma-vs-regular-i-e-quirrell-points", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 470, "htmlBody": "<p>I consider this a low value post, because it muses about a particular idea without actually doing hard work to get it done. (I do not have the knowledge or resources to do so, or even know if it's possible to implement this idea on Less Wrong. I'm not even sure if it would be worth the effort)</p>\n<p>There are posts that I upvote because I thought they were funny, mildly informative or well reasoned. Sometimes I upvote a simple (easy to produce) link to a good article. Sometimes I admit I upvote them simply because I agree with them (I generally don't upvote things I agree with if they use bad reasoning, but I am less likely to upvote something I DON'T agree with unless it is extremely well thought out, to the point that I actually updated my beliefs because of it.) I don't apologize for that - it's a natural outgrowth of the Karma system. It costs me nothing to give Karma to whatever I like and there is no means to enforce any particular usage of Karma.</p>\n<p>But there are things I upvote because they were actually important and good and required hard work to put together. And I feel a little bit sad that the most I can reward those things is with a \"click\" that is exactly as valuable as the click I give people who said something mildly funny.</p>\n<p>High value posts tend to acquire a lot of Karma because a lot of people feel motivated to click. But I think there is a qualitative difference between a guy who makes one amazing post that gathers 80 Karma and a guy who makes 80 posts that are kinda neat. I think it would interesting, fun, and potentially valuable to distinguish between those kinds of people.</p>\n<p>So what if we had regular Karma, and then we had some kind of Superkarma. (Perhaps a good name would be \"Status\"). Status points would be genuinely rare - when you give one, you are not allowed to give another one for at least 24 hours. You can still give them to a funny joke or viewpoint that aligns with your tribe, but I think assigning them rarity would encourage people to reward genuinely important things. (I'm not sure 24 hours is the ideal waiting period, it just sounded nice).</p>\n<p>I'm actually kinda amazed by how much I care about Karma. I get a \"sweet, level up!\" message in my head every time I see that I've passed another 100 points. But most of my Karma is from random comments. The two fastest upvoted posts I made were links to an article about the Singularity and a webcomic, neither of which required much effort on my part. The fact that my more serious posts are judged by the same metric is (slightly) demotivating.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"MfpEPj6kJneT9gWT6": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "wb9vudKMxQsAugan5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 17, "baseScore": 20, "extendedScore": null, "score": 4.2e-05, "legacy": true, "legacyId": "6837", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 20, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 83, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-16T23:20:51.350Z", "modifiedAt": null, "url": null, "title": "The right kind of fun?", "slug": "the-right-kind-of-fun", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:29.363Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Dorikka", "createdAt": "2010-12-11T03:34:20.472Z", "isAdmin": false, "displayName": "Dorikka"}, "userId": "HJB33ckc8NzPbvJYz", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/aHJ6gT4rSZbRd4eNr/the-right-kind-of-fun", "pageUrlRelative": "/posts/aHJ6gT4rSZbRd4eNr/the-right-kind-of-fun", "linkUrl": "https://www.lesswrong.com/posts/aHJ6gT4rSZbRd4eNr/the-right-kind-of-fun", "postedAtFormatted": "Saturday, April 16th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20The%20right%20kind%20of%20fun%3F&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AThe%20right%20kind%20of%20fun%3F%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaHJ6gT4rSZbRd4eNr%2Fthe-right-kind-of-fun%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=The%20right%20kind%20of%20fun%3F%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaHJ6gT4rSZbRd4eNr%2Fthe-right-kind-of-fun", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FaHJ6gT4rSZbRd4eNr%2Fthe-right-kind-of-fun", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 200, "htmlBody": "<p>If you consider that the utility generated by working is much greater than the utility directly generated by having fun, then the main thing that you're going to optimizing when you have fun is how much motivation the memory of having that fun increases your working capabilities. This is distinctly different from optimizing for the direct preference fulfillment generated by the fun, even if the same activities are optimal for both utility functions.</p>\n<p>The same model works for any action A such that the utility generated by the effect of that action on another action is much greater than the utility generated by the action itself. This probably applies to most maintainance actions, such as doing laundry, sleeping, eating, but this is more obvious to us -- we usually don't see laundry as an end unto itself, but we often do pursue fun for it's own sake. I'm not advocating that we shouldn't have fun, but that we (or at least I) seem to be optimizing for the wrong thing -- direct preference fulfillment, rather than motivation.</p>\n<p>This feels like a significant insight, but I tend to get a significant number of false positives. Any ideas on how we might use this?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "aHJ6gT4rSZbRd4eNr", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 4, "extendedScore": null, "score": 1.2e-05, "legacy": true, "legacyId": "6838", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 4, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T10:13:00.247Z", "modifiedAt": null, "url": null, "title": "Ray Kurzweil on The Colbert Report [video embed]", "slug": "ray-kurzweil-on-the-colbert-report-video-embed-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/jkjHtXDJJkqL74dTc/ray-kurzweil-on-the-colbert-report-video-embed-0", "pageUrlRelative": "/posts/jkjHtXDJJkqL74dTc/ray-kurzweil-on-the-colbert-report-video-embed-0", "linkUrl": "https://www.lesswrong.com/posts/jkjHtXDJJkqL74dTc/ray-kurzweil-on-the-colbert-report-video-embed-0", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ray%20Kurzweil%20on%20The%20Colbert%20Report%20%5Bvideo%20embed%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARay%20Kurzweil%20on%20The%20Colbert%20Report%20%5Bvideo%20embed%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjkjHtXDJJkqL74dTc%2Fray-kurzweil-on-the-colbert-report-video-embed-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ray%20Kurzweil%20on%20The%20Colbert%20Report%20%5Bvideo%20embed%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjkjHtXDJJkqL74dTc%2Fray-kurzweil-on-the-colbert-report-video-embed-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FjkjHtXDJJkqL74dTc%2Fray-kurzweil-on-the-colbert-report-video-embed-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 119, "htmlBody": "<p>\n<p><span style=\"white-space: pre;\"> </span>&lt;table style='font:11px arial; color:#333; background-color:#f5f5f5' cellpadding='0' cellspacing='0' width='512' height='340'&gt;&lt;tbody&gt;&lt;tr style='background-color:#e5e5e5' valign='middle'&gt;&lt;td style='padding:2px 1px 0px 5px;'&gt;&lt;a target='_blank' style='color:#333; text-decoration:none; font-weight:bold;' href='http://www.colbertnation.com'&gt;The Colbert Report&lt;/a&gt;&lt;/td&gt;&lt;td style='padding:2px 5px 0px 5px; text-align:right; font-weight:bold;'&gt;Mon - Thurs 11:30pm / 10:30c&lt;/td&gt;&lt;/tr&gt;&lt;tr style='height:14px;' valign='middle'&gt;&lt;td style='padding:2px 1px 0px 5px;' colspan='2'&gt;&lt;a target='_blank' style='color:#333; text-decoration:none; font-weight:bold;' href='http://www.colbertnation.com/the-colbert-report-videos/381488/april-12-2011/ray-kurzweil'&gt;Ray Kurzweil&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style='height:14px; background-color:#353535' valign='middle'&gt;&lt;td colspan='2' style='padding:2px 5px 0px 5px; width:512px; overflow:hidden; text-align:right'&gt;&lt;a target='_blank' style='color:#96deff; text-decoration:none; font-weight:bold;' href='http://www.colbertnation.com/'&gt;www.colbertnation.com&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign='middle'&gt;&lt;td style='padding:0px;' colspan='2'&gt;&lt;embed style='display:block' src='http://media.mtvnservices.com/mgid:cms:item:comedycentral.com:381488' width='512' height='288' type='application/x-shockwave-flash' wmode='window' allowFullscreen='true' flashvars='autoPlay=false' allowscriptaccess='always' allownetworking='all' bgcolor='#000000'&gt;&lt;/embed&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style='height:18px;' valign='middle'&gt;&lt;td style='padding:0px;' colspan='2'&gt;&lt;table style='margin:0px; text-align:center' cellpadding='0' cellspacing='0' width='100%' height='100%'&gt;&lt;tr valign='middle'&gt;&lt;td style='padding:3px; width:33%;'&gt;&lt;a target='_blank' style='font:10px arial; color:#333; text-decoration:none;' href='http://www.colbertnation.com/full-episodes/'&gt;Colbert Report Full Episodes&lt;/a&gt;&lt;/td&gt;&lt;td style='padding:3px; width:33%;'&gt;&lt;a target='_blank' style='font:10px arial; color:#333; text-decoration:none;' href='http://www.indecisionforever.com/'&gt;Political Humor &amp; Satire Blog&lt;/a&gt;&lt;/td&gt;&lt;td style='padding:3px; width:33%;'&gt;&lt;a target='_blank' style='font:10px arial; color:#333; text-decoration:none;' href='http://www.colbertnation.com/video'&gt;Video Archive&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><span style=\"white-space: pre;\"> </span></p>\n</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "jkjHtXDJJkqL74dTc", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6839", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T10:32:51.347Z", "modifiedAt": null, "url": null, "title": "Ray Kurzweil on The Colbert Report [video embed]", "slug": "ray-kurzweil-on-the-colbert-report-video-embed", "viewCount": null, "lastCommentedAt": "2017-06-17T04:01:25.450Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Kevin", "createdAt": "2009-03-01T08:53:06.623Z", "isAdmin": false, "displayName": "Kevin"}, "userId": "8GnKujYLZ2ZZLs5zk", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/cHMqWjY9NMcxhFxQe/ray-kurzweil-on-the-colbert-report-video-embed", "pageUrlRelative": "/posts/cHMqWjY9NMcxhFxQe/ray-kurzweil-on-the-colbert-report-video-embed", "linkUrl": "https://www.lesswrong.com/posts/cHMqWjY9NMcxhFxQe/ray-kurzweil-on-the-colbert-report-video-embed", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Ray%20Kurzweil%20on%20The%20Colbert%20Report%20%5Bvideo%20embed%5D&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ARay%20Kurzweil%20on%20The%20Colbert%20Report%20%5Bvideo%20embed%5D%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcHMqWjY9NMcxhFxQe%2Fray-kurzweil-on-the-colbert-report-video-embed%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Ray%20Kurzweil%20on%20The%20Colbert%20Report%20%5Bvideo%20embed%5D%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcHMqWjY9NMcxhFxQe%2Fray-kurzweil-on-the-colbert-report-video-embed", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FcHMqWjY9NMcxhFxQe%2Fray-kurzweil-on-the-colbert-report-video-embed", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 19, "htmlBody": "<table style=\"font: normal normal normal 11px/normal arial; color: #333333; background-color: #f5f5f5; height: 340px;\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\" width=\"512\">\n<tbody>\n<tr style=\"background-color:#e5e5e5\" valign=\"middle\">\n<td style=\"padding:2px 1px 0px 5px;\"><a style=\"color:#333; text-decoration:none; font-weight:bold;\" href=\"http://www.colbertnation.com\" target=\"_blank\">The Colbert Report</a></td>\n<td style=\"padding:2px 5px 0px 5px; text-align:right; font-weight:bold;\">Mon - Thurs 11:30pm / 10:30c</td>\n</tr>\n<tr style=\"height: 14px;\" valign=\"middle\">\n<td style=\"padding:2px 1px 0px 5px;\" colspan=\"2\"><a style=\"color:#333; text-decoration:none; font-weight:bold;\" href=\"http://www.colbertnation.com/the-colbert-report-videos/381488/april-12-2011/ray-kurzweil\" target=\"_blank\">Ray Kurzweil</a></td>\n</tr>\n<tr style=\"height: 14px; background-color: #353535;\" valign=\"middle\">\n<td style=\"padding: 2px 5px 0px 5px; width: 512px; overflow: hidden; text-align: right;\" colspan=\"2\"><a style=\"color:#96deff; text-decoration:none; font-weight:bold;\" href=\"http://www.colbertnation.com/\" target=\"_blank\">www.colbertnation.com</a></td>\n</tr>\n<tr valign=\"middle\">\n<td style=\"padding:0px;\" colspan=\"2\">\n<object width=\"512\" height=\"288\" data=\"http://media.mtvnservices.com/mgid:cms:item:comedycentral.com:381488\" type=\"application/x-shockwave-flash\">\n<param name=\"bgcolor\" value=\"#000000\" />\n<param name=\"flashvars\" value=\"autoPlay=false\" />\n<param name=\"src\" value=\"http://media.mtvnservices.com/mgid:cms:item:comedycentral.com:381488\" />\n<param name=\"wmode\" value=\"window\" />\n<param name=\"allowfullscreen\" value=\"true\" />\n</object>\n</td>\n</tr>\n<tr style=\"height: 18px;\" valign=\"middle\">\n<td style=\"padding:0px;\" colspan=\"2\">\n<table style=\"text-align: center; height: 100%; margin: 0px;\" border=\"0\" cellspacing=\"0\" cellpadding=\"0\" width=\"100%\">\n<tbody>\n<tr valign=\"middle\">\n<td style=\"padding: 3px; width: 33%;\"><a style=\"font:10px arial; color:#333; text-decoration:none;\" href=\"http://www.colbertnation.com/full-episodes/\" target=\"_blank\">Colbert Report Full Episodes</a></td>\n<td style=\"padding: 3px; width: 33%;\"><a style=\"font:10px arial; color:#333; text-decoration:none;\" href=\"http://www.indecisionforever.com/\" target=\"_blank\">Political Humor &amp; Satire Blog</a></td>\n<td style=\"padding: 3px; width: 33%;\"><a style=\"font:10px arial; color:#333; text-decoration:none;\" href=\"http://www.colbertnation.com/video\" target=\"_blank\">Video Archive</a></td>\n</tr>\n</tbody>\n</table>\n</td>\n</tr>\n</tbody>\n</table>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "cHMqWjY9NMcxhFxQe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.034045349308375e-07, "legacy": true, "legacyId": "6840", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T11:11:35.144Z", "modifiedAt": null, "url": null, "title": "Shanghai Less Wrong Meetup April 30th, 2pm", "slug": "shanghai-less-wrong-meetup-april-30th-2pm", "viewCount": null, "lastCommentedAt": "2011-04-18T16:02:30.201Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Patrick", "createdAt": "2009-02-27T08:09:44.663Z", "isAdmin": false, "displayName": "Patrick"}, "userId": "KC7mjSorWj2XsdL3v", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/PHdwBiininz8bqRgf/shanghai-less-wrong-meetup-april-30th-2pm", "pageUrlRelative": "/posts/PHdwBiininz8bqRgf/shanghai-less-wrong-meetup-april-30th-2pm", "linkUrl": "https://www.lesswrong.com/posts/PHdwBiininz8bqRgf/shanghai-less-wrong-meetup-april-30th-2pm", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Shanghai%20Less%20Wrong%20Meetup%20April%2030th%2C%202pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AShanghai%20Less%20Wrong%20Meetup%20April%2030th%2C%202pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPHdwBiininz8bqRgf%2Fshanghai-less-wrong-meetup-april-30th-2pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Shanghai%20Less%20Wrong%20Meetup%20April%2030th%2C%202pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPHdwBiininz8bqRgf%2Fshanghai-less-wrong-meetup-april-30th-2pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FPHdwBiininz8bqRgf%2Fshanghai-less-wrong-meetup-april-30th-2pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 58, "htmlBody": "<p><a id=\"more\"></a></p>\n<p>John Teddy asked me to post the following info for a Less Wrong meetup he is organizing.</p>\n<p><strong>Where</strong>: Starbucks, Carrefour Mall, the Zhongshan Park Store, near the Zhongshan Park Station, Line 2, 3, or 4, Shanghai, China</p>\n<div><span style=\"border-collapse: collapse; font-size: 12px; line-height: 24px;\">B1&amp;B2, No.1018, ChangNing Road, ChangNing District, Shanghai (&nbsp;</span><span style=\"font-family: 'Lucida Grande','Helvetica Neue',Helvetica,Arial; font-size: 16px; line-height: 21px;\">\u957f\u5b81\u8def1018\u53f7,&nbsp; &nbsp;\u9f99\u4e4b\u68a6\u8d2d\u7269\u4e2d\u5fc3B1-2\u697c&nbsp; &nbsp;\u8fd1\u51ef\u65cb\u8def )</span></div>\n<div><br />\n<div><strong>When</strong>: 2011, April 30th at 2pm.</div>\n<div>Contact John Teddy: 18721399070 (phone no.)<br /></div>\n</div>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "PHdwBiininz8bqRgf", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 11, "extendedScore": null, "score": 7.034154526190278e-07, "legacy": true, "legacyId": "6841", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 8, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 3, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": 0, "afLastCommentedAt": "2011-04-17T11:11:35.144Z", "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T13:40:20.112Z", "modifiedAt": null, "url": null, "title": "A confused model of the self-indication assumption", "slug": "a-confused-model-of-the-self-indication-assumption", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.046Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AdeleneDawner", "createdAt": "2009-04-28T14:40:00.131Z", "isAdmin": false, "displayName": "AdeleneDawner"}, "userId": "MeSREm4SMRGxeQ8X3", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/YAHsWvtwSwNHcN2HR/a-confused-model-of-the-self-indication-assumption", "pageUrlRelative": "/posts/YAHsWvtwSwNHcN2HR/a-confused-model-of-the-self-indication-assumption", "linkUrl": "https://www.lesswrong.com/posts/YAHsWvtwSwNHcN2HR/a-confused-model-of-the-self-indication-assumption", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20A%20confused%20model%20of%20the%20self-indication%20assumption&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AA%20confused%20model%20of%20the%20self-indication%20assumption%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAHsWvtwSwNHcN2HR%2Fa-confused-model-of-the-self-indication-assumption%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=A%20confused%20model%20of%20the%20self-indication%20assumption%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAHsWvtwSwNHcN2HR%2Fa-confused-model-of-the-self-indication-assumption", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FYAHsWvtwSwNHcN2HR%2Fa-confused-model-of-the-self-indication-assumption", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 324, "htmlBody": "<p>Imagine that I write a computer program that starts by choosing a random integer W between 0 and 2. It then generates 10^(3W) random simple math problems, numbering each one and placing it in list P. It then chooses a random math problem from P and presents it to me, without telling me what the problem number is for that particular math problem.</p>\n<p>In this case, being presented with a single math problem tells me nothing about the state of W - I expect it to do that in any case. Similarly, if I subsequently find out that I was shown P(50), that rules out W=0 and makes W=1 1,000 times more likely than W=2.</p>\n<p>&nbsp;</p>\n<p>Given that W represents which world we're in, each math problem in P represents a unique person, and being presented with a math problem represents experiencing being that person or knowing that that person exists, the self indication assumption says that my model is flawed.</p>\n<p>&nbsp;</p>\n<p>According to the self-indication assumption, my program needs to do an extra step to be a proper representation. After it generates a list of math problems, it needs to then choose a second random number, X, and present me with a math problem only if there's a math problem numbered X. In this case, being presented with a math problem or not does tell me something about W - I have a much higher chance of getting a math problem if W=2 and a much lower chance if W=0 - and finding out that the one math problem I was presented with was P(50) tells me much more about X than it does about W.</p>\n<p>I don't see why this is a proper representation, or why my first model is flawed, though I suspect it relates to thinking about the issue in terms of specific people rather than any person in the relevant set, and I tend to get lost in the math of the usual discussions. Help?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "YAHsWvtwSwNHcN2HR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 3, "extendedScore": null, "score": 7.034573868045465e-07, "legacy": true, "legacyId": "6843", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 30, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T15:31:26.691Z", "modifiedAt": null, "url": null, "title": "Making Beliefs Pay Rent (in Anticipated Experiences): Exercises", "slug": "making-beliefs-pay-rent-in-anticipated-experiences-exercises", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:29.081Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "RobinZ", "createdAt": "2009-07-08T20:34:05.168Z", "isAdmin": false, "displayName": "RobinZ"}, "userId": "eTMojvi4f2z3pDfsc", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/rB4sLpRcRPWJyDXQj/making-beliefs-pay-rent-in-anticipated-experiences-exercises", "pageUrlRelative": "/posts/rB4sLpRcRPWJyDXQj/making-beliefs-pay-rent-in-anticipated-experiences-exercises", "linkUrl": "https://www.lesswrong.com/posts/rB4sLpRcRPWJyDXQj/making-beliefs-pay-rent-in-anticipated-experiences-exercises", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Making%20Beliefs%20Pay%20Rent%20(in%20Anticipated%20Experiences)%3A%20Exercises&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMaking%20Beliefs%20Pay%20Rent%20(in%20Anticipated%20Experiences)%3A%20Exercises%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrB4sLpRcRPWJyDXQj%2Fmaking-beliefs-pay-rent-in-anticipated-experiences-exercises%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Making%20Beliefs%20Pay%20Rent%20(in%20Anticipated%20Experiences)%3A%20Exercises%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrB4sLpRcRPWJyDXQj%2Fmaking-beliefs-pay-rent-in-anticipated-experiences-exercises", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FrB4sLpRcRPWJyDXQj%2Fmaking-beliefs-pay-rent-in-anticipated-experiences-exercises", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 252, "htmlBody": "<p><em>The following is a series of exercises designed to test one's understanding of \"<a href=\"/lw/i3/making_beliefs_pay_rent_in_anticipated_experiences/\">Making Beliefs Pay Rent (in Anticipated Experiences)</a>\", a post in the <a href=\"http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions\">Mysterious Answers to Mysterious Questions</a>&nbsp;sequence by Eliezer Yudkowsky.</em></p>\n<p><a id=\"more\"></a><strong>A.</strong> Examine the following list of statements. For each statement, ask:&nbsp;What observations would you expect to make if this statement were true that you would not expect to make if this statement were false, or vice-versa?&nbsp;If no such observations exist, indicate that this is so.</p>\n<ol>\n<li>Bismarck is the capital of North Dakota.</li>\n<li>The universe does not exist; all existence is imaginary.</li>\n<li>The earth is flat.</li>\n<li>The comic book <em>Queen &amp; Country</em>&nbsp;is based on the British ITV series <em>The Sandbaggers</em>.</li>\n<li><em>G&ouml;del, Escher, Bach: An Eternal Golden Braid</em>&nbsp;by Douglas Hofstadter is a good book.</li>\n<li>\"A Visit from St. Nicholas\" (a.k.a. \"Twas the Night Before Christmas\") was written by Clement Clarke Moore.</li>\n<li>Herbert Hoover was left-handed.</li>\n</ol>\n<p><strong>B.</strong> In the Dan le Sac vs. Scroobius Pip song \"<a href=\"http://www.youtube.com/watch?v=yoN6XfyQsr4\">Thou Shalt Always Kill</a>\", one of the injunctions given to the listener is, \"Thou shalt not put musicians and recording artists on ridiculous pedestals no matter how great they are or were.\" After this statement comes a list of such bands, beginning, \"The Beatles: Were just a band. Led Zeppelin: Just a band. The Beach Boys: Just a band.\" Consider just this first statement, that the Beatles were just a band. What does it imply in terms of anticipated experiences?</p>\n<p>The author's remarks on the solutions to these questions appear in <a href=\"/r/discussion/lw/53b/making_beliefs_pay_rent_in_anticipated/3yba\">this comment</a>.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"SJFsFfFhE6m2ThAYJ": 1, "DWWZwkxTJs4d5WrcX": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "rB4sLpRcRPWJyDXQj", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 31, "baseScore": 38, "extendedScore": null, "score": 6.8e-05, "legacy": true, "legacyId": "6599", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 31, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 13, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["a7n8GdKiAZRX86T5A"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T20:22:43.498Z", "modifiedAt": null, "url": null, "title": "Sequence Exercise: \"Extensions and Intensions\" from \"A Human's Guide to Words\"", "slug": "sequence-exercise-extensions-and-intensions-from-a-human-s", "viewCount": null, "lastCommentedAt": "2017-06-17T04:26:03.324Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Normal_Anomaly", "createdAt": "2010-11-14T03:31:54.691Z", "isAdmin": false, "displayName": "Normal_Anomaly"}, "userId": "WgGYj5bqcZKsFNG6F", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/7JRkoSyXFpp9fxqN5/sequence-exercise-extensions-and-intensions-from-a-human-s", "pageUrlRelative": "/posts/7JRkoSyXFpp9fxqN5/sequence-exercise-extensions-and-intensions-from-a-human-s", "linkUrl": "https://www.lesswrong.com/posts/7JRkoSyXFpp9fxqN5/sequence-exercise-extensions-and-intensions-from-a-human-s", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Sequence%20Exercise%3A%20%22Extensions%20and%20Intensions%22%20from%20%22A%20Human's%20Guide%20to%20Words%22&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASequence%20Exercise%3A%20%22Extensions%20and%20Intensions%22%20from%20%22A%20Human's%20Guide%20to%20Words%22%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JRkoSyXFpp9fxqN5%2Fsequence-exercise-extensions-and-intensions-from-a-human-s%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Sequence%20Exercise%3A%20%22Extensions%20and%20Intensions%22%20from%20%22A%20Human's%20Guide%20to%20Words%22%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JRkoSyXFpp9fxqN5%2Fsequence-exercise-extensions-and-intensions-from-a-human-s", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2F7JRkoSyXFpp9fxqN5%2Fsequence-exercise-extensions-and-intensions-from-a-human-s", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 149, "htmlBody": "<p>Exercise for &ldquo;<a href=\"/lw/nh/extensions_and_intensions\">Extensions and Intensions</a>&rdquo;</p>\n<p>Give an intensional definition for each of the following words:</p>\n<ol>\n<li>Shoe</li>\n<li>Hope </li>\n<li>Wire</li>\n<li>Green</li>\n<li>Politician</li>\n<li>Apple</li>\n</ol>\n<p>Now rank them from easiest to define to hardest.</p>\n<p>Describe how you would give an extensional definition of the same words:</p>\n<ol>\n<li>Shoe</li>\n<li>Hope </li>\n<li>Wire</li>\n<li>Green</li>\n<li>Politician</li>\n<li>Apple</li>\n</ol>\n<p>Again, rank them from easiest to hardest.</p>\n<p>Are the two lists the same? If not, what tends to make something easier to define intensionally than extensionally and vice versa?</p>\n<hr />\n<p>You can share your answers in the comments. I'm interested in seeing how similarly people think of these things. Please make suggestions as to how this could be improved or augmented and what to do the same/differently in future exercises. My current plan is to do more from the sequence \"A Human's Guide to Words.\" This post will be edited in response to suggestions.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "7JRkoSyXFpp9fxqN5", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 16, "baseScore": 19, "extendedScore": null, "score": 3.8e-05, "legacy": true, "legacyId": "6844", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 19, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 20, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["HsznWM9A7NiuGsp28"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-17T23:01:26.545Z", "modifiedAt": null, "url": null, "title": "Build Small Skills in the Right Order", "slug": "build-small-skills-in-the-right-order", "viewCount": null, "lastCommentedAt": "2020-09-08T11:50:55.883Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/qwdupkFd6kmeZHYXy/build-small-skills-in-the-right-order", "pageUrlRelative": "/posts/qwdupkFd6kmeZHYXy/build-small-skills-in-the-right-order", "linkUrl": "https://www.lesswrong.com/posts/qwdupkFd6kmeZHYXy/build-small-skills-in-the-right-order", "postedAtFormatted": "Sunday, April 17th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Build%20Small%20Skills%20in%20the%20Right%20Order&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ABuild%20Small%20Skills%20in%20the%20Right%20Order%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqwdupkFd6kmeZHYXy%2Fbuild-small-skills-in-the-right-order%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Build%20Small%20Skills%20in%20the%20Right%20Order%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqwdupkFd6kmeZHYXy%2Fbuild-small-skills-in-the-right-order", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FqwdupkFd6kmeZHYXy%2Fbuild-small-skills-in-the-right-order", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1634, "htmlBody": "<p>I took some Scientology classes in Hollywood so I could get into their <a href=\"http://www.toastmasters.org/\">Toastmasters</a> club, which is <a href=\"http://www.renaissancespeakers.com/\">the best Toastmasters club in L.A. county</a>.<sup>1</sup> My first Scientology class, '<a href=\"http://www.whatisscientology.org/html/Part03/Chp08/pg0199-a.html\">Success Through Communication</a>', taught skills that were mostly non-specific to Scientology. At first, the class exercises seemed to teach skills too basic to be worth practicing. Later, I came to respect the class as surprisingly useful. (But please, <em>don't</em>&nbsp;take Scientology classes. They are <a href=\"http://commonsenseatheism.com/?p=10554\">highly</a>&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Dark_arts\">Dark Arts</a>, and extremely manipulative.)</p>\n<p>For the first exercise, I had to sit upright, still, and silent with my eyes closed for about an hour. I was to remain alert and aware but utterly calm. When my head drooped or my hand twitched, I was forced to start over. It took me five hours of silent sitting to complete the exercise successfully. At first I thought the exercise was stupid, but later I found I was now more in control of my awareness and attention, and less disturbed by things in the environment.</p>\n<p>For the second exercise, I had to stare directly into someone's eyes without looking away - even for a split second - for 20 minutes in a row. If you've never tried this, you should. It's very difficult. Unfortunately, they first paired me with a 12-year-old girl. I was sure I would freak her out if I stared into her eyes for 20 minutes (it's an intense experience), so I made faces when the instructors weren't looking and waited for them to pair me with an adult. After half a dozen failures, I finally managed to maintain eye contact for 20 minutes in a row, without a single glance away or a long blink.</p>\n<p>Again, this seemed absurd at the time, but later I discovered that I no longer had any trouble maintaining eye contact with people. This skill is a small one, but it is highly valuable in almost <a href=\"http://www.mypublicspeakingtips.com/public-speaking-tips/the-importance-of-eye-contact-in-public-speaking/\">every</a> <a href=\"http://hellobeautiful.com/hellobeautiful-original/christiemaillet/5-reasons-why-eye-contact-is-important/\">social</a> <a href=\"http://www.stevenaitchison.co.uk/blog/6-ways-to-dramatically-improve-your-eye-contact-skills/\">endeavor</a>.</p>\n<p>Later exercises seemed childish. An instructor would ask me simple questions from a book like, \"What's that over there?\" and I would have to answer correctly: \"That's a table.\" I had to do this for hundreds of questions. But I couldn't just say \"That's a table\" any old way. I had to say it without a stutter, I had to enunciate, and I had to speak loudly. Answering questions like this 100 times in a row will reveal how often most of us speak softly, fail to enunciate, and use filler words like \"um.\" Every time I did one of those things, I had to start over.</p>\n<p>In another exercise, the instructor would do everything she could to make me laugh, and I had to sit still and not crack a hint of a smile for 10 minutes in a row. This simple skill took many rounds to master. It is a small skill, but repeating a simple exercise like this will eventually bring almost anyone to mastery of this small skill. At the end of the exercise I had noticeably improved a small part of my self-control mechanism.</p>\n<p>This class - a religious class I took as an atheist in order to achieve an unrelated goal - turned out to be one of the most important classes I have ever taken in my life. It taught me an important meta-skill I have used to great effect ever since.</p>\n<p>This is the meta-skill of building small skills in the right order. It is now one of the key tools in my toolkit for <a href=\"/lw/31/what_do_we_mean_by_rationality/\">instrumental rationality</a>.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4>Why it works</h4>\n<p>Previously, I explained the utility of <a href=\"/lw/3w3/how_to_beat_procrastination/#spirals\">success spirals</a><sup>2</sup>:</p>\n<blockquote>\n<p>When you achieve one challenging goal after another, your obviously gain confidence in your ability to succeed. So: give yourself a series of meaningful, challenging but achievable goals, and then achieve them! Set yourself up for success by doing things you know you can succeed at, again and again, to keep your confidence high.</p>\n</blockquote>\n<p>Building small skills in the right order is an excellent way to create and maintain success spirals.</p>\n<p>Trying to master a large skill set like salesmanship is a daunting task that will likely involve many demotivating failures before you ever taste success. The same goes for public speaking, writing research papers, and lots of other large skill sets involving a complex interaction of many small skills.</p>\n<p><a href=\"http://www.annasalamon.com/\">Anna Salamon</a> uses math to explain this concept. You <em>could</em>&nbsp;tackle calculus immediately after Algebra I, and you might eventually pick it up after many frustrating failures if you read the calculus textbook enough times, but why would you do this? It's much easier and more satisfying to learn more algebra piece by piece until the jump to calculus is not so great. That way, you can experience the pleasure and confidence-boost of mastering new concepts all along the way to calculus.</p>\n<p>A key component of <a href=\"/lw/3w3/how_to_beat_procrastination/\">motivation</a> is time delay. The greater the distance between you and the reward, the less motivated you are to work toward the reward. If you don't experience much reward until you've mastered the entire skill set of salesmanship or public speaking, maintaining motivation will be quite a challenge. But if you experience the reward of mastering small skills all along the way to becoming an effective salesman or public speaker, you have some hope of maintaining motivation throughout the journey.</p>\n<p>&nbsp;</p>\n<h4>Practical examples</h4>\n<p>How might one practice this meta-skill of building small skills in the right order?</p>\n<p>Many skill sets, of course, are taught this way by default. Nobody teaches people to play piano by starting with Rachmaninov. Nobody teaches math by starting with calculus. Nobody teaches rock climbing by first free-climbing a <a href=\"http://en.wikipedia.org/wiki/Grade_(climbing)#YDS_Class\">YDS Class 5.10 route</a>.&nbsp;But in other areas, this rather obvious lesson is not always applied.</p>\n<p>For example, let's say you want to improve your social skills. Don't start by approaching an intimidating businessman and giving him your elevator pitch. You will probably fail, and be demotivated. Instead, start by asking a friend if you can practice staring into his or her eyes for 20 minutes in a row. Offer to buy them lunch, or something. After you've mastered that, ask them to do whatever they can to make you laugh while you try to suppress the urge to smile for 10 minutes in a row. (They will probably do this one without a bribe.) Once you've mastered that, ask them to pretend like they are a stranger so you can approach them and open a conversation 20 times in a row. Have them correct you every time you stutter or speak too softly or without a smile, and start over. Next, do the same exercise with your friend in public. Next, walk up to 10 <em>actual</em>&nbsp;strangers and ask for the time of day, then say \"Thanks\" and walk away. And so on. Build one skill at a time, and pay attention to the satisfaction of mastery each time you master a new small skill. After mastering many such exercises, you will find that you have mastered an <em>entire new skill set</em>&nbsp;that you previously lacked. And you did it with one small, mostly non-scary step at a time.<sup>3</sup></p>\n<p>Or suppose you want to learn how to write research papers. Don't start by setting a goal of having a well-written research paper one month from today. Instead, start by learning <a href=\"http://hcl.harvard.edu/research/guides/google/\">how to use Google effectively</a>. Talk to a local librarian about how to use your library's resources effectively. Learn how to quickly understand the key terms and concepts in a given field (hint: <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">read textbooks</a>), so you know what to look for in <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">Google Scholar</a>. Learn how to bring yourself up to speed very quickly in a given field (hint: find a recent scholarly <em>anthology</em>&nbsp;of review articles from a major academic press, like <a href=\"http://www.amazon.com/Two-Minds-Dual-Processes-Beyond/dp/0199230161/\">this</a> or <a href=\"http://www.amazon.com/Comparative-Cognition-Experimental-Explorations-Intelligence/dp/019537780X/\">this</a> or <a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/\">this</a>). Learn how to skim paper titles and abstracts. Learn <a href=\"http://commonsenseatheism.com/?p=1404\">how to get academic papers for free</a>. Learn how to skim full papers for explanations and references relevant to the particular questions you are looking to answer. Learn how to find the home pages for leading academics in the field to see which papers they've written most recently. Learn the same kinds of small skills - one at a time - relevant to turning all that work into a <a href=\"http://www.amazon.com/Write-Great-Research-Literacy-Essentials/dp/0865306796/\">great research paper</a>. After learning, practicing, and mastering each of these <em>small</em>&nbsp;skills, you will after some time find yourself with some mastery in the entire skill set relevant to writing great research papers.</p>\n<p>If you read a <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">self-help book</a> and its recommendations appear well-vetted but you don't experience much improvement, ask yourself: Which smaller, intermediate skills might I need to master before I can succeed in doing what the self-help book recommends? Practice and master those smaller skills first, then go back to the self-help book and try again. You may discover there are small skills that remain to be mastered before you're ready to tackle what the self-help book recommends, in which case you should do another round of granular self-improvement by mastering small skills that are prerequisites for the skills needed to achieve your larger goals. Fill your <a href=\"/lw/453/procedural_knowledge_gaps/\">procedural knowledge gaps</a>.</p>\n<p>Much failure and frustration and demotivation results from <em>not</em>&nbsp;building small skills in the right order. This is unnecessary. Master small skills, one at a time, and don't be embarrassed about it. <a href=\"/lw/453/procedural_knowledge_gaps/\">Just try it</a>.</p>\n<p>And if you need a partner for eye contact training, just ask. I'll be glad to help kick off your success spiral.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><em>Notes</em></p>\n<p><sup>1</sup> It was a wise choice, by the way. I learned to do public speaking very quickly.</p>\n<p><sup>2</sup> In business academia, success spirals are known as \"efficacy-performance spirals\" or \"efficacy-performance deviation amplifying loops.\" See:&nbsp;Lindsley, Brass, &amp; Thomas (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Lindsley-Efficacy-performance-spirals-A-multilevel-perspective.pdf\">Efficacy-performance spirals: A multilevel perspective</a>. <em>Academy of Management Review, 20(3)</em>: 645-678.</p>\n<p><sup>3</sup> <a href=\"http://www.amazon.com/Social-Skills-Picture-School-Beyond/dp/1932565353/\">This book</a> may also help. It's intended for children and those with various degrees of autism, but if you need to develop your social skills one small skill at a time and you can get over your own ego, it might be useful.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"fF9GEdWXKJ3z73TmB": 3, "fkABsGCJZ6y9qConW": 2, "fR7QfYx4JA3BnptT9": 2, "YwcMcGypGWqtiBKvD": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "qwdupkFd6kmeZHYXy", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 150, "baseScore": 152, "extendedScore": null, "score": 0.000278, "legacy": true, "legacyId": "6790", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 152, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>I took some Scientology classes in Hollywood so I could get into their <a href=\"http://www.toastmasters.org/\">Toastmasters</a> club, which is <a href=\"http://www.renaissancespeakers.com/\">the best Toastmasters club in L.A. county</a>.<sup>1</sup> My first Scientology class, '<a href=\"http://www.whatisscientology.org/html/Part03/Chp08/pg0199-a.html\">Success Through Communication</a>', taught skills that were mostly non-specific to Scientology. At first, the class exercises seemed to teach skills too basic to be worth practicing. Later, I came to respect the class as surprisingly useful. (But please, <em>don't</em>&nbsp;take Scientology classes. They are <a href=\"http://commonsenseatheism.com/?p=10554\">highly</a>&nbsp;<a href=\"http://wiki.lesswrong.com/wiki/Dark_arts\">Dark Arts</a>, and extremely manipulative.)</p>\n<p>For the first exercise, I had to sit upright, still, and silent with my eyes closed for about an hour. I was to remain alert and aware but utterly calm. When my head drooped or my hand twitched, I was forced to start over. It took me five hours of silent sitting to complete the exercise successfully. At first I thought the exercise was stupid, but later I found I was now more in control of my awareness and attention, and less disturbed by things in the environment.</p>\n<p>For the second exercise, I had to stare directly into someone's eyes without looking away - even for a split second - for 20 minutes in a row. If you've never tried this, you should. It's very difficult. Unfortunately, they first paired me with a 12-year-old girl. I was sure I would freak her out if I stared into her eyes for 20 minutes (it's an intense experience), so I made faces when the instructors weren't looking and waited for them to pair me with an adult. After half a dozen failures, I finally managed to maintain eye contact for 20 minutes in a row, without a single glance away or a long blink.</p>\n<p>Again, this seemed absurd at the time, but later I discovered that I no longer had any trouble maintaining eye contact with people. This skill is a small one, but it is highly valuable in almost <a href=\"http://www.mypublicspeakingtips.com/public-speaking-tips/the-importance-of-eye-contact-in-public-speaking/\">every</a> <a href=\"http://hellobeautiful.com/hellobeautiful-original/christiemaillet/5-reasons-why-eye-contact-is-important/\">social</a> <a href=\"http://www.stevenaitchison.co.uk/blog/6-ways-to-dramatically-improve-your-eye-contact-skills/\">endeavor</a>.</p>\n<p>Later exercises seemed childish. An instructor would ask me simple questions from a book like, \"What's that over there?\" and I would have to answer correctly: \"That's a table.\" I had to do this for hundreds of questions. But I couldn't just say \"That's a table\" any old way. I had to say it without a stutter, I had to enunciate, and I had to speak loudly. Answering questions like this 100 times in a row will reveal how often most of us speak softly, fail to enunciate, and use filler words like \"um.\" Every time I did one of those things, I had to start over.</p>\n<p>In another exercise, the instructor would do everything she could to make me laugh, and I had to sit still and not crack a hint of a smile for 10 minutes in a row. This simple skill took many rounds to master. It is a small skill, but repeating a simple exercise like this will eventually bring almost anyone to mastery of this small skill. At the end of the exercise I had noticeably improved a small part of my self-control mechanism.</p>\n<p>This class - a religious class I took as an atheist in order to achieve an unrelated goal - turned out to be one of the most important classes I have ever taken in my life. It taught me an important meta-skill I have used to great effect ever since.</p>\n<p>This is the meta-skill of building small skills in the right order. It is now one of the key tools in my toolkit for <a href=\"/lw/31/what_do_we_mean_by_rationality/\">instrumental rationality</a>.</p>\n<p><a id=\"more\"></a></p>\n<p>&nbsp;</p>\n<h4 id=\"Why_it_works\">Why it works</h4>\n<p>Previously, I explained the utility of <a href=\"/lw/3w3/how_to_beat_procrastination/#spirals\">success spirals</a><sup>2</sup>:</p>\n<blockquote>\n<p>When you achieve one challenging goal after another, your obviously gain confidence in your ability to succeed. So: give yourself a series of meaningful, challenging but achievable goals, and then achieve them! Set yourself up for success by doing things you know you can succeed at, again and again, to keep your confidence high.</p>\n</blockquote>\n<p>Building small skills in the right order is an excellent way to create and maintain success spirals.</p>\n<p>Trying to master a large skill set like salesmanship is a daunting task that will likely involve many demotivating failures before you ever taste success. The same goes for public speaking, writing research papers, and lots of other large skill sets involving a complex interaction of many small skills.</p>\n<p><a href=\"http://www.annasalamon.com/\">Anna Salamon</a> uses math to explain this concept. You <em>could</em>&nbsp;tackle calculus immediately after Algebra I, and you might eventually pick it up after many frustrating failures if you read the calculus textbook enough times, but why would you do this? It's much easier and more satisfying to learn more algebra piece by piece until the jump to calculus is not so great. That way, you can experience the pleasure and confidence-boost of mastering new concepts all along the way to calculus.</p>\n<p>A key component of <a href=\"/lw/3w3/how_to_beat_procrastination/\">motivation</a> is time delay. The greater the distance between you and the reward, the less motivated you are to work toward the reward. If you don't experience much reward until you've mastered the entire skill set of salesmanship or public speaking, maintaining motivation will be quite a challenge. But if you experience the reward of mastering small skills all along the way to becoming an effective salesman or public speaker, you have some hope of maintaining motivation throughout the journey.</p>\n<p>&nbsp;</p>\n<h4 id=\"Practical_examples\">Practical examples</h4>\n<p>How might one practice this meta-skill of building small skills in the right order?</p>\n<p>Many skill sets, of course, are taught this way by default. Nobody teaches people to play piano by starting with Rachmaninov. Nobody teaches math by starting with calculus. Nobody teaches rock climbing by first free-climbing a <a href=\"http://en.wikipedia.org/wiki/Grade_(climbing)#YDS_Class\">YDS Class 5.10 route</a>.&nbsp;But in other areas, this rather obvious lesson is not always applied.</p>\n<p>For example, let's say you want to improve your social skills. Don't start by approaching an intimidating businessman and giving him your elevator pitch. You will probably fail, and be demotivated. Instead, start by asking a friend if you can practice staring into his or her eyes for 20 minutes in a row. Offer to buy them lunch, or something. After you've mastered that, ask them to do whatever they can to make you laugh while you try to suppress the urge to smile for 10 minutes in a row. (They will probably do this one without a bribe.) Once you've mastered that, ask them to pretend like they are a stranger so you can approach them and open a conversation 20 times in a row. Have them correct you every time you stutter or speak too softly or without a smile, and start over. Next, do the same exercise with your friend in public. Next, walk up to 10 <em>actual</em>&nbsp;strangers and ask for the time of day, then say \"Thanks\" and walk away. And so on. Build one skill at a time, and pay attention to the satisfaction of mastery each time you master a new small skill. After mastering many such exercises, you will find that you have mastered an <em>entire new skill set</em>&nbsp;that you previously lacked. And you did it with one small, mostly non-scary step at a time.<sup>3</sup></p>\n<p>Or suppose you want to learn how to write research papers. Don't start by setting a goal of having a well-written research paper one month from today. Instead, start by learning <a href=\"http://hcl.harvard.edu/research/guides/google/\">how to use Google effectively</a>. Talk to a local librarian about how to use your library's resources effectively. Learn how to quickly understand the key terms and concepts in a given field (hint: <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">read textbooks</a>), so you know what to look for in <a href=\"/lw/3gu/the_best_textbooks_on_every_subject/\">Google Scholar</a>. Learn how to bring yourself up to speed very quickly in a given field (hint: find a recent scholarly <em>anthology</em>&nbsp;of review articles from a major academic press, like <a href=\"http://www.amazon.com/Two-Minds-Dual-Processes-Beyond/dp/0199230161/\">this</a> or <a href=\"http://www.amazon.com/Comparative-Cognition-Experimental-Explorations-Intelligence/dp/019537780X/\">this</a> or <a href=\"http://www.amazon.com/Neuroeconomics-Decision-Paul-W-Glimcher/dp/0123741769/\">this</a>). Learn how to skim paper titles and abstracts. Learn <a href=\"http://commonsenseatheism.com/?p=1404\">how to get academic papers for free</a>. Learn how to skim full papers for explanations and references relevant to the particular questions you are looking to answer. Learn how to find the home pages for leading academics in the field to see which papers they've written most recently. Learn the same kinds of small skills - one at a time - relevant to turning all that work into a <a href=\"http://www.amazon.com/Write-Great-Research-Literacy-Essentials/dp/0865306796/\">great research paper</a>. After learning, practicing, and mastering each of these <em>small</em>&nbsp;skills, you will after some time find yourself with some mastery in the entire skill set relevant to writing great research papers.</p>\n<p>If you read a <a href=\"/lw/3nn/scientific_selfhelp_the_state_of_our_knowledge/\">self-help book</a> and its recommendations appear well-vetted but you don't experience much improvement, ask yourself: Which smaller, intermediate skills might I need to master before I can succeed in doing what the self-help book recommends? Practice and master those smaller skills first, then go back to the self-help book and try again. You may discover there are small skills that remain to be mastered before you're ready to tackle what the self-help book recommends, in which case you should do another round of granular self-improvement by mastering small skills that are prerequisites for the skills needed to achieve your larger goals. Fill your <a href=\"/lw/453/procedural_knowledge_gaps/\">procedural knowledge gaps</a>.</p>\n<p>Much failure and frustration and demotivation results from <em>not</em>&nbsp;building small skills in the right order. This is unnecessary. Master small skills, one at a time, and don't be embarrassed about it. <a href=\"/lw/453/procedural_knowledge_gaps/\">Just try it</a>.</p>\n<p>And if you need a partner for eye contact training, just ask. I'll be glad to help kick off your success spiral.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><em>Notes</em></p>\n<p><sup>1</sup> It was a wise choice, by the way. I learned to do public speaking very quickly.</p>\n<p><sup>2</sup> In business academia, success spirals are known as \"efficacy-performance spirals\" or \"efficacy-performance deviation amplifying loops.\" See:&nbsp;Lindsley, Brass, &amp; Thomas (1995). <a href=\"http://commonsenseatheism.com/wp-content/uploads/2011/02/Lindsley-Efficacy-performance-spirals-A-multilevel-perspective.pdf\">Efficacy-performance spirals: A multilevel perspective</a>. <em>Academy of Management Review, 20(3)</em>: 645-678.</p>\n<p><sup>3</sup> <a href=\"http://www.amazon.com/Social-Skills-Picture-School-Beyond/dp/1932565353/\">This book</a> may also help. It's intended for children and those with various degrees of autism, but if you need to develop your social skills one small skill at a time and you can get over your own ego, it might be useful.</p>", "sections": [{"title": "Why it works", "anchor": "Why_it_works", "level": 1}, {"title": "Practical examples", "anchor": "Practical_examples", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "219 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 220, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["RcZCwxFiZzE6X7nsv", "RWo4LwFzpHNQCTcYt", "xg3hXCYQPJkwHyik2", "33KewgYhNSxFpbpXg", "ka8eveZpT7hXLhRTM"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 9, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-18T03:18:26.511Z", "modifiedAt": null, "url": null, "title": "Austin Less Wrong Meetup, Saturday April 23rd, 12:00 Noon", "slug": "austin-less-wrong-meetup-saturday-april-23rd-12-00-noon", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:57.930Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "NMJablonski", "createdAt": "2010-01-08T19:07:30.974Z", "isAdmin": false, "displayName": "NMJablonski"}, "userId": "T2DYijok92QcqTKAW", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/APRJhh2WMjjRdzWma/austin-less-wrong-meetup-saturday-april-23rd-12-00-noon", "pageUrlRelative": "/posts/APRJhh2WMjjRdzWma/austin-less-wrong-meetup-saturday-april-23rd-12-00-noon", "linkUrl": "https://www.lesswrong.com/posts/APRJhh2WMjjRdzWma/austin-less-wrong-meetup-saturday-april-23rd-12-00-noon", "postedAtFormatted": "Monday, April 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Austin%20Less%20Wrong%20Meetup%2C%20Saturday%20April%2023rd%2C%2012%3A00%20Noon&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AAustin%20Less%20Wrong%20Meetup%2C%20Saturday%20April%2023rd%2C%2012%3A00%20Noon%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAPRJhh2WMjjRdzWma%2Faustin-less-wrong-meetup-saturday-april-23rd-12-00-noon%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Austin%20Less%20Wrong%20Meetup%2C%20Saturday%20April%2023rd%2C%2012%3A00%20Noon%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAPRJhh2WMjjRdzWma%2Faustin-less-wrong-meetup-saturday-april-23rd-12-00-noon", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FAPRJhh2WMjjRdzWma%2Faustin-less-wrong-meetup-saturday-april-23rd-12-00-noon", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 105, "htmlBody": "<p><a id=\"more\"></a>This is the second meeting of the <a href=\"/lw/54l/first_waco_texas_lw_meetup_409_1pm/\">group that met in Waco</a>&nbsp;last weekend.&nbsp;Meeting will be at the Starbucks on the corner of 15th and San Antonio, at 12:00 Noon on Saturday. This Starbucks has its own parking, and there are additional public parking options in the surrounding area. The address is:</p>\n<p>501 West 15th Street</p>\n<p>Austin, TX 78701</p>\n<p>We would love to see new people, and feel free to bring friends. Here is a <a href=\"http://i35.photobucket.com/albums/d187/SilasX/WacoMeetup.jpg\">photo</a> of the participants from last time.</p>\n<p>See you all on Saturday</p>\n<p>&nbsp;</p>\n<p>EDIT: Apologies for the late edit all. Skylar sent me the photos from the group yesterday and I wanted to <a href=\"http://img232.imageshack.us/i/img3792d.jpg/\">share one</a>.&nbsp;We're getting bigger!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "APRJhh2WMjjRdzWma", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 1.8e-05, "legacy": true, "legacyId": "6847", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 28, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["SwJY7CjsS5NdatqsZ"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-18T14:07:08.659Z", "modifiedAt": null, "url": null, "title": "Less Wrongers from Austin", "slug": "less-wrongers-from-austin", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:29.466Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "MinibearRex", "createdAt": "2011-02-03T20:01:25.670Z", "isAdmin": false, "displayName": "MinibearRex"}, "userId": "So4JxeRr9GArTAK5D", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/guo7iDdw4yt4XRECz/less-wrongers-from-austin", "pageUrlRelative": "/posts/guo7iDdw4yt4XRECz/less-wrongers-from-austin", "linkUrl": "https://www.lesswrong.com/posts/guo7iDdw4yt4XRECz/less-wrongers-from-austin", "postedAtFormatted": "Monday, April 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Less%20Wrongers%20from%20Austin&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALess%20Wrongers%20from%20Austin%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fguo7iDdw4yt4XRECz%2Fless-wrongers-from-austin%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Less%20Wrongers%20from%20Austin%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fguo7iDdw4yt4XRECz%2Fless-wrongers-from-austin", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fguo7iDdw4yt4XRECz%2Fless-wrongers-from-austin", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 118, "htmlBody": "<p>As far as I know, there is not a group of Less Wrongers from Austin that has formed yet. I haven't ever seen posts about meet-ups, etc. I would really like to get a group started, but I honestly do not know if there is even a single other member on this site who lives nearby, and I don't particularly want to go to all the trouble of finding a meeting place and getting a meet-up set up only to have no one come. So, not committing at all to any future dates for meetings, is there anyone else on this site from Austin? How many people do you know? How many people would be interested in meeting?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "guo7iDdw4yt4XRECz", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 2, "baseScore": 3, "extendedScore": null, "score": 7.038711342186523e-07, "legacy": true, "legacyId": "6857", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 1, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 1, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-18T18:55:32.552Z", "modifiedAt": null, "url": null, "title": "Learned Blankness", "slug": "learned-blankness", "viewCount": null, "lastCommentedAt": "2020-05-08T15:19:02.284Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "AnnaSalamon", "createdAt": "2009-02-27T04:25:14.013Z", "isAdmin": false, "displayName": "AnnaSalamon"}, "userId": "pnFbJAtNHGDK8PHQx", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/puhPJimawPuNZ5wAR/learned-blankness", "pageUrlRelative": "/posts/puhPJimawPuNZ5wAR/learned-blankness", "linkUrl": "https://www.lesswrong.com/posts/puhPJimawPuNZ5wAR/learned-blankness", "postedAtFormatted": "Monday, April 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Learned%20Blankness&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ALearned%20Blankness%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpuhPJimawPuNZ5wAR%2Flearned-blankness%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Learned%20Blankness%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpuhPJimawPuNZ5wAR%2Flearned-blankness", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FpuhPJimawPuNZ5wAR%2Flearned-blankness", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1439, "htmlBody": "<p>Related to: <a href=\"/lw/it/semantic_stopsigns/\">Semantic stopsigns</a>, <a href=\"/lw/la/truly_part_of_you/\">Truly part of you</a>.</p>\n<p>One day, the dishwasher broke. I asked Steve Rayhawk to look at it because he&rsquo;s &ldquo;good with mechanical things&rdquo;.</p>\n<p>&ldquo;The drain is clogged,&rdquo; he said.</p>\n<p>&ldquo;How do you know?&rdquo; I asked.</p>\n<p>He pointed at a pool of backed up water. &ldquo;Because the water is backed up.&rdquo;</p>\n<p>We cleared the clog and the dishwasher started working.</p>\n<p>I felt silly, because I, too, could have reasoned that out. &nbsp;The water wasn&rsquo;t draining -- therefore, perhaps the drain was clogged. &nbsp;Basic rationality in action.[1]</p>\n<p>But before giving it even <em>ten seconds&rsquo;</em> thought, I&rsquo;d classified the problem as a &ldquo;mechanical thing&rdquo;. &nbsp;And I&rsquo;d remembered I &ldquo;didn&rsquo;t know how mechanical things worked&rdquo; (a <a href=\"/lw/k5/cached_thoughts/\">cached thought</a>). &nbsp;And then -- prompted by my cached belief that there was a magical &ldquo;way mechanical things work&rdquo; that some knew and I didn&rsquo;t -- I stopped trying to think at all. &nbsp;</p>\n<p>&ldquo;Mechanical things&rdquo; was for me a mental <a href=\"/lw/it/semantic_stopsigns/\">stopsign</a> -- a blank domain that stayed blank, because I never asked the obvious next questions (questions like &ldquo;does the dishwasher look unusual in any way? &nbsp;Why is there water at the bottom?&rdquo;).</p>\n<p>When I tutored math, new students acted as though the laws of exponents (or whatever we were learning) had fallen from the sky on stone tablets. &nbsp;They clung rigidly to the handed-down procedures. &nbsp;It didn&rsquo;t occur to them to try to understand, or to improvise. &nbsp;The students treated math the way I treated broken dishwashers.</p>\n<p>Martin Seligman coined the term \"<a href=\"http://en.wikipedia.org/wiki/Learned_helplessness\">learned helplessness</a>\" to describe a condition in which someone has learned to behave as though they were helpless. I think we need a term for learned helplessness about thinking (in a particular domain). &nbsp;I&rsquo;ll call this &ldquo;learned blankness&rdquo;[2]. &nbsp;Folks who fall prey to learned blankness may still take actions -- sometimes my students practiced the procedures again and again, hired a tutor, etc. &nbsp;But they do so as though carrying out rituals to an unknown god -- parts of them may be trying, but their &ldquo;understand X&rdquo; center has given up.<a id=\"more\"></a></p>\n<p>To avoid misunderstanding: calling a plumber, and realizing he knows more than you do, can be good. &nbsp;The thing to avoid&nbsp;is mentally walling off your own impressions; keeping parts of your map blank, because you imagine either that the domain itself is <a href=\"/lw/wb/chaotic_inversion/\">chaotic</a>, or that one needs some <a href=\"/lw/qs/einsteins_superpowers/\">special skillset</a> to reason about *that*.</p>\n<h2>Notice your learned blankness</h2>\n<p>Learned blankness is common. &nbsp;My guess is that most of us treat <em>most</em> of our environment as blank givens inaccessible to reason[3]. To spot it in yourself, try comparing yourself to the following examples:</p>\n<p>1. &nbsp;Sandra runs helpless to her roommate when her computer breaks -- she isn&rsquo;t &ldquo;good with computers&rdquo;. &nbsp;Her roommate, by contrast, clicks on one thing and then another, doing Google searches and puzzling it out.[4]</p>\n<p>2. &nbsp;Most scientists know the scientific method is good (and that e.g. p-values of 0.05 are good). &nbsp;But many not only <a href=\"/lw/gv/outside_the_laboratory/\">don&rsquo;t understand</a> why the scientific method (or these p-values) are good -- they don&rsquo;t understand that it&rsquo;s the sort of thing one <em>could</em> understand. &nbsp;</p>\n<p>3. &nbsp;Many respond to questions about consciousness, morality, or <a href=\"/lw/i8/religions_claim_to_be_nondisprovable/\">God</a> by expecting that some other, <a href=\"/lw/iu/mysterious_answers_to_mysterious_questions/\">special</a> kind of reasoning is needed, and, thus, walling off and distrusting their own impressions. &nbsp;</p>\n<p>4. &nbsp;Fred finds he has an intuition about how serious nano risks are. &nbsp;His intuition is a blank for him; something he can act on or ignore, but not examine. &nbsp;It doesn&rsquo;t occur to him that he could examine the causes of his intuition[5], or could examine the accuracy rate of similar intuitions.</p>\n<p>5. &nbsp;I find it hard to fully try to write fiction -- though&nbsp;a drink of alcohol helps. &nbsp;The trouble is that since I&rsquo;m unskilled at fiction-writing, and since I find it painful to <a href=\"/lw/21b/ugh_fields/\">notice</a>&nbsp;my un-skill, <a href=\"/lw/2q6/compartmentalization_in_epistemic_and/\">most of my mind</a> prefers to either not write at all, or to write half-heartedly, picking at the page without *really* trying.&nbsp;&nbsp;Similarly, many pure math specialists avoid seriously trying their hand at philosophy, social science, or other &ldquo;messy&rdquo; areas.</p>\n<p>6. &nbsp;Bob feels a vague desire to \"win\" at life, and a vague dissatisfaction with his current trajectory. &nbsp;But he's never tried to <a href=\"/lw/25d/too_busy_to_think_about_life/\">write down what he means by \"win\"</a>, or what he needs to change to achieve it. &nbsp;He doesn't even realize that he <em>could</em>.</p>\n<p>7. &nbsp;Sandra just doesn&rsquo;t think about much of anything. &nbsp;She drives to work in a car that works by magic, sits down in her cubicle at a company that makes profits by magic, and thinks through her actual coding work. &nbsp;Then she orders some lunch that she magically likes, chats with coworkers via magically habitual chatting-patterns, does another four hours&rsquo; work, and drives home to a relationship that is magically succeeding or failing.</p>\n<p>I&rsquo;m not saying we should constantly re-examine everything. Directed attention, and a focus on your day&rsquo;s work, is useful. But the &ldquo;learned blankness&rdquo; I&rsquo;m discussing is not goal-oriented. &nbsp;Learned blankness means not just choosing to ignore a domain, but viewing that domain as inaccessible; it means being <a href=\"/lw/2q6/compartmentalization_in_epistemic_and/\">alienated</a> from the parts of your mind that could otherwise understand the thing.</p>\n<p>Analogously, there are often good reasons not to e.g. seek a new job, skillset, or romantic partner... but one usually shouldn&rsquo;t be in the depression-like state of learned helplessness about doing so.</p>\n<h2>Reduce learned blankness</h2>\n<p>There are many reasons folks feel helpless about understanding a given topic, including:</p>\n<ul>\n<li>A. &nbsp;Simple habit. You aren&rsquo;t used to thinking about it; and so you just automatically don&rsquo;t.</li>\n</ul>\n<ul>\n<li>B. &nbsp;Desire to avoid initial blunders that will force you to emotionally confront potential incompetence (as with my fear of writing fiction);</li>\n</ul>\n<ul>\n<li>C. &nbsp;Avoidance of social conflict, or of status-claims; if your boss/spouse/whoever will be upset by your disagreement, it may be more comfortable to &ldquo;not understand&rdquo; the domain.</li>\n</ul>\n<p>So, if you&rsquo;d like to reduce your learned blankness, try to notice areas you care about, that you&rsquo;ve been treating as blank defaults. &nbsp;Then, seed some thoughts in that area: set a ten minute timer, and write as many questions as you can about that topic before it beeps. &nbsp;Better yet: hang out with some people for whom the area <em>isn't</em> blank. &nbsp;<a href=\"/lw/58g/levels_of_action/\">Do some mundane tasks that are new to you</a>, so that more of your world is filled in. &nbsp;Ask <a href=\"/lw/58m/build_small_skills_in_the_right_order/\">what subskills</a> can give you stepping-stones.</p>\n<p>If fears such as (B) and (C) pop up, try asking &ldquo;I wonder what it would take to [hit my goals]?&rdquo;. &nbsp;Like: &ldquo;I wonder what it would take to feel comfortable dancing?&rdquo; or &ldquo;I wonder what it would take write fiction without fear?&rdquo;. &nbsp;</p>\n<p>You don&rsquo;t even have to try answering the question; if it&rsquo;s a topic you&rsquo;ve feared, just asking it will open up space in your mind. Then, look up the answers on Google or Wikipedia or How.com and experience the pleasure of gaining competence.</p>\n<p>&nbsp;</p>\n<hr />\n<p>[1] Richard Feynman, as a kid, surprised people because he could &ldquo;<a href=\"http://books.google.com/books?id=7papZR4oVssC&amp;pg=PA20&amp;lpg=PA20&amp;dq=fix+radios+thinking&amp;source=bl&amp;ots=esNY8elP_U&amp;sig=m7miPOIM83Ep_fdVvXBJze3aFyk&amp;hl=en&amp;ei=koesTYSWJIfliAKpiM3vDA&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=7&amp;ved=0CDcQ6AEwBg#v=onepage&amp;q=fix%20radios%20thinking&amp;f=false\">fix radios by thinking</a>&rdquo;; apparently it's common to not-notice that reasoning works on machines.</p>\n<p>[2] Thanks to Steve Rayhawk for suggesting this term. &nbsp;Also, thanks to Lukeprog for helping me write this post.</p>\n<p>[3] <a href=\"http://www.fanfiction.net/s/5782108/1/Harry_Potter_and_the_Methods_of_Rationality\">Eliezer&rsquo;s Harry Potter</a> <a href=\"http://www.fanfiction.net/s/5782108/69/Harry_Potter_and_the_Methods_of_Rationality\">suggests</a> that *not* having learned blankness be pervasive -- not having your world be tiny tunnels of thought, surrounded by large swaths of blankness that you leave alone -- is what it takes to be a &ldquo;hero&rdquo;. &nbsp;To quote:</p>\n<blockquote>\n<p>\"Ah...\" Harry said. His fork and knife nervously sawed at a piece of steak, cutting it into tinier and tinier pieces. \"I think a lot of people can do things when the world channels them into it... like people are expecting you to do it, or it only uses skills you already know, or there's an authority watching to catch your mistakes and make sure you do your part. But problems like that are probably already being solved, you know, and then there's no need for heroes. So I think the people we call 'heroes' are rare because they've got to make everything up as they go along, and most people aren't comfortable with that.&rdquo;</p>\n</blockquote>\n<p>[4] Thanks to Zack Davis for noting that the &ldquo;good with computers&rdquo; trait seems to be substantially about the willingness to play around and figure things out. &nbsp;If you&rsquo;d like to reduce the amount of cached blankness in your life, and you&rsquo;re not already good with computers, acquiring the &ldquo;good with computers&rdquo; trait in Zack&rsquo;s sense is an easy place to start.</p>\n<p>[5] One way to get at the causes of an intuition is to imagine alternate scenarios and see how your intuition changes. &nbsp;Fred might ask himself: \"Suppose nanotech was developed via a Manhattan project. &nbsp;How much doom would I expect then?\" or \"Suppose John (who I learned all this from) changed his mind about doom probabilities. &nbsp;Would that shift my views?\".</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"x6evH6MyPK3nxsoff": 2, "Ng8Gice9KNkncxqcj": 2, "iP2X4jQNHMWHRNPne": 3, "5f5c37ee1b5cdee568cfb0d6": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "puhPJimawPuNZ5wAR", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": null}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "bigUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 167, "baseScore": 215, "extendedScore": null, "score": 0.000394, "legacy": true, "legacyId": "6849", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": "2018-01-30T00:32:03.501Z", "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 215, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": {"html": "<p>Related to: <a href=\"/lw/it/semantic_stopsigns/\">Semantic stopsigns</a>, <a href=\"/lw/la/truly_part_of_you/\">Truly part of you</a>.</p>\n<p>One day, the dishwasher broke. I asked Steve Rayhawk to look at it because he\u2019s \u201cgood with mechanical things\u201d.</p>\n<p>\u201cThe drain is clogged,\u201d he said.</p>\n<p>\u201cHow do you know?\u201d I asked.</p>\n<p>He pointed at a pool of backed up water. \u201cBecause the water is backed up.\u201d</p>\n<p>We cleared the clog and the dishwasher started working.</p>\n<p>I felt silly, because I, too, could have reasoned that out. &nbsp;The water wasn\u2019t draining -- therefore, perhaps the drain was clogged. &nbsp;Basic rationality in action.[1]</p>\n<p>But before giving it even <em>ten seconds\u2019</em> thought, I\u2019d classified the problem as a \u201cmechanical thing\u201d. &nbsp;And I\u2019d remembered I \u201cdidn\u2019t know how mechanical things worked\u201d (a <a href=\"/lw/k5/cached_thoughts/\">cached thought</a>). &nbsp;And then -- prompted by my cached belief that there was a magical \u201cway mechanical things work\u201d that some knew and I didn\u2019t -- I stopped trying to think at all. &nbsp;</p>\n<p>\u201cMechanical things\u201d was for me a mental <a href=\"/lw/it/semantic_stopsigns/\">stopsign</a> -- a blank domain that stayed blank, because I never asked the obvious next questions (questions like \u201cdoes the dishwasher look unusual in any way? &nbsp;Why is there water at the bottom?\u201d).</p>\n<p>When I tutored math, new students acted as though the laws of exponents (or whatever we were learning) had fallen from the sky on stone tablets. &nbsp;They clung rigidly to the handed-down procedures. &nbsp;It didn\u2019t occur to them to try to understand, or to improvise. &nbsp;The students treated math the way I treated broken dishwashers.</p>\n<p>Martin Seligman coined the term \"<a href=\"http://en.wikipedia.org/wiki/Learned_helplessness\">learned helplessness</a>\" to describe a condition in which someone has learned to behave as though they were helpless. I think we need a term for learned helplessness about thinking (in a particular domain). &nbsp;I\u2019ll call this \u201clearned blankness\u201d[2]. &nbsp;Folks who fall prey to learned blankness may still take actions -- sometimes my students practiced the procedures again and again, hired a tutor, etc. &nbsp;But they do so as though carrying out rituals to an unknown god -- parts of them may be trying, but their \u201cunderstand X\u201d center has given up.<a id=\"more\"></a></p>\n<p>To avoid misunderstanding: calling a plumber, and realizing he knows more than you do, can be good. &nbsp;The thing to avoid&nbsp;is mentally walling off your own impressions; keeping parts of your map blank, because you imagine either that the domain itself is <a href=\"/lw/wb/chaotic_inversion/\">chaotic</a>, or that one needs some <a href=\"/lw/qs/einsteins_superpowers/\">special skillset</a> to reason about *that*.</p>\n<h2 id=\"Notice_your_learned_blankness\">Notice your learned blankness</h2>\n<p>Learned blankness is common. &nbsp;My guess is that most of us treat <em>most</em> of our environment as blank givens inaccessible to reason[3]. To spot it in yourself, try comparing yourself to the following examples:</p>\n<p>1. &nbsp;Sandra runs helpless to her roommate when her computer breaks -- she isn\u2019t \u201cgood with computers\u201d. &nbsp;Her roommate, by contrast, clicks on one thing and then another, doing Google searches and puzzling it out.[4]</p>\n<p>2. &nbsp;Most scientists know the scientific method is good (and that e.g. p-values of 0.05 are good). &nbsp;But many not only <a href=\"/lw/gv/outside_the_laboratory/\">don\u2019t understand</a> why the scientific method (or these p-values) are good -- they don\u2019t understand that it\u2019s the sort of thing one <em>could</em> understand. &nbsp;</p>\n<p>3. &nbsp;Many respond to questions about consciousness, morality, or <a href=\"/lw/i8/religions_claim_to_be_nondisprovable/\">God</a> by expecting that some other, <a href=\"/lw/iu/mysterious_answers_to_mysterious_questions/\">special</a> kind of reasoning is needed, and, thus, walling off and distrusting their own impressions. &nbsp;</p>\n<p>4. &nbsp;Fred finds he has an intuition about how serious nano risks are. &nbsp;His intuition is a blank for him; something he can act on or ignore, but not examine. &nbsp;It doesn\u2019t occur to him that he could examine the causes of his intuition[5], or could examine the accuracy rate of similar intuitions.</p>\n<p>5. &nbsp;I find it hard to fully try to write fiction -- though&nbsp;a drink of alcohol helps. &nbsp;The trouble is that since I\u2019m unskilled at fiction-writing, and since I find it painful to <a href=\"/lw/21b/ugh_fields/\">notice</a>&nbsp;my un-skill, <a href=\"/lw/2q6/compartmentalization_in_epistemic_and/\">most of my mind</a> prefers to either not write at all, or to write half-heartedly, picking at the page without *really* trying.&nbsp;&nbsp;Similarly, many pure math specialists avoid seriously trying their hand at philosophy, social science, or other \u201cmessy\u201d areas.</p>\n<p>6. &nbsp;Bob feels a vague desire to \"win\" at life, and a vague dissatisfaction with his current trajectory. &nbsp;But he's never tried to <a href=\"/lw/25d/too_busy_to_think_about_life/\">write down what he means by \"win\"</a>, or what he needs to change to achieve it. &nbsp;He doesn't even realize that he <em>could</em>.</p>\n<p>7. &nbsp;Sandra just doesn\u2019t think about much of anything. &nbsp;She drives to work in a car that works by magic, sits down in her cubicle at a company that makes profits by magic, and thinks through her actual coding work. &nbsp;Then she orders some lunch that she magically likes, chats with coworkers via magically habitual chatting-patterns, does another four hours\u2019 work, and drives home to a relationship that is magically succeeding or failing.</p>\n<p>I\u2019m not saying we should constantly re-examine everything. Directed attention, and a focus on your day\u2019s work, is useful. But the \u201clearned blankness\u201d I\u2019m discussing is not goal-oriented. &nbsp;Learned blankness means not just choosing to ignore a domain, but viewing that domain as inaccessible; it means being <a href=\"/lw/2q6/compartmentalization_in_epistemic_and/\">alienated</a> from the parts of your mind that could otherwise understand the thing.</p>\n<p>Analogously, there are often good reasons not to e.g. seek a new job, skillset, or romantic partner... but one usually shouldn\u2019t be in the depression-like state of learned helplessness about doing so.</p>\n<h2 id=\"Reduce_learned_blankness\">Reduce learned blankness</h2>\n<p>There are many reasons folks feel helpless about understanding a given topic, including:</p>\n<ul>\n<li>A. &nbsp;Simple habit. You aren\u2019t used to thinking about it; and so you just automatically don\u2019t.</li>\n</ul>\n<ul>\n<li>B. &nbsp;Desire to avoid initial blunders that will force you to emotionally confront potential incompetence (as with my fear of writing fiction);</li>\n</ul>\n<ul>\n<li>C. &nbsp;Avoidance of social conflict, or of status-claims; if your boss/spouse/whoever will be upset by your disagreement, it may be more comfortable to \u201cnot understand\u201d the domain.</li>\n</ul>\n<p>So, if you\u2019d like to reduce your learned blankness, try to notice areas you care about, that you\u2019ve been treating as blank defaults. &nbsp;Then, seed some thoughts in that area: set a ten minute timer, and write as many questions as you can about that topic before it beeps. &nbsp;Better yet: hang out with some people for whom the area <em>isn't</em> blank. &nbsp;<a href=\"/lw/58g/levels_of_action/\">Do some mundane tasks that are new to you</a>, so that more of your world is filled in. &nbsp;Ask <a href=\"/lw/58m/build_small_skills_in_the_right_order/\">what subskills</a> can give you stepping-stones.</p>\n<p>If fears such as (B) and (C) pop up, try asking \u201cI wonder what it would take to [hit my goals]?\u201d. &nbsp;Like: \u201cI wonder what it would take to feel comfortable dancing?\u201d or \u201cI wonder what it would take write fiction without fear?\u201d. &nbsp;</p>\n<p>You don\u2019t even have to try answering the question; if it\u2019s a topic you\u2019ve feared, just asking it will open up space in your mind. Then, look up the answers on Google or Wikipedia or How.com and experience the pleasure of gaining competence.</p>\n<p>&nbsp;</p>\n<hr>\n<p>[1] Richard Feynman, as a kid, surprised people because he could \u201c<a href=\"http://books.google.com/books?id=7papZR4oVssC&amp;pg=PA20&amp;lpg=PA20&amp;dq=fix+radios+thinking&amp;source=bl&amp;ots=esNY8elP_U&amp;sig=m7miPOIM83Ep_fdVvXBJze3aFyk&amp;hl=en&amp;ei=koesTYSWJIfliAKpiM3vDA&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=7&amp;ved=0CDcQ6AEwBg#v=onepage&amp;q=fix%20radios%20thinking&amp;f=false\">fix radios by thinking</a>\u201d; apparently it's common to not-notice that reasoning works on machines.</p>\n<p>[2] Thanks to Steve Rayhawk for suggesting this term. &nbsp;Also, thanks to Lukeprog for helping me write this post.</p>\n<p>[3] <a href=\"http://www.fanfiction.net/s/5782108/1/Harry_Potter_and_the_Methods_of_Rationality\">Eliezer\u2019s Harry Potter</a> <a href=\"http://www.fanfiction.net/s/5782108/69/Harry_Potter_and_the_Methods_of_Rationality\">suggests</a> that *not* having learned blankness be pervasive -- not having your world be tiny tunnels of thought, surrounded by large swaths of blankness that you leave alone -- is what it takes to be a \u201chero\u201d. &nbsp;To quote:</p>\n<blockquote>\n<p>\"Ah...\" Harry said. His fork and knife nervously sawed at a piece of steak, cutting it into tinier and tinier pieces. \"I think a lot of people can do things when the world channels them into it... like people are expecting you to do it, or it only uses skills you already know, or there's an authority watching to catch your mistakes and make sure you do your part. But problems like that are probably already being solved, you know, and then there's no need for heroes. So I think the people we call 'heroes' are rare because they've got to make everything up as they go along, and most people aren't comfortable with that.\u201d</p>\n</blockquote>\n<p>[4] Thanks to Zack Davis for noting that the \u201cgood with computers\u201d trait seems to be substantially about the willingness to play around and figure things out. &nbsp;If you\u2019d like to reduce the amount of cached blankness in your life, and you\u2019re not already good with computers, acquiring the \u201cgood with computers\u201d trait in Zack\u2019s sense is an easy place to start.</p>\n<p>[5] One way to get at the causes of an intuition is to imagine alternate scenarios and see how your intuition changes. &nbsp;Fred might ask himself: \"Suppose nanotech was developed via a Manhattan project. &nbsp;How much doom would I expect then?\" or \"Suppose John (who I learned all this from) changed his mind about doom probabilities. &nbsp;Would that shift my views?\".</p>", "sections": [{"title": "Notice your learned blankness", "anchor": "Notice_your_learned_blankness", "level": 1}, {"title": "Reduce learned blankness", "anchor": "Reduce_learned_blankness", "level": 1}, {"divider": true, "level": 0, "anchor": "postHeadingsDivider"}, {"anchor": "comments", "level": 0, "title": "188 comments"}], "headingsCount": 4}, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 188, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["FWMfQKG3RpZx6irjm", "fg9fXrHpeaDD6pEPL", "2MD3NMLBPCqPfnfre", "NyFtHycJvkyNjXNsP", "5o4EZJyqmHY4XgRCY", "N2pENnTPB75sfc9kb", "fAuWLS7RKWD2npBFR", "6i3zToomS86oj9bS6", "EFQ3F6kmt4WHXRqik", "N99KgncSXewWqkzMA", "4psQW7vRwt7PE5Pnj", "guDcrPqLsnhEjrPZj", "qwdupkFd6kmeZHYXy"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 17, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-18T21:21:10.200Z", "modifiedAt": null, "url": null, "title": "Nonsuperintelligent AI threat", "slug": "nonsuperintelligent-ai-threat", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.556Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "PlaidX", "createdAt": "2009-06-28T10:50:31.260Z", "isAdmin": false, "displayName": "PlaidX"}, "userId": "Cgh6rBbvZe4Noxt5d", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/gJqzf9hBnz7xphRFe/nonsuperintelligent-ai-threat", "pageUrlRelative": "/posts/gJqzf9hBnz7xphRFe/nonsuperintelligent-ai-threat", "linkUrl": "https://www.lesswrong.com/posts/gJqzf9hBnz7xphRFe/nonsuperintelligent-ai-threat", "postedAtFormatted": "Monday, April 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Nonsuperintelligent%20AI%20threat&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ANonsuperintelligent%20AI%20threat%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJqzf9hBnz7xphRFe%2Fnonsuperintelligent-ai-threat%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Nonsuperintelligent%20AI%20threat%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJqzf9hBnz7xphRFe%2Fnonsuperintelligent-ai-threat", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FgJqzf9hBnz7xphRFe%2Fnonsuperintelligent-ai-threat", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 99, "htmlBody": "<p>Something that I don't think I've seen discussed here is the threat posed by an AI which is smarter than we are when it comes to computer security without being generally intelligent.</p>\n<p>Suppose there were a computer virus that could read code, to the extent of looking at the programs on a computer, seeing how they process input from the internet, and how they could be exploited to run arbitrary code. Historically, viruses have been annoyances. How much smarter would a virus have to be in order to be a threat on the scale of say, a planetary EMP burst?</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "gJqzf9hBnz7xphRFe", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 12, "baseScore": 16, "extendedScore": null, "score": 7.039936437726812e-07, "legacy": true, "legacyId": "6858", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 9, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 10, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-18T22:14:25.795Z", "modifiedAt": null, "url": null, "title": "Vanilla and chocolate and preference judgements", "slug": "vanilla-and-chocolate-and-preference-judgements", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:34.283Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Swimmer963", "createdAt": "2010-09-28T01:54:53.120Z", "isAdmin": false, "displayName": "Swimmer963"}, "userId": "6Fx2vQtkYSZkaCvAg", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/mqQCuF2m9jSSAfHYB/vanilla-and-chocolate-and-preference-judgements", "pageUrlRelative": "/posts/mqQCuF2m9jSSAfHYB/vanilla-and-chocolate-and-preference-judgements", "linkUrl": "https://www.lesswrong.com/posts/mqQCuF2m9jSSAfHYB/vanilla-and-chocolate-and-preference-judgements", "postedAtFormatted": "Monday, April 18th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Vanilla%20and%20chocolate%20and%20preference%20judgements&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AVanilla%20and%20chocolate%20and%20preference%20judgements%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmqQCuF2m9jSSAfHYB%2Fvanilla-and-chocolate-and-preference-judgements%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Vanilla%20and%20chocolate%20and%20preference%20judgements%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmqQCuF2m9jSSAfHYB%2Fvanilla-and-chocolate-and-preference-judgements", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FmqQCuF2m9jSSAfHYB%2Fvanilla-and-chocolate-and-preference-judgements", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1744, "htmlBody": "<p>Related to: <a href=\"/lw/ro/2place_and_1place_words/\">2-Place and 1-Place Worlds</a>, <a href=\"/lw/59i/offense_versus_harm_minimization/\">Offence versus harm minimization</a>.</p>\n<p>Note: edited to replace 'value' with 'preference' as suggested by orthonormal.</p>\n<p>Imagine you overheard two children having an argument over whether vanilla ice cream was better than chocolate ice cream. To you as an observer, it would be obvious that this kind of argument has no content. The children aren&rsquo;t disputing anything measurable in the exterior world; they would agree with each other than chocolate ice cream contains elements from cocoa beans, and vanilla contains the extract from vanilla beans. Most adults wouldn&rsquo;t have this argument at all, because it&rsquo;s self-evident that if Mary says, truthfully, that she likes vanilla better than chocolate ice cream, and her husband Albert confesses that he prefers chocolate, then <em>both of them are right</em>. There is no contradiction; vanilla and chocolate are both neutral items until they come into contact with human tastebuds and human brains, at which point their positive or negative weighting is a fact about those brains, not about the substances themselves.</p>\n<p>I think that this concept generalizes. Imagine that Mary and Albert are having an argument. Mary hates how Albert leaves papers spread across the kitchen table with empty coffee mugs on top. She wishes he would remember to put his clothes in the laundry basket instead of leaving them on the floor. She nags about it. Albert is helplessly baffled at why she thinks it&rsquo;s such a big deal. He accuses her of being a nitpicker and a perfectionist.<sup>1</sup></p>\n<p>It&rsquo;s hard to say that <em>both</em> of them are right, if each is hurting the other&rsquo;s feelings. Again, though, their argument isn&rsquo;t about anything factual. They both agree that there are papers on the desk and clothes on the floor, and that Albert is the one responsible. Where they diverge is the <em>preference</em> they place on this world-state.<a id=\"more\"></a></p>\n<p>Mary is a bit of a neat freak. She likes shiny floors and spotless counters, and she finds cleaning pleasant and relaxing. Seeing a cluttered countertop causes her a small amount of psychological pain. It doesn&rsquo;t matter where she acquired this attitude; it&rsquo;s so deeply entrenched in her mind that <em>clean is good</em> that she doesn&rsquo;t even realize it&rsquo;s a preference, instead of a fact.</p>\n<p>Albert, in turn, has no particular opinion about a clean living space. It doesn&rsquo;t bother him if the floors are clean enough to eat off, but it doesn&rsquo;t bring him any particular happiness either. He just doesn&rsquo;t notice his environment as much. However, he finds cleaning tedious to the point of pain. Left to his own devices, he would live contentedly in squalor.</p>\n<p>To Mary, Albert seems incredibly lazy. After all, if cleanliness is so pleasant, and the act of cleaning really isn&rsquo;t so bad, what except for laziness could keep her husband from holding up his end of the housework? It&rsquo;s a health hazard, leaving all those dishes everywhere. Doesn&rsquo;t it <em>bother</em> him?</p>\n<p>To Albert, Mary seems obsessive and unreasonable. Why hold yourself to such high standards when it could be so much more rewarding to relax once in a while? It&rsquo;s one thing for her to work herself to the bone keeping the house that clean, but she doesn&rsquo;t <em>have</em> to, and she has no right to ask <em>him</em> to, that&rsquo;s for sure.</p>\n<p>These viewpoints are not contradictory. In a universe that contained no minds, a clean table and a cluttered table would both be neutral objects, but in the world-simulation that Mary&rsquo;s brain builds, a cluttered table is obviously <em>bad</em> and cleaning is neutral. In Albert&rsquo;s world, a cluttered table is neutral and cleaning is bad. Since they live together and each presumably wants the other to be happy.</p>\n<p>If Mary and Albert were rationalists, Mary might say the following:</p>\n<p>&ldquo;Albert, you know that keeping a clean house has a large positive weighting in my utility function, but I know that stuff like vacuuming and scrubbing the bathroom is a big negative in your utility function. I want you to be happy; that means that my utility function includes a miniature copy of yours. Part of me wishes we could share the chores equally because that would feel fairer, but I know it <em>wouldn&rsquo;t</em> be fair; I enjoy cleaning as a way to wind down at the end of a stressful day, but you don&rsquo;t, and I don&rsquo;t have the right to ask you to self-modify so that you would enjoy it. Since I&rsquo;m too busy to do all of the cleaning by myself, would it be too much to ask for you to do 10% of it? That should balance out my desire for fairness with your lack of enjoyment for cleaning. Also, I know you like to spread out and making a mess when you&rsquo;re working, so why don&rsquo;t we say that the study on the second floor belongs to you and you can keep it as messy as you want as long as it doesn&rsquo;t start to smell. In return, I want you to keep your clothes off the floor and please don&rsquo;t leave your papers or your coffee-cups anywhere <em>except</em> the study. That shouldn&rsquo;t be too much to ask?&rdquo;</p>\n<p>Albert has a few minor suggestions to make. Maybe he&rsquo;s willing to do up to 15% of the cleaning, maybe he doesn&rsquo;t mind mopping the floor and just hates vacuuming because it makes his ears hurt, maybe he wants to clarify that he doesn&rsquo;t leave coffee mugs everyone on purpose, he&rsquo;s just <em>really forgetful</em> and may need to be reminded once in a while. But because Albert&rsquo;s a rationalist, too, the discussion goes smoothly. Maybe he even <em>offers</em> to try hacking his attitudes to cleaning so he doesn&rsquo;t find it so unpleasant.</p>\n<p>If Mary and Albert aren&rsquo;t rationalists, though, they have a long way to go to reach that conversation. To each of them, it seems like the other is being pig-headed and deliberately blind about something obvious. Albert doesn&rsquo;t realize that he&rsquo;s making a preference judgement about tidiness versus messiness, let alone that he could <em>change</em> how he feels about it.</p>\n<p>In the past year, I&rsquo;ve started to realize how many of the arguments I have, or hear others having, are not about anything that can be measured. (Maybe this was obvious all along to most people; it wasn&rsquo;t obvious to me.) Different minds work differently. I wish some of my friends would work out more and be fitter, because to me it&rsquo;s <em>really obvious</em> that fitness is incredibly important and exercise is really not all that bad and you feel better afterwards and you focus better and sleep better&hellip;but that&rsquo;s a preference judgement. I made it with <em>my</em> brain, with all its particularities, and even if it&rsquo;s verifiably true for me (and I don&rsquo;t know if I <em>actually</em> focus better after exercise or whether that&rsquo;s just a biased perception) it may be verifiably false for other people. Maybe there are people who just feel tired and sweaty and grumpy after they work out. They might agree that it would be nice to be fitter, but they&rsquo;re not making the same trade-off that I am, because the act of exercising, as separate from its long-term benefits, has a negative rather than a positive weight to them.</p>\n<p>I don&rsquo;t exercise because I judged it a rational thing to do; my mother put me on a swim team when I was eight years old and my body is so used to being worked hard in the pool every day that I get crabby if I <em>don&rsquo;t</em> swim. That a particularity about my childhood and the way it affected the wiring in my brain. It might take someone else orders of magnitude more motivation to follow the same routine that I do, but that doesn&rsquo;t mean they&rsquo;re just being lazy and irrational when they don&rsquo;t work out every day.</p>\n<p>Ultimately, for me this means that if I want to go out and help someone because I think they&rsquo;re making sub-optimal decisions, first I have to make sure my mental model of them is accurate, right down to their preferences and where they differ from mine. What might seem like &lsquo;helping&rsquo; to me could be annoying interference to them, and it&rsquo;s useful to know that in advance. If someone I know spends all their time writing poetry instead of going to the gym, and they fully enjoy that and would consider trading poetry-writing-time for gym-time to be an unreasonable and unnecessary drop in their quality of life, then that&rsquo;s a true fact about how their brain works. It doesn&rsquo;t <em>have</em> to be, and maybe their total happiness would be higher once they got used to getting out of the house; maybe they would find that exercise brought a wave of inspiration; but telling someone they&rsquo;re wrong about <em>their own preferences</em> is not going to help them make that change.<sup>2 </sup></p>\n<p>This applies to the arguments I choose to have, too. If I notice that a pet peeve I have is really a more complicated equivalent of vanilla vs. chocolate, it helps me to find it less irritating and bring it up less often. I don&rsquo;t apply this method often enough in my daily life, but when I do, it snips a lot of needless conflict in the bud, leaving time for discussions and yes, sometimes conflict, over facts or over preferences that I <em>really want</em> to change people&rsquo;s minds about.</p>\n<p><strong>Notes</strong></p>\n<p>1. Albert and Mary are loosely based on the dynamic between myself and my former landlady. She was the tidy one, as were most of my roommates; I was the messy one who apparently drove everyone crazy. It took me most of the year to realize how irrational I was being in the way I treated the whole issue. I did, and still do, value sleeping over cleaning, and my schedule is busy enough that there <em>is</em> a trade-off between the two, but I did sign the contract and agree to live in the house, and there was a certain implicit assumption that I would hold up the same standards as everyone else &hellip; and if I could do the year over, I would either live somewhere else or do a better job of cleaning, because according to my value system it isn't okay to treat other people's values as less worthwhile than your own.</p>\n<p>2. They might <em>not</em> be right about their values; some people have remarkably poor models of what really makes them happy and what they find unpleasant, and another, more rational person might have a better model of them than they do of themselves.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"PJKgSRkXkCqXmCk3M": 2, "chuP2QqQycjD8qakL": 2}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "mqQCuF2m9jSSAfHYB", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 38, "baseScore": 39, "extendedScore": null, "score": 7.040086796863578e-07, "legacy": true, "legacyId": "6859", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 29, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 32, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eDpPnT7wdBwWPGvo5", "9thqSN8HDLM3LTxK5"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T02:24:12.880Z", "modifiedAt": null, "url": null, "title": "Pittsburgh Less Wrong meet-up April 22 7pm", "slug": "pittsburgh-less-wrong-meet-up-april-22-7pm", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.930Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Matt_Duing", "createdAt": "2009-03-06T07:13:31.573Z", "isAdmin": false, "displayName": "Matt_Duing"}, "userId": "QEv5PFb6cmjkrprtR", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/WQqTxjDM3XSBvEkiP/pittsburgh-less-wrong-meet-up-april-22-7pm", "pageUrlRelative": "/posts/WQqTxjDM3XSBvEkiP/pittsburgh-less-wrong-meet-up-april-22-7pm", "linkUrl": "https://www.lesswrong.com/posts/WQqTxjDM3XSBvEkiP/pittsburgh-less-wrong-meet-up-april-22-7pm", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Pittsburgh%20Less%20Wrong%20meet-up%20April%2022%207pm&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APittsburgh%20Less%20Wrong%20meet-up%20April%2022%207pm%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQqTxjDM3XSBvEkiP%2Fpittsburgh-less-wrong-meet-up-april-22-7pm%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Pittsburgh%20Less%20Wrong%20meet-up%20April%2022%207pm%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQqTxjDM3XSBvEkiP%2Fpittsburgh-less-wrong-meet-up-april-22-7pm", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FWQqTxjDM3XSBvEkiP%2Fpittsburgh-less-wrong-meet-up-april-22-7pm", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 14, "htmlBody": "<p><a id=\"more\"></a>We'll be gathering at the Starbucks at 417 South Craig Street at 7:00 PM.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "WQqTxjDM3XSBvEkiP", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.040792045117514e-07, "legacy": true, "legacyId": "6861", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 8, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T04:48:43.407Z", "modifiedAt": null, "url": null, "title": "Introduction to the Sequence Reruns", "slug": "introduction-to-the-sequence-reruns-0", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Unnamed", "createdAt": "2009-02-27T06:08:10.900Z", "isAdmin": false, "displayName": "Unnamed"}, "userId": "PdzQ73mN7S4SvRMhu", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/q3ByvNg95SgySmWzT/introduction-to-the-sequence-reruns-0", "pageUrlRelative": "/posts/q3ByvNg95SgySmWzT/introduction-to-the-sequence-reruns-0", "linkUrl": "https://www.lesswrong.com/posts/q3ByvNg95SgySmWzT/introduction-to-the-sequence-reruns-0", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Introduction%20to%20the%20Sequence%20Reruns&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AIntroduction%20to%20the%20Sequence%20Reruns%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3ByvNg95SgySmWzT%2Fintroduction-to-the-sequence-reruns-0%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Introduction%20to%20the%20Sequence%20Reruns%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3ByvNg95SgySmWzT%2Fintroduction-to-the-sequence-reruns-0", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2Fq3ByvNg95SgySmWzT%2Fintroduction-to-the-sequence-reruns-0", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 1356, "htmlBody": "<p style=\"margin-bottom: 0in;\">BACKGROUND</p>\n<p style=\"margin-bottom: 0in;\">The <a href=\"http://wiki.lesswrong.com/wiki/Sequences\">sequences</a> - hundreds of posts written by Eliezer Yudkowsky from 2006 through 2009 - contain the core material behind Less Wrong, including many ideas that are often treated as background knowledge in new posts. New LW members are encouraged to read the sequences and many LW regulars have expressed interest in rereading them, but even though the posts are sitting in the archives for anyone to read it takes <a href=\"/lw/f1/beware_trivial_inconveniences/\">another step</a> to <em>actually read them</em>.&nbsp; The sheer number of words can be overwhelming, and many people find that they never quite get around to delving in. To many people, reading new blog posts is <em>fun</em> but going through the sequences is <em>work. </em><span style=\"font-style: normal;\">And it can be hard to have lively discussions on years-old posts.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">As announced <a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/\">here</a>, we are introducing the Rerunning the Sequences series to the discussion section as an attempt to make the sequences more accessible by making them more like new blog posts. We will be going through the sequence posts in order, one post per day, making posts that contain a link to the sequence post and a summary of it.&nbsp; If you're interested, follow along (the posts will all have </span><span style=\"font-style: normal;\">[SEQ RERUN] in the title and will be easy to spot), take part in the discussion, and get involved in other ways described below.&nbsp; If you're not interested, you can ignore these posts (they all have </span><span style=\"font-style: normal;\">[SEQ RERUN] in the title and will be easy to spot).</span></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">DETAILS</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">For our purposes, we're considering the sequences to consist of Eliezer's 702 posts (listed in order <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">here</a>) beginning with <a href=\"/lw/gn/the_martial_art_of_rationality/\">The Martial Art of Rationality</a>, ending with <a href=\"/lw/d4/practical_advice_backed_by_deep_theories/\">Practical Advice Backed By Deep Theories</a>, and excluding only open threads, quotes threads, and administrivia. We may also include some posts not by Eliezer, like Robin Hanson's side of the <a href=\"http://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate\">AI Foom Debate</a>. Each day, there will be a post in the discussion section which links to one of these posts and follows the standard template included below.&nbsp; We'll go through the posts in chronological order, one per day, beginning today (April 18, 2011) with The Martial Art of Rationality. These posts will be clearly identified by the [SEQ RERUN] tag in the title, and easy to find under the <a href=\"/r/discussion/tag/sequence_reruns/\">sequence_reruns tag</a>.&nbsp; Hopefully, this will capture the feel of reading a blog, with a new post to read each day.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">Each post also serves as a focal point for discussion. Discussion should take place in the comments to the new post in the discussion section, not the original post, since this is a fresh discussion which is taking place a few years after the original post was made. This will also keep everything in the discussion section, so that the main page doesn't get flooded with comments on old posts.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">This is a community-driven effort, and in order for it to work people will need to get involved. Someone needs to make the sequence reruns post each day, and that role is open to anyone who will do it (just like the open threads and quotes threads). If you're ever wondering where a day's sequence reruns post is, go ahead and make the post. A standard template is being used to make this process as simple as possible - it shouldn't take more than five minutes (especially after you've done it once).&nbsp; Instructions (along with the template to copy and paste) are included at the end of this post.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">Each sequence reruns post includes a summary of the post that it links to, which is taken from the <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">LW wiki</a>. But many of the posts don't have a summary written yet, and some of the others don't have a good summary yet. So another way to be involved is by writing summaries for the posts that need them and adding them to the LW wiki before we get to those posts. After a sequence reruns post has been made, if it is missing a summary or its summary isn't very good then you could write a new summary for it then and leave it in the comments. But it's better to get the summaries written ahead of time.</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">Finally, there are other issues that can arise with the sequence reruns, and decisions to be made.&nbsp; For instance: deciding precisely which posts to include (e.g., should we <a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/3wot\">include all the posts</a> in the AI Foom Debate?). Things will run more smoothly if folks are involved in spotting these issues ahead of time and helping to make the decisions. Discussion about these kinds of issues, and other kinds of meta discussion about the Rerunning the Sequences series, should mostly take place in the comments to this post or in other meta posts, rather than in the comments to individual posts in the series. Discussion in the individual posts should be based on the linked sequence post, rather than on these kinds of meta issues. </span></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">POSTING INSTRUCTIONS</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">To make a post in the Rerunning the Sequences series</span><span style=\"font-style: normal;\">, you will need to copy and paste a standard template (included below) and add links and information from the original sequence post, the previous Sequence Reruns post, and the LW wiki page which has summaries.&nbsp; There are 8 things to change in the template, which I've labeled 111111, 222222, &hellip;, 888888.&nbsp; <br /></span></p>\n<p><span style=\"font-style: normal;\">1. Find the previous Sequence Reruns post and find the sequence post that is due for that day (which will generally be the next post listed <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/All_articles\">here</a>)</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">2. Go to the LW wiki to find a summary of the sequence post (summaries arranged by year: <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries\">2006</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2007_Articles/Summaries\">2007</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2008_Articles/Summaries\">2008</a>, <a href=\"http://wiki.lesswrong.com/wiki/Less_Wrong/2009_Articles/Summaries\">2009</a>); if there are multiple summaries available choose the one that looks best</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">3. Copy and paste the template below into a text document and make the 8 edits to the template:</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">111111 the title of the sequence post (e.g., Why truth? And... )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">222222 the url of the sequence post (e.g., http://lesswrong.com/lw/go/why_truth_and/ )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">333333 the title of the sequence post, again (e.g., Why truth? And... )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">444444 the date when the sequence post was originally published (e.g., November 26, 2006 )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">555555 the lw wiki page where you found the summary (e.g., http://wiki.lesswrong.com/wiki/Less_Wrong/2006_Articles/Summaries )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">666666 the summary of the sequence post which you took from the lw wiki (e.g., You have an instrumental motive to care about the truth of your </span><em>beliefs about</em><span style=\"font-style: normal;\"> anything you care about. )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">777777 the url of the previous Sequence Reruns post (e.g., )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">888888 the title of the previous sequence post (e.g., The Martial Art of Rationality )</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">4. Click to create a new article</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">5. Make the title: [SEQ RERUN] 111111</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">6. Make the tags: sequence_reruns</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">7. On the &ldquo;submit article&rdquo; page, click where it says &ldquo;HTML&rdquo; (edit HTML source) and paste the edited version of the template that you've created.&nbsp; Click \"update.\"<br /></span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">8. Check and make sure your post looks okay. Does it have the appropriate title and tag? Have all of the strings of numbers been replaced? Was there any special formatting (like italics) in the summary which you need to add to the post?</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">9. Make the post. If there is a &ldquo;Post to&rdquo; option set it to &ldquo;Less Wrong Discussion&rdquo; (if there is not, you're already in the discussion section so it's fine) and click &ldquo;Submit.&rdquo;</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">10. The post should be made.&nbsp; Finally, leave a comment on the sequence post saying &ldquo;There is more discussion of this post [here](999999) as part of the Rerunning the Sequences series.&rdquo; Replace 999999 with the url of the post you just made.</span></p>\n<p style=\"margin-bottom: 0in;\">&nbsp;</p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">TEMPLATE:</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">Title: </span><span style=\"font-style: normal;\">[SEQ RERUN] 111111</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">Tags: </span><span style=\"font-style: normal;\">sequence_reruns</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">Today's post, &lt;a href=\"222222\"&gt;333333&lt;/a&gt; was originally published on 444444.&amp;nbsp; A summary (taken from the &lt;a href=\"555555\"&gt;LW wiki&lt;/a&gt;):&lt;/p&gt;</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">&lt;blockquote&gt;666666&lt;/blockquote&gt;</span></p>\n<p style=\"margin-bottom: 0in;\"><span style=\"font-style: normal;\">&lt;p&gt;&lt;br /&gt;Discuss the post here, rather than in the comments to the original post.&lt;br /&gt;&lt;br /&gt;&lt;em&gt;This post is part of the Rerunning the Sequences series, where we'll be going through Eliezer Yudkowsky's old posts in order so that people who are interested can (re-)read and discuss them.&amp;nbsp; The previous post was &lt;a href=\"777777\"&gt;888888&lt;/a&gt;, and you can use the &lt;a href=\"/r/discussion/tag/sequence_reruns/\"&gt;sequence_reruns tag&lt;/a&gt; to follow the rest of the series.&lt;br /&gt;&lt;br /&gt;Sequence reruns are a community-driven effort.&amp;nbsp; You can participate by re-reading the sequence post, discussing it here, posting the next day's sequence reruns post, or summarizing forthcoming articles on the wiki. Go &lt;a href=\"/r/discussion/lw/55t/new_less_wrong_feature_rerunning_the_sequences/\"&gt;here&lt;/a&gt; for more details, or to have meta discussions about the Rerunning the Sequences series.&lt;/em&gt;</span></p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "q3ByvNg95SgySmWzT", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 1, "baseScore": 2, "extendedScore": null, "score": 0, "legacy": true, "legacyId": "6867", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 0, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": true, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["reitXJgJXFzKpdKyd", "7XPZQddvD2RBEMdQq", "teaxCFgtmCQ3E9fy8", "LqjKP255fPRY7aMzw"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T12:24:43.249Z", "modifiedAt": null, "url": null, "title": "Cambridge Less Wrong Meetups April 21, May 1, May 15, ...", "slug": "cambridge-less-wrong-meetups-april-21-may-1-may-15", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:30.749Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jimrandomh", "createdAt": "2009-02-27T22:56:02.437Z", "isAdmin": true, "displayName": "jimrandomh"}, "userId": "nLbwLhBaQeG6tCNDN", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/NMr5CeKPBsLix8d2c/cambridge-less-wrong-meetups-april-21-may-1-may-15", "pageUrlRelative": "/posts/NMr5CeKPBsLix8d2c/cambridge-less-wrong-meetups-april-21-may-1-may-15", "linkUrl": "https://www.lesswrong.com/posts/NMr5CeKPBsLix8d2c/cambridge-less-wrong-meetups-april-21-may-1-may-15", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Cambridge%20Less%20Wrong%20Meetups%20April%2021%2C%20May%201%2C%20May%2015%2C%20...&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ACambridge%20Less%20Wrong%20Meetups%20April%2021%2C%20May%201%2C%20May%2015%2C%20...%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNMr5CeKPBsLix8d2c%2Fcambridge-less-wrong-meetups-april-21-may-1-may-15%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Cambridge%20Less%20Wrong%20Meetups%20April%2021%2C%20May%201%2C%20May%2015%2C%20...%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNMr5CeKPBsLix8d2c%2Fcambridge-less-wrong-meetups-april-21-may-1-may-15", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FNMr5CeKPBsLix8d2c%2Fcambridge-less-wrong-meetups-april-21-may-1-may-15", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 95, "htmlBody": "<p>The Cambridge, Massachusetts Less Wrong group has 2:00pm afternoon meetups on the first and third Sunday of every month. Additionally, we're having an extra meetup on Thursday evening (April 21) at 7:30pm. The full schedule is kept on <a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/\">meetup.com</a>, and you can join/subscribe to the group there to get e-mail reminders. Meetups take place at <a href=\"http://www.meetup.com/Cambridge-Less-Wrong-Meetup/venue/912336/\">Cosi</a>, near Kendall Square on the red line. Follow the right-hand rule to reach our usual table, which is in the back room where it's reasonably quiet (except for us). All are welcome to attend and no RSVP is necessary.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "NMr5CeKPBsLix8d2c", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 6, "baseScore": 8, "extendedScore": null, "score": 7.04248804004426e-07, "legacy": true, "legacyId": "6878", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 5, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 4, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T15:05:34.930Z", "modifiedAt": null, "url": null, "title": "SIAI awareness opportunity", "slug": "siai-awareness-opportunity", "viewCount": null, "lastCommentedAt": null, "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "curiousepic", "createdAt": "2010-04-15T14:35:25.116Z", "isAdmin": false, "displayName": "curiousepic"}, "userId": "wxLCJJwvPiQbkXjTe", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/xwSsDrrQGhqrxQpdM/siai-awareness-opportunity", "pageUrlRelative": "/posts/xwSsDrrQGhqrxQpdM/siai-awareness-opportunity", "linkUrl": "https://www.lesswrong.com/posts/xwSsDrrQGhqrxQpdM/siai-awareness-opportunity", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20SIAI%20awareness%20opportunity&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASIAI%20awareness%20opportunity%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxwSsDrrQGhqrxQpdM%2Fsiai-awareness-opportunity%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=SIAI%20awareness%20opportunity%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxwSsDrrQGhqrxQpdM%2Fsiai-awareness-opportunity", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FxwSsDrrQGhqrxQpdM%2Fsiai-awareness-opportunity", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 31, "htmlBody": "<p>I'm using today's <a href=\"http://www.facebook.com/event.php?eid=203785532977845\">\"Skynet becomes self-aware\" Facebook event</a> to link to&nbsp;<a href=\"http://intelligence.org/\">http://singinst.org/</a>. &nbsp;Today (intentionally) is also the release date for Portal 2, which you should know features an unfriendly, if entertaining, AGI.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "xwSsDrrQGhqrxQpdM", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 9, "baseScore": 9, "extendedScore": null, "score": 7.042942479737935e-07, "legacy": true, "legacyId": "6879", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 6, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": null, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T15:27:28.702Z", "modifiedAt": null, "url": null, "title": "Planning a series: discounting utility", "slug": "planning-a-series-discounting-utility", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:32.555Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "Psychohistorian", "createdAt": "2009-04-05T18:10:22.976Z", "isAdmin": false, "displayName": "Psychohistorian"}, "userId": "mAQgf4N8jv2jTMK5B", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/Eu9gmpDLRRudjKMbD/planning-a-series-discounting-utility", "pageUrlRelative": "/posts/Eu9gmpDLRRudjKMbD/planning-a-series-discounting-utility", "linkUrl": "https://www.lesswrong.com/posts/Eu9gmpDLRRudjKMbD/planning-a-series-discounting-utility", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Planning%20a%20series%3A%20discounting%20utility&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0APlanning%20a%20series%3A%20discounting%20utility%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEu9gmpDLRRudjKMbD%2Fplanning-a-series-discounting-utility%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Planning%20a%20series%3A%20discounting%20utility%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEu9gmpDLRRudjKMbD%2Fplanning-a-series-discounting-utility", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FEu9gmpDLRRudjKMbD%2Fplanning-a-series-discounting-utility", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 858, "htmlBody": "<p>I'm planning a top-level post (probably two or three or more) on when agent utility should not be part of utilitarian calculations - which seems to be an interesting and controversial topic given some recent posts. I'm looking for additional ideas, and particularly counterarguments. Also hunting for article titles. The series would look something like the following - noting that obviously this summary does not have much room for nuance or background argument. I'm assuming moral antirealism, with the selection of utilitarianism as an implemented moral system.</p>\n<p>Intro - Utilitarianism has serious, fundamental measurement problems, and sometimes substantially contradicts our intuitions. One solution is to say our intuitions are wrong - this isn't quite right (i.e. a morality can't be \"wrong\") unless our intuitions are internally inconsistent, which I do not think is the problem. This is particularly problematic because agents (especially with high self modification capacities) may face socially undesirable incentives. I argue that a better solution is to ignore or discount the utility of certain agents in certain circumstances. This better fits general moral intuitions. (There remains a debate as to whether Morality A might be better than Morality B when Morality B better matches our general intuitions - I don't want to get into this, as I'm not sure there's a non-circular meaning of \"better\" as applied to morality that does not relate to moral intuitions.)</p>\n<p>1 -First, expressly anti-utilitarian utility can be disregarded. Most of the cases of this are fairly simple and bright-line. No matter how much Bob enjoys raping people, the utility he derives from doing so is irrelevant unless he drinks the utilitarian Koolaid and only, for example, engages in rape fantasies (in which case his utility is counted - the issue is not that his desire is bad, it's that his actions are). This gets into some slight line-drawing problems with, for example, utility derived from competition (as one may delight in defeating people - this probably survives, however, particularly since it is all consensual).</p>\n<p>1.5 - The above point is also related to the issue of discounting the future utility of such persons; I'm trying to figure out if it belongs in this sequence. The example I plan to use (which makes pretty much the entire point) is as follows. You have some chocolate ice cream you have to give away. You can give it to a small child and a person who has just brutally beaten and molested that child. The child kinda likes chocolate ice cream; vanilla is his favorite flavor, but chocolate's OK. The adult absolutely, totally loves chocolate ice cream; it's his favorite food in the world. I, personally, give the kid the ice cream, and I think so does well over 90% of the general population. On the other hand, if the adult were simply someone who had an interest in molesting children, but scrupulously never acted on it, I would not discount his utility so cheerfully. This may simply belong as a separate post on its own on the utility value of punishment. I'd be interested in feedback on it.</p>\n<p>2 -Finally, and trickiest, is the problem of utility conditioned on false beliefs. Take two examples: an african village stoning a child to death because they think she's a witch who has made it stop raining, and the same village curing that&nbsp;witch-hood&nbsp;by ritually dunking her in holy water (or by some other innocuous procedure). In the former case, there's massive disutility that occurs because people will think it will solve a problem that it won't (I'm also a little unclear on what it would mean for the utility of the many to \"outweigh\" the utility of the one, but that's an issue I'll address in the intro article). In the latter, there's minimal disutility (maybe even positive utility), even though there's the same impotence. The best answer seems to be that utility conditioned on false beliefs should be ignored to the extent that it is conditioned on false beliefs. Many people (myself included) celebrate religious holidays with no belief whatsoever in the underlying religion - there is substantial value in the gathering of family and community. Similarly, there is some value to the gathering of the community in both village cases; in the murder it doesn't outweigh the costs, in the baptism it very well might.</p>\n<p>3 - (tentative) How this approach coincides with the unweighted approach in the long term. Basically, if we ignore certain kinds of utility, we will encourage agents to pursue other kinds of utility (if you can't burn witches to improve your harvest, perhaps you'll learn how to rotate crops better). The utility they pursue is likely to be of only somewhat lower value to them (or higher value in some cases, if they're imperfect, i.e. human). However, it will be of non-negative value to others. Thus, a policy-maker employing adjusted&nbsp;utilitarianism&nbsp;is likely to obtain better outcomes from an unweighted perspective. I'm not sure this point is correct or cogent.</p>\n<p>I'm aware at least some of this is against lesswrong canon. I'm curious as to if people have counterarguments, objections, counterexamples, or general feedback on whether this would be a desirable series to spell out.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "Eu9gmpDLRRudjKMbD", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 7, "baseScore": 3, "extendedScore": null, "score": 7.043004341301651e-07, "legacy": true, "legacyId": "6880", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 2, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 17, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T15:32:32.251Z", "modifiedAt": null, "url": null, "title": "Meetup meta: please think carefully when posting -- add desired time/title the first time", "slug": "meetup-meta-please-think-carefully-when-posting-add-desired", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:31.235Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "jwhendy", "createdAt": "2011-01-04T19:53:21.160Z", "isAdmin": false, "displayName": "jwhendy"}, "userId": "ZaJctSZkCvg7qvSEC", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/uJQDMueTbdF9PcY8a/meetup-meta-please-think-carefully-when-posting-add-desired", "pageUrlRelative": "/posts/uJQDMueTbdF9PcY8a/meetup-meta-please-think-carefully-when-posting-add-desired", "linkUrl": "https://www.lesswrong.com/posts/uJQDMueTbdF9PcY8a/meetup-meta-please-think-carefully-when-posting-add-desired", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Meetup%20meta%3A%20please%20think%20carefully%20when%20posting%20--%20add%20desired%20time%2Ftitle%20the%20first%20time&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0AMeetup%20meta%3A%20please%20think%20carefully%20when%20posting%20--%20add%20desired%20time%2Ftitle%20the%20first%20time%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuJQDMueTbdF9PcY8a%2Fmeetup-meta-please-think-carefully-when-posting-add-desired%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Meetup%20meta%3A%20please%20think%20carefully%20when%20posting%20--%20add%20desired%20time%2Ftitle%20the%20first%20time%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuJQDMueTbdF9PcY8a%2Fmeetup-meta-please-think-carefully-when-posting-add-desired", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FuJQDMueTbdF9PcY8a%2Fmeetup-meta-please-think-carefully-when-posting-add-desired", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 150, "htmlBody": "<p>There seem to here have been a fair amount of meetups posted with no times, and then re-posted with added times or slightly adjusted wording. Perhaps Google Reader is the problem (how I follow the top-level), but not only are there a lot of meetups (which has been talked about quite a bit lately), but these changed post titles show up as two separate entities. (<a href=\"http://i.imgur.com/Q0tUG.png\">Example</a>)</p>\n<p>For planners, please think carefully when announcing your meetup and post the time and the title you want on the first try, if possible.&nbsp;Thanks.</p>\n<p>&nbsp;</p>\n<p>Perhaps a standard title format could be proposed that handled such things?</p>\n<blockquote>\n<p>Meetup: [City/State/Country] [Time] [AM/PM] @ [Venue]</p>\n</blockquote>\n<p>Or something like that? This would have the benefit of helping planners not forget anything important, but might have the added benefit that if <a href=\"/r/discussion/lw/57r/meta_meetup_section_of_the_site/\">a future implementation of some sort</a>&nbsp;makes a meetup page or auto-scraped list of happenings, a standard format will make this easier.</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": null, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "uJQDMueTbdF9PcY8a", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 8, "baseScore": 12, "extendedScore": null, "score": 7.043018634526368e-07, "legacy": true, "legacyId": "6881", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 7, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 9, "af": false, "version": "1.0.0", "pingbacks": {"Posts": ["eEHaBBspvgE33kwot"]}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}, {"createdAt": null, "postedAt": "2011-04-19T17:27:34.178Z", "modifiedAt": null, "url": null, "title": "Singularity FAQ", "slug": "singularity-faq", "viewCount": null, "lastCommentedAt": "2017-06-17T03:58:48.257Z", "clickCount": null, "deletedDraft": false, "status": 2, "isFuture": false, "sticky": false, "stickyPriority": 2, "userIP": null, "userAgent": null, "referrer": null, "author": null, "user": {"username": "lukeprog", "createdAt": "2009-03-19T08:07:34.230Z", "isAdmin": false, "displayName": "lukeprog"}, "userId": "SdZmP36R37riQrHAw", "domain": null, "pageUrl": "https://www.lesswrong.com/posts/TYrN5yMSRFQwqDRHS/singularity-faq", "pageUrlRelative": "/posts/TYrN5yMSRFQwqDRHS/singularity-faq", "linkUrl": "https://www.lesswrong.com/posts/TYrN5yMSRFQwqDRHS/singularity-faq", "postedAtFormatted": "Tuesday, April 19th 2011", "emailShareUrl": "mailto:?subject=Interesting%20link%3A%20Singularity%20FAQ&body=I%20thought%20you%20might%20find%20this%20interesting%3A%0A%0ASingularity%20FAQ%0Ahttps%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTYrN5yMSRFQwqDRHS%2Fsingularity-faq%0A%0A(found%20via%20https%3A%2F%2Fwww.lesswrong.com)%0A%20%20", "twitterShareUrl": "https://twitter.com/intent/tweet?text=Singularity%20FAQ%20https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTYrN5yMSRFQwqDRHS%2Fsingularity-faq", "facebookShareUrl": "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.lesswrong.com%2Fposts%2FTYrN5yMSRFQwqDRHS%2Fsingularity-faq", "socialPreviewImageUrl": "", "question": false, "authorIsUnreviewed": false, "wordCount": 35, "htmlBody": "<p>I wrote a new Singularity FAQ for the Singularity Institute's website. <a href=\"http://intelligence.org/singularityfaq\">Here it is</a>. I'm sure it will evolve over time. Many thanks to those who helped me revise early drafts, especially Carl and Anna!</p>", "submitToFrontpage": true, "hiddenRelatedQuestion": false, "originalPostRelationSourceId": null, "shortform": false, "canonicalSource": null, "nominationCount2018": null, "nominationCount2019": 0, "reviewCount2018": null, "reviewCount2019": null, "reviewCount": 0, "reviewVoteCount": 0, "positiveReviewVoteCount": 0, "reviewVoteScoreAF": null, "reviewVotesAF": null, "reviewVoteScoreHighKarma": null, "reviewVotesHighKarma": null, "reviewVoteScoreAllKarma": null, "reviewVotesAllKarma": null, "finalReviewVoteScoreHighKarma": null, "finalReviewVotesHighKarma": null, "finalReviewVoteScoreAllKarma": null, "finalReviewVotesAllKarma": null, "finalReviewVoteScoreAF": null, "finalReviewVotesAF": null, "lastCommentPromotedAt": null, "tagRelevance": {"DigEmY3RrF3XL5cwe": 1, "5f5c37ee1b5cdee568cfb1be": 1}, "noIndex": null, "rsvps": null, "activateRSVPs": null, "nextDayReminderSent": null, "onlyVisibleToLoggedIn": null, "onlyVisibleToEstablishedAccounts": null, "votingSystem": null, "myEditorAccess": "none", "_id": "TYrN5yMSRFQwqDRHS", "schemaVersion": 2, "currentUserVote": null, "currentUserExtendedVote": null, "allVotes": [{"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallDownvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}, {"voteType": "smallUpvote", "cancelled": false, "isUnvote": false}], "voteCount": 19, "baseScore": 22, "extendedScore": null, "score": 7.043343642825545e-07, "legacy": true, "legacyId": "6883", "legacySpam": null, "feedId": null, "feedLink": null, "lastVisitedAt": null, "isRead": false, "curatedDate": null, "metaDate": null, "suggestForCuratedUsernames": null, "suggestForCuratedUserIds": null, "frontpageDate": null, "collectionTitle": null, "coauthorUserIds": null, "socialPreviewImageId": null, "socialPreviewImageAutoUrl": null, "canonicalSequenceId": null, "canonicalCollectionSlug": null, "canonicalBookId": null, "canonicalNextPostSlug": null, "canonicalPrevPostSlug": null, "unlisted": false, "disableRecommendation": null, "defaultRecommendation": null, "draft": null, "meta": false, "hideFrontpageComments": false, "maxBaseScore": 16, "bannedUserIds": null, "commentsLocked": null, "organizerIds": null, "groupId": null, "eventType": null, "isEvent": false, "reviewedByUserId": "XtphY3uYHwruKqDyG", "reviewForCuratedUserId": null, "startTime": null, "localStartTime": null, "endTime": null, "localEndTime": null, "eventRegistrationLink": null, "joinEventLink": null, "onlineEvent": null, "globalEvent": null, "mongoLocation": null, "googleLocation": null, "location": null, "contactInfo": null, "facebookLink": null, "meetupLink": null, "website": null, "eventImageId": null, "types": null, "metaSticky": false, "sharingSettings": null, "shareWithUsers": null, "linkSharingKey": null, "linkSharingKeyUsedBy": null, "commentSortOrder": null, "hideAuthor": false, "tableOfContents": null, "showModerationGuidelines": false, "moderationStyle": null, "hideCommentKarma": null, "commentCount": 35, "af": false, "version": "1.0.0", "pingbacks": {}, "moderationGuidelinesVersion": null, "customHighlightVersion": null, "afDate": null, "afBaseScore": 0, "afExtendedScore": null, "afCommentCount": null, "afLastCommentedAt": null, "afSticky": false, "suggestForAlignmentUserIds": null, "reviewForAlignmentUserId": null}]}